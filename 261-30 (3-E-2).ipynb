{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3010,"status":"ok","timestamp":1726456639423,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"m0hxbkmFQqQ3","outputId":"8ec6476d-b767-485a-dc26-6ecd69ad4030"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"]}],"source":["!pip install xlrd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7500,"status":"ok","timestamp":1726456646920,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"-dVSaH6MdwMU","outputId":"e90725c5-d235-49f4-a1e2-2eaf2320984e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"]}],"source":["!pip install openpyxl\n","\n","import pathlib\n","\n","import pandas as pd\n","import numpy as np\n","import xlrd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import PercentFormatter\n","import scipy.stats as stats\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1510,"status":"ok","timestamp":1726456648417,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"SWB0I35adDWT","outputId":"47bce6ab-1946-496b-8916-9114a6208134"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2759,"status":"ok","timestamp":1726456651173,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"XrclvH4fQA_I","outputId":"b4a77328-dc76-492f-a217-09cdc77b0300"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (0.4.6)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.26.4)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.3.2)\n","Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n"]}],"source":["!pip install bayesian-optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1726456651672,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"6b7epD9JV04o","outputId":"01adad30-242b-4a33-fcd7-f9405bc25fbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         Días      Área  PY_VC_PCA  Valor_Proyecto\n","#                                                 \n","1    0.199969 -0.224328  -0.670771       -0.563421\n","2    0.199969 -0.224328  -0.670771       -0.545120\n","3    0.199969 -0.222966  -0.670771       -0.544601\n","4    0.199969 -0.222966  -0.670771       -0.532932\n","5    1.478731 -0.182279  -0.670771       -0.532623\n","..        ...       ...        ...             ...\n","121 -0.699160 -0.219754  -1.883419       -0.617652\n","122 -0.659199 -0.223679  -1.883419       -0.604545\n","123 -0.579276 -0.224410  -1.883419       -0.584883\n","124 -0.898967 -0.074911  -1.932311       -0.488695\n","125  0.080085 -0.203695  -0.670771        1.333930\n","\n","[115 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-b257bc56-e6ed-43fd-b06d-d881e6c83345\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Días</th>\n","      <th>Área</th>\n","      <th>PY_VC_PCA</th>\n","      <th>Valor_Proyecto</th>\n","    </tr>\n","    <tr>\n","      <th>#</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.199969</td>\n","      <td>-0.224328</td>\n","      <td>-0.670771</td>\n","      <td>-0.563421</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.199969</td>\n","      <td>-0.224328</td>\n","      <td>-0.670771</td>\n","      <td>-0.545120</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.199969</td>\n","      <td>-0.222966</td>\n","      <td>-0.670771</td>\n","      <td>-0.544601</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.199969</td>\n","      <td>-0.222966</td>\n","      <td>-0.670771</td>\n","      <td>-0.532932</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.478731</td>\n","      <td>-0.182279</td>\n","      <td>-0.670771</td>\n","      <td>-0.532623</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>-0.699160</td>\n","      <td>-0.219754</td>\n","      <td>-1.883419</td>\n","      <td>-0.617652</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>-0.659199</td>\n","      <td>-0.223679</td>\n","      <td>-1.883419</td>\n","      <td>-0.604545</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>-0.579276</td>\n","      <td>-0.224410</td>\n","      <td>-1.883419</td>\n","      <td>-0.584883</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>-0.898967</td>\n","      <td>-0.074911</td>\n","      <td>-1.932311</td>\n","      <td>-0.488695</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>0.080085</td>\n","      <td>-0.203695</td>\n","      <td>-0.670771</td>\n","      <td>1.333930</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>115 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b257bc56-e6ed-43fd-b06d-d881e6c83345')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b257bc56-e6ed-43fd-b06d-d881e6c83345 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b257bc56-e6ed-43fd-b06d-d881e6c83345');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4828f07b-0c9f-4dc3-9703-88c5cec20c7d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4828f07b-0c9f-4dc3-9703-88c5cec20c7d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4828f07b-0c9f-4dc3-9703-88c5cec20c7d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_0970bab0-71c3-4c7a-ae76-8021ff3c43a1\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('PY_DATOS_REALES_EST_SA')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0970bab0-71c3-4c7a-ae76-8021ff3c43a1 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('PY_DATOS_REALES_EST_SA');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"PY_DATOS_REALES_EST_SA","summary":"{\n  \"name\": \"PY_DATOS_REALES_EST_SA\",\n  \"rows\": 115,\n  \"fields\": [\n    {\n      \"column\": \"#\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 1,\n        \"max\": 125,\n        \"num_unique_values\": 115,\n        \"samples\": [\n          88,\n          5,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D\\u00edas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803867251482979,\n        \"min\": -0.9189475169275999,\n        \"max\": 3.576699032651917,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          1.099098267550317,\n          0.3198528656232003,\n          0.1999689576344132\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u00c1rea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6059869599176284,\n        \"min\": -0.2244174118541763,\n        \"max\": 4.300395967794374,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          -0.2215413972005786,\n          -0.221120588490909,\n          -0.2197543115106207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PY_VC_PCA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.861373017906514,\n        \"min\": -1.932310996606438,\n        \"max\": 3.52411703404423,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          2.311469443226625,\n          -0.4732605429692015,\n          -0.6707711165617886\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valor_Proyecto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7062492114343796,\n        \"min\": -0.6821759220149384,\n        \"max\": 2.571424409907773,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.1168984995526829,\n          -0.5326233376160263,\n          -0.4347466604685049\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}],"source":["PY_DATOS_REALES_EST_SA=pd.read_excel(\"/content/drive/MyDrive/Datos/Copia de 4 Variables. Datos reales estandarizados sin atípicos (z-score).xlsx\", sheet_name='Datos sin atipicos', header=0, index_col=0, usecols='A, B, C, D, E')\n","PY_DATOS_REALES_EST_SA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726456651673,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"V79YMsGZZZF5","outputId":"b5e2899d-b30c-4b71-f038-af16c9d1fd02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             Días        Área   PY_VC_PCA  Valor_Proyecto\n","count  115.000000  115.000000  115.000000      115.000000\n","mean    -0.082193   -0.098454   -0.089025       -0.097465\n","std      0.780387    0.605987    1.861373        0.706249\n","min     -0.918948   -0.224417   -1.932311       -0.682176\n","25%     -0.669189   -0.224096   -1.883419       -0.587202\n","50%     -0.359489   -0.222363   -0.670771       -0.410561\n","75%      0.219950   -0.203633    0.739387        0.150954\n","max      3.576699    4.300396    3.524117        2.571424"],"text/html":["\n","  <div id=\"df-03e4fb2e-1277-489a-bd57-827f222919d2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Días</th>\n","      <th>Área</th>\n","      <th>PY_VC_PCA</th>\n","      <th>Valor_Proyecto</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>115.000000</td>\n","      <td>115.000000</td>\n","      <td>115.000000</td>\n","      <td>115.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-0.082193</td>\n","      <td>-0.098454</td>\n","      <td>-0.089025</td>\n","      <td>-0.097465</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.780387</td>\n","      <td>0.605987</td>\n","      <td>1.861373</td>\n","      <td>0.706249</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-0.918948</td>\n","      <td>-0.224417</td>\n","      <td>-1.932311</td>\n","      <td>-0.682176</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-0.669189</td>\n","      <td>-0.224096</td>\n","      <td>-1.883419</td>\n","      <td>-0.587202</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-0.359489</td>\n","      <td>-0.222363</td>\n","      <td>-0.670771</td>\n","      <td>-0.410561</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.219950</td>\n","      <td>-0.203633</td>\n","      <td>0.739387</td>\n","      <td>0.150954</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.576699</td>\n","      <td>4.300396</td>\n","      <td>3.524117</td>\n","      <td>2.571424</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03e4fb2e-1277-489a-bd57-827f222919d2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-03e4fb2e-1277-489a-bd57-827f222919d2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-03e4fb2e-1277-489a-bd57-827f222919d2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e1c36264-96d5-479b-a9c3-ca033006abc1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1c36264-96d5-479b-a9c3-ca033006abc1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e1c36264-96d5-479b-a9c3-ca033006abc1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"PY_DATOS_REALES_EST_SA\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"D\\u00edas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.5545662531427,\n        \"min\": -0.9189475169275999,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.08219258812470316,\n          -0.3594892796465934,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u00c1rea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.48971129133538,\n        \"min\": -0.2244174118541763,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.09845418591053573,\n          -0.2223626584729893,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PY_VC_PCA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.62230361790927,\n        \"min\": -1.932310996606438,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.08902548734541608,\n          -0.6707711165617886,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valor_Proyecto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.58885053966308,\n        \"min\": -0.6821759220149384,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.09746450807400997,\n          -0.4105610840414156,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["PY_DATOS_REALES_EST_SA.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUevuBrFumOK"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, ReLU, ELU, Activation\n","from keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adagrad\n","from keras.regularizers import l2\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import tensorflow as tf\n","from bayes_opt import BayesianOptimization\n","from scipy.stats import spearmanr\n","import random\n","\n","# Fijar la semilla para reproducibilidad\n","random.seed(42)\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# Función personalizada para calcular SSE\n","def sse(y_true, y_pred):\n","    return tf.reduce_sum(tf.square(y_true - y_pred))\n","\n","# Función personalizada para calcular SAE\n","def sae(y_true, y_pred):\n","    return tf.reduce_sum(tf.abs(y_true - y_pred))\n","\n","# Función personalizada para calcular el coeficiente de determinación R^2\n","def r2_keras(y_true, y_pred):\n","    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n","    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n","    return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n","\n","# Función personalizada para calcular el coeficiente de correlación de Pearson\n","def pearson_correlation(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float64)\n","    y_pred = tf.cast(y_pred, tf.float64)\n","    x = y_true - tf.reduce_mean(y_true)\n","    y = y_pred - tf.reduce_mean(y_pred)\n","    r_num = tf.reduce_sum(x * y)\n","    r_den = tf.sqrt(tf.reduce_sum(tf.square(x)) * tf.reduce_sum(tf.square(y)))\n","    return r_num / (r_den + tf.keras.backend.epsilon())\n","\n","# Función para calcular RMSE\n","def rmse(y_true, y_pred):\n","    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n","\n","# Seleccionar las columnas relevantes para la predicción de 'Valor_Proyecto'\n","data = PY_DATOS_REALES_EST_SA[['Días', 'Área', 'PY_VC_PCA', 'Valor_Proyecto']]\n","X = data.drop('Valor_Proyecto', axis=1).values\n","y = data['Valor_Proyecto'].values\n","\n","# Dividir los datos en entrenamiento y validación con una semilla fija\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqOzCp8HvXOs","outputId":"79725bb3-7092-448a-8dd0-687f25f86ec4","executionInfo":{"status":"ok","timestamp":1726457124357,"user_tz":300,"elapsed":162750,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["|   iter    |  target   | learni... |  units_1  |  units_2  |\n","-------------------------------------------------------------\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - huber_loss: 0.6724 - loss: 0.7614 - mae: 1.0486 - mse: 2.0130 - pearson_correlation: 5.9929e-16 - r2_keras: -246.6328 - rmse: 1.3694 - sae: 4115.5127 - sse: 7681.2598\n","Epoch 1: val_loss improved from inf to 0.32601, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 570ms/step - huber_loss: 0.8477 - loss: 0.8682 - mae: 1.1692 - mse: 2.5215 - pearson_correlation: 5.4729e-16 - r2_keras: -292.8384 - rmse: 1.7143 - sae: 3209.6931 - sse: 6631.0806 - val_huber_loss: 0.2366 - val_loss: 0.3260 - val_mae: 0.6002 - val_mse: 0.5357 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -25.1031 - val_rmse: 0.8320 - val_sae: 368.6128 - val_sse: 366.1766 - learning_rate: 0.0375\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3981 - loss: 0.4875 - mae: 0.7057 - mse: 1.0611 - pearson_correlation: -1.6205e-16 - r2_keras: -228.0875 - rmse: 1.3171 - sae: 3948.7158 - sse: 7106.0078\n","Epoch 2: val_loss did not improve from 0.32601\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.3663 - loss: 0.4682 - mae: 0.6850 - mse: 0.9834 - pearson_correlation: -3.4909e-17 - r2_keras: -171.9336 - rmse: 1.1956 - sae: 2822.2517 - sse: 4974.3857 - val_huber_loss: 0.2880 - val_loss: 0.3775 - val_mae: 0.6698 - val_mse: 0.6339 - val_pearson_correlation: -1.4322e-16 - val_r2_keras: -27.6475 - val_rmse: 0.8716 - val_sae: 398.7686 - val_sse: 401.8703 - learning_rate: 0.0375\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.2295 - loss: 0.3190 - mae: 0.5526 - mse: 0.4889 - pearson_correlation: 1.0761e-16 - r2_keras: -122.3480 - rmse: 0.9665 - sae: 3147.7666 - sse: 3826.0996\n","Epoch 3: val_loss did not improve from 0.32601\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.2318 - loss: 0.3204 - mae: 0.5513 - mse: 0.4908 - pearson_correlation: 5.6870e-17 - r2_keras: -101.0722 - rmse: 0.9589 - sae: 2294.0549 - sse: 2783.4597 - val_huber_loss: 0.3324 - val_loss: 0.4219 - val_mae: 0.7162 - val_mse: 0.7295 - val_pearson_correlation: -4.9434e-16 - val_r2_keras: -29.2832 - val_rmse: 0.8961 - val_sae: 407.1118 - val_sse: 424.8159 - learning_rate: 0.0375\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.2359 - loss: 0.3253 - mae: 0.5673 - mse: 0.5231 - pearson_correlation: -3.9633e-16 - r2_keras: -126.2345 - rmse: 0.9816 - sae: 2964.0950 - sse: 3946.6562\n","Epoch 4: val_loss did not improve from 0.32601\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.2239 - loss: 0.3180 - mae: 0.5619 - mse: 0.5005 - pearson_correlation: -4.3962e-16 - r2_keras: -105.5351 - rmse: 0.9835 - sae: 2186.1519 - sse: 2885.7871 - val_huber_loss: 0.3891 - val_loss: 0.4784 - val_mae: 0.7871 - val_mse: 0.8362 - val_pearson_correlation: -7.3342e-17 - val_r2_keras: -32.9489 - val_rmse: 0.9488 - val_sae: 440.4771 - val_sse: 476.2383 - learning_rate: 0.0375\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2002 - loss: 0.2895 - mae: 0.5068 - mse: 0.4100 - pearson_correlation: 4.1191e-16 - r2_keras: -97.3049 - rmse: 0.8628 - sae: 2698.9292 - sse: 3049.2944\n","Epoch 5: val_loss did not improve from 0.32601\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.1968 - loss: 0.2875 - mae: 0.5135 - mse: 0.4052 - pearson_correlation: 2.2649e-16 - r2_keras: -88.3842 - rmse: 0.9201 - sae: 2016.0892 - sse: 2312.5969 - val_huber_loss: 0.3562 - val_loss: 0.4455 - val_mae: 0.7525 - val_mse: 0.7624 - val_pearson_correlation: 9.5160e-17 - val_r2_keras: -32.2181 - val_rmse: 0.9386 - val_sae: 434.3171 - val_sse: 465.9870 - learning_rate: 0.0375\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1374 - loss: 0.2267 - mae: 0.4123 - mse: 0.2844 - pearson_correlation: -1.0564e-15 - r2_keras: -88.0411 - rmse: 0.8212 - sae: 2498.8247 - sse: 2761.9448\n","Epoch 6: val_loss did not improve from 0.32601\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1264 - loss: 0.2200 - mae: 0.4023 - mse: 0.2697 - pearson_correlation: -7.3758e-16 - r2_keras: -76.0911 - rmse: 0.8448 - sae: 1848.5778 - sse: 2049.2744 - val_huber_loss: 0.2955 - val_loss: 0.3848 - val_mae: 0.6799 - val_mse: 0.6385 - val_pearson_correlation: 4.0275e-17 - val_r2_keras: -31.3530 - val_rmse: 0.9263 - val_sae: 419.0022 - val_sse: 453.8521 - learning_rate: 0.0375\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0922 - loss: 0.1815 - mae: 0.3062 - mse: 0.1936 - pearson_correlation: -3.4713e-16 - r2_keras: -95.1202 - rmse: 0.8532 - sae: 2513.1113 - sse: 2981.5283\n","Epoch 7: val_loss did not improve from 0.32601\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0866 - loss: 0.1781 - mae: 0.3016 - mse: 0.1852 - pearson_correlation: -2.8564e-16 - r2_keras: -77.7784 - rmse: 0.8395 - sae: 1834.9937 - sse: 2160.0969 - val_huber_loss: 0.2498 - val_loss: 0.3391 - val_mae: 0.6140 - val_mse: 0.5409 - val_pearson_correlation: 1.0879e-16 - val_r2_keras: -30.7978 - val_rmse: 0.9183 - val_sae: 406.0451 - val_sse: 446.0630 - learning_rate: 0.0075\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0860 - loss: 0.1752 - mae: 0.2749 - mse: 0.1822 - pearson_correlation: 6.2556e-16 - r2_keras: -98.6639 - rmse: 0.8688 - sae: 2538.8250 - sse: 3091.4492\n","Epoch 8: val_loss improved from 0.32601 to 0.30361, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0795 - loss: 0.1713 - mae: 0.2702 - mse: 0.1724 - pearson_correlation: 4.1731e-16 - r2_keras: -80.0289 - rmse: 0.8489 - sae: 1850.9714 - sse: 2232.0637 - val_huber_loss: 0.2144 - val_loss: 0.3036 - val_mae: 0.5522 - val_mse: 0.4646 - val_pearson_correlation: 1.7793e-16 - val_r2_keras: -30.7216 - val_rmse: 0.9172 - val_sae: 395.6732 - val_sse: 444.9936 - learning_rate: 0.0075\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0845 - loss: 0.1738 - mae: 0.2673 - mse: 0.1790 - pearson_correlation: -2.2663e-17 - r2_keras: -99.9893 - rmse: 0.8745 - sae: 2554.4792 - sse: 3132.5620\n","Epoch 9: val_loss improved from 0.30361 to 0.27284, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0778 - loss: 0.1697 - mae: 0.2631 - mse: 0.1689 - pearson_correlation: 5.4344e-17 - r2_keras: -80.9683 - rmse: 0.8532 - sae: 1862.1243 - sse: 2260.1272 - val_huber_loss: 0.1836 - val_loss: 0.2728 - val_mae: 0.4886 - val_mse: 0.3982 - val_pearson_correlation: 1.9046e-16 - val_r2_keras: -30.8232 - val_rmse: 0.9186 - val_sae: 385.2497 - val_sse: 446.4200 - learning_rate: 0.0075\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0833 - loss: 0.1726 - mae: 0.2632 - mse: 0.1760 - pearson_correlation: -1.5094e-15 - r2_keras: -100.4179 - rmse: 0.8764 - sae: 2562.1465 - sse: 3145.8567\n","Epoch 10: val_loss improved from 0.27284 to 0.24692, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0766 - loss: 0.1685 - mae: 0.2594 - mse: 0.1661 - pearson_correlation: -9.0675e-16 - r2_keras: -81.3199 - rmse: 0.8551 - sae: 1867.7904 - sse: 2269.7629 - val_huber_loss: 0.1577 - val_loss: 0.2469 - val_mae: 0.4330 - val_mse: 0.3423 - val_pearson_correlation: -2.3050e-16 - val_r2_keras: -31.0421 - val_rmse: 0.9218 - val_sae: 375.2430 - val_sse: 449.4897 - learning_rate: 0.0075\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0823 - loss: 0.1715 - mae: 0.2603 - mse: 0.1735 - pearson_correlation: 4.5495e-16 - r2_keras: -100.4313 - rmse: 0.8764 - sae: 2565.0039 - sse: 3146.2715\n","Epoch 11: val_loss improved from 0.24692 to 0.22764, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0756 - loss: 0.1674 - mae: 0.2569 - mse: 0.1636 - pearson_correlation: 2.9811e-16 - r2_keras: -81.3703 - rmse: 0.8555 - sae: 1870.0289 - sse: 2270.5259 - val_huber_loss: 0.1385 - val_loss: 0.2276 - val_mae: 0.3854 - val_mse: 0.3006 - val_pearson_correlation: -6.3645e-17 - val_r2_keras: -31.4815 - val_rmse: 0.9281 - val_sae: 366.6319 - val_sse: 455.6536 - learning_rate: 0.0075\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0815 - loss: 0.1707 - mae: 0.2584 - mse: 0.1714 - pearson_correlation: -6.3445e-16 - r2_keras: -100.3447 - rmse: 0.8761 - sae: 2565.8601 - sse: 3143.5872\n","Epoch 12: val_loss improved from 0.22764 to 0.21450, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0748 - loss: 0.1666 - mae: 0.2550 - mse: 0.1617 - pearson_correlation: -4.3949e-16 - r2_keras: -81.3640 - rmse: 0.8557 - sae: 1870.9119 - sse: 2269.3391 - val_huber_loss: 0.1253 - val_loss: 0.2145 - val_mae: 0.3545 - val_mse: 0.2719 - val_pearson_correlation: 1.2096e-17 - val_r2_keras: -32.0800 - val_rmse: 0.9366 - val_sae: 361.7786 - val_sse: 464.0498 - learning_rate: 0.0075\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1699 - mae: 0.2568 - mse: 0.1696 - pearson_correlation: 6.3679e-16 - r2_keras: -100.2771 - rmse: 0.8758 - sae: 2566.1902 - sse: 3141.4878\n","Epoch 13: val_loss improved from 0.21450 to 0.20586, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0740 - loss: 0.1658 - mae: 0.2533 - mse: 0.1598 - pearson_correlation: 4.3584e-16 - r2_keras: -81.3699 - rmse: 0.8560 - sae: 1871.4039 - sse: 2268.5383 - val_huber_loss: 0.1167 - val_loss: 0.2059 - val_mae: 0.3360 - val_mse: 0.2529 - val_pearson_correlation: 2.3258e-17 - val_r2_keras: -32.7156 - val_rmse: 0.9456 - val_sae: 359.9664 - val_sse: 472.9659 - learning_rate: 0.0075\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0801 - loss: 0.1692 - mae: 0.2556 - mse: 0.1681 - pearson_correlation: 5.5317e-16 - r2_keras: -100.0885 - rmse: 0.8749 - sae: 2564.8071 - sse: 3135.6401\n","Epoch 14: val_loss improved from 0.20586 to 0.20089, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0733 - loss: 0.1651 - mae: 0.2519 - mse: 0.1583 - pearson_correlation: 3.4012e-16 - r2_keras: -81.2905 - rmse: 0.8559 - sae: 1870.7191 - sse: 2265.1821 - val_huber_loss: 0.1117 - val_loss: 0.2009 - val_mae: 0.3220 - val_mse: 0.2419 - val_pearson_correlation: -1.2346e-16 - val_r2_keras: -33.4406 - val_rmse: 0.9557 - val_sae: 360.4992 - val_sse: 483.1358 - learning_rate: 0.0075\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0795 - loss: 0.1686 - mae: 0.2545 - mse: 0.1666 - pearson_correlation: -1.2486e-16 - r2_keras: -99.9468 - rmse: 0.8743 - sae: 2563.5979 - sse: 3131.2437\n","Epoch 15: val_loss improved from 0.20089 to 0.19795, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0726 - loss: 0.1644 - mae: 0.2505 - mse: 0.1568 - pearson_correlation: -7.3574e-17 - r2_keras: -81.2609 - rmse: 0.8561 - sae: 1870.2018 - sse: 2263.0122 - val_huber_loss: 0.1088 - val_loss: 0.1980 - val_mae: 0.3144 - val_mse: 0.2350 - val_pearson_correlation: -2.9580e-16 - val_r2_keras: -34.0079 - val_rmse: 0.9635 - val_sae: 362.2847 - val_sse: 491.0949 - learning_rate: 0.0075\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0789 - loss: 0.1680 - mae: 0.2533 - mse: 0.1653 - pearson_correlation: 1.0791e-16 - r2_keras: -99.8607 - rmse: 0.8740 - sae: 2562.8545 - sse: 3128.5720\n","Epoch 16: val_loss improved from 0.19795 to 0.19645, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0720 - loss: 0.1638 - mae: 0.2490 - mse: 0.1554 - pearson_correlation: 6.5365e-17 - r2_keras: -81.2714 - rmse: 0.8564 - sae: 1869.9841 - sse: 2262.0278 - val_huber_loss: 0.1073 - val_loss: 0.1965 - val_mae: 0.3101 - val_mse: 0.2316 - val_pearson_correlation: 7.5490e-17 - val_r2_keras: -34.4156 - val_rmse: 0.9691 - val_sae: 364.2525 - val_sse: 496.8138 - learning_rate: 0.0075\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0784 - loss: 0.1675 - mae: 0.2526 - mse: 0.1642 - pearson_correlation: 7.3242e-16 - r2_keras: -99.7386 - rmse: 0.8734 - sae: 2562.1626 - sse: 3124.7842\n","Epoch 17: val_loss improved from 0.19645 to 0.19577, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1633 - mae: 0.2481 - mse: 0.1541 - pearson_correlation: 5.4675e-16 - r2_keras: -81.2303 - rmse: 0.8565 - sae: 1869.7169 - sse: 2259.9758 - val_huber_loss: 0.1067 - val_loss: 0.1958 - val_mae: 0.3107 - val_mse: 0.2302 - val_pearson_correlation: 3.2000e-17 - val_r2_keras: -34.7182 - val_rmse: 0.9732 - val_sae: 366.1295 - val_sse: 501.0594 - learning_rate: 0.0075\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0779 - loss: 0.1670 - mae: 0.2515 - mse: 0.1629 - pearson_correlation: -1.2097e-16 - r2_keras: -99.6316 - rmse: 0.8730 - sae: 2561.7637 - sse: 3121.4658\n","Epoch 18: val_loss improved from 0.19577 to 0.19503, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0708 - loss: 0.1627 - mae: 0.2468 - mse: 0.1529 - pearson_correlation: -1.1329e-16 - r2_keras: -81.2004 - rmse: 0.8565 - sae: 1869.6639 - sse: 2258.2493 - val_huber_loss: 0.1060 - val_loss: 0.1950 - val_mae: 0.3108 - val_mse: 0.2283 - val_pearson_correlation: 4.2322e-17 - val_r2_keras: -34.9476 - val_rmse: 0.9764 - val_sae: 367.6220 - val_sse: 504.2762 - learning_rate: 0.0075\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0775 - loss: 0.1666 - mae: 0.2509 - mse: 0.1619 - pearson_correlation: -3.3894e-16 - r2_keras: -99.5057 - rmse: 0.8724 - sae: 2560.3674 - sse: 3117.5605\n","Epoch 19: val_loss did not improve from 0.19503\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1622 - mae: 0.2460 - mse: 0.1518 - pearson_correlation: -2.1796e-16 - r2_keras: -81.1645 - rmse: 0.8566 - sae: 1868.9603 - sse: 2256.2092 - val_huber_loss: 0.1061 - val_loss: 0.1952 - val_mae: 0.3113 - val_mse: 0.2287 - val_pearson_correlation: -1.4713e-16 - val_r2_keras: -35.1381 - val_rmse: 0.9789 - val_sae: 368.9270 - val_sse: 506.9490 - learning_rate: 0.0075\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0770 - loss: 0.1661 - mae: 0.2498 - mse: 0.1607 - pearson_correlation: -8.4701e-17 - r2_keras: -99.5360 - rmse: 0.8726 - sae: 2561.4866 - sse: 3118.5010\n","Epoch 20: val_loss improved from 0.19503 to 0.19463, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0698 - loss: 0.1617 - mae: 0.2446 - mse: 0.1506 - pearson_correlation: -2.0570e-19 - r2_keras: -81.2361 - rmse: 0.8571 - sae: 1869.9374 - sse: 2257.4390 - val_huber_loss: 0.1056 - val_loss: 0.1946 - val_mae: 0.3107 - val_mse: 0.2274 - val_pearson_correlation: 2.4102e-16 - val_r2_keras: -35.2239 - val_rmse: 0.9801 - val_sae: 369.5553 - val_sse: 508.1527 - learning_rate: 0.0075\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0766 - loss: 0.1657 - mae: 0.2492 - mse: 0.1599 - pearson_correlation: -1.9234e-16 - r2_keras: -99.4845 - rmse: 0.8723 - sae: 2561.0664 - sse: 3116.9028\n","Epoch 21: val_loss improved from 0.19463 to 0.19454, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0693 - loss: 0.1612 - mae: 0.2438 - mse: 0.1496 - pearson_correlation: -6.7211e-17 - r2_keras: -81.2441 - rmse: 0.8574 - sae: 1869.8474 - sse: 2256.8704 - val_huber_loss: 0.1055 - val_loss: 0.1945 - val_mae: 0.3104 - val_mse: 0.2272 - val_pearson_correlation: -1.0449e-17 - val_r2_keras: -35.3095 - val_rmse: 0.9813 - val_sae: 370.2110 - val_sse: 509.3535 - learning_rate: 0.0075\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0762 - loss: 0.1653 - mae: 0.2482 - mse: 0.1588 - pearson_correlation: -8.0068e-17 - r2_keras: -99.4415 - rmse: 0.8721 - sae: 2560.8774 - sse: 3115.5708\n","Epoch 22: val_loss improved from 0.19454 to 0.19409, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0688 - loss: 0.1608 - mae: 0.2426 - mse: 0.1486 - pearson_correlation: -1.0825e-17 - r2_keras: -81.2456 - rmse: 0.8575 - sae: 1869.8558 - sse: 2256.3357 - val_huber_loss: 0.1051 - val_loss: 0.1941 - val_mae: 0.3098 - val_mse: 0.2262 - val_pearson_correlation: 2.0896e-17 - val_r2_keras: -35.3130 - val_rmse: 0.9813 - val_sae: 370.2504 - val_sse: 509.4022 - learning_rate: 0.0075\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0758 - loss: 0.1649 - mae: 0.2475 - mse: 0.1579 - pearson_correlation: 2.7157e-16 - r2_keras: -99.3810 - rmse: 0.8719 - sae: 2560.6133 - sse: 3113.6919\n","Epoch 23: val_loss did not improve from 0.19409\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0684 - loss: 0.1603 - mae: 0.2417 - mse: 0.1476 - pearson_correlation: 2.4569e-16 - r2_keras: -81.2378 - rmse: 0.8576 - sae: 1869.8267 - sse: 2255.4653 - val_huber_loss: 0.1053 - val_loss: 0.1943 - val_mae: 0.3092 - val_mse: 0.2266 - val_pearson_correlation: -2.0823e-16 - val_r2_keras: -35.4089 - val_rmse: 0.9826 - val_sae: 370.7663 - val_sse: 510.7480 - learning_rate: 0.0075\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0755 - loss: 0.1645 - mae: 0.2466 - mse: 0.1571 - pearson_correlation: -2.1958e-17 - r2_keras: -99.3987 - rmse: 0.8720 - sae: 2560.9014 - sse: 3114.2412\n","Epoch 24: val_loss improved from 0.19409 to 0.19398, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0680 - loss: 0.1599 - mae: 0.2405 - mse: 0.1467 - pearson_correlation: -2.7414e-17 - r2_keras: -81.3001 - rmse: 0.8581 - sae: 1870.2314 - sse: 2256.4236 - val_huber_loss: 0.1050 - val_loss: 0.1940 - val_mae: 0.3087 - val_mse: 0.2261 - val_pearson_correlation: 1.6661e-16 - val_r2_keras: -35.4071 - val_rmse: 0.9826 - val_sae: 370.8151 - val_sse: 510.7229 - learning_rate: 0.0075\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0751 - loss: 0.1641 - mae: 0.2454 - mse: 0.1562 - pearson_correlation: -9.0852e-17 - r2_keras: -99.3577 - rmse: 0.8718 - sae: 2560.6487 - sse: 3112.9712\n","Epoch 25: val_loss improved from 0.19398 to 0.19376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0676 - loss: 0.1595 - mae: 0.2393 - mse: 0.1458 - pearson_correlation: -5.4193e-17 - r2_keras: -81.2961 - rmse: 0.8582 - sae: 1870.1312 - sse: 2255.8503 - val_huber_loss: 0.1048 - val_loss: 0.1938 - val_mae: 0.3085 - val_mse: 0.2258 - val_pearson_correlation: 1.0440e-16 - val_r2_keras: -35.3421 - val_rmse: 0.9817 - val_sae: 370.3408 - val_sse: 509.8112 - learning_rate: 0.0075\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0748 - loss: 0.1638 - mae: 0.2454 - mse: 0.1555 - pearson_correlation: 5.0809e-16 - r2_keras: -99.0914 - rmse: 0.8706 - sae: 2557.9043 - sse: 3104.7107\n","Epoch 26: val_loss improved from 0.19376 to 0.19357, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0672 - loss: 0.1592 - mae: 0.2390 - mse: 0.1451 - pearson_correlation: 3.0979e-16 - r2_keras: -81.1166 - rmse: 0.8575 - sae: 1868.3083 - sse: 2250.3210 - val_huber_loss: 0.1046 - val_loss: 0.1936 - val_mae: 0.3078 - val_mse: 0.2255 - val_pearson_correlation: 1.8801e-16 - val_r2_keras: -35.3273 - val_rmse: 0.9815 - val_sae: 370.1638 - val_sse: 509.6028 - learning_rate: 0.0075\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0745 - loss: 0.1634 - mae: 0.2441 - mse: 0.1547 - pearson_correlation: 7.9973e-16 - r2_keras: -99.2622 - rmse: 0.8714 - sae: 2560.0874 - sse: 3110.0073\n","Epoch 27: val_loss improved from 0.19357 to 0.19346, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0668 - loss: 0.1588 - mae: 0.2376 - mse: 0.1442 - pearson_correlation: 5.6003e-16 - r2_keras: -81.2744 - rmse: 0.8583 - sae: 1869.9236 - sse: 2254.3677 - val_huber_loss: 0.1045 - val_loss: 0.1935 - val_mae: 0.3065 - val_mse: 0.2252 - val_pearson_correlation: -8.3500e-17 - val_r2_keras: -35.3340 - val_rmse: 0.9816 - val_sae: 370.2010 - val_sse: 509.6976 - learning_rate: 0.0075\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0741 - loss: 0.1631 - mae: 0.2433 - mse: 0.1539 - pearson_correlation: -5.7461e-16 - r2_keras: -99.2704 - rmse: 0.8714 - sae: 2560.3940 - sse: 3110.2634\n","Epoch 28: val_loss improved from 0.19346 to 0.19295, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0665 - loss: 0.1584 - mae: 0.2367 - mse: 0.1434 - pearson_correlation: -4.1913e-16 - r2_keras: -81.3168 - rmse: 0.8587 - sae: 1870.2793 - sse: 2254.9707 - val_huber_loss: 0.1040 - val_loss: 0.1929 - val_mae: 0.3059 - val_mse: 0.2240 - val_pearson_correlation: 3.1349e-17 - val_r2_keras: -35.3014 - val_rmse: 0.9811 - val_sae: 369.6751 - val_sse: 509.2404 - learning_rate: 0.0075\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0738 - loss: 0.1627 - mae: 0.2424 - mse: 0.1533 - pearson_correlation: -7.7446e-16 - r2_keras: -99.3187 - rmse: 0.8716 - sae: 2560.3237 - sse: 3111.7600\n","Epoch 29: val_loss did not improve from 0.19295\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0661 - loss: 0.1580 - mae: 0.2355 - mse: 0.1427 - pearson_correlation: -4.8232e-16 - r2_keras: -81.3904 - rmse: 0.8592 - sae: 1870.3658 - sse: 2256.4546 - val_huber_loss: 0.1041 - val_loss: 0.1930 - val_mae: 0.3057 - val_mse: 0.2246 - val_pearson_correlation: 1.6778e-16 - val_r2_keras: -35.2145 - val_rmse: 0.9800 - val_sae: 369.2679 - val_sse: 508.0210 - learning_rate: 0.0075\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0736 - loss: 0.1625 - mae: 0.2418 - mse: 0.1526 - pearson_correlation: 2.9049e-16 - r2_keras: -99.1820 - rmse: 0.8710 - sae: 2559.4062 - sse: 3107.5217\n","Epoch 30: val_loss did not improve from 0.19295\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0658 - loss: 0.1578 - mae: 0.2349 - mse: 0.1421 - pearson_correlation: 1.1834e-16 - r2_keras: -81.2889 - rmse: 0.8587 - sae: 1869.7159 - sse: 2253.5066 - val_huber_loss: 0.1041 - val_loss: 0.1930 - val_mae: 0.3051 - val_mse: 0.2244 - val_pearson_correlation: 1.6735e-16 - val_r2_keras: -35.2761 - val_rmse: 0.9808 - val_sae: 369.6777 - val_sse: 508.8848 - learning_rate: 0.0075\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0732 - loss: 0.1621 - mae: 0.2409 - mse: 0.1518 - pearson_correlation: 6.8442e-16 - r2_keras: -99.2911 - rmse: 0.8715 - sae: 2560.6968 - sse: 3110.9036\n","Epoch 31: val_loss improved from 0.19295 to 0.19273, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0655 - loss: 0.1574 - mae: 0.2339 - mse: 0.1413 - pearson_correlation: 5.0714e-16 - r2_keras: -81.4008 - rmse: 0.8594 - sae: 1870.7191 - sse: 2256.2212 - val_huber_loss: 0.1039 - val_loss: 0.1927 - val_mae: 0.3039 - val_mse: 0.2241 - val_pearson_correlation: 5.2383e-17 - val_r2_keras: -35.2321 - val_rmse: 0.9802 - val_sae: 369.1258 - val_sse: 508.2680 - learning_rate: 0.0075\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - huber_loss: 0.0730 - loss: 0.1619 - mae: 0.2401 - mse: 0.1514 - pearson_correlation: -4.7171e-17 - r2_keras: -99.4172 - rmse: 0.8720 - sae: 2561.7305 - sse: 3114.8145\n","Epoch 32: val_loss improved from 0.19273 to 0.19253, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0652 - loss: 0.1571 - mae: 0.2330 - mse: 0.1408 - pearson_correlation: -6.2938e-18 - r2_keras: -81.5018 - rmse: 0.8599 - sae: 1871.4531 - sse: 2259.0281 - val_huber_loss: 0.1037 - val_loss: 0.1925 - val_mae: 0.3047 - val_mse: 0.2237 - val_pearson_correlation: -1.4681e-16 - val_r2_keras: -35.2125 - val_rmse: 0.9799 - val_sae: 369.2099 - val_sse: 507.9936 - learning_rate: 0.0075\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0727 - loss: 0.1616 - mae: 0.2399 - mse: 0.1506 - pearson_correlation: 3.0768e-16 - r2_keras: -99.1999 - rmse: 0.8711 - sae: 2559.7778 - sse: 3108.0742\n","Epoch 33: val_loss did not improve from 0.19253\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0650 - loss: 0.1569 - mae: 0.2327 - mse: 0.1401 - pearson_correlation: 1.8914e-16 - r2_keras: -81.3451 - rmse: 0.8592 - sae: 1870.1255 - sse: 2254.3955 - val_huber_loss: 0.1038 - val_loss: 0.1926 - val_mae: 0.3032 - val_mse: 0.2240 - val_pearson_correlation: 9.4196e-17 - val_r2_keras: -35.2561 - val_rmse: 0.9805 - val_sae: 369.4294 - val_sse: 508.6052 - learning_rate: 0.0075\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0724 - loss: 0.1613 - mae: 0.2386 - mse: 0.1499 - pearson_correlation: 3.5341e-16 - r2_keras: -99.4646 - rmse: 0.8722 - sae: 2562.6626 - sse: 3116.2871\n","Epoch 34: val_loss improved from 0.19253 to 0.19252, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0646 - loss: 0.1565 - mae: 0.2314 - mse: 0.1394 - pearson_correlation: 2.6456e-16 - r2_keras: -81.5634 - rmse: 0.8603 - sae: 1872.1842 - sse: 2260.3604 - val_huber_loss: 0.1037 - val_loss: 0.1925 - val_mae: 0.3031 - val_mse: 0.2239 - val_pearson_correlation: 1.1525e-16 - val_r2_keras: -35.2277 - val_rmse: 0.9801 - val_sae: 369.0107 - val_sse: 508.2057 - learning_rate: 0.0075\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0722 - loss: 0.1610 - mae: 0.2378 - mse: 0.1494 - pearson_correlation: -6.8944e-16 - r2_keras: -99.5472 - rmse: 0.8726 - sae: 2562.9990 - sse: 3118.8491\n","Epoch 35: val_loss did not improve from 0.19252\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0643 - loss: 0.1562 - mae: 0.2303 - mse: 0.1388 - pearson_correlation: -4.9863e-16 - r2_keras: -81.6444 - rmse: 0.8608 - sae: 1872.4783 - sse: 2262.3726 - val_huber_loss: 0.1038 - val_loss: 0.1926 - val_mae: 0.3039 - val_mse: 0.2242 - val_pearson_correlation: 1.6788e-16 - val_r2_keras: -35.1980 - val_rmse: 0.9797 - val_sae: 369.0208 - val_sse: 507.7898 - learning_rate: 0.0075\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0720 - loss: 0.1608 - mae: 0.2377 - mse: 0.1488 - pearson_correlation: -2.0471e-17 - r2_keras: -99.4176 - rmse: 0.8720 - sae: 2562.1169 - sse: 3114.8271\n","Epoch 36: val_loss did not improve from 0.19252\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0641 - loss: 0.1560 - mae: 0.2302 - mse: 0.1382 - pearson_correlation: -6.0866e-17 - r2_keras: -81.5504 - rmse: 0.8603 - sae: 1871.8737 - sse: 2259.6025 - val_huber_loss: 0.1040 - val_loss: 0.1928 - val_mae: 0.3034 - val_mse: 0.2246 - val_pearson_correlation: -3.1433e-16 - val_r2_keras: -35.2285 - val_rmse: 0.9802 - val_sae: 368.9720 - val_sse: 508.2172 - learning_rate: 0.0075\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0716 - loss: 0.1604 - mae: 0.2367 - mse: 0.1480 - pearson_correlation: 8.7038e-17 - r2_keras: -99.5737 - rmse: 0.8727 - sae: 2563.5518 - sse: 3119.6709\n","Epoch 37: val_loss improved from 0.19252 to 0.19229, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0638 - loss: 0.1556 - mae: 0.2291 - mse: 0.1375 - pearson_correlation: 3.6900e-17 - r2_keras: -81.6988 - rmse: 0.8612 - sae: 1873.0066 - sse: 2263.3521 - val_huber_loss: 0.1035 - val_loss: 0.1923 - val_mae: 0.3027 - val_mse: 0.2235 - val_pearson_correlation: -2.2048e-16 - val_r2_keras: -35.1684 - val_rmse: 0.9793 - val_sae: 368.4998 - val_sse: 507.3741 - learning_rate: 0.0075\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0714 - loss: 0.1601 - mae: 0.2362 - mse: 0.1474 - pearson_correlation: -5.8558e-16 - r2_keras: -99.7223 - rmse: 0.8734 - sae: 2565.0000 - sse: 3124.2793\n","Epoch 38: val_loss improved from 0.19229 to 0.19222, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0635 - loss: 0.1553 - mae: 0.2284 - mse: 0.1369 - pearson_correlation: -3.6065e-16 - r2_keras: -81.8102 - rmse: 0.8617 - sae: 1874.0137 - sse: 2266.5691 - val_huber_loss: 0.1035 - val_loss: 0.1922 - val_mae: 0.3021 - val_mse: 0.2235 - val_pearson_correlation: -1.0494e-17 - val_r2_keras: -35.1894 - val_rmse: 0.9796 - val_sae: 368.7013 - val_sse: 507.6682 - learning_rate: 0.0075\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0711 - loss: 0.1598 - mae: 0.2354 - mse: 0.1467 - pearson_correlation: -1.3580e-16 - r2_keras: -99.7827 - rmse: 0.8736 - sae: 2565.9375 - sse: 3126.1543\n","Epoch 39: val_loss did not improve from 0.19222\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0632 - loss: 0.1550 - mae: 0.2276 - mse: 0.1362 - pearson_correlation: -3.2048e-17 - r2_keras: -81.8578 - rmse: 0.8620 - sae: 1874.6973 - sse: 2267.9050 - val_huber_loss: 0.1036 - val_loss: 0.1923 - val_mae: 0.3020 - val_mse: 0.2236 - val_pearson_correlation: 2.8300e-16 - val_r2_keras: -35.2235 - val_rmse: 0.9801 - val_sae: 368.9016 - val_sse: 508.1469 - learning_rate: 0.0075\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0707 - loss: 0.1595 - mae: 0.2348 - mse: 0.1460 - pearson_correlation: -5.5323e-16 - r2_keras: -99.7032 - rmse: 0.8733 - sae: 2565.0864 - sse: 3123.6870\n","Epoch 40: val_loss improved from 0.19222 to 0.19185, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0628 - loss: 0.1547 - mae: 0.2270 - mse: 0.1355 - pearson_correlation: -3.2668e-16 - r2_keras: -81.8175 - rmse: 0.8618 - sae: 1874.1781 - sse: 2266.4084 - val_huber_loss: 0.1031 - val_loss: 0.1918 - val_mae: 0.3023 - val_mse: 0.2226 - val_pearson_correlation: 2.9453e-16 - val_r2_keras: -35.1250 - val_rmse: 0.9788 - val_sae: 367.9679 - val_sse: 506.7654 - learning_rate: 0.0075\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0705 - loss: 0.1592 - mae: 0.2344 - mse: 0.1454 - pearson_correlation: -4.6350e-17 - r2_keras: -99.7801 - rmse: 0.8736 - sae: 2565.3213 - sse: 3126.0713\n","Epoch 41: val_loss did not improve from 0.19185\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0626 - loss: 0.1544 - mae: 0.2264 - mse: 0.1349 - pearson_correlation: -5.1955e-17 - r2_keras: -81.8779 - rmse: 0.8622 - sae: 1874.3618 - sse: 2268.1062 - val_huber_loss: 0.1033 - val_loss: 0.1920 - val_mae: 0.3010 - val_mse: 0.2229 - val_pearson_correlation: 3.1455e-17 - val_r2_keras: -35.2119 - val_rmse: 0.9799 - val_sae: 368.6643 - val_sse: 507.9849 - learning_rate: 0.0075\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0701 - loss: 0.1588 - mae: 0.2332 - mse: 0.1446 - pearson_correlation: 1.4837e-16 - r2_keras: -99.9889 - rmse: 0.8745 - sae: 2567.9292 - sse: 3132.5508\n","Epoch 42: val_loss improved from 0.19185 to 0.19169, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0622 - loss: 0.1540 - mae: 0.2252 - mse: 0.1341 - pearson_correlation: 1.0799e-16 - r2_keras: -82.0419 - rmse: 0.8630 - sae: 1876.2173 - sse: 2272.7151 - val_huber_loss: 0.1030 - val_loss: 0.1917 - val_mae: 0.3004 - val_mse: 0.2224 - val_pearson_correlation: 1.0505e-17 - val_r2_keras: -35.1671 - val_rmse: 0.9793 - val_sae: 368.5499 - val_sse: 507.3555 - learning_rate: 0.0075\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0699 - loss: 0.1586 - mae: 0.2332 - mse: 0.1440 - pearson_correlation: 4.6663e-16 - r2_keras: -99.8929 - rmse: 0.8741 - sae: 2567.0747 - sse: 3129.5723\n","Epoch 43: val_loss improved from 0.19169 to 0.19147, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0620 - loss: 0.1538 - mae: 0.2251 - mse: 0.1335 - pearson_correlation: 3.4454e-16 - r2_keras: -81.9684 - rmse: 0.8626 - sae: 1875.6351 - sse: 2270.6184 - val_huber_loss: 0.1028 - val_loss: 0.1915 - val_mae: 0.3001 - val_mse: 0.2220 - val_pearson_correlation: -1.9982e-16 - val_r2_keras: -35.1319 - val_rmse: 0.9789 - val_sae: 368.1838 - val_sse: 506.8619 - learning_rate: 0.0075\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0696 - loss: 0.1583 - mae: 0.2321 - mse: 0.1435 - pearson_correlation: -8.8303e-16 - r2_keras: -100.1243 - rmse: 0.8751 - sae: 2569.3960 - sse: 3136.7485\n","Epoch 44: val_loss improved from 0.19147 to 0.19121, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0617 - loss: 0.1535 - mae: 0.2240 - mse: 0.1330 - pearson_correlation: -5.7963e-16 - r2_keras: -82.1511 - rmse: 0.8635 - sae: 1877.2770 - sse: 2275.7371 - val_huber_loss: 0.1026 - val_loss: 0.1912 - val_mae: 0.2993 - val_mse: 0.2212 - val_pearson_correlation: -7.3584e-17 - val_r2_keras: -35.1365 - val_rmse: 0.9789 - val_sae: 368.1479 - val_sse: 506.9268 - learning_rate: 0.0075\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0694 - loss: 0.1580 - mae: 0.2318 - mse: 0.1428 - pearson_correlation: -6.2039e-16 - r2_keras: -100.1525 - rmse: 0.8752 - sae: 2569.4360 - sse: 3137.6252\n","Epoch 45: val_loss did not improve from 0.19121\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0614 - loss: 0.1532 - mae: 0.2236 - mse: 0.1323 - pearson_correlation: -3.9884e-16 - r2_keras: -82.1957 - rmse: 0.8638 - sae: 1877.4117 - sse: 2276.6238 - val_huber_loss: 0.1028 - val_loss: 0.1914 - val_mae: 0.3003 - val_mse: 0.2219 - val_pearson_correlation: 2.2083e-16 - val_r2_keras: -35.1408 - val_rmse: 0.9790 - val_sae: 367.9877 - val_sse: 506.9872 - learning_rate: 0.0075\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0692 - loss: 0.1578 - mae: 0.2313 - mse: 0.1425 - pearson_correlation: -2.5578e-16 - r2_keras: -100.1746 - rmse: 0.8753 - sae: 2569.4678 - sse: 3138.3105\n","Epoch 46: val_loss did not improve from 0.19121\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0612 - loss: 0.1530 - mae: 0.2229 - mse: 0.1319 - pearson_correlation: -1.7289e-16 - r2_keras: -82.2215 - rmse: 0.8640 - sae: 1877.4685 - sse: 2277.2095 - val_huber_loss: 0.1029 - val_loss: 0.1915 - val_mae: 0.3000 - val_mse: 0.2223 - val_pearson_correlation: -6.3133e-17 - val_r2_keras: -35.1262 - val_rmse: 0.9788 - val_sae: 368.1680 - val_sse: 506.7818 - learning_rate: 0.0075\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0689 - loss: 0.1576 - mae: 0.2309 - mse: 0.1418 - pearson_correlation: 8.7319e-17 - r2_keras: -100.0879 - rmse: 0.8749 - sae: 2568.9851 - sse: 3135.6189\n","Epoch 47: val_loss improved from 0.19121 to 0.19111, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0610 - loss: 0.1527 - mae: 0.2226 - mse: 0.1313 - pearson_correlation: 1.1339e-16 - r2_keras: -82.1596 - rmse: 0.8637 - sae: 1877.1254 - sse: 2275.3682 - val_huber_loss: 0.1025 - val_loss: 0.1911 - val_mae: 0.3003 - val_mse: 0.2214 - val_pearson_correlation: -3.6901e-16 - val_r2_keras: -35.0682 - val_rmse: 0.9780 - val_sae: 367.4356 - val_sse: 505.9693 - learning_rate: 0.0075\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0687 - loss: 0.1573 - mae: 0.2304 - mse: 0.1414 - pearson_correlation: -1.2642e-16 - r2_keras: -100.2592 - rmse: 0.8757 - sae: 2570.3096 - sse: 3140.9346\n","Epoch 48: val_loss did not improve from 0.19111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0607 - loss: 0.1525 - mae: 0.2218 - mse: 0.1309 - pearson_correlation: -5.3423e-17 - r2_keras: -82.2973 - rmse: 0.8644 - sae: 1878.0717 - sse: 2279.1877 - val_huber_loss: 0.1029 - val_loss: 0.1915 - val_mae: 0.3003 - val_mse: 0.2225 - val_pearson_correlation: -9.4734e-17 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.8222 - val_sse: 506.6085 - learning_rate: 0.0075\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0685 - loss: 0.1571 - mae: 0.2295 - mse: 0.1408 - pearson_correlation: 3.7798e-17 - r2_keras: -100.3402 - rmse: 0.8760 - sae: 2571.3752 - sse: 3143.4451\n","Epoch 49: val_loss did not improve from 0.19111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0605 - loss: 0.1522 - mae: 0.2209 - mse: 0.1303 - pearson_correlation: 4.1779e-17 - r2_keras: -82.3794 - rmse: 0.8649 - sae: 1878.8932 - sse: 2281.1912 - val_huber_loss: 0.1029 - val_loss: 0.1915 - val_mae: 0.3001 - val_mse: 0.2225 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1084 - val_rmse: 0.9785 - val_sae: 367.6230 - val_sse: 506.5320 - learning_rate: 0.0075\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0684 - loss: 0.1570 - mae: 0.2291 - mse: 0.1406 - pearson_correlation: -3.9432e-16 - r2_keras: -100.4657 - rmse: 0.8766 - sae: 2572.7568 - sse: 3147.3396\n","Epoch 50: val_loss did not improve from 0.19111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0602 - loss: 0.1520 - mae: 0.2201 - mse: 0.1298 - pearson_correlation: -3.3630e-16 - r2_keras: -82.4629 - rmse: 0.8653 - sae: 1879.8270 - sse: 2283.7854 - val_huber_loss: 0.1028 - val_loss: 0.1914 - val_mae: 0.3000 - val_mse: 0.2222 - val_pearson_correlation: -2.2118e-16 - val_r2_keras: -35.1074 - val_rmse: 0.9785 - val_sae: 367.6771 - val_sse: 506.5182 - learning_rate: 0.0015\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0683 - loss: 0.1569 - mae: 0.2289 - mse: 0.1403 - pearson_correlation: 4.1147e-16 - r2_keras: -100.4315 - rmse: 0.8764 - sae: 2572.4363 - sse: 3146.2773\n","Epoch 51: val_loss did not improve from 0.19111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0601 - loss: 0.1519 - mae: 0.2200 - mse: 0.1296 - pearson_correlation: 2.9611e-16 - r2_keras: -82.4346 - rmse: 0.8651 - sae: 1879.5947 - sse: 2283.0125 - val_huber_loss: 0.1027 - val_loss: 0.1913 - val_mae: 0.2999 - val_mse: 0.2220 - val_pearson_correlation: -1.1586e-16 - val_r2_keras: -35.1074 - val_rmse: 0.9785 - val_sae: 367.7083 - val_sse: 506.5184 - learning_rate: 0.0015\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0682 - loss: 0.1568 - mae: 0.2288 - mse: 0.1401 - pearson_correlation: 3.4917e-16 - r2_keras: -100.4239 - rmse: 0.8764 - sae: 2572.3623 - sse: 3146.0420\n","Epoch 52: val_loss did not improve from 0.19111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0600 - loss: 0.1518 - mae: 0.2199 - mse: 0.1294 - pearson_correlation: 2.7733e-16 - r2_keras: -82.4274 - rmse: 0.8651 - sae: 1879.5385 - sse: 2282.8311 - val_huber_loss: 0.1026 - val_loss: 0.1911 - val_mae: 0.2997 - val_mse: 0.2217 - val_pearson_correlation: -1.2639e-16 - val_r2_keras: -35.1066 - val_rmse: 0.9785 - val_sae: 367.7024 - val_sse: 506.5073 - learning_rate: 0.0015\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0681 - loss: 0.1567 - mae: 0.2285 - mse: 0.1400 - pearson_correlation: -1.3371e-16 - r2_keras: -100.4526 - rmse: 0.8765 - sae: 2572.6133 - sse: 3146.9314\n","Epoch 53: val_loss improved from 0.19111 to 0.19111, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0600 - loss: 0.1517 - mae: 0.2196 - mse: 0.1293 - pearson_correlation: -3.8453e-17 - r2_keras: -82.4542 - rmse: 0.8652 - sae: 1879.7347 - sse: 2283.5137 - val_huber_loss: 0.1025 - val_loss: 0.1911 - val_mae: 0.2998 - val_mse: 0.2215 - val_pearson_correlation: -1.7903e-16 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.7429 - val_sse: 506.5801 - learning_rate: 0.0015\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0681 - loss: 0.1566 - mae: 0.2284 - mse: 0.1398 - pearson_correlation: -1.9518e-16 - r2_keras: -100.4403 - rmse: 0.8765 - sae: 2572.4741 - sse: 3146.5498\n","Epoch 54: val_loss improved from 0.19111 to 0.19107, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0599 - loss: 0.1517 - mae: 0.2196 - mse: 0.1292 - pearson_correlation: -1.3865e-16 - r2_keras: -82.4443 - rmse: 0.8652 - sae: 1879.6368 - sse: 2283.2393 - val_huber_loss: 0.1025 - val_loss: 0.1911 - val_mae: 0.2995 - val_mse: 0.2215 - val_pearson_correlation: -7.3722e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.7231 - val_sse: 506.5591 - learning_rate: 0.0015\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0680 - loss: 0.1566 - mae: 0.2281 - mse: 0.1397 - pearson_correlation: 2.1960e-16 - r2_keras: -100.4956 - rmse: 0.8767 - sae: 2573.0723 - sse: 3148.2651\n","Epoch 55: val_loss improved from 0.19107 to 0.19107, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0599 - loss: 0.1516 - mae: 0.2193 - mse: 0.1290 - pearson_correlation: 1.8948e-16 - r2_keras: -82.4899 - rmse: 0.8654 - sae: 1880.0692 - sse: 2284.4851 - val_huber_loss: 0.1025 - val_loss: 0.1911 - val_mae: 0.2996 - val_mse: 0.2215 - val_pearson_correlation: -3.7911e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.7345 - val_sse: 506.5963 - learning_rate: 0.0015\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0680 - loss: 0.1565 - mae: 0.2279 - mse: 0.1396 - pearson_correlation: 3.5510e-16 - r2_keras: -100.5325 - rmse: 0.8769 - sae: 2573.4507 - sse: 3149.4106\n","Epoch 56: val_loss improved from 0.19107 to 0.19090, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0598 - loss: 0.1516 - mae: 0.2190 - mse: 0.1289 - pearson_correlation: 2.4004e-16 - r2_keras: -82.5218 - rmse: 0.8656 - sae: 1880.3452 - sse: 2285.3345 - val_huber_loss: 0.1023 - val_loss: 0.1909 - val_mae: 0.2992 - val_mse: 0.2211 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1019 - val_rmse: 0.9784 - val_sae: 367.6328 - val_sse: 506.4407 - learning_rate: 0.0015\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0679 - loss: 0.1565 - mae: 0.2277 - mse: 0.1395 - pearson_correlation: -9.9618e-17 - r2_keras: -100.5647 - rmse: 0.8770 - sae: 2573.7266 - sse: 3150.4097\n","Epoch 57: val_loss did not improve from 0.19090\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0598 - loss: 0.1515 - mae: 0.2189 - mse: 0.1288 - pearson_correlation: -6.7831e-17 - r2_keras: -82.5453 - rmse: 0.8657 - sae: 1880.5348 - sse: 2286.0237 - val_huber_loss: 0.1024 - val_loss: 0.1909 - val_mae: 0.2995 - val_mse: 0.2211 - val_pearson_correlation: -8.4280e-17 - val_r2_keras: -35.1044 - val_rmse: 0.9785 - val_sae: 367.6819 - val_sse: 506.4761 - learning_rate: 0.0015\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0679 - loss: 0.1564 - mae: 0.2277 - mse: 0.1394 - pearson_correlation: -3.7471e-16 - r2_keras: -100.5263 - rmse: 0.8768 - sae: 2573.3562 - sse: 3149.2173\n","Epoch 58: val_loss improved from 0.19090 to 0.19084, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0597 - loss: 0.1515 - mae: 0.2188 - mse: 0.1287 - pearson_correlation: -2.6116e-16 - r2_keras: -82.5173 - rmse: 0.8656 - sae: 1880.2792 - sse: 2285.2009 - val_huber_loss: 0.1023 - val_loss: 0.1908 - val_mae: 0.2993 - val_mse: 0.2209 - val_pearson_correlation: -1.0537e-16 - val_r2_keras: -35.0986 - val_rmse: 0.9784 - val_sae: 367.6049 - val_sse: 506.3953 - learning_rate: 0.0015\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0678 - loss: 0.1564 - mae: 0.2275 - mse: 0.1393 - pearson_correlation: -7.2082e-16 - r2_keras: -100.5824 - rmse: 0.8771 - sae: 2573.9407 - sse: 3150.9592\n","Epoch 59: val_loss did not improve from 0.19084\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0597 - loss: 0.1514 - mae: 0.2186 - mse: 0.1286 - pearson_correlation: -4.8811e-16 - r2_keras: -82.5593 - rmse: 0.8658 - sae: 1880.6847 - sse: 2286.4165 - val_huber_loss: 0.1024 - val_loss: 0.1909 - val_mae: 0.2995 - val_mse: 0.2211 - val_pearson_correlation: -3.1593e-17 - val_r2_keras: -35.1154 - val_rmse: 0.9786 - val_sae: 367.7368 - val_sse: 506.6313 - learning_rate: 0.0015\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0678 - loss: 0.1563 - mae: 0.2273 - mse: 0.1392 - pearson_correlation: -3.9824e-16 - r2_keras: -100.6087 - rmse: 0.8772 - sae: 2574.2495 - sse: 3151.7749\n","Epoch 60: val_loss did not improve from 0.19084\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0596 - loss: 0.1514 - mae: 0.2185 - mse: 0.1285 - pearson_correlation: -2.7447e-16 - r2_keras: -82.5843 - rmse: 0.8659 - sae: 1880.9259 - sse: 2287.0479 - val_huber_loss: 0.1023 - val_loss: 0.1908 - val_mae: 0.2994 - val_mse: 0.2210 - val_pearson_correlation: 1.6857e-16 - val_r2_keras: -35.1047 - val_rmse: 0.9785 - val_sae: 367.6094 - val_sse: 506.4810 - learning_rate: 0.0015\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0677 - loss: 0.1563 - mae: 0.2272 - mse: 0.1391 - pearson_correlation: 3.4734e-17 - r2_keras: -100.6287 - rmse: 0.8773 - sae: 2574.4238 - sse: 3152.3945\n","Epoch 61: val_loss improved from 0.19084 to 0.19082, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0596 - loss: 0.1513 - mae: 0.2183 - mse: 0.1285 - pearson_correlation: -6.8051e-17 - r2_keras: -82.6016 - rmse: 0.8660 - sae: 1881.0541 - sse: 2287.5081 - val_huber_loss: 0.1023 - val_loss: 0.1908 - val_mae: 0.2996 - val_mse: 0.2209 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1153 - val_rmse: 0.9786 - val_sae: 367.7533 - val_sse: 506.6292 - learning_rate: 0.0015\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0677 - loss: 0.1562 - mae: 0.2271 - mse: 0.1390 - pearson_correlation: -3.8478e-16 - r2_keras: -100.6144 - rmse: 0.8772 - sae: 2574.3311 - sse: 3151.9514\n","Epoch 62: val_loss improved from 0.19082 to 0.19078, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0595 - loss: 0.1513 - mae: 0.2182 - mse: 0.1283 - pearson_correlation: -2.0876e-16 - r2_keras: -82.5844 - rmse: 0.8659 - sae: 1880.9658 - sse: 2287.1223 - val_huber_loss: 0.1022 - val_loss: 0.1908 - val_mae: 0.2995 - val_mse: 0.2208 - val_pearson_correlation: 2.9495e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.7064 - val_sse: 506.5623 - learning_rate: 3.0013e-04\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0677 - loss: 0.1562 - mae: 0.2271 - mse: 0.1390 - pearson_correlation: 1.1531e-16 - r2_keras: -100.6216 - rmse: 0.8773 - sae: 2574.4106 - sse: 3152.1763\n","Epoch 63: val_loss improved from 0.19078 to 0.19076, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0595 - loss: 0.1513 - mae: 0.2182 - mse: 0.1283 - pearson_correlation: 8.5381e-17 - r2_keras: -82.5907 - rmse: 0.8659 - sae: 1881.0245 - sse: 2287.2886 - val_huber_loss: 0.1022 - val_loss: 0.1908 - val_mae: 0.2995 - val_mse: 0.2208 - val_pearson_correlation: 3.2658e-16 - val_r2_keras: -35.1079 - val_rmse: 0.9785 - val_sae: 367.6740 - val_sse: 506.5257 - learning_rate: 3.0013e-04\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0677 - loss: 0.1562 - mae: 0.2271 - mse: 0.1389 - pearson_correlation: 2.1163e-16 - r2_keras: -100.6257 - rmse: 0.8773 - sae: 2574.4419 - sse: 3152.3018\n","Epoch 64: val_loss improved from 0.19076 to 0.19076, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2182 - mse: 0.1283 - pearson_correlation: 8.6246e-17 - r2_keras: -82.5949 - rmse: 0.8660 - sae: 1881.0510 - sse: 2287.3899 - val_huber_loss: 0.1022 - val_loss: 0.1908 - val_mae: 0.2995 - val_mse: 0.2208 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1080 - val_rmse: 0.9785 - val_sae: 367.6675 - val_sse: 506.5271 - learning_rate: 3.0013e-04\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0677 - loss: 0.1562 - mae: 0.2270 - mse: 0.1389 - pearson_correlation: 3.5900e-16 - r2_keras: -100.6331 - rmse: 0.8773 - sae: 2574.5225 - sse: 3152.5315\n","Epoch 65: val_loss improved from 0.19076 to 0.19074, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2181 - mse: 0.1283 - pearson_correlation: 1.7788e-16 - r2_keras: -82.6015 - rmse: 0.8660 - sae: 1881.1112 - sse: 2287.5625 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.6338e-16 - val_r2_keras: -35.1079 - val_rmse: 0.9785 - val_sae: 367.6599 - val_sse: 506.5261 - learning_rate: 3.0013e-04\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0677 - loss: 0.1562 - mae: 0.2270 - mse: 0.1389 - pearson_correlation: -3.3678e-16 - r2_keras: -100.6406 - rmse: 0.8773 - sae: 2574.5977 - sse: 3152.7659\n","Epoch 66: val_loss improved from 0.19074 to 0.19074, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2181 - mse: 0.1282 - pearson_correlation: -2.4201e-16 - r2_keras: -82.6076 - rmse: 0.8660 - sae: 1881.1659 - sse: 2287.7322 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.7909e-16 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6682 - val_sse: 506.5473 - learning_rate: 3.0013e-04\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1389 - pearson_correlation: -1.3452e-16 - r2_keras: -100.6504 - rmse: 0.8774 - sae: 2574.7053 - sse: 3153.0688\n","Epoch 67: val_loss did not improve from 0.19074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -1.1520e-16 - r2_keras: -82.6156 - rmse: 0.8661 - sae: 1881.2435 - sse: 2287.9514 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -8.4279e-17 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6636 - val_sse: 506.5474 - learning_rate: 3.0013e-04\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1389 - pearson_correlation: 5.7276e-16 - r2_keras: -100.6572 - rmse: 0.8774 - sae: 2574.7754 - sse: 3153.2791\n","Epoch 68: val_loss improved from 0.19074 to 0.19073, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 3.6293e-16 - r2_keras: -82.6209 - rmse: 0.8661 - sae: 1881.2933 - sse: 2288.1001 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6558 - val_sse: 506.5381 - learning_rate: 6.0026e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1389 - pearson_correlation: 3.9098e-17 - r2_keras: -100.6579 - rmse: 0.8774 - sae: 2574.7783 - sse: 3153.2996\n","Epoch 69: val_loss improved from 0.19073 to 0.19073, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 2.4647e-17 - r2_keras: -82.6215 - rmse: 0.8661 - sae: 1881.2963 - sse: 2288.1165 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -4.1088e-16 - val_r2_keras: -35.1086 - val_rmse: 0.9785 - val_sae: 367.6516 - val_sse: 506.5347 - learning_rate: 6.0026e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: -1.4968e-16 - r2_keras: -100.6592 - rmse: 0.8774 - sae: 2574.7908 - sse: 3153.3420\n","Epoch 70: val_loss improved from 0.19073 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -9.1751e-17 - r2_keras: -82.6227 - rmse: 0.8661 - sae: 1881.3055 - sse: 2288.1475 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -3.1607e-17 - val_r2_keras: -35.1084 - val_rmse: 0.9785 - val_sae: 367.6490 - val_sse: 506.5328 - learning_rate: 6.0026e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 1.8819e-16 - r2_keras: -100.6606 - rmse: 0.8774 - sae: 2574.8027 - sse: 3153.3845\n","Epoch 71: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 1.6940e-16 - r2_keras: -82.6238 - rmse: 0.8661 - sae: 1881.3143 - sse: 2288.1785 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.4750e-16 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6508 - val_sse: 506.5370 - learning_rate: 6.0026e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 1.4996e-16 - r2_keras: -100.6625 - rmse: 0.8774 - sae: 2574.8247 - sse: 3153.4438\n","Epoch 72: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 5.8393e-17 - r2_keras: -82.6254 - rmse: 0.8661 - sae: 1881.3303 - sse: 2288.2219 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.5803e-16 - val_r2_keras: -35.1085 - val_rmse: 0.9785 - val_sae: 367.6478 - val_sse: 506.5343 - learning_rate: 6.0026e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: -1.6659e-16 - r2_keras: -100.6639 - rmse: 0.8774 - sae: 2574.8364 - sse: 3153.4863\n","Epoch 73: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -6.6170e-17 - r2_keras: -82.6264 - rmse: 0.8661 - sae: 1881.3383 - sse: 2288.2505 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0536e-16 - val_r2_keras: -35.1084 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5331 - learning_rate: 1.2005e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: -3.9240e-16 - r2_keras: -100.6640 - rmse: 0.8774 - sae: 2574.8369 - sse: 3153.4888\n","Epoch 74: val_loss did not improve from 0.19072\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -1.9923e-16 - r2_keras: -82.6265 - rmse: 0.8661 - sae: 1881.3387 - sse: 2288.2527 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1084 - val_rmse: 0.9785 - val_sae: 367.6463 - val_sse: 506.5328 - learning_rate: 1.2005e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: -7.3404e-16 - r2_keras: -100.6642 - rmse: 0.8774 - sae: 2574.8394 - sse: 3153.4966\n","Epoch 75: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -5.3519e-16 - r2_keras: -82.6267 - rmse: 0.8661 - sae: 1881.3406 - sse: 2288.2585 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.8964e-16 - val_r2_keras: -35.1084 - val_rmse: 0.9785 - val_sae: 367.6461 - val_sse: 506.5329 - learning_rate: 1.2005e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 5.8466e-16 - r2_keras: -100.6644 - rmse: 0.8774 - sae: 2574.8418 - sse: 3153.5034\n","Epoch 76: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 3.5812e-16 - r2_keras: -82.6269 - rmse: 0.8661 - sae: 1881.3425 - sse: 2288.2639 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0536e-17 - val_r2_keras: -35.1085 - val_rmse: 0.9785 - val_sae: 367.6461 - val_sse: 506.5333 - learning_rate: 1.2005e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 2.7366e-16 - r2_keras: -100.6646 - rmse: 0.8774 - sae: 2574.8430 - sse: 3153.5083\n","Epoch 77: val_loss did not improve from 0.19072\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 3.2845e-16 - r2_keras: -82.6270 - rmse: 0.8661 - sae: 1881.3435 - sse: 2288.2676 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.2643e-16 - val_r2_keras: -35.1084 - val_rmse: 0.9785 - val_sae: 367.6459 - val_sse: 506.5332 - learning_rate: 1.2005e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 8.1806e-16 - r2_keras: -100.6648 - rmse: 0.8774 - sae: 2574.8457 - sse: 3153.5151\n","Epoch 78: val_loss did not improve from 0.19072\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 5.9451e-16 - r2_keras: -82.6273 - rmse: 0.8661 - sae: 1881.3456 - sse: 2288.2729 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -3.1607e-17 - val_r2_keras: -35.1085 - val_rmse: 0.9785 - val_sae: 367.6464 - val_sse: 506.5344 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 2.7541e-16 - r2_keras: -100.6650 - rmse: 0.8774 - sae: 2574.8479 - sse: 3153.5227\n","Epoch 79: val_loss did not improve from 0.19072\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 2.3464e-16 - r2_keras: -82.6275 - rmse: 0.8661 - sae: 1881.3472 - sse: 2288.2786 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.8964e-16 - val_r2_keras: -35.1086 - val_rmse: 0.9785 - val_sae: 367.6471 - val_sse: 506.5357 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: 1.1145e-16 - r2_keras: -100.6653 - rmse: 0.8774 - sae: 2574.8506 - sse: 3153.5293\n","Epoch 80: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: 6.4847e-17 - r2_keras: -82.6277 - rmse: 0.8661 - sae: 1881.3492 - sse: 2288.2834 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.8446e-16 - val_r2_keras: -35.1086 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5354 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2269 - mse: 0.1388 - pearson_correlation: -6.0683e-17 - r2_keras: -100.6655 - rmse: 0.8774 - sae: 2574.8525 - sse: 3153.5366\n","Epoch 81: val_loss improved from 0.19072 to 0.19072, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -4.8015e-17 - r2_keras: -82.6278 - rmse: 0.8661 - sae: 1881.3506 - sse: 2288.2888 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.3178e-16 - val_r2_keras: -35.1086 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5360 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.0996e-15 - r2_keras: -100.6658 - rmse: 0.8774 - sae: 2574.8557 - sse: 3153.5449\n","Epoch 82: val_loss improved from 0.19072 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2180 - mse: 0.1282 - pearson_correlation: -7.8125e-16 - r2_keras: -82.6281 - rmse: 0.8661 - sae: 1881.3529 - sse: 2288.2947 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.3696e-16 - val_r2_keras: -35.1085 - val_rmse: 0.9785 - val_sae: 367.6461 - val_sse: 506.5345 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.0101e-16 - r2_keras: -100.6659 - rmse: 0.8774 - sae: 2574.8564 - sse: 3153.5488\n","Epoch 83: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 9.2899e-17 - r2_keras: -82.6282 - rmse: 0.8661 - sae: 1881.3534 - sse: 2288.2976 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -4.2142e-17 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5363 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -7.2352e-17 - r2_keras: -100.6661 - rmse: 0.8774 - sae: 2574.8589 - sse: 3153.5549\n","Epoch 84: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 5.6306e-18 - r2_keras: -82.6284 - rmse: 0.8661 - sae: 1881.3553 - sse: 2288.3022 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 6.3213e-17 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5365 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.4455e-16 - r2_keras: -100.6663 - rmse: 0.8774 - sae: 2574.8604 - sse: 3153.5601\n","Epoch 85: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -2.4056e-16 - r2_keras: -82.6285 - rmse: 0.8661 - sae: 1881.3564 - sse: 2288.3062 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 4.2142e-17 - val_r2_keras: -35.1086 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5359 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.6665e-16 - r2_keras: -100.6665 - rmse: 0.8774 - sae: 2574.8630 - sse: 3153.5679\n","Epoch 86: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 1.6312e-16 - r2_keras: -82.6287 - rmse: 0.8661 - sae: 1881.3584 - sse: 2288.3120 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.8964e-16 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5367 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.3303e-16 - r2_keras: -100.6667 - rmse: 0.8774 - sae: 2574.8652 - sse: 3153.5747\n","Epoch 87: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 4.1439e-17 - r2_keras: -82.6289 - rmse: 0.8661 - sae: 1881.3600 - sse: 2288.3169 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5363 - learning_rate: 1.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 7.2934e-18 - r2_keras: -100.6669 - rmse: 0.8774 - sae: 2574.8674 - sse: 3153.5806\n","Epoch 88: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 1.1477e-17 - r2_keras: -82.6290 - rmse: 0.8661 - sae: 1881.3615 - sse: 2288.3210 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.4750e-16 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5366 - learning_rate: 1.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.6036e-16 - r2_keras: -100.6671 - rmse: 0.8775 - sae: 2574.8691 - sse: 3153.5864\n","Epoch 89: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 3.5935e-16 - r2_keras: -82.6292 - rmse: 0.8661 - sae: 1881.3629 - sse: 2288.3257 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.1071e-17 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6471 - val_sse: 506.5376 - learning_rate: 1.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -8.8629e-16 - r2_keras: -100.6674 - rmse: 0.8775 - sae: 2574.8716 - sse: 3153.5940\n","Epoch 90: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -6.0787e-16 - r2_keras: -82.6294 - rmse: 0.8661 - sae: 1881.3646 - sse: 2288.3311 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 4.2142e-17 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5369 - learning_rate: 1.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.7913e-16 - r2_keras: -100.6676 - rmse: 0.8775 - sae: 2574.8738 - sse: 3153.6003\n","Epoch 91: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -1.2131e-16 - r2_keras: -82.6296 - rmse: 0.8661 - sae: 1881.3662 - sse: 2288.3357 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.3178e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5375 - learning_rate: 1.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.6571e-16 - r2_keras: -100.6678 - rmse: 0.8775 - sae: 2574.8760 - sse: 3153.6072\n","Epoch 92: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -1.1803e-16 - r2_keras: -82.6298 - rmse: 0.8661 - sae: 1881.3679 - sse: 2288.3408 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1087 - val_rmse: 0.9785 - val_sae: 367.6463 - val_sse: 506.5366 - learning_rate: 1.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -7.8097e-16 - r2_keras: -100.6678 - rmse: 0.8775 - sae: 2574.8765 - sse: 3153.6089\n","Epoch 93: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -4.7434e-16 - r2_keras: -82.6298 - rmse: 0.8661 - sae: 1881.3683 - sse: 2288.3420 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.6857e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5379 - learning_rate: 1.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.6395e-16 - r2_keras: -100.6682 - rmse: 0.8775 - sae: 2574.8804 - sse: 3153.6196\n","Epoch 94: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 6.0164e-17 - r2_keras: -82.6301 - rmse: 0.8661 - sae: 1881.3711 - sse: 2288.3499 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5383 - learning_rate: 1.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.1653e-16 - r2_keras: -100.6684 - rmse: 0.8775 - sae: 2574.8823 - sse: 3153.6257\n","Epoch 95: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 2.5496e-16 - r2_keras: -82.6303 - rmse: 0.8661 - sae: 1881.3726 - sse: 2288.3545 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.2643e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5378 - learning_rate: 1.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.4762e-16 - r2_keras: -100.6686 - rmse: 0.8775 - sae: 2574.8843 - sse: 3153.6318\n","Epoch 96: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -1.1448e-16 - r2_keras: -82.6305 - rmse: 0.8661 - sae: 1881.3739 - sse: 2288.3591 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6474 - val_sse: 506.5392 - learning_rate: 1.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.3614e-16 - r2_keras: -100.6688 - rmse: 0.8775 - sae: 2574.8867 - sse: 3153.6387\n","Epoch 97: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -2.0288e-16 - r2_keras: -82.6307 - rmse: 0.8661 - sae: 1881.3759 - sse: 2288.3643 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.3178e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6464 - val_sse: 506.5379 - learning_rate: 1.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -2.8327e-16 - r2_keras: -100.6689 - rmse: 0.8775 - sae: 2574.8872 - sse: 3153.6416\n","Epoch 98: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: -1.5058e-16 - r2_keras: -82.6307 - rmse: 0.8661 - sae: 1881.3761 - sse: 2288.3662 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.6857e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5387 - learning_rate: 1.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.1938e-16 - r2_keras: -100.6692 - rmse: 0.8775 - sae: 2574.8904 - sse: 3153.6509\n","Epoch 99: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1282 - pearson_correlation: 1.6232e-16 - r2_keras: -82.6310 - rmse: 0.8661 - sae: 1881.3785 - sse: 2288.3730 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.7910e-16 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5392 - learning_rate: 1.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.3759e-17 - r2_keras: -100.6694 - rmse: 0.8775 - sae: 2574.8928 - sse: 3153.6575\n","Epoch 100: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 4.3820e-17 - r2_keras: -82.6312 - rmse: 0.8661 - sae: 1881.3802 - sse: 2288.3779 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -9.4819e-17 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5393 - learning_rate: 1.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.3128e-17 - r2_keras: -100.6696 - rmse: 0.8775 - sae: 2574.8950 - sse: 3153.6641\n","Epoch 101: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 6.5427e-17 - r2_keras: -82.6313 - rmse: 0.8661 - sae: 1881.3818 - sse: 2288.3826 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5398 - learning_rate: 1.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -7.5207e-16 - r2_keras: -100.6698 - rmse: 0.8775 - sae: 2574.8970 - sse: 3153.6699\n","Epoch 102: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -5.1934e-16 - r2_keras: -82.6315 - rmse: 0.8661 - sae: 1881.3833 - sse: 2288.3872 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1088 - val_rmse: 0.9785 - val_sae: 367.6464 - val_sse: 506.5387 - learning_rate: 1.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.3892e-16 - r2_keras: -100.6699 - rmse: 0.8775 - sae: 2574.8977 - sse: 3153.6736\n","Epoch 103: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.8905e-16 - r2_keras: -82.6316 - rmse: 0.8661 - sae: 1881.3839 - sse: 2288.3896 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5389 - learning_rate: 1.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.8770e-16 - r2_keras: -100.6702 - rmse: 0.8775 - sae: 2574.9009 - sse: 3153.6816\n","Epoch 104: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.4571e-16 - r2_keras: -82.6318 - rmse: 0.8661 - sae: 1881.3862 - sse: 2288.3958 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1090 - val_rmse: 0.9785 - val_sae: 367.6475 - val_sse: 506.5408 - learning_rate: 1.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.6466e-17 - r2_keras: -100.6704 - rmse: 0.8775 - sae: 2574.9036 - sse: 3153.6887\n","Epoch 105: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -8.0578e-17 - r2_keras: -82.6320 - rmse: 0.8661 - sae: 1881.3882 - sse: 2288.4011 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.7910e-16 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5401 - learning_rate: 1.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.7172e-16 - r2_keras: -100.6706 - rmse: 0.8775 - sae: 2574.9053 - sse: 3153.6956\n","Epoch 106: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -3.1731e-16 - r2_keras: -82.6322 - rmse: 0.8661 - sae: 1881.3894 - sse: 2288.4060 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -8.4283e-17 - val_r2_keras: -35.1090 - val_rmse: 0.9785 - val_sae: 367.6473 - val_sse: 506.5409 - learning_rate: 1.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.1202e-16 - r2_keras: -100.6708 - rmse: 0.8775 - sae: 2574.9077 - sse: 3153.7024\n","Epoch 107: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.1765e-17 - r2_keras: -82.6324 - rmse: 0.8661 - sae: 1881.3912 - sse: 2288.4111 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.7392e-16 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6462 - val_sse: 506.5395 - learning_rate: 1.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 5.4698e-16 - r2_keras: -100.6709 - rmse: 0.8775 - sae: 2574.9082 - sse: 3153.7056\n","Epoch 108: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 3.3442e-16 - r2_keras: -82.6325 - rmse: 0.8661 - sae: 1881.3916 - sse: 2288.4133 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 3.1606e-17 - val_r2_keras: -35.1090 - val_rmse: 0.9785 - val_sae: 367.6471 - val_sse: 506.5407 - learning_rate: 1.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 9.6122e-16 - r2_keras: -100.6712 - rmse: 0.8775 - sae: 2574.9116 - sse: 3153.7134\n","Epoch 109: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 6.5641e-16 - r2_keras: -82.6327 - rmse: 0.8662 - sae: 1881.3942 - sse: 2288.4192 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 3.1606e-17 - val_r2_keras: -35.1090 - val_rmse: 0.9785 - val_sae: 367.6473 - val_sse: 506.5414 - learning_rate: 1.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.6657e-16 - r2_keras: -100.6714 - rmse: 0.8775 - sae: 2574.9141 - sse: 3153.7209\n","Epoch 110: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -7.1361e-17 - r2_keras: -82.6329 - rmse: 0.8662 - sae: 1881.3960 - sse: 2288.4248 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -6.3212e-17 - val_r2_keras: -35.1090 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5410 - learning_rate: 1.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1562 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.7434e-16 - r2_keras: -100.6717 - rmse: 0.8775 - sae: 2574.9160 - sse: 3153.7280\n","Epoch 111: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.8740e-16 - r2_keras: -82.6331 - rmse: 0.8662 - sae: 1881.3973 - sse: 2288.4297 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 8.4283e-17 - val_r2_keras: -35.1090 - val_rmse: 0.9785 - val_sae: 367.6471 - val_sse: 506.5414 - learning_rate: 1.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.3898e-16 - r2_keras: -100.6719 - rmse: 0.8775 - sae: 2574.9185 - sse: 3153.7339\n","Epoch 112: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.9433e-16 - r2_keras: -82.6333 - rmse: 0.8662 - sae: 1881.3992 - sse: 2288.4341 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.4231e-16 - val_r2_keras: -35.1089 - val_rmse: 0.9785 - val_sae: 367.6462 - val_sse: 506.5402 - learning_rate: 1.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -7.0538e-16 - r2_keras: -100.6719 - rmse: 0.8775 - sae: 2574.9185 - sse: 3153.7366\n","Epoch 113: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -4.3434e-16 - r2_keras: -82.6334 - rmse: 0.8662 - sae: 1881.3992 - sse: 2288.4363 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -5.2677e-17 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5417 - learning_rate: 1.0000e-05\n","Epoch 114/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -2.4825e-16 - r2_keras: -100.6721 - rmse: 0.8775 - sae: 2574.9209 - sse: 3153.7427\n","Epoch 114: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.0850e-16 - r2_keras: -82.6335 - rmse: 0.8662 - sae: 1881.4010 - sse: 2288.4409 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 3.7927e-16 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6473 - val_sse: 506.5421 - learning_rate: 1.0000e-05\n","Epoch 115/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.3606e-16 - r2_keras: -100.6724 - rmse: 0.8775 - sae: 2574.9246 - sse: 3153.7520\n","Epoch 115: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.3821e-16 - r2_keras: -82.6338 - rmse: 0.8662 - sae: 1881.4037 - sse: 2288.4475 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5417 - learning_rate: 1.0000e-05\n","Epoch 116/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.8133e-17 - r2_keras: -100.6727 - rmse: 0.8775 - sae: 2574.9263 - sse: 3153.7590\n","Epoch 116: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -7.2797e-17 - r2_keras: -82.6340 - rmse: 0.8662 - sae: 1881.4049 - sse: 2288.4526 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.5285e-16 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5424 - learning_rate: 1.0000e-05\n","Epoch 117/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.0502e-16 - r2_keras: -100.6729 - rmse: 0.8775 - sae: 2574.9287 - sse: 3153.7656\n","Epoch 117: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0595 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.7569e-17 - r2_keras: -82.6342 - rmse: 0.8662 - sae: 1881.4067 - sse: 2288.4578 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 9.4818e-17 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5427 - learning_rate: 1.0000e-05\n","Epoch 118/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.0449e-16 - r2_keras: -100.6731 - rmse: 0.8775 - sae: 2574.9312 - sse: 3153.7727\n","Epoch 118: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.5350e-16 - r2_keras: -82.6343 - rmse: 0.8662 - sae: 1881.4084 - sse: 2288.4626 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 4.2142e-17 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5423 - learning_rate: 1.0000e-05\n","Epoch 119/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -2.9346e-16 - r2_keras: -100.6732 - rmse: 0.8775 - sae: 2574.9314 - sse: 3153.7744\n","Epoch 119: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.4887e-16 - r2_keras: -82.6344 - rmse: 0.8662 - sae: 1881.4088 - sse: 2288.4641 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 3.2660e-16 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6473 - val_sse: 506.5430 - learning_rate: 1.0000e-05\n","Epoch 120/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.6435e-16 - r2_keras: -100.6735 - rmse: 0.8775 - sae: 2574.9353 - sse: 3153.7847\n","Epoch 120: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.0747e-16 - r2_keras: -82.6347 - rmse: 0.8662 - sae: 1881.4115 - sse: 2288.4717 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 9.4818e-17 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5424 - learning_rate: 1.0000e-05\n","Epoch 121/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.2485e-16 - r2_keras: -100.6737 - rmse: 0.8775 - sae: 2574.9370 - sse: 3153.7908\n","Epoch 121: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.0875e-16 - r2_keras: -82.6348 - rmse: 0.8662 - sae: 1881.4127 - sse: 2288.4761 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -5.2677e-17 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6474 - val_sse: 506.5439 - learning_rate: 1.0000e-05\n","Epoch 122/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.3465e-17 - r2_keras: -100.6739 - rmse: 0.8775 - sae: 2574.9395 - sse: 3153.7971\n","Epoch 122: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.3481e-16 - r2_keras: -82.6350 - rmse: 0.8662 - sae: 1881.4146 - sse: 2288.4807 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.7910e-16 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5430 - learning_rate: 1.0000e-05\n","Epoch 123/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -8.6930e-17 - r2_keras: -100.6741 - rmse: 0.8775 - sae: 2574.9414 - sse: 3153.8037\n","Epoch 123: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -4.2835e-17 - r2_keras: -82.6352 - rmse: 0.8662 - sae: 1881.4160 - sse: 2288.4856 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -8.4283e-17 - val_r2_keras: -35.1091 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5431 - learning_rate: 1.0000e-05\n","Epoch 124/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.3944e-16 - r2_keras: -100.6742 - rmse: 0.8775 - sae: 2574.9421 - sse: 3153.8069\n","Epoch 124: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.6619e-16 - r2_keras: -82.6353 - rmse: 0.8662 - sae: 1881.4166 - sse: 2288.4880 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.8964e-16 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5432 - learning_rate: 1.0000e-05\n","Epoch 125/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.8978e-16 - r2_keras: -100.6744 - rmse: 0.8775 - sae: 2574.9443 - sse: 3153.8127\n","Epoch 125: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 3.0242e-16 - r2_keras: -82.6355 - rmse: 0.8662 - sae: 1881.4183 - sse: 2288.4924 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5436 - learning_rate: 1.0000e-05\n","Epoch 126/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -8.4858e-16 - r2_keras: -100.6747 - rmse: 0.8775 - sae: 2574.9475 - sse: 3153.8218\n","Epoch 126: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -4.8257e-16 - r2_keras: -82.6357 - rmse: 0.8662 - sae: 1881.4205 - sse: 2288.4988 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.6857e-16 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5443 - learning_rate: 1.0000e-05\n","Epoch 127/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.7882e-16 - r2_keras: -100.6749 - rmse: 0.8775 - sae: 2574.9495 - sse: 3153.8284\n","Epoch 127: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.6031e-16 - r2_keras: -82.6359 - rmse: 0.8662 - sae: 1881.4220 - sse: 2288.5039 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5436 - learning_rate: 1.0000e-05\n","Epoch 128/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -9.6846e-17 - r2_keras: -100.6751 - rmse: 0.8775 - sae: 2574.9514 - sse: 3153.8345\n","Epoch 128: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.2990e-17 - r2_keras: -82.6360 - rmse: 0.8662 - sae: 1881.4233 - sse: 2288.5081 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -5.2677e-17 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6465 - val_sse: 506.5435 - learning_rate: 1.0000e-05\n","Epoch 129/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.0629e-16 - r2_keras: -100.6752 - rmse: 0.8775 - sae: 2574.9526 - sse: 3153.8384\n","Epoch 129: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.2640e-16 - r2_keras: -82.6361 - rmse: 0.8662 - sae: 1881.4243 - sse: 2288.5110 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 3.1606e-17 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5441 - learning_rate: 1.0000e-05\n","Epoch 130/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.9696e-16 - r2_keras: -100.6754 - rmse: 0.8775 - sae: 2574.9543 - sse: 3153.8435\n","Epoch 130: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.9293e-16 - r2_keras: -82.6363 - rmse: 0.8662 - sae: 1881.4257 - sse: 2288.5151 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5444 - learning_rate: 1.0000e-05\n","Epoch 131/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.1883e-16 - r2_keras: -100.6756 - rmse: 0.8775 - sae: 2574.9570 - sse: 3153.8508\n","Epoch 131: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.3886e-16 - r2_keras: -82.6365 - rmse: 0.8662 - sae: 1881.4276 - sse: 2288.5203 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.8964e-16 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5452 - learning_rate: 1.0000e-05\n","Epoch 132/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 8.0598e-16 - r2_keras: -100.6759 - rmse: 0.8775 - sae: 2574.9600 - sse: 3153.8591\n","Epoch 132: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 5.3826e-16 - r2_keras: -82.6367 - rmse: 0.8662 - sae: 1881.4297 - sse: 2288.5264 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5443 - learning_rate: 1.0000e-05\n","Epoch 133/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.4806e-16 - r2_keras: -100.6761 - rmse: 0.8775 - sae: 2574.9619 - sse: 3153.8652\n","Epoch 133: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.7083e-16 - r2_keras: -82.6369 - rmse: 0.8662 - sae: 1881.4310 - sse: 2288.5308 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 3.1606e-17 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6469 - val_sse: 506.5451 - learning_rate: 1.0000e-05\n","Epoch 134/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.1994e-16 - r2_keras: -100.6764 - rmse: 0.8775 - sae: 2574.9644 - sse: 3153.8735\n","Epoch 134: val_loss improved from 0.19071 to 0.19071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.4805e-16 - r2_keras: -82.6371 - rmse: 0.8662 - sae: 1881.4330 - sse: 2288.5369 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.2124e-16 - val_r2_keras: -35.1092 - val_rmse: 0.9785 - val_sae: 367.6464 - val_sse: 506.5444 - learning_rate: 1.0000e-05\n","Epoch 135/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 7.5434e-16 - r2_keras: -100.6764 - rmse: 0.8775 - sae: 2574.9648 - sse: 3153.8755\n","Epoch 135: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 5.0431e-16 - r2_keras: -82.6371 - rmse: 0.8662 - sae: 1881.4332 - sse: 2288.5383 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 7.3747e-17 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5447 - learning_rate: 1.0000e-05\n","Epoch 136/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.0822e-16 - r2_keras: -100.6766 - rmse: 0.8775 - sae: 2574.9668 - sse: 3153.8818\n","Epoch 136: val_loss did not improve from 0.19071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -5.3250e-17 - r2_keras: -82.6373 - rmse: 0.8662 - sae: 1881.4348 - sse: 2288.5432 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.4749e-16 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5459 - learning_rate: 1.0000e-05\n","Epoch 137/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.9024e-16 - r2_keras: -100.6769 - rmse: 0.8775 - sae: 2574.9707 - sse: 3153.8916\n","Epoch 137: val_loss improved from 0.19071 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.3507e-16 - r2_keras: -82.6376 - rmse: 0.8662 - sae: 1881.4376 - sse: 2288.5503 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.8445e-16 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5455 - learning_rate: 1.0000e-05\n","Epoch 138/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -6.9133e-17 - r2_keras: -100.6771 - rmse: 0.8775 - sae: 2574.9719 - sse: 3153.8975\n","Epoch 138: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 4.6980e-17 - r2_keras: -82.6377 - rmse: 0.8662 - sae: 1881.4384 - sse: 2288.5542 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.1071e-17 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5463 - learning_rate: 1.0000e-05\n","Epoch 139/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.9082e-16 - r2_keras: -100.6773 - rmse: 0.8775 - sae: 2574.9746 - sse: 3153.9036\n","Epoch 139: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.2396e-16 - r2_keras: -82.6379 - rmse: 0.8662 - sae: 1881.4404 - sse: 2288.5588 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6461 - val_sse: 506.5449 - learning_rate: 1.0000e-05\n","Epoch 140/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 2.9170e-18 - r2_keras: -100.6774 - rmse: 0.8775 - sae: 2574.9751 - sse: 3153.9072\n","Epoch 140: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.6480e-17 - r2_keras: -82.6380 - rmse: 0.8662 - sae: 1881.4408 - sse: 2288.5615 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1093 - val_rmse: 0.9785 - val_sae: 367.6465 - val_sse: 506.5457 - learning_rate: 1.0000e-05\n","Epoch 141/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -2.2840e-16 - r2_keras: -100.6776 - rmse: 0.8775 - sae: 2574.9768 - sse: 3153.9124\n","Epoch 141: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.7022e-16 - r2_keras: -82.6382 - rmse: 0.8662 - sae: 1881.4421 - sse: 2288.5657 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -8.4282e-17 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5463 - learning_rate: 1.0000e-05\n","Epoch 142/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.2660e-16 - r2_keras: -100.6779 - rmse: 0.8775 - sae: 2574.9797 - sse: 3153.9204\n","Epoch 142: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.1936e-16 - r2_keras: -82.6384 - rmse: 0.8662 - sae: 1881.4443 - sse: 2288.5715 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -8.4282e-17 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6471 - val_sse: 506.5468 - learning_rate: 1.0000e-05\n","Epoch 143/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.6685e-16 - r2_keras: -100.6781 - rmse: 0.8775 - sae: 2574.9824 - sse: 3153.9277\n","Epoch 143: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 6.3518e-17 - r2_keras: -82.6386 - rmse: 0.8662 - sae: 1881.4462 - sse: 2288.5767 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.7392e-16 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5470 - learning_rate: 1.0000e-05\n","Epoch 144/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 6.2685e-16 - r2_keras: -100.6783 - rmse: 0.8775 - sae: 2574.9846 - sse: 3153.9343\n","Epoch 144: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 4.2971e-16 - r2_keras: -82.6388 - rmse: 0.8662 - sae: 1881.4479 - sse: 2288.5815 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6462 - val_sse: 506.5459 - learning_rate: 1.0000e-05\n","Epoch 145/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.1376e-16 - r2_keras: -100.6784 - rmse: 0.8775 - sae: 2574.9854 - sse: 3153.9380\n","Epoch 145: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.2970e-16 - r2_keras: -82.6389 - rmse: 0.8662 - sae: 1881.4484 - sse: 2288.5842 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -3.8980e-16 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6466 - val_sse: 506.5468 - learning_rate: 1.0000e-05\n","Epoch 146/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 5.0959e-16 - r2_keras: -100.6786 - rmse: 0.8775 - sae: 2574.9873 - sse: 3153.9438\n","Epoch 146: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.9201e-16 - r2_keras: -82.6390 - rmse: 0.8662 - sae: 1881.4498 - sse: 2288.5889 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5473 - learning_rate: 1.0000e-05\n","Epoch 147/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.3253e-16 - r2_keras: -100.6788 - rmse: 0.8775 - sae: 2574.9897 - sse: 3153.9507\n","Epoch 147: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.3444e-16 - r2_keras: -82.6392 - rmse: 0.8662 - sae: 1881.4518 - sse: 2288.5940 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.3178e-16 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6468 - val_sse: 506.5476 - learning_rate: 1.0000e-05\n","Epoch 148/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 6.6506e-16 - r2_keras: -100.6791 - rmse: 0.8775 - sae: 2574.9917 - sse: 3153.9570\n","Epoch 148: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 5.0195e-16 - r2_keras: -82.6394 - rmse: 0.8662 - sae: 1881.4531 - sse: 2288.5984 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.1070e-16 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6472 - val_sse: 506.5482 - learning_rate: 1.0000e-05\n","Epoch 149/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 6.3209e-16 - r2_keras: -100.6793 - rmse: 0.8775 - sae: 2574.9951 - sse: 3153.9653\n","Epoch 149: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 4.0864e-16 - r2_keras: -82.6396 - rmse: 0.8662 - sae: 1881.4556 - sse: 2288.6045 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1094 - val_rmse: 0.9785 - val_sae: 367.6463 - val_sse: 506.5470 - learning_rate: 1.0000e-05\n","Epoch 150/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.5790e-16 - r2_keras: -100.6795 - rmse: 0.8775 - sae: 2574.9956 - sse: 3153.9697\n","Epoch 150: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.2207e-16 - r2_keras: -82.6397 - rmse: 0.8662 - sae: 1881.4559 - sse: 2288.6077 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.4231e-16 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6465 - val_sse: 506.5476 - learning_rate: 1.0000e-05\n","Epoch 151/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.9047e-16 - r2_keras: -100.6796 - rmse: 0.8775 - sae: 2574.9976 - sse: 3153.9746\n","Epoch 151: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.6903e-16 - r2_keras: -82.6399 - rmse: 0.8662 - sae: 1881.4575 - sse: 2288.6116 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -4.4248e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9785 - val_sae: 367.6474 - val_sse: 506.5492 - learning_rate: 1.0000e-05\n","Epoch 152/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.5503e-17 - r2_keras: -100.6798 - rmse: 0.8775 - sae: 2575.0000 - sse: 3153.9814\n","Epoch 152: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.4667e-17 - r2_keras: -82.6401 - rmse: 0.8662 - sae: 1881.4594 - sse: 2288.6167 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -8.4282e-17 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6467 - val_sse: 506.5484 - learning_rate: 1.0000e-05\n","Epoch 153/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.1006e-16 - r2_keras: -100.6801 - rmse: 0.8775 - sae: 2575.0020 - sse: 3153.9888\n","Epoch 153: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.8214e-16 - r2_keras: -82.6403 - rmse: 0.8662 - sae: 1881.4607 - sse: 2288.6218 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -3.5820e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9785 - val_sae: 367.6471 - val_sse: 506.5491 - learning_rate: 1.0000e-05\n","Epoch 154/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.0715e-16 - r2_keras: -100.6803 - rmse: 0.8775 - sae: 2575.0049 - sse: 3153.9966\n","Epoch 154: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.1894e-16 - r2_keras: -82.6405 - rmse: 0.8662 - sae: 1881.4628 - sse: 2288.6277 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.6338e-16 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 367.6462 - val_sse: 506.5476 - learning_rate: 1.0000e-05\n","Epoch 155/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 7.8638e-16 - r2_keras: -100.6804 - rmse: 0.8775 - sae: 2575.0056 - sse: 3153.9998\n","Epoch 155: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 4.9497e-16 - r2_keras: -82.6406 - rmse: 0.8662 - sae: 1881.4633 - sse: 2288.6299 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9785 - val_sae: 367.6470 - val_sse: 506.5493 - learning_rate: 1.0000e-05\n","Epoch 156/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -5.8191e-16 - r2_keras: -100.6806 - rmse: 0.8775 - sae: 2575.0078 - sse: 3154.0056\n","Epoch 156: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -3.6527e-16 - r2_keras: -82.6407 - rmse: 0.8662 - sae: 1881.4650 - sse: 2288.6345 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 5.2676e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5494 - learning_rate: 1.0000e-05\n","Epoch 157/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.3767e-16 - r2_keras: -100.6808 - rmse: 0.8775 - sae: 2575.0098 - sse: 3154.0115\n","Epoch 157: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 5.6826e-17 - r2_keras: -82.6409 - rmse: 0.8662 - sae: 1881.4666 - sse: 2288.6389 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2207 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5493 - learning_rate: 1.0000e-05\n","Epoch 158/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 1.4467e-16 - r2_keras: -100.6810 - rmse: 0.8775 - sae: 2575.0120 - sse: 3154.0183\n","Epoch 158: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 9.5033e-17 - r2_keras: -82.6411 - rmse: 0.8662 - sae: 1881.4681 - sse: 2288.6438 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4817e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5499 - learning_rate: 1.0000e-05\n","Epoch 159/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.3514e-16 - r2_keras: -100.6813 - rmse: 0.8775 - sae: 2575.0142 - sse: 3154.0254\n","Epoch 159: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.8531e-16 - r2_keras: -82.6413 - rmse: 0.8662 - sae: 1881.4697 - sse: 2288.6489 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3746e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5500 - learning_rate: 1.0000e-05\n","Epoch 160/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.7807e-16 - r2_keras: -100.6814 - rmse: 0.8775 - sae: 2575.0166 - sse: 3154.0315\n","Epoch 160: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 3.3005e-16 - r2_keras: -82.6414 - rmse: 0.8662 - sae: 1881.4716 - sse: 2288.6536 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5496 - learning_rate: 1.0000e-05\n","Epoch 161/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.2819e-16 - r2_keras: -100.6816 - rmse: 0.8775 - sae: 2575.0181 - sse: 3154.0361\n","Epoch 161: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.1932e-16 - r2_keras: -82.6416 - rmse: 0.8662 - sae: 1881.4727 - sse: 2288.6570 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6473 - val_sse: 506.5509 - learning_rate: 1.0000e-05\n","Epoch 162/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.4681e-16 - r2_keras: -100.6818 - rmse: 0.8775 - sae: 2575.0200 - sse: 3154.0430\n","Epoch 162: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.8302e-16 - r2_keras: -82.6418 - rmse: 0.8662 - sae: 1881.4740 - sse: 2288.6621 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.6873e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5498 - learning_rate: 1.0000e-05\n","Epoch 163/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -2.6864e-16 - r2_keras: -100.6820 - rmse: 0.8775 - sae: 2575.0225 - sse: 3154.0496\n","Epoch 163: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -2.0413e-16 - r2_keras: -82.6419 - rmse: 0.8662 - sae: 1881.4757 - sse: 2288.6667 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 7.3746e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6475 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 164/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.8434e-16 - r2_keras: -100.6822 - rmse: 0.8775 - sae: 2575.0239 - sse: 3154.0547\n","Epoch 164: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.0919e-16 - r2_keras: -82.6421 - rmse: 0.8662 - sae: 1881.4769 - sse: 2288.6707 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3746e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5502 - learning_rate: 1.0000e-05\n","Epoch 165/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -4.7835e-17 - r2_keras: -100.6824 - rmse: 0.8775 - sae: 2575.0261 - sse: 3154.0601\n","Epoch 165: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.0558e-16 - r2_keras: -82.6423 - rmse: 0.8662 - sae: 1881.4785 - sse: 2288.6746 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5506 - learning_rate: 1.0000e-05\n","Epoch 166/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.9289e-16 - r2_keras: -100.6826 - rmse: 0.8775 - sae: 2575.0286 - sse: 3154.0674\n","Epoch 166: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 2.3217e-16 - r2_keras: -82.6424 - rmse: 0.8662 - sae: 1881.4803 - sse: 2288.6799 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6474 - val_sse: 506.5518 - learning_rate: 1.0000e-05\n","Epoch 167/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -7.8957e-16 - r2_keras: -100.6828 - rmse: 0.8775 - sae: 2575.0308 - sse: 3154.0737\n","Epoch 167: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -5.2685e-16 - r2_keras: -82.6426 - rmse: 0.8662 - sae: 1881.4819 - sse: 2288.6846 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5507 - learning_rate: 1.0000e-05\n","Epoch 168/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -2.4355e-16 - r2_keras: -100.6830 - rmse: 0.8775 - sae: 2575.0327 - sse: 3154.0796\n","Epoch 168: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.7984e-16 - r2_keras: -82.6428 - rmse: 0.8662 - sae: 1881.4834 - sse: 2288.6890 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6475 - val_sse: 506.5524 - learning_rate: 1.0000e-05\n","Epoch 169/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -6.8048e-16 - r2_keras: -100.6832 - rmse: 0.8775 - sae: 2575.0347 - sse: 3154.0854\n","Epoch 169: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -4.1255e-16 - r2_keras: -82.6430 - rmse: 0.8662 - sae: 1881.4849 - sse: 2288.6936 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4816e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 170/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -1.9455e-16 - r2_keras: -100.6834 - rmse: 0.8775 - sae: 2575.0361 - sse: 3154.0916\n","Epoch 170: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.2875e-16 - r2_keras: -82.6431 - rmse: 0.8662 - sae: 1881.4860 - sse: 2288.6978 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4816e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5514 - learning_rate: 1.0000e-05\n","Epoch 171/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 5.9501e-17 - r2_keras: -100.6836 - rmse: 0.8775 - sae: 2575.0381 - sse: 3154.0967\n","Epoch 171: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.9828e-17 - r2_keras: -82.6433 - rmse: 0.8662 - sae: 1881.4874 - sse: 2288.7019 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 7.3746e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 172/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 9.1877e-17 - r2_keras: -100.6838 - rmse: 0.8775 - sae: 2575.0405 - sse: 3154.1033\n","Epoch 172: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.0754e-16 - r2_keras: -82.6434 - rmse: 0.8662 - sae: 1881.4891 - sse: 2288.7063 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6471 - val_sse: 506.5524 - learning_rate: 1.0000e-05\n","Epoch 173/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -3.7917e-17 - r2_keras: -100.6839 - rmse: 0.8775 - sae: 2575.0425 - sse: 3154.1089\n","Epoch 173: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.2542e-16 - r2_keras: -82.6436 - rmse: 0.8662 - sae: 1881.4906 - sse: 2288.7107 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5528 - learning_rate: 1.0000e-05\n","Epoch 174/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 4.1709e-17 - r2_keras: -100.6841 - rmse: 0.8775 - sae: 2575.0444 - sse: 3154.1150\n","Epoch 174: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -1.4708e-17 - r2_keras: -82.6438 - rmse: 0.8662 - sae: 1881.4921 - sse: 2288.7153 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.7926e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5523 - learning_rate: 1.0000e-05\n","Epoch 175/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 5.8334e-17 - r2_keras: -100.6844 - rmse: 0.8775 - sae: 2575.0469 - sse: 3154.1228\n","Epoch 175: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.0455e-16 - r2_keras: -82.6440 - rmse: 0.8662 - sae: 1881.4938 - sse: 2288.7207 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5526 - learning_rate: 1.0000e-05\n","Epoch 176/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: -9.1293e-17 - r2_keras: -100.6846 - rmse: 0.8775 - sae: 2575.0488 - sse: 3154.1279\n","Epoch 176: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: -6.5385e-18 - r2_keras: -82.6441 - rmse: 0.8662 - sae: 1881.4952 - sse: 2288.7249 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.5284e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6465 - val_sse: 506.5521 - learning_rate: 1.0000e-05\n","Epoch 177/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2268 - mse: 0.1388 - pearson_correlation: 3.1734e-16 - r2_keras: -100.6847 - rmse: 0.8775 - sae: 2575.0493 - sse: 3154.1309\n","Epoch 177: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.9077e-16 - r2_keras: -82.6442 - rmse: 0.8662 - sae: 1881.4956 - sse: 2288.7268 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.5284e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5526 - learning_rate: 1.0000e-05\n","Epoch 178/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 2.8204e-16 - r2_keras: -100.6849 - rmse: 0.8775 - sae: 2575.0525 - sse: 3154.1389\n","Epoch 178: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2179 - mse: 0.1281 - pearson_correlation: 1.6866e-16 - r2_keras: -82.6444 - rmse: 0.8662 - sae: 1881.4979 - sse: 2288.7329 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.5803e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6471 - val_sse: 506.5533 - learning_rate: 1.0000e-05\n","Epoch 179/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -1.1958e-16 - r2_keras: -100.6851 - rmse: 0.8775 - sae: 2575.0544 - sse: 3154.1453\n","Epoch 179: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -9.7200e-17 - r2_keras: -82.6446 - rmse: 0.8662 - sae: 1881.4995 - sse: 2288.7378 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.7910e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5529 - learning_rate: 1.0000e-05\n","Epoch 180/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 2.8321e-16 - r2_keras: -100.6853 - rmse: 0.8775 - sae: 2575.0566 - sse: 3154.1523\n","Epoch 180: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.9873e-16 - r2_keras: -82.6448 - rmse: 0.8662 - sae: 1881.5010 - sse: 2288.7427 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.0552e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6476 - val_sse: 506.5546 - learning_rate: 1.0000e-05\n","Epoch 181/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 1.3708e-17 - r2_keras: -100.6856 - rmse: 0.8775 - sae: 2575.0596 - sse: 3154.1597\n","Epoch 181: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.4335e-17 - r2_keras: -82.6450 - rmse: 0.8662 - sae: 1881.5032 - sse: 2288.7480 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6463 - val_sse: 506.5526 - learning_rate: 1.0000e-05\n","Epoch 182/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -1.7500e-16 - r2_keras: -100.6856 - rmse: 0.8775 - sae: 2575.0596 - sse: 3154.1616\n","Epoch 182: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -8.1239e-17 - r2_keras: -82.6450 - rmse: 0.8662 - sae: 1881.5032 - sse: 2288.7495 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5535 - learning_rate: 1.0000e-05\n","Epoch 183/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 9.9166e-18 - r2_keras: -100.6859 - rmse: 0.8775 - sae: 2575.0630 - sse: 3154.1702\n","Epoch 183: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.6374e-17 - r2_keras: -82.6453 - rmse: 0.8662 - sae: 1881.5057 - sse: 2288.7559 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6471 - val_sse: 506.5544 - learning_rate: 1.0000e-05\n","Epoch 184/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 2.8962e-16 - r2_keras: -100.6861 - rmse: 0.8775 - sae: 2575.0654 - sse: 3154.1772\n","Epoch 184: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.8411e-16 - r2_keras: -82.6455 - rmse: 0.8662 - sae: 1881.5074 - sse: 2288.7610 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5543 - learning_rate: 1.0000e-05\n","Epoch 185/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 1.2775e-16 - r2_keras: -100.6863 - rmse: 0.8775 - sae: 2575.0669 - sse: 3154.1812\n","Epoch 185: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.0075e-16 - r2_keras: -82.6456 - rmse: 0.8662 - sae: 1881.5085 - sse: 2288.7639 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.0017e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 186/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 2.2341e-16 - r2_keras: -100.6865 - rmse: 0.8775 - sae: 2575.0688 - sse: 3154.1880\n","Epoch 186: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.8768e-16 - r2_keras: -82.6458 - rmse: 0.8662 - sae: 1881.5100 - sse: 2288.7690 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6461 - val_sse: 506.5531 - learning_rate: 1.0000e-05\n","Epoch 187/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 1.0471e-16 - r2_keras: -100.6866 - rmse: 0.8775 - sae: 2575.0693 - sse: 3154.1904\n","Epoch 187: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 9.7201e-17 - r2_keras: -82.6458 - rmse: 0.8662 - sae: 1881.5104 - sse: 2288.7710 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5544 - learning_rate: 1.0000e-05\n","Epoch 188/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 3.2258e-16 - r2_keras: -100.6868 - rmse: 0.8775 - sae: 2575.0720 - sse: 3154.1978\n","Epoch 188: val_loss did not improve from 0.19070\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.4387e-16 - r2_keras: -82.6461 - rmse: 0.8662 - sae: 1881.5125 - sse: 2288.7766 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6474 - val_sse: 506.5557 - learning_rate: 1.0000e-05\n","Epoch 189/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -1.3125e-16 - r2_keras: -100.6871 - rmse: 0.8775 - sae: 2575.0752 - sse: 3154.2063\n","Epoch 189: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -6.4352e-17 - r2_keras: -82.6463 - rmse: 0.8662 - sae: 1881.5146 - sse: 2288.7825 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.5803e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 190/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 5.8944e-16 - r2_keras: -100.6872 - rmse: 0.8775 - sae: 2575.0767 - sse: 3154.2112\n","Epoch 190: val_loss improved from 0.19070 to 0.19070, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.6604e-16 - r2_keras: -82.6464 - rmse: 0.8662 - sae: 1881.5157 - sse: 2288.7861 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4815e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5554 - learning_rate: 1.0000e-05\n","Epoch 191/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 3.9986e-16 - r2_keras: -100.6875 - rmse: 0.8775 - sae: 2575.0793 - sse: 3154.2192\n","Epoch 191: val_loss improved from 0.19070 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.4565e-16 - r2_keras: -82.6466 - rmse: 0.8662 - sae: 1881.5178 - sse: 2288.7920 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.8445e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6461 - val_sse: 506.5541 - learning_rate: 1.0000e-05\n","Epoch 192/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 6.9735e-16 - r2_keras: -100.6876 - rmse: 0.8775 - sae: 2575.0796 - sse: 3154.2212\n","Epoch 192: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 4.4176e-16 - r2_keras: -82.6467 - rmse: 0.8662 - sae: 1881.5179 - sse: 2288.7935 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.7408e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5555 - learning_rate: 1.0000e-05\n","Epoch 193/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 1.7616e-16 - r2_keras: -100.6877 - rmse: 0.8775 - sae: 2575.0815 - sse: 3154.2266\n","Epoch 193: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 5.0367e-17 - r2_keras: -82.6469 - rmse: 0.8662 - sae: 1881.5194 - sse: 2288.7976 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.0552e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6471 - val_sse: 506.5561 - learning_rate: 1.0000e-05\n","Epoch 194/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -2.1903e-16 - r2_keras: -100.6880 - rmse: 0.8775 - sae: 2575.0845 - sse: 3154.2344\n","Epoch 194: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.0871e-16 - r2_keras: -82.6471 - rmse: 0.8662 - sae: 1881.5216 - sse: 2288.8035 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.2140e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5555 - learning_rate: 1.0000e-05\n","Epoch 195/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -3.5640e-16 - r2_keras: -100.6882 - rmse: 0.8775 - sae: 2575.0867 - sse: 3154.2412\n","Epoch 195: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.7114e-16 - r2_keras: -82.6472 - rmse: 0.8662 - sae: 1881.5232 - sse: 2288.8083 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.9498e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5561 - learning_rate: 1.0000e-05\n","Epoch 196/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 6.3931e-16 - r2_keras: -100.6885 - rmse: 0.8775 - sae: 2575.0896 - sse: 3154.2493\n","Epoch 196: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.8794e-16 - r2_keras: -82.6475 - rmse: 0.8662 - sae: 1881.5253 - sse: 2288.8142 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.1605e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6461 - val_sse: 506.5550 - learning_rate: 1.0000e-05\n","Epoch 197/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 3.7857e-16 - r2_keras: -100.6886 - rmse: 0.8775 - sae: 2575.0898 - sse: 3154.2522\n","Epoch 197: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.1695e-16 - r2_keras: -82.6475 - rmse: 0.8662 - sae: 1881.5255 - sse: 2288.8164 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.9515e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5561 - learning_rate: 1.0000e-05\n","Epoch 198/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -4.4215e-16 - r2_keras: -100.6887 - rmse: 0.8775 - sae: 2575.0918 - sse: 3154.2568\n","Epoch 198: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.8957e-16 - r2_keras: -82.6477 - rmse: 0.8662 - sae: 1881.5271 - sse: 2288.8201 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 7.3745e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5569 - learning_rate: 1.0000e-05\n","Epoch 199/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -5.1127e-16 - r2_keras: -100.6889 - rmse: 0.8775 - sae: 2575.0942 - sse: 3154.2637\n","Epoch 199: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.4037e-16 - r2_keras: -82.6479 - rmse: 0.8662 - sae: 1881.5288 - sse: 2288.8250 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.9498e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5564 - learning_rate: 1.0000e-05\n","Epoch 200/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -6.5038e-16 - r2_keras: -100.6891 - rmse: 0.8775 - sae: 2575.0957 - sse: 3154.2700\n","Epoch 200: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.7218e-16 - r2_keras: -82.6480 - rmse: 0.8662 - sae: 1881.5299 - sse: 2288.8296 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.4749e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5568 - learning_rate: 1.0000e-05\n","Epoch 201/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -2.0795e-16 - r2_keras: -100.6894 - rmse: 0.8775 - sae: 2575.0991 - sse: 3154.2778\n","Epoch 201: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -7.5810e-17 - r2_keras: -82.6483 - rmse: 0.8662 - sae: 1881.5323 - sse: 2288.8354 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.4749e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6464 - val_sse: 506.5562 - learning_rate: 1.0000e-05\n","Epoch 202/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -7.5537e-17 - r2_keras: -100.6895 - rmse: 0.8775 - sae: 2575.1001 - sse: 3154.2817\n","Epoch 202: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -4.0689e-18 - r2_keras: -82.6484 - rmse: 0.8662 - sae: 1881.5331 - sse: 2288.8384 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -9.4815e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5572 - learning_rate: 1.0000e-05\n","Epoch 203/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -2.1699e-16 - r2_keras: -100.6898 - rmse: 0.8775 - sae: 2575.1025 - sse: 3154.2891\n","Epoch 203: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.9425e-16 - r2_keras: -82.6486 - rmse: 0.8662 - sae: 1881.5348 - sse: 2288.8435 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2675e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6461 - val_sse: 506.5559 - learning_rate: 1.0000e-05\n","Epoch 204/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 7.7754e-16 - r2_keras: -100.6899 - rmse: 0.8775 - sae: 2575.1038 - sse: 3154.2930\n","Epoch 204: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 5.7929e-16 - r2_keras: -82.6487 - rmse: 0.8662 - sae: 1881.5358 - sse: 2288.8467 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6464 - val_sse: 506.5569 - learning_rate: 1.0000e-05\n","Epoch 205/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -1.1724e-16 - r2_keras: -100.6901 - rmse: 0.8775 - sae: 2575.1057 - sse: 3154.2991\n","Epoch 205: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1512 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.1453e-16 - r2_keras: -82.6489 - rmse: 0.8662 - sae: 1881.5372 - sse: 2288.8513 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5582 - learning_rate: 1.0000e-05\n","Epoch 206/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -2.7386e-16 - r2_keras: -100.6903 - rmse: 0.8776 - sae: 2575.1086 - sse: 3154.3057\n","Epoch 206: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.4478e-16 - r2_keras: -82.6490 - rmse: 0.8662 - sae: 1881.5394 - sse: 2288.8562 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -6.3210e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5576 - learning_rate: 1.0000e-05\n","Epoch 207/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -7.4953e-17 - r2_keras: -100.6906 - rmse: 0.8776 - sae: 2575.1116 - sse: 3154.3152\n","Epoch 207: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -7.1224e-17 - r2_keras: -82.6493 - rmse: 0.8662 - sae: 1881.5415 - sse: 2288.8628 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5576 - learning_rate: 1.0000e-05\n","Epoch 208/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 5.4392e-16 - r2_keras: -100.6907 - rmse: 0.8776 - sae: 2575.1123 - sse: 3154.3179\n","Epoch 208: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.3994e-16 - r2_keras: -82.6494 - rmse: 0.8662 - sae: 1881.5421 - sse: 2288.8650 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.5284e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6462 - val_sse: 506.5569 - learning_rate: 1.0000e-05\n","Epoch 209/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -9.2977e-16 - r2_keras: -100.6908 - rmse: 0.8776 - sae: 2575.1140 - sse: 3154.3230\n","Epoch 209: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -5.5372e-16 - r2_keras: -82.6495 - rmse: 0.8662 - sae: 1881.5433 - sse: 2288.8687 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2675e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5583 - learning_rate: 1.0000e-05\n","Epoch 210/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -1.3416e-17 - r2_keras: -100.6911 - rmse: 0.8776 - sae: 2575.1167 - sse: 3154.3308\n","Epoch 210: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.4612e-17 - r2_keras: -82.6497 - rmse: 0.8662 - sae: 1881.5454 - sse: 2288.8745 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6473 - val_sse: 506.5593 - learning_rate: 1.0000e-05\n","Epoch 211/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 2.5227e-16 - r2_keras: -100.6913 - rmse: 0.8776 - sae: 2575.1187 - sse: 3154.3376\n","Epoch 211: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.2250e-16 - r2_keras: -82.6499 - rmse: 0.8662 - sae: 1881.5468 - sse: 2288.8796 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4815e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6465 - val_sse: 506.5581 - learning_rate: 1.0000e-05\n","Epoch 212/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -2.4702e-16 - r2_keras: -100.6915 - rmse: 0.8776 - sae: 2575.1204 - sse: 3154.3425\n","Epoch 212: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.4876e-16 - r2_keras: -82.6500 - rmse: 0.8662 - sae: 1881.5481 - sse: 2288.8833 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5586 - learning_rate: 1.0000e-05\n","Epoch 213/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: 2.9456e-16 - r2_keras: -100.6917 - rmse: 0.8776 - sae: 2575.1228 - sse: 3154.3489\n","Epoch 213: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.4536e-16 - r2_keras: -82.6502 - rmse: 0.8662 - sae: 1881.5499 - sse: 2288.8879 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5587 - learning_rate: 1.0000e-05\n","Epoch 214/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1388 - pearson_correlation: -5.8095e-16 - r2_keras: -100.6919 - rmse: 0.8776 - sae: 2575.1245 - sse: 3154.3542\n","Epoch 214: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.1173e-16 - r2_keras: -82.6503 - rmse: 0.8662 - sae: 1881.5510 - sse: 2288.8916 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5589 - learning_rate: 1.0000e-05\n","Epoch 215/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 5.7628e-16 - r2_keras: -100.6920 - rmse: 0.8776 - sae: 2575.1262 - sse: 3154.3589\n","Epoch 215: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 4.4228e-16 - r2_keras: -82.6505 - rmse: 0.8662 - sae: 1881.5524 - sse: 2288.8955 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.3695e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5597 - learning_rate: 1.0000e-05\n","Epoch 216/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -5.8328e-18 - r2_keras: -100.6923 - rmse: 0.8776 - sae: 2575.1292 - sse: 3154.3667\n","Epoch 216: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -7.6671e-18 - r2_keras: -82.6507 - rmse: 0.8662 - sae: 1881.5546 - sse: 2288.9011 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4815e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6465 - val_sse: 506.5589 - learning_rate: 1.0000e-05\n","Epoch 217/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -3.1905e-16 - r2_keras: -100.6924 - rmse: 0.8776 - sae: 2575.1304 - sse: 3154.3721\n","Epoch 217: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.9759e-16 - r2_keras: -82.6509 - rmse: 0.8662 - sae: 1881.5554 - sse: 2288.9050 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3744e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6473 - val_sse: 506.5605 - learning_rate: 1.0000e-05\n","Epoch 218/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 4.6225e-16 - r2_keras: -100.6927 - rmse: 0.8776 - sae: 2575.1333 - sse: 3154.3804\n","Epoch 218: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.6140e-16 - r2_keras: -82.6511 - rmse: 0.8662 - sae: 1881.5576 - sse: 2288.9111 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5594 - learning_rate: 1.0000e-05\n","Epoch 219/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.8872e-16 - r2_keras: -100.6929 - rmse: 0.8776 - sae: 2575.1353 - sse: 3154.3857\n","Epoch 219: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.8540e-16 - r2_keras: -82.6512 - rmse: 0.8662 - sae: 1881.5590 - sse: 2288.9148 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.5819e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 220/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 4.6808e-16 - r2_keras: -100.6930 - rmse: 0.8776 - sae: 2575.1370 - sse: 3154.3909\n","Epoch 220: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.4511e-16 - r2_keras: -82.6514 - rmse: 0.8662 - sae: 1881.5603 - sse: 2288.9189 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6471 - val_sse: 506.5608 - learning_rate: 1.0000e-05\n","Epoch 221/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.6189e-16 - r2_keras: -100.6933 - rmse: 0.8776 - sae: 2575.1392 - sse: 3154.3979\n","Epoch 221: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.1946e-16 - r2_keras: -82.6516 - rmse: 0.8663 - sae: 1881.5620 - sse: 2288.9241 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5602 - learning_rate: 1.0000e-05\n","Epoch 222/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.3739e-16 - r2_keras: -100.6935 - rmse: 0.8776 - sae: 2575.1411 - sse: 3154.4043\n","Epoch 222: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.9794e-16 - r2_keras: -82.6517 - rmse: 0.8663 - sae: 1881.5634 - sse: 2288.9285 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6473 - val_sse: 506.5612 - learning_rate: 1.0000e-05\n","Epoch 223/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -1.6302e-16 - r2_keras: -100.6936 - rmse: 0.8776 - sae: 2575.1438 - sse: 3154.4099\n","Epoch 223: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -8.5067e-17 - r2_keras: -82.6519 - rmse: 0.8663 - sae: 1881.5653 - sse: 2288.9329 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6462 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 224/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 5.3602e-16 - r2_keras: -100.6938 - rmse: 0.8776 - sae: 2575.1440 - sse: 3154.4131\n","Epoch 224: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.5026e-16 - r2_keras: -82.6520 - rmse: 0.8663 - sae: 1881.5656 - sse: 2288.9353 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.8444e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5611 - learning_rate: 1.0000e-05\n","Epoch 225/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -3.5433e-16 - r2_keras: -100.6941 - rmse: 0.8776 - sae: 2575.1475 - sse: 3154.4224\n","Epoch 225: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.9573e-16 - r2_keras: -82.6522 - rmse: 0.8663 - sae: 1881.5680 - sse: 2288.9421 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.5284e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5615 - learning_rate: 1.0000e-05\n","Epoch 226/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -3.6017e-16 - r2_keras: -100.6942 - rmse: 0.8776 - sae: 2575.1499 - sse: 3154.4282\n","Epoch 226: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.4707e-16 - r2_keras: -82.6524 - rmse: 0.8663 - sae: 1881.5698 - sse: 2288.9465 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2674e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5618 - learning_rate: 1.0000e-05\n","Epoch 227/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 7.8157e-17 - r2_keras: -100.6944 - rmse: 0.8776 - sae: 2575.1514 - sse: 3154.4336\n","Epoch 227: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 4.8326e-17 - r2_keras: -82.6525 - rmse: 0.8663 - sae: 1881.5708 - sse: 2288.9502 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.7909e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5618 - learning_rate: 1.0000e-05\n","Epoch 228/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -1.0382e-16 - r2_keras: -100.6946 - rmse: 0.8776 - sae: 2575.1538 - sse: 3154.4395\n","Epoch 228: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.2414e-17 - r2_keras: -82.6527 - rmse: 0.8663 - sae: 1881.5728 - sse: 2288.9548 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -6.3209e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6463 - val_sse: 506.5606 - learning_rate: 1.0000e-05\n","Epoch 229/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -3.7300e-16 - r2_keras: -100.6947 - rmse: 0.8776 - sae: 2575.1541 - sse: 3154.4436\n","Epoch 229: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.2080e-16 - r2_keras: -82.6528 - rmse: 0.8663 - sae: 1881.5729 - sse: 2288.9578 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.6337e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5614 - learning_rate: 1.0000e-05\n","Epoch 230/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 8.1773e-16 - r2_keras: -100.6949 - rmse: 0.8776 - sae: 2575.1565 - sse: 3154.4497\n","Epoch 230: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 5.2768e-16 - r2_keras: -82.6530 - rmse: 0.8663 - sae: 1881.5748 - sse: 2288.9624 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.6856e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6474 - val_sse: 506.5626 - learning_rate: 1.0000e-05\n","Epoch 231/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.9163e-17 - r2_keras: -100.6952 - rmse: 0.8776 - sae: 2575.1599 - sse: 3154.4568\n","Epoch 231: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 8.6710e-19 - r2_keras: -82.6532 - rmse: 0.8663 - sae: 1881.5773 - sse: 2288.9675 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 4.2139e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5622 - learning_rate: 1.0000e-05\n","Epoch 232/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 5.1210e-16 - r2_keras: -100.6954 - rmse: 0.8776 - sae: 2575.1616 - sse: 3154.4636\n","Epoch 232: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.3243e-16 - r2_keras: -82.6534 - rmse: 0.8663 - sae: 1881.5785 - sse: 2288.9727 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6473 - val_sse: 506.5631 - learning_rate: 1.0000e-05\n","Epoch 233/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -5.1385e-16 - r2_keras: -100.6956 - rmse: 0.8776 - sae: 2575.1641 - sse: 3154.4714\n","Epoch 233: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.4681e-16 - r2_keras: -82.6536 - rmse: 0.8663 - sae: 1881.5802 - sse: 2288.9783 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6464 - val_sse: 506.5617 - learning_rate: 1.0000e-05\n","Epoch 234/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -4.0390e-16 - r2_keras: -100.6957 - rmse: 0.8776 - sae: 2575.1646 - sse: 3154.4731\n","Epoch 234: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.3870e-16 - r2_keras: -82.6536 - rmse: 0.8663 - sae: 1881.5807 - sse: 2288.9795 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.7909e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5630 - learning_rate: 1.0000e-05\n","Epoch 235/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -1.5223e-16 - r2_keras: -100.6959 - rmse: 0.8776 - sae: 2575.1665 - sse: 3154.4785\n","Epoch 235: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.3124e-16 - r2_keras: -82.6538 - rmse: 0.8663 - sae: 1881.5822 - sse: 2288.9836 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.3711e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 236/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -1.8285e-16 - r2_keras: -100.6961 - rmse: 0.8776 - sae: 2575.1687 - sse: 3154.4858\n","Epoch 236: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -8.6949e-17 - r2_keras: -82.6540 - rmse: 0.8663 - sae: 1881.5839 - sse: 2288.9893 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.6872e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5628 - learning_rate: 1.0000e-05\n","Epoch 237/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 5.6050e-16 - r2_keras: -100.6964 - rmse: 0.8776 - sae: 2575.1719 - sse: 3154.4941\n","Epoch 237: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.9527e-16 - r2_keras: -82.6542 - rmse: 0.8663 - sae: 1881.5861 - sse: 2288.9951 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.7407e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5639 - learning_rate: 1.0000e-05\n","Epoch 238/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 3.4791e-16 - r2_keras: -100.6966 - rmse: 0.8776 - sae: 2575.1748 - sse: 3154.5024\n","Epoch 238: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.4280e-16 - r2_keras: -82.6544 - rmse: 0.8663 - sae: 1881.5881 - sse: 2289.0010 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2674e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5629 - learning_rate: 1.0000e-05\n","Epoch 239/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 4.3160e-16 - r2_keras: -100.6966 - rmse: 0.8776 - sae: 2575.1746 - sse: 3154.5029\n","Epoch 239: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.8962e-16 - r2_keras: -82.6544 - rmse: 0.8663 - sae: 1881.5880 - sse: 2289.0015 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4813e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 240/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.1493e-16 - r2_keras: -100.6969 - rmse: 0.8776 - sae: 2575.1770 - sse: 3154.5098\n","Epoch 240: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.3856e-16 - r2_keras: -82.6547 - rmse: 0.8663 - sae: 1881.5898 - sse: 2289.0066 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6465 - val_sse: 506.5631 - learning_rate: 1.0000e-05\n","Epoch 241/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -7.0281e-17 - r2_keras: -100.6970 - rmse: 0.8776 - sae: 2575.1782 - sse: 3154.5146\n","Epoch 241: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -5.0160e-17 - r2_keras: -82.6548 - rmse: 0.8663 - sae: 1881.5907 - sse: 2289.0100 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6464 - val_sse: 506.5631 - learning_rate: 1.0000e-05\n","Epoch 242/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.4234e-16 - r2_keras: -100.6972 - rmse: 0.8776 - sae: 2575.1799 - sse: 3154.5200\n","Epoch 242: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.1918e-16 - r2_keras: -82.6550 - rmse: 0.8663 - sae: 1881.5920 - sse: 2289.0144 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.5802e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5641 - learning_rate: 1.0000e-05\n","Epoch 243/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 1.1986e-16 - r2_keras: -100.6974 - rmse: 0.8776 - sae: 2575.1826 - sse: 3154.5273\n","Epoch 243: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 6.2902e-17 - r2_keras: -82.6552 - rmse: 0.8663 - sae: 1881.5941 - sse: 2289.0198 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.2139e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6465 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 244/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -4.7242e-16 - r2_keras: -100.6976 - rmse: 0.8776 - sae: 2575.1841 - sse: 3154.5322\n","Epoch 244: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.5922e-16 - r2_keras: -82.6553 - rmse: 0.8663 - sae: 1881.5951 - sse: 2289.0232 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.7909e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6469 - val_sse: 506.5641 - learning_rate: 1.0000e-05\n","Epoch 245/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.8637e-16 - r2_keras: -100.6978 - rmse: 0.8776 - sae: 2575.1863 - sse: 3154.5376\n","Epoch 245: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.8477e-16 - r2_keras: -82.6554 - rmse: 0.8663 - sae: 1881.5968 - sse: 2289.0273 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6462 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 246/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.1492e-16 - r2_keras: -100.6980 - rmse: 0.8776 - sae: 2575.1882 - sse: 3154.5449\n","Epoch 246: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.3903e-16 - r2_keras: -82.6556 - rmse: 0.8663 - sae: 1881.5981 - sse: 2289.0325 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6467 - val_sse: 506.5645 - learning_rate: 1.0000e-05\n","Epoch 247/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 1.3035e-16 - r2_keras: -100.6982 - rmse: 0.8776 - sae: 2575.1904 - sse: 3154.5503\n","Epoch 247: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 6.1871e-17 - r2_keras: -82.6558 - rmse: 0.8663 - sae: 1881.5997 - sse: 2289.0366 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6472 - val_sse: 506.5654 - learning_rate: 1.0000e-05\n","Epoch 248/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 1.1169e-16 - r2_keras: -100.6984 - rmse: 0.8776 - sae: 2575.1929 - sse: 3154.5571\n","Epoch 248: val_loss improved from 0.19069 to 0.19069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.2508e-17 - r2_keras: -82.6560 - rmse: 0.8663 - sae: 1881.6016 - sse: 2289.0417 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.6337e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5645 - learning_rate: 1.0000e-05\n","Epoch 249/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -4.3713e-16 - r2_keras: -100.6983 - rmse: 0.8776 - sae: 2575.1917 - sse: 3154.5542\n","Epoch 249: val_loss did not improve from 0.19069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.0228e-16 - r2_keras: -82.6559 - rmse: 0.8663 - sae: 1881.6006 - sse: 2289.0393 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -8.4278e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5641 - learning_rate: 1.0000e-05\n","Epoch 250/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 4.0243e-16 - r2_keras: -100.6984 - rmse: 0.8776 - sae: 2575.1934 - sse: 3154.5586\n","Epoch 250: val_loss improved from 0.19069 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 3.1882e-16 - r2_keras: -82.6560 - rmse: 0.8663 - sae: 1881.6019 - sse: 2289.0427 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -9.4813e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6461 - val_sse: 506.5637 - learning_rate: 1.0000e-05\n","Epoch 251/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -3.3186e-16 - r2_keras: -100.6987 - rmse: 0.8776 - sae: 2575.1953 - sse: 3154.5652\n","Epoch 251: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.1227e-16 - r2_keras: -82.6562 - rmse: 0.8663 - sae: 1881.6034 - sse: 2289.0474 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.5818e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6468 - val_sse: 506.5651 - learning_rate: 1.0000e-05\n","Epoch 252/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -7.9027e-17 - r2_keras: -100.6989 - rmse: 0.8776 - sae: 2575.1980 - sse: 3154.5728\n","Epoch 252: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -8.0549e-17 - r2_keras: -82.6564 - rmse: 0.8663 - sae: 1881.6053 - sse: 2289.0530 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6470 - val_sse: 506.5655 - learning_rate: 1.0000e-05\n","Epoch 253/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.5516e-16 - r2_keras: -100.6991 - rmse: 0.8776 - sae: 2575.2002 - sse: 3154.5784\n","Epoch 253: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 2.1403e-16 - r2_keras: -82.6565 - rmse: 0.8663 - sae: 1881.6069 - sse: 2289.0571 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -8.4278e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6463 - val_sse: 506.5644 - learning_rate: 1.0000e-05\n","Epoch 254/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.3329e-17 - r2_keras: -100.6990 - rmse: 0.8776 - sae: 2575.1990 - sse: 3154.5747\n","Epoch 254: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 4.1528e-17 - r2_keras: -82.6564 - rmse: 0.8663 - sae: 1881.6060 - sse: 2289.0544 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5647 - learning_rate: 1.0000e-05\n","Epoch 255/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 3.0182e-16 - r2_keras: -100.6993 - rmse: 0.8776 - sae: 2575.2021 - sse: 3154.5845\n","Epoch 255: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.8138e-16 - r2_keras: -82.6567 - rmse: 0.8663 - sae: 1881.6083 - sse: 2289.0615 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.2123e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6457 - val_sse: 506.5633 - learning_rate: 1.0000e-05\n","Epoch 256/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.1142e-16 - r2_keras: -100.6993 - rmse: 0.8776 - sae: 2575.2026 - sse: 3154.5864\n","Epoch 256: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.5842e-16 - r2_keras: -82.6567 - rmse: 0.8663 - sae: 1881.6086 - sse: 2289.0630 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6463 - val_sse: 506.5647 - learning_rate: 1.0000e-05\n","Epoch 257/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -1.3881e-16 - r2_keras: -100.6996 - rmse: 0.8776 - sae: 2575.2051 - sse: 3154.5930\n","Epoch 257: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -9.0177e-17 - r2_keras: -82.6569 - rmse: 0.8663 - sae: 1881.6105 - sse: 2289.0679 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6466 - val_sse: 506.5649 - learning_rate: 1.0000e-05\n","Epoch 258/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -4.0184e-16 - r2_keras: -100.6995 - rmse: 0.8776 - sae: 2575.2041 - sse: 3154.5901\n","Epoch 258: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -3.6140e-16 - r2_keras: -82.6568 - rmse: 0.8663 - sae: 1881.6097 - sse: 2289.0657 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6458 - val_sse: 506.5638 - learning_rate: 1.0000e-05\n","Epoch 259/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -4.4617e-17 - r2_keras: -100.6997 - rmse: 0.8776 - sae: 2575.2061 - sse: 3154.5962\n","Epoch 259: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -5.3358e-17 - r2_keras: -82.6570 - rmse: 0.8663 - sae: 1881.6112 - sse: 2289.0701 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6461 - val_sse: 506.5646 - learning_rate: 1.0000e-05\n","Epoch 260/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.6916e-16 - r2_keras: -100.6999 - rmse: 0.8776 - sae: 2575.2085 - sse: 3154.6030\n","Epoch 260: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.4213e-16 - r2_keras: -82.6572 - rmse: 0.8663 - sae: 1881.6129 - sse: 2289.0752 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6456 - val_sse: 506.5635 - learning_rate: 1.0000e-05\n","Epoch 261/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -4.1234e-16 - r2_keras: -100.7000 - rmse: 0.8776 - sae: 2575.2100 - sse: 3154.6064\n","Epoch 261: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -2.2814e-16 - r2_keras: -82.6573 - rmse: 0.8663 - sae: 1881.6139 - sse: 2289.0774 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.1604e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6458 - val_sse: 506.5642 - learning_rate: 1.0000e-05\n","Epoch 262/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 8.3400e-17 - r2_keras: -100.7002 - rmse: 0.8776 - sae: 2575.2119 - sse: 3154.6128\n","Epoch 262: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 7.4287e-18 - r2_keras: -82.6575 - rmse: 0.8663 - sae: 1881.6155 - sse: 2289.0825 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4813e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6459 - val_sse: 506.5644 - learning_rate: 1.0000e-05\n","Epoch 263/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.7207e-16 - r2_keras: -100.7001 - rmse: 0.8776 - sae: 2575.2112 - sse: 3154.6101\n","Epoch 263: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.7808e-16 - r2_keras: -82.6574 - rmse: 0.8663 - sae: 1881.6150 - sse: 2289.0803 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 8.4279e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6454 - val_sse: 506.5637 - learning_rate: 1.0000e-05\n","Epoch 264/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -7.9026e-17 - r2_keras: -100.7004 - rmse: 0.8776 - sae: 2575.2136 - sse: 3154.6179\n","Epoch 264: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.1313e-16 - r2_keras: -82.6576 - rmse: 0.8663 - sae: 1881.6166 - sse: 2289.0859 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6459 - val_sse: 506.5648 - learning_rate: 1.0000e-05\n","Epoch 265/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.5895e-16 - r2_keras: -100.7005 - rmse: 0.8776 - sae: 2575.2158 - sse: 3154.6235\n","Epoch 265: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.0463e-16 - r2_keras: -82.6578 - rmse: 0.8663 - sae: 1881.6183 - sse: 2289.0901 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.2123e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6457 - val_sse: 506.5641 - learning_rate: 1.0000e-05\n","Epoch 266/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -1.1635e-16 - r2_keras: -100.7008 - rmse: 0.8776 - sae: 2575.2190 - sse: 3154.6323\n","Epoch 266: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -1.5644e-16 - r2_keras: -82.6580 - rmse: 0.8663 - sae: 1881.6205 - sse: 2289.0964 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.3177e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6453 - val_sse: 506.5633 - learning_rate: 1.0000e-05\n","Epoch 267/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.2162e-16 - r2_keras: -100.7006 - rmse: 0.8776 - sae: 2575.2158 - sse: 3154.6243\n","Epoch 267: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: 1.1516e-16 - r2_keras: -82.6578 - rmse: 0.8663 - sae: 1881.6183 - sse: 2289.0906 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 8.4279e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6456 - val_sse: 506.5642 - learning_rate: 1.0000e-05\n","Epoch 268/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -5.0740e-17 - r2_keras: -100.7008 - rmse: 0.8776 - sae: 2575.2188 - sse: 3154.6326\n","Epoch 268: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1281 - pearson_correlation: -7.6779e-19 - r2_keras: -82.6580 - rmse: 0.8663 - sae: 1881.6205 - sse: 2289.0967 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.0551e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6452 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 269/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 7.5468e-16 - r2_keras: -100.7010 - rmse: 0.8776 - sae: 2575.2205 - sse: 3154.6377\n","Epoch 269: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 5.0595e-16 - r2_keras: -82.6581 - rmse: 0.8663 - sae: 1881.6217 - sse: 2289.1003 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6456 - val_sse: 506.5646 - learning_rate: 1.0000e-05\n","Epoch 270/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 8.9581e-16 - r2_keras: -100.7012 - rmse: 0.8776 - sae: 2575.2231 - sse: 3154.6455\n","Epoch 270: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 5.8965e-16 - r2_keras: -82.6583 - rmse: 0.8663 - sae: 1881.6237 - sse: 2289.1062 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2674e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6447 - val_sse: 506.5634 - learning_rate: 1.0000e-05\n","Epoch 271/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -9.6521e-17 - r2_keras: -100.7014 - rmse: 0.8776 - sae: 2575.2244 - sse: 3154.6504\n","Epoch 271: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: -6.4347e-17 - r2_keras: -82.6585 - rmse: 0.8663 - sae: 1881.6246 - sse: 2289.1096 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6455 - val_sse: 506.5642 - learning_rate: 1.0000e-05\n","Epoch 272/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 8.5586e-16 - r2_keras: -100.7014 - rmse: 0.8776 - sae: 2575.2246 - sse: 3154.6494\n","Epoch 272: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 5.7482e-16 - r2_keras: -82.6584 - rmse: 0.8663 - sae: 1881.6246 - sse: 2289.1089 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.6337e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6451 - val_sse: 506.5638 - learning_rate: 1.0000e-05\n","Epoch 273/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 5.9516e-16 - r2_keras: -100.7015 - rmse: 0.8776 - sae: 2575.2261 - sse: 3154.6533\n","Epoch 273: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 4.6950e-16 - r2_keras: -82.6586 - rmse: 0.8663 - sae: 1881.6259 - sse: 2289.1121 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3744e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6449 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 274/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -6.1295e-16 - r2_keras: -100.7017 - rmse: 0.8776 - sae: 2575.2280 - sse: 3154.6592\n","Epoch 274: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: -4.3933e-16 - r2_keras: -82.6587 - rmse: 0.8663 - sae: 1881.6271 - sse: 2289.1160 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3744e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6449 - val_sse: 506.5639 - learning_rate: 1.0000e-05\n","Epoch 275/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 2.9685e-16 - r2_keras: -100.7019 - rmse: 0.8776 - sae: 2575.2300 - sse: 3154.6655\n","Epoch 275: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 1.8279e-16 - r2_keras: -82.6589 - rmse: 0.8663 - sae: 1881.6288 - sse: 2289.1208 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6445 - val_sse: 506.5630 - learning_rate: 1.0000e-05\n","Epoch 276/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -3.6188e-16 - r2_keras: -100.7018 - rmse: 0.8776 - sae: 2575.2288 - sse: 3154.6628\n","Epoch 276: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: -1.7797e-16 - r2_keras: -82.6588 - rmse: 0.8663 - sae: 1881.6277 - sse: 2289.1187 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6446 - val_sse: 506.5631 - learning_rate: 1.0000e-05\n","Epoch 277/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 8.1649e-17 - r2_keras: -100.7021 - rmse: 0.8776 - sae: 2575.2324 - sse: 3154.6724\n","Epoch 277: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 1.1677e-16 - r2_keras: -82.6591 - rmse: 0.8663 - sae: 1881.6304 - sse: 2289.1257 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 5.2674e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6454 - val_sse: 506.5648 - learning_rate: 1.0000e-05\n","Epoch 278/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 3.7762e-16 - r2_keras: -100.7023 - rmse: 0.8776 - sae: 2575.2349 - sse: 3154.6780\n","Epoch 278: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 2.6403e-16 - r2_keras: -82.6592 - rmse: 0.8663 - sae: 1881.6322 - sse: 2289.1299 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6445 - val_sse: 506.5633 - learning_rate: 1.0000e-05\n","Epoch 279/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: -2.4349e-16 - r2_keras: -100.7024 - rmse: 0.8776 - sae: 2575.2351 - sse: 3154.6799\n","Epoch 279: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: -2.3741e-16 - r2_keras: -82.6593 - rmse: 0.8663 - sae: 1881.6323 - sse: 2289.1313 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -6.3209e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6447 - val_sse: 506.5634 - learning_rate: 1.0000e-05\n","Epoch 280/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 1.2510e-16 - r2_keras: -100.7023 - rmse: 0.8776 - sae: 2575.2344 - sse: 3154.6782\n","Epoch 280: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 1.3724e-16 - r2_keras: -82.6592 - rmse: 0.8663 - sae: 1881.6320 - sse: 2289.1301 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 5.2674e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6440 - val_sse: 506.5627 - learning_rate: 1.0000e-05\n","Epoch 281/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2267 - mse: 0.1387 - pearson_correlation: 3.6829e-16 - r2_keras: -100.7025 - rmse: 0.8776 - sae: 2575.2361 - sse: 3154.6843\n","Epoch 281: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 2.1766e-16 - r2_keras: -82.6594 - rmse: 0.8663 - sae: 1881.6331 - sse: 2289.1343 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6446 - val_sse: 506.5638 - learning_rate: 1.0000e-05\n","Epoch 282/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.5870e-16 - r2_keras: -100.7027 - rmse: 0.8776 - sae: 2575.2385 - sse: 3154.6909\n","Epoch 282: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 3.5877e-16 - r2_keras: -82.6596 - rmse: 0.8663 - sae: 1881.6349 - sse: 2289.1394 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6446 - val_sse: 506.5640 - learning_rate: 1.0000e-05\n","Epoch 283/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.1759e-16 - r2_keras: -100.7029 - rmse: 0.8776 - sae: 2575.2402 - sse: 3154.6953\n","Epoch 283: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2178 - mse: 0.1280 - pearson_correlation: 3.5592e-16 - r2_keras: -82.6597 - rmse: 0.8663 - sae: 1881.6362 - sse: 2289.1428 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6438 - val_sse: 506.5627 - learning_rate: 1.0000e-05\n","Epoch 284/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 9.6227e-17 - r2_keras: -100.7031 - rmse: 0.8776 - sae: 2575.2424 - sse: 3154.7021\n","Epoch 284: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.3927e-17 - r2_keras: -82.6599 - rmse: 0.8663 - sae: 1881.6378 - sse: 2289.1475 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6441 - val_sse: 506.5629 - learning_rate: 1.0000e-05\n","Epoch 285/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.3299e-16 - r2_keras: -100.7029 - rmse: 0.8776 - sae: 2575.2412 - sse: 3154.6980\n","Epoch 285: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.1436e-16 - r2_keras: -82.6598 - rmse: 0.8663 - sae: 1881.6368 - sse: 2289.1445 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6437 - val_sse: 506.5626 - learning_rate: 1.0000e-05\n","Epoch 286/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.3619e-17 - r2_keras: -100.7032 - rmse: 0.8776 - sae: 2575.2434 - sse: 3154.7056\n","Epoch 286: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -4.2665e-17 - r2_keras: -82.6600 - rmse: 0.8663 - sae: 1881.6384 - sse: 2289.1499 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.5819e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6442 - val_sse: 506.5637 - learning_rate: 1.0000e-05\n","Epoch 287/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.4786e-16 - r2_keras: -100.7034 - rmse: 0.8776 - sae: 2575.2454 - sse: 3154.7114\n","Epoch 287: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 6.5594e-17 - r2_keras: -82.6601 - rmse: 0.8663 - sae: 1881.6399 - sse: 2289.1543 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.2123e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6443 - val_sse: 506.5639 - learning_rate: 1.0000e-05\n","Epoch 288/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.4148e-16 - r2_keras: -100.7036 - rmse: 0.8776 - sae: 2575.2476 - sse: 3154.7180\n","Epoch 288: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.6976e-16 - r2_keras: -82.6603 - rmse: 0.8663 - sae: 1881.6416 - sse: 2289.1592 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.7909e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6439 - val_sse: 506.5630 - learning_rate: 1.0000e-05\n","Epoch 289/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.9136e-16 - r2_keras: -100.7035 - rmse: 0.8776 - sae: 2575.2466 - sse: 3154.7151\n","Epoch 289: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.1029e-16 - r2_keras: -82.6602 - rmse: 0.8663 - sae: 1881.6407 - sse: 2289.1567 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6435 - val_sse: 506.5624 - learning_rate: 1.0000e-05\n","Epoch 290/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.8341e-16 - r2_keras: -100.7037 - rmse: 0.8776 - sae: 2575.2488 - sse: 3154.7207\n","Epoch 290: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.0858e-16 - r2_keras: -82.6604 - rmse: 0.8663 - sae: 1881.6423 - sse: 2289.1611 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.1605e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6434 - val_sse: 506.5625 - learning_rate: 1.0000e-05\n","Epoch 291/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -6.9983e-18 - r2_keras: -100.7038 - rmse: 0.8776 - sae: 2575.2502 - sse: 3154.7261\n","Epoch 291: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.1615e-17 - r2_keras: -82.6605 - rmse: 0.8663 - sae: 1881.6434 - sse: 2289.1650 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6436 - val_sse: 506.5632 - learning_rate: 1.0000e-05\n","Epoch 292/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -8.5729e-17 - r2_keras: -100.7041 - rmse: 0.8776 - sae: 2575.2529 - sse: 3154.7336\n","Epoch 292: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -6.8486e-17 - r2_keras: -82.6607 - rmse: 0.8663 - sae: 1881.6455 - sse: 2289.1707 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6440 - val_sse: 506.5635 - learning_rate: 1.0000e-05\n","Epoch 293/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.2429e-16 - r2_keras: -100.7039 - rmse: 0.8776 - sae: 2575.2510 - sse: 3154.7273\n","Epoch 293: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.6275e-16 - r2_keras: -82.6606 - rmse: 0.8663 - sae: 1881.6440 - sse: 2289.1660 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.8444e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6435 - val_sse: 506.5629 - learning_rate: 1.0000e-05\n","Epoch 294/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -7.8264e-16 - r2_keras: -100.7042 - rmse: 0.8776 - sae: 2575.2544 - sse: 3154.7368\n","Epoch 294: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -4.3250e-16 - r2_keras: -82.6608 - rmse: 0.8663 - sae: 1881.6464 - sse: 2289.1726 - val_huber_loss: 0.1022 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6438 - val_sse: 506.5636 - learning_rate: 1.0000e-05\n","Epoch 295/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.0118e-16 - r2_keras: -100.7043 - rmse: 0.8776 - sae: 2575.2561 - sse: 3154.7417\n","Epoch 295: val_loss improved from 0.19068 to 0.19068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -6.0844e-17 - r2_keras: -82.6609 - rmse: 0.8663 - sae: 1881.6477 - sse: 2289.1765 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.5819e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6429 - val_sse: 506.5620 - learning_rate: 1.0000e-05\n","Epoch 296/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 6.8553e-16 - r2_keras: -100.7044 - rmse: 0.8776 - sae: 2575.2563 - sse: 3154.7437\n","Epoch 296: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.9197e-16 - r2_keras: -82.6610 - rmse: 0.8663 - sae: 1881.6481 - sse: 2289.1780 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6431 - val_sse: 506.5628 - learning_rate: 1.0000e-05\n","Epoch 297/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.2339e-16 - r2_keras: -100.7046 - rmse: 0.8776 - sae: 2575.2578 - sse: 3154.7480\n","Epoch 297: val_loss did not improve from 0.19068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.8321e-16 - r2_keras: -82.6611 - rmse: 0.8663 - sae: 1881.6492 - sse: 2289.1814 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.8979e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6437 - val_sse: 506.5633 - learning_rate: 1.0000e-05\n","Epoch 298/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -3.0151e-16 - r2_keras: -100.7045 - rmse: 0.8776 - sae: 2575.2581 - sse: 3154.7468\n","Epoch 298: val_loss improved from 0.19068 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.4681e-16 - r2_keras: -82.6611 - rmse: 0.8663 - sae: 1881.6492 - sse: 2289.1804 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3744e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6434 - val_sse: 506.5629 - learning_rate: 1.0000e-05\n","Epoch 299/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -9.0393e-18 - r2_keras: -100.7047 - rmse: 0.8776 - sae: 2575.2603 - sse: 3154.7537\n","Epoch 299: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -8.4418e-17 - r2_keras: -82.6613 - rmse: 0.8663 - sae: 1881.6508 - sse: 2289.1853 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -5.2674e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6435 - val_sse: 506.5635 - learning_rate: 1.0000e-05\n","Epoch 300/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.9072e-16 - r2_keras: -100.7049 - rmse: 0.8776 - sae: 2575.2625 - sse: 3154.7603\n","Epoch 300: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.5945e-16 - r2_keras: -82.6614 - rmse: 0.8663 - sae: 1881.6525 - sse: 2289.1902 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6424 - val_sse: 506.5617 - learning_rate: 1.0000e-05\n","Epoch 301/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -8.8060e-16 - r2_keras: -100.7050 - rmse: 0.8776 - sae: 2575.2625 - sse: 3154.7622\n","Epoch 301: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -5.5968e-16 - r2_keras: -82.6615 - rmse: 0.8663 - sae: 1881.6525 - sse: 2289.1917 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6428 - val_sse: 506.5620 - learning_rate: 1.0000e-05\n","Epoch 302/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -5.1174e-16 - r2_keras: -100.7048 - rmse: 0.8776 - sae: 2575.2607 - sse: 3154.7559\n","Epoch 302: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.9819e-16 - r2_keras: -82.6613 - rmse: 0.8663 - sae: 1881.6512 - sse: 2289.1873 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6436 - val_sse: 506.5635 - learning_rate: 1.0000e-05\n","Epoch 303/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 8.3220e-16 - r2_keras: -100.7051 - rmse: 0.8776 - sae: 2575.2646 - sse: 3154.7656\n","Epoch 303: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 6.1288e-16 - r2_keras: -82.6616 - rmse: 0.8663 - sae: 1881.6541 - sse: 2289.1941 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6428 - val_sse: 506.5623 - learning_rate: 1.0000e-05\n","Epoch 304/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.2572e-16 - r2_keras: -100.7053 - rmse: 0.8776 - sae: 2575.2659 - sse: 3154.7708\n","Epoch 304: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.6020e-16 - r2_keras: -82.6617 - rmse: 0.8663 - sae: 1881.6550 - sse: 2289.1980 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -6.3209e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6429 - val_sse: 506.5629 - learning_rate: 1.0000e-05\n","Epoch 305/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.5017e-16 - r2_keras: -100.7055 - rmse: 0.8776 - sae: 2575.2676 - sse: 3154.7761\n","Epoch 305: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -7.4139e-17 - r2_keras: -82.6619 - rmse: 0.8663 - sae: 1881.6562 - sse: 2289.2019 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.5300e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6421 - val_sse: 506.5616 - learning_rate: 1.0000e-05\n","Epoch 306/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.5601e-16 - r2_keras: -100.7056 - rmse: 0.8776 - sae: 2575.2686 - sse: 3154.7793\n","Epoch 306: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.1590e-16 - r2_keras: -82.6620 - rmse: 0.8663 - sae: 1881.6570 - sse: 2289.2043 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6429 - val_sse: 506.5624 - learning_rate: 1.0000e-05\n","Epoch 307/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.8841e-16 - r2_keras: -100.7055 - rmse: 0.8776 - sae: 2575.2686 - sse: 3154.7773\n","Epoch 307: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.6953e-16 - r2_keras: -82.6619 - rmse: 0.8663 - sae: 1881.6569 - sse: 2289.2029 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.8444e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6430 - val_sse: 506.5632 - learning_rate: 1.0000e-05\n","Epoch 308/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.0153e-17 - r2_keras: -100.7057 - rmse: 0.8776 - sae: 2575.2705 - sse: 3154.7834\n","Epoch 308: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.3233e-17 - r2_keras: -82.6621 - rmse: 0.8663 - sae: 1881.6583 - sse: 2289.2073 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.4230e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6423 - val_sse: 506.5620 - learning_rate: 1.0000e-05\n","Epoch 309/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -3.5020e-16 - r2_keras: -100.7058 - rmse: 0.8776 - sae: 2575.2715 - sse: 3154.7871\n","Epoch 309: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.9485e-16 - r2_keras: -82.6622 - rmse: 0.8663 - sae: 1881.6592 - sse: 2289.2100 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.5284e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6425 - val_sse: 506.5626 - learning_rate: 1.0000e-05\n","Epoch 310/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.7033e-16 - r2_keras: -100.7060 - rmse: 0.8776 - sae: 2575.2739 - sse: 3154.7944\n","Epoch 310: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.9266e-16 - r2_keras: -82.6624 - rmse: 0.8663 - sae: 1881.6610 - sse: 2289.2153 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 6.3209e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6427 - val_sse: 506.5626 - learning_rate: 1.0000e-05\n","Epoch 311/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.3619e-16 - r2_keras: -100.7060 - rmse: 0.8776 - sae: 2575.2737 - sse: 3154.7930\n","Epoch 311: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.6312e-16 - r2_keras: -82.6623 - rmse: 0.8663 - sae: 1881.6606 - sse: 2289.2141 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 4.0033e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6428 - val_sse: 506.5629 - learning_rate: 1.0000e-05\n","Epoch 312/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 3.4232e-16 - r2_keras: -100.7062 - rmse: 0.8776 - sae: 2575.2759 - sse: 3154.7983\n","Epoch 312: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.0696e-16 - r2_keras: -82.6625 - rmse: 0.8663 - sae: 1881.6624 - sse: 2289.2183 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.3695e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6417 - val_sse: 506.5612 - learning_rate: 1.0000e-05\n","Epoch 313/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -3.6040e-16 - r2_keras: -100.7063 - rmse: 0.8776 - sae: 2575.2761 - sse: 3154.8010\n","Epoch 313: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.0721e-16 - r2_keras: -82.6626 - rmse: 0.8663 - sae: 1881.6625 - sse: 2289.2200 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.0551e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6421 - val_sse: 506.5616 - learning_rate: 1.0000e-05\n","Epoch 314/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.3009e-16 - r2_keras: -100.7065 - rmse: 0.8776 - sae: 2575.2788 - sse: 3154.8076\n","Epoch 314: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.1317e-16 - r2_keras: -82.6627 - rmse: 0.8663 - sae: 1881.6644 - sse: 2289.2249 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6422 - val_sse: 506.5625 - learning_rate: 1.0000e-05\n","Epoch 315/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.1755e-16 - r2_keras: -100.7067 - rmse: 0.8776 - sae: 2575.2808 - sse: 3154.8145\n","Epoch 315: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.3162e-16 - r2_keras: -82.6629 - rmse: 0.8663 - sae: 1881.6660 - sse: 2289.2302 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6424 - val_sse: 506.5625 - learning_rate: 1.0000e-05\n","Epoch 316/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 1.5512e-16 - r2_keras: -100.7066 - rmse: 0.8776 - sae: 2575.2798 - sse: 3154.8105\n","Epoch 316: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 9.1610e-17 - r2_keras: -82.6628 - rmse: 0.8663 - sae: 1881.6652 - sse: 2289.2271 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.7391e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6424 - val_sse: 506.5626 - learning_rate: 1.0000e-05\n","Epoch 317/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.7820e-16 - r2_keras: -100.7068 - rmse: 0.8776 - sae: 2575.2822 - sse: 3154.8164\n","Epoch 317: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.2069e-16 - r2_keras: -82.6630 - rmse: 0.8663 - sae: 1881.6670 - sse: 2289.2317 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.7391e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6413 - val_sse: 506.5609 - learning_rate: 1.0000e-05\n","Epoch 318/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.3209e-16 - r2_keras: -100.7068 - rmse: 0.8776 - sae: 2575.2817 - sse: 3154.8167\n","Epoch 318: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -9.6558e-17 - r2_keras: -82.6630 - rmse: 0.8663 - sae: 1881.6666 - sse: 2289.2317 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6417 - val_sse: 506.5617 - learning_rate: 1.0000e-05\n","Epoch 319/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 3.8489e-17 - r2_keras: -100.7071 - rmse: 0.8776 - sae: 2575.2852 - sse: 3154.8257\n","Epoch 319: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.3132e-17 - r2_keras: -82.6632 - rmse: 0.8663 - sae: 1881.6691 - sse: 2289.2383 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.7909e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6423 - val_sse: 506.5628 - learning_rate: 1.0000e-05\n","Epoch 320/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.6242e-17 - r2_keras: -100.7072 - rmse: 0.8776 - sae: 2575.2871 - sse: 3154.8311\n","Epoch 320: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 7.3690e-17 - r2_keras: -82.6634 - rmse: 0.8663 - sae: 1881.6707 - sse: 2289.2424 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6420 - val_sse: 506.5622 - learning_rate: 1.0000e-05\n","Epoch 321/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 8.5084e-16 - r2_keras: -100.7071 - rmse: 0.8776 - sae: 2575.2847 - sse: 3154.8257\n","Epoch 321: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 5.4314e-16 - r2_keras: -82.6632 - rmse: 0.8663 - sae: 1881.6688 - sse: 2289.2383 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.0016e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6421 - val_sse: 506.5624 - learning_rate: 1.0000e-05\n","Epoch 322/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -5.0210e-16 - r2_keras: -100.7073 - rmse: 0.8776 - sae: 2575.2871 - sse: 3154.8325\n","Epoch 322: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.0357e-16 - r2_keras: -82.6634 - rmse: 0.8663 - sae: 1881.6707 - sse: 2289.2434 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6408 - val_sse: 506.5606 - learning_rate: 1.0000e-05\n","Epoch 323/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.7058e-16 - r2_keras: -100.7073 - rmse: 0.8776 - sae: 2575.2871 - sse: 3154.8340\n","Epoch 323: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.4158e-16 - r2_keras: -82.6635 - rmse: 0.8663 - sae: 1881.6708 - sse: 2289.2446 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6418 - val_sse: 506.5622 - learning_rate: 1.0000e-05\n","Epoch 324/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 1.7203e-17 - r2_keras: -100.7076 - rmse: 0.8776 - sae: 2575.2910 - sse: 3154.8433\n","Epoch 324: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.3191e-17 - r2_keras: -82.6637 - rmse: 0.8663 - sae: 1881.6735 - sse: 2289.2512 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6419 - val_sse: 506.5620 - learning_rate: 1.0000e-05\n","Epoch 325/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.3996e-17 - r2_keras: -100.7075 - rmse: 0.8776 - sae: 2575.2896 - sse: 3154.8381\n","Epoch 325: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.3581e-17 - r2_keras: -82.6636 - rmse: 0.8663 - sae: 1881.6725 - sse: 2289.2476 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6413 - val_sse: 506.5615 - learning_rate: 1.0000e-05\n","Epoch 326/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.0030e-16 - r2_keras: -100.7077 - rmse: 0.8776 - sae: 2575.2915 - sse: 3154.8452\n","Epoch 326: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.0240e-16 - r2_keras: -82.6638 - rmse: 0.8663 - sae: 1881.6738 - sse: 2289.2527 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4814e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6414 - val_sse: 506.5616 - learning_rate: 1.0000e-05\n","Epoch 327/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 1.6445e-16 - r2_keras: -100.7079 - rmse: 0.8776 - sae: 2575.2937 - sse: 3154.8511\n","Epoch 327: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.3147e-16 - r2_keras: -82.6639 - rmse: 0.8663 - sae: 1881.6754 - sse: 2289.2571 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.7391e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6415 - val_sse: 506.5619 - learning_rate: 1.0000e-05\n","Epoch 328/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.6563e-16 - r2_keras: -100.7081 - rmse: 0.8776 - sae: 2575.2959 - sse: 3154.8574\n","Epoch 328: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.0353e-16 - r2_keras: -82.6641 - rmse: 0.8663 - sae: 1881.6771 - sse: 2289.2615 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.5802e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6410 - val_sse: 506.5610 - learning_rate: 1.0000e-05\n","Epoch 329/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.0559e-16 - r2_keras: -100.7078 - rmse: 0.8776 - sae: 2575.2932 - sse: 3154.8501\n","Epoch 329: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.8456e-16 - r2_keras: -82.6639 - rmse: 0.8663 - sae: 1881.6752 - sse: 2289.2563 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.7391e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6413 - val_sse: 506.5616 - learning_rate: 1.0000e-05\n","Epoch 330/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 6.6393e-16 - r2_keras: -100.7080 - rmse: 0.8776 - sae: 2575.2954 - sse: 3154.8564\n","Epoch 330: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.2562e-16 - r2_keras: -82.6641 - rmse: 0.8663 - sae: 1881.6768 - sse: 2289.2610 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 6.3210e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6410 - val_sse: 506.5612 - learning_rate: 1.0000e-05\n","Epoch 331/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -3.4698e-16 - r2_keras: -100.7083 - rmse: 0.8776 - sae: 2575.2983 - sse: 3154.8640\n","Epoch 331: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.4643e-16 - r2_keras: -82.6643 - rmse: 0.8663 - sae: 1881.6788 - sse: 2289.2664 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6415 - val_sse: 506.5623 - learning_rate: 1.0000e-05\n","Epoch 332/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.8548e-16 - r2_keras: -100.7085 - rmse: 0.8776 - sae: 2575.3000 - sse: 3154.8694\n","Epoch 332: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.1704e-16 - r2_keras: -82.6644 - rmse: 0.8663 - sae: 1881.6802 - sse: 2289.2705 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6408 - val_sse: 506.5612 - learning_rate: 1.0000e-05\n","Epoch 333/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.1781e-16 - r2_keras: -100.7086 - rmse: 0.8776 - sae: 2575.3008 - sse: 3154.8728\n","Epoch 333: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.3198e-16 - r2_keras: -82.6645 - rmse: 0.8663 - sae: 1881.6807 - sse: 2289.2729 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 8.4280e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6407 - val_sse: 506.5609 - learning_rate: 1.0000e-05\n","Epoch 334/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.8573e-16 - r2_keras: -100.7084 - rmse: 0.8776 - sae: 2575.2991 - sse: 3154.8682\n","Epoch 334: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.4696e-16 - r2_keras: -82.6644 - rmse: 0.8663 - sae: 1881.6794 - sse: 2289.2695 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6408 - val_sse: 506.5612 - learning_rate: 1.0000e-05\n","Epoch 335/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.8720e-16 - r2_keras: -100.7086 - rmse: 0.8776 - sae: 2575.3010 - sse: 3154.8733\n","Epoch 335: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.8722e-16 - r2_keras: -82.6646 - rmse: 0.8663 - sae: 1881.6809 - sse: 2289.2734 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 8.4280e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6406 - val_sse: 506.5610 - learning_rate: 1.0000e-05\n","Epoch 336/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.7090e-16 - r2_keras: -100.7087 - rmse: 0.8776 - sae: 2575.3025 - sse: 3154.8774\n","Epoch 336: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.4935e-16 - r2_keras: -82.6647 - rmse: 0.8663 - sae: 1881.6820 - sse: 2289.2766 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -9.4815e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6410 - val_sse: 506.5617 - learning_rate: 1.0000e-05\n","Epoch 337/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -5.8023e-17 - r2_keras: -100.7090 - rmse: 0.8776 - sae: 2575.3052 - sse: 3154.8853\n","Epoch 337: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -9.6764e-17 - r2_keras: -82.6649 - rmse: 0.8663 - sae: 1881.6840 - sse: 2289.2822 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 9.4815e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6404 - val_sse: 506.5606 - learning_rate: 1.0000e-05\n","Epoch 338/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.8547e-16 - r2_keras: -100.7089 - rmse: 0.8776 - sae: 2575.3042 - sse: 3154.8821\n","Epoch 338: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.5623e-16 - r2_keras: -82.6648 - rmse: 0.8663 - sae: 1881.6832 - sse: 2289.2798 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6405 - val_sse: 506.5611 - learning_rate: 1.0000e-05\n","Epoch 339/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.5950e-16 - r2_keras: -100.7091 - rmse: 0.8776 - sae: 2575.3066 - sse: 3154.8894\n","Epoch 339: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.8339e-16 - r2_keras: -82.6650 - rmse: 0.8663 - sae: 1881.6849 - sse: 2289.2852 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -8.4280e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6399 - val_sse: 506.5603 - learning_rate: 1.0000e-05\n","Epoch 340/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.1113e-16 - r2_keras: -100.7091 - rmse: 0.8776 - sae: 2575.3066 - sse: 3154.8901\n","Epoch 340: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.3556e-16 - r2_keras: -82.6650 - rmse: 0.8663 - sae: 1881.6851 - sse: 2289.2859 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.6337e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6403 - val_sse: 506.5608 - learning_rate: 1.0000e-05\n","Epoch 341/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.3036e-16 - r2_keras: -100.7093 - rmse: 0.8776 - sae: 2575.3091 - sse: 3154.8962\n","Epoch 341: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.3649e-16 - r2_keras: -82.6652 - rmse: 0.8663 - sae: 1881.6869 - sse: 2289.2905 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6404 - val_sse: 506.5613 - learning_rate: 1.0000e-05\n","Epoch 342/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.9420e-16 - r2_keras: -100.7096 - rmse: 0.8776 - sae: 2575.3118 - sse: 3154.9043\n","Epoch 342: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.7205e-16 - r2_keras: -82.6654 - rmse: 0.8663 - sae: 1881.6888 - sse: 2289.2964 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6402 - val_sse: 506.5608 - learning_rate: 1.0000e-05\n","Epoch 343/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.2596e-16 - r2_keras: -100.7095 - rmse: 0.8776 - sae: 2575.3103 - sse: 3154.9001\n","Epoch 343: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -6.4140e-17 - r2_keras: -82.6653 - rmse: 0.8663 - sae: 1881.6876 - sse: 2289.2930 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 7.3745e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6402 - val_sse: 506.5608 - learning_rate: 1.0000e-05\n","Epoch 344/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 8.5722e-17 - r2_keras: -100.7097 - rmse: 0.8776 - sae: 2575.3125 - sse: 3154.9067\n","Epoch 344: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 8.9731e-17 - r2_keras: -82.6655 - rmse: 0.8663 - sae: 1881.6893 - sse: 2289.2981 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6401 - val_sse: 506.5609 - learning_rate: 1.0000e-05\n","Epoch 345/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.2891e-16 - r2_keras: -100.7098 - rmse: 0.8776 - sae: 2575.3132 - sse: 3154.9094\n","Epoch 345: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.2616e-16 - r2_keras: -82.6655 - rmse: 0.8663 - sae: 1881.6898 - sse: 2289.2998 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6399 - val_sse: 506.5604 - learning_rate: 1.0000e-05\n","Epoch 346/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.0993e-16 - r2_keras: -100.7099 - rmse: 0.8776 - sae: 2575.3149 - sse: 3154.9141\n","Epoch 346: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.1351e-16 - r2_keras: -82.6657 - rmse: 0.8663 - sae: 1881.6912 - sse: 2289.3035 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.3695e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6402 - val_sse: 506.5612 - learning_rate: 1.0000e-05\n","Epoch 347/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.7728e-16 - r2_keras: -100.7101 - rmse: 0.8776 - sae: 2575.3174 - sse: 3154.9211\n","Epoch 347: val_loss improved from 0.19067 to 0.19067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.5218e-16 - r2_keras: -82.6659 - rmse: 0.8663 - sae: 1881.6930 - sse: 2289.3088 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6396 - val_sse: 506.5601 - learning_rate: 1.0000e-05\n","Epoch 348/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 6.1959e-16 - r2_keras: -100.7099 - rmse: 0.8776 - sae: 2575.3149 - sse: 3154.9141\n","Epoch 348: val_loss did not improve from 0.19067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.1201e-16 - r2_keras: -82.6657 - rmse: 0.8663 - sae: 1881.6913 - sse: 2289.3035 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6404 - val_sse: 506.5613 - learning_rate: 1.0000e-05\n","Epoch 349/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.3005e-16 - r2_keras: -100.7102 - rmse: 0.8776 - sae: 2575.3184 - sse: 3154.9229\n","Epoch 349: val_loss improved from 0.19067 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.3401e-16 - r2_keras: -82.6659 - rmse: 0.8663 - sae: 1881.6937 - sse: 2289.3098 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -4.2140e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6397 - val_sse: 506.5605 - learning_rate: 1.0000e-05\n","Epoch 350/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 5.2366e-16 - r2_keras: -100.7104 - rmse: 0.8776 - sae: 2575.3203 - sse: 3154.9287\n","Epoch 350: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.8452e-16 - r2_keras: -82.6661 - rmse: 0.8663 - sae: 1881.6951 - sse: 2289.3142 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -9.4815e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6393 - val_sse: 506.5602 - learning_rate: 1.0000e-05\n","Epoch 351/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.4141e-16 - r2_keras: -100.7105 - rmse: 0.8776 - sae: 2575.3206 - sse: 3154.9312\n","Epoch 351: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.7041e-16 - r2_keras: -82.6661 - rmse: 0.8663 - sae: 1881.6953 - sse: 2289.3162 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 4.2140e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6396 - val_sse: 506.5602 - learning_rate: 1.0000e-05\n","Epoch 352/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -6.8752e-16 - r2_keras: -100.7103 - rmse: 0.8776 - sae: 2575.3188 - sse: 3154.9258\n","Epoch 352: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -4.0263e-16 - r2_keras: -82.6660 - rmse: 0.8663 - sae: 1881.6941 - sse: 2289.3123 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6394 - val_sse: 506.5601 - learning_rate: 1.0000e-05\n","Epoch 353/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -9.1844e-17 - r2_keras: -100.7105 - rmse: 0.8776 - sae: 2575.3213 - sse: 3154.9326\n","Epoch 353: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.6181e-16 - r2_keras: -82.6662 - rmse: 0.8663 - sae: 1881.6958 - sse: 2289.3171 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6397 - val_sse: 506.5605 - learning_rate: 1.0000e-05\n","Epoch 354/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.4637e-16 - r2_keras: -100.7107 - rmse: 0.8776 - sae: 2575.3240 - sse: 3154.9395\n","Epoch 354: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -7.1607e-17 - r2_keras: -82.6664 - rmse: 0.8663 - sae: 1881.6979 - sse: 2289.3220 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.1605e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6391 - val_sse: 506.5599 - learning_rate: 1.0000e-05\n","Epoch 355/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.2977e-16 - r2_keras: -100.7109 - rmse: 0.8776 - sae: 2575.3252 - sse: 3154.9443\n","Epoch 355: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.6102e-16 - r2_keras: -82.6665 - rmse: 0.8663 - sae: 1881.6986 - sse: 2289.3257 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6395 - val_sse: 506.5603 - learning_rate: 1.0000e-05\n","Epoch 356/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -9.1844e-17 - r2_keras: -100.7107 - rmse: 0.8776 - sae: 2575.3235 - sse: 3154.9395\n","Epoch 356: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.2120e-17 - r2_keras: -82.6664 - rmse: 0.8663 - sae: 1881.6975 - sse: 2289.3220 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3745e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6394 - val_sse: 506.5601 - learning_rate: 1.0000e-05\n","Epoch 357/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.8459e-16 - r2_keras: -100.7108 - rmse: 0.8776 - sae: 2575.3250 - sse: 3154.9426\n","Epoch 357: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.5281e-16 - r2_keras: -82.6665 - rmse: 0.8663 - sae: 1881.6986 - sse: 2289.3247 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.5819e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6388 - val_sse: 506.5594 - learning_rate: 1.0000e-05\n","Epoch 358/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -6.4728e-17 - r2_keras: -100.7111 - rmse: 0.8776 - sae: 2575.3267 - sse: 3154.9497\n","Epoch 358: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.4929e-17 - r2_keras: -82.6666 - rmse: 0.8663 - sae: 1881.6998 - sse: 2289.3298 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6391 - val_sse: 506.5603 - learning_rate: 1.0000e-05\n","Epoch 359/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 7.9743e-16 - r2_keras: -100.7113 - rmse: 0.8776 - sae: 2575.3296 - sse: 3154.9565\n","Epoch 359: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.8912e-16 - r2_keras: -82.6668 - rmse: 0.8663 - sae: 1881.7020 - sse: 2289.3347 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6385 - val_sse: 506.5592 - learning_rate: 1.0000e-05\n","Epoch 360/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -2.4579e-16 - r2_keras: -100.7114 - rmse: 0.8776 - sae: 2575.3306 - sse: 3154.9595\n","Epoch 360: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.8039e-16 - r2_keras: -82.6669 - rmse: 0.8663 - sae: 1881.7026 - sse: 2289.3369 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3745e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6392 - val_sse: 506.5602 - learning_rate: 1.0000e-05\n","Epoch 361/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -6.9976e-18 - r2_keras: -100.7113 - rmse: 0.8776 - sae: 2575.3298 - sse: 3154.9563\n","Epoch 361: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.2555e-17 - r2_keras: -82.6668 - rmse: 0.8663 - sae: 1881.7021 - sse: 2289.3347 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 7.3745e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6391 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 362/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 1.6852e-16 - r2_keras: -100.7115 - rmse: 0.8776 - sae: 2575.3318 - sse: 3154.9626\n","Epoch 362: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.5532e-16 - r2_keras: -82.6670 - rmse: 0.8663 - sae: 1881.7035 - sse: 2289.3394 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -3.6873e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6383 - val_sse: 506.5590 - learning_rate: 1.0000e-05\n","Epoch 363/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.1256e-16 - r2_keras: -100.7117 - rmse: 0.8776 - sae: 2575.3335 - sse: 3154.9683\n","Epoch 363: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.0196e-16 - r2_keras: -82.6672 - rmse: 0.8663 - sae: 1881.7047 - sse: 2289.3433 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6386 - val_sse: 506.5597 - learning_rate: 1.0000e-05\n","Epoch 364/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.8398e-16 - r2_keras: -100.7117 - rmse: 0.8776 - sae: 2575.3335 - sse: 3154.9695\n","Epoch 364: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -8.0626e-17 - r2_keras: -82.6672 - rmse: 0.8663 - sae: 1881.7050 - sse: 2289.3445 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -3.7926e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6385 - val_sse: 506.5595 - learning_rate: 1.0000e-05\n","Epoch 365/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 3.4696e-16 - r2_keras: -100.7119 - rmse: 0.8776 - sae: 2575.3354 - sse: 3154.9751\n","Epoch 365: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.3094e-16 - r2_keras: -82.6674 - rmse: 0.8663 - sae: 1881.7064 - sse: 2289.3484 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6387 - val_sse: 506.5597 - learning_rate: 1.0000e-05\n","Epoch 366/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 1.0977e-15 - r2_keras: -100.7119 - rmse: 0.8776 - sae: 2575.3364 - sse: 3154.9753\n","Epoch 366: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 7.8613e-16 - r2_keras: -82.6673 - rmse: 0.8663 - sae: 1881.7069 - sse: 2289.3484 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.6338e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6389 - val_sse: 506.5604 - learning_rate: 1.0000e-05\n","Epoch 367/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.9651e-16 - r2_keras: -100.7121 - rmse: 0.8776 - sae: 2575.3384 - sse: 3154.9824\n","Epoch 367: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.2298e-16 - r2_keras: -82.6675 - rmse: 0.8663 - sae: 1881.7084 - sse: 2289.3538 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6378 - val_sse: 506.5587 - learning_rate: 1.0000e-05\n","Epoch 368/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.3033e-17 - r2_keras: -100.7121 - rmse: 0.8776 - sae: 2575.3384 - sse: 3154.9834\n","Epoch 368: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.6432e-18 - r2_keras: -82.6676 - rmse: 0.8663 - sae: 1881.7085 - sse: 2289.3545 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6382 - val_sse: 506.5594 - learning_rate: 1.0000e-05\n","Epoch 369/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.7233e-17 - r2_keras: -100.7123 - rmse: 0.8776 - sae: 2575.3398 - sse: 3154.9878\n","Epoch 369: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 6.8320e-17 - r2_keras: -82.6677 - rmse: 0.8663 - sae: 1881.7096 - sse: 2289.3579 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -7.3745e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6382 - val_sse: 506.5588 - learning_rate: 1.0000e-05\n","Epoch 370/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -3.7874e-16 - r2_keras: -100.7122 - rmse: 0.8776 - sae: 2575.3398 - sse: 3154.9858\n","Epoch 370: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.0905e-16 - r2_keras: -82.6676 - rmse: 0.8663 - sae: 1881.7095 - sse: 2289.3562 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6384 - val_sse: 506.5595 - learning_rate: 1.0000e-05\n","Epoch 371/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.6269e-16 - r2_keras: -100.7125 - rmse: 0.8776 - sae: 2575.3418 - sse: 3154.9932\n","Epoch 371: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.9487e-16 - r2_keras: -82.6678 - rmse: 0.8663 - sae: 1881.7109 - sse: 2289.3616 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.3177e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6383 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 372/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -8.7468e-17 - r2_keras: -100.7126 - rmse: 0.8776 - sae: 2575.3438 - sse: 3154.9990\n","Epoch 372: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -6.1618e-17 - r2_keras: -82.6680 - rmse: 0.8663 - sae: 1881.7124 - sse: 2289.3660 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: 1.3696e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6375 - val_sse: 506.5584 - learning_rate: 1.0000e-05\n","Epoch 373/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -3.0468e-16 - r2_keras: -100.7126 - rmse: 0.8776 - sae: 2575.3438 - sse: 3154.9983\n","Epoch 373: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.3476e-16 - r2_keras: -82.6680 - rmse: 0.8663 - sae: 1881.7124 - sse: 2289.3657 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6383 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 374/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -9.7090e-17 - r2_keras: -100.7129 - rmse: 0.8776 - sae: 2575.3467 - sse: 3155.0063\n","Epoch 374: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -5.1977e-17 - r2_keras: -82.6682 - rmse: 0.8663 - sae: 1881.7146 - sse: 2289.3716 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6378 - val_sse: 506.5589 - learning_rate: 1.0000e-05\n","Epoch 375/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 2.1138e-16 - r2_keras: -100.7128 - rmse: 0.8776 - sae: 2575.3452 - sse: 3155.0034\n","Epoch 375: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.2581e-16 - r2_keras: -82.6681 - rmse: 0.8663 - sae: 1881.7134 - sse: 2289.3689 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 3.3712e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6376 - val_sse: 506.5585 - learning_rate: 1.0000e-05\n","Epoch 376/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 3.9157e-16 - r2_keras: -100.7129 - rmse: 0.8776 - sae: 2575.3467 - sse: 3155.0068\n","Epoch 376: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.2101e-16 - r2_keras: -82.6682 - rmse: 0.8663 - sae: 1881.7145 - sse: 2289.3716 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -8.4280e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6378 - val_sse: 506.5592 - learning_rate: 1.0000e-05\n","Epoch 377/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 3.7640e-16 - r2_keras: -100.7131 - rmse: 0.8776 - sae: 2575.3481 - sse: 3155.0122\n","Epoch 377: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.5943e-16 - r2_keras: -82.6684 - rmse: 0.8663 - sae: 1881.7157 - sse: 2289.3757 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -2.3177e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6373 - val_sse: 506.5583 - learning_rate: 1.0000e-05\n","Epoch 378/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0676 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 4.7378e-16 - r2_keras: -100.7132 - rmse: 0.8776 - sae: 2575.3496 - sse: 3155.0151\n","Epoch 378: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.5033e-16 - r2_keras: -82.6685 - rmse: 0.8663 - sae: 1881.7168 - sse: 2289.3782 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 2.6338e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6377 - val_sse: 506.5589 - learning_rate: 1.0000e-05\n","Epoch 379/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 1.8077e-16 - r2_keras: -100.7131 - rmse: 0.8776 - sae: 2575.3491 - sse: 3155.0142\n","Epoch 379: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.0776e-16 - r2_keras: -82.6684 - rmse: 0.8663 - sae: 1881.7164 - sse: 2289.3774 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6370 - val_sse: 506.5580 - learning_rate: 1.0000e-05\n","Epoch 380/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 9.0675e-17 - r2_keras: -100.7133 - rmse: 0.8776 - sae: 2575.3503 - sse: 3155.0186\n","Epoch 380: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 5.1006e-17 - r2_keras: -82.6685 - rmse: 0.8663 - sae: 1881.7172 - sse: 2289.3801 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6370 - val_sse: 506.5580 - learning_rate: 1.0000e-05\n","Epoch 381/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 3.4433e-16 - r2_keras: -100.7134 - rmse: 0.8776 - sae: 2575.3521 - sse: 3155.0232\n","Epoch 381: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.5070e-16 - r2_keras: -82.6687 - rmse: 0.8663 - sae: 1881.7186 - sse: 2289.3838 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: -1.5803e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6378 - val_sse: 506.5595 - learning_rate: 1.0000e-05\n","Epoch 382/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.6562e-16 - r2_keras: -100.7136 - rmse: 0.8777 - sae: 2575.3545 - sse: 3155.0293\n","Epoch 382: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.7641e-16 - r2_keras: -82.6689 - rmse: 0.8663 - sae: 1881.7203 - sse: 2289.3887 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6373 - val_sse: 506.5589 - learning_rate: 1.0000e-05\n","Epoch 383/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -1.2070e-16 - r2_keras: -100.7139 - rmse: 0.8777 - sae: 2575.3567 - sse: 3155.0366\n","Epoch 383: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.6263e-16 - r2_keras: -82.6690 - rmse: 0.8663 - sae: 1881.7219 - sse: 2289.3938 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6371 - val_sse: 506.5581 - learning_rate: 1.0000e-05\n","Epoch 384/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -5.1897e-17 - r2_keras: -100.7136 - rmse: 0.8777 - sae: 2575.3538 - sse: 3155.0283\n","Epoch 384: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -5.8679e-17 - r2_keras: -82.6688 - rmse: 0.8663 - sae: 1881.7198 - sse: 2289.3877 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2206 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6364 - val_sse: 506.5572 - learning_rate: 1.0000e-05\n","Epoch 385/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: 7.6067e-16 - r2_keras: -100.7138 - rmse: 0.8777 - sae: 2575.3552 - sse: 3155.0337\n","Epoch 385: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 4.4054e-16 - r2_keras: -82.6690 - rmse: 0.8663 - sae: 1881.7208 - sse: 2289.3916 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2206 - val_pearson_correlation: 8.4281e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6372 - val_sse: 506.5586 - learning_rate: 1.0000e-05\n","Epoch 386/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1387 - pearson_correlation: -4.1780e-16 - r2_keras: -100.7140 - rmse: 0.8777 - sae: 2575.3574 - sse: 3155.0396\n","Epoch 386: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.3897e-16 - r2_keras: -82.6691 - rmse: 0.8663 - sae: 1881.7225 - sse: 2289.3960 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.0552e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6363 - val_sse: 506.5576 - learning_rate: 1.0000e-05\n","Epoch 387/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 3.2625e-16 - r2_keras: -100.7141 - rmse: 0.8777 - sae: 2575.3586 - sse: 3155.0444\n","Epoch 387: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.3450e-16 - r2_keras: -82.6693 - rmse: 0.8663 - sae: 1881.7235 - sse: 2289.3997 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.8461e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6368 - val_sse: 506.5580 - learning_rate: 1.0000e-05\n","Epoch 388/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 2.3412e-16 - r2_keras: -100.7140 - rmse: 0.8777 - sae: 2575.3582 - sse: 3155.0415\n","Epoch 388: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.5325e-16 - r2_keras: -82.6692 - rmse: 0.8663 - sae: 1881.7230 - sse: 2289.3975 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6368 - val_sse: 506.5580 - learning_rate: 1.0000e-05\n","Epoch 389/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 3.1138e-16 - r2_keras: -100.7142 - rmse: 0.8777 - sae: 2575.3604 - sse: 3155.0479\n","Epoch 389: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.0900e-16 - r2_keras: -82.6693 - rmse: 0.8663 - sae: 1881.7247 - sse: 2289.4021 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.9498e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6359 - val_sse: 506.5568 - learning_rate: 1.0000e-05\n","Epoch 390/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -6.0702e-16 - r2_keras: -100.7143 - rmse: 0.8777 - sae: 2575.3608 - sse: 3155.0508\n","Epoch 390: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -4.5095e-16 - r2_keras: -82.6694 - rmse: 0.8663 - sae: 1881.7250 - sse: 2289.4043 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6366 - val_sse: 506.5581 - learning_rate: 1.0000e-05\n","Epoch 391/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -8.8341e-17 - r2_keras: -100.7145 - rmse: 0.8777 - sae: 2575.3633 - sse: 3155.0571\n","Epoch 391: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -7.9197e-17 - r2_keras: -82.6696 - rmse: 0.8663 - sae: 1881.7269 - sse: 2289.4092 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.4749e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6368 - val_sse: 506.5587 - learning_rate: 1.0000e-05\n","Epoch 392/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 1.0642e-16 - r2_keras: -100.7146 - rmse: 0.8777 - sae: 2575.3643 - sse: 3155.0598\n","Epoch 392: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -5.0753e-18 - r2_keras: -82.6697 - rmse: 0.8663 - sae: 1881.7277 - sse: 2289.4111 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.4231e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6363 - val_sse: 506.5574 - learning_rate: 1.0000e-05\n","Epoch 393/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -1.1487e-16 - r2_keras: -100.7146 - rmse: 0.8777 - sae: 2575.3640 - sse: 3155.0593\n","Epoch 393: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -7.9414e-17 - r2_keras: -82.6697 - rmse: 0.8663 - sae: 1881.7274 - sse: 2289.4104 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.7910e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6364 - val_sse: 506.5578 - learning_rate: 1.0000e-05\n","Epoch 394/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -1.9826e-17 - r2_keras: -100.7148 - rmse: 0.8777 - sae: 2575.3660 - sse: 3155.0647\n","Epoch 394: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -6.1851e-17 - r2_keras: -82.6698 - rmse: 0.8663 - sae: 1881.7289 - sse: 2289.4146 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6357 - val_sse: 506.5569 - learning_rate: 1.0000e-05\n","Epoch 395/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 5.2042e-16 - r2_keras: -100.7149 - rmse: 0.8777 - sae: 2575.3667 - sse: 3155.0679\n","Epoch 395: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.1342e-16 - r2_keras: -82.6699 - rmse: 0.8663 - sae: 1881.7294 - sse: 2289.4170 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 7.3746e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6362 - val_sse: 506.5577 - learning_rate: 1.0000e-05\n","Epoch 396/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -5.7436e-17 - r2_keras: -100.7150 - rmse: 0.8777 - sae: 2575.3689 - sse: 3155.0735\n","Epoch 396: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.6571e-17 - r2_keras: -82.6701 - rmse: 0.8663 - sae: 1881.7311 - sse: 2289.4209 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.3712e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6358 - val_sse: 506.5573 - learning_rate: 1.0000e-05\n","Epoch 397/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 3.5919e-16 - r2_keras: -100.7152 - rmse: 0.8777 - sae: 2575.3706 - sse: 3155.0786\n","Epoch 397: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.4938e-16 - r2_keras: -82.6702 - rmse: 0.8663 - sae: 1881.7323 - sse: 2289.4248 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6359 - val_sse: 506.5573 - learning_rate: 1.0000e-05\n","Epoch 398/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 2.7056e-16 - r2_keras: -100.7151 - rmse: 0.8777 - sae: 2575.3691 - sse: 3155.0752\n","Epoch 398: val_loss did not improve from 0.19066\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.9926e-16 - r2_keras: -82.6701 - rmse: 0.8663 - sae: 1881.7312 - sse: 2289.4224 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2995 - val_mse: 0.2205 - val_pearson_correlation: 3.5819e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6365 - val_sse: 506.5583 - learning_rate: 1.0000e-05\n","Epoch 399/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -6.8310e-16 - r2_keras: -100.7153 - rmse: 0.8777 - sae: 2575.3716 - sse: 3155.0815\n","Epoch 399: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -4.3935e-16 - r2_keras: -82.6703 - rmse: 0.8663 - sae: 1881.7330 - sse: 2289.4270 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3211e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6358 - val_sse: 506.5575 - learning_rate: 1.0000e-05\n","Epoch 400/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -1.9884e-16 - r2_keras: -100.7155 - rmse: 0.8777 - sae: 2575.3735 - sse: 3155.0874\n","Epoch 400: val_loss improved from 0.19066 to 0.19066, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.5428e-16 - r2_keras: -82.6704 - rmse: 0.8664 - sae: 1881.7345 - sse: 2289.4312 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 9.4816e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6356 - val_sse: 506.5573 - learning_rate: 1.0000e-05\n","Epoch 401/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -7.5803e-18 - r2_keras: -100.7155 - rmse: 0.8777 - sae: 2575.3738 - sse: 3155.0884\n","Epoch 401: val_loss improved from 0.19066 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.3277e-17 - r2_keras: -82.6705 - rmse: 0.8664 - sae: 1881.7347 - sse: 2289.4321 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.2659e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6350 - val_sse: 506.5564 - learning_rate: 1.0000e-05\n","Epoch 402/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 3.0409e-16 - r2_keras: -100.7157 - rmse: 0.8777 - sae: 2575.3757 - sse: 3155.0942\n","Epoch 402: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.0933e-16 - r2_keras: -82.6706 - rmse: 0.8664 - sae: 1881.7361 - sse: 2289.4365 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.7910e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6359 - val_sse: 506.5577 - learning_rate: 1.0000e-05\n","Epoch 403/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -1.5889e-16 - r2_keras: -100.7156 - rmse: 0.8777 - sae: 2575.3750 - sse: 3155.0918\n","Epoch 403: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.7864e-16 - r2_keras: -82.6706 - rmse: 0.8664 - sae: 1881.7356 - sse: 2289.4346 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3211e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6361 - val_sse: 506.5582 - learning_rate: 1.0000e-05\n","Epoch 404/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 2.2624e-16 - r2_keras: -100.7159 - rmse: 0.8777 - sae: 2575.3784 - sse: 3155.1011\n","Epoch 404: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.5316e-17 - r2_keras: -82.6708 - rmse: 0.8664 - sae: 1881.7379 - sse: 2289.4412 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.4749e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6353 - val_sse: 506.5568 - learning_rate: 1.0000e-05\n","Epoch 405/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -2.8834e-16 - r2_keras: -100.7160 - rmse: 0.8777 - sae: 2575.3792 - sse: 3155.1038\n","Epoch 405: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -2.0450e-16 - r2_keras: -82.6709 - rmse: 0.8664 - sae: 1881.7385 - sse: 2289.4434 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6357 - val_sse: 506.5579 - learning_rate: 1.0000e-05\n","Epoch 406/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 8.2537e-16 - r2_keras: -100.7162 - rmse: 0.8777 - sae: 2575.3806 - sse: 3155.1091\n","Epoch 406: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 5.5544e-16 - r2_keras: -82.6710 - rmse: 0.8664 - sae: 1881.7396 - sse: 2289.4473 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6352 - val_sse: 506.5565 - learning_rate: 1.0000e-05\n","Epoch 407/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 4.3207e-16 - r2_keras: -100.7160 - rmse: 0.8777 - sae: 2575.3784 - sse: 3155.1021\n","Epoch 407: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 2.4131e-16 - r2_keras: -82.6708 - rmse: 0.8664 - sae: 1881.7380 - sse: 2289.4419 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6352 - val_sse: 506.5567 - learning_rate: 1.0000e-05\n","Epoch 408/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: -1.3382e-16 - r2_keras: -100.7162 - rmse: 0.8777 - sae: 2575.3804 - sse: 3155.1079\n","Epoch 408: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -1.1754e-16 - r2_keras: -82.6710 - rmse: 0.8664 - sae: 1881.7395 - sse: 2289.4465 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -6.3211e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6354 - val_sse: 506.5572 - learning_rate: 1.0000e-05\n","Epoch 409/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 6.6764e-16 - r2_keras: -100.7164 - rmse: 0.8777 - sae: 2575.3828 - sse: 3155.1155\n","Epoch 409: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 3.9080e-16 - r2_keras: -82.6712 - rmse: 0.8664 - sae: 1881.7413 - sse: 2289.4519 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6349 - val_sse: 506.5567 - learning_rate: 1.0000e-05\n","Epoch 410/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 3.7901e-18 - r2_keras: -100.7165 - rmse: 0.8777 - sae: 2575.3843 - sse: 3155.1199\n","Epoch 410: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.1026e-17 - r2_keras: -82.6713 - rmse: 0.8664 - sae: 1881.7423 - sse: 2289.4553 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6350 - val_sse: 506.5571 - learning_rate: 1.0000e-05\n","Epoch 411/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 8.5277e-16 - r2_keras: -100.7167 - rmse: 0.8777 - sae: 2575.3862 - sse: 3155.1260\n","Epoch 411: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 6.0393e-16 - r2_keras: -82.6715 - rmse: 0.8664 - sae: 1881.7438 - sse: 2289.4597 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6348 - val_sse: 506.5566 - learning_rate: 1.0000e-05\n","Epoch 412/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 1.2566e-16 - r2_keras: -100.7165 - rmse: 0.8777 - sae: 2575.3840 - sse: 3155.1191\n","Epoch 412: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 1.1304e-16 - r2_keras: -82.6713 - rmse: 0.8664 - sae: 1881.7422 - sse: 2289.4546 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.2659e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6349 - val_sse: 506.5564 - learning_rate: 1.0000e-05\n","Epoch 413/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2266 - mse: 0.1386 - pearson_correlation: 7.3907e-16 - r2_keras: -100.7167 - rmse: 0.8777 - sae: 2575.3862 - sse: 3155.1250\n","Epoch 413: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 5.3757e-16 - r2_keras: -82.6715 - rmse: 0.8664 - sae: 1881.7438 - sse: 2289.4590 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6350 - val_sse: 506.5570 - learning_rate: 1.0000e-05\n","Epoch 414/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -9.7084e-17 - r2_keras: -100.7169 - rmse: 0.8777 - sae: 2575.3884 - sse: 3155.1316\n","Epoch 414: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -3.7150e-20 - r2_keras: -82.6717 - rmse: 0.8664 - sae: 1881.7455 - sse: 2289.4639 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6345 - val_sse: 506.5564 - learning_rate: 1.0000e-05\n","Epoch 415/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 9.6210e-17 - r2_keras: -100.7170 - rmse: 0.8777 - sae: 2575.3896 - sse: 3155.1357\n","Epoch 415: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 9.4830e-17 - r2_keras: -82.6718 - rmse: 0.8664 - sae: 1881.7463 - sse: 2289.4670 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6351 - val_sse: 506.5575 - learning_rate: 1.0000e-05\n","Epoch 416/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.1003e-15 - r2_keras: -100.7172 - rmse: 0.8777 - sae: 2575.3921 - sse: 3155.1416\n","Epoch 416: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: 7.2880e-16 - r2_keras: -82.6720 - rmse: 0.8664 - sae: 1881.7482 - sse: 2289.4714 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.9499e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6341 - val_sse: 506.5557 - learning_rate: 1.0000e-05\n","Epoch 417/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -6.2682e-17 - r2_keras: -100.7169 - rmse: 0.8777 - sae: 2575.3879 - sse: 3155.1326\n","Epoch 417: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2177 - mse: 0.1280 - pearson_correlation: -9.0892e-17 - r2_keras: -82.6717 - rmse: 0.8664 - sae: 1881.7452 - sse: 2289.4648 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.5284e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6344 - val_sse: 506.5561 - learning_rate: 1.0000e-05\n","Epoch 418/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.1370e-17 - r2_keras: -100.7173 - rmse: 0.8777 - sae: 2575.3916 - sse: 3155.1421\n","Epoch 418: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -2.0801e-17 - r2_keras: -82.6720 - rmse: 0.8664 - sae: 1881.7478 - sse: 2289.4717 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6346 - val_sse: 506.5567 - learning_rate: 1.0000e-05\n","Epoch 419/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -8.4839e-17 - r2_keras: -100.7175 - rmse: 0.8777 - sae: 2575.3938 - sse: 3155.1487\n","Epoch 419: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -6.1753e-17 - r2_keras: -82.6721 - rmse: 0.8664 - sae: 1881.7494 - sse: 2289.4766 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.3696e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6345 - val_sse: 506.5570 - learning_rate: 1.0000e-05\n","Epoch 420/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.7813e-16 - r2_keras: -100.7176 - rmse: 0.8777 - sae: 2575.3953 - sse: 3155.1533\n","Epoch 420: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -8.9953e-17 - r2_keras: -82.6723 - rmse: 0.8664 - sae: 1881.7506 - sse: 2289.4800 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6348 - val_sse: 506.5567 - learning_rate: 1.0000e-05\n","Epoch 421/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 6.3615e-16 - r2_keras: -100.7175 - rmse: 0.8777 - sae: 2575.3945 - sse: 3155.1487\n","Epoch 421: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 4.3118e-16 - r2_keras: -82.6721 - rmse: 0.8664 - sae: 1881.7500 - sse: 2289.4766 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6339 - val_sse: 506.5557 - learning_rate: 1.0000e-05\n","Epoch 422/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.4431e-16 - r2_keras: -100.7177 - rmse: 0.8777 - sae: 2575.3965 - sse: 3155.1558\n","Epoch 422: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 2.9526e-16 - r2_keras: -82.6723 - rmse: 0.8664 - sae: 1881.7513 - sse: 2289.4814 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6338 - val_sse: 506.5555 - learning_rate: 1.0000e-05\n","Epoch 423/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.5714e-16 - r2_keras: -100.7178 - rmse: 0.8777 - sae: 2575.3970 - sse: 3155.1587\n","Epoch 423: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 9.2484e-17 - r2_keras: -82.6724 - rmse: 0.8664 - sae: 1881.7518 - sse: 2289.4839 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3211e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6342 - val_sse: 506.5565 - learning_rate: 1.0000e-05\n","Epoch 424/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.8163e-16 - r2_keras: -100.7179 - rmse: 0.8777 - sae: 2575.3989 - sse: 3155.1633\n","Epoch 424: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -2.9030e-16 - r2_keras: -82.6726 - rmse: 0.8664 - sae: 1881.7533 - sse: 2289.4875 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6338 - val_sse: 506.5561 - learning_rate: 1.0000e-05\n","Epoch 425/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.7026e-16 - r2_keras: -100.7180 - rmse: 0.8777 - sae: 2575.3994 - sse: 3155.1655\n","Epoch 425: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -1.4325e-16 - r2_keras: -82.6726 - rmse: 0.8664 - sae: 1881.7537 - sse: 2289.4893 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.2124e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6343 - val_sse: 506.5564 - learning_rate: 1.0000e-05\n","Epoch 426/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.0641e-16 - r2_keras: -100.7180 - rmse: 0.8777 - sae: 2575.4001 - sse: 3155.1650\n","Epoch 426: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -1.0021e-16 - r2_keras: -82.6726 - rmse: 0.8664 - sae: 1881.7542 - sse: 2289.4888 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3746e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6337 - val_sse: 506.5557 - learning_rate: 1.0000e-05\n","Epoch 427/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.4052e-16 - r2_keras: -100.7182 - rmse: 0.8777 - sae: 2575.4021 - sse: 3155.1729\n","Epoch 427: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 1.0596e-16 - r2_keras: -82.6728 - rmse: 0.8664 - sae: 1881.7555 - sse: 2289.4939 - val_huber_loss: 0.1021 - val_loss: 0.1907 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6342 - val_sse: 506.5564 - learning_rate: 1.0000e-05\n","Epoch 428/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -8.1164e-16 - r2_keras: -100.7184 - rmse: 0.8777 - sae: 2575.4038 - sse: 3155.1770\n","Epoch 428: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -5.2882e-16 - r2_keras: -82.6729 - rmse: 0.8664 - sae: 1881.7568 - sse: 2289.4973 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6330 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 429/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.4489e-17 - r2_keras: -100.7184 - rmse: 0.8777 - sae: 2575.4033 - sse: 3155.1777\n","Epoch 429: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 7.4400e-17 - r2_keras: -82.6730 - rmse: 0.8664 - sae: 1881.7566 - sse: 2289.4983 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.4231e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6336 - val_sse: 506.5556 - learning_rate: 1.0000e-05\n","Epoch 430/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.0815e-17 - r2_keras: -100.7184 - rmse: 0.8777 - sae: 2575.4033 - sse: 3155.1772\n","Epoch 430: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 3.5237e-17 - r2_keras: -82.6729 - rmse: 0.8664 - sae: 1881.7565 - sse: 2289.4976 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6337 - val_sse: 506.5558 - learning_rate: 1.0000e-05\n","Epoch 431/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.7638e-16 - r2_keras: -100.7186 - rmse: 0.8777 - sae: 2575.4058 - sse: 3155.1831\n","Epoch 431: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -2.6414e-16 - r2_keras: -82.6731 - rmse: 0.8664 - sae: 1881.7583 - sse: 2289.5022 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6338 - val_sse: 506.5561 - learning_rate: 1.0000e-05\n","Epoch 432/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.9124e-16 - r2_keras: -100.7188 - rmse: 0.8777 - sae: 2575.4080 - sse: 3155.1895\n","Epoch 432: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -2.3628e-16 - r2_keras: -82.6732 - rmse: 0.8664 - sae: 1881.7599 - sse: 2289.5063 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6335 - val_sse: 506.5560 - learning_rate: 1.0000e-05\n","Epoch 433/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.1831e-15 - r2_keras: -100.7189 - rmse: 0.8777 - sae: 2575.4092 - sse: 3155.1938\n","Epoch 433: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 7.9862e-16 - r2_keras: -82.6734 - rmse: 0.8664 - sae: 1881.7609 - sse: 2289.5098 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 7.3747e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6326 - val_sse: 506.5546 - learning_rate: 1.0000e-05\n","Epoch 434/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -7.3992e-16 - r2_keras: -100.7189 - rmse: 0.8777 - sae: 2575.4087 - sse: 3155.1931\n","Epoch 434: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -4.9706e-16 - r2_keras: -82.6734 - rmse: 0.8664 - sae: 1881.7606 - sse: 2289.5095 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2141e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6331 - val_sse: 506.5551 - learning_rate: 1.0000e-05\n","Epoch 435/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.6967e-16 - r2_keras: -100.7189 - rmse: 0.8777 - sae: 2575.4087 - sse: 3155.1934\n","Epoch 435: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 2.2331e-16 - r2_keras: -82.6734 - rmse: 0.8664 - sae: 1881.7605 - sse: 2289.5095 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6333 - val_sse: 506.5555 - learning_rate: 1.0000e-05\n","Epoch 436/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.5188e-16 - r2_keras: -100.7191 - rmse: 0.8777 - sae: 2575.4111 - sse: 3155.1992\n","Epoch 436: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 2.5631e-16 - r2_keras: -82.6735 - rmse: 0.8664 - sae: 1881.7623 - sse: 2289.5139 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6331 - val_sse: 506.5554 - learning_rate: 1.0000e-05\n","Epoch 437/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.8687e-16 - r2_keras: -100.7193 - rmse: 0.8777 - sae: 2575.4126 - sse: 3155.2046\n","Epoch 437: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -9.1153e-17 - r2_keras: -82.6737 - rmse: 0.8664 - sae: 1881.7633 - sse: 2289.5178 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6333 - val_sse: 506.5560 - learning_rate: 1.0000e-05\n","Epoch 438/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.3555e-16 - r2_keras: -100.7194 - rmse: 0.8777 - sae: 2575.4141 - sse: 3155.2095\n","Epoch 438: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 2.9179e-16 - r2_keras: -82.6738 - rmse: 0.8664 - sae: 1881.7645 - sse: 2289.5215 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4282e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6321 - val_sse: 506.5542 - learning_rate: 1.0000e-05\n","Epoch 439/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.4049e-15 - r2_keras: -100.7194 - rmse: 0.8777 - sae: 2575.4136 - sse: 3155.2095\n","Epoch 439: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -9.6682e-16 - r2_keras: -82.6738 - rmse: 0.8664 - sae: 1881.7642 - sse: 2289.5215 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6327 - val_sse: 506.5548 - learning_rate: 1.0000e-05\n","Epoch 440/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.8308e-16 - r2_keras: -100.7194 - rmse: 0.8777 - sae: 2575.4141 - sse: 3155.2097\n","Epoch 440: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -1.2678e-16 - r2_keras: -82.6738 - rmse: 0.8664 - sae: 1881.7645 - sse: 2289.5217 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6332 - val_sse: 506.5559 - learning_rate: 1.0000e-05\n","Epoch 441/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -5.7665e-16 - r2_keras: -100.7197 - rmse: 0.8777 - sae: 2575.4170 - sse: 3155.2163\n","Epoch 441: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -3.4194e-16 - r2_keras: -82.6740 - rmse: 0.8664 - sae: 1881.7665 - sse: 2289.5264 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.5803e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6327 - val_sse: 506.5550 - learning_rate: 1.0000e-05\n","Epoch 442/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.6645e-16 - r2_keras: -100.7197 - rmse: 0.8777 - sae: 2575.4175 - sse: 3155.2192\n","Epoch 442: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 3.2938e-16 - r2_keras: -82.6741 - rmse: 0.8664 - sae: 1881.7670 - sse: 2289.5286 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6329 - val_sse: 506.5557 - learning_rate: 1.0000e-05\n","Epoch 443/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.7841e-16 - r2_keras: -100.7199 - rmse: 0.8777 - sae: 2575.4194 - sse: 3155.2251\n","Epoch 443: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -2.7446e-16 - r2_keras: -82.6743 - rmse: 0.8664 - sae: 1881.7684 - sse: 2289.5330 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3747e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6324 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 444/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.8803e-16 - r2_keras: -100.7199 - rmse: 0.8777 - sae: 2575.4189 - sse: 3155.2229\n","Epoch 444: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -3.2441e-16 - r2_keras: -82.6742 - rmse: 0.8664 - sae: 1881.7679 - sse: 2289.5312 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6330 - val_sse: 506.5556 - learning_rate: 1.0000e-05\n","Epoch 445/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.9560e-18 - r2_keras: -100.7201 - rmse: 0.8777 - sae: 2575.4214 - sse: 3155.2297\n","Epoch 445: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: -2.7855e-17 - r2_keras: -82.6744 - rmse: 0.8664 - sae: 1881.7699 - sse: 2289.5364 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2141e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6327 - val_sse: 506.5554 - learning_rate: 1.0000e-05\n","Epoch 446/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.1981e-16 - r2_keras: -100.7202 - rmse: 0.8777 - sae: 2575.4219 - sse: 3155.2319\n","Epoch 446: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 2.6712e-16 - r2_keras: -82.6744 - rmse: 0.8664 - sae: 1881.7703 - sse: 2289.5381 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2141e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6322 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 447/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.4809e-16 - r2_keras: -100.7203 - rmse: 0.8777 - sae: 2575.4233 - sse: 3155.2361\n","Epoch 447: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1280 - pearson_correlation: 1.0732e-16 - r2_keras: -82.6745 - rmse: 0.8664 - sae: 1881.7714 - sse: 2289.5410 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.2124e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6323 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 448/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.5129e-16 - r2_keras: -100.7205 - rmse: 0.8777 - sae: 2575.4253 - sse: 3155.2419\n","Epoch 448: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.5081e-16 - r2_keras: -82.6747 - rmse: 0.8664 - sae: 1881.7728 - sse: 2289.5457 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -8.4282e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6326 - val_sse: 506.5553 - learning_rate: 1.0000e-05\n","Epoch 449/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.4313e-16 - r2_keras: -100.7204 - rmse: 0.8777 - sae: 2575.4248 - sse: 3155.2397\n","Epoch 449: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.2875e-16 - r2_keras: -82.6746 - rmse: 0.8664 - sae: 1881.7723 - sse: 2289.5437 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6325 - val_sse: 506.5552 - learning_rate: 1.0000e-05\n","Epoch 450/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.9269e-17 - r2_keras: -100.7206 - rmse: 0.8777 - sae: 2575.4263 - sse: 3155.2446\n","Epoch 450: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -8.2948e-18 - r2_keras: -82.6748 - rmse: 0.8664 - sae: 1881.7734 - sse: 2289.5474 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6322 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 451/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.5946e-17 - r2_keras: -100.7207 - rmse: 0.8777 - sae: 2575.4270 - sse: 3155.2478\n","Epoch 451: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.0860e-17 - r2_keras: -82.6749 - rmse: 0.8664 - sae: 1881.7740 - sse: 2289.5498 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.8462e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6315 - val_sse: 506.5539 - learning_rate: 1.0000e-05\n","Epoch 452/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.4867e-16 - r2_keras: -100.7208 - rmse: 0.8777 - sae: 2575.4282 - sse: 3155.2524\n","Epoch 452: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.8278e-16 - r2_keras: -82.6750 - rmse: 0.8664 - sae: 1881.7750 - sse: 2289.5532 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6326 - val_sse: 506.5558 - learning_rate: 1.0000e-05\n","Epoch 453/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.1865e-17 - r2_keras: -100.7210 - rmse: 0.8777 - sae: 2575.4312 - sse: 3155.2588\n","Epoch 453: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.9685e-17 - r2_keras: -82.6752 - rmse: 0.8664 - sae: 1881.7772 - sse: 2289.5581 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.5820e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6321 - val_sse: 506.5546 - learning_rate: 1.0000e-05\n","Epoch 454/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.8948e-16 - r2_keras: -100.7209 - rmse: 0.8777 - sae: 2575.4294 - sse: 3155.2544\n","Epoch 454: val_loss did not improve from 0.19065\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.5352e-16 - r2_keras: -82.6750 - rmse: 0.8664 - sae: 1881.7758 - sse: 2289.5544 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3211e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6321 - val_sse: 506.5550 - learning_rate: 1.0000e-05\n","Epoch 455/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.0728e-16 - r2_keras: -100.7211 - rmse: 0.8777 - sae: 2575.4319 - sse: 3155.2607\n","Epoch 455: val_loss improved from 0.19065 to 0.19065, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -4.9634e-18 - r2_keras: -82.6752 - rmse: 0.8664 - sae: 1881.7777 - sse: 2289.5593 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6319 - val_sse: 506.5548 - learning_rate: 1.0000e-05\n","Epoch 456/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -5.5099e-17 - r2_keras: -100.7212 - rmse: 0.8777 - sae: 2575.4329 - sse: 3155.2646\n","Epoch 456: val_loss improved from 0.19065 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.8421e-17 - r2_keras: -82.6754 - rmse: 0.8664 - sae: 1881.7784 - sse: 2289.5623 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.7910e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6314 - val_sse: 506.5541 - learning_rate: 1.0000e-05\n","Epoch 457/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -7.3465e-17 - r2_keras: -100.7214 - rmse: 0.8777 - sae: 2575.4351 - sse: 3155.2715\n","Epoch 457: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.1555e-16 - r2_keras: -82.6755 - rmse: 0.8664 - sae: 1881.7800 - sse: 2289.5671 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6322 - val_sse: 506.5551 - learning_rate: 1.0000e-05\n","Epoch 458/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.9327e-16 - r2_keras: -100.7212 - rmse: 0.8777 - sae: 2575.4333 - sse: 3155.2656\n","Epoch 458: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.3763e-16 - r2_keras: -82.6754 - rmse: 0.8664 - sae: 1881.7788 - sse: 2289.5630 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.8445e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6315 - val_sse: 506.5543 - learning_rate: 1.0000e-05\n","Epoch 459/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.9008e-16 - r2_keras: -100.7214 - rmse: 0.8777 - sae: 2575.4353 - sse: 3155.2720\n","Epoch 459: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.5032e-16 - r2_keras: -82.6755 - rmse: 0.8664 - sae: 1881.7802 - sse: 2289.5674 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.6338e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6317 - val_sse: 506.5544 - learning_rate: 1.0000e-05\n","Epoch 460/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.5507e-16 - r2_keras: -100.7217 - rmse: 0.8777 - sae: 2575.4380 - sse: 3155.2798\n","Epoch 460: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.6995e-16 - r2_keras: -82.6757 - rmse: 0.8664 - sae: 1881.7821 - sse: 2289.5732 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3212e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6313 - val_sse: 506.5542 - learning_rate: 1.0000e-05\n","Epoch 461/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.0753e-16 - r2_keras: -100.7218 - rmse: 0.8777 - sae: 2575.4395 - sse: 3155.2844\n","Epoch 461: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 5.4543e-16 - r2_keras: -82.6759 - rmse: 0.8664 - sae: 1881.7832 - sse: 2289.5767 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -6.3212e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6315 - val_sse: 506.5548 - learning_rate: 1.0000e-05\n","Epoch 462/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.9590e-16 - r2_keras: -100.7219 - rmse: 0.8777 - sae: 2575.4404 - sse: 3155.2871\n","Epoch 462: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.5950e-16 - r2_keras: -82.6759 - rmse: 0.8664 - sae: 1881.7839 - sse: 2289.5786 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6317 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 463/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.7578e-16 - r2_keras: -100.7217 - rmse: 0.8777 - sae: 2575.4387 - sse: 3155.2808\n","Epoch 463: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.4325e-16 - r2_keras: -82.6758 - rmse: 0.8664 - sae: 1881.7828 - sse: 2289.5742 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6310 - val_sse: 506.5536 - learning_rate: 1.0000e-05\n","Epoch 464/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.1573e-16 - r2_keras: -100.7219 - rmse: 0.8777 - sae: 2575.4399 - sse: 3155.2871\n","Epoch 464: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.6365e-16 - r2_keras: -82.6760 - rmse: 0.8664 - sae: 1881.7837 - sse: 2289.5789 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6313 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 465/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -7.8449e-16 - r2_keras: -100.7222 - rmse: 0.8777 - sae: 2575.4434 - sse: 3155.2964\n","Epoch 465: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -5.3008e-16 - r2_keras: -82.6762 - rmse: 0.8664 - sae: 1881.7861 - sse: 2289.5857 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6312 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 466/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.4250e-17 - r2_keras: -100.7224 - rmse: 0.8777 - sae: 2575.4453 - sse: 3155.3008\n","Epoch 466: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.2893e-18 - r2_keras: -82.6763 - rmse: 0.8664 - sae: 1881.7876 - sse: 2289.5889 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6313 - val_sse: 506.5547 - learning_rate: 1.0000e-05\n","Epoch 467/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.2448e-16 - r2_keras: -100.7225 - rmse: 0.8777 - sae: 2575.4468 - sse: 3155.3057\n","Epoch 467: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.1367e-16 - r2_keras: -82.6765 - rmse: 0.8664 - sae: 1881.7887 - sse: 2289.5923 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4282e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6311 - val_sse: 506.5540 - learning_rate: 1.0000e-05\n","Epoch 468/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1561 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 9.0664e-17 - r2_keras: -100.7223 - rmse: 0.8777 - sae: 2575.4443 - sse: 3155.2979\n","Epoch 468: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 7.0357e-17 - r2_keras: -82.6763 - rmse: 0.8664 - sae: 1881.7870 - sse: 2289.5869 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6307 - val_sse: 506.5535 - learning_rate: 1.0000e-05\n","Epoch 469/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 5.6002e-16 - r2_keras: -100.7225 - rmse: 0.8777 - sae: 2575.4468 - sse: 3155.3057\n","Epoch 469: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.9789e-16 - r2_keras: -82.6765 - rmse: 0.8664 - sae: 1881.7887 - sse: 2289.5925 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6314 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 470/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.4837e-16 - r2_keras: -100.7227 - rmse: 0.8777 - sae: 2575.4492 - sse: 3155.3123\n","Epoch 470: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.5491e-16 - r2_keras: -82.6767 - rmse: 0.8664 - sae: 1881.7905 - sse: 2289.5974 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.3696e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6306 - val_sse: 506.5538 - learning_rate: 1.0000e-05\n","Epoch 471/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -5.7051e-16 - r2_keras: -100.7228 - rmse: 0.8777 - sae: 2575.4502 - sse: 3155.3154\n","Epoch 471: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.8695e-16 - r2_keras: -82.6767 - rmse: 0.8664 - sae: 1881.7911 - sse: 2289.5996 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6309 - val_sse: 506.5540 - learning_rate: 1.0000e-05\n","Epoch 472/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.4983e-17 - r2_keras: -100.7227 - rmse: 0.8777 - sae: 2575.4490 - sse: 3155.3120\n","Epoch 472: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.0500e-17 - r2_keras: -82.6767 - rmse: 0.8664 - sae: 1881.7904 - sse: 2289.5974 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.5285e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6307 - val_sse: 506.5538 - learning_rate: 1.0000e-05\n","Epoch 473/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -6.2619e-16 - r2_keras: -100.7229 - rmse: 0.8777 - sae: 2575.4507 - sse: 3155.3174\n","Epoch 473: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.6553e-16 - r2_keras: -82.6768 - rmse: 0.8664 - sae: 1881.7916 - sse: 2289.6013 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6307 - val_sse: 506.5539 - learning_rate: 1.0000e-05\n","Epoch 474/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.4575e-16 - r2_keras: -100.7231 - rmse: 0.8777 - sae: 2575.4526 - sse: 3155.3228\n","Epoch 474: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.4401e-16 - r2_keras: -82.6769 - rmse: 0.8664 - sae: 1881.7931 - sse: 2289.6052 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.5803e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6309 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 475/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.7083e-16 - r2_keras: -100.7232 - rmse: 0.8777 - sae: 2575.4539 - sse: 3155.3267\n","Epoch 475: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -5.6761e-17 - r2_keras: -82.6771 - rmse: 0.8664 - sae: 1881.7939 - sse: 2289.6079 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2141e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6300 - val_sse: 506.5530 - learning_rate: 1.0000e-05\n","Epoch 476/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.9647e-16 - r2_keras: -100.7233 - rmse: 0.8777 - sae: 2575.4548 - sse: 3155.3298\n","Epoch 476: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.5204e-16 - r2_keras: -82.6772 - rmse: 0.8664 - sae: 1881.7947 - sse: 2289.6106 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2676e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6306 - val_sse: 506.5538 - learning_rate: 1.0000e-05\n","Epoch 477/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.1625e-18 - r2_keras: -100.7234 - rmse: 0.8777 - sae: 2575.4558 - sse: 3155.3315\n","Epoch 477: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.5160e-17 - r2_keras: -82.6772 - rmse: 0.8664 - sae: 1881.7953 - sse: 2289.6116 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6304 - val_sse: 506.5537 - learning_rate: 1.0000e-05\n","Epoch 478/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 5.6030e-16 - r2_keras: -100.7235 - rmse: 0.8777 - sae: 2575.4563 - sse: 3155.3345\n","Epoch 478: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.5040e-16 - r2_keras: -82.6773 - rmse: 0.8664 - sae: 1881.7958 - sse: 2289.6138 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1071e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6303 - val_sse: 506.5536 - learning_rate: 1.0000e-05\n","Epoch 479/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.5945e-17 - r2_keras: -100.7235 - rmse: 0.8777 - sae: 2575.4575 - sse: 3155.3372\n","Epoch 479: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 7.1590e-17 - r2_keras: -82.6773 - rmse: 0.8664 - sae: 1881.7965 - sse: 2289.6157 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6302 - val_sse: 506.5537 - learning_rate: 1.0000e-05\n","Epoch 480/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.8452e-16 - r2_keras: -100.7237 - rmse: 0.8777 - sae: 2575.4587 - sse: 3155.3416\n","Epoch 480: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.1942e-16 - r2_keras: -82.6775 - rmse: 0.8664 - sae: 1881.7976 - sse: 2289.6191 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.8981e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6298 - val_sse: 506.5533 - learning_rate: 1.0000e-05\n","Epoch 481/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.3584e-16 - r2_keras: -100.7239 - rmse: 0.8777 - sae: 2575.4604 - sse: 3155.3472\n","Epoch 481: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.3645e-16 - r2_keras: -82.6776 - rmse: 0.8664 - sae: 1881.7988 - sse: 2289.6233 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.6874e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6302 - val_sse: 506.5536 - learning_rate: 1.0000e-05\n","Epoch 482/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.7811e-16 - r2_keras: -100.7239 - rmse: 0.8777 - sae: 2575.4607 - sse: 3155.3467\n","Epoch 482: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.4858e-16 - r2_keras: -82.6776 - rmse: 0.8664 - sae: 1881.7990 - sse: 2289.6228 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.8445e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6310 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 483/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -7.4920e-17 - r2_keras: -100.7241 - rmse: 0.8777 - sae: 2575.4634 - sse: 3155.3538\n","Epoch 483: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -4.8058e-17 - r2_keras: -82.6778 - rmse: 0.8664 - sae: 1881.8009 - sse: 2289.6279 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6299 - val_sse: 506.5532 - learning_rate: 1.0000e-05\n","Epoch 484/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.1486e-15 - r2_keras: -100.7240 - rmse: 0.8777 - sae: 2575.4622 - sse: 3155.3518\n","Epoch 484: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 6.8593e-16 - r2_keras: -82.6778 - rmse: 0.8664 - sae: 1881.8002 - sse: 2289.6267 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2141e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6298 - val_sse: 506.5534 - learning_rate: 1.0000e-05\n","Epoch 485/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.3321e-18 - r2_keras: -100.7242 - rmse: 0.8777 - sae: 2575.4639 - sse: 3155.3574\n","Epoch 485: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -4.2823e-17 - r2_keras: -82.6779 - rmse: 0.8664 - sae: 1881.8015 - sse: 2289.6311 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.1606e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6295 - val_sse: 506.5526 - learning_rate: 1.0000e-05\n","Epoch 486/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.4925e-16 - r2_keras: -100.7242 - rmse: 0.8777 - sae: 2575.4639 - sse: 3155.3577\n","Epoch 486: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.9874e-16 - r2_keras: -82.6779 - rmse: 0.8664 - sae: 1881.8014 - sse: 2289.6309 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1071e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6300 - val_sse: 506.5536 - learning_rate: 1.0000e-05\n","Epoch 487/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.5887e-16 - r2_keras: -100.7244 - rmse: 0.8777 - sae: 2575.4666 - sse: 3155.3638\n","Epoch 487: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.0138e-16 - r2_keras: -82.6781 - rmse: 0.8664 - sae: 1881.8033 - sse: 2289.6353 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.6856e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6303 - val_sse: 506.5542 - learning_rate: 1.0000e-05\n","Epoch 488/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.2386e-16 - r2_keras: -100.7245 - rmse: 0.8777 - sae: 2575.4678 - sse: 3155.3677\n","Epoch 488: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.2309e-16 - r2_keras: -82.6782 - rmse: 0.8664 - sae: 1881.8042 - sse: 2289.6382 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3212e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5524 - learning_rate: 1.0000e-05\n","Epoch 489/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.3410e-16 - r2_keras: -100.7245 - rmse: 0.8777 - sae: 2575.4673 - sse: 3155.3677\n","Epoch 489: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.5927e-16 - r2_keras: -82.6782 - rmse: 0.8664 - sae: 1881.8041 - sse: 2289.6387 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3212e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6296 - val_sse: 506.5533 - learning_rate: 1.0000e-05\n","Epoch 490/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.6354e-16 - r2_keras: -100.7248 - rmse: 0.8777 - sae: 2575.4707 - sse: 3155.3760\n","Epoch 490: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.2697e-16 - r2_keras: -82.6784 - rmse: 0.8664 - sae: 1881.8065 - sse: 2289.6448 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1071e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6296 - val_sse: 506.5531 - learning_rate: 1.0000e-05\n","Epoch 491/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.6148e-17 - r2_keras: -100.7246 - rmse: 0.8777 - sae: 2575.4690 - sse: 3155.3713\n","Epoch 491: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -9.6539e-19 - r2_keras: -82.6783 - rmse: 0.8664 - sae: 1881.8052 - sse: 2289.6411 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.8964e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6296 - val_sse: 506.5532 - learning_rate: 1.0000e-05\n","Epoch 492/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -7.3753e-17 - r2_keras: -100.7248 - rmse: 0.8777 - sae: 2575.4707 - sse: 3155.3767\n","Epoch 492: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -4.3976e-17 - r2_keras: -82.6784 - rmse: 0.8664 - sae: 1881.8065 - sse: 2289.6450 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4283e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6296 - val_sse: 506.5535 - learning_rate: 1.0000e-05\n","Epoch 493/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -9.3867e-17 - r2_keras: -100.7250 - rmse: 0.8777 - sae: 2575.4729 - sse: 3155.3835\n","Epoch 493: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.8485e-16 - r2_keras: -82.6786 - rmse: 0.8664 - sae: 1881.8081 - sse: 2289.6501 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3212e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5532 - learning_rate: 1.0000e-05\n","Epoch 494/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.1777e-16 - r2_keras: -100.7251 - rmse: 0.8777 - sae: 2575.4736 - sse: 3155.3867\n","Epoch 494: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -5.2076e-17 - r2_keras: -82.6787 - rmse: 0.8664 - sae: 1881.8087 - sse: 2289.6526 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2677e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5529 - learning_rate: 1.0000e-05\n","Epoch 495/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.2702e-16 - r2_keras: -100.7253 - rmse: 0.8777 - sae: 2575.4756 - sse: 3155.3916\n","Epoch 495: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 5.5937e-16 - r2_keras: -82.6789 - rmse: 0.8664 - sae: 1881.8101 - sse: 2289.6562 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.5285e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5523 - learning_rate: 1.0000e-05\n","Epoch 496/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.8858e-16 - r2_keras: -100.7251 - rmse: 0.8777 - sae: 2575.4734 - sse: 3155.3850\n","Epoch 496: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.9550e-16 - r2_keras: -82.6787 - rmse: 0.8664 - sae: 1881.8085 - sse: 2289.6514 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.8981e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5529 - learning_rate: 1.0000e-05\n","Epoch 497/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -7.3957e-16 - r2_keras: -100.7253 - rmse: 0.8777 - sae: 2575.4756 - sse: 3155.3923\n","Epoch 497: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -5.0390e-16 - r2_keras: -82.6789 - rmse: 0.8664 - sae: 1881.8101 - sse: 2289.6565 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5533 - learning_rate: 1.0000e-05\n","Epoch 498/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.1482e-16 - r2_keras: -100.7255 - rmse: 0.8777 - sae: 2575.4775 - sse: 3155.3975\n","Epoch 498: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.2612e-16 - r2_keras: -82.6790 - rmse: 0.8664 - sae: 1881.8116 - sse: 2289.6606 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.4231e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5529 - learning_rate: 1.0000e-05\n","Epoch 499/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.4863e-16 - r2_keras: -100.7257 - rmse: 0.8777 - sae: 2575.4800 - sse: 3155.4053\n","Epoch 499: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0594 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.1986e-16 - r2_keras: -82.6792 - rmse: 0.8664 - sae: 1881.8134 - sse: 2289.6663 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.6874e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5528 - learning_rate: 1.0000e-05\n","Epoch 500/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.7162e-17 - r2_keras: -100.7255 - rmse: 0.8777 - sae: 2575.4775 - sse: 3155.3965\n","Epoch 500: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 6.7550e-17 - r2_keras: -82.6790 - rmse: 0.8664 - sae: 1881.8115 - sse: 2289.6599 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3748e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5516 - learning_rate: 1.0000e-05\n","Epoch 501/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.6614e-16 - r2_keras: -100.7256 - rmse: 0.8777 - sae: 2575.4788 - sse: 3155.4016\n","Epoch 501: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.0963e-16 - r2_keras: -82.6791 - rmse: 0.8664 - sae: 1881.8125 - sse: 2289.6636 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.3713e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5524 - learning_rate: 1.0000e-05\n","Epoch 502/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.2389e-16 - r2_keras: -100.7259 - rmse: 0.8777 - sae: 2575.4814 - sse: 3155.4092\n","Epoch 502: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.3547e-16 - r2_keras: -82.6793 - rmse: 0.8664 - sae: 1881.8145 - sse: 2289.6692 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5530 - learning_rate: 1.0000e-05\n","Epoch 503/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 6.0517e-16 - r2_keras: -100.7260 - rmse: 0.8777 - sae: 2575.4829 - sse: 3155.4133\n","Epoch 503: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 4.0770e-16 - r2_keras: -82.6795 - rmse: 0.8664 - sae: 1881.8156 - sse: 2289.6724 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5530 - learning_rate: 1.0000e-05\n","Epoch 504/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.0989e-16 - r2_keras: -100.7262 - rmse: 0.8777 - sae: 2575.4849 - sse: 3155.4185\n","Epoch 504: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.5031e-16 - r2_keras: -82.6796 - rmse: 0.8664 - sae: 1881.8169 - sse: 2289.6760 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3747e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5526 - learning_rate: 1.0000e-05\n","Epoch 505/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.7024e-16 - r2_keras: -100.7259 - rmse: 0.8777 - sae: 2575.4824 - sse: 3155.4116\n","Epoch 505: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -9.8859e-17 - r2_keras: -82.6794 - rmse: 0.8664 - sae: 1881.8152 - sse: 2289.6711 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.7910e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6278 - val_sse: 506.5512 - learning_rate: 1.0000e-05\n","Epoch 506/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.9355e-16 - r2_keras: -100.7262 - rmse: 0.8777 - sae: 2575.4844 - sse: 3155.4182\n","Epoch 506: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.2780e-16 - r2_keras: -82.6796 - rmse: 0.8664 - sae: 1881.8165 - sse: 2289.6758 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5521 - learning_rate: 1.0000e-05\n","Epoch 507/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.2739e-16 - r2_keras: -100.7264 - rmse: 0.8777 - sae: 2575.4861 - sse: 3155.4248\n","Epoch 507: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.3308e-16 - r2_keras: -82.6798 - rmse: 0.8664 - sae: 1881.8180 - sse: 2289.6807 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.1606e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5516 - learning_rate: 1.0000e-05\n","Epoch 508/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 7.3052e-16 - r2_keras: -100.7265 - rmse: 0.8777 - sae: 2575.4878 - sse: 3155.4277\n","Epoch 508: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 5.4980e-16 - r2_keras: -82.6799 - rmse: 0.8664 - sae: 1881.8191 - sse: 2289.6829 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3748e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5523 - learning_rate: 1.0000e-05\n","Epoch 509/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.3086e-16 - r2_keras: -100.7267 - rmse: 0.8777 - sae: 2575.4897 - sse: 3155.4341\n","Epoch 509: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.7392e-16 - r2_keras: -82.6800 - rmse: 0.8664 - sae: 1881.8206 - sse: 2289.6875 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.7910e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5525 - learning_rate: 1.0000e-05\n","Epoch 510/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 5.7981e-16 - r2_keras: -100.7266 - rmse: 0.8777 - sae: 2575.4888 - sse: 3155.4312\n","Epoch 510: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.6435e-16 - r2_keras: -82.6800 - rmse: 0.8664 - sae: 1881.8198 - sse: 2289.6853 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.2124e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5510 - learning_rate: 1.0000e-05\n","Epoch 511/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 4.0199e-16 - r2_keras: -100.7267 - rmse: 0.8777 - sae: 2575.4893 - sse: 3155.4343\n","Epoch 511: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.0576e-16 - r2_keras: -82.6800 - rmse: 0.8664 - sae: 1881.8202 - sse: 2289.6875 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5520 - learning_rate: 1.0000e-05\n","Epoch 512/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.4135e-16 - r2_keras: -100.7269 - rmse: 0.8777 - sae: 2575.4924 - sse: 3155.4412\n","Epoch 512: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.0066e-16 - r2_keras: -82.6802 - rmse: 0.8664 - sae: 1881.8226 - sse: 2289.6929 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 513/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.5333e-16 - r2_keras: -100.7270 - rmse: 0.8777 - sae: 2575.4932 - sse: 3155.4438\n","Epoch 513: val_loss did not improve from 0.19064\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 4.8403e-17 - r2_keras: -82.6803 - rmse: 0.8664 - sae: 1881.8231 - sse: 2289.6946 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.1606e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5522 - learning_rate: 1.0000e-05\n","Epoch 514/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.8860e-16 - r2_keras: -100.7272 - rmse: 0.8777 - sae: 2575.4951 - sse: 3155.4502\n","Epoch 514: val_loss improved from 0.19064 to 0.19064, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.4131e-16 - r2_keras: -82.6805 - rmse: 0.8664 - sae: 1881.8246 - sse: 2289.6995 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5524 - learning_rate: 1.0000e-05\n","Epoch 515/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.8830e-16 - r2_keras: -100.7271 - rmse: 0.8777 - sae: 2575.4941 - sse: 3155.4473\n","Epoch 515: val_loss improved from 0.19064 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.0211e-16 - r2_keras: -82.6804 - rmse: 0.8664 - sae: 1881.8239 - sse: 2289.6973 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5518 - learning_rate: 1.0000e-05\n","Epoch 516/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.1650e-16 - r2_keras: -100.7273 - rmse: 0.8777 - sae: 2575.4966 - sse: 3155.4546\n","Epoch 516: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 5.6322e-16 - r2_keras: -82.6806 - rmse: 0.8664 - sae: 1881.8256 - sse: 2289.7024 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5518 - learning_rate: 1.0000e-05\n","Epoch 517/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.7457e-16 - r2_keras: -100.7274 - rmse: 0.8777 - sae: 2575.4978 - sse: 3155.4570\n","Epoch 517: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.7397e-16 - r2_keras: -82.6807 - rmse: 0.8664 - sae: 1881.8265 - sse: 2289.7046 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.2124e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6272 - val_sse: 506.5513 - learning_rate: 1.0000e-05\n","Epoch 518/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.1631e-16 - r2_keras: -100.7275 - rmse: 0.8777 - sae: 2575.4988 - sse: 3155.4609\n","Epoch 518: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 7.9192e-17 - r2_keras: -82.6808 - rmse: 0.8664 - sae: 1881.8273 - sse: 2289.7073 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.1606e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 519/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.5359e-16 - r2_keras: -100.7274 - rmse: 0.8777 - sae: 2575.4976 - sse: 3155.4578\n","Epoch 519: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.4564e-16 - r2_keras: -82.6807 - rmse: 0.8664 - sae: 1881.8264 - sse: 2289.7051 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.8964e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5518 - learning_rate: 1.0000e-05\n","Epoch 520/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 6.8212e-17 - r2_keras: -100.7277 - rmse: 0.8777 - sae: 2575.5000 - sse: 3155.4648\n","Epoch 520: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.9311e-18 - r2_keras: -82.6809 - rmse: 0.8664 - sae: 1881.8281 - sse: 2289.7102 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5518 - learning_rate: 1.0000e-05\n","Epoch 521/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 6.6579e-16 - r2_keras: -100.7278 - rmse: 0.8777 - sae: 2575.5015 - sse: 3155.4683\n","Epoch 521: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 4.0137e-16 - r2_keras: -82.6810 - rmse: 0.8664 - sae: 1881.8292 - sse: 2289.7126 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4283e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.5519 - learning_rate: 1.0000e-05\n","Epoch 522/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.5710e-16 - r2_keras: -100.7280 - rmse: 0.8777 - sae: 2575.5039 - sse: 3155.4744\n","Epoch 522: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.9123e-16 - r2_keras: -82.6811 - rmse: 0.8664 - sae: 1881.8311 - sse: 2289.7173 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5505 - learning_rate: 1.0000e-05\n","Epoch 523/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.7489e-16 - r2_keras: -100.7280 - rmse: 0.8777 - sae: 2575.5039 - sse: 3155.4766\n","Epoch 523: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.7759e-16 - r2_keras: -82.6812 - rmse: 0.8664 - sae: 1881.8311 - sse: 2289.7188 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.0017e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6269 - val_sse: 506.5508 - learning_rate: 1.0000e-05\n","Epoch 524/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -5.7222e-16 - r2_keras: -100.7279 - rmse: 0.8777 - sae: 2575.5027 - sse: 3155.4731\n","Epoch 524: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.3380e-16 - r2_keras: -82.6811 - rmse: 0.8664 - sae: 1881.8302 - sse: 2289.7166 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.7910e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5520 - learning_rate: 1.0000e-05\n","Epoch 525/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.0753e-16 - r2_keras: -100.7282 - rmse: 0.8777 - sae: 2575.5066 - sse: 3155.4827\n","Epoch 525: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.6167e-16 - r2_keras: -82.6814 - rmse: 0.8664 - sae: 1881.8329 - sse: 2289.7231 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6269 - val_sse: 506.5511 - learning_rate: 1.0000e-05\n","Epoch 526/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 8.4010e-16 - r2_keras: -100.7283 - rmse: 0.8777 - sae: 2575.5073 - sse: 3155.4856\n","Epoch 526: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 6.0917e-16 - r2_keras: -82.6814 - rmse: 0.8664 - sae: 1881.8335 - sse: 2289.7253 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6272 - val_sse: 506.5519 - learning_rate: 1.0000e-05\n","Epoch 527/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.3817e-16 - r2_keras: -100.7285 - rmse: 0.8777 - sae: 2575.5093 - sse: 3155.4917\n","Epoch 527: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.3224e-16 - r2_keras: -82.6816 - rmse: 0.8664 - sae: 1881.8350 - sse: 2289.7300 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.3713e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5500 - learning_rate: 1.0000e-05\n","Epoch 528/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -8.8033e-17 - r2_keras: -100.7286 - rmse: 0.8777 - sae: 2575.5093 - sse: 3155.4932\n","Epoch 528: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -7.9932e-17 - r2_keras: -82.6817 - rmse: 0.8664 - sae: 1881.8351 - sse: 2289.7310 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.5820e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6269 - val_sse: 506.5512 - learning_rate: 1.0000e-05\n","Epoch 529/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.3407e-16 - r2_keras: -100.7285 - rmse: 0.8777 - sae: 2575.5085 - sse: 3155.4895\n","Epoch 529: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.3433e-16 - r2_keras: -82.6816 - rmse: 0.8664 - sae: 1881.8345 - sse: 2289.7283 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2142e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6262 - val_sse: 506.5499 - learning_rate: 1.0000e-05\n","Epoch 530/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.6703e-16 - r2_keras: -100.7287 - rmse: 0.8777 - sae: 2575.5112 - sse: 3155.4980\n","Epoch 530: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.6092e-16 - r2_keras: -82.6818 - rmse: 0.8664 - sae: 1881.8363 - sse: 2289.7344 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.6857e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6265 - val_sse: 506.5509 - learning_rate: 1.0000e-05\n","Epoch 531/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -4.2442e-16 - r2_keras: -100.7289 - rmse: 0.8777 - sae: 2575.5127 - sse: 3155.5020\n","Epoch 531: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.5132e-16 - r2_keras: -82.6819 - rmse: 0.8664 - sae: 1881.8375 - sse: 2289.7375 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.4750e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6267 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 532/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 7.4740e-16 - r2_keras: -100.7290 - rmse: 0.8777 - sae: 2575.5142 - sse: 3155.5073\n","Epoch 532: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 5.1668e-16 - r2_keras: -82.6821 - rmse: 0.8664 - sae: 1881.8386 - sse: 2289.7415 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5498 - learning_rate: 1.0000e-05\n","Epoch 533/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.7197e-16 - r2_keras: -100.7288 - rmse: 0.8777 - sae: 2575.5122 - sse: 3155.5002\n","Epoch 533: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.2238e-16 - r2_keras: -82.6819 - rmse: 0.8664 - sae: 1881.8372 - sse: 2289.7363 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6264 - val_sse: 506.5506 - learning_rate: 1.0000e-05\n","Epoch 534/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.4078e-16 - r2_keras: -100.7291 - rmse: 0.8777 - sae: 2575.5154 - sse: 3155.5090\n","Epoch 534: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 9.9148e-17 - r2_keras: -82.6821 - rmse: 0.8664 - sae: 1881.8395 - sse: 2289.7427 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 7.3748e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5500 - learning_rate: 1.0000e-05\n","Epoch 535/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -5.0779e-16 - r2_keras: -100.7292 - rmse: 0.8777 - sae: 2575.5156 - sse: 3155.5117\n","Epoch 535: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.5741e-16 - r2_keras: -82.6821 - rmse: 0.8664 - sae: 1881.8396 - sse: 2289.7444 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4284e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6258 - val_sse: 506.5499 - learning_rate: 1.0000e-05\n","Epoch 536/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.5158e-16 - r2_keras: -100.7293 - rmse: 0.8777 - sae: 2575.5171 - sse: 3155.5156\n","Epoch 536: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.4212e-16 - r2_keras: -82.6823 - rmse: 0.8664 - sae: 1881.8408 - sse: 2289.7478 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5507 - learning_rate: 1.0000e-05\n","Epoch 537/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -3.0374e-16 - r2_keras: -100.7295 - rmse: 0.8777 - sae: 2575.5195 - sse: 3155.5227\n","Epoch 537: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.2177e-16 - r2_keras: -82.6825 - rmse: 0.8664 - sae: 1881.8425 - sse: 2289.7527 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 7.3748e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6260 - val_sse: 506.5502 - learning_rate: 1.0000e-05\n","Epoch 538/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -6.6957e-16 - r2_keras: -100.7294 - rmse: 0.8777 - sae: 2575.5188 - sse: 3155.5190\n","Epoch 538: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -4.2986e-16 - r2_keras: -82.6824 - rmse: 0.8664 - sae: 1881.8419 - sse: 2289.7500 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1071e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6260 - val_sse: 506.5503 - learning_rate: 1.0000e-05\n","Epoch 539/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 6.5208e-16 - r2_keras: -100.7296 - rmse: 0.8777 - sae: 2575.5210 - sse: 3155.5254\n","Epoch 539: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 4.3991e-16 - r2_keras: -82.6825 - rmse: 0.8664 - sae: 1881.8436 - sse: 2289.7546 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3213e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6254 - val_sse: 506.5496 - learning_rate: 1.0000e-05\n","Epoch 540/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 3.9556e-16 - r2_keras: -100.7297 - rmse: 0.8777 - sae: 2575.5215 - sse: 3155.5281\n","Epoch 540: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.9203e-16 - r2_keras: -82.6826 - rmse: 0.8664 - sae: 1881.8439 - sse: 2289.7566 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.5285e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6253 - val_sse: 506.5494 - learning_rate: 1.0000e-05\n","Epoch 541/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.9967e-16 - r2_keras: -100.7298 - rmse: 0.8777 - sae: 2575.5227 - sse: 3155.5322\n","Epoch 541: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.2934e-16 - r2_keras: -82.6827 - rmse: 0.8664 - sae: 1881.8450 - sse: 2289.7600 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.6339e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5509 - learning_rate: 1.0000e-05\n","Epoch 542/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -6.0019e-16 - r2_keras: -100.7300 - rmse: 0.8777 - sae: 2575.5251 - sse: 3155.5386\n","Epoch 542: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.4914e-16 - r2_keras: -82.6829 - rmse: 0.8664 - sae: 1881.8468 - sse: 2289.7646 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.3178e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5499 - learning_rate: 1.0000e-05\n","Epoch 543/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.6499e-16 - r2_keras: -100.7300 - rmse: 0.8777 - sae: 2575.5247 - sse: 3155.5376\n","Epoch 543: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.7750e-16 - r2_keras: -82.6829 - rmse: 0.8664 - sae: 1881.8463 - sse: 2289.7637 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.3178e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6260 - val_sse: 506.5505 - learning_rate: 1.0000e-05\n","Epoch 544/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -9.5610e-17 - r2_keras: -100.7301 - rmse: 0.8777 - sae: 2575.5261 - sse: 3155.5417\n","Epoch 544: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -2.1726e-17 - r2_keras: -82.6830 - rmse: 0.8664 - sae: 1881.8474 - sse: 2289.7668 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1071e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9785 - val_sae: 367.6250 - val_sse: 506.5493 - learning_rate: 1.0000e-05\n","Epoch 545/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.8712e-16 - r2_keras: -100.7302 - rmse: 0.8777 - sae: 2575.5261 - sse: 3155.5439\n","Epoch 545: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.1691e-16 - r2_keras: -82.6830 - rmse: 0.8664 - sae: 1881.8474 - sse: 2289.7683 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5498 - learning_rate: 1.0000e-05\n","Epoch 546/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -2.8275e-17 - r2_keras: -100.7304 - rmse: 0.8777 - sae: 2575.5298 - sse: 3155.5508\n","Epoch 546: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 3.7798e-17 - r2_keras: -82.6832 - rmse: 0.8664 - sae: 1881.8501 - sse: 2289.7734 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -9.4819e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5504 - learning_rate: 1.0000e-05\n","Epoch 547/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 5.3051e-17 - r2_keras: -100.7306 - rmse: 0.8777 - sae: 2575.5312 - sse: 3155.5564\n","Epoch 547: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -1.5615e-17 - r2_keras: -82.6834 - rmse: 0.8664 - sae: 1881.8512 - sse: 2289.7776 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2677e-17 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6253 - val_sse: 506.5497 - learning_rate: 1.0000e-05\n","Epoch 548/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 2.1075e-16 - r2_keras: -100.7305 - rmse: 0.8777 - sae: 2575.5298 - sse: 3155.5518\n","Epoch 548: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.5277e-16 - r2_keras: -82.6833 - rmse: 0.8664 - sae: 1881.8501 - sse: 2289.7742 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.1589e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5505 - learning_rate: 1.0000e-05\n","Epoch 549/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: 1.1426e-16 - r2_keras: -100.7307 - rmse: 0.8777 - sae: 2575.5317 - sse: 3155.5581\n","Epoch 549: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 6.2015e-17 - r2_keras: -82.6835 - rmse: 0.8664 - sae: 1881.8517 - sse: 2289.7791 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.2124e-16 - val_r2_keras: -35.1096 - val_rmse: 0.9786 - val_sae: 367.6250 - val_sse: 506.5497 - learning_rate: 1.0000e-05\n","Epoch 550/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2265 - mse: 0.1386 - pearson_correlation: -1.3409e-16 - r2_keras: -100.7307 - rmse: 0.8777 - sae: 2575.5322 - sse: 3155.5601\n","Epoch 550: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -6.8620e-17 - r2_keras: -82.6835 - rmse: 0.8664 - sae: 1881.8521 - sse: 2289.7805 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5507 - learning_rate: 1.0000e-05\n","Epoch 551/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 2.9470e-16 - r2_keras: -100.7310 - rmse: 0.8777 - sae: 2575.5347 - sse: 3155.5676\n","Epoch 551: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 2.3565e-16 - r2_keras: -82.6837 - rmse: 0.8664 - sae: 1881.8539 - sse: 2289.7861 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5511 - learning_rate: 1.0000e-05\n","Epoch 552/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 9.0945e-17 - r2_keras: -100.7311 - rmse: 0.8777 - sae: 2575.5369 - sse: 3155.5730\n","Epoch 552: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -5.1720e-17 - r2_keras: -82.6839 - rmse: 0.8664 - sae: 1881.8555 - sse: 2289.7903 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.0553e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6252 - val_sse: 506.5503 - learning_rate: 1.0000e-05\n","Epoch 553/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 1.4516e-16 - r2_keras: -100.7310 - rmse: 0.8777 - sae: 2575.5349 - sse: 3155.5684\n","Epoch 553: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 9.5359e-17 - r2_keras: -82.6838 - rmse: 0.8664 - sae: 1881.8541 - sse: 2289.7869 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.8964e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5519 - learning_rate: 1.0000e-05\n","Epoch 554/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -4.6988e-16 - r2_keras: -100.7312 - rmse: 0.8777 - sae: 2575.5371 - sse: 3155.5747\n","Epoch 554: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: -3.3025e-16 - r2_keras: -82.6839 - rmse: 0.8664 - sae: 1881.8558 - sse: 2289.7917 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.7392e-16 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6252 - val_sse: 506.5510 - learning_rate: 1.0000e-05\n","Epoch 555/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 2.4951e-16 - r2_keras: -100.7314 - rmse: 0.8777 - sae: 2575.5386 - sse: 3155.5793\n","Epoch 555: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2176 - mse: 0.1279 - pearson_correlation: 1.0120e-16 - r2_keras: -82.6841 - rmse: 0.8664 - sae: 1881.8568 - sse: 2289.7949 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1071e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6251 - val_sse: 506.5508 - learning_rate: 1.0000e-05\n","Epoch 556/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 4.3228e-16 - r2_keras: -100.7314 - rmse: 0.8777 - sae: 2575.5388 - sse: 3155.5806\n","Epoch 556: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 2.8110e-16 - r2_keras: -82.6841 - rmse: 0.8664 - sae: 1881.8572 - sse: 2289.7964 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5515 - learning_rate: 1.0000e-05\n","Epoch 557/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 1.3875e-16 - r2_keras: -100.7314 - rmse: 0.8777 - sae: 2575.5396 - sse: 3155.5815\n","Epoch 557: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.0005e-16 - r2_keras: -82.6842 - rmse: 0.8664 - sae: 1881.8577 - sse: 2289.7969 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2142e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6251 - val_sse: 506.5508 - learning_rate: 1.0000e-05\n","Epoch 558/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 6.1795e-17 - r2_keras: -100.7316 - rmse: 0.8777 - sae: 2575.5410 - sse: 3155.5876\n","Epoch 558: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 7.8961e-17 - r2_keras: -82.6843 - rmse: 0.8664 - sae: 1881.8588 - sse: 2289.8013 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6258 - val_sse: 506.5525 - learning_rate: 1.0000e-05\n","Epoch 559/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -1.9967e-16 - r2_keras: -100.7317 - rmse: 0.8777 - sae: 2575.5425 - sse: 3155.5906\n","Epoch 559: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -6.2304e-17 - r2_keras: -82.6844 - rmse: 0.8664 - sae: 1881.8599 - sse: 2289.8037 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6252 - val_sse: 506.5516 - learning_rate: 1.0000e-05\n","Epoch 560/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -1.0668e-16 - r2_keras: -100.7318 - rmse: 0.8777 - sae: 2575.5435 - sse: 3155.5947\n","Epoch 560: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -3.3359e-17 - r2_keras: -82.6845 - rmse: 0.8664 - sae: 1881.8606 - sse: 2289.8069 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.3178e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5523 - learning_rate: 1.0000e-05\n","Epoch 561/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -2.8332e-16 - r2_keras: -100.7321 - rmse: 0.8777 - sae: 2575.5459 - sse: 3155.6021\n","Epoch 561: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.5726e-16 - r2_keras: -82.6847 - rmse: 0.8664 - sae: 1881.8624 - sse: 2289.8123 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1097 - val_rmse: 0.9786 - val_sae: 367.6249 - val_sse: 506.5511 - learning_rate: 1.0000e-05\n","Epoch 562/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 8.6193e-16 - r2_keras: -100.7319 - rmse: 0.8777 - sae: 2575.5444 - sse: 3155.5977\n","Epoch 562: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 6.1333e-16 - r2_keras: -82.6846 - rmse: 0.8664 - sae: 1881.8613 - sse: 2289.8088 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3748e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6253 - val_sse: 506.5518 - learning_rate: 1.0000e-05\n","Epoch 563/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -1.7489e-18 - r2_keras: -100.7320 - rmse: 0.8777 - sae: 2575.5452 - sse: 3155.6001\n","Epoch 563: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.1943e-18 - r2_keras: -82.6847 - rmse: 0.8664 - sae: 1881.8619 - sse: 2289.8110 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6253 - val_sse: 506.5525 - learning_rate: 1.0000e-05\n","Epoch 564/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -3.3871e-16 - r2_keras: -100.7322 - rmse: 0.8777 - sae: 2575.5469 - sse: 3155.6060\n","Epoch 564: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.3808e-16 - r2_keras: -82.6849 - rmse: 0.8664 - sae: 1881.8634 - sse: 2289.8154 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.1606e-17 - val_r2_keras: -35.1098 - val_rmse: 0.9786 - val_sae: 367.6251 - val_sse: 506.5522 - learning_rate: 1.0000e-05\n","Epoch 565/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -2.0841e-16 - r2_keras: -100.7324 - rmse: 0.8777 - sae: 2575.5488 - sse: 3155.6116\n","Epoch 565: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.5593e-16 - r2_keras: -82.6850 - rmse: 0.8664 - sae: 1881.8647 - sse: 2289.8196 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.2124e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5531 - learning_rate: 1.0000e-05\n","Epoch 566/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 9.2109e-17 - r2_keras: -100.7327 - rmse: 0.8777 - sae: 2575.5522 - sse: 3155.6206\n","Epoch 566: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 6.1878e-17 - r2_keras: -82.6853 - rmse: 0.8664 - sae: 1881.8673 - sse: 2289.8262 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.6857e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6257 - val_sse: 506.5533 - learning_rate: 1.0000e-05\n","Epoch 567/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: 7.6981e-16 - r2_keras: -100.7326 - rmse: 0.8777 - sae: 2575.5510 - sse: 3155.6169\n","Epoch 567: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 4.9432e-16 - r2_keras: -82.6852 - rmse: 0.8664 - sae: 1881.8663 - sse: 2289.8232 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.2642e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5530 - learning_rate: 1.0000e-05\n","Epoch 568/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -2.6263e-16 - r2_keras: -100.7327 - rmse: 0.8777 - sae: 2575.5522 - sse: 3155.6199\n","Epoch 568: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.1230e-16 - r2_keras: -82.6853 - rmse: 0.8664 - sae: 1881.8673 - sse: 2289.8259 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5533 - learning_rate: 1.0000e-05\n","Epoch 569/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1386 - pearson_correlation: -3.5124e-16 - r2_keras: -100.7327 - rmse: 0.8777 - sae: 2575.5527 - sse: 3155.6226\n","Epoch 569: val_loss improved from 0.19063 to 0.19063, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1511 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.3274e-16 - r2_keras: -82.6854 - rmse: 0.8664 - sae: 1881.8678 - sse: 2289.8281 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6254 - val_sse: 506.5535 - learning_rate: 1.0000e-05\n","Epoch 570/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.5536e-16 - r2_keras: -100.7329 - rmse: 0.8777 - sae: 2575.5542 - sse: 3155.6279\n","Epoch 570: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -7.9499e-17 - r2_keras: -82.6855 - rmse: 0.8664 - sae: 1881.8689 - sse: 2289.8320 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.4231e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5537 - learning_rate: 1.0000e-05\n","Epoch 571/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.8738e-16 - r2_keras: -100.7331 - rmse: 0.8777 - sae: 2575.5562 - sse: 3155.6323\n","Epoch 571: val_loss did not improve from 0.19063\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.7848e-16 - r2_keras: -82.6856 - rmse: 0.8664 - sae: 1881.8705 - sse: 2289.8354 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.1606e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6258 - val_sse: 506.5540 - learning_rate: 1.0000e-05\n","Epoch 572/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.0985e-16 - r2_keras: -100.7330 - rmse: 0.8777 - sae: 2575.5552 - sse: 3155.6294\n","Epoch 572: val_loss improved from 0.19063 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.6786e-16 - r2_keras: -82.6856 - rmse: 0.8664 - sae: 1881.8698 - sse: 2289.8333 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6257 - val_sse: 506.5541 - learning_rate: 1.0000e-05\n","Epoch 573/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.4106e-16 - r2_keras: -100.7331 - rmse: 0.8777 - sae: 2575.5569 - sse: 3155.6350\n","Epoch 573: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.2766e-16 - r2_keras: -82.6857 - rmse: 0.8664 - sae: 1881.8710 - sse: 2289.8374 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 5.2677e-17 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6254 - val_sse: 506.5540 - learning_rate: 1.0000e-05\n","Epoch 574/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.2204e-16 - r2_keras: -100.7333 - rmse: 0.8777 - sae: 2575.5576 - sse: 3155.6384\n","Epoch 574: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.9563e-16 - r2_keras: -82.6858 - rmse: 0.8664 - sae: 1881.8716 - sse: 2289.8403 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.6338e-16 - val_r2_keras: -35.1099 - val_rmse: 0.9786 - val_sae: 367.6254 - val_sse: 506.5542 - learning_rate: 1.0000e-05\n","Epoch 575/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.2096e-16 - r2_keras: -100.7334 - rmse: 0.8777 - sae: 2575.5596 - sse: 3155.6440\n","Epoch 575: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -9.2444e-17 - r2_keras: -82.6860 - rmse: 0.8664 - sae: 1881.8730 - sse: 2289.8442 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.5285e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6255 - val_sse: 506.5545 - learning_rate: 1.0000e-05\n","Epoch 576/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.3027e-16 - r2_keras: -100.7336 - rmse: 0.8777 - sae: 2575.5608 - sse: 3155.6479\n","Epoch 576: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.1299e-16 - r2_keras: -82.6861 - rmse: 0.8664 - sae: 1881.8741 - sse: 2289.8474 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5551 - learning_rate: 1.0000e-05\n","Epoch 577/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.1659e-16 - r2_keras: -100.7335 - rmse: 0.8777 - sae: 2575.5610 - sse: 3155.6460\n","Epoch 577: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -8.3865e-17 - r2_keras: -82.6861 - rmse: 0.8664 - sae: 1881.8741 - sse: 2289.8459 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1071e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6257 - val_sse: 506.5549 - learning_rate: 1.0000e-05\n","Epoch 578/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.7984e-16 - r2_keras: -100.7337 - rmse: 0.8777 - sae: 2575.5625 - sse: 3155.6519\n","Epoch 578: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.7418e-16 - r2_keras: -82.6862 - rmse: 0.8664 - sae: 1881.8752 - sse: 2289.8501 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4282e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6262 - val_sse: 506.5557 - learning_rate: 1.0000e-05\n","Epoch 579/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -7.6659e-16 - r2_keras: -100.7338 - rmse: 0.8777 - sae: 2575.5645 - sse: 3155.6567\n","Epoch 579: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -4.9501e-16 - r2_keras: -82.6864 - rmse: 0.8664 - sae: 1881.8768 - sse: 2289.8540 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.8964e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6252 - val_sse: 506.5546 - learning_rate: 1.0000e-05\n","Epoch 580/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -9.3273e-17 - r2_keras: -100.7339 - rmse: 0.8777 - sae: 2575.5645 - sse: 3155.6592\n","Epoch 580: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -7.8982e-18 - r2_keras: -82.6864 - rmse: 0.8664 - sae: 1881.8768 - sse: 2289.8560 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6254 - val_sse: 506.5551 - learning_rate: 1.0000e-05\n","Epoch 581/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.3991e-16 - r2_keras: -100.7341 - rmse: 0.8777 - sae: 2575.5659 - sse: 3155.6631\n","Epoch 581: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 9.7993e-17 - r2_keras: -82.6866 - rmse: 0.8664 - sae: 1881.8781 - sse: 2289.8591 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6260 - val_sse: 506.5558 - learning_rate: 1.0000e-05\n","Epoch 582/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.1213e-16 - r2_keras: -100.7341 - rmse: 0.8777 - sae: 2575.5662 - sse: 3155.6631\n","Epoch 582: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 3.0554e-16 - r2_keras: -82.6866 - rmse: 0.8664 - sae: 1881.8782 - sse: 2289.8589 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5563 - learning_rate: 1.0000e-05\n","Epoch 583/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 7.9399e-16 - r2_keras: -100.7342 - rmse: 0.8777 - sae: 2575.5684 - sse: 3155.6685\n","Epoch 583: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 5.1469e-16 - r2_keras: -82.6867 - rmse: 0.8664 - sae: 1881.8798 - sse: 2289.8628 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.8964e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6262 - val_sse: 506.5567 - learning_rate: 1.0000e-05\n","Epoch 584/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.2096e-16 - r2_keras: -100.7344 - rmse: 0.8777 - sae: 2575.5693 - sse: 3155.6729\n","Epoch 584: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.1038e-16 - r2_keras: -82.6868 - rmse: 0.8664 - sae: 1881.8805 - sse: 2289.8662 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 8.4283e-17 - val_r2_keras: -35.1100 - val_rmse: 0.9786 - val_sae: 367.6252 - val_sse: 506.5551 - learning_rate: 1.0000e-05\n","Epoch 585/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.1999e-16 - r2_keras: -100.7344 - rmse: 0.8777 - sae: 2575.5693 - sse: 3155.6743\n","Epoch 585: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -3.7829e-16 - r2_keras: -82.6869 - rmse: 0.8664 - sae: 1881.8806 - sse: 2289.8677 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5562 - learning_rate: 1.0000e-05\n","Epoch 586/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 7.8086e-16 - r2_keras: -100.7346 - rmse: 0.8777 - sae: 2575.5713 - sse: 3155.6799\n","Epoch 586: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 4.4316e-16 - r2_keras: -82.6871 - rmse: 0.8664 - sae: 1881.8821 - sse: 2289.8718 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.9499e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6263 - val_sse: 506.5570 - learning_rate: 1.0000e-05\n","Epoch 587/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.7712e-17 - r2_keras: -100.7345 - rmse: 0.8777 - sae: 2575.5703 - sse: 3155.6758\n","Epoch 587: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 2.8090e-17 - r2_keras: -82.6870 - rmse: 0.8664 - sae: 1881.8815 - sse: 2289.8689 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.5820e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6258 - val_sse: 506.5565 - learning_rate: 1.0000e-05\n","Epoch 588/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 8.2837e-16 - r2_keras: -100.7347 - rmse: 0.8777 - sae: 2575.5728 - sse: 3155.6836\n","Epoch 588: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 5.5461e-16 - r2_keras: -82.6871 - rmse: 0.8664 - sae: 1881.8832 - sse: 2289.8745 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 6.3212e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5573 - learning_rate: 1.0000e-05\n","Epoch 589/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.9529e-17 - r2_keras: -100.7348 - rmse: 0.8777 - sae: 2575.5742 - sse: 3155.6875\n","Epoch 589: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 3.5017e-18 - r2_keras: -82.6873 - rmse: 0.8664 - sae: 1881.8844 - sse: 2289.8777 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3747e-17 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5566 - learning_rate: 1.0000e-05\n","Epoch 590/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.8594e-16 - r2_keras: -100.7350 - rmse: 0.8777 - sae: 2575.5757 - sse: 3155.6929\n","Epoch 590: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.8638e-16 - r2_keras: -82.6874 - rmse: 0.8664 - sae: 1881.8855 - sse: 2289.8816 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5585 - learning_rate: 1.0000e-05\n","Epoch 591/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -7.6366e-17 - r2_keras: -100.7352 - rmse: 0.8777 - sae: 2575.5781 - sse: 3155.6992\n","Epoch 591: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -8.4288e-18 - r2_keras: -82.6876 - rmse: 0.8664 - sae: 1881.8873 - sse: 2289.8865 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1101 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5565 - learning_rate: 1.0000e-05\n","Epoch 592/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.8975e-16 - r2_keras: -100.7350 - rmse: 0.8777 - sae: 2575.5757 - sse: 3155.6931\n","Epoch 592: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.3972e-16 - r2_keras: -82.6874 - rmse: 0.8664 - sae: 1881.8855 - sse: 2289.8818 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -5.2676e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5572 - learning_rate: 1.0000e-05\n","Epoch 593/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.3196e-16 - r2_keras: -100.7351 - rmse: 0.8777 - sae: 2575.5771 - sse: 3155.6970\n","Epoch 593: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 3.0922e-16 - r2_keras: -82.6876 - rmse: 0.8664 - sae: 1881.8866 - sse: 2289.8850 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.6856e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5580 - learning_rate: 1.0000e-05\n","Epoch 594/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.6437e-16 - r2_keras: -100.7354 - rmse: 0.8777 - sae: 2575.5796 - sse: 3155.7046\n","Epoch 594: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 2.0032e-16 - r2_keras: -82.6878 - rmse: 0.8664 - sae: 1881.8885 - sse: 2289.8904 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3747e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6260 - val_sse: 506.5579 - learning_rate: 1.0000e-05\n","Epoch 595/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.3485e-16 - r2_keras: -100.7355 - rmse: 0.8777 - sae: 2575.5806 - sse: 3155.7073\n","Epoch 595: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 3.8253e-16 - r2_keras: -82.6879 - rmse: 0.8664 - sae: 1881.8893 - sse: 2289.8926 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5585 - learning_rate: 1.0000e-05\n","Epoch 596/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -7.9718e-16 - r2_keras: -100.7357 - rmse: 0.8777 - sae: 2575.5825 - sse: 3155.7129\n","Epoch 596: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -5.9848e-16 - r2_keras: -82.6880 - rmse: 0.8664 - sae: 1881.8907 - sse: 2289.8970 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -8.4282e-17 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6256 - val_sse: 506.5573 - learning_rate: 1.0000e-05\n","Epoch 597/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -8.2079e-16 - r2_keras: -100.7355 - rmse: 0.8777 - sae: 2575.5801 - sse: 3155.7065\n","Epoch 597: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -6.1139e-16 - r2_keras: -82.6879 - rmse: 0.8664 - sae: 1881.8889 - sse: 2289.8921 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1102 - val_rmse: 0.9786 - val_sae: 367.6258 - val_sse: 506.5579 - learning_rate: 1.0000e-05\n","Epoch 598/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.9346e-16 - r2_keras: -100.7357 - rmse: 0.8777 - sae: 2575.5823 - sse: 3155.7129\n","Epoch 598: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 2.6808e-16 - r2_keras: -82.6880 - rmse: 0.8664 - sae: 1881.8906 - sse: 2289.8970 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.7409e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6264 - val_sse: 506.5590 - learning_rate: 1.0000e-05\n","Epoch 599/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.9608e-16 - r2_keras: -100.7358 - rmse: 0.8777 - sae: 2575.5840 - sse: 3155.7180\n","Epoch 599: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 3.0051e-16 - r2_keras: -82.6882 - rmse: 0.8664 - sae: 1881.8920 - sse: 2289.9009 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.0017e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5587 - learning_rate: 1.0000e-05\n","Epoch 600/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.1217e-16 - r2_keras: -100.7360 - rmse: 0.8777 - sae: 2575.5854 - sse: 3155.7234\n","Epoch 600: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.2935e-16 - r2_keras: -82.6883 - rmse: 0.8664 - sae: 1881.8931 - sse: 2289.9048 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.0552e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6264 - val_sse: 506.5593 - learning_rate: 1.0000e-05\n","Epoch 601/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.7107e-17 - r2_keras: -100.7362 - rmse: 0.8777 - sae: 2575.5884 - sse: 3155.7295\n","Epoch 601: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 4.4032e-17 - r2_keras: -82.6885 - rmse: 0.8664 - sae: 1881.8953 - sse: 2289.9097 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 9.4817e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6260 - val_sse: 506.5588 - learning_rate: 1.0000e-05\n","Epoch 602/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.1744e-16 - r2_keras: -100.7361 - rmse: 0.8777 - sae: 2575.5864 - sse: 3155.7251\n","Epoch 602: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.4590e-16 - r2_keras: -82.6884 - rmse: 0.8664 - sae: 1881.8937 - sse: 2289.9060 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.3177e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 603/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.2790e-16 - r2_keras: -100.7362 - rmse: 0.8777 - sae: 2575.5889 - sse: 3155.7310\n","Epoch 603: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.7187e-16 - r2_keras: -82.6886 - rmse: 0.8664 - sae: 1881.8956 - sse: 2289.9106 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6263 - val_sse: 506.5595 - learning_rate: 1.0000e-05\n","Epoch 604/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 8.1466e-16 - r2_keras: -100.7363 - rmse: 0.8777 - sae: 2575.5891 - sse: 3155.7334\n","Epoch 604: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 6.1013e-16 - r2_keras: -82.6887 - rmse: 0.8664 - sae: 1881.8959 - sse: 2289.9128 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1070e-16 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5592 - learning_rate: 1.0000e-05\n","Epoch 605/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.9899e-16 - r2_keras: -100.7365 - rmse: 0.8777 - sae: 2575.5908 - sse: 3155.7390\n","Epoch 605: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 3.3880e-16 - r2_keras: -82.6888 - rmse: 0.8664 - sae: 1881.8972 - sse: 2289.9170 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -9.4817e-17 - val_r2_keras: -35.1103 - val_rmse: 0.9786 - val_sae: 367.6263 - val_sse: 506.5598 - learning_rate: 1.0000e-05\n","Epoch 606/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.3524e-16 - r2_keras: -100.7367 - rmse: 0.8778 - sae: 2575.5930 - sse: 3155.7441\n","Epoch 606: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -9.3465e-17 - r2_keras: -82.6890 - rmse: 0.8665 - sae: 1881.8988 - sse: 2289.9207 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5609 - learning_rate: 1.0000e-05\n","Epoch 607/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.0284e-16 - r2_keras: -100.7365 - rmse: 0.8777 - sae: 2575.5918 - sse: 3155.7397\n","Epoch 607: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.9481e-16 - r2_keras: -82.6889 - rmse: 0.8664 - sae: 1881.8979 - sse: 2289.9177 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5605 - learning_rate: 1.0000e-05\n","Epoch 608/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.6497e-16 - r2_keras: -100.7367 - rmse: 0.8778 - sae: 2575.5933 - sse: 3155.7456\n","Epoch 608: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.4113e-16 - r2_keras: -82.6890 - rmse: 0.8665 - sae: 1881.8990 - sse: 2289.9219 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6263 - val_sse: 506.5602 - learning_rate: 1.0000e-05\n","Epoch 609/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 6.3074e-16 - r2_keras: -100.7368 - rmse: 0.8778 - sae: 2575.5938 - sse: 3155.7480\n","Epoch 609: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 4.5967e-16 - r2_keras: -82.6891 - rmse: 0.8665 - sae: 1881.8995 - sse: 2289.9241 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.1606e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5600 - learning_rate: 1.0000e-05\n","Epoch 610/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.4102e-16 - r2_keras: -100.7370 - rmse: 0.8778 - sae: 2575.5955 - sse: 3155.7537\n","Epoch 610: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.6558e-16 - r2_keras: -82.6893 - rmse: 0.8665 - sae: 1881.9008 - sse: 2289.9282 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1070e-16 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6263 - val_sse: 506.5604 - learning_rate: 1.0000e-05\n","Epoch 611/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.3346e-16 - r2_keras: -100.7372 - rmse: 0.8778 - sae: 2575.5979 - sse: 3155.7593\n","Epoch 611: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.2119e-16 - r2_keras: -82.6894 - rmse: 0.8665 - sae: 1881.9026 - sse: 2289.9324 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5619 - learning_rate: 1.0000e-05\n","Epoch 612/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 7.2867e-18 - r2_keras: -100.7370 - rmse: 0.8778 - sae: 2575.5967 - sse: 3155.7554\n","Epoch 612: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 9.5778e-18 - r2_keras: -82.6893 - rmse: 0.8665 - sae: 1881.9017 - sse: 2289.9297 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5614 - learning_rate: 1.0000e-05\n","Epoch 613/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.1277e-16 - r2_keras: -100.7372 - rmse: 0.8778 - sae: 2575.5984 - sse: 3155.7617\n","Epoch 613: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.7772e-16 - r2_keras: -82.6895 - rmse: 0.8665 - sae: 1881.9031 - sse: 2289.9343 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.2642e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6268 - val_sse: 506.5619 - learning_rate: 1.0000e-05\n","Epoch 614/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.7922e-16 - r2_keras: -100.7374 - rmse: 0.8778 - sae: 2575.6001 - sse: 3155.7666\n","Epoch 614: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -8.9389e-17 - r2_keras: -82.6896 - rmse: 0.8665 - sae: 1881.9044 - sse: 2289.9380 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.1606e-17 - val_r2_keras: -35.1104 - val_rmse: 0.9786 - val_sae: 367.6259 - val_sse: 506.5607 - learning_rate: 1.0000e-05\n","Epoch 615/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.4446e-16 - r2_keras: -100.7375 - rmse: 0.8778 - sae: 2575.6003 - sse: 3155.7690\n","Epoch 615: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -3.4173e-16 - r2_keras: -82.6897 - rmse: 0.8665 - sae: 1881.9047 - sse: 2289.9399 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2141e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6269 - val_sse: 506.5624 - learning_rate: 1.0000e-05\n","Epoch 616/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.4250e-16 - r2_keras: -100.7377 - rmse: 0.8778 - sae: 2575.6030 - sse: 3155.7754\n","Epoch 616: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.8857e-16 - r2_keras: -82.6899 - rmse: 0.8665 - sae: 1881.9066 - sse: 2289.9446 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6271 - val_sse: 506.5626 - learning_rate: 1.0000e-05\n","Epoch 617/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.7809e-16 - r2_keras: -100.7375 - rmse: 0.8778 - sae: 2575.6021 - sse: 3155.7710\n","Epoch 617: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.0315e-16 - r2_keras: -82.6898 - rmse: 0.8665 - sae: 1881.9059 - sse: 2289.9417 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.1605e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5620 - learning_rate: 1.0000e-05\n","Epoch 618/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -4.6401e-16 - r2_keras: -100.7377 - rmse: 0.8778 - sae: 2575.6033 - sse: 3155.7769\n","Epoch 618: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -3.4521e-16 - r2_keras: -82.6899 - rmse: 0.8665 - sae: 1881.9069 - sse: 2289.9458 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.7910e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6267 - val_sse: 506.5625 - learning_rate: 1.0000e-05\n","Epoch 619/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.0834e-16 - r2_keras: -100.7379 - rmse: 0.8778 - sae: 2575.6050 - sse: 3155.7822\n","Epoch 619: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 2.6373e-16 - r2_keras: -82.6901 - rmse: 0.8665 - sae: 1881.9081 - sse: 2289.9500 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.5803e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6267 - val_sse: 506.5625 - learning_rate: 1.0000e-05\n","Epoch 620/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.7459e-16 - r2_keras: -100.7381 - rmse: 0.8778 - sae: 2575.6069 - sse: 3155.7876\n","Epoch 620: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.2772e-16 - r2_keras: -82.6903 - rmse: 0.8665 - sae: 1881.9095 - sse: 2289.9539 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -6.4264e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6267 - val_sse: 506.5627 - learning_rate: 1.0000e-05\n","Epoch 621/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.0172e-16 - r2_keras: -100.7381 - rmse: 0.8778 - sae: 2575.6074 - sse: 3155.7891\n","Epoch 621: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.7826e-16 - r2_keras: -82.6903 - rmse: 0.8665 - sae: 1881.9100 - sse: 2289.9551 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -8.4281e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5628 - learning_rate: 1.0000e-05\n","Epoch 622/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -6.6687e-16 - r2_keras: -100.7379 - rmse: 0.8778 - sae: 2575.6062 - sse: 3155.7839\n","Epoch 622: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -4.2570e-16 - r2_keras: -82.6902 - rmse: 0.8665 - sae: 1881.9092 - sse: 2289.9517 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 9.4816e-17 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6263 - val_sse: 506.5622 - learning_rate: 1.0000e-05\n","Epoch 623/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 9.0936e-16 - r2_keras: -100.7381 - rmse: 0.8778 - sae: 2575.6079 - sse: 3155.7900\n","Epoch 623: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 5.9067e-16 - r2_keras: -82.6904 - rmse: 0.8665 - sae: 1881.9105 - sse: 2289.9561 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -4.2140e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6271 - val_sse: 506.5638 - learning_rate: 1.0000e-05\n","Epoch 624/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.2737e-16 - r2_keras: -100.7384 - rmse: 0.8778 - sae: 2575.6104 - sse: 3155.7983\n","Epoch 624: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.7223e-16 - r2_keras: -82.6906 - rmse: 0.8665 - sae: 1881.9122 - sse: 2289.9622 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.8445e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6265 - val_sse: 506.5630 - learning_rate: 1.0000e-05\n","Epoch 625/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 6.7910e-17 - r2_keras: -100.7386 - rmse: 0.8778 - sae: 2575.6121 - sse: 3155.8027\n","Epoch 625: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 2.9698e-17 - r2_keras: -82.6907 - rmse: 0.8665 - sae: 1881.9136 - sse: 2289.9656 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2140e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6273 - val_sse: 506.5640 - learning_rate: 1.0000e-05\n","Epoch 626/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.7222e-16 - r2_keras: -100.7385 - rmse: 0.8778 - sae: 2575.6113 - sse: 3155.7998\n","Epoch 626: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -1.3806e-16 - r2_keras: -82.6906 - rmse: 0.8665 - sae: 1881.9130 - sse: 2289.9631 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2141e-16 - val_r2_keras: -35.1105 - val_rmse: 0.9786 - val_sae: 367.6261 - val_sse: 506.5620 - learning_rate: 1.0000e-05\n","Epoch 627/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.5821e-16 - r2_keras: -100.7385 - rmse: 0.8778 - sae: 2575.6108 - sse: 3155.7998\n","Epoch 627: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.6423e-16 - r2_keras: -82.6906 - rmse: 0.8665 - sae: 1881.9127 - sse: 2289.9636 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -7.3746e-17 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6269 - val_sse: 506.5638 - learning_rate: 1.0000e-05\n","Epoch 628/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.9761e-16 - r2_keras: -100.7387 - rmse: 0.8778 - sae: 2575.6133 - sse: 3155.8064\n","Epoch 628: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 1.4779e-16 - r2_keras: -82.6908 - rmse: 0.8665 - sae: 1881.9147 - sse: 2289.9685 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.6873e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5644 - learning_rate: 1.0000e-05\n","Epoch 629/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.3774e-16 - r2_keras: -100.7389 - rmse: 0.8778 - sae: 2575.6152 - sse: 3155.8125\n","Epoch 629: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -4.0711e-16 - r2_keras: -82.6910 - rmse: 0.8665 - sae: 1881.9161 - sse: 2289.9731 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 367.6266 - val_sse: 506.5639 - learning_rate: 1.0000e-05\n","Epoch 630/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 6.1440e-16 - r2_keras: -100.7390 - rmse: 0.8778 - sae: 2575.6169 - sse: 3155.8167\n","Epoch 630: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: 4.5632e-16 - r2_keras: -82.6911 - rmse: 0.8665 - sae: 1881.9174 - sse: 2289.9763 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5645 - learning_rate: 1.0000e-05\n","Epoch 631/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.1915e-16 - r2_keras: -100.7392 - rmse: 0.8778 - sae: 2575.6189 - sse: 3155.8223\n","Epoch 631: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -2.3023e-16 - r2_keras: -82.6913 - rmse: 0.8665 - sae: 1881.9188 - sse: 2289.9805 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.1589e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5646 - learning_rate: 1.0000e-05\n","Epoch 632/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.2734e-17 - r2_keras: -100.7391 - rmse: 0.8778 - sae: 2575.6174 - sse: 3155.8188\n","Epoch 632: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1279 - pearson_correlation: -3.6291e-17 - r2_keras: -82.6912 - rmse: 0.8665 - sae: 1881.9177 - sse: 2289.9778 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.1605e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6268 - val_sse: 506.5642 - learning_rate: 1.0000e-05\n","Epoch 633/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.0781e-16 - r2_keras: -100.7392 - rmse: 0.8778 - sae: 2575.6187 - sse: 3155.8218\n","Epoch 633: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.8999e-16 - r2_keras: -82.6913 - rmse: 0.8665 - sae: 1881.9187 - sse: 2289.9802 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 4.2140e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5649 - learning_rate: 1.0000e-05\n","Epoch 634/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.8554e-16 - r2_keras: -100.7393 - rmse: 0.8778 - sae: 2575.6201 - sse: 3155.8271\n","Epoch 634: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.3891e-16 - r2_keras: -82.6915 - rmse: 0.8665 - sae: 1881.9198 - sse: 2289.9844 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -3.1605e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6268 - val_sse: 506.5648 - learning_rate: 1.0000e-05\n","Epoch 635/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.7222e-16 - r2_keras: -100.7396 - rmse: 0.8778 - sae: 2575.6226 - sse: 3155.8342\n","Epoch 635: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.7393e-16 - r2_keras: -82.6916 - rmse: 0.8665 - sae: 1881.9216 - sse: 2289.9895 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.3696e-16 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5658 - learning_rate: 1.0000e-05\n","Epoch 636/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.7575e-16 - r2_keras: -100.7397 - rmse: 0.8778 - sae: 2575.6235 - sse: 3155.8369\n","Epoch 636: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 9.9230e-17 - r2_keras: -82.6917 - rmse: 0.8665 - sae: 1881.9225 - sse: 2289.9919 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: 3.2659e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5653 - learning_rate: 1.0000e-05\n","Epoch 637/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -6.9950e-18 - r2_keras: -100.7396 - rmse: 0.8778 - sae: 2575.6221 - sse: 3155.8340\n","Epoch 637: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.2549e-16 - r2_keras: -82.6916 - rmse: 0.8665 - sae: 1881.9213 - sse: 2289.9893 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.4749e-16 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5653 - learning_rate: 1.0000e-05\n","Epoch 638/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.6659e-16 - r2_keras: -100.7398 - rmse: 0.8778 - sae: 2575.6245 - sse: 3155.8398\n","Epoch 638: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.7301e-16 - r2_keras: -82.6918 - rmse: 0.8665 - sae: 1881.9232 - sse: 2289.9939 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -1.8963e-16 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6270 - val_sse: 506.5657 - learning_rate: 1.0000e-05\n","Epoch 639/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 7.1902e-16 - r2_keras: -100.7398 - rmse: 0.8778 - sae: 2575.6245 - sse: 3155.8408\n","Epoch 639: val_loss improved from 0.19062 to 0.19062, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 4.5905e-16 - r2_keras: -82.6919 - rmse: 0.8665 - sae: 1881.9233 - sse: 2289.9951 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.0017e-16 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6273 - val_sse: 506.5662 - learning_rate: 1.0000e-05\n","Epoch 640/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -4.7303e-16 - r2_keras: -100.7400 - rmse: 0.8778 - sae: 2575.6267 - sse: 3155.8467\n","Epoch 640: val_loss did not improve from 0.19062\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -3.3518e-16 - r2_keras: -82.6920 - rmse: 0.8665 - sae: 1881.9249 - sse: 2289.9993 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2205 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5665 - learning_rate: 1.0000e-05\n","Epoch 641/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.9285e-16 - r2_keras: -100.7401 - rmse: 0.8778 - sae: 2575.6284 - sse: 3155.8521\n","Epoch 641: val_loss improved from 0.19062 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.5689e-16 - r2_keras: -82.6922 - rmse: 0.8665 - sae: 1881.9263 - sse: 2290.0034 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 5.2675e-17 - val_r2_keras: -35.1107 - val_rmse: 0.9786 - val_sae: 367.6267 - val_sse: 506.5655 - learning_rate: 1.0000e-05\n","Epoch 642/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.1588e-16 - r2_keras: -100.7400 - rmse: 0.8778 - sae: 2575.6270 - sse: 3155.8477\n","Epoch 642: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.4439e-16 - r2_keras: -82.6921 - rmse: 0.8665 - sae: 1881.9252 - sse: 2290.0000 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.2124e-16 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6273 - val_sse: 506.5666 - learning_rate: 1.0000e-05\n","Epoch 643/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.7779e-16 - r2_keras: -100.7403 - rmse: 0.8778 - sae: 2575.6296 - sse: 3155.8564\n","Epoch 643: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.2938e-16 - r2_keras: -82.6923 - rmse: 0.8665 - sae: 1881.9271 - sse: 2290.0066 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -8.4280e-17 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5677 - learning_rate: 1.0000e-05\n","Epoch 644/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.8498e-16 - r2_keras: -100.7404 - rmse: 0.8778 - sae: 2575.6316 - sse: 3155.8604\n","Epoch 644: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.2190e-16 - r2_keras: -82.6924 - rmse: 0.8665 - sae: 1881.9287 - sse: 2290.0098 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1070e-17 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6271 - val_sse: 506.5667 - learning_rate: 1.0000e-05\n","Epoch 645/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.1512e-16 - r2_keras: -100.7406 - rmse: 0.8778 - sae: 2575.6323 - sse: 3155.8647\n","Epoch 645: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.1309e-16 - r2_keras: -82.6925 - rmse: 0.8665 - sae: 1881.9292 - sse: 2290.0127 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5670 - learning_rate: 1.0000e-05\n","Epoch 646/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.7779e-16 - r2_keras: -100.7403 - rmse: 0.8778 - sae: 2575.6299 - sse: 3155.8574\n","Epoch 646: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.4684e-16 - r2_keras: -82.6924 - rmse: 0.8665 - sae: 1881.9275 - sse: 2290.0076 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.5284e-16 - val_r2_keras: -35.1108 - val_rmse: 0.9786 - val_sae: 367.6267 - val_sse: 506.5659 - learning_rate: 1.0000e-05\n","Epoch 647/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.1879e-16 - r2_keras: -100.7405 - rmse: 0.8778 - sae: 2575.6321 - sse: 3155.8638\n","Epoch 647: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 4.1618e-16 - r2_keras: -82.6925 - rmse: 0.8665 - sae: 1881.9291 - sse: 2290.0122 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1605e-16 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5675 - learning_rate: 1.0000e-05\n","Epoch 648/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.1710e-16 - r2_keras: -100.7407 - rmse: 0.8778 - sae: 2575.6343 - sse: 3155.8704\n","Epoch 648: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.1659e-16 - r2_keras: -82.6927 - rmse: 0.8665 - sae: 1881.9308 - sse: 2290.0173 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4815e-17 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5680 - learning_rate: 1.0000e-05\n","Epoch 649/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.7707e-16 - r2_keras: -100.7409 - rmse: 0.8778 - sae: 2575.6367 - sse: 3155.8765\n","Epoch 649: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 4.2106e-16 - r2_keras: -82.6929 - rmse: 0.8665 - sae: 1881.9326 - sse: 2290.0220 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -5.2675e-17 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6273 - val_sse: 506.5677 - learning_rate: 1.0000e-05\n","Epoch 650/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.4190e-16 - r2_keras: -100.7411 - rmse: 0.8778 - sae: 2575.6377 - sse: 3155.8809\n","Epoch 650: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.2782e-16 - r2_keras: -82.6930 - rmse: 0.8665 - sae: 1881.9332 - sse: 2290.0249 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6272 - val_sse: 506.5677 - learning_rate: 1.0000e-05\n","Epoch 651/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -4.4709e-16 - r2_keras: -100.7411 - rmse: 0.8778 - sae: 2575.6377 - sse: 3155.8804\n","Epoch 651: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.6832e-16 - r2_keras: -82.6930 - rmse: 0.8665 - sae: 1881.9335 - sse: 2290.0251 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4815e-17 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6273 - val_sse: 506.5677 - learning_rate: 1.0000e-05\n","Epoch 652/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.7999e-17 - r2_keras: -100.7410 - rmse: 0.8778 - sae: 2575.6367 - sse: 3155.8774\n","Epoch 652: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.8524e-18 - r2_keras: -82.6930 - rmse: 0.8665 - sae: 1881.9327 - sse: 2290.0229 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.4230e-16 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5682 - learning_rate: 1.0000e-05\n","Epoch 653/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.0894e-17 - r2_keras: -100.7412 - rmse: 0.8778 - sae: 2575.6394 - sse: 3155.8848\n","Epoch 653: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.4844e-17 - r2_keras: -82.6932 - rmse: 0.8665 - sae: 1881.9347 - sse: 2290.0283 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5691 - learning_rate: 1.0000e-05\n","Epoch 654/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.8070e-16 - r2_keras: -100.7414 - rmse: 0.8778 - sae: 2575.6418 - sse: 3155.8911\n","Epoch 654: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.6058e-16 - r2_keras: -82.6933 - rmse: 0.8665 - sae: 1881.9365 - sse: 2290.0330 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.6337e-16 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5683 - learning_rate: 1.0000e-05\n","Epoch 655/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.2752e-17 - r2_keras: -100.7415 - rmse: 0.8778 - sae: 2575.6421 - sse: 3155.8936\n","Epoch 655: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -8.8972e-17 - r2_keras: -82.6934 - rmse: 0.8665 - sae: 1881.9368 - sse: 2290.0349 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5695 - learning_rate: 1.0000e-05\n","Epoch 656/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.8381e-17 - r2_keras: -100.7417 - rmse: 0.8778 - sae: 2575.6445 - sse: 3155.8999\n","Epoch 656: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -4.2788e-17 - r2_keras: -82.6936 - rmse: 0.8665 - sae: 1881.9386 - sse: 2290.0398 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3745e-17 - val_r2_keras: -35.1109 - val_rmse: 0.9786 - val_sae: 367.6271 - val_sse: 506.5682 - learning_rate: 1.0000e-05\n","Epoch 657/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.6023e-16 - r2_keras: -100.7415 - rmse: 0.8778 - sae: 2575.6418 - sse: 3155.8936\n","Epoch 657: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.2930e-16 - r2_keras: -82.6934 - rmse: 0.8665 - sae: 1881.9366 - sse: 2290.0352 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -8.4280e-17 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5687 - learning_rate: 1.0000e-05\n","Epoch 658/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.6405e-16 - r2_keras: -100.7417 - rmse: 0.8778 - sae: 2575.6445 - sse: 3155.9004\n","Epoch 658: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.2082e-16 - r2_keras: -82.6936 - rmse: 0.8665 - sae: 1881.9386 - sse: 2290.0400 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.5284e-16 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6278 - val_sse: 506.5697 - learning_rate: 1.0000e-05\n","Epoch 659/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.9786e-16 - r2_keras: -100.7419 - rmse: 0.8778 - sae: 2575.6462 - sse: 3155.9055\n","Epoch 659: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.9008e-16 - r2_keras: -82.6938 - rmse: 0.8665 - sae: 1881.9401 - sse: 2290.0442 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.7909e-16 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6272 - val_sse: 506.5688 - learning_rate: 1.0000e-05\n","Epoch 660/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 7.3445e-16 - r2_keras: -100.7420 - rmse: 0.8778 - sae: 2575.6472 - sse: 3155.9089\n","Epoch 660: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 4.6556e-16 - r2_keras: -82.6939 - rmse: 0.8665 - sae: 1881.9407 - sse: 2290.0466 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2123e-16 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5705 - learning_rate: 1.0000e-05\n","Epoch 661/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.1162e-16 - r2_keras: -100.7422 - rmse: 0.8778 - sae: 2575.6492 - sse: 3155.9146\n","Epoch 661: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 6.2617e-17 - r2_keras: -82.6940 - rmse: 0.8665 - sae: 1881.9423 - sse: 2290.0510 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6269 - val_sse: 506.5685 - learning_rate: 1.0000e-05\n","Epoch 662/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -7.3066e-16 - r2_keras: -100.7419 - rmse: 0.8778 - sae: 2575.6462 - sse: 3155.9070\n","Epoch 662: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -4.3991e-16 - r2_keras: -82.6938 - rmse: 0.8665 - sae: 1881.9401 - sse: 2290.0454 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1110 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5695 - learning_rate: 1.0000e-05\n","Epoch 663/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -5.7969e-16 - r2_keras: -100.7422 - rmse: 0.8778 - sae: 2575.6489 - sse: 3155.9150\n","Epoch 663: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -4.2941e-16 - r2_keras: -82.6941 - rmse: 0.8665 - sae: 1881.9421 - sse: 2290.0515 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -5.2675e-17 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5703 - learning_rate: 1.0000e-05\n","Epoch 664/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.1884e-16 - r2_keras: -100.7424 - rmse: 0.8778 - sae: 2575.6514 - sse: 3155.9214\n","Epoch 664: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.1445e-16 - r2_keras: -82.6942 - rmse: 0.8665 - sae: 1881.9440 - sse: 2290.0562 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.5284e-16 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.5703 - learning_rate: 1.0000e-05\n","Epoch 665/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.6165e-16 - r2_keras: -100.7425 - rmse: 0.8778 - sae: 2575.6519 - sse: 3155.9241\n","Epoch 665: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.5874e-16 - r2_keras: -82.6943 - rmse: 0.8665 - sae: 1881.9443 - sse: 2290.0581 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4814e-17 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5706 - learning_rate: 1.0000e-05\n","Epoch 666/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.2176e-16 - r2_keras: -100.7426 - rmse: 0.8778 - sae: 2575.6538 - sse: 3155.9287\n","Epoch 666: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.7397e-16 - r2_keras: -82.6945 - rmse: 0.8665 - sae: 1881.9459 - sse: 2290.0620 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3745e-17 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5703 - learning_rate: 1.0000e-05\n","Epoch 667/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.6871e-16 - r2_keras: -100.7425 - rmse: 0.8778 - sae: 2575.6519 - sse: 3155.9246\n","Epoch 667: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.6829e-16 - r2_keras: -82.6944 - rmse: 0.8665 - sae: 1881.9445 - sse: 2290.0588 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5711 - learning_rate: 1.0000e-05\n","Epoch 668/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 6.0621e-17 - r2_keras: -100.7428 - rmse: 0.8778 - sae: 2575.6558 - sse: 3155.9336\n","Epoch 668: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 8.3361e-17 - r2_keras: -82.6946 - rmse: 0.8665 - sae: 1881.9473 - sse: 2290.0654 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3744e-17 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5714 - learning_rate: 1.0000e-05\n","Epoch 669/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.0055e-16 - r2_keras: -100.7428 - rmse: 0.8778 - sae: 2575.6560 - sse: 3155.9351\n","Epoch 669: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.0054e-16 - r2_keras: -82.6947 - rmse: 0.8665 - sae: 1881.9476 - sse: 2290.0669 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.3712e-16 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5707 - learning_rate: 1.0000e-05\n","Epoch 670/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.1389e-16 - r2_keras: -100.7429 - rmse: 0.8778 - sae: 2575.6562 - sse: 3155.9377\n","Epoch 670: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.1681e-16 - r2_keras: -82.6947 - rmse: 0.8665 - sae: 1881.9478 - sse: 2290.0688 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2140e-17 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5709 - learning_rate: 1.0000e-05\n","Epoch 671/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 6.9597e-16 - r2_keras: -100.7428 - rmse: 0.8778 - sae: 2575.6558 - sse: 3155.9346\n","Epoch 671: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 4.2339e-16 - r2_keras: -82.6947 - rmse: 0.8665 - sae: 1881.9475 - sse: 2290.0667 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6274 - val_sse: 506.5707 - learning_rate: 1.0000e-05\n","Epoch 672/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.4310e-16 - r2_keras: -100.7430 - rmse: 0.8778 - sae: 2575.6572 - sse: 3155.9399\n","Epoch 672: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.1758e-16 - r2_keras: -82.6948 - rmse: 0.8665 - sae: 1881.9486 - sse: 2290.0706 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.5802e-16 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5721 - learning_rate: 1.0000e-05\n","Epoch 673/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 3.0485e-16 - r2_keras: -100.7432 - rmse: 0.8778 - sae: 2575.6599 - sse: 3155.9473\n","Epoch 673: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.6836e-16 - r2_keras: -82.6950 - rmse: 0.8665 - sae: 1881.9506 - sse: 2290.0759 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.4230e-16 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5724 - learning_rate: 1.0000e-05\n","Epoch 674/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -8.4751e-16 - r2_keras: -100.7434 - rmse: 0.8778 - sae: 2575.6616 - sse: 3155.9526\n","Epoch 674: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -5.6831e-16 - r2_keras: -82.6952 - rmse: 0.8665 - sae: 1881.9518 - sse: 2290.0801 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.6856e-16 - val_r2_keras: -35.1111 - val_rmse: 0.9786 - val_sae: 367.6272 - val_sse: 506.5709 - learning_rate: 1.0000e-05\n","Epoch 675/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.2324e-16 - r2_keras: -100.7434 - rmse: 0.8778 - sae: 2575.6611 - sse: 3155.9524\n","Epoch 675: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.2099e-16 - r2_keras: -82.6952 - rmse: 0.8665 - sae: 1881.9515 - sse: 2290.0801 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5719 - learning_rate: 1.0000e-05\n","Epoch 676/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.1512e-16 - r2_keras: -100.7433 - rmse: 0.8778 - sae: 2575.6606 - sse: 3155.9502\n","Epoch 676: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.7103e-17 - r2_keras: -82.6951 - rmse: 0.8665 - sae: 1881.9513 - sse: 2290.0786 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.5717 - learning_rate: 1.0000e-05\n","Epoch 677/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 4.4940e-16 - r2_keras: -100.7434 - rmse: 0.8778 - sae: 2575.6616 - sse: 3155.9541\n","Epoch 677: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 2.8686e-16 - r2_keras: -82.6952 - rmse: 0.8665 - sae: 1881.9520 - sse: 2290.0813 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.6872e-16 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5726 - learning_rate: 1.0000e-05\n","Epoch 678/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 9.7050e-17 - r2_keras: -100.7437 - rmse: 0.8778 - sae: 2575.6648 - sse: 3155.9617\n","Epoch 678: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 7.5083e-17 - r2_keras: -82.6954 - rmse: 0.8665 - sae: 1881.9543 - sse: 2290.0869 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3744e-17 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5727 - learning_rate: 1.0000e-05\n","Epoch 679/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -4.6456e-16 - r2_keras: -100.7438 - rmse: 0.8778 - sae: 2575.6665 - sse: 3155.9668\n","Epoch 679: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.8894e-16 - r2_keras: -82.6956 - rmse: 0.8665 - sae: 1881.9557 - sse: 2290.0911 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.6856e-16 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5719 - learning_rate: 1.0000e-05\n","Epoch 680/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -8.4809e-17 - r2_keras: -100.7439 - rmse: 0.8778 - sae: 2575.6660 - sse: 3155.9670\n","Epoch 680: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.6424e-17 - r2_keras: -82.6956 - rmse: 0.8665 - sae: 1881.9553 - sse: 2290.0913 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5733 - learning_rate: 1.0000e-05\n","Epoch 681/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.4539e-16 - r2_keras: -100.7440 - rmse: 0.8778 - sae: 2575.6682 - sse: 3155.9731\n","Epoch 681: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.5652e-16 - r2_keras: -82.6958 - rmse: 0.8665 - sae: 1881.9570 - sse: 2290.0959 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1112 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.5722 - learning_rate: 1.0000e-05\n","Epoch 682/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.0754e-16 - r2_keras: -100.7439 - rmse: 0.8778 - sae: 2575.6665 - sse: 3155.9678\n","Epoch 682: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 5.6120e-17 - r2_keras: -82.6956 - rmse: 0.8665 - sae: 1881.9557 - sse: 2290.0918 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3744e-17 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5732 - learning_rate: 1.0000e-05\n","Epoch 683/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -3.0281e-16 - r2_keras: -100.7441 - rmse: 0.8778 - sae: 2575.6694 - sse: 3155.9761\n","Epoch 683: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.9290e-16 - r2_keras: -82.6959 - rmse: 0.8665 - sae: 1881.9579 - sse: 2290.0981 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5736 - learning_rate: 1.0000e-05\n","Epoch 684/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.4397e-16 - r2_keras: -100.7443 - rmse: 0.8778 - sae: 2575.6711 - sse: 3155.9812\n","Epoch 684: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 6.3889e-17 - r2_keras: -82.6960 - rmse: 0.8665 - sae: 1881.9592 - sse: 2290.1021 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3744e-17 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5736 - learning_rate: 1.0000e-05\n","Epoch 685/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 5.7588e-16 - r2_keras: -100.7444 - rmse: 0.8778 - sae: 2575.6719 - sse: 3155.9839\n","Epoch 685: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.5891e-16 - r2_keras: -82.6961 - rmse: 0.8665 - sae: 1881.9598 - sse: 2290.1040 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4814e-17 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5735 - learning_rate: 1.0000e-05\n","Epoch 686/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.1508e-16 - r2_keras: -100.7442 - rmse: 0.8778 - sae: 2575.6694 - sse: 3155.9771\n","Epoch 686: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.5755e-16 - r2_keras: -82.6960 - rmse: 0.8665 - sae: 1881.9581 - sse: 2290.0994 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.3177e-16 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.5729 - learning_rate: 1.0000e-05\n","Epoch 687/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -8.4809e-17 - r2_keras: -100.7444 - rmse: 0.8778 - sae: 2575.6719 - sse: 3155.9846\n","Epoch 687: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -5.5699e-18 - r2_keras: -82.6961 - rmse: 0.8665 - sae: 1881.9598 - sse: 2290.1045 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4814e-17 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5736 - learning_rate: 1.0000e-05\n","Epoch 688/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -4.1442e-16 - r2_keras: -100.7446 - rmse: 0.8778 - sae: 2575.6733 - sse: 3155.9893\n","Epoch 688: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.1776e-16 - r2_keras: -82.6963 - rmse: 0.8665 - sae: 1881.9611 - sse: 2290.1084 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2139e-17 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5749 - learning_rate: 1.0000e-05\n","Epoch 689/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -7.3413e-16 - r2_keras: -100.7447 - rmse: 0.8778 - sae: 2575.6755 - sse: 3155.9944\n","Epoch 689: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -4.2524e-16 - r2_keras: -82.6964 - rmse: 0.8665 - sae: 1881.9626 - sse: 2290.1121 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3744e-17 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5740 - learning_rate: 1.0000e-05\n","Epoch 690/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 2.5064e-17 - r2_keras: -100.7448 - rmse: 0.8778 - sae: 2575.6760 - sse: 3155.9976\n","Epoch 690: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 3.0395e-17 - r2_keras: -82.6965 - rmse: 0.8665 - sae: 1881.9631 - sse: 2290.1147 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3177e-16 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5744 - learning_rate: 1.0000e-05\n","Epoch 691/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -2.9435e-16 - r2_keras: -100.7447 - rmse: 0.8778 - sae: 2575.6753 - sse: 3155.9946\n","Epoch 691: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.8873e-16 - r2_keras: -82.6965 - rmse: 0.8665 - sae: 1881.9626 - sse: 2290.1125 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3744e-17 - val_r2_keras: -35.1113 - val_rmse: 0.9786 - val_sae: 367.6275 - val_sse: 506.5735 - learning_rate: 1.0000e-05\n","Epoch 692/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.5679e-16 - r2_keras: -100.7449 - rmse: 0.8778 - sae: 2575.6768 - sse: 3156.0000\n","Epoch 692: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.6352e-16 - r2_keras: -82.6966 - rmse: 0.8665 - sae: 1881.9636 - sse: 2290.1165 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.5802e-16 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5747 - learning_rate: 1.0000e-05\n","Epoch 693/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: 1.9410e-16 - r2_keras: -100.7451 - rmse: 0.8778 - sae: 2575.6787 - sse: 3156.0044\n","Epoch 693: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 7.5598e-17 - r2_keras: -82.6967 - rmse: 0.8665 - sae: 1881.9652 - sse: 2290.1199 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.4749e-16 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5752 - learning_rate: 1.0000e-05\n","Epoch 694/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2264 - mse: 0.1385 - pearson_correlation: -1.9235e-17 - r2_keras: -100.7453 - rmse: 0.8778 - sae: 2575.6804 - sse: 3156.0105\n","Epoch 694: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -4.1611e-17 - r2_keras: -82.6969 - rmse: 0.8665 - sae: 1881.9664 - sse: 2290.1245 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4813e-17 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5747 - learning_rate: 1.0000e-05\n","Epoch 695/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.0484e-16 - r2_keras: -100.7453 - rmse: 0.8778 - sae: 2575.6809 - sse: 3156.0127\n","Epoch 695: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: 1.9190e-16 - r2_keras: -82.6970 - rmse: 0.8665 - sae: 1881.9669 - sse: 2290.1262 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5750 - learning_rate: 1.0000e-05\n","Epoch 696/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -4.1063e-16 - r2_keras: -100.7452 - rmse: 0.8778 - sae: 2575.6804 - sse: 3156.0098\n","Epoch 696: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.4355e-16 - r2_keras: -82.6969 - rmse: 0.8665 - sae: 1881.9666 - sse: 2290.1240 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.7909e-16 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5753 - learning_rate: 1.0000e-05\n","Epoch 697/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -2.6433e-16 - r2_keras: -100.7454 - rmse: 0.8778 - sae: 2575.6826 - sse: 3156.0161\n","Epoch 697: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -2.7957e-16 - r2_keras: -82.6971 - rmse: 0.8665 - sae: 1881.9681 - sse: 2290.1287 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1114 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5750 - learning_rate: 1.0000e-05\n","Epoch 698/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.8389e-16 - r2_keras: -100.7455 - rmse: 0.8778 - sae: 2575.6831 - sse: 3156.0188\n","Epoch 698: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -1.0136e-16 - r2_keras: -82.6972 - rmse: 0.8665 - sae: 1881.9686 - sse: 2290.1309 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1070e-17 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5758 - learning_rate: 1.0000e-05\n","Epoch 699/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.7777e-17 - r2_keras: -100.7456 - rmse: 0.8778 - sae: 2575.6843 - sse: 3156.0227\n","Epoch 699: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2175 - mse: 0.1278 - pearson_correlation: -3.7336e-17 - r2_keras: -82.6973 - rmse: 0.8665 - sae: 1881.9696 - sse: 2290.1340 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 5.2674e-17 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6278 - val_sse: 506.5755 - learning_rate: 1.0000e-05\n","Epoch 700/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -5.9744e-17 - r2_keras: -100.7458 - rmse: 0.8778 - sae: 2575.6855 - sse: 3156.0259\n","Epoch 700: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -8.2774e-17 - r2_keras: -82.6974 - rmse: 0.8665 - sae: 1881.9706 - sse: 2290.1365 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4813e-17 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5763 - learning_rate: 1.0000e-05\n","Epoch 701/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.7777e-16 - r2_keras: -100.7457 - rmse: 0.8778 - sae: 2575.6855 - sse: 3156.0249\n","Epoch 701: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.0813e-16 - r2_keras: -82.6974 - rmse: 0.8665 - sae: 1881.9705 - sse: 2290.1355 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3744e-17 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5758 - learning_rate: 1.0000e-05\n","Epoch 702/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.5446e-17 - r2_keras: -100.7459 - rmse: 0.8778 - sae: 2575.6875 - sse: 3156.0312\n","Epoch 702: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.5871e-17 - r2_keras: -82.6975 - rmse: 0.8665 - sae: 1881.9718 - sse: 2290.1401 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2139e-17 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5764 - learning_rate: 1.0000e-05\n","Epoch 703/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -2.0954e-16 - r2_keras: -100.7460 - rmse: 0.8778 - sae: 2575.6882 - sse: 3156.0347\n","Epoch 703: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.5385e-16 - r2_keras: -82.6976 - rmse: 0.8665 - sae: 1881.9725 - sse: 2290.1428 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3177e-16 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5761 - learning_rate: 1.0000e-05\n","Epoch 704/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.1657e-18 - r2_keras: -100.7461 - rmse: 0.8778 - sae: 2575.6887 - sse: 3156.0361\n","Epoch 704: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -7.8644e-17 - r2_keras: -82.6977 - rmse: 0.8665 - sae: 1881.9730 - sse: 2290.1445 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5766 - learning_rate: 1.0000e-05\n","Epoch 705/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.6229e-17 - r2_keras: -100.7462 - rmse: 0.8778 - sae: 2575.6904 - sse: 3156.0410\n","Epoch 705: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 7.5060e-17 - r2_keras: -82.6978 - rmse: 0.8665 - sae: 1881.9742 - sse: 2290.1477 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.0016e-16 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5768 - learning_rate: 1.0000e-05\n","Epoch 706/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 1.6320e-17 - r2_keras: -100.7461 - rmse: 0.8778 - sae: 2575.6892 - sse: 3156.0376\n","Epoch 706: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 7.2230e-17 - r2_keras: -82.6978 - rmse: 0.8665 - sae: 1881.9735 - sse: 2290.1455 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.4230e-16 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5761 - learning_rate: 1.0000e-05\n","Epoch 707/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.8964e-16 - r2_keras: -100.7463 - rmse: 0.8778 - sae: 2575.6914 - sse: 3156.0442\n","Epoch 707: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.9044e-16 - r2_keras: -82.6979 - rmse: 0.8665 - sae: 1881.9750 - sse: 2290.1501 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.3176e-16 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5767 - learning_rate: 1.0000e-05\n","Epoch 708/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.6433e-16 - r2_keras: -100.7465 - rmse: 0.8778 - sae: 2575.6934 - sse: 3156.0498\n","Epoch 708: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.1539e-16 - r2_keras: -82.6981 - rmse: 0.8665 - sae: 1881.9766 - sse: 2290.1545 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 8.4278e-17 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5776 - learning_rate: 1.0000e-05\n","Epoch 709/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.7074e-16 - r2_keras: -100.7467 - rmse: 0.8778 - sae: 2575.6951 - sse: 3156.0542\n","Epoch 709: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.9087e-16 - r2_keras: -82.6982 - rmse: 0.8665 - sae: 1881.9778 - sse: 2290.1580 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.5818e-16 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5768 - learning_rate: 1.0000e-05\n","Epoch 710/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 4.4880e-17 - r2_keras: -100.7467 - rmse: 0.8778 - sae: 2575.6943 - sse: 3156.0540\n","Epoch 710: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.1608e-17 - r2_keras: -82.6982 - rmse: 0.8665 - sae: 1881.9774 - sse: 2290.1580 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5775 - learning_rate: 1.0000e-05\n","Epoch 711/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -6.1492e-17 - r2_keras: -100.7466 - rmse: 0.8778 - sae: 2575.6938 - sse: 3156.0527\n","Epoch 711: val_loss improved from 0.19061 to 0.19061, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 5.1973e-17 - r2_keras: -82.6982 - rmse: 0.8665 - sae: 1881.9771 - sse: 2290.1570 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.3711e-16 - val_r2_keras: -35.1115 - val_rmse: 0.9786 - val_sae: 367.6277 - val_sse: 506.5766 - learning_rate: 1.0000e-05\n","Epoch 712/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.1682e-16 - r2_keras: -100.7467 - rmse: 0.8778 - sae: 2575.6948 - sse: 3156.0562\n","Epoch 712: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.2709e-16 - r2_keras: -82.6983 - rmse: 0.8665 - sae: 1881.9778 - sse: 2290.1597 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5775 - learning_rate: 1.0000e-05\n","Epoch 713/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -6.9681e-16 - r2_keras: -100.7469 - rmse: 0.8778 - sae: 2575.6973 - sse: 3156.0625\n","Epoch 713: val_loss did not improve from 0.19061\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.9422e-16 - r2_keras: -82.6985 - rmse: 0.8665 - sae: 1881.9796 - sse: 2290.1646 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.6856e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5788 - learning_rate: 1.0000e-05\n","Epoch 714/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 6.7903e-17 - r2_keras: -100.7472 - rmse: 0.8778 - sae: 2575.7004 - sse: 3156.0701\n","Epoch 714: val_loss improved from 0.19061 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 6.0841e-17 - r2_keras: -82.6987 - rmse: 0.8665 - sae: 1881.9819 - sse: 2290.1699 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -5.2674e-17 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5780 - learning_rate: 1.0000e-05\n","Epoch 715/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.4155e-16 - r2_keras: -100.7472 - rmse: 0.8778 - sae: 2575.7004 - sse: 3156.0723\n","Epoch 715: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.1826e-16 - r2_keras: -82.6988 - rmse: 0.8665 - sae: 1881.9821 - sse: 2290.1716 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1069e-17 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5775 - learning_rate: 1.0000e-05\n","Epoch 716/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.9642e-16 - r2_keras: -100.7470 - rmse: 0.8778 - sae: 2575.6973 - sse: 3156.0645\n","Epoch 716: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.8663e-16 - r2_keras: -82.6986 - rmse: 0.8665 - sae: 1881.9799 - sse: 2290.1663 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3176e-16 - val_r2_keras: -35.1116 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.5771 - learning_rate: 1.0000e-05\n","Epoch 717/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.1095e-16 - r2_keras: -100.7471 - rmse: 0.8778 - sae: 2575.6987 - sse: 3156.0688\n","Epoch 717: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.6672e-16 - r2_keras: -82.6987 - rmse: 0.8665 - sae: 1881.9810 - sse: 2290.1697 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5787 - learning_rate: 1.0000e-05\n","Epoch 718/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.0746e-16 - r2_keras: -100.7474 - rmse: 0.8778 - sae: 2575.7021 - sse: 3156.0767\n","Epoch 718: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.3140e-16 - r2_keras: -82.6989 - rmse: 0.8665 - sae: 1881.9834 - sse: 2290.1753 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1069e-17 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5792 - learning_rate: 1.0000e-05\n","Epoch 719/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -1.1919e-16 - r2_keras: -100.7476 - rmse: 0.8778 - sae: 2575.7036 - sse: 3156.0820\n","Epoch 719: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.8222e-17 - r2_keras: -82.6991 - rmse: 0.8665 - sae: 1881.9845 - sse: 2290.1794 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1069e-17 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5782 - learning_rate: 1.0000e-05\n","Epoch 720/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.5558e-16 - r2_keras: -100.7476 - rmse: 0.8778 - sae: 2575.7036 - sse: 3156.0830\n","Epoch 720: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.4212e-16 - r2_keras: -82.6991 - rmse: 0.8665 - sae: 1881.9846 - sse: 2290.1802 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2139e-17 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5789 - learning_rate: 1.0000e-05\n","Epoch 721/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -2.5558e-16 - r2_keras: -100.7475 - rmse: 0.8778 - sae: 2575.7029 - sse: 3156.0806\n","Epoch 721: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.2938e-16 - r2_keras: -82.6991 - rmse: 0.8665 - sae: 1881.9841 - sse: 2290.1785 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.8962e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5784 - learning_rate: 1.0000e-05\n","Epoch 722/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -2.4305e-16 - r2_keras: -100.7477 - rmse: 0.8778 - sae: 2575.7043 - sse: 3156.0850\n","Epoch 722: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.1630e-16 - r2_keras: -82.6992 - rmse: 0.8665 - sae: 1881.9851 - sse: 2290.1816 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -8.4278e-17 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5785 - learning_rate: 1.0000e-05\n","Epoch 723/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.5787e-16 - r2_keras: -100.7478 - rmse: 0.8778 - sae: 2575.7061 - sse: 3156.0896\n","Epoch 723: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.7444e-16 - r2_keras: -82.6993 - rmse: 0.8665 - sae: 1881.9865 - sse: 2290.1855 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.8962e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5792 - learning_rate: 1.0000e-05\n","Epoch 724/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -3.7594e-16 - r2_keras: -100.7479 - rmse: 0.8778 - sae: 2575.7068 - sse: 3156.0923\n","Epoch 724: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.1433e-16 - r2_keras: -82.6994 - rmse: 0.8665 - sae: 1881.9872 - sse: 2290.1877 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5793 - learning_rate: 1.0000e-05\n","Epoch 725/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 8.8593e-17 - r2_keras: -100.7481 - rmse: 0.8778 - sae: 2575.7085 - sse: 3156.0981\n","Epoch 725: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.4901e-18 - r2_keras: -82.6996 - rmse: 0.8665 - sae: 1881.9884 - sse: 2290.1917 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.9513e-16 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5800 - learning_rate: 1.0000e-05\n","Epoch 726/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.7948e-16 - r2_keras: -100.7480 - rmse: 0.8778 - sae: 2575.7080 - sse: 3156.0947\n","Epoch 726: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.5993e-16 - r2_keras: -82.6995 - rmse: 0.8665 - sae: 1881.9880 - sse: 2290.1895 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5794 - learning_rate: 1.0000e-05\n","Epoch 727/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -8.5970e-16 - r2_keras: -100.7482 - rmse: 0.8778 - sae: 2575.7100 - sse: 3156.1016\n","Epoch 727: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -6.1749e-16 - r2_keras: -82.6996 - rmse: 0.8665 - sae: 1881.9894 - sse: 2290.1943 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0535e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5789 - learning_rate: 1.0000e-05\n","Epoch 728/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.9284e-16 - r2_keras: -100.7483 - rmse: 0.8778 - sae: 2575.7109 - sse: 3156.1050\n","Epoch 728: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.3263e-16 - r2_keras: -82.6998 - rmse: 0.8665 - sae: 1881.9902 - sse: 2290.1970 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2123e-16 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5800 - learning_rate: 1.0000e-05\n","Epoch 729/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -4.6482e-16 - r2_keras: -100.7484 - rmse: 0.8778 - sae: 2575.7119 - sse: 3156.1074\n","Epoch 729: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.8157e-16 - r2_keras: -82.6998 - rmse: 0.8665 - sae: 1881.9911 - sse: 2290.1990 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1604e-17 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5801 - learning_rate: 1.0000e-05\n","Epoch 730/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 1.3318e-16 - r2_keras: -100.7485 - rmse: 0.8778 - sae: 2575.7126 - sse: 3156.1099\n","Epoch 730: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 9.4921e-17 - r2_keras: -82.6999 - rmse: 0.8665 - sae: 1881.9916 - sse: 2290.2009 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3743e-17 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5801 - learning_rate: 1.0000e-05\n","Epoch 731/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -2.1478e-16 - r2_keras: -100.7484 - rmse: 0.8778 - sae: 2575.7124 - sse: 3156.1084\n","Epoch 731: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.4319e-16 - r2_keras: -82.6999 - rmse: 0.8665 - sae: 1881.9915 - sse: 2290.2000 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.7390e-16 - val_r2_keras: -35.1117 - val_rmse: 0.9786 - val_sae: 367.6278 - val_sse: 506.5795 - learning_rate: 1.0000e-05\n","Epoch 732/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -2.7277e-16 - r2_keras: -100.7486 - rmse: 0.8778 - sae: 2575.7136 - sse: 3156.1138\n","Epoch 732: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.3187e-16 - r2_keras: -82.7000 - rmse: 0.8665 - sae: 1881.9924 - sse: 2290.2039 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1604e-16 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5808 - learning_rate: 1.0000e-05\n","Epoch 733/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -3.8555e-16 - r2_keras: -100.7489 - rmse: 0.8778 - sae: 2575.7168 - sse: 3156.1226\n","Epoch 733: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.8818e-16 - r2_keras: -82.7003 - rmse: 0.8665 - sae: 1881.9948 - sse: 2290.2102 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5810 - learning_rate: 1.0000e-05\n","Epoch 734/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 8.4425e-16 - r2_keras: -100.7489 - rmse: 0.8778 - sae: 2575.7168 - sse: 3156.1226\n","Epoch 734: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 5.9728e-16 - r2_keras: -82.7003 - rmse: 0.8665 - sae: 1881.9949 - sse: 2290.2107 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.8444e-16 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5804 - learning_rate: 1.0000e-05\n","Epoch 735/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.0108e-17 - r2_keras: -100.7489 - rmse: 0.8778 - sae: 2575.7166 - sse: 3156.1235\n","Epoch 735: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.8683e-17 - r2_keras: -82.7003 - rmse: 0.8665 - sae: 1881.9948 - sse: 2290.2117 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4812e-17 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5805 - learning_rate: 1.0000e-05\n","Epoch 736/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 1.0695e-16 - r2_keras: -100.7489 - rmse: 0.8778 - sae: 2575.7170 - sse: 3156.1233\n","Epoch 736: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 8.7817e-17 - r2_keras: -82.7003 - rmse: 0.8665 - sae: 1881.9951 - sse: 2290.2114 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1604e-17 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5804 - learning_rate: 1.0000e-05\n","Epoch 737/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.7394e-17 - r2_keras: -100.7491 - rmse: 0.8778 - sae: 2575.7183 - sse: 3156.1287\n","Epoch 737: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.7228e-17 - r2_keras: -82.7005 - rmse: 0.8665 - sae: 1881.9961 - sse: 2290.2153 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.6871e-16 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5817 - learning_rate: 1.0000e-05\n","Epoch 738/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 1.8097e-16 - r2_keras: -100.7493 - rmse: 0.8778 - sae: 2575.7202 - sse: 3156.1348\n","Epoch 738: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.3433e-16 - r2_keras: -82.7007 - rmse: 0.8665 - sae: 1881.9974 - sse: 2290.2200 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5819 - learning_rate: 1.0000e-05\n","Epoch 739/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -5.8750e-16 - r2_keras: -100.7494 - rmse: 0.8778 - sae: 2575.7227 - sse: 3156.1401\n","Epoch 739: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.5816e-16 - r2_keras: -82.7008 - rmse: 0.8665 - sae: 1881.9994 - sse: 2290.2239 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0535e-16 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5809 - learning_rate: 1.0000e-05\n","Epoch 740/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 2.1478e-16 - r2_keras: -100.7495 - rmse: 0.8778 - sae: 2575.7224 - sse: 3156.1414\n","Epoch 740: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.4177e-16 - r2_keras: -82.7009 - rmse: 0.8665 - sae: 1881.9993 - sse: 2290.2251 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5816 - learning_rate: 1.0000e-05\n","Epoch 741/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.8147e-16 - r2_keras: -100.7493 - rmse: 0.8778 - sae: 2575.7202 - sse: 3156.1348\n","Epoch 741: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.8966e-16 - r2_keras: -82.7007 - rmse: 0.8665 - sae: 1881.9977 - sse: 2290.2205 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 6.3208e-17 - val_r2_keras: -35.1118 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5808 - learning_rate: 1.0000e-05\n","Epoch 742/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -7.1689e-17 - r2_keras: -100.7495 - rmse: 0.8778 - sae: 2575.7227 - sse: 3156.1428\n","Epoch 742: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.5433e-17 - r2_keras: -82.7009 - rmse: 0.8665 - sae: 1881.9994 - sse: 2290.2261 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5818 - learning_rate: 1.0000e-05\n","Epoch 743/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 4.0799e-17 - r2_keras: -100.7497 - rmse: 0.8778 - sae: 2575.7249 - sse: 3156.1479\n","Epoch 743: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.8955e-17 - r2_keras: -82.7011 - rmse: 0.8665 - sae: 1882.0011 - sse: 2290.2302 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0535e-17 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5829 - learning_rate: 1.0000e-05\n","Epoch 744/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.6573e-16 - r2_keras: -100.7498 - rmse: 0.8778 - sae: 2575.7258 - sse: 3156.1516\n","Epoch 744: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 3.2546e-16 - r2_keras: -82.7012 - rmse: 0.8665 - sae: 1882.0020 - sse: 2290.2329 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2138e-17 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5822 - learning_rate: 1.0000e-05\n","Epoch 745/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -9.9665e-17 - r2_keras: -100.7500 - rmse: 0.8778 - sae: 2575.7280 - sse: 3156.1577\n","Epoch 745: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.0231e-16 - r2_keras: -82.7013 - rmse: 0.8665 - sae: 1882.0035 - sse: 2290.2375 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5822 - learning_rate: 1.0000e-05\n","Epoch 746/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -5.1902e-16 - r2_keras: -100.7498 - rmse: 0.8778 - sae: 2575.7249 - sse: 3156.1501\n","Epoch 746: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.6064e-16 - r2_keras: -82.7012 - rmse: 0.8665 - sae: 1882.0013 - sse: 2290.2322 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.6855e-16 - val_r2_keras: -35.1119 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5816 - learning_rate: 1.0000e-05\n","Epoch 747/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 7.4894e-17 - r2_keras: -100.7499 - rmse: 0.8778 - sae: 2575.7266 - sse: 3156.1543\n","Epoch 747: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 6.9277e-17 - r2_keras: -82.7013 - rmse: 0.8665 - sae: 1882.0026 - sse: 2290.2351 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2138e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5826 - learning_rate: 1.0000e-05\n","Epoch 748/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 4.2518e-16 - r2_keras: -100.7502 - rmse: 0.8778 - sae: 2575.7297 - sse: 3156.1626\n","Epoch 748: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.7165e-16 - r2_keras: -82.7015 - rmse: 0.8665 - sae: 1882.0049 - sse: 2290.2412 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.2123e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5833 - learning_rate: 1.0000e-05\n","Epoch 749/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 4.4295e-16 - r2_keras: -100.7503 - rmse: 0.8778 - sae: 2575.7310 - sse: 3156.1670\n","Epoch 749: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 3.0238e-16 - r2_keras: -82.7016 - rmse: 0.8665 - sae: 1882.0059 - sse: 2290.2446 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5824 - learning_rate: 1.0000e-05\n","Epoch 750/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -4.0798e-16 - r2_keras: -100.7504 - rmse: 0.8778 - sae: 2575.7319 - sse: 3156.1694\n","Epoch 750: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.6633e-16 - r2_keras: -82.7017 - rmse: 0.8665 - sae: 1882.0067 - sse: 2290.2466 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1069e-17 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5836 - learning_rate: 1.0000e-05\n","Epoch 751/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -3.0948e-16 - r2_keras: -100.7503 - rmse: 0.8778 - sae: 2575.7314 - sse: 3156.1680\n","Epoch 751: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.3794e-16 - r2_keras: -82.7017 - rmse: 0.8665 - sae: 1882.0063 - sse: 2290.2456 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.0550e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.5825 - learning_rate: 1.0000e-05\n","Epoch 752/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: 3.8379e-16 - r2_keras: -100.7504 - rmse: 0.8778 - sae: 2575.7310 - sse: 3156.1687\n","Epoch 752: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.7757e-16 - r2_keras: -82.7017 - rmse: 0.8665 - sae: 1882.0060 - sse: 2290.2461 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5827 - learning_rate: 1.0000e-05\n","Epoch 753/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1385 - pearson_correlation: -3.3134e-16 - r2_keras: -100.7505 - rmse: 0.8778 - sae: 2575.7324 - sse: 3156.1724\n","Epoch 753: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.6997e-16 - r2_keras: -82.7018 - rmse: 0.8665 - sae: 1882.0072 - sse: 2290.2493 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.3176e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5837 - learning_rate: 1.0000e-05\n","Epoch 754/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 4.6393e-16 - r2_keras: -100.7507 - rmse: 0.8778 - sae: 2575.7356 - sse: 3156.1807\n","Epoch 754: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.8569e-16 - r2_keras: -82.7021 - rmse: 0.8665 - sae: 1882.0095 - sse: 2290.2554 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2138e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5839 - learning_rate: 1.0000e-05\n","Epoch 755/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 3.4678e-17 - r2_keras: -100.7509 - rmse: 0.8778 - sae: 2575.7368 - sse: 3156.1846\n","Epoch 755: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 4.3409e-17 - r2_keras: -82.7022 - rmse: 0.8665 - sae: 1882.0104 - sse: 2290.2583 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2123e-16 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5841 - learning_rate: 1.0000e-05\n","Epoch 756/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.5382e-16 - r2_keras: -100.7507 - rmse: 0.8778 - sae: 2575.7354 - sse: 3156.1804\n","Epoch 756: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.8762e-16 - r2_keras: -82.7021 - rmse: 0.8665 - sae: 1882.0094 - sse: 2290.2551 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.5818e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5834 - learning_rate: 1.0000e-05\n","Epoch 757/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 8.8386e-16 - r2_keras: -100.7509 - rmse: 0.8778 - sae: 2575.7366 - sse: 3156.1848\n","Epoch 757: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 5.5338e-16 - r2_keras: -82.7022 - rmse: 0.8665 - sae: 1882.0103 - sse: 2290.2583 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.5818e-16 - val_r2_keras: -35.1120 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5830 - learning_rate: 1.0000e-05\n","Epoch 758/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.1365e-17 - r2_keras: -100.7510 - rmse: 0.8778 - sae: 2575.7378 - sse: 3156.1875\n","Epoch 758: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.9755e-17 - r2_keras: -82.7023 - rmse: 0.8665 - sae: 1882.0114 - sse: 2290.2607 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3742e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5847 - learning_rate: 1.0000e-05\n","Epoch 759/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.2526e-16 - r2_keras: -100.7511 - rmse: 0.8778 - sae: 2575.7390 - sse: 3156.1919\n","Epoch 759: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.8604e-16 - r2_keras: -82.7024 - rmse: 0.8665 - sae: 1882.0123 - sse: 2290.2644 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5842 - learning_rate: 1.0000e-05\n","Epoch 760/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -8.2936e-16 - r2_keras: -100.7512 - rmse: 0.8778 - sae: 2575.7397 - sse: 3156.1953\n","Epoch 760: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -5.9443e-16 - r2_keras: -82.7025 - rmse: 0.8665 - sae: 1882.0128 - sse: 2290.2666 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -8.4276e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5847 - learning_rate: 1.0000e-05\n","Epoch 761/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -6.5626e-16 - r2_keras: -100.7512 - rmse: 0.8778 - sae: 2575.7397 - sse: 3156.1934\n","Epoch 761: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.2288e-16 - r2_keras: -82.7025 - rmse: 0.8665 - sae: 1882.0128 - sse: 2290.2654 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4811e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5840 - learning_rate: 1.0000e-05\n","Epoch 762/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 5.0181e-16 - r2_keras: -100.7513 - rmse: 0.8778 - sae: 2575.7407 - sse: 3156.1982\n","Epoch 762: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.8688e-16 - r2_keras: -82.7026 - rmse: 0.8665 - sae: 1882.0135 - sse: 2290.2690 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.4748e-16 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5854 - learning_rate: 1.0000e-05\n","Epoch 763/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -5.3882e-16 - r2_keras: -100.7516 - rmse: 0.8778 - sae: 2575.7441 - sse: 3156.2065\n","Epoch 763: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.9413e-16 - r2_keras: -82.7028 - rmse: 0.8665 - sae: 1882.0161 - sse: 2290.2749 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0535e-17 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5852 - learning_rate: 1.0000e-05\n","Epoch 764/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.4221e-16 - r2_keras: -100.7516 - rmse: 0.8778 - sae: 2575.7437 - sse: 3156.2061\n","Epoch 764: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 9.5278e-17 - r2_keras: -82.7028 - rmse: 0.8665 - sae: 1882.0160 - sse: 2290.2751 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.0016e-16 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5846 - learning_rate: 1.0000e-05\n","Epoch 765/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -4.4498e-16 - r2_keras: -100.7516 - rmse: 0.8778 - sae: 2575.7437 - sse: 3156.2075\n","Epoch 765: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.5422e-16 - r2_keras: -82.7029 - rmse: 0.8665 - sae: 1882.0160 - sse: 2290.2764 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3742e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5848 - learning_rate: 1.0000e-05\n","Epoch 766/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.6256e-16 - r2_keras: -100.7516 - rmse: 0.8778 - sae: 2575.7437 - sse: 3156.2061\n","Epoch 766: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.7032e-16 - r2_keras: -82.7029 - rmse: 0.8665 - sae: 1882.0160 - sse: 2290.2751 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2138e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5850 - learning_rate: 1.0000e-05\n","Epoch 767/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -7.4805e-16 - r2_keras: -100.7517 - rmse: 0.8778 - sae: 2575.7456 - sse: 3156.2117\n","Epoch 767: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.2745e-16 - r2_keras: -82.7030 - rmse: 0.8665 - sae: 1882.0173 - sse: 2290.2793 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.0016e-16 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5860 - learning_rate: 1.0000e-05\n","Epoch 768/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.2909e-16 - r2_keras: -100.7519 - rmse: 0.8778 - sae: 2575.7473 - sse: 3156.2180\n","Epoch 768: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.1107e-16 - r2_keras: -82.7032 - rmse: 0.8665 - sae: 1882.0187 - sse: 2290.2842 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1604e-16 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5862 - learning_rate: 1.0000e-05\n","Epoch 769/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.2589e-16 - r2_keras: -100.7522 - rmse: 0.8778 - sae: 2575.7500 - sse: 3156.2246\n","Epoch 769: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.4761e-17 - r2_keras: -82.7034 - rmse: 0.8665 - sae: 1882.0206 - sse: 2290.2891 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1121 - val_rmse: 0.9786 - val_sae: 367.6279 - val_sse: 506.5848 - learning_rate: 1.0000e-05\n","Epoch 770/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.4366e-16 - r2_keras: -100.7522 - rmse: 0.8778 - sae: 2575.7495 - sse: 3156.2249\n","Epoch 770: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.2550e-16 - r2_keras: -82.7034 - rmse: 0.8665 - sae: 1882.0205 - sse: 2290.2896 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 6.3207e-17 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5863 - learning_rate: 1.0000e-05\n","Epoch 771/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.8971e-16 - r2_keras: -100.7520 - rmse: 0.8778 - sae: 2575.7480 - sse: 3156.2205\n","Epoch 771: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.3449e-16 - r2_keras: -82.7033 - rmse: 0.8665 - sae: 1882.0194 - sse: 2290.2864 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5867 - learning_rate: 1.0000e-05\n","Epoch 772/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.3313e-16 - r2_keras: -100.7521 - rmse: 0.8778 - sae: 2575.7495 - sse: 3156.2241\n","Epoch 772: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.2856e-16 - r2_keras: -82.7034 - rmse: 0.8665 - sae: 1882.0206 - sse: 2290.2893 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3742e-17 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5861 - learning_rate: 1.0000e-05\n","Epoch 773/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -9.9079e-17 - r2_keras: -100.7524 - rmse: 0.8778 - sae: 2575.7520 - sse: 3156.2314\n","Epoch 773: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -6.0390e-17 - r2_keras: -82.7036 - rmse: 0.8665 - sae: 1882.0223 - sse: 2290.2944 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 8.4276e-17 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5869 - learning_rate: 1.0000e-05\n","Epoch 774/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 4.3099e-16 - r2_keras: -100.7526 - rmse: 0.8778 - sae: 2575.7534 - sse: 3156.2373\n","Epoch 774: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.8025e-16 - r2_keras: -82.7038 - rmse: 0.8665 - sae: 1882.0236 - sse: 2290.2991 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1604e-17 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5862 - learning_rate: 1.0000e-05\n","Epoch 775/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 3.1093e-16 - r2_keras: -100.7526 - rmse: 0.8778 - sae: 2575.7537 - sse: 3156.2378\n","Epoch 775: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.3843e-16 - r2_keras: -82.7038 - rmse: 0.8665 - sae: 1882.0237 - sse: 2290.2993 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5865 - learning_rate: 1.0000e-05\n","Epoch 776/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.3021e-17 - r2_keras: -100.7524 - rmse: 0.8778 - sae: 2575.7524 - sse: 3156.2334\n","Epoch 776: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -7.3858e-17 - r2_keras: -82.7037 - rmse: 0.8665 - sae: 1882.0228 - sse: 2290.2964 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3742e-17 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.5858 - learning_rate: 1.0000e-05\n","Epoch 777/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.9053e-16 - r2_keras: -100.7526 - rmse: 0.8778 - sae: 2575.7539 - sse: 3156.2383\n","Epoch 777: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.0454e-16 - r2_keras: -82.7038 - rmse: 0.8665 - sae: 1882.0239 - sse: 2290.2998 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.4748e-16 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5866 - learning_rate: 1.0000e-05\n","Epoch 778/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -6.6528e-16 - r2_keras: -100.7528 - rmse: 0.8778 - sae: 2575.7554 - sse: 3156.2439\n","Epoch 778: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.3455e-16 - r2_keras: -82.7040 - rmse: 0.8665 - sae: 1882.0251 - sse: 2290.3042 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3741e-17 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5880 - learning_rate: 1.0000e-05\n","Epoch 779/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 3.0364e-16 - r2_keras: -100.7530 - rmse: 0.8778 - sae: 2575.7583 - sse: 3156.2515\n","Epoch 779: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.8356e-16 - r2_keras: -82.7042 - rmse: 0.8665 - sae: 1882.0272 - sse: 2290.3098 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5875 - learning_rate: 1.0000e-05\n","Epoch 780/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.9199e-16 - r2_keras: -100.7531 - rmse: 0.8778 - sae: 2575.7593 - sse: 3156.2539\n","Epoch 780: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.2907e-16 - r2_keras: -82.7043 - rmse: 0.8665 - sae: 1882.0280 - sse: 2290.3118 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.2641e-16 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5876 - learning_rate: 1.0000e-05\n","Epoch 781/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.5061e-17 - r2_keras: -100.7531 - rmse: 0.8778 - sae: 2575.7588 - sse: 3156.2524\n","Epoch 781: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.9625e-17 - r2_keras: -82.7042 - rmse: 0.8665 - sae: 1882.0277 - sse: 2290.3108 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 5.2673e-17 - val_r2_keras: -35.1122 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5864 - learning_rate: 1.0000e-05\n","Epoch 782/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 4.5955e-16 - r2_keras: -100.7530 - rmse: 0.8778 - sae: 2575.7578 - sse: 3156.2522\n","Epoch 782: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.8749e-16 - r2_keras: -82.7042 - rmse: 0.8665 - sae: 1882.0270 - sse: 2290.3105 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4810e-17 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5878 - learning_rate: 1.0000e-05\n","Epoch 783/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -5.1987e-16 - r2_keras: -100.7532 - rmse: 0.8778 - sae: 2575.7605 - sse: 3156.2578\n","Epoch 783: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.0789e-16 - r2_keras: -82.7044 - rmse: 0.8665 - sae: 1882.0291 - sse: 2290.3149 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1603e-17 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5882 - learning_rate: 1.0000e-05\n","Epoch 784/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.4920e-16 - r2_keras: -100.7533 - rmse: 0.8778 - sae: 2575.7612 - sse: 3156.2617\n","Epoch 784: val_loss improved from 0.19060 to 0.19060, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.2400e-16 - r2_keras: -82.7045 - rmse: 0.8665 - sae: 1882.0297 - sse: 2290.3181 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3176e-16 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5879 - learning_rate: 1.0000e-05\n","Epoch 785/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.6547e-16 - r2_keras: -100.7536 - rmse: 0.8778 - sae: 2575.7642 - sse: 3156.2690\n","Epoch 785: val_loss did not improve from 0.19060\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.3549e-16 - r2_keras: -82.7047 - rmse: 0.8665 - sae: 1882.0317 - sse: 2290.3232 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4810e-17 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5881 - learning_rate: 1.0000e-05\n","Epoch 786/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.3545e-16 - r2_keras: -100.7535 - rmse: 0.8778 - sae: 2575.7627 - sse: 3156.2651\n","Epoch 786: val_loss improved from 0.19060 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.7112e-16 - r2_keras: -82.7046 - rmse: 0.8665 - sae: 1882.0308 - sse: 2290.3206 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1123 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5876 - learning_rate: 1.0000e-05\n","Epoch 787/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.6901e-17 - r2_keras: -100.7536 - rmse: 0.8778 - sae: 2575.7637 - sse: 3156.2695\n","Epoch 787: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.6275e-17 - r2_keras: -82.7047 - rmse: 0.8665 - sae: 1882.0315 - sse: 2290.3237 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.5283e-16 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5883 - learning_rate: 1.0000e-05\n","Epoch 788/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -7.3783e-16 - r2_keras: -100.7536 - rmse: 0.8778 - sae: 2575.7637 - sse: 3156.2700\n","Epoch 788: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.8764e-16 - r2_keras: -82.7048 - rmse: 0.8665 - sae: 1882.0316 - sse: 2290.3245 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5888 - learning_rate: 1.0000e-05\n","Epoch 789/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -7.0228e-17 - r2_keras: -100.7538 - rmse: 0.8778 - sae: 2575.7666 - sse: 3156.2766\n","Epoch 789: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.2755e-17 - r2_keras: -82.7050 - rmse: 0.8665 - sae: 1882.0338 - sse: 2290.3293 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5882 - learning_rate: 1.0000e-05\n","Epoch 790/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.1102e-16 - r2_keras: -100.7540 - rmse: 0.8778 - sae: 2575.7673 - sse: 3156.2805\n","Epoch 790: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -8.2981e-17 - r2_keras: -82.7051 - rmse: 0.8665 - sae: 1882.0344 - sse: 2290.3323 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.1588e-16 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6294 - val_sse: 506.5894 - learning_rate: 1.0000e-05\n","Epoch 791/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0675 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.1132e-16 - r2_keras: -100.7540 - rmse: 0.8778 - sae: 2575.7681 - sse: 3156.2805\n","Epoch 791: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.0299e-16 - r2_keras: -82.7051 - rmse: 0.8665 - sae: 1882.0349 - sse: 2290.3323 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-16 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5888 - learning_rate: 1.0000e-05\n","Epoch 792/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.5643e-16 - r2_keras: -100.7540 - rmse: 0.8778 - sae: 2575.7678 - sse: 3156.2817\n","Epoch 792: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.2380e-16 - r2_keras: -82.7051 - rmse: 0.8665 - sae: 1882.0348 - sse: 2290.3330 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.2138e-16 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5892 - learning_rate: 1.0000e-05\n","Epoch 793/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -5.1432e-16 - r2_keras: -100.7542 - rmse: 0.8778 - sae: 2575.7695 - sse: 3156.2871\n","Epoch 793: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.3863e-16 - r2_keras: -82.7053 - rmse: 0.8665 - sae: 1882.0361 - sse: 2290.3374 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.6855e-16 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5889 - learning_rate: 1.0000e-05\n","Epoch 794/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -7.0869e-16 - r2_keras: -100.7543 - rmse: 0.8778 - sae: 2575.7710 - sse: 3156.2905\n","Epoch 794: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -5.6918e-16 - r2_keras: -82.7054 - rmse: 0.8665 - sae: 1882.0372 - sse: 2290.3401 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.9496e-16 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5893 - learning_rate: 1.0000e-05\n","Epoch 795/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.1884e-16 - r2_keras: -100.7544 - rmse: 0.8778 - sae: 2575.7720 - sse: 3156.2944\n","Epoch 795: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.0490e-16 - r2_keras: -82.7055 - rmse: 0.8665 - sae: 1882.0380 - sse: 2290.3430 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2122e-16 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5898 - learning_rate: 1.0000e-05\n","Epoch 796/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 6.7255e-16 - r2_keras: -100.7543 - rmse: 0.8778 - sae: 2575.7710 - sse: 3156.2913\n","Epoch 796: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 4.3327e-16 - r2_keras: -82.7054 - rmse: 0.8665 - sae: 1882.0374 - sse: 2290.3408 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 6.3207e-17 - val_r2_keras: -35.1124 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5890 - learning_rate: 1.0000e-05\n","Epoch 797/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 3.1821e-16 - r2_keras: -100.7544 - rmse: 0.8778 - sae: 2575.7720 - sse: 3156.2947\n","Epoch 797: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.3337e-16 - r2_keras: -82.7055 - rmse: 0.8665 - sae: 1882.0381 - sse: 2290.3433 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1603e-17 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5900 - learning_rate: 1.0000e-05\n","Epoch 798/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.1272e-16 - r2_keras: -100.7547 - rmse: 0.8778 - sae: 2575.7747 - sse: 3156.3025\n","Epoch 798: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.5927e-16 - r2_keras: -82.7057 - rmse: 0.8665 - sae: 1882.0400 - sse: 2290.3491 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-16 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5908 - learning_rate: 1.0000e-05\n","Epoch 799/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.2345e-17 - r2_keras: -100.7548 - rmse: 0.8778 - sae: 2575.7764 - sse: 3156.3076\n","Epoch 799: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.1056e-18 - r2_keras: -82.7059 - rmse: 0.8665 - sae: 1882.0414 - sse: 2290.3530 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2138e-17 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5896 - learning_rate: 1.0000e-05\n","Epoch 800/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -6.3583e-16 - r2_keras: -100.7548 - rmse: 0.8778 - sae: 2575.7761 - sse: 3156.3071\n","Epoch 800: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.3615e-16 - r2_keras: -82.7059 - rmse: 0.8665 - sae: 1882.0414 - sse: 2290.3530 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5903 - learning_rate: 1.0000e-05\n","Epoch 801/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.3715e-16 - r2_keras: -100.7547 - rmse: 0.8778 - sae: 2575.7744 - sse: 3156.3027\n","Epoch 801: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.6204e-16 - r2_keras: -82.7058 - rmse: 0.8665 - sae: 1882.0402 - sse: 2290.3499 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1603e-17 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5896 - learning_rate: 1.0000e-05\n","Epoch 802/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.3341e-16 - r2_keras: -100.7549 - rmse: 0.8778 - sae: 2575.7776 - sse: 3156.3105\n","Epoch 802: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.7637e-16 - r2_keras: -82.7060 - rmse: 0.8665 - sae: 1882.0422 - sse: 2290.3552 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.4748e-16 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5902 - learning_rate: 1.0000e-05\n","Epoch 803/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.3637e-16 - r2_keras: -100.7550 - rmse: 0.8778 - sae: 2575.7783 - sse: 3156.3140\n","Epoch 803: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 8.6198e-17 - r2_keras: -82.7061 - rmse: 0.8665 - sae: 1882.0430 - sse: 2290.3582 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.8443e-16 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5915 - learning_rate: 1.0000e-05\n","Epoch 804/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.5444e-17 - r2_keras: -100.7552 - rmse: 0.8778 - sae: 2575.7805 - sse: 3156.3198\n","Epoch 804: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.6979e-17 - r2_keras: -82.7063 - rmse: 0.8665 - sae: 1882.0447 - sse: 2290.3625 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1069e-17 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5902 - learning_rate: 1.0000e-05\n","Epoch 805/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.1772e-16 - r2_keras: -100.7552 - rmse: 0.8778 - sae: 2575.7800 - sse: 3156.3201\n","Epoch 805: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -9.0279e-17 - r2_keras: -82.7063 - rmse: 0.8665 - sae: 1882.0444 - sse: 2290.3630 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.0015e-16 - val_r2_keras: -35.1125 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5907 - learning_rate: 1.0000e-05\n","Epoch 806/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -4.0766e-16 - r2_keras: -100.7552 - rmse: 0.8778 - sae: 2575.7793 - sse: 3156.3179\n","Epoch 806: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.4913e-16 - r2_keras: -82.7062 - rmse: 0.8665 - sae: 1882.0438 - sse: 2290.3613 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1603e-17 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5915 - learning_rate: 1.0000e-05\n","Epoch 807/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.5648e-16 - r2_keras: -100.7553 - rmse: 0.8778 - sae: 2575.7810 - sse: 3156.3225\n","Epoch 807: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 9.4883e-17 - r2_keras: -82.7064 - rmse: 0.8665 - sae: 1882.0450 - sse: 2290.3647 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-16 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5911 - learning_rate: 1.0000e-05\n","Epoch 808/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.4657e-16 - r2_keras: -100.7554 - rmse: 0.8778 - sae: 2575.7820 - sse: 3156.3257\n","Epoch 808: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.2933e-16 - r2_keras: -82.7065 - rmse: 0.8665 - sae: 1882.0460 - sse: 2290.3674 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6294 - val_sse: 506.5921 - learning_rate: 1.0000e-05\n","Epoch 809/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.3288e-16 - r2_keras: -100.7557 - rmse: 0.8778 - sae: 2575.7852 - sse: 3156.3342\n","Epoch 809: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -7.1127e-17 - r2_keras: -82.7067 - rmse: 0.8666 - sae: 1882.0483 - sse: 2290.3735 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.4748e-16 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5914 - learning_rate: 1.0000e-05\n","Epoch 810/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.3142e-16 - r2_keras: -100.7558 - rmse: 0.8778 - sae: 2575.7856 - sse: 3156.3369\n","Epoch 810: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -8.5725e-17 - r2_keras: -82.7068 - rmse: 0.8666 - sae: 1882.0487 - sse: 2290.3757 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5919 - learning_rate: 1.0000e-05\n","Epoch 811/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.2321e-16 - r2_keras: -100.7558 - rmse: 0.8778 - sae: 2575.7861 - sse: 3156.3369\n","Epoch 811: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -9.1243e-17 - r2_keras: -82.7068 - rmse: 0.8666 - sae: 1882.0491 - sse: 2290.3757 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.0015e-16 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5914 - learning_rate: 1.0000e-05\n","Epoch 812/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.1330e-16 - r2_keras: -100.7558 - rmse: 0.8778 - sae: 2575.7856 - sse: 3156.3364\n","Epoch 812: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.2757e-16 - r2_keras: -82.7068 - rmse: 0.8666 - sae: 1882.0487 - sse: 2290.3755 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 6.3206e-17 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5922 - learning_rate: 1.0000e-05\n","Epoch 813/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.3574e-16 - r2_keras: -100.7559 - rmse: 0.8778 - sae: 2575.7876 - sse: 3156.3418\n","Epoch 813: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 9.2991e-17 - r2_keras: -82.7070 - rmse: 0.8666 - sae: 1882.0502 - sse: 2290.3796 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 5.2672e-17 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5925 - learning_rate: 1.0000e-05\n","Epoch 814/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -7.9230e-16 - r2_keras: -100.7561 - rmse: 0.8778 - sae: 2575.7891 - sse: 3156.3469\n","Epoch 814: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -4.5082e-16 - r2_keras: -82.7071 - rmse: 0.8666 - sae: 1882.0514 - sse: 2290.3835 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4809e-17 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5922 - learning_rate: 1.0000e-05\n","Epoch 815/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.8382e-16 - r2_keras: -100.7562 - rmse: 0.8778 - sae: 2575.7905 - sse: 3156.3511\n","Epoch 815: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -1.7694e-16 - r2_keras: -82.7072 - rmse: 0.8666 - sae: 1882.0524 - sse: 2290.3865 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -6.3206e-17 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6294 - val_sse: 506.5928 - learning_rate: 1.0000e-05\n","Epoch 816/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -5.3034e-16 - r2_keras: -100.7561 - rmse: 0.8778 - sae: 2575.7896 - sse: 3156.3477\n","Epoch 816: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -3.3185e-16 - r2_keras: -82.7071 - rmse: 0.8666 - sae: 1882.0518 - sse: 2290.3840 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5923 - learning_rate: 1.0000e-05\n","Epoch 817/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.2238e-17 - r2_keras: -100.7563 - rmse: 0.8778 - sae: 2575.7908 - sse: 3156.3525\n","Epoch 817: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 8.6009e-17 - r2_keras: -82.7073 - rmse: 0.8666 - sae: 1882.0526 - sse: 2290.3877 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1126 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5920 - learning_rate: 1.0000e-05\n","Epoch 818/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.5322e-16 - r2_keras: -100.7563 - rmse: 0.8778 - sae: 2575.7910 - sse: 3156.3535\n","Epoch 818: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.1361e-16 - r2_keras: -82.7073 - rmse: 0.8666 - sae: 1882.0529 - sse: 2290.3887 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.2122e-16 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5927 - learning_rate: 1.0000e-05\n","Epoch 819/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 3.0800e-16 - r2_keras: -100.7565 - rmse: 0.8778 - sae: 2575.7927 - sse: 3156.3579\n","Epoch 819: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 2.9828e-16 - r2_keras: -82.7075 - rmse: 0.8666 - sae: 1882.0543 - sse: 2290.3921 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3740e-17 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5929 - learning_rate: 1.0000e-05\n","Epoch 820/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.6959e-16 - r2_keras: -100.7566 - rmse: 0.8778 - sae: 2575.7939 - sse: 3156.3625\n","Epoch 820: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: 1.5835e-16 - r2_keras: -82.7076 - rmse: 0.8666 - sae: 1882.0553 - sse: 2290.3955 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1603e-17 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6295 - val_sse: 506.5938 - learning_rate: 1.0000e-05\n","Epoch 821/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.9605e-16 - r2_keras: -100.7566 - rmse: 0.8778 - sae: 2575.7937 - sse: 3156.3618\n","Epoch 821: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1278 - pearson_correlation: -2.2332e-16 - r2_keras: -82.7076 - rmse: 0.8666 - sae: 1882.0551 - sse: 2290.3950 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.2656e-16 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5929 - learning_rate: 1.0000e-05\n","Epoch 822/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.0781e-17 - r2_keras: -100.7567 - rmse: 0.8778 - sae: 2575.7949 - sse: 3156.3657\n","Epoch 822: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 8.3822e-18 - r2_keras: -82.7077 - rmse: 0.8666 - sae: 1882.0560 - sse: 2290.3979 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4809e-17 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5932 - learning_rate: 1.0000e-05\n","Epoch 823/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 3.9658e-16 - r2_keras: -100.7569 - rmse: 0.8778 - sae: 2575.7969 - sse: 3156.3706\n","Epoch 823: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 2.4221e-16 - r2_keras: -82.7078 - rmse: 0.8666 - sae: 1882.0575 - sse: 2290.4016 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -6.3206e-17 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5939 - learning_rate: 1.0000e-05\n","Epoch 824/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.3142e-16 - r2_keras: -100.7568 - rmse: 0.8778 - sae: 2575.7966 - sse: 3156.3701\n","Epoch 824: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 9.2801e-17 - r2_keras: -82.7078 - rmse: 0.8666 - sae: 1882.0575 - sse: 2290.4016 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.5933 - learning_rate: 1.0000e-05\n","Epoch 825/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -2.2641e-16 - r2_keras: -100.7570 - rmse: 0.8778 - sae: 2575.7974 - sse: 3156.3745\n","Epoch 825: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -9.4794e-17 - r2_keras: -82.7080 - rmse: 0.8666 - sae: 1882.0580 - sse: 2290.4050 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 4.7404e-16 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5940 - learning_rate: 1.0000e-05\n","Epoch 826/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.4675e-17 - r2_keras: -100.7570 - rmse: 0.8778 - sae: 2575.7979 - sse: 3156.3740\n","Epoch 826: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -5.0954e-17 - r2_keras: -82.7079 - rmse: 0.8666 - sae: 1882.0583 - sse: 2290.4045 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1127 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5930 - learning_rate: 1.0000e-05\n","Epoch 827/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.6755e-16 - r2_keras: -100.7571 - rmse: 0.8778 - sae: 2575.7988 - sse: 3156.3789\n","Epoch 827: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 1.2397e-16 - r2_keras: -82.7081 - rmse: 0.8666 - sae: 1882.0591 - sse: 2290.4080 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3740e-17 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5938 - learning_rate: 1.0000e-05\n","Epoch 828/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.3306e-16 - r2_keras: -100.7572 - rmse: 0.8778 - sae: 2575.7998 - sse: 3156.3818\n","Epoch 828: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -2.4233e-16 - r2_keras: -82.7082 - rmse: 0.8666 - sae: 1882.0599 - sse: 2290.4106 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.8962e-16 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5946 - learning_rate: 1.0000e-05\n","Epoch 829/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 4.3708e-16 - r2_keras: -100.7574 - rmse: 0.8778 - sae: 2575.8020 - sse: 3156.3865\n","Epoch 829: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 3.0696e-16 - r2_keras: -82.7083 - rmse: 0.8666 - sae: 1882.0615 - sse: 2290.4141 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.8962e-16 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5937 - learning_rate: 1.0000e-05\n","Epoch 830/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.6201e-16 - r2_keras: -100.7574 - rmse: 0.8778 - sae: 2575.8022 - sse: 3156.3887\n","Epoch 830: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -4.8560e-17 - r2_keras: -82.7084 - rmse: 0.8666 - sae: 1882.0618 - sse: 2290.4158 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4809e-17 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5944 - learning_rate: 1.0000e-05\n","Epoch 831/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.4803e-16 - r2_keras: -100.7574 - rmse: 0.8778 - sae: 2575.8018 - sse: 3156.3862\n","Epoch 831: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -4.5369e-17 - r2_keras: -82.7083 - rmse: 0.8666 - sae: 1882.0614 - sse: 2290.4141 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.8962e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5952 - learning_rate: 1.0000e-05\n","Epoch 832/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 2.3981e-16 - r2_keras: -100.7575 - rmse: 0.8778 - sae: 2575.8030 - sse: 3156.3914\n","Epoch 832: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 1.2166e-16 - r2_keras: -82.7085 - rmse: 0.8666 - sae: 1882.0624 - sse: 2290.4180 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1069e-17 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5950 - learning_rate: 1.0000e-05\n","Epoch 833/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.3480e-16 - r2_keras: -100.7577 - rmse: 0.8778 - sae: 2575.8049 - sse: 3156.3960\n","Epoch 833: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -1.3922e-16 - r2_keras: -82.7086 - rmse: 0.8666 - sae: 1882.0638 - sse: 2290.4211 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5952 - learning_rate: 1.0000e-05\n","Epoch 834/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.6482e-16 - r2_keras: -100.7578 - rmse: 0.8778 - sae: 2575.8062 - sse: 3156.4004\n","Epoch 834: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -2.4840e-16 - r2_keras: -82.7087 - rmse: 0.8666 - sae: 1882.0648 - sse: 2290.4248 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.2656e-16 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5943 - learning_rate: 1.0000e-05\n","Epoch 835/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 6.6407e-16 - r2_keras: -100.7579 - rmse: 0.8778 - sae: 2575.8062 - sse: 3156.4016\n","Epoch 835: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 4.6111e-16 - r2_keras: -82.7088 - rmse: 0.8666 - sae: 1882.0648 - sse: 2290.4258 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1603e-17 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5953 - learning_rate: 1.0000e-05\n","Epoch 836/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.4220e-16 - r2_keras: -100.7579 - rmse: 0.8778 - sae: 2575.8066 - sse: 3156.4016\n","Epoch 836: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -5.6582e-17 - r2_keras: -82.7088 - rmse: 0.8666 - sae: 1882.0652 - sse: 2290.4258 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.9496e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6295 - val_sse: 506.5960 - learning_rate: 1.0000e-05\n","Epoch 837/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.1393e-16 - r2_keras: -100.7580 - rmse: 0.8778 - sae: 2575.8079 - sse: 3156.4058\n","Epoch 837: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 4.2929e-17 - r2_keras: -82.7089 - rmse: 0.8666 - sae: 1882.0662 - sse: 2290.4290 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.3695e-16 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5948 - learning_rate: 1.0000e-05\n","Epoch 838/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.1772e-16 - r2_keras: -100.7580 - rmse: 0.8778 - sae: 2575.8079 - sse: 3156.4067\n","Epoch 838: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 8.6029e-17 - r2_keras: -82.7089 - rmse: 0.8666 - sae: 1882.0663 - sse: 2290.4299 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1603e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5957 - learning_rate: 1.0000e-05\n","Epoch 839/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -1.3695e-16 - r2_keras: -100.7583 - rmse: 0.8778 - sae: 2575.8108 - sse: 3156.4146\n","Epoch 839: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -1.4414e-16 - r2_keras: -82.7092 - rmse: 0.8666 - sae: 1882.0685 - sse: 2290.4358 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2137e-17 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5955 - learning_rate: 1.0000e-05\n","Epoch 840/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -4.7787e-17 - r2_keras: -100.7584 - rmse: 0.8778 - sae: 2575.8115 - sse: 3156.4180\n","Epoch 840: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -7.4792e-17 - r2_keras: -82.7093 - rmse: 0.8666 - sae: 1882.0690 - sse: 2290.4382 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -6.3206e-17 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6298 - val_sse: 506.5966 - learning_rate: 1.0000e-05\n","Epoch 841/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 1.9785e-16 - r2_keras: -100.7584 - rmse: 0.8778 - sae: 2575.8123 - sse: 3156.4180\n","Epoch 841: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 1.6964e-16 - r2_keras: -82.7093 - rmse: 0.8666 - sae: 1882.0695 - sse: 2290.4380 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1603e-17 - val_r2_keras: -35.1128 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5949 - learning_rate: 1.0000e-05\n","Epoch 842/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -6.5124e-16 - r2_keras: -100.7584 - rmse: 0.8778 - sae: 2575.8115 - sse: 3156.4175\n","Epoch 842: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -3.5443e-16 - r2_keras: -82.7093 - rmse: 0.8666 - sae: 1882.0690 - sse: 2290.4380 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5956 - learning_rate: 1.0000e-05\n","Epoch 843/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: 7.7508e-17 - r2_keras: -100.7585 - rmse: 0.8778 - sae: 2575.8120 - sse: 3156.4204\n","Epoch 843: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 4.6954e-17 - r2_keras: -82.7094 - rmse: 0.8666 - sae: 1882.0695 - sse: 2290.4404 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5963 - learning_rate: 1.0000e-05\n","Epoch 844/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2263 - mse: 0.1384 - pearson_correlation: -3.2635e-17 - r2_keras: -100.7586 - rmse: 0.8778 - sae: 2575.8140 - sse: 3156.4248\n","Epoch 844: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 2.7782e-17 - r2_keras: -82.7095 - rmse: 0.8666 - sae: 1882.0710 - sse: 2290.4441 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -5.2671e-17 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5966 - learning_rate: 1.0000e-05\n","Epoch 845/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.1312e-16 - r2_keras: -100.7588 - rmse: 0.8778 - sae: 2575.8164 - sse: 3156.4321\n","Epoch 845: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 3.5482e-16 - r2_keras: -82.7097 - rmse: 0.8666 - sae: 1882.0726 - sse: 2290.4490 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.4748e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6294 - val_sse: 506.5972 - learning_rate: 1.0000e-05\n","Epoch 846/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.1679e-16 - r2_keras: -100.7590 - rmse: 0.8778 - sae: 2575.8179 - sse: 3156.4373\n","Epoch 846: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: -6.1490e-17 - r2_keras: -82.7098 - rmse: 0.8666 - sae: 1882.0739 - sse: 2290.4529 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.8962e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5951 - learning_rate: 1.0000e-05\n","Epoch 847/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 6.3434e-16 - r2_keras: -100.7587 - rmse: 0.8778 - sae: 2575.8147 - sse: 3156.4287\n","Epoch 847: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 3.9930e-16 - r2_keras: -82.7096 - rmse: 0.8666 - sae: 1882.0717 - sse: 2290.4468 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1129 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5963 - learning_rate: 1.0000e-05\n","Epoch 848/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -3.6423e-17 - r2_keras: -100.7589 - rmse: 0.8778 - sae: 2575.8169 - sse: 3156.4341\n","Epoch 848: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2174 - mse: 0.1277 - pearson_correlation: 5.5923e-17 - r2_keras: -82.7098 - rmse: 0.8666 - sae: 1882.0732 - sse: 2290.4507 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.5801e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5970 - learning_rate: 1.0000e-05\n","Epoch 849/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.2664e-16 - r2_keras: -100.7590 - rmse: 0.8778 - sae: 2575.8179 - sse: 3156.4375\n","Epoch 849: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.0313e-16 - r2_keras: -82.7099 - rmse: 0.8666 - sae: 1882.0741 - sse: 2290.4536 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5966 - learning_rate: 1.0000e-05\n","Epoch 850/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1560 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 2.5525e-16 - r2_keras: -100.7592 - rmse: 0.8778 - sae: 2575.8198 - sse: 3156.4434\n","Epoch 850: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.1499e-16 - r2_keras: -82.7100 - rmse: 0.8666 - sae: 1882.0756 - sse: 2290.4578 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.6336e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5971 - learning_rate: 1.0000e-05\n","Epoch 851/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 4.0910e-16 - r2_keras: -100.7592 - rmse: 0.8778 - sae: 2575.8198 - sse: 3156.4426\n","Epoch 851: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.5433e-16 - r2_keras: -82.7100 - rmse: 0.8666 - sae: 1882.0756 - sse: 2290.4573 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.8962e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6295 - val_sse: 506.5977 - learning_rate: 1.0000e-05\n","Epoch 852/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -6.9931e-18 - r2_keras: -100.7593 - rmse: 0.8778 - sae: 2575.8218 - sse: 3156.4478\n","Epoch 852: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.6004e-17 - r2_keras: -82.7102 - rmse: 0.8666 - sae: 1882.0770 - sse: 2290.4612 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3175e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5969 - learning_rate: 1.0000e-05\n","Epoch 853/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.0694e-16 - r2_keras: -100.7594 - rmse: 0.8778 - sae: 2575.8208 - sse: 3156.4480\n","Epoch 853: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.8830e-17 - r2_keras: -82.7102 - rmse: 0.8666 - sae: 1882.0764 - sse: 2290.4617 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.8962e-16 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5978 - learning_rate: 1.0000e-05\n","Epoch 854/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.9179e-16 - r2_keras: -100.7595 - rmse: 0.8778 - sae: 2575.8228 - sse: 3156.4526\n","Epoch 854: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.2567e-16 - r2_keras: -82.7103 - rmse: 0.8666 - sae: 1882.0778 - sse: 2290.4651 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2137e-17 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5969 - learning_rate: 1.0000e-05\n","Epoch 855/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.2548e-16 - r2_keras: -100.7596 - rmse: 0.8778 - sae: 2575.8237 - sse: 3156.4556\n","Epoch 855: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.7108e-16 - r2_keras: -82.7104 - rmse: 0.8666 - sae: 1882.0786 - sse: 2290.4675 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.0549e-16 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5979 - learning_rate: 1.0000e-05\n","Epoch 856/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.0664e-16 - r2_keras: -100.7598 - rmse: 0.8778 - sae: 2575.8252 - sse: 3156.4609\n","Epoch 856: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.0978e-16 - r2_keras: -82.7106 - rmse: 0.8666 - sae: 1882.0797 - sse: 2290.4714 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1603e-17 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5977 - learning_rate: 1.0000e-05\n","Epoch 857/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.0129e-17 - r2_keras: -100.7597 - rmse: 0.8778 - sae: 2575.8250 - sse: 3156.4595\n","Epoch 857: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -9.5880e-17 - r2_keras: -82.7105 - rmse: 0.8666 - sae: 1882.0795 - sse: 2290.4702 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.2641e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5978 - learning_rate: 1.0000e-05\n","Epoch 858/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 2.2116e-16 - r2_keras: -100.7599 - rmse: 0.8779 - sae: 2575.8264 - sse: 3156.4639\n","Epoch 858: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.3706e-16 - r2_keras: -82.7107 - rmse: 0.8666 - sae: 1882.0807 - sse: 2290.4736 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3739e-17 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5984 - learning_rate: 1.0000e-05\n","Epoch 859/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.7710e-16 - r2_keras: -100.7600 - rmse: 0.8779 - sae: 2575.8279 - sse: 3156.4675\n","Epoch 859: val_loss improved from 0.19059 to 0.19059, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.3001e-16 - r2_keras: -82.7108 - rmse: 0.8666 - sae: 1882.0818 - sse: 2290.4766 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.4748e-16 - val_r2_keras: -35.1130 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.5970 - learning_rate: 1.0000e-05\n","Epoch 860/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.0857e-16 - r2_keras: -100.7600 - rmse: 0.8779 - sae: 2575.8271 - sse: 3156.4678\n","Epoch 860: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.7648e-16 - r2_keras: -82.7108 - rmse: 0.8666 - sae: 1882.0814 - sse: 2290.4768 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5986 - learning_rate: 1.0000e-05\n","Epoch 861/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -6.4744e-16 - r2_keras: -100.7602 - rmse: 0.8779 - sae: 2575.8301 - sse: 3156.4749\n","Epoch 861: val_loss did not improve from 0.19059\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -4.2361e-16 - r2_keras: -82.7110 - rmse: 0.8666 - sae: 1882.0835 - sse: 2290.4822 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4808e-17 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6294 - val_sse: 506.5989 - learning_rate: 1.0000e-05\n","Epoch 862/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.3724e-16 - r2_keras: -100.7601 - rmse: 0.8779 - sae: 2575.8291 - sse: 3156.4717\n","Epoch 862: val_loss improved from 0.19059 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 9.2436e-17 - r2_keras: -82.7109 - rmse: 0.8666 - sae: 1882.0829 - sse: 2290.4797 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2137e-17 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.5982 - learning_rate: 1.0000e-05\n","Epoch 863/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.0979e-16 - r2_keras: -100.7603 - rmse: 0.8779 - sae: 2575.8311 - sse: 3156.4780\n","Epoch 863: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.2146e-16 - r2_keras: -82.7111 - rmse: 0.8666 - sae: 1882.0842 - sse: 2290.4844 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2122e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6294 - val_sse: 506.5993 - learning_rate: 1.0000e-05\n","Epoch 864/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.6603e-16 - r2_keras: -100.7605 - rmse: 0.8779 - sae: 2575.8330 - sse: 3156.4832\n","Epoch 864: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.4150e-16 - r2_keras: -82.7112 - rmse: 0.8666 - sae: 1882.0857 - sse: 2290.4883 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.5989 - learning_rate: 1.0000e-05\n","Epoch 865/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 7.2057e-16 - r2_keras: -100.7605 - rmse: 0.8779 - sae: 2575.8328 - sse: 3156.4839\n","Epoch 865: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.9876e-16 - r2_keras: -82.7113 - rmse: 0.8666 - sae: 1882.0856 - sse: 2290.4890 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1068e-16 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5983 - learning_rate: 1.0000e-05\n","Epoch 866/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.3310e-18 - r2_keras: -100.7604 - rmse: 0.8779 - sae: 2575.8311 - sse: 3156.4790\n","Epoch 866: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.5226e-18 - r2_keras: -82.7112 - rmse: 0.8666 - sae: 1882.0845 - sse: 2290.4856 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2137e-17 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.5992 - learning_rate: 1.0000e-05\n","Epoch 867/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.4843e-16 - r2_keras: -100.7605 - rmse: 0.8779 - sae: 2575.8335 - sse: 3156.4849\n","Epoch 867: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.8812e-16 - r2_keras: -82.7113 - rmse: 0.8666 - sae: 1882.0863 - sse: 2290.4900 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.2641e-16 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.5987 - learning_rate: 1.0000e-05\n","Epoch 868/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.1189e-16 - r2_keras: -100.7607 - rmse: 0.8779 - sae: 2575.8335 - sse: 3156.4883\n","Epoch 868: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.0148e-16 - r2_keras: -82.7114 - rmse: 0.8666 - sae: 1882.0863 - sse: 2290.4924 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.6335e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.5993 - learning_rate: 1.0000e-05\n","Epoch 869/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.2541e-17 - r2_keras: -100.7609 - rmse: 0.8779 - sae: 2575.8367 - sse: 3156.4951\n","Epoch 869: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.9211e-17 - r2_keras: -82.7116 - rmse: 0.8666 - sae: 1882.0886 - sse: 2290.4976 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.5991 - learning_rate: 1.0000e-05\n","Epoch 870/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.7453e-16 - r2_keras: -100.7609 - rmse: 0.8779 - sae: 2575.8367 - sse: 3156.4971\n","Epoch 870: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.6731e-16 - r2_keras: -82.7117 - rmse: 0.8666 - sae: 1882.0887 - sse: 2290.4993 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.8442e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.6002 - learning_rate: 1.0000e-05\n","Epoch 871/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.9038e-16 - r2_keras: -100.7611 - rmse: 0.8779 - sae: 2575.8384 - sse: 3156.5020\n","Epoch 871: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.4626e-16 - r2_keras: -82.7118 - rmse: 0.8666 - sae: 1882.0901 - sse: 2290.5029 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.2122e-16 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.5983 - learning_rate: 1.0000e-05\n","Epoch 872/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.3764e-16 - r2_keras: -100.7609 - rmse: 0.8779 - sae: 2575.8364 - sse: 3156.4961\n","Epoch 872: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.8140e-16 - r2_keras: -82.7117 - rmse: 0.8666 - sae: 1882.0886 - sse: 2290.4988 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -5.2671e-17 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5992 - learning_rate: 1.0000e-05\n","Epoch 873/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 8.7674e-16 - r2_keras: -100.7611 - rmse: 0.8779 - sae: 2575.8379 - sse: 3156.5010\n","Epoch 873: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.3921e-16 - r2_keras: -82.7118 - rmse: 0.8666 - sae: 1882.0897 - sse: 2290.5024 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.8961e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6295 - val_sse: 506.6003 - learning_rate: 1.0000e-05\n","Epoch 874/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.1116e-15 - r2_keras: -100.7613 - rmse: 0.8779 - sae: 2575.8408 - sse: 3156.5083\n","Epoch 874: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -7.1511e-16 - r2_keras: -82.7120 - rmse: 0.8666 - sae: 1882.0919 - sse: 2290.5078 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.7389e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.5998 - learning_rate: 1.0000e-05\n","Epoch 875/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 4.3181e-16 - r2_keras: -100.7613 - rmse: 0.8779 - sae: 2575.8406 - sse: 3156.5093\n","Epoch 875: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.3081e-16 - r2_keras: -82.7120 - rmse: 0.8666 - sae: 1882.0918 - sse: 2290.5085 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1588e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6003 - learning_rate: 1.0000e-05\n","Epoch 876/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 2.8846e-17 - r2_keras: -100.7615 - rmse: 0.8779 - sae: 2575.8420 - sse: 3156.5137\n","Epoch 876: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -4.0684e-17 - r2_keras: -82.7122 - rmse: 0.8666 - sae: 1882.0930 - sse: 2290.5122 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4808e-17 - val_r2_keras: -35.1131 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.5985 - learning_rate: 1.0000e-05\n","Epoch 877/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.2540e-17 - r2_keras: -100.7613 - rmse: 0.8779 - sae: 2575.8398 - sse: 3156.5083\n","Epoch 877: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.9760e-17 - r2_keras: -82.7120 - rmse: 0.8666 - sae: 1882.0914 - sse: 2290.5081 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.3175e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6002 - learning_rate: 1.0000e-05\n","Epoch 878/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.1439e-16 - r2_keras: -100.7615 - rmse: 0.8779 - sae: 2575.8423 - sse: 3156.5139\n","Epoch 878: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.5298e-16 - r2_keras: -82.7122 - rmse: 0.8666 - sae: 1882.0931 - sse: 2290.5122 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -3.1602e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.6008 - learning_rate: 1.0000e-05\n","Epoch 879/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.7703e-17 - r2_keras: -100.7616 - rmse: 0.8779 - sae: 2575.8438 - sse: 3156.5186\n","Epoch 879: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.0920e-17 - r2_keras: -82.7123 - rmse: 0.8666 - sae: 1882.0944 - sse: 2290.5159 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.4244e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.5997 - learning_rate: 1.0000e-05\n","Epoch 880/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.3420e-16 - r2_keras: -100.7617 - rmse: 0.8779 - sae: 2575.8438 - sse: 3156.5195\n","Epoch 880: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.3915e-16 - r2_keras: -82.7124 - rmse: 0.8666 - sae: 1882.0944 - sse: 2290.5168 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3739e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6006 - learning_rate: 1.0000e-05\n","Epoch 881/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 2.8846e-17 - r2_keras: -100.7620 - rmse: 0.8779 - sae: 2575.8472 - sse: 3156.5288\n","Epoch 881: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 7.9082e-18 - r2_keras: -82.7126 - rmse: 0.8666 - sae: 1882.0968 - sse: 2290.5237 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6296 - val_sse: 506.6017 - learning_rate: 1.0000e-05\n","Epoch 882/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.3671e-16 - r2_keras: -100.7618 - rmse: 0.8779 - sae: 2575.8457 - sse: 3156.5242\n","Epoch 882: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.0781e-16 - r2_keras: -82.7125 - rmse: 0.8666 - sae: 1882.0958 - sse: 2290.5203 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.5801e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6002 - learning_rate: 1.0000e-05\n","Epoch 883/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.4563e-16 - r2_keras: -100.7618 - rmse: 0.8779 - sae: 2575.8452 - sse: 3156.5244\n","Epoch 883: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -8.2607e-17 - r2_keras: -82.7125 - rmse: 0.8666 - sae: 1882.0956 - sse: 2290.5205 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 5.2671e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6009 - learning_rate: 1.0000e-05\n","Epoch 884/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.8461e-17 - r2_keras: -100.7621 - rmse: 0.8779 - sae: 2575.8481 - sse: 3156.5317\n","Epoch 884: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -9.2300e-17 - r2_keras: -82.7127 - rmse: 0.8666 - sae: 1882.0978 - sse: 2290.5261 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.7908e-16 - val_r2_keras: -35.1132 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.6002 - learning_rate: 1.0000e-05\n","Epoch 885/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 7.2988e-16 - r2_keras: -100.7621 - rmse: 0.8779 - sae: 2575.8479 - sse: 3156.5325\n","Epoch 885: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.0782e-16 - r2_keras: -82.7128 - rmse: 0.8666 - sae: 1882.0975 - sse: 2290.5266 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.0549e-16 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6016 - learning_rate: 1.0000e-05\n","Epoch 886/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.0163e-16 - r2_keras: -100.7623 - rmse: 0.8779 - sae: 2575.8496 - sse: 3156.5378\n","Epoch 886: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.5235e-16 - r2_keras: -82.7129 - rmse: 0.8666 - sae: 1882.0990 - sse: 2290.5310 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.8457e-16 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.6021 - learning_rate: 1.0000e-05\n","Epoch 887/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.1532e-16 - r2_keras: -100.7622 - rmse: 0.8779 - sae: 2575.8486 - sse: 3156.5347\n","Epoch 887: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.5017e-16 - r2_keras: -82.7128 - rmse: 0.8666 - sae: 1882.0983 - sse: 2290.5286 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.1068e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6011 - learning_rate: 1.0000e-05\n","Epoch 888/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 8.8868e-17 - r2_keras: -100.7624 - rmse: 0.8779 - sae: 2575.8511 - sse: 3156.5408\n","Epoch 888: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.7451e-17 - r2_keras: -82.7130 - rmse: 0.8666 - sae: 1882.1000 - sse: 2290.5332 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.4748e-16 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6018 - learning_rate: 1.0000e-05\n","Epoch 889/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.4481e-16 - r2_keras: -100.7625 - rmse: 0.8779 - sae: 2575.8525 - sse: 3156.5469\n","Epoch 889: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.4843e-16 - r2_keras: -82.7132 - rmse: 0.8666 - sae: 1882.1012 - sse: 2290.5376 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.6855e-16 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6012 - learning_rate: 1.0000e-05\n","Epoch 890/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.9318e-16 - r2_keras: -100.7625 - rmse: 0.8779 - sae: 2575.8523 - sse: 3156.5466\n","Epoch 890: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -9.6234e-17 - r2_keras: -82.7132 - rmse: 0.8666 - sae: 1882.1011 - sse: 2290.5376 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -4.2136e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6018 - learning_rate: 1.0000e-05\n","Epoch 891/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.5559e-16 - r2_keras: -100.7626 - rmse: 0.8779 - sae: 2575.8530 - sse: 3156.5479\n","Epoch 891: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 8.0139e-17 - r2_keras: -82.7133 - rmse: 0.8666 - sae: 1882.1017 - sse: 2290.5388 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.6022 - learning_rate: 1.0000e-05\n","Epoch 892/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.6245e-17 - r2_keras: -100.7626 - rmse: 0.8779 - sae: 2575.8535 - sse: 3156.5479\n","Epoch 892: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -9.3822e-17 - r2_keras: -82.7132 - rmse: 0.8666 - sae: 1882.1021 - sse: 2290.5388 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3739e-17 - val_r2_keras: -35.1133 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6018 - learning_rate: 1.0000e-05\n","Epoch 893/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -5.4136e-16 - r2_keras: -100.7627 - rmse: 0.8779 - sae: 2575.8540 - sse: 3156.5520\n","Epoch 893: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -4.1469e-16 - r2_keras: -82.7134 - rmse: 0.8666 - sae: 1882.1024 - sse: 2290.5420 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.7389e-16 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6023 - learning_rate: 1.0000e-05\n","Epoch 894/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.3105e-16 - r2_keras: -100.7630 - rmse: 0.8779 - sae: 2575.8569 - sse: 3156.5598\n","Epoch 894: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.4602e-16 - r2_keras: -82.7136 - rmse: 0.8666 - sae: 1882.1046 - sse: 2290.5476 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6028 - learning_rate: 1.0000e-05\n","Epoch 895/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.9334e-17 - r2_keras: -100.7630 - rmse: 0.8779 - sae: 2575.8574 - sse: 3156.5625\n","Epoch 895: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.2641e-17 - r2_keras: -82.7137 - rmse: 0.8666 - sae: 1882.1051 - sse: 2290.5498 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.8442e-16 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6024 - learning_rate: 1.0000e-05\n","Epoch 896/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.8140e-16 - r2_keras: -100.7630 - rmse: 0.8779 - sae: 2575.8564 - sse: 3156.5610\n","Epoch 896: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.4530e-16 - r2_keras: -82.7137 - rmse: 0.8666 - sae: 1882.1045 - sse: 2290.5491 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -6.3205e-17 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6026 - learning_rate: 1.0000e-05\n","Epoch 897/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -3.8460e-17 - r2_keras: -100.7629 - rmse: 0.8779 - sae: 2575.8560 - sse: 3156.5574\n","Epoch 897: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.7056e-17 - r2_keras: -82.7136 - rmse: 0.8666 - sae: 1882.1041 - sse: 2290.5466 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6024 - learning_rate: 1.0000e-05\n","Epoch 898/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.0285e-16 - r2_keras: -100.7632 - rmse: 0.8779 - sae: 2575.8586 - sse: 3156.5657\n","Epoch 898: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 9.6401e-17 - r2_keras: -82.7138 - rmse: 0.8666 - sae: 1882.1061 - sse: 2290.5525 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -8.4273e-17 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6030 - learning_rate: 1.0000e-05\n","Epoch 899/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.1218e-16 - r2_keras: -100.7632 - rmse: 0.8779 - sae: 2575.8594 - sse: 3156.5669\n","Epoch 899: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 6.3934e-17 - r2_keras: -82.7139 - rmse: 0.8666 - sae: 1882.1068 - sse: 2290.5537 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 3.1602e-17 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6027 - learning_rate: 1.0000e-05\n","Epoch 900/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -7.2987e-16 - r2_keras: -100.7634 - rmse: 0.8779 - sae: 2575.8604 - sse: 3156.5720\n","Epoch 900: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.9270e-16 - r2_keras: -82.7140 - rmse: 0.8666 - sae: 1882.1075 - sse: 2290.5574 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -9.4807e-17 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6035 - learning_rate: 1.0000e-05\n","Epoch 901/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.1553e-16 - r2_keras: -100.7636 - rmse: 0.8779 - sae: 2575.8635 - sse: 3156.5806\n","Epoch 901: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -4.9227e-16 - r2_keras: -82.7142 - rmse: 0.8666 - sae: 1882.1099 - sse: 2290.5637 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3175e-16 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6033 - learning_rate: 1.0000e-05\n","Epoch 902/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.4958e-16 - r2_keras: -100.7633 - rmse: 0.8779 - sae: 2575.8594 - sse: 3156.5698\n","Epoch 902: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.0821e-16 - r2_keras: -82.7140 - rmse: 0.8666 - sae: 1882.1069 - sse: 2290.5564 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.0015e-16 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6032 - learning_rate: 1.0000e-05\n","Epoch 903/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.6531e-16 - r2_keras: -100.7635 - rmse: 0.8779 - sae: 2575.8628 - sse: 3156.5779\n","Epoch 903: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.4275e-16 - r2_keras: -82.7142 - rmse: 0.8666 - sae: 1882.1094 - sse: 2290.5620 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6035 - learning_rate: 1.0000e-05\n","Epoch 904/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.2371e-16 - r2_keras: -100.7636 - rmse: 0.8779 - sae: 2575.8633 - sse: 3156.5806\n","Epoch 904: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.1345e-16 - r2_keras: -82.7142 - rmse: 0.8666 - sae: 1882.1097 - sse: 2290.5642 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 6.3205e-17 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6028 - learning_rate: 1.0000e-05\n","Epoch 905/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 9.6441e-17 - r2_keras: -100.7638 - rmse: 0.8779 - sae: 2575.8643 - sse: 3156.5845\n","Epoch 905: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 8.1277e-17 - r2_keras: -82.7144 - rmse: 0.8666 - sae: 1882.1106 - sse: 2290.5671 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.3694e-16 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6041 - learning_rate: 1.0000e-05\n","Epoch 906/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.8273e-17 - r2_keras: -100.7639 - rmse: 0.8779 - sae: 2575.8662 - sse: 3156.5896\n","Epoch 906: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.7148e-17 - r2_keras: -82.7145 - rmse: 0.8666 - sae: 1882.1122 - sse: 2290.5713 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1068e-17 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.6042 - learning_rate: 1.0000e-05\n","Epoch 907/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -3.0710e-16 - r2_keras: -100.7638 - rmse: 0.8779 - sae: 2575.8650 - sse: 3156.5850\n","Epoch 907: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.9199e-16 - r2_keras: -82.7144 - rmse: 0.8666 - sae: 1882.1112 - sse: 2290.5679 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.1068e-17 - val_r2_keras: -35.1134 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6031 - learning_rate: 1.0000e-05\n","Epoch 908/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -9.6121e-16 - r2_keras: -100.7639 - rmse: 0.8779 - sae: 2575.8652 - sse: 3156.5874\n","Epoch 908: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0593 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -6.2477e-16 - r2_keras: -82.7145 - rmse: 0.8666 - sae: 1882.1115 - sse: 2290.5696 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6036 - learning_rate: 1.0000e-05\n","Epoch 909/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.1436e-16 - r2_keras: -100.7640 - rmse: 0.8779 - sae: 2575.8665 - sse: 3156.5913\n","Epoch 909: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -6.4810e-16 - r2_keras: -82.7146 - rmse: 0.8666 - sae: 1882.1124 - sse: 2290.5728 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3738e-17 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6046 - learning_rate: 1.0000e-05\n","Epoch 910/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.5488e-16 - r2_keras: -100.7641 - rmse: 0.8779 - sae: 2575.8677 - sse: 3156.5952\n","Epoch 910: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.5215e-16 - r2_keras: -82.7147 - rmse: 0.8666 - sae: 1882.1134 - sse: 2290.5759 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3175e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6048 - learning_rate: 1.0000e-05\n","Epoch 911/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.8272e-16 - r2_keras: -100.7643 - rmse: 0.8779 - sae: 2575.8706 - sse: 3156.6021\n","Epoch 911: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.6442e-16 - r2_keras: -82.7149 - rmse: 0.8666 - sae: 1882.1155 - sse: 2290.5808 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6045 - learning_rate: 1.0000e-05\n","Epoch 912/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.7929e-16 - r2_keras: -100.7642 - rmse: 0.8779 - sae: 2575.8682 - sse: 3156.5967\n","Epoch 912: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.4500e-16 - r2_keras: -82.7148 - rmse: 0.8666 - sae: 1882.1139 - sse: 2290.5771 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.2641e-16 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6044 - learning_rate: 1.0000e-05\n","Epoch 913/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.5174e-16 - r2_keras: -100.7644 - rmse: 0.8779 - sae: 2575.8706 - sse: 3156.6030\n","Epoch 913: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.1782e-16 - r2_keras: -82.7149 - rmse: 0.8666 - sae: 1882.1156 - sse: 2290.5815 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -7.3738e-17 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6043 - learning_rate: 1.0000e-05\n","Epoch 914/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.0260e-16 - r2_keras: -100.7644 - rmse: 0.8779 - sae: 2575.8706 - sse: 3156.6040\n","Epoch 914: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.0676e-16 - r2_keras: -82.7150 - rmse: 0.8666 - sae: 1882.1157 - sse: 2290.5825 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.2641e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6050 - learning_rate: 1.0000e-05\n","Epoch 915/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.7540e-16 - r2_keras: -100.7645 - rmse: 0.8779 - sae: 2575.8718 - sse: 3156.6089\n","Epoch 915: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.3108e-16 - r2_keras: -82.7151 - rmse: 0.8666 - sae: 1882.1167 - sse: 2290.5864 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2121e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6050 - learning_rate: 1.0000e-05\n","Epoch 916/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 4.2801e-16 - r2_keras: -100.7646 - rmse: 0.8779 - sae: 2575.8726 - sse: 3156.6113\n","Epoch 916: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.0562e-16 - r2_keras: -82.7152 - rmse: 0.8666 - sae: 1882.1173 - sse: 2290.5884 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.3694e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.6056 - learning_rate: 1.0000e-05\n","Epoch 917/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.3833e-16 - r2_keras: -100.7646 - rmse: 0.8779 - sae: 2575.8728 - sse: 3156.6094\n","Epoch 917: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.9851e-16 - r2_keras: -82.7152 - rmse: 0.8666 - sae: 1882.1176 - sse: 2290.5869 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6047 - learning_rate: 1.0000e-05\n","Epoch 918/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.5844e-16 - r2_keras: -100.7647 - rmse: 0.8779 - sae: 2575.8740 - sse: 3156.6152\n","Epoch 918: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.3455e-16 - r2_keras: -82.7153 - rmse: 0.8666 - sae: 1882.1184 - sse: 2290.5911 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 7.3738e-17 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6052 - learning_rate: 1.0000e-05\n","Epoch 919/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.7929e-16 - r2_keras: -100.7649 - rmse: 0.8779 - sae: 2575.8755 - sse: 3156.6187\n","Epoch 919: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.7660e-16 - r2_keras: -82.7154 - rmse: 0.8666 - sae: 1882.1195 - sse: 2290.5938 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.4228e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6049 - learning_rate: 1.0000e-05\n","Epoch 920/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 4.9007e-16 - r2_keras: -100.7649 - rmse: 0.8779 - sae: 2575.8755 - sse: 3156.6196\n","Epoch 920: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.6963e-16 - r2_keras: -82.7155 - rmse: 0.8666 - sae: 1882.1196 - sse: 2290.5947 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.1587e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6055 - learning_rate: 1.0000e-05\n","Epoch 921/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.0751e-16 - r2_keras: -100.7650 - rmse: 0.8779 - sae: 2575.8767 - sse: 3156.6245\n","Epoch 921: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.2781e-16 - r2_keras: -82.7156 - rmse: 0.8666 - sae: 1882.1206 - sse: 2290.5986 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.4228e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6058 - learning_rate: 1.0000e-05\n","Epoch 922/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 5.9729e-17 - r2_keras: -100.7650 - rmse: 0.8779 - sae: 2575.8765 - sse: 3156.6226\n","Epoch 922: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 6.2934e-17 - r2_keras: -82.7156 - rmse: 0.8666 - sae: 1882.1205 - sse: 2290.5972 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.2121e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6053 - learning_rate: 1.0000e-05\n","Epoch 923/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -5.2153e-17 - r2_keras: -100.7651 - rmse: 0.8779 - sae: 2575.8779 - sse: 3156.6274\n","Epoch 923: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.8355e-17 - r2_keras: -82.7157 - rmse: 0.8666 - sae: 1882.1215 - sse: 2290.6006 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6065 - learning_rate: 1.0000e-05\n","Epoch 924/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 9.5595e-16 - r2_keras: -100.7652 - rmse: 0.8779 - sae: 2575.8784 - sse: 3156.6292\n","Epoch 924: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.7126e-16 - r2_keras: -82.7158 - rmse: 0.8666 - sae: 1882.1219 - sse: 2290.6021 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.2121e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.6050 - learning_rate: 1.0000e-05\n","Epoch 925/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 2.7621e-16 - r2_keras: -100.7653 - rmse: 0.8779 - sae: 2575.8794 - sse: 3156.6321\n","Epoch 925: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.9782e-16 - r2_keras: -82.7159 - rmse: 0.8666 - sae: 1882.1227 - sse: 2290.6045 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 9.4806e-17 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6057 - learning_rate: 1.0000e-05\n","Epoch 926/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.8822e-16 - r2_keras: -100.7654 - rmse: 0.8779 - sae: 2575.8801 - sse: 3156.6357\n","Epoch 926: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -8.4438e-17 - r2_keras: -82.7160 - rmse: 0.8666 - sae: 1882.1233 - sse: 2290.6072 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -5.2670e-17 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6062 - learning_rate: 1.0000e-05\n","Epoch 927/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 2.7242e-16 - r2_keras: -100.7655 - rmse: 0.8779 - sae: 2575.8813 - sse: 3156.6401\n","Epoch 927: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.1180e-16 - r2_keras: -82.7161 - rmse: 0.8666 - sae: 1882.1244 - sse: 2290.6106 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6062 - learning_rate: 1.0000e-05\n","Epoch 928/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.7611e-16 - r2_keras: -100.7654 - rmse: 0.8779 - sae: 2575.8804 - sse: 3156.6357\n","Epoch 928: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -6.9776e-16 - r2_keras: -82.7160 - rmse: 0.8666 - sae: 1882.1237 - sse: 2290.6077 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6068 - learning_rate: 1.0000e-05\n","Epoch 929/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -2.7213e-16 - r2_keras: -100.7656 - rmse: 0.8779 - sae: 2575.8828 - sse: 3156.6426\n","Epoch 929: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.0689e-16 - r2_keras: -82.7162 - rmse: 0.8666 - sae: 1882.1254 - sse: 2290.6125 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -2.5282e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6292 - val_sse: 506.6075 - learning_rate: 1.0000e-05\n","Epoch 930/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.8925e-16 - r2_keras: -100.7658 - rmse: 0.8779 - sae: 2575.8843 - sse: 3156.6479\n","Epoch 930: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.8356e-16 - r2_keras: -82.7163 - rmse: 0.8666 - sae: 1882.1266 - sse: 2290.6167 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.3175e-16 - val_r2_keras: -35.1136 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.6061 - learning_rate: 1.0000e-05\n","Epoch 931/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.5892e-16 - r2_keras: -100.7658 - rmse: 0.8779 - sae: 2575.8838 - sse: 3156.6479\n","Epoch 931: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.8912e-16 - r2_keras: -82.7164 - rmse: 0.8666 - sae: 1882.1263 - sse: 2290.6169 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.4748e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6075 - learning_rate: 1.0000e-05\n","Epoch 932/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 6.3661e-16 - r2_keras: -100.7660 - rmse: 0.8779 - sae: 2575.8865 - sse: 3156.6541\n","Epoch 932: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.4139e-16 - r2_keras: -82.7165 - rmse: 0.8666 - sae: 1882.1283 - sse: 2290.6213 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 2.8442e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6068 - learning_rate: 1.0000e-05\n","Epoch 933/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -5.8271e-19 - r2_keras: -100.7659 - rmse: 0.8779 - sae: 2575.8843 - sse: 3156.6497\n","Epoch 933: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.1876e-17 - r2_keras: -82.7164 - rmse: 0.8666 - sae: 1882.1267 - sse: 2290.6182 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.0534e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6071 - learning_rate: 1.0000e-05\n","Epoch 934/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -9.0320e-17 - r2_keras: -100.7661 - rmse: 0.8779 - sae: 2575.8872 - sse: 3156.6567\n","Epoch 934: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -6.7761e-17 - r2_keras: -82.7166 - rmse: 0.8666 - sae: 1882.1288 - sse: 2290.6235 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: -1.0534e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6077 - learning_rate: 1.0000e-05\n","Epoch 935/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -3.9158e-16 - r2_keras: -100.7661 - rmse: 0.8779 - sae: 2575.8872 - sse: 3156.6577\n","Epoch 935: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.5020e-16 - r2_keras: -82.7167 - rmse: 0.8666 - sae: 1882.1289 - sse: 2290.6245 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -3.1602e-17 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6071 - learning_rate: 1.0000e-05\n","Epoch 936/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 3.9916e-17 - r2_keras: -100.7663 - rmse: 0.8779 - sae: 2575.8887 - sse: 3156.6626\n","Epoch 936: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.9724e-17 - r2_keras: -82.7168 - rmse: 0.8666 - sae: 1882.1300 - sse: 2290.6282 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2204 - val_pearson_correlation: 1.2641e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6293 - val_sse: 506.6085 - learning_rate: 1.0000e-05\n","Epoch 937/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 6.1213e-16 - r2_keras: -100.7665 - rmse: 0.8779 - sae: 2575.8914 - sse: 3156.6692\n","Epoch 937: val_loss improved from 0.19058 to 0.19058, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.1516e-16 - r2_keras: -82.7170 - rmse: 0.8666 - sae: 1882.1321 - sse: 2290.6331 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.8961e-16 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6072 - learning_rate: 1.0000e-05\n","Epoch 938/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.0605e-16 - r2_keras: -100.7663 - rmse: 0.8779 - sae: 2575.8887 - sse: 3156.6624\n","Epoch 938: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 9.3816e-17 - r2_keras: -82.7168 - rmse: 0.8666 - sae: 1882.1301 - sse: 2290.6279 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.8961e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6076 - learning_rate: 1.0000e-05\n","Epoch 939/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -4.3616e-16 - r2_keras: -100.7664 - rmse: 0.8779 - sae: 2575.8896 - sse: 3156.6660\n","Epoch 939: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.9548e-16 - r2_keras: -82.7169 - rmse: 0.8666 - sae: 1882.1310 - sse: 2290.6311 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 2.5282e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6080 - learning_rate: 1.0000e-05\n","Epoch 940/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -8.5366e-17 - r2_keras: -100.7666 - rmse: 0.8779 - sae: 2575.8921 - sse: 3156.6719\n","Epoch 940: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -7.5779e-17 - r2_keras: -82.7171 - rmse: 0.8666 - sae: 1882.1327 - sse: 2290.6353 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -6.3204e-17 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6084 - learning_rate: 1.0000e-05\n","Epoch 941/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -3.1495e-16 - r2_keras: -100.7667 - rmse: 0.8779 - sae: 2575.8926 - sse: 3156.6743\n","Epoch 941: val_loss did not improve from 0.19058\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.8072e-16 - r2_keras: -82.7172 - rmse: 0.8666 - sae: 1882.1332 - sse: 2290.6372 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.5801e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6089 - learning_rate: 1.0000e-05\n","Epoch 942/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -6.6166e-16 - r2_keras: -100.7668 - rmse: 0.8779 - sae: 2575.8940 - sse: 3156.6790\n","Epoch 942: val_loss improved from 0.19058 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.8875e-16 - r2_keras: -82.7173 - rmse: 0.8666 - sae: 1882.1344 - sse: 2290.6409 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -2.1068e-17 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.6074 - learning_rate: 1.0000e-05\n","Epoch 943/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -9.6350e-16 - r2_keras: -100.7666 - rmse: 0.8779 - sae: 2575.8921 - sse: 3156.6733\n","Epoch 943: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -6.1450e-16 - r2_keras: -82.7172 - rmse: 0.8666 - sae: 1882.1329 - sse: 2290.6367 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 2.0015e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6082 - learning_rate: 1.0000e-05\n","Epoch 944/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -7.5751e-17 - r2_keras: -100.7668 - rmse: 0.8779 - sae: 2575.8940 - sse: 3156.6802\n","Epoch 944: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -9.9087e-17 - r2_keras: -82.7174 - rmse: 0.8666 - sae: 1882.1344 - sse: 2290.6418 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.1587e-16 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6090 - learning_rate: 1.0000e-05\n","Epoch 945/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: -1.0809e-16 - r2_keras: -100.7670 - rmse: 0.8779 - sae: 2575.8958 - sse: 3156.6841\n","Epoch 945: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.4041e-17 - r2_keras: -82.7175 - rmse: 0.8666 - sae: 1882.1357 - sse: 2290.6450 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -8.4272e-17 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6085 - learning_rate: 1.0000e-05\n","Epoch 946/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 1.6170e-16 - r2_keras: -100.7670 - rmse: 0.8779 - sae: 2575.8960 - sse: 3156.6858\n","Epoch 946: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.5073e-16 - r2_keras: -82.7175 - rmse: 0.8666 - sae: 1882.1359 - sse: 2290.6462 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 4.2136e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6093 - learning_rate: 1.0000e-05\n","Epoch 947/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1384 - pearson_correlation: 6.9341e-17 - r2_keras: -100.7672 - rmse: 0.8779 - sae: 2575.8982 - sse: 3156.6924\n","Epoch 947: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.7737e-17 - r2_keras: -82.7177 - rmse: 0.8666 - sae: 1882.1376 - sse: 2290.6511 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6083 - learning_rate: 1.0000e-05\n","Epoch 948/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -3.8167e-17 - r2_keras: -100.7670 - rmse: 0.8779 - sae: 2575.8958 - sse: 3156.6863\n","Epoch 948: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.2049e-17 - r2_keras: -82.7176 - rmse: 0.8666 - sae: 1882.1359 - sse: 2290.6467 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6090 - learning_rate: 1.0000e-05\n","Epoch 949/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -1.9229e-16 - r2_keras: -100.7674 - rmse: 0.8779 - sae: 2575.8997 - sse: 3156.6968\n","Epoch 949: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.9329e-16 - r2_keras: -82.7178 - rmse: 0.8666 - sae: 1882.1388 - sse: 2290.6545 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6100 - learning_rate: 1.0000e-05\n","Epoch 950/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.4655e-16 - r2_keras: -100.7674 - rmse: 0.8779 - sae: 2575.8999 - sse: 3156.6978\n","Epoch 950: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 6.5623e-17 - r2_keras: -82.7179 - rmse: 0.8666 - sae: 1882.1390 - sse: 2290.6555 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -3.5815e-16 - val_r2_keras: -35.1138 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.6089 - learning_rate: 1.0000e-05\n","Epoch 951/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -9.9875e-16 - r2_keras: -100.7674 - rmse: 0.8779 - sae: 2575.8999 - sse: 3156.6987\n","Epoch 951: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1510 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -6.4508e-16 - r2_keras: -82.7179 - rmse: 0.8666 - sae: 1882.1390 - sse: 2290.6565 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -9.4805e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6096 - learning_rate: 1.0000e-05\n","Epoch 952/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -6.7068e-16 - r2_keras: -100.7676 - rmse: 0.8779 - sae: 2575.9019 - sse: 3156.7048\n","Epoch 952: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -4.7307e-16 - r2_keras: -82.7181 - rmse: 0.8666 - sae: 1882.1406 - sse: 2290.6611 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 4.0029e-16 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6092 - learning_rate: 1.0000e-05\n","Epoch 953/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -2.7882e-16 - r2_keras: -100.7675 - rmse: 0.8779 - sae: 2575.9004 - sse: 3156.7007\n","Epoch 953: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.1041e-16 - r2_keras: -82.7180 - rmse: 0.8666 - sae: 1882.1395 - sse: 2290.6580 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 4.2136e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6103 - learning_rate: 1.0000e-05\n","Epoch 954/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.3926e-16 - r2_keras: -100.7677 - rmse: 0.8779 - sae: 2575.9023 - sse: 3156.7056\n","Epoch 954: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.1313e-16 - r2_keras: -82.7181 - rmse: 0.8666 - sae: 1882.1410 - sse: 2290.6616 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 3.4762e-16 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6096 - learning_rate: 1.0000e-05\n","Epoch 955/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 4.2916e-16 - r2_keras: -100.7677 - rmse: 0.8779 - sae: 2575.9028 - sse: 3156.7075\n","Epoch 955: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.1912e-16 - r2_keras: -82.7182 - rmse: 0.8666 - sae: 1882.1415 - sse: 2290.6633 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 8.4272e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.6092 - learning_rate: 1.0000e-05\n","Epoch 956/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.8953e-16 - r2_keras: -100.7678 - rmse: 0.8779 - sae: 2575.9038 - sse: 3156.7104\n","Epoch 956: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.8563e-16 - r2_keras: -82.7183 - rmse: 0.8666 - sae: 1882.1422 - sse: 2290.6655 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 2.1068e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6287 - val_sse: 506.6102 - learning_rate: 1.0000e-05\n","Epoch 957/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -2.7853e-16 - r2_keras: -100.7680 - rmse: 0.8779 - sae: 2575.9060 - sse: 3156.7170\n","Epoch 957: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -7.6252e-17 - r2_keras: -82.7185 - rmse: 0.8666 - sae: 1882.1439 - sse: 2290.6704 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6101 - learning_rate: 1.0000e-05\n","Epoch 958/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -2.5318e-16 - r2_keras: -100.7679 - rmse: 0.8779 - sae: 2575.9043 - sse: 3156.7124\n","Epoch 958: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.2539e-16 - r2_keras: -82.7184 - rmse: 0.8666 - sae: 1882.1426 - sse: 2290.6670 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 9.4805e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6104 - learning_rate: 1.0000e-05\n","Epoch 959/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -1.7918e-16 - r2_keras: -100.7681 - rmse: 0.8779 - sae: 2575.9070 - sse: 3156.7192\n","Epoch 959: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.5011e-16 - r2_keras: -82.7186 - rmse: 0.8666 - sae: 1882.1445 - sse: 2290.6721 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 7.3737e-17 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6108 - learning_rate: 1.0000e-05\n","Epoch 960/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 8.1548e-16 - r2_keras: -100.7682 - rmse: 0.8779 - sae: 2575.9080 - sse: 3156.7231\n","Epoch 960: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.0733e-16 - r2_keras: -82.7187 - rmse: 0.8666 - sae: 1882.1454 - sse: 2290.6753 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -8.4271e-17 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.6101 - learning_rate: 1.0000e-05\n","Epoch 961/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 4.5217e-16 - r2_keras: -100.7682 - rmse: 0.8779 - sae: 2575.9075 - sse: 3156.7236\n","Epoch 961: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.1513e-16 - r2_keras: -82.7187 - rmse: 0.8666 - sae: 1882.1451 - sse: 2290.6758 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -5.2669e-17 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6110 - learning_rate: 1.0000e-05\n","Epoch 962/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -3.4962e-16 - r2_keras: -100.7684 - rmse: 0.8779 - sae: 2575.9097 - sse: 3156.7275\n","Epoch 962: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.0242e-16 - r2_keras: -82.7188 - rmse: 0.8666 - sae: 1882.1467 - sse: 2290.6787 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -6.3203e-17 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6112 - learning_rate: 1.0000e-05\n","Epoch 963/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -1.4655e-16 - r2_keras: -100.7682 - rmse: 0.8779 - sae: 2575.9082 - sse: 3156.7239\n","Epoch 963: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.1232e-16 - r2_keras: -82.7187 - rmse: 0.8666 - sae: 1882.1456 - sse: 2290.6763 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6106 - learning_rate: 1.0000e-05\n","Epoch 964/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 4.5712e-16 - r2_keras: -100.7684 - rmse: 0.8779 - sae: 2575.9094 - sse: 3156.7290\n","Epoch 964: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.6843e-16 - r2_keras: -82.7189 - rmse: 0.8666 - sae: 1882.1466 - sse: 2290.6799 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -2.4228e-16 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6112 - learning_rate: 1.0000e-05\n","Epoch 965/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -4.3177e-16 - r2_keras: -100.7686 - rmse: 0.8779 - sae: 2575.9111 - sse: 3156.7344\n","Epoch 965: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.9209e-16 - r2_keras: -82.7190 - rmse: 0.8666 - sae: 1882.1481 - sse: 2290.6841 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.6854e-16 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6111 - learning_rate: 1.0000e-05\n","Epoch 966/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.6082e-16 - r2_keras: -100.7688 - rmse: 0.8779 - sae: 2575.9136 - sse: 3156.7407\n","Epoch 966: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 7.6883e-18 - r2_keras: -82.7192 - rmse: 0.8666 - sae: 1882.1498 - sse: 2290.6885 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 5.1616e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6291 - val_sse: 506.6122 - learning_rate: 1.0000e-05\n","Epoch 967/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 5.5647e-16 - r2_keras: -100.7689 - rmse: 0.8779 - sae: 2575.9141 - sse: 3156.7432\n","Epoch 967: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 3.3371e-16 - r2_keras: -82.7193 - rmse: 0.8666 - sae: 1882.1503 - sse: 2290.6907 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 3.2655e-16 - val_r2_keras: -35.1139 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.6103 - learning_rate: 1.0000e-05\n","Epoch 968/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -4.0788e-17 - r2_keras: -100.7687 - rmse: 0.8779 - sae: 2575.9119 - sse: 3156.7363\n","Epoch 968: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -7.6248e-17 - r2_keras: -82.7191 - rmse: 0.8666 - sae: 1882.1487 - sse: 2290.6858 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -3.3708e-16 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6113 - learning_rate: 1.0000e-05\n","Epoch 969/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -1.3897e-16 - r2_keras: -100.7689 - rmse: 0.8779 - sae: 2575.9141 - sse: 3156.7434\n","Epoch 969: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.5114e-16 - r2_keras: -82.7193 - rmse: 0.8666 - sae: 1882.1503 - sse: 2290.6909 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 3.0548e-16 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6115 - learning_rate: 1.0000e-05\n","Epoch 970/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.2732e-16 - r2_keras: -100.7690 - rmse: 0.8779 - sae: 2575.9148 - sse: 3156.7456\n","Epoch 970: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.3747e-17 - r2_keras: -82.7194 - rmse: 0.8666 - sae: 1882.1509 - sse: 2290.6929 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.4747e-16 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6115 - learning_rate: 1.0000e-05\n","Epoch 971/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 9.3026e-16 - r2_keras: -100.7691 - rmse: 0.8779 - sae: 2575.9160 - sse: 3156.7502\n","Epoch 971: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 5.3716e-16 - r2_keras: -82.7195 - rmse: 0.8666 - sae: 1882.1519 - sse: 2290.6963 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -3.1602e-17 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6125 - learning_rate: 1.0000e-05\n","Epoch 972/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.2660e-16 - r2_keras: -100.7693 - rmse: 0.8779 - sae: 2575.9175 - sse: 3156.7551\n","Epoch 972: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.3518e-16 - r2_keras: -82.7197 - rmse: 0.8666 - sae: 1882.1530 - sse: 2290.7002 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.0534e-17 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6118 - learning_rate: 1.0000e-05\n","Epoch 973/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.1246e-16 - r2_keras: -100.7691 - rmse: 0.8779 - sae: 2575.9160 - sse: 3156.7493\n","Epoch 973: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 9.7141e-17 - r2_keras: -82.7195 - rmse: 0.8666 - sae: 1882.1520 - sse: 2290.6958 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -2.8442e-16 - val_r2_keras: -35.1140 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.6112 - learning_rate: 1.0000e-05\n","Epoch 974/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -8.1576e-17 - r2_keras: -100.7691 - rmse: 0.8779 - sae: 2575.9165 - sse: 3156.7517\n","Epoch 974: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.1554e-17 - r2_keras: -82.7196 - rmse: 0.8666 - sae: 1882.1523 - sse: 2290.6978 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.3694e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6128 - learning_rate: 1.0000e-05\n","Epoch 975/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -4.2856e-16 - r2_keras: -100.7694 - rmse: 0.8779 - sae: 2575.9189 - sse: 3156.7585\n","Epoch 975: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.8948e-16 - r2_keras: -82.7198 - rmse: 0.8666 - sae: 1882.1542 - sse: 2290.7029 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.3694e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.6120 - learning_rate: 1.0000e-05\n","Epoch 976/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.1436e-16 - r2_keras: -100.7694 - rmse: 0.8779 - sae: 2575.9194 - sse: 3156.7603\n","Epoch 976: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.4919e-16 - r2_keras: -82.7198 - rmse: 0.8666 - sae: 1882.1547 - sse: 2290.7043 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.0534e-17 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6129 - learning_rate: 1.0000e-05\n","Epoch 977/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 2.5172e-16 - r2_keras: -100.7696 - rmse: 0.8779 - sae: 2575.9216 - sse: 3156.7666\n","Epoch 977: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.8715e-16 - r2_keras: -82.7200 - rmse: 0.8666 - sae: 1882.1562 - sse: 2290.7090 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -7.3737e-17 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6288 - val_sse: 506.6134 - learning_rate: 1.0000e-05\n","Epoch 978/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.9025e-16 - r2_keras: -100.7698 - rmse: 0.8779 - sae: 2575.9229 - sse: 3156.7715\n","Epoch 978: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.3155e-16 - r2_keras: -82.7202 - rmse: 0.8666 - sae: 1882.1571 - sse: 2290.7126 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -8.4271e-17 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6122 - learning_rate: 1.0000e-05\n","Epoch 979/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 2.8930e-16 - r2_keras: -100.7696 - rmse: 0.8779 - sae: 2575.9209 - sse: 3156.7651\n","Epoch 979: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.5136e-16 - r2_keras: -82.7200 - rmse: 0.8666 - sae: 1882.1558 - sse: 2290.7083 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -5.2669e-17 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6129 - learning_rate: 1.0000e-05\n","Epoch 980/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -6.5260e-17 - r2_keras: -100.7697 - rmse: 0.8779 - sae: 2575.9221 - sse: 3156.7683\n","Epoch 980: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -5.4355e-17 - r2_keras: -82.7201 - rmse: 0.8666 - sae: 1882.1567 - sse: 2290.7107 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.5801e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.6122 - learning_rate: 1.0000e-05\n","Epoch 981/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.9710e-16 - r2_keras: -100.7698 - rmse: 0.8779 - sae: 2575.9229 - sse: 3156.7720\n","Epoch 981: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.9445e-16 - r2_keras: -82.7202 - rmse: 0.8666 - sae: 1882.1573 - sse: 2290.7134 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 5.8990e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.6125 - learning_rate: 1.0000e-05\n","Epoch 982/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.7772e-17 - r2_keras: -100.7700 - rmse: 0.8779 - sae: 2575.9253 - sse: 3156.7783\n","Epoch 982: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 4.6280e-17 - r2_keras: -82.7204 - rmse: 0.8666 - sae: 1882.1592 - sse: 2290.7180 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.3694e-16 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6290 - val_sse: 506.6141 - learning_rate: 1.0000e-05\n","Epoch 983/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -7.4874e-17 - r2_keras: -100.7702 - rmse: 0.8779 - sae: 2575.9268 - sse: 3156.7832\n","Epoch 983: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.4069e-17 - r2_keras: -82.7205 - rmse: 0.8666 - sae: 1882.1603 - sse: 2290.7219 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -8.4271e-17 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6134 - learning_rate: 1.0000e-05\n","Epoch 984/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -1.5179e-16 - r2_keras: -100.7700 - rmse: 0.8779 - sae: 2575.9248 - sse: 3156.7773\n","Epoch 984: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.9600e-16 - r2_keras: -82.7204 - rmse: 0.8666 - sae: 1882.1588 - sse: 2290.7175 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 3.1602e-17 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.6130 - learning_rate: 1.0000e-05\n","Epoch 985/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -7.1495e-16 - r2_keras: -100.7700 - rmse: 0.8779 - sae: 2575.9253 - sse: 3156.7788\n","Epoch 985: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -4.1154e-16 - r2_keras: -82.7205 - rmse: 0.8666 - sae: 1882.1593 - sse: 2290.7190 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.4747e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.6126 - learning_rate: 1.0000e-05\n","Epoch 986/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 4.1137e-16 - r2_keras: -100.7703 - rmse: 0.8779 - sae: 2575.9277 - sse: 3156.7861\n","Epoch 986: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.1057e-16 - r2_keras: -82.7206 - rmse: 0.8666 - sae: 1882.1610 - sse: 2290.7241 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 3.0548e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6281 - val_sse: 506.6129 - learning_rate: 1.0000e-05\n","Epoch 987/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -4.0758e-16 - r2_keras: -100.7703 - rmse: 0.8779 - sae: 2575.9282 - sse: 3156.7888\n","Epoch 987: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.6936e-16 - r2_keras: -82.7207 - rmse: 0.8666 - sae: 1882.1616 - sse: 2290.7266 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 2.3174e-16 - val_r2_keras: -35.1143 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6147 - learning_rate: 1.0000e-05\n","Epoch 988/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 2.3074e-16 - r2_keras: -100.7705 - rmse: 0.8779 - sae: 2575.9302 - sse: 3156.7942\n","Epoch 988: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.6326e-16 - r2_keras: -82.7209 - rmse: 0.8666 - sae: 1882.1631 - sse: 2290.7305 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -2.1068e-17 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6138 - learning_rate: 1.0000e-05\n","Epoch 989/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.1057e-16 - r2_keras: -100.7704 - rmse: 0.8779 - sae: 2575.9292 - sse: 3156.7915\n","Epoch 989: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.1035e-16 - r2_keras: -82.7208 - rmse: 0.8666 - sae: 1882.1622 - sse: 2290.7285 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.1587e-16 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6286 - val_sse: 506.6142 - learning_rate: 1.0000e-05\n","Epoch 990/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -4.0787e-18 - r2_keras: -100.7706 - rmse: 0.8779 - sae: 2575.9309 - sse: 3156.7964\n","Epoch 990: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -9.3225e-18 - r2_keras: -82.7210 - rmse: 0.8666 - sae: 1882.1637 - sse: 2290.7322 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.8961e-16 - val_r2_keras: -35.1141 - val_rmse: 0.9786 - val_sae: 367.6276 - val_sse: 506.6129 - learning_rate: 1.0000e-05\n","Epoch 991/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.7393e-16 - r2_keras: -100.7706 - rmse: 0.8779 - sae: 2575.9302 - sse: 3156.7952\n","Epoch 991: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 8.3407e-17 - r2_keras: -82.7209 - rmse: 0.8666 - sae: 1882.1632 - sse: 2290.7317 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.5801e-16 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6144 - learning_rate: 1.0000e-05\n","Epoch 992/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -5.3926e-16 - r2_keras: -100.7707 - rmse: 0.8779 - sae: 2575.9326 - sse: 3156.8013\n","Epoch 992: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.4819e-16 - r2_keras: -82.7211 - rmse: 0.8666 - sae: 1882.1650 - sse: 2290.7361 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.1143 - val_rmse: 0.9786 - val_sae: 367.6285 - val_sse: 506.6147 - learning_rate: 1.0000e-05\n","Epoch 993/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.7874e-18 - r2_keras: -100.7709 - rmse: 0.8779 - sae: 2575.9341 - sse: 3156.8059\n","Epoch 993: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.9410e-17 - r2_keras: -82.7213 - rmse: 0.8666 - sae: 1882.1661 - sse: 2290.7397 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 4.2135e-17 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6282 - val_sse: 506.6140 - learning_rate: 1.0000e-05\n","Epoch 994/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 2.0306e-16 - r2_keras: -100.7708 - rmse: 0.8779 - sae: 2575.9321 - sse: 3156.8027\n","Epoch 994: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 1.2264e-16 - r2_keras: -82.7212 - rmse: 0.8666 - sae: 1882.1648 - sse: 2290.7373 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -2.3174e-16 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.6146 - learning_rate: 1.0000e-05\n","Epoch 995/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -1.0080e-16 - r2_keras: -100.7709 - rmse: 0.8779 - sae: 2575.9336 - sse: 3156.8066\n","Epoch 995: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -3.9373e-17 - r2_keras: -82.7213 - rmse: 0.8666 - sae: 1882.1659 - sse: 2290.7405 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 1.1587e-16 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6144 - learning_rate: 1.0000e-05\n","Epoch 996/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 5.7393e-17 - r2_keras: -100.7711 - rmse: 0.8779 - sae: 2575.9355 - sse: 3156.8108\n","Epoch 996: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.6451e-17 - r2_keras: -82.7214 - rmse: 0.8666 - sae: 1882.1674 - sse: 2290.7434 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -5.2669e-17 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.6143 - learning_rate: 1.0000e-05\n","Epoch 997/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 1.2621e-15 - r2_keras: -100.7711 - rmse: 0.8779 - sae: 2575.9353 - sse: 3156.8120\n","Epoch 997: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 8.5223e-16 - r2_keras: -82.7215 - rmse: 0.8666 - sae: 1882.1672 - sse: 2290.7444 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 2.1068e-17 - val_r2_keras: -35.1143 - val_rmse: 0.9786 - val_sae: 367.6284 - val_sse: 506.6151 - learning_rate: 1.0000e-05\n","Epoch 998/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: 3.4640e-16 - r2_keras: -100.7712 - rmse: 0.8779 - sae: 2575.9368 - sse: 3156.8169\n","Epoch 998: val_loss improved from 0.19057 to 0.19057, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: 2.2244e-16 - r2_keras: -82.7216 - rmse: 0.8666 - sae: 1882.1683 - sse: 2290.7483 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 3.0548e-16 - val_r2_keras: -35.1142 - val_rmse: 0.9786 - val_sae: 367.6280 - val_sse: 506.6142 - learning_rate: 1.0000e-05\n","Epoch 999/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -3.5543e-16 - r2_keras: -100.7711 - rmse: 0.8779 - sae: 2575.9358 - sse: 3156.8135\n","Epoch 999: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -1.9309e-16 - r2_keras: -82.7215 - rmse: 0.8666 - sae: 1882.1677 - sse: 2290.7458 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: 7.3737e-17 - val_r2_keras: -35.1143 - val_rmse: 0.9786 - val_sae: 367.6283 - val_sse: 506.6151 - learning_rate: 1.0000e-05\n","Epoch 1000/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0674 - loss: 0.1559 - mae: 0.2262 - mse: 0.1383 - pearson_correlation: -3.4348e-16 - r2_keras: -100.7713 - rmse: 0.8779 - sae: 2575.9373 - sse: 3156.8188\n","Epoch 1000: val_loss did not improve from 0.19057\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0592 - loss: 0.1509 - mae: 0.2173 - mse: 0.1277 - pearson_correlation: -2.3795e-16 - r2_keras: -82.7217 - rmse: 0.8666 - sae: 1882.1688 - sse: 2290.7498 - val_huber_loss: 0.1021 - val_loss: 0.1906 - val_mae: 0.2994 - val_mse: 0.2203 - val_pearson_correlation: -1.5801e-16 - val_r2_keras: -35.1143 - val_rmse: 0.9786 - val_sae: 367.6289 - val_sse: 506.6160 - learning_rate: 1.0000e-05\n","| \u001b[39m1        \u001b[39m | \u001b[39m-0.1906  \u001b[39m | \u001b[39m0.03752  \u001b[39m | \u001b[39m95.32    \u001b[39m | \u001b[39m74.54    \u001b[39m |\n","Epoch 1/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - huber_loss: 1.0106 - loss: 1.0334 - mae: 1.4206 - mse: 3.4148 - pearson_correlation: 3.7495e-16 - r2_keras: -306.4402 - rmse: 1.5259 - sae: 4868.7598 - sse: 9536.4102\n","Epoch 1: val_loss improved from inf to 0.23233, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 520ms/step - huber_loss: 0.8908 - loss: 0.9605 - mae: 1.3420 - mse: 3.0460 - pearson_correlation: 2.7287e-16 - r2_keras: -248.0769 - rmse: 1.4863 - sae: 3544.7456 - sse: 6875.0981 - val_huber_loss: 0.2093 - val_loss: 0.2323 - val_mae: 0.5311 - val_mse: 0.4461 - val_pearson_correlation: 7.7242e-17 - val_r2_keras: -29.4875 - val_rmse: 0.8992 - val_sae: 364.4355 - val_sse: 427.6823 - learning_rate: 0.0599\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1939 - loss: 0.2169 - mae: 0.4434 - mse: 0.4835 - pearson_correlation: -4.4719e-17 - r2_keras: -127.0214 - rmse: 0.9846 - sae: 2953.2717 - sse: 3971.0642\n","Epoch 2: val_loss improved from 0.23233 to 0.20493, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1858 - loss: 0.2120 - mae: 0.4467 - mse: 0.4633 - pearson_correlation: -1.0345e-16 - r2_keras: -99.2582 - rmse: 0.9291 - sae: 2134.9517 - sse: 2822.2778 - val_huber_loss: 0.1819 - val_loss: 0.2049 - val_mae: 0.4363 - val_mse: 0.3889 - val_pearson_correlation: -4.7298e-17 - val_r2_keras: -31.0664 - val_rmse: 0.9221 - val_sae: 345.9738 - val_sse: 449.8311 - learning_rate: 0.0599\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1504 - loss: 0.1734 - mae: 0.3820 - mse: 0.3546 - pearson_correlation: -5.4458e-17 - r2_keras: -115.9823 - rmse: 0.9412 - sae: 2788.4707 - sse: 3628.6455\n","Epoch 3: val_loss improved from 0.20493 to 0.19590, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.1520 - loss: 0.1744 - mae: 0.3953 - mse: 0.3496 - pearson_correlation: 1.3262e-16 - r2_keras: -89.7662 - rmse: 0.8799 - sae: 2014.6635 - sse: 2568.9832 - val_huber_loss: 0.1729 - val_loss: 0.1959 - val_mae: 0.3901 - val_mse: 0.3545 - val_pearson_correlation: -3.3614e-16 - val_r2_keras: -37.2927 - val_rmse: 1.0077 - val_sae: 376.3254 - val_sse: 537.1735 - learning_rate: 0.0599\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.1997 - loss: 0.2228 - mae: 0.4210 - mse: 0.4921 - pearson_correlation: 8.6508e-17 - r2_keras: -147.3662 - rmse: 1.0600 - sae: 2934.9043 - sse: 4602.1338\n","Epoch 4: val_loss improved from 0.19590 to 0.18521, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1679 - loss: 0.2034 - mae: 0.4069 - mse: 0.4358 - pearson_correlation: 5.1521e-17 - r2_keras: -112.8514 - rmse: 0.9796 - sae: 2118.4519 - sse: 3243.3425 - val_huber_loss: 0.1622 - val_loss: 0.1852 - val_mae: 0.4044 - val_mse: 0.3674 - val_pearson_correlation: -1.5907e-16 - val_r2_keras: -28.5237 - val_rmse: 0.8848 - val_sae: 327.8354 - val_sse: 414.1621 - learning_rate: 0.0599\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1287 - loss: 0.1517 - mae: 0.3226 - mse: 0.2944 - pearson_correlation: -6.4806e-16 - r2_keras: -94.6940 - rmse: 0.8513 - sae: 2501.0200 - sse: 2968.3091\n","Epoch 5: val_loss did not improve from 0.18521\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1201 - loss: 0.1465 - mae: 0.3202 - mse: 0.2769 - pearson_correlation: -4.4387e-16 - r2_keras: -78.1718 - rmse: 0.8444 - sae: 1827.6602 - sse: 2159.2314 - val_huber_loss: 0.1762 - val_loss: 0.1992 - val_mae: 0.4180 - val_mse: 0.4433 - val_pearson_correlation: 3.6700e-17 - val_r2_keras: -25.2962 - val_rmse: 0.8351 - val_sae: 301.3105 - val_sse: 368.8858 - learning_rate: 0.0599\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1493 - loss: 0.1723 - mae: 0.3816 - mse: 0.3318 - pearson_correlation: -3.2110e-17 - r2_keras: -91.6420 - rmse: 0.8376 - sae: 2462.6899 - sse: 2873.6394\n","Epoch 6: val_loss improved from 0.18521 to 0.17189, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.1315 - loss: 0.1615 - mae: 0.3657 - mse: 0.3034 - pearson_correlation: -7.1431e-17 - r2_keras: -78.5081 - rmse: 0.8559 - sae: 1812.5892 - sse: 2123.9294 - val_huber_loss: 0.1489 - val_loss: 0.1719 - val_mae: 0.4045 - val_mse: 0.3609 - val_pearson_correlation: 2.2999e-16 - val_r2_keras: -25.5913 - val_rmse: 0.8397 - val_sae: 316.1072 - val_sse: 373.0250 - learning_rate: 0.0599\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1228 - loss: 0.1458 - mae: 0.3502 - mse: 0.2666 - pearson_correlation: 4.2867e-16 - r2_keras: -86.7222 - rmse: 0.8151 - sae: 2431.6531 - sse: 2721.0317\n","Epoch 7: val_loss improved from 0.17189 to 0.15557, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.1101 - loss: 0.1381 - mae: 0.3340 - mse: 0.2470 - pearson_correlation: 2.5255e-16 - r2_keras: -73.6886 - rmse: 0.8277 - sae: 1786.9203 - sse: 2004.1312 - val_huber_loss: 0.1326 - val_loss: 0.1556 - val_mae: 0.3790 - val_mse: 0.3196 - val_pearson_correlation: -3.5241e-17 - val_r2_keras: -26.6967 - val_rmse: 0.8570 - val_sae: 325.0913 - val_sse: 388.5319 - learning_rate: 0.0599\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1116 - loss: 0.1345 - mae: 0.3214 - mse: 0.2399 - pearson_correlation: -6.9017e-16 - r2_keras: -90.8205 - rmse: 0.8339 - sae: 2478.5320 - sse: 2848.1567\n","Epoch 8: val_loss improved from 0.15557 to 0.14904, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.1004 - loss: 0.1277 - mae: 0.3067 - mse: 0.2229 - pearson_correlation: -4.3764e-16 - r2_keras: -76.2215 - rmse: 0.8385 - sae: 1817.0746 - sse: 2086.5435 - val_huber_loss: 0.1261 - val_loss: 0.1490 - val_mae: 0.3703 - val_mse: 0.3027 - val_pearson_correlation: 3.8444e-16 - val_r2_keras: -27.6169 - val_rmse: 0.8711 - val_sae: 335.4413 - val_sse: 401.4407 - learning_rate: 0.0599\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1049 - loss: 0.1278 - mae: 0.3008 - mse: 0.2253 - pearson_correlation: 2.2875e-16 - r2_keras: -90.2659 - rmse: 0.8314 - sae: 2474.4038 - sse: 2830.9536\n","Epoch 9: val_loss improved from 0.14904 to 0.14697, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0948 - loss: 0.1217 - mae: 0.2879 - mse: 0.2099 - pearson_correlation: 1.9372e-16 - r2_keras: -75.8460 - rmse: 0.8367 - sae: 1814.2465 - sse: 2075.0076 - val_huber_loss: 0.1241 - val_loss: 0.1470 - val_mae: 0.3604 - val_mse: 0.2989 - val_pearson_correlation: 3.0385e-16 - val_r2_keras: -28.2437 - val_rmse: 0.8806 - val_sae: 340.7746 - val_sse: 410.2340 - learning_rate: 0.0599\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1003 - loss: 0.1231 - mae: 0.2903 - mse: 0.2152 - pearson_correlation: -9.2564e-16 - r2_keras: -89.8651 - rmse: 0.8295 - sae: 2471.0928 - sse: 2818.5225\n","Epoch 10: val_loss improved from 0.14697 to 0.14645, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0910 - loss: 0.1175 - mae: 0.2787 - mse: 0.2010 - pearson_correlation: -6.8245e-16 - r2_keras: -75.6232 - rmse: 0.8359 - sae: 1812.2665 - sse: 2067.2400 - val_huber_loss: 0.1236 - val_loss: 0.1465 - val_mae: 0.3487 - val_mse: 0.2994 - val_pearson_correlation: 1.0197e-16 - val_r2_keras: -28.7950 - val_rmse: 0.8889 - val_sae: 343.5139 - val_sse: 417.9672 - learning_rate: 0.0599\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0974 - loss: 0.1203 - mae: 0.2858 - mse: 0.2094 - pearson_correlation: -5.0966e-17 - r2_keras: -89.3221 - rmse: 0.8270 - sae: 2463.0505 - sse: 2801.6797\n","Epoch 11: val_loss did not improve from 0.14645\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0882 - loss: 0.1147 - mae: 0.2739 - mse: 0.1951 - pearson_correlation: -7.1299e-17 - r2_keras: -75.2684 - rmse: 0.8343 - sae: 1806.9135 - sse: 2056.0962 - val_huber_loss: 0.1239 - val_loss: 0.1468 - val_mae: 0.3414 - val_mse: 0.3001 - val_pearson_correlation: -3.0544e-16 - val_r2_keras: -29.4840 - val_rmse: 0.8991 - val_sae: 347.0359 - val_sse: 427.6334 - learning_rate: 0.0599\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0948 - loss: 0.1176 - mae: 0.2809 - mse: 0.2036 - pearson_correlation: -1.8278e-16 - r2_keras: -89.3647 - rmse: 0.8272 - sae: 2462.7373 - sse: 2802.9990\n","Epoch 12: val_loss improved from 0.14645 to 0.14621, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0855 - loss: 0.1120 - mae: 0.2694 - mse: 0.1895 - pearson_correlation: -1.9520e-16 - r2_keras: -75.3605 - rmse: 0.8350 - sae: 1807.0797 - sse: 2057.7229 - val_huber_loss: 0.1234 - val_loss: 0.1462 - val_mae: 0.3384 - val_mse: 0.2977 - val_pearson_correlation: 9.3506e-17 - val_r2_keras: -30.0879 - val_rmse: 0.9080 - val_sae: 350.3773 - val_sse: 436.1039 - learning_rate: 0.0599\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0923 - loss: 0.1151 - mae: 0.2765 - mse: 0.1983 - pearson_correlation: -1.0667e-16 - r2_keras: -89.5735 - rmse: 0.8282 - sae: 2464.0215 - sse: 2809.4780\n","Epoch 13: val_loss did not improve from 0.14621\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0832 - loss: 0.1096 - mae: 0.2654 - mse: 0.1845 - pearson_correlation: -3.5213e-17 - r2_keras: -75.4399 - rmse: 0.8351 - sae: 1807.7966 - sse: 2061.3403 - val_huber_loss: 0.1262 - val_loss: 0.1490 - val_mae: 0.3334 - val_mse: 0.3078 - val_pearson_correlation: 3.9058e-17 - val_r2_keras: -30.4998 - val_rmse: 0.9140 - val_sae: 349.4345 - val_sse: 441.8823 - learning_rate: 0.0599\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0906 - loss: 0.1134 - mae: 0.2739 - mse: 0.1940 - pearson_correlation: 3.4229e-16 - r2_keras: -90.3854 - rmse: 0.8319 - sae: 2473.8955 - sse: 2834.6621\n","Epoch 14: val_loss did not improve from 0.14621\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0815 - loss: 0.1078 - mae: 0.2626 - mse: 0.1803 - pearson_correlation: 8.1814e-17 - r2_keras: -75.8542 - rmse: 0.8365 - sae: 1813.8320 - sse: 2076.6409 - val_huber_loss: 0.1323 - val_loss: 0.1550 - val_mae: 0.3334 - val_mse: 0.3262 - val_pearson_correlation: -1.0079e-16 - val_r2_keras: -31.0851 - val_rmse: 0.9224 - val_sae: 349.0668 - val_sse: 450.0939 - learning_rate: 0.0599\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0897 - loss: 0.1124 - mae: 0.2739 - mse: 0.1911 - pearson_correlation: -1.6356e-16 - r2_keras: -91.3311 - rmse: 0.8362 - sae: 2483.2380 - sse: 2863.9951\n","Epoch 15: val_loss did not improve from 0.14621\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0804 - loss: 0.1068 - mae: 0.2621 - mse: 0.1775 - pearson_correlation: -1.9254e-16 - r2_keras: -76.6759 - rmse: 0.8410 - sae: 1820.9340 - sse: 2098.4395 - val_huber_loss: 0.1254 - val_loss: 0.1481 - val_mae: 0.3255 - val_mse: 0.3031 - val_pearson_correlation: 2.5637e-16 - val_r2_keras: -31.6712 - val_rmse: 0.9308 - val_sae: 355.0333 - val_sse: 458.3157 - learning_rate: 0.0599\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0878 - loss: 0.1105 - mae: 0.2681 - mse: 0.1877 - pearson_correlation: 4.3664e-16 - r2_keras: -91.3574 - rmse: 0.8363 - sae: 2481.2915 - sse: 2864.8123\n","Epoch 16: val_loss did not improve from 0.14621\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0784 - loss: 0.1048 - mae: 0.2568 - mse: 0.1738 - pearson_correlation: 2.2698e-16 - r2_keras: -76.5746 - rmse: 0.8400 - sae: 1819.1626 - sse: 2097.5906 - val_huber_loss: 0.1239 - val_loss: 0.1466 - val_mae: 0.3227 - val_mse: 0.2956 - val_pearson_correlation: 9.4570e-17 - val_r2_keras: -32.3187 - val_rmse: 0.9400 - val_sae: 359.5210 - val_sse: 467.3980 - learning_rate: 0.0599\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0865 - loss: 0.1091 - mae: 0.2656 - mse: 0.1845 - pearson_correlation: -4.1226e-16 - r2_keras: -92.8315 - rmse: 0.8430 - sae: 2496.3311 - sse: 2910.5344\n","Epoch 17: val_loss improved from 0.14621 to 0.14472, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0774 - loss: 0.1036 - mae: 0.2546 - mse: 0.1710 - pearson_correlation: -2.9253e-16 - r2_keras: -77.6253 - rmse: 0.8451 - sae: 1829.5070 - sse: 2128.8696 - val_huber_loss: 0.1221 - val_loss: 0.1447 - val_mae: 0.3133 - val_mse: 0.2912 - val_pearson_correlation: 6.9537e-17 - val_r2_keras: -32.7307 - val_rmse: 0.9458 - val_sae: 360.0334 - val_sse: 473.1785 - learning_rate: 0.0599\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0850 - loss: 0.1076 - mae: 0.2617 - mse: 0.1814 - pearson_correlation: -5.4647e-16 - r2_keras: -93.4726 - rmse: 0.8458 - sae: 2498.9780 - sse: 2930.4211\n","Epoch 18: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0760 - loss: 0.1022 - mae: 0.2517 - mse: 0.1681 - pearson_correlation: -4.0560e-16 - r2_keras: -77.9480 - rmse: 0.8461 - sae: 1830.9130 - sse: 2140.8987 - val_huber_loss: 0.1222 - val_loss: 0.1449 - val_mae: 0.3173 - val_mse: 0.2857 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.6425 - val_rmse: 0.9585 - val_sae: 368.1924 - val_sse: 485.9688 - learning_rate: 0.0599\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1066 - mae: 0.2581 - mse: 0.1788 - pearson_correlation: -5.0280e-17 - r2_keras: -95.0864 - rmse: 0.8530 - sae: 2517.9243 - sse: 2980.4810\n","Epoch 19: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0747 - loss: 0.1009 - mae: 0.2469 - mse: 0.1654 - pearson_correlation: -6.6125e-17 - r2_keras: -78.7439 - rmse: 0.8484 - sae: 1841.9796 - sse: 2170.9873 - val_huber_loss: 0.1290 - val_loss: 0.1516 - val_mae: 0.3206 - val_mse: 0.3080 - val_pearson_correlation: 1.5528e-16 - val_r2_keras: -33.7129 - val_rmse: 0.9594 - val_sae: 363.0241 - val_sse: 486.9560 - learning_rate: 0.0599\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0829 - loss: 0.1055 - mae: 0.2598 - mse: 0.1755 - pearson_correlation: -4.4336e-16 - r2_keras: -96.2852 - rmse: 0.8583 - sae: 2527.0391 - sse: 3017.6638\n","Epoch 20: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0740 - loss: 0.1001 - mae: 0.2479 - mse: 0.1626 - pearson_correlation: -3.1724e-16 - r2_keras: -79.7697 - rmse: 0.8539 - sae: 1849.1451 - sse: 2198.4348 - val_huber_loss: 0.1336 - val_loss: 0.1561 - val_mae: 0.3306 - val_mse: 0.3217 - val_pearson_correlation: 2.6829e-16 - val_r2_keras: -33.5284 - val_rmse: 0.9569 - val_sae: 362.3893 - val_sse: 484.3688 - learning_rate: 0.0599\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0814 - loss: 0.1040 - mae: 0.2554 - mse: 0.1716 - pearson_correlation: 2.8721e-16 - r2_keras: -95.4982 - rmse: 0.8549 - sae: 2522.1357 - sse: 2993.2534\n","Epoch 21: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0729 - loss: 0.0988 - mae: 0.2447 - mse: 0.1594 - pearson_correlation: 1.5145e-16 - r2_keras: -79.4032 - rmse: 0.8530 - sae: 1846.6798 - sse: 2184.0159 - val_huber_loss: 0.1576 - val_loss: 0.1801 - val_mae: 0.3876 - val_mse: 0.3959 - val_pearson_correlation: -5.2063e-16 - val_r2_keras: -33.3459 - val_rmse: 0.9544 - val_sae: 361.0954 - val_sse: 481.8083 - learning_rate: 0.0599\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0824 - loss: 0.1049 - mae: 0.2628 - mse: 0.1717 - pearson_correlation: 7.5762e-16 - r2_keras: -93.9320 - rmse: 0.8479 - sae: 2511.6765 - sse: 2944.6729\n","Epoch 22: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0748 - loss: 0.1003 - mae: 0.2517 - mse: 0.1611 - pearson_correlation: 4.2504e-16 - r2_keras: -79.0787 - rmse: 0.8546 - sae: 1842.7794 - sse: 2160.0708 - val_huber_loss: 0.2020 - val_loss: 0.2245 - val_mae: 0.4668 - val_mse: 0.5288 - val_pearson_correlation: -3.6024e-16 - val_r2_keras: -33.7906 - val_rmse: 0.9605 - val_sae: 364.5548 - val_sse: 488.0462 - learning_rate: 0.0599\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0869 - loss: 0.1094 - mae: 0.2804 - mse: 0.1798 - pearson_correlation: -5.6718e-17 - r2_keras: -91.8399 - rmse: 0.8385 - sae: 2493.6831 - sse: 2879.7788\n","Epoch 23: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0757 - loss: 0.1026 - mae: 0.2680 - mse: 0.1649 - pearson_correlation: -2.1611e-17 - r2_keras: -76.6328 - rmse: 0.8392 - sae: 1826.9830 - sse: 2104.4771 - val_huber_loss: 0.1422 - val_loss: 0.1647 - val_mae: 0.3548 - val_mse: 0.3471 - val_pearson_correlation: -7.8225e-17 - val_r2_keras: -33.5435 - val_rmse: 0.9571 - val_sae: 361.8343 - val_sse: 484.5793 - learning_rate: 0.0120\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0785 - loss: 0.1010 - mae: 0.2520 - mse: 0.1640 - pearson_correlation: -3.2078e-16 - r2_keras: -95.1882 - rmse: 0.8535 - sae: 2517.2336 - sse: 2983.6362\n","Epoch 24: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0693 - loss: 0.0954 - mae: 0.2403 - mse: 0.1514 - pearson_correlation: -3.1524e-16 - r2_keras: -78.9404 - rmse: 0.8498 - sae: 1842.5050 - sse: 2174.6011 - val_huber_loss: 0.1295 - val_loss: 0.1520 - val_mae: 0.3200 - val_mse: 0.3052 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.0472 - val_rmse: 0.9640 - val_sae: 366.3481 - val_sse: 491.6458 - learning_rate: 0.0120\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0772 - loss: 0.0997 - mae: 0.2470 - mse: 0.1617 - pearson_correlation: -1.4041e-16 - r2_keras: -97.1307 - rmse: 0.8621 - sae: 2532.6541 - sse: 3043.8911\n","Epoch 25: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0684 - loss: 0.0943 - mae: 0.2359 - mse: 0.1495 - pearson_correlation: -1.0304e-16 - r2_keras: -80.2912 - rmse: 0.8560 - sae: 1852.9919 - sse: 2215.4253 - val_huber_loss: 0.1271 - val_loss: 0.1496 - val_mae: 0.3172 - val_mse: 0.2968 - val_pearson_correlation: 2.5101e-16 - val_r2_keras: -34.1298 - val_rmse: 0.9652 - val_sae: 367.7537 - val_sse: 492.8044 - learning_rate: 0.0120\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0763 - loss: 0.0987 - mae: 0.2454 - mse: 0.1597 - pearson_correlation: -3.8488e-16 - r2_keras: -97.8675 - rmse: 0.8653 - sae: 2539.4316 - sse: 3066.7468\n","Epoch 26: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0677 - loss: 0.0936 - mae: 0.2344 - mse: 0.1479 - pearson_correlation: -2.2072e-16 - r2_keras: -80.7783 - rmse: 0.8582 - sae: 1857.4653 - sse: 2230.6138 - val_huber_loss: 0.1256 - val_loss: 0.1481 - val_mae: 0.3155 - val_mse: 0.2920 - val_pearson_correlation: -1.5273e-16 - val_r2_keras: -34.1433 - val_rmse: 0.9654 - val_sae: 368.2160 - val_sse: 492.9936 - learning_rate: 0.0120\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0757 - loss: 0.0982 - mae: 0.2443 - mse: 0.1585 - pearson_correlation: -4.7031e-16 - r2_keras: -98.2843 - rmse: 0.8671 - sae: 2543.2310 - sse: 3079.6753\n","Epoch 27: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0674 - loss: 0.0931 - mae: 0.2335 - mse: 0.1469 - pearson_correlation: -2.9940e-16 - r2_keras: -81.0764 - rmse: 0.8596 - sae: 1860.0983 - sse: 2239.4702 - val_huber_loss: 0.1251 - val_loss: 0.1476 - val_mae: 0.3151 - val_mse: 0.2904 - val_pearson_correlation: -5.6830e-16 - val_r2_keras: -34.0993 - val_rmse: 0.9648 - val_sae: 367.9702 - val_sse: 492.3770 - learning_rate: 0.0120\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0752 - loss: 0.0977 - mae: 0.2433 - mse: 0.1572 - pearson_correlation: 1.5258e-16 - r2_keras: -98.5476 - rmse: 0.8683 - sae: 2545.6597 - sse: 3087.8413\n","Epoch 28: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0669 - loss: 0.0926 - mae: 0.2325 - mse: 0.1457 - pearson_correlation: 9.4175e-17 - r2_keras: -81.2444 - rmse: 0.8603 - sae: 1861.7495 - sse: 2244.8267 - val_huber_loss: 0.1256 - val_loss: 0.1480 - val_mae: 0.3162 - val_mse: 0.2914 - val_pearson_correlation: -8.7410e-17 - val_r2_keras: -34.1063 - val_rmse: 0.9649 - val_sae: 368.0713 - val_sse: 492.4756 - learning_rate: 0.0024\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0751 - loss: 0.0976 - mae: 0.2431 - mse: 0.1569 - pearson_correlation: -1.4796e-16 - r2_keras: -98.5981 - rmse: 0.8685 - sae: 2546.1633 - sse: 3089.4072\n","Epoch 29: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0668 - loss: 0.0925 - mae: 0.2323 - mse: 0.1455 - pearson_correlation: -5.5275e-17 - r2_keras: -81.2792 - rmse: 0.8604 - sae: 1862.0885 - sse: 2245.8838 - val_huber_loss: 0.1258 - val_loss: 0.1483 - val_mae: 0.3170 - val_mse: 0.2919 - val_pearson_correlation: 2.9497e-16 - val_r2_keras: -34.1104 - val_rmse: 0.9649 - val_sae: 368.1337 - val_sse: 492.5331 - learning_rate: 0.0024\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0750 - loss: 0.0975 - mae: 0.2429 - mse: 0.1567 - pearson_correlation: -5.3184e-16 - r2_keras: -98.6362 - rmse: 0.8686 - sae: 2546.4702 - sse: 3090.5898\n","Epoch 30: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0667 - loss: 0.0924 - mae: 0.2322 - mse: 0.1453 - pearson_correlation: -2.9518e-16 - r2_keras: -81.3074 - rmse: 0.8605 - sae: 1862.3036 - sse: 2246.7041 - val_huber_loss: 0.1260 - val_loss: 0.1485 - val_mae: 0.3175 - val_mse: 0.2922 - val_pearson_correlation: -5.4624e-17 - val_r2_keras: -34.1104 - val_rmse: 0.9649 - val_sae: 368.1584 - val_sse: 492.5318 - learning_rate: 0.0024\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0749 - loss: 0.0973 - mae: 0.2427 - mse: 0.1564 - pearson_correlation: 3.3182e-16 - r2_keras: -98.6879 - rmse: 0.8689 - sae: 2547.0281 - sse: 3092.1953\n","Epoch 31: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0666 - loss: 0.0923 - mae: 0.2320 - mse: 0.1451 - pearson_correlation: 2.7306e-16 - r2_keras: -81.3411 - rmse: 0.8607 - sae: 1862.6696 - sse: 2247.7649 - val_huber_loss: 0.1260 - val_loss: 0.1485 - val_mae: 0.3178 - val_mse: 0.2922 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.1151 - val_rmse: 0.9650 - val_sae: 368.2161 - val_sse: 492.5984 - learning_rate: 0.0024\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0748 - loss: 0.0973 - mae: 0.2425 - mse: 0.1563 - pearson_correlation: 4.3436e-17 - r2_keras: -98.7331 - rmse: 0.8691 - sae: 2547.4766 - sse: 3093.5957\n","Epoch 32: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0666 - loss: 0.0923 - mae: 0.2319 - mse: 0.1449 - pearson_correlation: 5.4034e-18 - r2_keras: -81.3786 - rmse: 0.8609 - sae: 1863.0021 - sse: 2248.7861 - val_huber_loss: 0.1259 - val_loss: 0.1483 - val_mae: 0.3177 - val_mse: 0.2915 - val_pearson_correlation: 8.7317e-17 - val_r2_keras: -34.1340 - val_rmse: 0.9652 - val_sae: 368.3419 - val_sse: 492.8640 - learning_rate: 0.0024\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0747 - loss: 0.0972 - mae: 0.2424 - mse: 0.1561 - pearson_correlation: 3.1591e-16 - r2_keras: -98.8267 - rmse: 0.8695 - sae: 2548.2212 - sse: 3096.4990\n","Epoch 33: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0665 - loss: 0.0922 - mae: 0.2317 - mse: 0.1447 - pearson_correlation: 2.4547e-16 - r2_keras: -81.4417 - rmse: 0.8612 - sae: 1863.5135 - sse: 2250.7297 - val_huber_loss: 0.1260 - val_loss: 0.1484 - val_mae: 0.3182 - val_mse: 0.2917 - val_pearson_correlation: -4.2548e-16 - val_r2_keras: -34.1453 - val_rmse: 0.9654 - val_sae: 368.4182 - val_sse: 493.0215 - learning_rate: 4.7925e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0747 - loss: 0.0972 - mae: 0.2424 - mse: 0.1560 - pearson_correlation: -6.2629e-16 - r2_keras: -98.8440 - rmse: 0.8695 - sae: 2548.3608 - sse: 3097.0366\n","Epoch 34: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0665 - loss: 0.0922 - mae: 0.2317 - mse: 0.1447 - pearson_correlation: -4.0622e-16 - r2_keras: -81.4545 - rmse: 0.8612 - sae: 1863.6122 - sse: 2251.1033 - val_huber_loss: 0.1260 - val_loss: 0.1485 - val_mae: 0.3185 - val_mse: 0.2917 - val_pearson_correlation: -2.1813e-17 - val_r2_keras: -34.1528 - val_rmse: 0.9655 - val_sae: 368.4661 - val_sse: 493.1275 - learning_rate: 4.7925e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0747 - loss: 0.0972 - mae: 0.2424 - mse: 0.1560 - pearson_correlation: 3.8244e-16 - r2_keras: -98.8617 - rmse: 0.8696 - sae: 2548.5039 - sse: 3097.5840\n","Epoch 35: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0665 - loss: 0.0922 - mae: 0.2317 - mse: 0.1447 - pearson_correlation: 2.5402e-16 - r2_keras: -81.4669 - rmse: 0.8613 - sae: 1863.7103 - sse: 2251.4749 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3187 - val_mse: 0.2919 - val_pearson_correlation: 1.7450e-16 - val_r2_keras: -34.1537 - val_rmse: 0.9655 - val_sae: 368.4683 - val_sse: 493.1397 - learning_rate: 4.7925e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0747 - loss: 0.0971 - mae: 0.2423 - mse: 0.1559 - pearson_correlation: -2.7387e-16 - r2_keras: -98.8690 - rmse: 0.8697 - sae: 2548.5840 - sse: 3097.8113\n","Epoch 36: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0665 - loss: 0.0921 - mae: 0.2317 - mse: 0.1446 - pearson_correlation: -1.6468e-16 - r2_keras: -81.4731 - rmse: 0.8613 - sae: 1863.7693 - sse: 2251.6414 - val_huber_loss: 0.1261 - val_loss: 0.1485 - val_mae: 0.3188 - val_mse: 0.2918 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.1586 - val_rmse: 0.9656 - val_sae: 368.4977 - val_sse: 493.2092 - learning_rate: 4.7925e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2423 - mse: 0.1559 - pearson_correlation: 4.7975e-16 - r2_keras: -98.8863 - rmse: 0.8697 - sae: 2548.7239 - sse: 3098.3486\n","Epoch 37: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0665 - loss: 0.0921 - mae: 0.2316 - mse: 0.1446 - pearson_correlation: 3.1324e-16 - r2_keras: -81.4857 - rmse: 0.8614 - sae: 1863.8673 - sse: 2252.0122 - val_huber_loss: 0.1261 - val_loss: 0.1485 - val_mae: 0.3188 - val_mse: 0.2917 - val_pearson_correlation: 2.2894e-16 - val_r2_keras: -34.1630 - val_rmse: 0.9656 - val_sae: 368.5226 - val_sse: 493.2706 - learning_rate: 4.7925e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2423 - mse: 0.1559 - pearson_correlation: 2.6388e-16 - r2_keras: -98.9026 - rmse: 0.8698 - sae: 2548.8542 - sse: 3098.8545\n","Epoch 38: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1446 - pearson_correlation: 2.0417e-16 - r2_keras: -81.4965 - rmse: 0.8614 - sae: 1863.9562 - sse: 2252.3486 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3189 - val_mse: 0.2918 - val_pearson_correlation: -1.0901e-17 - val_r2_keras: -34.1659 - val_rmse: 0.9657 - val_sae: 368.5394 - val_sse: 493.3105 - learning_rate: 9.5850e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2423 - mse: 0.1559 - pearson_correlation: -3.6846e-16 - r2_keras: -98.9061 - rmse: 0.8698 - sae: 2548.8823 - sse: 3098.9614\n","Epoch 39: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -2.6165e-16 - r2_keras: -81.4989 - rmse: 0.8614 - sae: 1863.9755 - sse: 2252.4216 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3189 - val_mse: 0.2918 - val_pearson_correlation: -1.8530e-16 - val_r2_keras: -34.1677 - val_rmse: 0.9657 - val_sae: 368.5498 - val_sse: 493.3360 - learning_rate: 9.5850e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2423 - mse: 0.1558 - pearson_correlation: -1.4672e-16 - r2_keras: -98.9095 - rmse: 0.8698 - sae: 2548.9121 - sse: 3099.0667\n","Epoch 40: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -8.1802e-17 - r2_keras: -81.5014 - rmse: 0.8614 - sae: 1863.9965 - sse: 2252.4946 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: -3.2698e-17 - val_r2_keras: -34.1689 - val_rmse: 0.9657 - val_sae: 368.5558 - val_sse: 493.3528 - learning_rate: 9.5850e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2423 - mse: 0.1558 - pearson_correlation: -2.8864e-16 - r2_keras: -98.9128 - rmse: 0.8698 - sae: 2548.9390 - sse: 3099.1709\n","Epoch 41: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -2.4328e-16 - r2_keras: -81.5038 - rmse: 0.8615 - sae: 1864.0148 - sse: 2252.5659 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: -1.0899e-17 - val_r2_keras: -34.1699 - val_rmse: 0.9657 - val_sae: 368.5612 - val_sse: 493.3668 - learning_rate: 9.5850e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -2.5397e-17 - r2_keras: -98.9160 - rmse: 0.8699 - sae: 2548.9629 - sse: 3099.2708\n","Epoch 42: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -5.9309e-17 - r2_keras: -81.5062 - rmse: 0.8615 - sae: 1864.0319 - sse: 2252.6353 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 3.2696e-16 - val_r2_keras: -34.1705 - val_rmse: 0.9657 - val_sae: 368.5640 - val_sse: 493.3756 - learning_rate: 9.5850e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -1.5596e-16 - r2_keras: -98.9194 - rmse: 0.8699 - sae: 2548.9900 - sse: 3099.3740\n","Epoch 43: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -7.2896e-17 - r2_keras: -81.5084 - rmse: 0.8615 - sae: 1864.0504 - sse: 2252.7041 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: -6.1030e-16 - val_r2_keras: -34.1710 - val_rmse: 0.9657 - val_sae: 368.5666 - val_sse: 493.3826 - learning_rate: 1.9170e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 5.4077e-17 - r2_keras: -98.9201 - rmse: 0.8699 - sae: 2548.9958 - sse: 3099.3953\n","Epoch 44: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 6.0536e-17 - r2_keras: -81.5089 - rmse: 0.8615 - sae: 1864.0544 - sse: 2252.7188 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: 8.7185e-17 - val_r2_keras: -34.1713 - val_rmse: 0.9658 - val_sae: 368.5681 - val_sse: 493.3873 - learning_rate: 1.9170e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -5.6975e-16 - r2_keras: -98.9207 - rmse: 0.8699 - sae: 2549.0010 - sse: 3099.4155\n","Epoch 45: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -3.4311e-16 - r2_keras: -81.5094 - rmse: 0.8615 - sae: 1864.0581 - sse: 2252.7327 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: -4.4682e-16 - val_r2_keras: -34.1716 - val_rmse: 0.9658 - val_sae: 368.5695 - val_sse: 493.3909 - learning_rate: 1.9170e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -3.8809e-16 - r2_keras: -98.9214 - rmse: 0.8699 - sae: 2549.0063 - sse: 3099.4360\n","Epoch 46: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -2.8792e-16 - r2_keras: -81.5099 - rmse: 0.8615 - sae: 1864.0619 - sse: 2252.7471 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: 2.9424e-16 - val_r2_keras: -34.1718 - val_rmse: 0.9658 - val_sae: 368.5702 - val_sse: 493.3933 - learning_rate: 1.9170e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -3.6957e-16 - r2_keras: -98.9220 - rmse: 0.8699 - sae: 2549.0115 - sse: 3099.4556\n","Epoch 47: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -3.2077e-16 - r2_keras: -81.5103 - rmse: 0.8615 - sae: 1864.0656 - sse: 2252.7605 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: 2.1796e-17 - val_r2_keras: -34.1719 - val_rmse: 0.9658 - val_sae: 368.5709 - val_sse: 493.3954 - learning_rate: 1.9170e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -5.0102e-16 - r2_keras: -98.9226 - rmse: 0.8699 - sae: 2549.0168 - sse: 3099.4756\n","Epoch 48: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -3.6415e-16 - r2_keras: -81.5108 - rmse: 0.8615 - sae: 1864.0692 - sse: 2252.7739 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: 1.7437e-16 - val_r2_keras: -34.1720 - val_rmse: 0.9658 - val_sae: 368.5714 - val_sse: 493.3969 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -1.3982e-16 - r2_keras: -98.9230 - rmse: 0.8699 - sae: 2549.0195 - sse: 3099.4854\n","Epoch 49: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -1.2241e-16 - r2_keras: -81.5110 - rmse: 0.8615 - sae: 1864.0710 - sse: 2252.7808 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: 6.5387e-17 - val_r2_keras: -34.1721 - val_rmse: 0.9658 - val_sae: 368.5717 - val_sse: 493.3981 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -3.6090e-16 - r2_keras: -98.9233 - rmse: 0.8699 - sae: 2549.0225 - sse: 3099.4961\n","Epoch 50: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -1.5302e-16 - r2_keras: -81.5113 - rmse: 0.8615 - sae: 1864.0731 - sse: 2252.7881 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2918 - val_pearson_correlation: 2.5065e-16 - val_r2_keras: -34.1722 - val_rmse: 0.9658 - val_sae: 368.5720 - val_sse: 493.3991 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -4.5172e-16 - r2_keras: -98.9236 - rmse: 0.8699 - sae: 2549.0249 - sse: 3099.5061\n","Epoch 51: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -3.0585e-16 - r2_keras: -81.5115 - rmse: 0.8615 - sae: 1864.0747 - sse: 2252.7949 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.7436e-16 - val_r2_keras: -34.1722 - val_rmse: 0.9658 - val_sae: 368.5724 - val_sse: 493.4001 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -3.8181e-16 - r2_keras: -98.9240 - rmse: 0.8699 - sae: 2549.0278 - sse: 3099.5171\n","Epoch 52: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -2.8185e-16 - r2_keras: -81.5117 - rmse: 0.8615 - sae: 1864.0768 - sse: 2252.8025 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 4.3591e-17 - val_r2_keras: -34.1723 - val_rmse: 0.9658 - val_sae: 368.5725 - val_sse: 493.4006 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -2.3213e-16 - r2_keras: -98.9243 - rmse: 0.8699 - sae: 2549.0303 - sse: 3099.5271\n","Epoch 53: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -1.9054e-16 - r2_keras: -81.5120 - rmse: 0.8615 - sae: 1864.0785 - sse: 2252.8093 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 2.0706e-16 - val_r2_keras: -34.1723 - val_rmse: 0.9658 - val_sae: 368.5726 - val_sse: 493.4010 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 6.7816e-16 - r2_keras: -98.9246 - rmse: 0.8699 - sae: 2549.0332 - sse: 3099.5364\n","Epoch 54: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 3.7489e-16 - r2_keras: -81.5122 - rmse: 0.8615 - sae: 1864.0806 - sse: 2252.8159 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.4167e-16 - val_r2_keras: -34.1724 - val_rmse: 0.9658 - val_sae: 368.5728 - val_sse: 493.4017 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -6.5725e-18 - r2_keras: -98.9249 - rmse: 0.8699 - sae: 2549.0352 - sse: 3099.5464\n","Epoch 55: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -5.3234e-18 - r2_keras: -81.5124 - rmse: 0.8615 - sae: 1864.0819 - sse: 2252.8225 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: -1.3077e-16 - val_r2_keras: -34.1724 - val_rmse: 0.9658 - val_sae: 368.5731 - val_sse: 493.4023 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 2.3362e-16 - r2_keras: -98.9253 - rmse: 0.8699 - sae: 2549.0383 - sse: 3099.5574\n","Epoch 56: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 1.0772e-16 - r2_keras: -81.5127 - rmse: 0.8615 - sae: 1864.0841 - sse: 2252.8301 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 2.1795e-17 - val_r2_keras: -34.1724 - val_rmse: 0.9658 - val_sae: 368.5731 - val_sse: 493.4026 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -2.2675e-16 - r2_keras: -98.9256 - rmse: 0.8699 - sae: 2549.0408 - sse: 3099.5669\n","Epoch 57: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -1.1915e-16 - r2_keras: -81.5129 - rmse: 0.8615 - sae: 1864.0858 - sse: 2252.8367 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: -1.5257e-16 - val_r2_keras: -34.1725 - val_rmse: 0.9658 - val_sae: 368.5734 - val_sse: 493.4034 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -3.3758e-17 - r2_keras: -98.9259 - rmse: 0.8699 - sae: 2549.0430 - sse: 3099.5767\n","Epoch 58: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 2.8346e-17 - r2_keras: -81.5131 - rmse: 0.8615 - sae: 1864.0873 - sse: 2252.8435 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.8526e-16 - val_r2_keras: -34.1725 - val_rmse: 0.9658 - val_sae: 368.5734 - val_sse: 493.4037 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 4.1525e-17 - r2_keras: -98.9262 - rmse: 0.8699 - sae: 2549.0459 - sse: 3099.5872\n","Epoch 59: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 4.0867e-17 - r2_keras: -81.5134 - rmse: 0.8615 - sae: 1864.0894 - sse: 2252.8506 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: -6.5386e-17 - val_r2_keras: -34.1725 - val_rmse: 0.9658 - val_sae: 368.5735 - val_sse: 493.4041 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 4.2153e-16 - r2_keras: -98.9266 - rmse: 0.8699 - sae: 2549.0483 - sse: 3099.5972\n","Epoch 60: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 3.4317e-16 - r2_keras: -81.5136 - rmse: 0.8615 - sae: 1864.0909 - sse: 2252.8574 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 2.5064e-16 - val_r2_keras: -34.1726 - val_rmse: 0.9658 - val_sae: 368.5738 - val_sse: 493.4048 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -5.2788e-16 - r2_keras: -98.9269 - rmse: 0.8699 - sae: 2549.0508 - sse: 3099.6072\n","Epoch 61: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -3.5192e-16 - r2_keras: -81.5138 - rmse: 0.8615 - sae: 1864.0927 - sse: 2252.8643 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.5257e-16 - val_r2_keras: -34.1726 - val_rmse: 0.9658 - val_sae: 368.5739 - val_sse: 493.4051 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 3.4116e-16 - r2_keras: -98.9272 - rmse: 0.8699 - sae: 2549.0537 - sse: 3099.6174\n","Epoch 62: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 1.7753e-16 - r2_keras: -81.5141 - rmse: 0.8615 - sae: 1864.0947 - sse: 2252.8713 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 4.2500e-16 - val_r2_keras: -34.1726 - val_rmse: 0.9658 - val_sae: 368.5739 - val_sse: 493.4056 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 3.5341e-16 - r2_keras: -98.9276 - rmse: 0.8699 - sae: 2549.0562 - sse: 3099.6277\n","Epoch 63: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 2.8740e-16 - r2_keras: -81.5143 - rmse: 0.8615 - sae: 1864.0964 - sse: 2252.8784 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: -1.8526e-16 - val_r2_keras: -34.1727 - val_rmse: 0.9658 - val_sae: 368.5741 - val_sse: 493.4061 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -1.0665e-16 - r2_keras: -98.9279 - rmse: 0.8699 - sae: 2549.0586 - sse: 3099.6377\n","Epoch 64: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -7.7691e-17 - r2_keras: -81.5145 - rmse: 0.8615 - sae: 1864.0981 - sse: 2252.8853 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.6346e-16 - val_r2_keras: -34.1727 - val_rmse: 0.9658 - val_sae: 368.5743 - val_sse: 493.4067 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: -5.3802e-16 - r2_keras: -98.9282 - rmse: 0.8699 - sae: 2549.0615 - sse: 3099.6477\n","Epoch 65: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: -3.7281e-16 - r2_keras: -81.5148 - rmse: 0.8615 - sae: 1864.1002 - sse: 2252.8921 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.9615e-16 - val_r2_keras: -34.1727 - val_rmse: 0.9658 - val_sae: 368.5744 - val_sse: 493.4070 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 1.5235e-16 - r2_keras: -98.9286 - rmse: 0.8699 - sae: 2549.0640 - sse: 3099.6587\n","Epoch 66: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 1.4489e-16 - r2_keras: -81.5150 - rmse: 0.8615 - sae: 1864.1018 - sse: 2252.8997 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: 1.0897e-17 - val_r2_keras: -34.1728 - val_rmse: 0.9658 - val_sae: 368.5746 - val_sse: 493.4077 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.0971 - mae: 0.2422 - mse: 0.1558 - pearson_correlation: 5.0814e-16 - r2_keras: -98.9289 - rmse: 0.8699 - sae: 2549.0667 - sse: 3099.6682\n","Epoch 67: val_loss did not improve from 0.14472\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0664 - loss: 0.0921 - mae: 0.2316 - mse: 0.1445 - pearson_correlation: 3.7926e-16 - r2_keras: -81.5152 - rmse: 0.8615 - sae: 1864.1036 - sse: 2252.9062 - val_huber_loss: 0.1261 - val_loss: 0.1486 - val_mae: 0.3190 - val_mse: 0.2917 - val_pearson_correlation: -8.7180e-17 - val_r2_keras: -34.1728 - val_rmse: 0.9658 - val_sae: 368.5746 - val_sse: 493.4079 - learning_rate: 1.0000e-05\n","| \u001b[35m2        \u001b[39m | \u001b[35m-0.1486  \u001b[39m | \u001b[35m0.05991  \u001b[39m | \u001b[35m19.82    \u001b[39m | \u001b[35m19.82    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.4918 - loss: 0.5157 - mae: 0.8187 - mse: 2.4936 - pearson_correlation: -1.6037e-16 - r2_keras: -464.6294 - rmse: 1.8778 - sae: 4336.9546 - sse: 14443.2402\n","Epoch 1: val_loss improved from inf to 0.28185, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 510ms/step - huber_loss: 0.4873 - loss: 0.5130 - mae: 0.8140 - mse: 2.3328 - pearson_correlation: -6.1236e-17 - r2_keras: -361.6673 - rmse: 1.7623 - sae: 3143.0461 - sse: 10241.6943 - val_huber_loss: 0.2580 - val_loss: 0.2818 - val_mae: 0.6336 - val_mse: 0.5404 - val_pearson_correlation: -2.1956e-16 - val_r2_keras: -32.2631 - val_rmse: 0.9392 - val_sae: 405.6927 - val_sse: 466.6182 - learning_rate: 0.0287\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.2637 - loss: 0.2876 - mae: 0.4999 - mse: 1.1948 - pearson_correlation: 6.4248e-17 - r2_keras: -245.7217 - rmse: 1.3669 - sae: 3060.3274 - sse: 7653.0000\n","Epoch 2: val_loss improved from 0.28185 to 0.25562, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.2848 - loss: 0.3004 - mae: 0.5365 - mse: 1.1374 - pearson_correlation: -2.3371e-16 - r2_keras: -194.7688 - rmse: 1.3063 - sae: 2257.6265 - sse: 5469.0049 - val_huber_loss: 0.2318 - val_loss: 0.2556 - val_mae: 0.5772 - val_mse: 0.5112 - val_pearson_correlation: -1.5623e-16 - val_r2_keras: -26.0349 - val_rmse: 0.8467 - val_sae: 351.8925 - val_sse: 379.2490 - learning_rate: 0.0287\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2692 - loss: 0.2931 - mae: 0.5445 - mse: 0.8707 - pearson_correlation: 3.0629e-16 - r2_keras: -160.9852 - rmse: 1.1076 - sae: 2757.3430 - sse: 5024.5767\n","Epoch 3: val_loss improved from 0.25562 to 0.22795, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.2551 - loss: 0.2845 - mae: 0.5406 - mse: 0.8060 - pearson_correlation: 1.6059e-16 - r2_keras: -125.9715 - rmse: 1.0461 - sae: 2014.3699 - sse: 3572.3699 - val_huber_loss: 0.2041 - val_loss: 0.2279 - val_mae: 0.5201 - val_mse: 0.4551 - val_pearson_correlation: 1.9673e-16 - val_r2_keras: -26.0346 - val_rmse: 0.8467 - val_sae: 336.5249 - val_sse: 379.2444 - learning_rate: 0.0287\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1887 - loss: 0.2125 - mae: 0.4145 - mse: 0.5294 - pearson_correlation: 1.0146e-16 - r2_keras: -130.2032 - rmse: 0.9968 - sae: 2673.0771 - sse: 4069.7607\n","Epoch 4: val_loss improved from 0.22795 to 0.22152, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1915 - loss: 0.2142 - mae: 0.4303 - mse: 0.5097 - pearson_correlation: 1.4714e-17 - r2_keras: -104.3127 - rmse: 0.9628 - sae: 1960.0973 - sse: 2922.4827 - val_huber_loss: 0.1977 - val_loss: 0.2215 - val_mae: 0.4926 - val_mse: 0.4598 - val_pearson_correlation: 1.1211e-16 - val_r2_keras: -24.8867 - val_rmse: 0.8285 - val_sae: 317.7500 - val_sse: 363.1418 - learning_rate: 0.0287\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1644 - loss: 0.1882 - mae: 0.3885 - mse: 0.3962 - pearson_correlation: -6.1158e-18 - r2_keras: -108.9057 - rmse: 0.9123 - sae: 2584.4526 - sse: 3409.1375\n","Epoch 5: val_loss improved from 0.22152 to 0.20390, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1625 - loss: 0.1871 - mae: 0.3961 - mse: 0.3840 - pearson_correlation: 8.5782e-17 - r2_keras: -87.6917 - rmse: 0.8855 - sae: 1889.4064 - sse: 2453.6501 - val_huber_loss: 0.1801 - val_loss: 0.2039 - val_mae: 0.4554 - val_mse: 0.4230 - val_pearson_correlation: 1.6662e-16 - val_r2_keras: -25.2616 - val_rmse: 0.8345 - val_sae: 313.3063 - val_sse: 368.4007 - learning_rate: 0.0287\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1303 - loss: 0.1542 - mae: 0.3466 - mse: 0.2953 - pearson_correlation: -1.5198e-16 - r2_keras: -98.3695 - rmse: 0.8675 - sae: 2531.1118 - sse: 3082.3167\n","Epoch 6: val_loss improved from 0.20390 to 0.19418, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.1327 - loss: 0.1556 - mae: 0.3583 - mse: 0.2941 - pearson_correlation: 2.0553e-17 - r2_keras: -79.8436 - rmse: 0.8481 - sae: 1849.9569 - sse: 2226.1042 - val_huber_loss: 0.1704 - val_loss: 0.1942 - val_mae: 0.4299 - val_mse: 0.4080 - val_pearson_correlation: -5.3529e-17 - val_r2_keras: -25.4044 - val_rmse: 0.8368 - val_sae: 308.6254 - val_sse: 370.4036 - learning_rate: 0.0287\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1172 - loss: 0.1410 - mae: 0.3258 - mse: 0.2669 - pearson_correlation: 2.4536e-16 - r2_keras: -94.3284 - rmse: 0.8497 - sae: 2493.8240 - sse: 2956.9675\n","Epoch 7: val_loss improved from 0.19418 to 0.18662, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.1198 - loss: 0.1426 - mae: 0.3351 - mse: 0.2660 - pearson_correlation: 1.0658e-16 - r2_keras: -76.7350 - rmse: 0.8324 - sae: 1821.6565 - sse: 2137.6755 - val_huber_loss: 0.1628 - val_loss: 0.1866 - val_mae: 0.4101 - val_mse: 0.3955 - val_pearson_correlation: 2.7475e-16 - val_r2_keras: -25.6785 - val_rmse: 0.8411 - val_sae: 306.9276 - val_sse: 374.2482 - learning_rate: 0.0287\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1120 - loss: 0.1358 - mae: 0.3147 - mse: 0.2551 - pearson_correlation: 5.2511e-16 - r2_keras: -93.0363 - rmse: 0.8439 - sae: 2475.0420 - sse: 2916.8882\n","Epoch 8: val_loss improved from 0.18662 to 0.17268, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1142 - loss: 0.1371 - mae: 0.3227 - mse: 0.2538 - pearson_correlation: 3.7218e-16 - r2_keras: -75.8073 - rmse: 0.8279 - sae: 1808.1630 - sse: 2110.1787 - val_huber_loss: 0.1489 - val_loss: 0.1727 - val_mae: 0.3871 - val_mse: 0.3620 - val_pearson_correlation: -8.2697e-17 - val_r2_keras: -26.2948 - val_rmse: 0.8508 - val_sae: 309.7793 - val_sse: 382.8940 - learning_rate: 0.0287\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1075 - loss: 0.1313 - mae: 0.3083 - mse: 0.2445 - pearson_correlation: 5.5106e-17 - r2_keras: -93.1372 - rmse: 0.8443 - sae: 2470.3418 - sse: 2920.0195\n","Epoch 9: val_loss improved from 0.17268 to 0.17235, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.1090 - loss: 0.1322 - mae: 0.3142 - mse: 0.2424 - pearson_correlation: 1.9152e-17 - r2_keras: -75.9365 - rmse: 0.8288 - sae: 1804.7513 - sse: 2112.9924 - val_huber_loss: 0.1486 - val_loss: 0.1723 - val_mae: 0.3782 - val_mse: 0.3659 - val_pearson_correlation: -7.6445e-17 - val_r2_keras: -26.3083 - val_rmse: 0.8510 - val_sae: 308.0759 - val_sse: 383.0838 - learning_rate: 0.0287\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1066 - loss: 0.1304 - mae: 0.3054 - mse: 0.2412 - pearson_correlation: -4.8627e-16 - r2_keras: -91.6791 - rmse: 0.8378 - sae: 2458.3660 - sse: 2874.7896\n","Epoch 10: val_loss improved from 0.17235 to 0.15872, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1070 - loss: 0.1306 - mae: 0.3091 - mse: 0.2379 - pearson_correlation: -2.9757e-16 - r2_keras: -74.8904 - rmse: 0.8237 - sae: 1796.1484 - sse: 2081.9702 - val_huber_loss: 0.1350 - val_loss: 0.1587 - val_mae: 0.3575 - val_mse: 0.3291 - val_pearson_correlation: -2.9550e-16 - val_r2_keras: -27.0707 - val_rmse: 0.8628 - val_sae: 314.2479 - val_sse: 393.7791 - learning_rate: 0.0287\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1039 - loss: 0.1277 - mae: 0.3017 - mse: 0.2348 - pearson_correlation: 3.7901e-17 - r2_keras: -91.9756 - rmse: 0.8391 - sae: 2460.4729 - sse: 2883.9868\n","Epoch 11: val_loss improved from 0.15872 to 0.14602, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.1037 - loss: 0.1275 - mae: 0.3036 - mse: 0.2308 - pearson_correlation: -2.7835e-17 - r2_keras: -75.1104 - rmse: 0.8248 - sae: 1797.4323 - sse: 2088.3643 - val_huber_loss: 0.1223 - val_loss: 0.1460 - val_mae: 0.3366 - val_mse: 0.2938 - val_pearson_correlation: -1.3796e-16 - val_r2_keras: -28.0547 - val_rmse: 0.8778 - val_sae: 321.1921 - val_sse: 407.5826 - learning_rate: 0.0287\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1012 - loss: 0.1249 - mae: 0.2989 - mse: 0.2277 - pearson_correlation: -6.0408e-17 - r2_keras: -92.7138 - rmse: 0.8424 - sae: 2465.0771 - sse: 2906.8862\n","Epoch 12: val_loss improved from 0.14602 to 0.13913, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1005 - loss: 0.1245 - mae: 0.2996 - mse: 0.2233 - pearson_correlation: 7.3838e-17 - r2_keras: -75.6836 - rmse: 0.8278 - sae: 1800.6630 - sse: 2104.5808 - val_huber_loss: 0.1154 - val_loss: 0.1391 - val_mae: 0.3191 - val_mse: 0.2739 - val_pearson_correlation: 1.4951e-17 - val_r2_keras: -28.8949 - val_rmse: 0.8904 - val_sae: 327.3977 - val_sse: 419.3689 - learning_rate: 0.0287\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0997 - loss: 0.1234 - mae: 0.2976 - mse: 0.2234 - pearson_correlation: -6.2273e-16 - r2_keras: -93.1289 - rmse: 0.8443 - sae: 2470.2993 - sse: 2919.7603\n","Epoch 13: val_loss did not improve from 0.13913\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0988 - loss: 0.1228 - mae: 0.2975 - mse: 0.2188 - pearson_correlation: -4.3693e-16 - r2_keras: -76.0344 - rmse: 0.8297 - sae: 1804.3525 - sse: 2114.0334 - val_huber_loss: 0.1197 - val_loss: 0.1434 - val_mae: 0.3205 - val_mse: 0.2861 - val_pearson_correlation: -1.0516e-16 - val_r2_keras: -28.7875 - val_rmse: 0.8888 - val_sae: 327.7399 - val_sse: 417.8625 - learning_rate: 0.0287\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0986 - loss: 0.1223 - mae: 0.2956 - mse: 0.2188 - pearson_correlation: -2.1647e-16 - r2_keras: -92.2326 - rmse: 0.8403 - sae: 2467.9358 - sse: 2891.9575\n","Epoch 14: val_loss improved from 0.13913 to 0.13531, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0973 - loss: 0.1215 - mae: 0.2949 - mse: 0.2142 - pearson_correlation: -9.1939e-17 - r2_keras: -75.4167 - rmse: 0.8269 - sae: 1802.7018 - sse: 2095.2617 - val_huber_loss: 0.1116 - val_loss: 0.1353 - val_mae: 0.3044 - val_mse: 0.2607 - val_pearson_correlation: -1.2482e-16 - val_r2_keras: -29.7869 - val_rmse: 0.9036 - val_sae: 334.9594 - val_sse: 431.8819 - learning_rate: 0.0287\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0963 - loss: 0.1199 - mae: 0.2912 - mse: 0.2139 - pearson_correlation: -1.7715e-16 - r2_keras: -93.0894 - rmse: 0.8441 - sae: 2475.0488 - sse: 2918.5366\n","Epoch 15: val_loss did not improve from 0.13531\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0950 - loss: 0.1192 - mae: 0.2906 - mse: 0.2092 - pearson_correlation: -1.0507e-16 - r2_keras: -76.0317 - rmse: 0.8298 - sae: 1807.6163 - sse: 2113.4939 - val_huber_loss: 0.1122 - val_loss: 0.1359 - val_mae: 0.3016 - val_mse: 0.2614 - val_pearson_correlation: -2.7881e-16 - val_r2_keras: -30.0450 - val_rmse: 0.9073 - val_sae: 337.2292 - val_sse: 435.5021 - learning_rate: 0.0287\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0947 - loss: 0.1184 - mae: 0.2865 - mse: 0.2094 - pearson_correlation: 1.5835e-16 - r2_keras: -92.9214 - rmse: 0.8434 - sae: 2476.4385 - sse: 2913.3245\n","Epoch 16: val_loss improved from 0.13531 to 0.13199, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0932 - loss: 0.1174 - mae: 0.2862 - mse: 0.2046 - pearson_correlation: 1.2302e-16 - r2_keras: -75.8761 - rmse: 0.8289 - sae: 1808.4117 - sse: 2109.5076 - val_huber_loss: 0.1083 - val_loss: 0.1320 - val_mae: 0.3002 - val_mse: 0.2492 - val_pearson_correlation: -3.7808e-16 - val_r2_keras: -30.7055 - val_rmse: 0.9169 - val_sae: 341.4619 - val_sse: 444.7687 - learning_rate: 0.0287\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0927 - loss: 0.1163 - mae: 0.2834 - mse: 0.2048 - pearson_correlation: -2.9485e-16 - r2_keras: -93.7750 - rmse: 0.8472 - sae: 2484.3579 - sse: 2939.8032\n","Epoch 17: val_loss improved from 0.13199 to 0.13112, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0909 - loss: 0.1153 - mae: 0.2831 - mse: 0.1997 - pearson_correlation: -2.1596e-16 - r2_keras: -76.5669 - rmse: 0.8326 - sae: 1814.2195 - sse: 2128.5879 - val_huber_loss: 0.1075 - val_loss: 0.1311 - val_mae: 0.2998 - val_mse: 0.2453 - val_pearson_correlation: 1.3283e-16 - val_r2_keras: -31.1740 - val_rmse: 0.9237 - val_sae: 345.1517 - val_sse: 451.3400 - learning_rate: 0.0287\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0915 - loss: 0.1151 - mae: 0.2822 - mse: 0.2013 - pearson_correlation: 3.0604e-16 - r2_keras: -94.0568 - rmse: 0.8484 - sae: 2490.4905 - sse: 2948.5439\n","Epoch 18: val_loss did not improve from 0.13112\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0896 - loss: 0.1140 - mae: 0.2821 - mse: 0.1961 - pearson_correlation: 1.4585e-16 - r2_keras: -76.7543 - rmse: 0.8335 - sae: 1818.5505 - sse: 2134.4104 - val_huber_loss: 0.1083 - val_loss: 0.1319 - val_mae: 0.2987 - val_mse: 0.2470 - val_pearson_correlation: 2.0036e-16 - val_r2_keras: -31.3348 - val_rmse: 0.9260 - val_sae: 346.4286 - val_sse: 453.5957 - learning_rate: 0.0287\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0905 - loss: 0.1141 - mae: 0.2796 - mse: 0.1984 - pearson_correlation: 1.9871e-17 - r2_keras: -94.1798 - rmse: 0.8490 - sae: 2495.6362 - sse: 2952.3596\n","Epoch 19: val_loss did not improve from 0.13112\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0887 - loss: 0.1130 - mae: 0.2794 - mse: 0.1934 - pearson_correlation: 8.5910e-17 - r2_keras: -76.9176 - rmse: 0.8346 - sae: 1822.3763 - sse: 2137.9075 - val_huber_loss: 0.1078 - val_loss: 0.1314 - val_mae: 0.2975 - val_mse: 0.2466 - val_pearson_correlation: -2.8852e-16 - val_r2_keras: -31.3117 - val_rmse: 0.9257 - val_sae: 346.0567 - val_sse: 453.2720 - learning_rate: 0.0287\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0890 - loss: 0.1126 - mae: 0.2758 - mse: 0.1949 - pearson_correlation: 1.2717e-16 - r2_keras: -94.0597 - rmse: 0.8485 - sae: 2495.3779 - sse: 2948.6343\n","Epoch 20: val_loss improved from 0.13112 to 0.13098, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0869 - loss: 0.1114 - mae: 0.2754 - mse: 0.1896 - pearson_correlation: 8.9032e-17 - r2_keras: -76.8824 - rmse: 0.8346 - sae: 1822.2600 - sse: 2135.9497 - val_huber_loss: 0.1074 - val_loss: 0.1310 - val_mae: 0.2979 - val_mse: 0.2457 - val_pearson_correlation: -3.0257e-16 - val_r2_keras: -31.2185 - val_rmse: 0.9243 - val_sae: 345.6653 - val_sse: 451.9641 - learning_rate: 0.0287\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0874 - loss: 0.1110 - mae: 0.2739 - mse: 0.1909 - pearson_correlation: 1.3188e-16 - r2_keras: -94.4108 - rmse: 0.8500 - sae: 2499.4294 - sse: 2959.5225\n","Epoch 21: val_loss improved from 0.13098 to 0.12951, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0854 - loss: 0.1097 - mae: 0.2735 - mse: 0.1858 - pearson_correlation: 3.4122e-17 - r2_keras: -76.9988 - rmse: 0.8346 - sae: 1824.3936 - sse: 2141.8293 - val_huber_loss: 0.1059 - val_loss: 0.1295 - val_mae: 0.2965 - val_mse: 0.2405 - val_pearson_correlation: -2.4812e-17 - val_r2_keras: -31.4668 - val_rmse: 0.9279 - val_sae: 347.8676 - val_sse: 455.4483 - learning_rate: 0.0287\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0866 - loss: 0.1101 - mae: 0.2740 - mse: 0.1882 - pearson_correlation: -1.3853e-16 - r2_keras: -94.8749 - rmse: 0.8521 - sae: 2505.9832 - sse: 2973.9185\n","Epoch 22: val_loss improved from 0.12951 to 0.12827, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0844 - loss: 0.1088 - mae: 0.2735 - mse: 0.1832 - pearson_correlation: -2.1638e-16 - r2_keras: -77.3708 - rmse: 0.8365 - sae: 1829.4703 - sse: 2152.1604 - val_huber_loss: 0.1047 - val_loss: 0.1283 - val_mae: 0.2958 - val_mse: 0.2363 - val_pearson_correlation: 3.9965e-16 - val_r2_keras: -31.9146 - val_rmse: 0.9343 - val_sae: 350.3022 - val_sse: 461.7298 - learning_rate: 0.0287\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0859 - loss: 0.1094 - mae: 0.2726 - mse: 0.1866 - pearson_correlation: 2.7342e-16 - r2_keras: -95.2826 - rmse: 0.8539 - sae: 2509.3447 - sse: 2986.5649\n","Epoch 23: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.0834 - loss: 0.1080 - mae: 0.2718 - mse: 0.1812 - pearson_correlation: 2.7327e-16 - r2_keras: -77.7491 - rmse: 0.8387 - sae: 1832.1722 - sse: 2161.8408 - val_huber_loss: 0.1071 - val_loss: 0.1307 - val_mae: 0.3056 - val_mse: 0.2435 - val_pearson_correlation: 1.4425e-16 - val_r2_keras: -32.1065 - val_rmse: 0.9370 - val_sae: 350.7819 - val_sse: 464.4211 - learning_rate: 0.0287\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0855 - loss: 0.1090 - mae: 0.2702 - mse: 0.1856 - pearson_correlation: 3.9530e-16 - r2_keras: -95.3901 - rmse: 0.8544 - sae: 2512.2417 - sse: 2989.9016\n","Epoch 24: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0828 - loss: 0.1074 - mae: 0.2692 - mse: 0.1799 - pearson_correlation: 2.5516e-16 - r2_keras: -77.9416 - rmse: 0.8402 - sae: 1834.4429 - sse: 2165.4824 - val_huber_loss: 0.1058 - val_loss: 0.1293 - val_mae: 0.2954 - val_mse: 0.2407 - val_pearson_correlation: 2.3657e-16 - val_r2_keras: -31.4016 - val_rmse: 0.9269 - val_sae: 347.5702 - val_sse: 454.5329 - learning_rate: 0.0287\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0843 - loss: 0.1078 - mae: 0.2709 - mse: 0.1822 - pearson_correlation: -6.4511e-16 - r2_keras: -95.7904 - rmse: 0.8561 - sae: 2517.1963 - sse: 3002.3181\n","Epoch 25: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0816 - loss: 0.1062 - mae: 0.2696 - mse: 0.1766 - pearson_correlation: -3.6609e-16 - r2_keras: -78.0045 - rmse: 0.8395 - sae: 1836.9236 - sse: 2171.3677 - val_huber_loss: 0.1078 - val_loss: 0.1313 - val_mae: 0.3039 - val_mse: 0.2455 - val_pearson_correlation: 4.3609e-16 - val_r2_keras: -31.9527 - val_rmse: 0.9348 - val_sae: 350.2438 - val_sse: 462.2642 - learning_rate: 0.0287\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0838 - loss: 0.1073 - mae: 0.2670 - mse: 0.1808 - pearson_correlation: 3.3269e-16 - r2_keras: -96.3833 - rmse: 0.8588 - sae: 2527.4141 - sse: 3020.7080\n","Epoch 26: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0812 - loss: 0.1057 - mae: 0.2663 - mse: 0.1753 - pearson_correlation: 1.2923e-16 - r2_keras: -78.5409 - rmse: 0.8425 - sae: 1844.8783 - sse: 2185.2834 - val_huber_loss: 0.1064 - val_loss: 0.1299 - val_mae: 0.2973 - val_mse: 0.2420 - val_pearson_correlation: -1.6903e-16 - val_r2_keras: -31.9938 - val_rmse: 0.9354 - val_sae: 350.6324 - val_sse: 462.8404 - learning_rate: 0.0287\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0829 - loss: 0.1064 - mae: 0.2649 - mse: 0.1787 - pearson_correlation: 5.1539e-16 - r2_keras: -96.2731 - rmse: 0.8583 - sae: 2524.1931 - sse: 3017.2903\n","Epoch 27: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0799 - loss: 0.1046 - mae: 0.2635 - mse: 0.1729 - pearson_correlation: 2.9118e-16 - r2_keras: -78.5036 - rmse: 0.8425 - sae: 1842.6547 - sse: 2183.4282 - val_huber_loss: 0.1090 - val_loss: 0.1325 - val_mae: 0.3042 - val_mse: 0.2498 - val_pearson_correlation: -3.6229e-17 - val_r2_keras: -32.0311 - val_rmse: 0.9359 - val_sae: 350.2206 - val_sse: 463.3636 - learning_rate: 0.0287\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0824 - loss: 0.1059 - mae: 0.2629 - mse: 0.1776 - pearson_correlation: -1.0380e-15 - r2_keras: -96.2707 - rmse: 0.8583 - sae: 2526.7544 - sse: 3017.2146\n","Epoch 28: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0788 - loss: 0.1037 - mae: 0.2604 - mse: 0.1709 - pearson_correlation: -7.1133e-16 - r2_keras: -78.2300 - rmse: 0.8400 - sae: 1842.6600 - sse: 2180.1880 - val_huber_loss: 0.1073 - val_loss: 0.1308 - val_mae: 0.2990 - val_mse: 0.2440 - val_pearson_correlation: 7.1768e-17 - val_r2_keras: -32.1805 - val_rmse: 0.9380 - val_sae: 351.6476 - val_sse: 465.4597 - learning_rate: 0.0057\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0817 - loss: 0.1052 - mae: 0.2608 - mse: 0.1762 - pearson_correlation: 1.4300e-16 - r2_keras: -96.8750 - rmse: 0.8609 - sae: 2532.3711 - sse: 3035.9590\n","Epoch 29: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0782 - loss: 0.1031 - mae: 0.2586 - mse: 0.1696 - pearson_correlation: -6.4436e-18 - r2_keras: -78.6714 - rmse: 0.8421 - sae: 1846.5887 - sse: 2193.1360 - val_huber_loss: 0.1064 - val_loss: 0.1299 - val_mae: 0.2961 - val_mse: 0.2405 - val_pearson_correlation: 7.0903e-17 - val_r2_keras: -32.3988 - val_rmse: 0.9411 - val_sae: 353.3329 - val_sse: 468.5225 - learning_rate: 0.0057\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0814 - loss: 0.1049 - mae: 0.2601 - mse: 0.1753 - pearson_correlation: -6.6732e-16 - r2_keras: -97.2820 - rmse: 0.8627 - sae: 2536.9814 - sse: 3048.5859\n","Epoch 30: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0779 - loss: 0.1028 - mae: 0.2580 - mse: 0.1689 - pearson_correlation: -4.8972e-16 - r2_keras: -78.9772 - rmse: 0.8437 - sae: 1849.8763 - sse: 2201.9583 - val_huber_loss: 0.1055 - val_loss: 0.1290 - val_mae: 0.2943 - val_mse: 0.2372 - val_pearson_correlation: 1.4040e-16 - val_r2_keras: -32.5910 - val_rmse: 0.9438 - val_sae: 354.6437 - val_sse: 471.2177 - learning_rate: 0.0057\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0811 - loss: 0.1045 - mae: 0.2592 - mse: 0.1746 - pearson_correlation: -8.1045e-16 - r2_keras: -97.6913 - rmse: 0.8645 - sae: 2540.8882 - sse: 3061.2798\n","Epoch 31: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0776 - loss: 0.1024 - mae: 0.2573 - mse: 0.1681 - pearson_correlation: -4.6568e-16 - r2_keras: -79.2658 - rmse: 0.8450 - sae: 1852.5372 - sse: 2210.6062 - val_huber_loss: 0.1055 - val_loss: 0.1290 - val_mae: 0.2937 - val_mse: 0.2368 - val_pearson_correlation: -6.9947e-17 - val_r2_keras: -32.6598 - val_rmse: 0.9448 - val_sae: 355.2034 - val_sse: 472.1832 - learning_rate: 0.0057\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1043 - mae: 0.2592 - mse: 0.1739 - pearson_correlation: -1.7329e-16 - r2_keras: -97.7800 - rmse: 0.8649 - sae: 2542.3403 - sse: 3064.0334\n","Epoch 32: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0774 - loss: 0.1022 - mae: 0.2572 - mse: 0.1675 - pearson_correlation: 7.0185e-17 - r2_keras: -79.3420 - rmse: 0.8454 - sae: 1853.6211 - sse: 2212.6414 - val_huber_loss: 0.1051 - val_loss: 0.1285 - val_mae: 0.2931 - val_mse: 0.2353 - val_pearson_correlation: 9.2823e-17 - val_r2_keras: -32.7560 - val_rmse: 0.9461 - val_sae: 355.7604 - val_sse: 473.5331 - learning_rate: 0.0057\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0806 - loss: 0.1040 - mae: 0.2586 - mse: 0.1733 - pearson_correlation: -4.5946e-16 - r2_keras: -98.0147 - rmse: 0.8659 - sae: 2544.4539 - sse: 3071.3110\n","Epoch 33: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0771 - loss: 0.1019 - mae: 0.2566 - mse: 0.1668 - pearson_correlation: -4.1506e-16 - r2_keras: -79.4784 - rmse: 0.8459 - sae: 1854.9141 - sse: 2217.2581 - val_huber_loss: 0.1052 - val_loss: 0.1286 - val_mae: 0.2938 - val_mse: 0.2356 - val_pearson_correlation: -9.2910e-17 - val_r2_keras: -32.7354 - val_rmse: 0.9458 - val_sae: 355.6269 - val_sse: 473.2441 - learning_rate: 0.0011\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0805 - loss: 0.1040 - mae: 0.2586 - mse: 0.1731 - pearson_correlation: -3.4816e-16 - r2_keras: -98.0128 - rmse: 0.8659 - sae: 2544.5342 - sse: 3071.2539\n","Epoch 34: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0770 - loss: 0.1019 - mae: 0.2566 - mse: 0.1667 - pearson_correlation: -2.8807e-16 - r2_keras: -79.4785 - rmse: 0.8459 - sae: 1854.9769 - sse: 2217.2356 - val_huber_loss: 0.1051 - val_loss: 0.1286 - val_mae: 0.2942 - val_mse: 0.2353 - val_pearson_correlation: -2.7845e-16 - val_r2_keras: -32.7561 - val_rmse: 0.9461 - val_sae: 355.7217 - val_sse: 473.5338 - learning_rate: 0.0011\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0805 - loss: 0.1039 - mae: 0.2585 - mse: 0.1730 - pearson_correlation: 1.6868e-16 - r2_keras: -98.0552 - rmse: 0.8661 - sae: 2544.9236 - sse: 3072.5688\n","Epoch 35: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0770 - loss: 0.1018 - mae: 0.2565 - mse: 0.1666 - pearson_correlation: 1.5829e-16 - r2_keras: -79.5094 - rmse: 0.8461 - sae: 1855.2424 - sse: 2218.1431 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2949 - val_mse: 0.2357 - val_pearson_correlation: -2.7841e-16 - val_r2_keras: -32.7590 - val_rmse: 0.9462 - val_sae: 355.7078 - val_sse: 473.5754 - learning_rate: 0.0011\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0805 - loss: 0.1039 - mae: 0.2585 - mse: 0.1729 - pearson_correlation: -5.9799e-16 - r2_keras: -98.0509 - rmse: 0.8661 - sae: 2545.0010 - sse: 3072.4338\n","Epoch 36: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0770 - loss: 0.1018 - mae: 0.2564 - mse: 0.1665 - pearson_correlation: -3.5179e-16 - r2_keras: -79.5131 - rmse: 0.8461 - sae: 1855.3229 - sse: 2218.1309 - val_huber_loss: 0.1053 - val_loss: 0.1288 - val_mae: 0.2954 - val_mse: 0.2357 - val_pearson_correlation: 1.1593e-17 - val_r2_keras: -32.7725 - val_rmse: 0.9464 - val_sae: 355.7472 - val_sse: 473.7644 - learning_rate: 0.0011\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0804 - loss: 0.1039 - mae: 0.2584 - mse: 0.1728 - pearson_correlation: 3.6019e-16 - r2_keras: -98.0840 - rmse: 0.8662 - sae: 2545.3206 - sse: 3073.4609\n","Epoch 37: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0769 - loss: 0.1017 - mae: 0.2563 - mse: 0.1664 - pearson_correlation: 3.9022e-16 - r2_keras: -79.5411 - rmse: 0.8463 - sae: 1855.5609 - sse: 2218.8848 - val_huber_loss: 0.1052 - val_loss: 0.1287 - val_mae: 0.2953 - val_mse: 0.2355 - val_pearson_correlation: 4.6336e-17 - val_r2_keras: -32.7890 - val_rmse: 0.9466 - val_sae: 355.8439 - val_sse: 473.9952 - learning_rate: 0.0011\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0804 - loss: 0.1038 - mae: 0.2583 - mse: 0.1727 - pearson_correlation: 4.7113e-17 - r2_keras: -98.1225 - rmse: 0.8664 - sae: 2545.6599 - sse: 3074.6560\n","Epoch 38: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0769 - loss: 0.1017 - mae: 0.2562 - mse: 0.1662 - pearson_correlation: -5.3776e-17 - r2_keras: -79.5635 - rmse: 0.8463 - sae: 1855.7675 - sse: 2219.6436 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2955 - val_mse: 0.2355 - val_pearson_correlation: -1.5062e-16 - val_r2_keras: -32.7843 - val_rmse: 0.9465 - val_sae: 355.8113 - val_sse: 473.9304 - learning_rate: 2.2935e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2583 - mse: 0.1726 - pearson_correlation: -1.3077e-16 - r2_keras: -98.1201 - rmse: 0.8664 - sae: 2545.6521 - sse: 3074.5830\n","Epoch 39: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0769 - loss: 0.1017 - mae: 0.2562 - mse: 0.1662 - pearson_correlation: -2.1922e-16 - r2_keras: -79.5622 - rmse: 0.8463 - sae: 1855.7609 - sse: 2219.5972 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2956 - val_mse: 0.2356 - val_pearson_correlation: -9.2684e-17 - val_r2_keras: -32.7859 - val_rmse: 0.9465 - val_sae: 355.8174 - val_sse: 473.9524 - learning_rate: 2.2935e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2583 - mse: 0.1726 - pearson_correlation: 1.3289e-17 - r2_keras: -98.1200 - rmse: 0.8664 - sae: 2545.6699 - sse: 3074.5781\n","Epoch 40: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0769 - loss: 0.1017 - mae: 0.2562 - mse: 0.1662 - pearson_correlation: 2.2700e-17 - r2_keras: -79.5631 - rmse: 0.8464 - sae: 1855.7777 - sse: 2219.6062 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2956 - val_mse: 0.2355 - val_pearson_correlation: 1.3900e-16 - val_r2_keras: -32.7899 - val_rmse: 0.9466 - val_sae: 355.8412 - val_sse: 474.0082 - learning_rate: 2.2935e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1726 - pearson_correlation: 8.0629e-17 - r2_keras: -98.1286 - rmse: 0.8664 - sae: 2545.7437 - sse: 3074.8467\n","Epoch 41: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0768 - loss: 0.1017 - mae: 0.2562 - mse: 0.1662 - pearson_correlation: 4.2042e-17 - r2_keras: -79.5694 - rmse: 0.8464 - sae: 1855.8301 - sse: 2219.7908 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2956 - val_mse: 0.2355 - val_pearson_correlation: 1.8531e-16 - val_r2_keras: -32.7927 - val_rmse: 0.9466 - val_sae: 355.8514 - val_sse: 474.0483 - learning_rate: 2.2935e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -2.8867e-16 - r2_keras: -98.1344 - rmse: 0.8665 - sae: 2545.7930 - sse: 3075.0242\n","Epoch 42: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2562 - mse: 0.1661 - pearson_correlation: -1.8021e-16 - r2_keras: -79.5740 - rmse: 0.8464 - sae: 1855.8647 - sse: 2219.9182 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -5.7907e-17 - val_r2_keras: -32.7932 - val_rmse: 0.9466 - val_sae: 355.8528 - val_sse: 474.0551 - learning_rate: 2.2935e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 1.1746e-16 - r2_keras: -98.1344 - rmse: 0.8665 - sae: 2545.8110 - sse: 3075.0254\n","Epoch 43: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2562 - mse: 0.1661 - pearson_correlation: 3.4129e-17 - r2_keras: -79.5740 - rmse: 0.8464 - sae: 1855.8750 - sse: 2219.9189 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.1581e-17 - val_r2_keras: -32.7940 - val_rmse: 0.9467 - val_sae: 355.8582 - val_sse: 474.0655 - learning_rate: 4.5870e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 3.9888e-16 - r2_keras: -98.1361 - rmse: 0.8665 - sae: 2545.8257 - sse: 3075.0789\n","Epoch 44: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 3.5428e-16 - r2_keras: -79.5752 - rmse: 0.8464 - sae: 1855.8855 - sse: 2219.9556 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -9.2644e-17 - val_r2_keras: -32.7947 - val_rmse: 0.9467 - val_sae: 355.8629 - val_sse: 474.0752 - learning_rate: 4.5870e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 1.9928e-16 - r2_keras: -98.1378 - rmse: 0.8665 - sae: 2545.8401 - sse: 3075.1318\n","Epoch 45: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 1.6586e-16 - r2_keras: -79.5764 - rmse: 0.8464 - sae: 1855.8958 - sse: 2219.9922 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -3.9373e-16 - val_r2_keras: -32.7952 - val_rmse: 0.9467 - val_sae: 355.8649 - val_sse: 474.0824 - learning_rate: 4.5870e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 3.1100e-17 - r2_keras: -98.1391 - rmse: 0.8665 - sae: 2545.8513 - sse: 3075.1719\n","Epoch 46: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -3.3557e-17 - r2_keras: -79.5775 - rmse: 0.8464 - sae: 1855.9042 - sse: 2220.0212 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 6.9479e-17 - val_r2_keras: -32.7957 - val_rmse: 0.9467 - val_sae: 355.8671 - val_sse: 474.0897 - learning_rate: 4.5870e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1038 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 5.3050e-16 - r2_keras: -98.1403 - rmse: 0.8665 - sae: 2545.8613 - sse: 3075.2078\n","Epoch 47: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 3.4568e-16 - r2_keras: -79.5784 - rmse: 0.8464 - sae: 1855.9113 - sse: 2220.0469 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 4.6319e-17 - val_r2_keras: -32.7960 - val_rmse: 0.9467 - val_sae: 355.8698 - val_sse: 474.0933 - learning_rate: 4.5870e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -1.1141e-16 - r2_keras: -98.1407 - rmse: 0.8665 - sae: 2545.8687 - sse: 3075.2219\n","Epoch 48: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -9.7694e-17 - r2_keras: -79.5786 - rmse: 0.8464 - sae: 1855.9155 - sse: 2220.0552 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 9.2637e-17 - val_r2_keras: -32.7960 - val_rmse: 0.9467 - val_sae: 355.8701 - val_sse: 474.0945 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -1.2530e-16 - r2_keras: -98.1411 - rmse: 0.8665 - sae: 2545.8716 - sse: 3075.2314\n","Epoch 49: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -9.3114e-17 - r2_keras: -79.5789 - rmse: 0.8464 - sae: 1855.9177 - sse: 2220.0620 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -3.4739e-17 - val_r2_keras: -32.7961 - val_rmse: 0.9467 - val_sae: 355.8705 - val_sse: 474.0958 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 5.5223e-16 - r2_keras: -98.1413 - rmse: 0.8665 - sae: 2545.8740 - sse: 3075.2397\n","Epoch 50: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 3.8518e-16 - r2_keras: -79.5791 - rmse: 0.8464 - sae: 1855.9196 - sse: 2220.0681 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 1.1580e-16 - val_r2_keras: -32.7962 - val_rmse: 0.9467 - val_sae: 355.8709 - val_sse: 474.0973 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -2.0984e-16 - r2_keras: -98.1416 - rmse: 0.8665 - sae: 2545.8762 - sse: 3075.2480\n","Epoch 51: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -1.1967e-16 - r2_keras: -79.5793 - rmse: 0.8464 - sae: 1855.9213 - sse: 2220.0742 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 3.1265e-16 - val_r2_keras: -32.7963 - val_rmse: 0.9467 - val_sae: 355.8715 - val_sse: 474.0988 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 4.4081e-17 - r2_keras: -98.1419 - rmse: 0.8665 - sae: 2545.8784 - sse: 3075.2563\n","Epoch 52: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 1.1880e-16 - r2_keras: -79.5795 - rmse: 0.8464 - sae: 1855.9227 - sse: 2220.0801 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.2737e-16 - val_r2_keras: -32.7964 - val_rmse: 0.9467 - val_sae: 355.8716 - val_sse: 474.0990 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -1.9384e-16 - r2_keras: -98.1418 - rmse: 0.8665 - sae: 2545.8792 - sse: 3075.2559\n","Epoch 53: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -5.7904e-17 - r2_keras: -79.5796 - rmse: 0.8464 - sae: 1855.9235 - sse: 2220.0803 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -9.2635e-17 - val_r2_keras: -32.7965 - val_rmse: 0.9467 - val_sae: 355.8725 - val_sse: 474.1010 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 8.1822e-17 - r2_keras: -98.1422 - rmse: 0.8665 - sae: 2545.8821 - sse: 3075.2668\n","Epoch 54: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 1.2055e-16 - r2_keras: -79.5798 - rmse: 0.8464 - sae: 1855.9255 - sse: 2220.0879 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -2.7790e-16 - val_r2_keras: -32.7966 - val_rmse: 0.9467 - val_sae: 355.8730 - val_sse: 474.1025 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -1.2349e-16 - r2_keras: -98.1424 - rmse: 0.8665 - sae: 2545.8843 - sse: 3075.2744\n","Epoch 55: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -1.2650e-16 - r2_keras: -79.5800 - rmse: 0.8464 - sae: 1855.9271 - sse: 2220.0933 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 1.9685e-16 - val_r2_keras: -32.7966 - val_rmse: 0.9467 - val_sae: 355.8730 - val_sse: 474.1027 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 5.1750e-16 - r2_keras: -98.1425 - rmse: 0.8665 - sae: 2545.8853 - sse: 3075.2751\n","Epoch 56: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 2.9177e-16 - r2_keras: -79.5801 - rmse: 0.8464 - sae: 1855.9280 - sse: 2220.0942 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 3.4738e-17 - val_r2_keras: -32.7967 - val_rmse: 0.9467 - val_sae: 355.8734 - val_sse: 474.1041 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -3.8857e-16 - r2_keras: -98.1427 - rmse: 0.8665 - sae: 2545.8877 - sse: 3075.2830\n","Epoch 57: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -2.7927e-16 - r2_keras: -79.5803 - rmse: 0.8464 - sae: 1855.9297 - sse: 2220.0999 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -2.5474e-16 - val_r2_keras: -32.7968 - val_rmse: 0.9467 - val_sae: 355.8740 - val_sse: 474.1048 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -3.7438e-16 - r2_keras: -98.1428 - rmse: 0.8665 - sae: 2545.8896 - sse: 3075.2861\n","Epoch 58: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -3.1133e-16 - r2_keras: -79.5804 - rmse: 0.8464 - sae: 1855.9312 - sse: 2220.1023 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 2.0843e-16 - val_r2_keras: -32.7969 - val_rmse: 0.9467 - val_sae: 355.8744 - val_sse: 474.1062 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 9.6615e-17 - r2_keras: -98.1431 - rmse: 0.8665 - sae: 2545.8916 - sse: 3075.2949\n","Epoch 59: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -1.1442e-16 - r2_keras: -79.5806 - rmse: 0.8464 - sae: 1855.9326 - sse: 2220.1086 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 6.9475e-17 - val_r2_keras: -32.7970 - val_rmse: 0.9467 - val_sae: 355.8748 - val_sse: 474.1077 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -8.8161e-17 - r2_keras: -98.1433 - rmse: 0.8665 - sae: 2545.8938 - sse: 3075.3018\n","Epoch 60: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -6.5161e-17 - r2_keras: -79.5808 - rmse: 0.8464 - sae: 1855.9342 - sse: 2220.1135 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -6.9475e-17 - val_r2_keras: -32.7970 - val_rmse: 0.9467 - val_sae: 355.8754 - val_sse: 474.1084 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 2.9769e-16 - r2_keras: -98.1434 - rmse: 0.8665 - sae: 2545.8950 - sse: 3075.3044\n","Epoch 61: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 2.9160e-16 - r2_keras: -79.5809 - rmse: 0.8464 - sae: 1855.9352 - sse: 2220.1155 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.7971 - val_rmse: 0.9467 - val_sae: 355.8757 - val_sse: 474.1097 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 1.9595e-16 - r2_keras: -98.1436 - rmse: 0.8665 - sae: 2545.8975 - sse: 3075.3120\n","Epoch 62: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 1.3223e-16 - r2_keras: -79.5811 - rmse: 0.8464 - sae: 1855.9369 - sse: 2220.1211 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.3895e-16 - val_r2_keras: -32.7971 - val_rmse: 0.9467 - val_sae: 355.8758 - val_sse: 474.1100 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -2.1617e-16 - r2_keras: -98.1437 - rmse: 0.8665 - sae: 2545.8984 - sse: 3075.3127\n","Epoch 63: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -7.6523e-17 - r2_keras: -79.5811 - rmse: 0.8464 - sae: 1855.9376 - sse: 2220.1221 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 1.3895e-16 - val_r2_keras: -32.7972 - val_rmse: 0.9467 - val_sae: 355.8762 - val_sse: 474.1114 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 2.5995e-16 - r2_keras: -98.1439 - rmse: 0.8665 - sae: 2545.9006 - sse: 3075.3208\n","Epoch 64: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 1.0411e-16 - r2_keras: -79.5813 - rmse: 0.8464 - sae: 1855.9392 - sse: 2220.1277 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 2.3158e-17 - val_r2_keras: -32.7973 - val_rmse: 0.9467 - val_sae: 355.8768 - val_sse: 474.1120 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -3.8343e-17 - r2_keras: -98.1440 - rmse: 0.8665 - sae: 2545.9019 - sse: 3075.3232\n","Epoch 65: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -2.8756e-17 - r2_keras: -79.5814 - rmse: 0.8464 - sae: 1855.9402 - sse: 2220.1296 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -3.4737e-17 - val_r2_keras: -32.7974 - val_rmse: 0.9467 - val_sae: 355.8771 - val_sse: 474.1135 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 2.6689e-16 - r2_keras: -98.1443 - rmse: 0.8665 - sae: 2545.9048 - sse: 3075.3323\n","Epoch 66: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 2.0880e-16 - r2_keras: -79.5816 - rmse: 0.8464 - sae: 1855.9424 - sse: 2220.1362 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.6210e-16 - val_r2_keras: -32.7975 - val_rmse: 0.9467 - val_sae: 355.8776 - val_sse: 474.1148 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 7.1554e-17 - r2_keras: -98.1445 - rmse: 0.8665 - sae: 2545.9067 - sse: 3075.3394\n","Epoch 67: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 1.1263e-16 - r2_keras: -79.5818 - rmse: 0.8464 - sae: 1855.9437 - sse: 2220.1414 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.7975 - val_rmse: 0.9467 - val_sae: 355.8777 - val_sse: 474.1151 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -5.9175e-17 - r2_keras: -98.1445 - rmse: 0.8665 - sae: 2545.9077 - sse: 3075.3398\n","Epoch 68: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -2.6677e-17 - r2_keras: -79.5819 - rmse: 0.8464 - sae: 1855.9446 - sse: 2220.1421 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 1.2737e-16 - val_r2_keras: -32.7976 - val_rmse: 0.9467 - val_sae: 355.8785 - val_sse: 474.1169 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -6.1288e-17 - r2_keras: -98.1449 - rmse: 0.8665 - sae: 2545.9106 - sse: 3075.3506\n","Epoch 69: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -3.6601e-17 - r2_keras: -79.5821 - rmse: 0.8464 - sae: 1855.9467 - sse: 2220.1494 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.3895e-16 - val_r2_keras: -32.7976 - val_rmse: 0.9467 - val_sae: 355.8786 - val_sse: 474.1171 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: -9.9933e-17 - r2_keras: -98.1449 - rmse: 0.8665 - sae: 2545.9116 - sse: 3075.3506\n","Epoch 70: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: -1.7659e-17 - r2_keras: -79.5822 - rmse: 0.8464 - sae: 1855.9474 - sse: 2220.1499 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.8526e-16 - val_r2_keras: -32.7977 - val_rmse: 0.9467 - val_sae: 355.8789 - val_sse: 474.1184 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 1.2988e-15 - r2_keras: -98.1452 - rmse: 0.8665 - sae: 2545.9136 - sse: 3075.3589\n","Epoch 71: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 7.2644e-16 - r2_keras: -79.5824 - rmse: 0.8464 - sae: 1855.9489 - sse: 2220.1560 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: -1.2737e-16 - val_r2_keras: -32.7979 - val_rmse: 0.9467 - val_sae: 355.8794 - val_sse: 474.1200 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0803 - loss: 0.1037 - mae: 0.2582 - mse: 0.1725 - pearson_correlation: 4.2932e-16 - r2_keras: -98.1454 - rmse: 0.8665 - sae: 2545.9155 - sse: 3075.3657\n","Epoch 72: val_loss did not improve from 0.12827\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0768 - loss: 0.1016 - mae: 0.2561 - mse: 0.1661 - pearson_correlation: 2.1756e-16 - r2_keras: -79.5826 - rmse: 0.8464 - sae: 1855.9503 - sse: 2220.1609 - val_huber_loss: 0.1053 - val_loss: 0.1287 - val_mae: 0.2957 - val_mse: 0.2355 - val_pearson_correlation: 5.7893e-17 - val_r2_keras: -32.7979 - val_rmse: 0.9467 - val_sae: 355.8799 - val_sse: 474.1206 - learning_rate: 1.0000e-05\n","| \u001b[35m3        \u001b[39m | \u001b[35m-0.1287  \u001b[39m | \u001b[35m0.02867  \u001b[39m | \u001b[35m18.59    \u001b[39m | \u001b[35m19.37    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - huber_loss: 1.2987 - loss: 1.3183 - mae: 1.7687 - mse: 3.8672 - pearson_correlation: -3.7786e-16 - r2_keras: -575.7235 - rmse: 2.0899 - sae: 7495.9785 - sse: 17889.2422\n","Epoch 1: val_loss improved from inf to 0.31272, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 516ms/step - huber_loss: 1.2374 - loss: 1.2810 - mae: 1.7216 - mse: 3.7856 - pearson_correlation: -2.1380e-16 - r2_keras: -466.8908 - rmse: 2.0382 - sae: 5416.8413 - sse: 12904.5459 - val_huber_loss: 0.2931 - val_loss: 0.3127 - val_mae: 0.5716 - val_mse: 0.8274 - val_pearson_correlation: 6.0344e-17 - val_r2_keras: -30.3698 - val_rmse: 0.9121 - val_sae: 318.3019 - val_sse: 440.0596 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.2939 - loss: 1.3135 - mae: 1.7637 - mse: 3.8481 - pearson_correlation: -1.8608e-16 - r2_keras: -573.1293 - rmse: 2.0851 - sae: 7477.8853 - sse: 17808.7734\n","Epoch 2: val_loss improved from 0.31272 to 0.29985, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 1.2329 - loss: 1.2763 - mae: 1.7168 - mse: 3.7670 - pearson_correlation: -7.0110e-17 - r2_keras: -464.7800 - rmse: 2.0336 - sae: 5403.7510 - sse: 12846.4258 - val_huber_loss: 0.2802 - val_loss: 0.2998 - val_mae: 0.5899 - val_mse: 0.7523 - val_pearson_correlation: 1.0255e-16 - val_r2_keras: -30.2801 - val_rmse: 0.9108 - val_sae: 344.4454 - val_sse: 438.8003 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 1.2902 - loss: 1.3098 - mae: 1.7599 - mse: 3.8336 - pearson_correlation: -1.4858e-16 - r2_keras: -571.1629 - rmse: 2.0816 - sae: 7464.1299 - sse: 17747.7773\n","Epoch 3: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 1.2294 - loss: 1.2728 - mae: 1.7131 - mse: 3.7528 - pearson_correlation: -9.4547e-17 - r2_keras: -463.1623 - rmse: 2.0300 - sae: 5393.7515 - sse: 12802.1641 - val_huber_loss: 0.2955 - val_loss: 0.3151 - val_mae: 0.6514 - val_mse: 0.7317 - val_pearson_correlation: -4.4537e-17 - val_r2_keras: -33.8766 - val_rmse: 0.9617 - val_sae: 389.5650 - val_sse: 489.2528 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2871 - loss: 1.3067 - mae: 1.7567 - mse: 3.8212 - pearson_correlation: -6.6922e-17 - r2_keras: -569.4874 - rmse: 2.0785 - sae: 7452.3896 - sse: 17695.8047\n","Epoch 4: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2264 - loss: 1.2697 - mae: 1.7100 - mse: 3.7407 - pearson_correlation: -6.8306e-17 - r2_keras: -461.7800 - rmse: 2.0270 - sae: 5385.2056 - sse: 12764.4033 - val_huber_loss: 0.3449 - val_loss: 0.3645 - val_mae: 0.7409 - val_mse: 0.7949 - val_pearson_correlation: 8.5525e-17 - val_r2_keras: -41.6997 - val_rmse: 1.0641 - val_sae: 449.9061 - val_sse: 598.9958 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2843 - loss: 1.3039 - mae: 1.7538 - mse: 3.8102 - pearson_correlation: -4.4138e-16 - r2_keras: -567.9968 - rmse: 2.0758 - sae: 7441.9375 - sse: 17649.5703\n","Epoch 5: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2237 - loss: 1.2670 - mae: 1.7072 - mse: 3.7299 - pearson_correlation: -3.6544e-16 - r2_keras: -460.5484 - rmse: 2.0242 - sae: 5377.5903 - sse: 12730.7900 - val_huber_loss: 0.4323 - val_loss: 0.4519 - val_mae: 0.8518 - val_mse: 0.9528 - val_pearson_correlation: -1.9038e-16 - val_r2_keras: -53.3815 - val_rmse: 1.2009 - val_sae: 520.8381 - val_sse: 762.8702 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.2818 - loss: 1.3014 - mae: 1.7512 - mse: 3.8002 - pearson_correlation: 2.2690e-16 - r2_keras: -566.6372 - rmse: 2.0733 - sae: 7432.3862 - sse: 17607.3965\n","Epoch 6: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2213 - loss: 1.2646 - mae: 1.7047 - mse: 3.7200 - pearson_correlation: 1.1732e-16 - r2_keras: -459.4243 - rmse: 2.0217 - sae: 5370.6299 - sse: 12700.1201 - val_huber_loss: 0.5427 - val_loss: 0.5623 - val_mae: 0.9640 - val_mse: 1.1864 - val_pearson_correlation: 1.6865e-16 - val_r2_keras: -68.0585 - val_rmse: 1.3533 - val_sae: 595.2578 - val_sse: 968.7606 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2794 - loss: 1.2990 - mae: 1.7487 - mse: 3.7909 - pearson_correlation: -3.2190e-16 - r2_keras: -565.3774 - rmse: 2.0710 - sae: 7423.5234 - sse: 17568.3203\n","Epoch 7: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2190 - loss: 1.2623 - mae: 1.7023 - mse: 3.7109 - pearson_correlation: -2.7013e-16 - r2_keras: -458.3823 - rmse: 2.0194 - sae: 5364.1704 - sse: 12671.6992 - val_huber_loss: 0.6644 - val_loss: 0.6840 - val_mae: 1.0923 - val_mse: 1.4881 - val_pearson_correlation: 4.7959e-17 - val_r2_keras: -85.2467 - val_rmse: 1.5123 - val_sae: 672.1866 - val_sse: 1209.8776 - learning_rate: 1.0000e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2772 - loss: 1.2968 - mae: 1.7465 - mse: 3.7822 - pearson_correlation: -3.0017e-16 - r2_keras: -564.1974 - rmse: 2.0689 - sae: 7415.2080 - sse: 17531.7188\n","Epoch 8: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2172 - loss: 1.2603 - mae: 1.7002 - mse: 3.7029 - pearson_correlation: -1.5928e-16 - r2_keras: -457.4756 - rmse: 2.0175 - sae: 5358.2925 - sse: 12645.8896 - val_huber_loss: 0.7845 - val_loss: 0.8041 - val_mae: 1.2203 - val_mse: 1.8338 - val_pearson_correlation: 2.8716e-16 - val_r2_keras: -103.3746 - val_rmse: 1.6637 - val_sae: 745.2805 - val_sse: 1464.1781 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2768 - loss: 1.2964 - mae: 1.7460 - mse: 3.7806 - pearson_correlation: 1.6598e-16 - r2_keras: -563.9745 - rmse: 2.0685 - sae: 7413.6362 - sse: 17524.8047\n","Epoch 9: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2168 - loss: 1.2599 - mae: 1.6998 - mse: 3.7013 - pearson_correlation: 2.0368e-16 - r2_keras: -457.2911 - rmse: 2.0171 - sae: 5357.1470 - sse: 12640.8604 - val_huber_loss: 0.8936 - val_loss: 0.9132 - val_mae: 1.3360 - val_mse: 2.1865 - val_pearson_correlation: -3.0682e-17 - val_r2_keras: -120.4194 - val_rmse: 1.7944 - val_sae: 808.7857 - val_sse: 1703.2839 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.2764 - loss: 1.2960 - mae: 1.7456 - mse: 3.7790 - pearson_correlation: -3.6536e-16 - r2_keras: -563.7628 - rmse: 2.0681 - sae: 7412.1416 - sse: 17518.2344\n","Epoch 10: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2164 - loss: 1.2595 - mae: 1.6994 - mse: 3.6998 - pearson_correlation: -2.7081e-16 - r2_keras: -457.1159 - rmse: 2.0167 - sae: 5356.0571 - sse: 12636.0801 - val_huber_loss: 0.9858 - val_loss: 1.0054 - val_mae: 1.4314 - val_mse: 2.5129 - val_pearson_correlation: -4.2838e-17 - val_r2_keras: -135.3582 - val_rmse: 1.9016 - val_sae: 860.7982 - val_sse: 1912.8473 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2760 - loss: 1.2956 - mae: 1.7452 - mse: 3.7775 - pearson_correlation: 3.0741e-16 - r2_keras: -563.5602 - rmse: 2.0677 - sae: 7410.7119 - sse: 17511.9531\n","Epoch 11: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 1.2160 - loss: 1.2591 - mae: 1.6990 - mse: 3.6983 - pearson_correlation: 2.9574e-16 - r2_keras: -456.9483 - rmse: 2.0163 - sae: 5355.0146 - sse: 12631.5107 - val_huber_loss: 1.0575 - val_loss: 1.0771 - val_mae: 1.5063 - val_mse: 2.7864 - val_pearson_correlation: -1.8997e-16 - val_r2_keras: -147.3476 - val_rmse: 1.9834 - val_sae: 900.0964 - val_sse: 2081.0359 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2757 - loss: 1.2953 - mae: 1.7448 - mse: 3.7761 - pearson_correlation: 5.0049e-16 - r2_keras: -563.3666 - rmse: 2.0673 - sae: 7409.3462 - sse: 17505.9453\n","Epoch 12: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 1.2157 - loss: 1.2587 - mae: 1.6987 - mse: 3.6969 - pearson_correlation: 3.2798e-16 - r2_keras: -456.7881 - rmse: 2.0159 - sae: 5354.0190 - sse: 12627.1406 - val_huber_loss: 1.1118 - val_loss: 1.1314 - val_mae: 1.5634 - val_mse: 3.0036 - val_pearson_correlation: -1.1783e-16 - val_r2_keras: -156.5595 - val_rmse: 2.0441 - val_sae: 928.8529 - val_sse: 2210.2615 - learning_rate: 2.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2753 - loss: 1.2949 - mae: 1.7445 - mse: 3.7747 - pearson_correlation: 3.7295e-16 - r2_keras: -563.1828 - rmse: 2.0670 - sae: 7408.0469 - sse: 17500.2441\n","Epoch 13: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2154 - loss: 1.2584 - mae: 1.6983 - mse: 3.6956 - pearson_correlation: 3.1335e-16 - r2_keras: -456.6425 - rmse: 2.0156 - sae: 5353.0889 - sse: 12623.0693 - val_huber_loss: 1.1511 - val_loss: 1.1707 - val_mae: 1.6058 - val_mse: 3.1669 - val_pearson_correlation: -1.0220e-16 - val_r2_keras: -163.2751 - val_rmse: 2.0872 - val_sae: 949.0288 - val_sse: 2304.4685 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 1.2752 - loss: 1.2948 - mae: 1.7443 - mse: 3.7741 - pearson_correlation: -6.5745e-17 - r2_keras: -563.0939 - rmse: 2.0668 - sae: 7407.4189 - sse: 17497.4883\n","Epoch 14: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 1.2152 - loss: 1.2583 - mae: 1.6982 - mse: 3.6950 - pearson_correlation: -1.2034e-17 - r2_keras: -456.5688 - rmse: 2.0155 - sae: 5352.6304 - sse: 12621.0625 - val_huber_loss: 1.1786 - val_loss: 1.1982 - val_mae: 1.6353 - val_mse: 3.2838 - val_pearson_correlation: -7.5401e-17 - val_r2_keras: -167.9625 - val_rmse: 2.1167 - val_sae: 962.7039 - val_sse: 2370.2249 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2750 - loss: 1.2946 - mae: 1.7442 - mse: 3.7734 - pearson_correlation: 6.8316e-17 - r2_keras: -563.0079 - rmse: 2.0667 - sae: 7406.8115 - sse: 17494.8203\n","Epoch 15: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 1.2150 - loss: 1.2581 - mae: 1.6980 - mse: 3.6943 - pearson_correlation: 7.8478e-17 - r2_keras: -456.4975 - rmse: 2.0153 - sae: 5352.1870 - sse: 12619.1201 - val_huber_loss: 1.1972 - val_loss: 1.2168 - val_mae: 1.6552 - val_mse: 3.3646 - val_pearson_correlation: 9.9458e-17 - val_r2_keras: -171.1322 - val_rmse: 2.1365 - val_sae: 971.7694 - val_sse: 2414.6890 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2748 - loss: 1.2944 - mae: 1.7440 - mse: 3.7728 - pearson_correlation: 1.1387e-16 - r2_keras: -562.9245 - rmse: 2.0665 - sae: 7406.2217 - sse: 17492.2324\n","Epoch 16: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 1.2149 - loss: 1.2580 - mae: 1.6979 - mse: 3.6937 - pearson_correlation: 4.4112e-17 - r2_keras: -456.4283 - rmse: 2.0151 - sae: 5351.7568 - sse: 12617.2354 - val_huber_loss: 1.2095 - val_loss: 1.2292 - val_mae: 1.6683 - val_mse: 3.4187 - val_pearson_correlation: 9.8769e-17 - val_r2_keras: -173.2209 - val_rmse: 2.1494 - val_sae: 977.6935 - val_sse: 2443.9893 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 1.2747 - loss: 1.2943 - mae: 1.7438 - mse: 3.7722 - pearson_correlation: 4.4300e-16 - r2_keras: -562.8434 - rmse: 2.0664 - sae: 7405.6489 - sse: 17489.7188\n","Epoch 17: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 1.2147 - loss: 1.2578 - mae: 1.6977 - mse: 3.6931 - pearson_correlation: 2.5672e-16 - r2_keras: -456.3611 - rmse: 2.0150 - sae: 5351.3389 - sse: 12615.4053 - val_huber_loss: 1.2176 - val_loss: 1.2372 - val_mae: 1.6769 - val_mse: 3.4545 - val_pearson_correlation: -1.2291e-17 - val_r2_keras: -174.5849 - val_rmse: 2.1578 - val_sae: 981.5268 - val_sse: 2463.1235 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 1.2745 - loss: 1.2941 - mae: 1.7437 - mse: 3.7716 - pearson_correlation: 1.7837e-16 - r2_keras: -562.7645 - rmse: 2.0662 - sae: 7405.0903 - sse: 17487.2695\n","Epoch 18: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 1.2146 - loss: 1.2577 - mae: 1.6976 - mse: 3.6926 - pearson_correlation: 1.1891e-16 - r2_keras: -456.2957 - rmse: 2.0149 - sae: 5350.9312 - sse: 12613.6221 - val_huber_loss: 1.2228 - val_loss: 1.2424 - val_mae: 1.6824 - val_mse: 3.4777 - val_pearson_correlation: -3.3090e-16 - val_r2_keras: -175.4642 - val_rmse: 2.1632 - val_sae: 983.9841 - val_sse: 2475.4592 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2744 - loss: 1.2940 - mae: 1.7435 - mse: 3.7711 - pearson_correlation: 3.2212e-16 - r2_keras: -562.6876 - rmse: 2.0661 - sae: 7404.5459 - sse: 17484.8828\n","Epoch 19: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 1.2145 - loss: 1.2575 - mae: 1.6974 - mse: 3.6920 - pearson_correlation: 1.4317e-16 - r2_keras: -456.2319 - rmse: 2.0147 - sae: 5350.5337 - sse: 12611.8838 - val_huber_loss: 1.2262 - val_loss: 1.2458 - val_mae: 1.6859 - val_mse: 3.4926 - val_pearson_correlation: 1.9574e-16 - val_r2_keras: -176.0245 - val_rmse: 2.1666 - val_sae: 985.5422 - val_sse: 2483.3191 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2743 - loss: 1.2939 - mae: 1.7434 - mse: 3.7705 - pearson_correlation: 1.4727e-16 - r2_keras: -562.6125 - rmse: 2.0660 - sae: 7404.0146 - sse: 17482.5566\n","Epoch 20: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2143 - loss: 1.2574 - mae: 1.6973 - mse: 3.6914 - pearson_correlation: 1.0614e-16 - r2_keras: -456.1697 - rmse: 2.0146 - sae: 5350.1460 - sse: 12610.1904 - val_huber_loss: 1.2283 - val_loss: 1.2479 - val_mae: 1.6882 - val_mse: 3.5021 - val_pearson_correlation: 1.2220e-17 - val_r2_keras: -176.3770 - val_rmse: 2.1688 - val_sae: 986.5191 - val_sse: 2488.2644 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.2741 - loss: 1.2937 - mae: 1.7432 - mse: 3.7700 - pearson_correlation: 6.6712e-16 - r2_keras: -562.5391 - rmse: 2.0658 - sae: 7403.4951 - sse: 17480.2793\n","Epoch 21: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2142 - loss: 1.2572 - mae: 1.6971 - mse: 3.6909 - pearson_correlation: 4.5270e-16 - r2_keras: -456.1088 - rmse: 2.0144 - sae: 5349.7671 - sse: 12608.5322 - val_huber_loss: 1.2296 - val_loss: 1.2492 - val_mae: 1.6896 - val_mse: 3.5079 - val_pearson_correlation: -1.9537e-16 - val_r2_keras: -176.5950 - val_rmse: 2.1701 - val_sae: 987.1215 - val_sse: 2491.3225 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2740 - loss: 1.2936 - mae: 1.7431 - mse: 3.7694 - pearson_correlation: -8.7928e-17 - r2_keras: -562.4673 - rmse: 2.0657 - sae: 7402.9868 - sse: 17478.0508\n","Epoch 22: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2141 - loss: 1.2571 - mae: 1.6970 - mse: 3.6904 - pearson_correlation: -1.7710e-17 - r2_keras: -456.0493 - rmse: 2.0143 - sae: 5349.3960 - sse: 12606.9102 - val_huber_loss: 1.2304 - val_loss: 1.2500 - val_mae: 1.6904 - val_mse: 3.5115 - val_pearson_correlation: -2.4412e-17 - val_r2_keras: -176.7265 - val_rmse: 2.1709 - val_sae: 987.4835 - val_sse: 2493.1670 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2738 - loss: 1.2935 - mae: 1.7430 - mse: 3.7689 - pearson_correlation: 2.6188e-16 - r2_keras: -562.3970 - rmse: 2.0656 - sae: 7402.4883 - sse: 17475.8711\n","Epoch 23: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2139 - loss: 1.2570 - mae: 1.6969 - mse: 3.6899 - pearson_correlation: 2.1209e-16 - r2_keras: -455.9910 - rmse: 2.0142 - sae: 5349.0322 - sse: 12605.3232 - val_huber_loss: 1.2308 - val_loss: 1.2504 - val_mae: 1.6909 - val_mse: 3.5136 - val_pearson_correlation: -1.7084e-16 - val_r2_keras: -176.8026 - val_rmse: 2.1714 - val_sae: 987.6928 - val_sse: 2494.2341 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2737 - loss: 1.2933 - mae: 1.7428 - mse: 3.7684 - pearson_correlation: -4.3649e-16 - r2_keras: -562.3281 - rmse: 2.0654 - sae: 7402.0010 - sse: 17473.7324\n","Epoch 24: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2138 - loss: 1.2569 - mae: 1.6967 - mse: 3.6894 - pearson_correlation: -1.9780e-16 - r2_keras: -455.9338 - rmse: 2.0140 - sae: 5348.6768 - sse: 12603.7666 - val_huber_loss: 1.2311 - val_loss: 1.2507 - val_mae: 1.6912 - val_mse: 3.5148 - val_pearson_correlation: -2.8063e-16 - val_r2_keras: -176.8430 - val_rmse: 2.1717 - val_sae: 987.8030 - val_sse: 2494.8015 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 1.2736 - loss: 1.2932 - mae: 1.7427 - mse: 3.7679 - pearson_correlation: -1.6723e-16 - r2_keras: -562.2605 - rmse: 2.0653 - sae: 7401.5234 - sse: 17471.6367\n","Epoch 25: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 1.2137 - loss: 1.2567 - mae: 1.6966 - mse: 3.6889 - pearson_correlation: -1.1035e-16 - r2_keras: -455.8778 - rmse: 2.0139 - sae: 5348.3281 - sse: 12602.2402 - val_huber_loss: 1.2312 - val_loss: 1.2508 - val_mae: 1.6913 - val_mse: 3.5154 - val_pearson_correlation: 2.4401e-17 - val_r2_keras: -176.8609 - val_rmse: 2.1718 - val_sae: 987.8508 - val_sse: 2495.0527 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2735 - loss: 1.2931 - mae: 1.7426 - mse: 3.7674 - pearson_correlation: 1.8072e-16 - r2_keras: -562.1942 - rmse: 2.0652 - sae: 7401.0537 - sse: 17469.5781\n","Epoch 26: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 1.2136 - loss: 1.2566 - mae: 1.6965 - mse: 3.6884 - pearson_correlation: 1.2957e-16 - r2_keras: -455.8228 - rmse: 2.0138 - sae: 5347.9854 - sse: 12600.7412 - val_huber_loss: 1.2312 - val_loss: 1.2508 - val_mae: 1.6914 - val_mse: 3.5155 - val_pearson_correlation: 1.0980e-16 - val_r2_keras: -176.8645 - val_rmse: 2.1718 - val_sae: 987.8588 - val_sse: 2495.1023 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 1.2733 - loss: 1.2930 - mae: 1.7424 - mse: 3.7669 - pearson_correlation: -3.9100e-16 - r2_keras: -562.1290 - rmse: 2.0651 - sae: 7400.5938 - sse: 17467.5586\n","Epoch 27: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2134 - loss: 1.2565 - mae: 1.6964 - mse: 3.6879 - pearson_correlation: -2.5839e-16 - r2_keras: -455.7688 - rmse: 2.0137 - sae: 5347.6494 - sse: 12599.2705 - val_huber_loss: 1.2312 - val_loss: 1.2508 - val_mae: 1.6914 - val_mse: 3.5155 - val_pearson_correlation: 7.3204e-17 - val_r2_keras: -176.8589 - val_rmse: 2.1717 - val_sae: 987.8416 - val_sse: 2495.0244 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 1.2732 - loss: 1.2928 - mae: 1.7423 - mse: 3.7665 - pearson_correlation: 1.7175e-16 - r2_keras: -562.0650 - rmse: 2.0650 - sae: 7400.1406 - sse: 17465.5723\n","Epoch 28: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2133 - loss: 1.2564 - mae: 1.6962 - mse: 3.6875 - pearson_correlation: 1.3383e-16 - r2_keras: -455.7158 - rmse: 2.0136 - sae: 5347.3188 - sse: 12597.8252 - val_huber_loss: 1.2312 - val_loss: 1.2508 - val_mae: 1.6913 - val_mse: 3.5152 - val_pearson_correlation: -1.3421e-16 - val_r2_keras: -176.8477 - val_rmse: 2.1717 - val_sae: 987.8088 - val_sse: 2494.8672 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2731 - loss: 1.2927 - mae: 1.7422 - mse: 3.7660 - pearson_correlation: -3.1784e-17 - r2_keras: -562.0020 - rmse: 2.0648 - sae: 7399.6953 - sse: 17463.6172\n","Epoch 29: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2132 - loss: 1.2563 - mae: 1.6961 - mse: 3.6870 - pearson_correlation: -9.1680e-17 - r2_keras: -455.6635 - rmse: 2.0134 - sae: 5346.9937 - sse: 12596.4014 - val_huber_loss: 1.2311 - val_loss: 1.2507 - val_mae: 1.6912 - val_mse: 3.5149 - val_pearson_correlation: 2.4403e-17 - val_r2_keras: -176.8329 - val_rmse: 2.1716 - val_sae: 987.7659 - val_sse: 2494.6597 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2730 - loss: 1.2926 - mae: 1.7421 - mse: 3.7655 - pearson_correlation: -3.1658e-16 - r2_keras: -561.9400 - rmse: 2.0647 - sae: 7399.2568 - sse: 17461.6953\n","Epoch 30: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2131 - loss: 1.2561 - mae: 1.6960 - mse: 3.6866 - pearson_correlation: -2.7700e-16 - r2_keras: -455.6122 - rmse: 2.0133 - sae: 5346.6733 - sse: 12595.0029 - val_huber_loss: 1.2310 - val_loss: 1.2506 - val_mae: 1.6911 - val_mse: 3.5145 - val_pearson_correlation: 3.6607e-17 - val_r2_keras: -176.8161 - val_rmse: 2.1715 - val_sae: 987.7176 - val_sse: 2494.4231 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2729 - loss: 1.2925 - mae: 1.7420 - mse: 3.7651 - pearson_correlation: -3.2238e-16 - r2_keras: -561.8790 - rmse: 2.0646 - sae: 7398.8262 - sse: 17459.8027\n","Epoch 31: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2130 - loss: 1.2560 - mae: 1.6959 - mse: 3.6861 - pearson_correlation: -2.0127e-16 - r2_keras: -455.5616 - rmse: 2.0132 - sae: 5346.3594 - sse: 12593.6250 - val_huber_loss: 1.2309 - val_loss: 1.2505 - val_mae: 1.6911 - val_mse: 3.5141 - val_pearson_correlation: -3.0507e-16 - val_r2_keras: -176.7979 - val_rmse: 2.1714 - val_sae: 987.6653 - val_sse: 2494.1677 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2728 - loss: 1.2924 - mae: 1.7418 - mse: 3.7647 - pearson_correlation: 2.5689e-16 - r2_keras: -561.8188 - rmse: 2.0645 - sae: 7398.4004 - sse: 17457.9375\n","Epoch 32: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2129 - loss: 1.2559 - mae: 1.6958 - mse: 3.6857 - pearson_correlation: 1.6216e-16 - r2_keras: -455.5117 - rmse: 2.0131 - sae: 5346.0483 - sse: 12592.2676 - val_huber_loss: 1.2308 - val_loss: 1.2504 - val_mae: 1.6910 - val_mse: 3.5137 - val_pearson_correlation: -2.1967e-16 - val_r2_keras: -176.7790 - val_rmse: 2.1713 - val_sae: 987.6115 - val_sse: 2493.9031 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2727 - loss: 1.2923 - mae: 1.7417 - mse: 3.7642 - pearson_correlation: 4.8266e-16 - r2_keras: -561.7598 - rmse: 2.0644 - sae: 7397.9824 - sse: 17456.1035\n","Epoch 33: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 1.2128 - loss: 1.2558 - mae: 1.6957 - mse: 3.6852 - pearson_correlation: 3.1040e-16 - r2_keras: -455.4628 - rmse: 2.0130 - sae: 5345.7437 - sse: 12590.9316 - val_huber_loss: 1.2307 - val_loss: 1.2503 - val_mae: 1.6909 - val_mse: 3.5133 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -176.7598 - val_rmse: 2.1711 - val_sae: 987.5566 - val_sse: 2493.6335 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.2725 - loss: 1.2921 - mae: 1.7416 - mse: 3.7638 - pearson_correlation: 1.9687e-16 - r2_keras: -561.7014 - rmse: 2.0643 - sae: 7397.5693 - sse: 17454.2930\n","Epoch 34: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2127 - loss: 1.2557 - mae: 1.6955 - mse: 3.6848 - pearson_correlation: 1.8129e-16 - r2_keras: -455.4144 - rmse: 2.0129 - sae: 5345.4419 - sse: 12589.6143 - val_huber_loss: 1.2306 - val_loss: 1.2502 - val_mae: 1.6907 - val_mse: 3.5128 - val_pearson_correlation: 1.2205e-17 - val_r2_keras: -176.7404 - val_rmse: 2.1710 - val_sae: 987.5015 - val_sse: 2493.3621 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2724 - loss: 1.2920 - mae: 1.7415 - mse: 3.7634 - pearson_correlation: 1.5737e-16 - r2_keras: -561.6437 - rmse: 2.0642 - sae: 7397.1621 - sse: 17452.5039\n","Epoch 35: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2126 - loss: 1.2556 - mae: 1.6954 - mse: 3.6844 - pearson_correlation: 1.8908e-16 - r2_keras: -455.3666 - rmse: 2.0128 - sae: 5345.1450 - sse: 12588.3115 - val_huber_loss: 1.2305 - val_loss: 1.2501 - val_mae: 1.6906 - val_mse: 3.5124 - val_pearson_correlation: -1.8309e-16 - val_r2_keras: -176.7211 - val_rmse: 2.1709 - val_sae: 987.4465 - val_sse: 2493.0913 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2723 - loss: 1.2919 - mae: 1.7414 - mse: 3.7629 - pearson_correlation: -4.1787e-16 - r2_keras: -561.5869 - rmse: 2.0641 - sae: 7396.7607 - sse: 17450.7422\n","Epoch 36: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 1.2125 - loss: 1.2555 - mae: 1.6953 - mse: 3.6840 - pearson_correlation: -3.3204e-16 - r2_keras: -455.3195 - rmse: 2.0127 - sae: 5344.8521 - sse: 12587.0293 - val_huber_loss: 1.2304 - val_loss: 1.2500 - val_mae: 1.6905 - val_mse: 3.5119 - val_pearson_correlation: -2.4414e-17 - val_r2_keras: -176.7019 - val_rmse: 2.1708 - val_sae: 987.3917 - val_sse: 2492.8210 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2722 - loss: 1.2918 - mae: 1.7413 - mse: 3.7625 - pearson_correlation: 3.1639e-16 - r2_keras: -561.5309 - rmse: 2.0640 - sae: 7396.3643 - sse: 17449.0039\n","Epoch 37: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 1.2124 - loss: 1.2554 - mae: 1.6952 - mse: 3.6836 - pearson_correlation: 1.6315e-16 - r2_keras: -455.2731 - rmse: 2.0126 - sae: 5344.5625 - sse: 12585.7646 - val_huber_loss: 1.2303 - val_loss: 1.2499 - val_mae: 1.6904 - val_mse: 3.5115 - val_pearson_correlation: 2.1974e-16 - val_r2_keras: -176.6828 - val_rmse: 2.1707 - val_sae: 987.3375 - val_sse: 2492.5535 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 1.2721 - loss: 1.2917 - mae: 1.7412 - mse: 3.7621 - pearson_correlation: -3.0002e-16 - r2_keras: -561.4755 - rmse: 2.0639 - sae: 7395.9722 - sse: 17447.2852\n","Epoch 38: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 1.2123 - loss: 1.2553 - mae: 1.6951 - mse: 3.6832 - pearson_correlation: -1.0673e-16 - r2_keras: -455.2272 - rmse: 2.0125 - sae: 5344.2764 - sse: 12584.5127 - val_huber_loss: 1.2302 - val_loss: 1.2498 - val_mae: 1.6903 - val_mse: 3.5110 - val_pearson_correlation: -9.7666e-17 - val_r2_keras: -176.6638 - val_rmse: 2.1706 - val_sae: 987.2834 - val_sse: 2492.2871 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 1.2720 - loss: 1.2916 - mae: 1.7411 - mse: 3.7617 - pearson_correlation: 2.4575e-16 - r2_keras: -561.4208 - rmse: 2.0638 - sae: 7395.5859 - sse: 17445.5918\n","Epoch 39: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 1.2122 - loss: 1.2552 - mae: 1.6950 - mse: 3.6828 - pearson_correlation: 1.5701e-16 - r2_keras: -455.1819 - rmse: 2.0124 - sae: 5343.9946 - sse: 12583.2803 - val_huber_loss: 1.2301 - val_loss: 1.2497 - val_mae: 1.6902 - val_mse: 3.5106 - val_pearson_correlation: 1.4651e-16 - val_r2_keras: -176.6451 - val_rmse: 2.1704 - val_sae: 987.2300 - val_sse: 2492.0244 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2719 - loss: 1.2915 - mae: 1.7410 - mse: 3.7613 - pearson_correlation: 1.2433e-16 - r2_keras: -561.3668 - rmse: 2.0637 - sae: 7395.2036 - sse: 17443.9141\n","Epoch 40: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2121 - loss: 1.2551 - mae: 1.6949 - mse: 3.6824 - pearson_correlation: 1.4432e-16 - r2_keras: -455.1371 - rmse: 2.0123 - sae: 5343.7153 - sse: 12582.0596 - val_huber_loss: 1.2300 - val_loss: 1.2496 - val_mae: 1.6901 - val_mse: 3.5102 - val_pearson_correlation: 2.3199e-16 - val_r2_keras: -176.6265 - val_rmse: 2.1703 - val_sae: 987.1772 - val_sse: 2491.7644 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.2718 - loss: 1.2914 - mae: 1.7409 - mse: 3.7609 - pearson_correlation: -2.8754e-16 - r2_keras: -561.3135 - rmse: 2.0636 - sae: 7394.8262 - sse: 17442.2617\n","Epoch 41: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2120 - loss: 1.2550 - mae: 1.6948 - mse: 3.6820 - pearson_correlation: -2.2355e-16 - r2_keras: -455.0930 - rmse: 2.0122 - sae: 5343.4399 - sse: 12580.8564 - val_huber_loss: 1.2299 - val_loss: 1.2495 - val_mae: 1.6900 - val_mse: 3.5097 - val_pearson_correlation: 2.6863e-16 - val_r2_keras: -176.6081 - val_rmse: 2.1702 - val_sae: 987.1249 - val_sse: 2491.5061 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2717 - loss: 1.2913 - mae: 1.7408 - mse: 3.7605 - pearson_correlation: 2.6442e-16 - r2_keras: -561.2607 - rmse: 2.0635 - sae: 7394.4531 - sse: 17440.6230\n","Epoch 42: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 1.2119 - loss: 1.2549 - mae: 1.6947 - mse: 3.6816 - pearson_correlation: 8.7528e-17 - r2_keras: -455.0492 - rmse: 2.0121 - sae: 5343.1675 - sse: 12579.6631 - val_huber_loss: 1.2298 - val_loss: 1.2494 - val_mae: 1.6899 - val_mse: 3.5093 - val_pearson_correlation: 2.4422e-17 - val_r2_keras: -176.5899 - val_rmse: 2.1701 - val_sae: 987.0731 - val_sse: 2491.2510 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.2716 - loss: 1.2912 - mae: 1.7407 - mse: 3.7601 - pearson_correlation: -3.8622e-16 - r2_keras: -561.2085 - rmse: 2.0634 - sae: 7394.0830 - sse: 17439.0039\n","Epoch 43: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2118 - loss: 1.2548 - mae: 1.6946 - mse: 3.6812 - pearson_correlation: -2.7910e-16 - r2_keras: -455.0060 - rmse: 2.0120 - sae: 5342.8975 - sse: 12578.4854 - val_huber_loss: 1.2297 - val_loss: 1.2493 - val_mae: 1.6898 - val_mse: 3.5089 - val_pearson_correlation: 3.6636e-17 - val_r2_keras: -176.5719 - val_rmse: 2.1700 - val_sae: 987.0219 - val_sse: 2490.9983 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 1.2715 - loss: 1.2911 - mae: 1.7406 - mse: 3.7598 - pearson_correlation: -2.4549e-16 - r2_keras: -561.1569 - rmse: 2.0633 - sae: 7393.7183 - sse: 17437.4023\n","Epoch 44: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 1.2117 - loss: 1.2547 - mae: 1.6945 - mse: 3.6809 - pearson_correlation: -2.5357e-16 - r2_keras: -454.9632 - rmse: 2.0119 - sae: 5342.6313 - sse: 12577.3193 - val_huber_loss: 1.2296 - val_loss: 1.2492 - val_mae: 1.6897 - val_mse: 3.5085 - val_pearson_correlation: -1.2213e-16 - val_r2_keras: -176.5541 - val_rmse: 2.1699 - val_sae: 986.9711 - val_sse: 2490.7488 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 1.2714 - loss: 1.2910 - mae: 1.7405 - mse: 3.7594 - pearson_correlation: 2.0759e-16 - r2_keras: -561.1058 - rmse: 2.0632 - sae: 7393.3564 - sse: 17435.8184\n","Epoch 45: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2116 - loss: 1.2546 - mae: 1.6944 - mse: 3.6805 - pearson_correlation: 1.7936e-16 - r2_keras: -454.9209 - rmse: 2.0118 - sae: 5342.3672 - sse: 12576.1670 - val_huber_loss: 1.2295 - val_loss: 1.2491 - val_mae: 1.6897 - val_mse: 3.5081 - val_pearson_correlation: 3.6640e-17 - val_r2_keras: -176.5366 - val_rmse: 2.1698 - val_sae: 986.9210 - val_sse: 2490.5022 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2713 - loss: 1.2909 - mae: 1.7404 - mse: 3.7590 - pearson_correlation: -1.1537e-16 - r2_keras: -561.0551 - rmse: 2.0631 - sae: 7392.9980 - sse: 17434.2461\n","Epoch 46: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2115 - loss: 1.2545 - mae: 1.6943 - mse: 3.6801 - pearson_correlation: -3.3662e-17 - r2_keras: -454.8789 - rmse: 2.0117 - sae: 5342.1060 - sse: 12575.0225 - val_huber_loss: 1.2294 - val_loss: 1.2490 - val_mae: 1.6896 - val_mse: 3.5077 - val_pearson_correlation: 1.0993e-16 - val_r2_keras: -176.5191 - val_rmse: 2.1697 - val_sae: 986.8713 - val_sse: 2490.2571 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2712 - loss: 1.2908 - mae: 1.7403 - mse: 3.7586 - pearson_correlation: -3.5448e-16 - r2_keras: -561.0053 - rmse: 2.0630 - sae: 7392.6460 - sse: 17432.7012\n","Epoch 47: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2114 - loss: 1.2544 - mae: 1.6942 - mse: 3.6798 - pearson_correlation: -2.9323e-16 - r2_keras: -454.8376 - rmse: 2.0116 - sae: 5341.8486 - sse: 12573.8975 - val_huber_loss: 1.2293 - val_loss: 1.2489 - val_mae: 1.6895 - val_mse: 3.5073 - val_pearson_correlation: -3.2980e-16 - val_r2_keras: -176.5018 - val_rmse: 2.1696 - val_sae: 986.8221 - val_sse: 2490.0151 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 1.2711 - loss: 1.2907 - mae: 1.7402 - mse: 3.7583 - pearson_correlation: 3.5032e-17 - r2_keras: -560.9557 - rmse: 2.0629 - sae: 7392.2949 - sse: 17431.1641\n","Epoch 48: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2113 - loss: 1.2543 - mae: 1.6941 - mse: 3.6794 - pearson_correlation: 1.4248e-17 - r2_keras: -454.7966 - rmse: 2.0115 - sae: 5341.5923 - sse: 12572.7783 - val_huber_loss: 1.2292 - val_loss: 1.2488 - val_mae: 1.6894 - val_mse: 3.5069 - val_pearson_correlation: -6.1077e-17 - val_r2_keras: -176.4847 - val_rmse: 2.1695 - val_sae: 986.7734 - val_sse: 2489.7751 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2711 - loss: 1.2907 - mae: 1.7401 - mse: 3.7579 - pearson_correlation: -2.5134e-16 - r2_keras: -560.9067 - rmse: 2.0628 - sae: 7391.9478 - sse: 17429.6445\n","Epoch 49: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 1.2112 - loss: 1.2542 - mae: 1.6940 - mse: 3.6790 - pearson_correlation: -2.1992e-16 - r2_keras: -454.7560 - rmse: 2.0114 - sae: 5341.3389 - sse: 12571.6729 - val_huber_loss: 1.2291 - val_loss: 1.2487 - val_mae: 1.6893 - val_mse: 3.5065 - val_pearson_correlation: 1.0994e-16 - val_r2_keras: -176.4678 - val_rmse: 2.1694 - val_sae: 986.7252 - val_sse: 2489.5376 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2710 - loss: 1.2906 - mae: 1.7400 - mse: 3.7576 - pearson_correlation: -2.2917e-16 - r2_keras: -560.8582 - rmse: 2.0627 - sae: 7391.6045 - sse: 17428.1367\n","Epoch 50: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 1.2111 - loss: 1.2542 - mae: 1.6939 - mse: 3.6787 - pearson_correlation: -1.6303e-16 - r2_keras: -454.7157 - rmse: 2.0113 - sae: 5341.0884 - sse: 12570.5752 - val_huber_loss: 1.2290 - val_loss: 1.2486 - val_mae: 1.6892 - val_mse: 3.5061 - val_pearson_correlation: -1.5882e-16 - val_r2_keras: -176.4511 - val_rmse: 2.1693 - val_sae: 986.6775 - val_sse: 2489.3027 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2709 - loss: 1.2905 - mae: 1.7399 - mse: 3.7572 - pearson_correlation: 1.0286e-17 - r2_keras: -560.8102 - rmse: 2.0627 - sae: 7391.2651 - sse: 17426.6504\n","Epoch 51: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.2111 - loss: 1.2541 - mae: 1.6939 - mse: 3.6783 - pearson_correlation: -2.9573e-17 - r2_keras: -454.6760 - rmse: 2.0112 - sae: 5340.8408 - sse: 12569.4932 - val_huber_loss: 1.2289 - val_loss: 1.2486 - val_mae: 1.6891 - val_mse: 3.5057 - val_pearson_correlation: 3.0543e-16 - val_r2_keras: -176.4345 - val_rmse: 2.1692 - val_sae: 986.6302 - val_sse: 2489.0701 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2708 - loss: 1.2904 - mae: 1.7398 - mse: 3.7569 - pearson_correlation: -1.6266e-16 - r2_keras: -560.7626 - rmse: 2.0626 - sae: 7390.9277 - sse: 17425.1719\n","Epoch 52: val_loss did not improve from 0.29985\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 1.2110 - loss: 1.2540 - mae: 1.6938 - mse: 3.6780 - pearson_correlation: -1.0958e-16 - r2_keras: -454.6366 - rmse: 2.0111 - sae: 5340.5947 - sse: 12568.4170 - val_huber_loss: 1.2289 - val_loss: 1.2485 - val_mae: 1.6890 - val_mse: 3.5053 - val_pearson_correlation: 8.5526e-17 - val_r2_keras: -176.4181 - val_rmse: 2.1691 - val_sae: 986.5834 - val_sse: 2488.8398 - learning_rate: 1.0000e-05\n","| \u001b[39m4        \u001b[39m | \u001b[39m-1.248   \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m16.51    \u001b[39m | \u001b[39m18.62    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.4966 - loss: 0.5222 - mae: 0.8432 - mse: 1.7815 - pearson_correlation: 3.3875e-16 - r2_keras: -275.0733 - rmse: 1.4459 - sae: 4092.2139 - sse: 8563.4473\n","Epoch 1: val_loss improved from inf to 0.26485, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 467ms/step - huber_loss: 0.5314 - loss: 0.5434 - mae: 0.8821 - mse: 1.8305 - pearson_correlation: 2.5198e-16 - r2_keras: -246.8854 - rmse: 1.5282 - sae: 3037.7195 - sse: 6457.7700 - val_huber_loss: 0.2393 - val_loss: 0.2649 - val_mae: 0.5860 - val_mse: 0.5682 - val_pearson_correlation: 4.1573e-16 - val_r2_keras: -22.8799 - val_rmse: 0.7958 - val_sae: 332.0270 - val_sse: 334.9898 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4943 - loss: 0.5199 - mae: 0.8391 - mse: 1.7752 - pearson_correlation: -1.0993e-16 - r2_keras: -273.9009 - rmse: 1.4428 - sae: 4077.1099 - sse: 8527.0830\n","Epoch 2: val_loss improved from 0.26485 to 0.26008, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.5290 - loss: 0.5410 - mae: 0.8782 - mse: 1.8241 - pearson_correlation: -6.5428e-17 - r2_keras: -245.8799 - rmse: 1.5251 - sae: 3026.8962 - sse: 6430.9009 - val_huber_loss: 0.2345 - val_loss: 0.2601 - val_mae: 0.5739 - val_mse: 0.5597 - val_pearson_correlation: 3.9226e-17 - val_r2_keras: -23.1576 - val_rmse: 0.8004 - val_sae: 330.1222 - val_sse: 338.8854 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.4925 - loss: 0.5180 - mae: 0.8358 - mse: 1.7703 - pearson_correlation: -5.2105e-17 - r2_keras: -273.0042 - rmse: 1.4405 - sae: 4065.4807 - sse: 8499.2676\n","Epoch 3: val_loss improved from 0.26008 to 0.25179, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - huber_loss: 0.5270 - loss: 0.5391 - mae: 0.8751 - mse: 1.8192 - pearson_correlation: -6.6225e-17 - r2_keras: -245.1018 - rmse: 1.5228 - sae: 3018.5212 - sse: 6410.2417 - val_huber_loss: 0.2262 - val_loss: 0.2518 - val_mae: 0.5583 - val_mse: 0.5378 - val_pearson_correlation: -9.2241e-17 - val_r2_keras: -23.8766 - val_rmse: 0.8122 - val_sae: 333.0378 - val_sse: 348.9711 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.4909 - loss: 0.5165 - mae: 0.8331 - mse: 1.7662 - pearson_correlation: 2.8188e-16 - r2_keras: -272.2409 - rmse: 1.4385 - sae: 4055.5537 - sse: 8475.5898\n","Epoch 4: val_loss improved from 0.25179 to 0.24104, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.5253 - loss: 0.5374 - mae: 0.8724 - mse: 1.8149 - pearson_correlation: 2.7497e-16 - r2_keras: -244.4364 - rmse: 1.5207 - sae: 3011.3574 - sse: 6392.6201 - val_huber_loss: 0.2154 - val_loss: 0.2410 - val_mae: 0.5345 - val_mse: 0.5019 - val_pearson_correlation: -8.7498e-17 - val_r2_keras: -25.3281 - val_rmse: 0.8356 - val_sae: 341.4671 - val_sse: 369.3338 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4894 - loss: 0.5150 - mae: 0.8305 - mse: 1.7624 - pearson_correlation: 1.4939e-18 - r2_keras: -271.5576 - rmse: 1.4367 - sae: 4046.6821 - sse: 8454.3945\n","Epoch 5: val_loss improved from 0.24104 to 0.23262, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.5238 - loss: 0.5359 - mae: 0.8700 - mse: 1.8110 - pearson_correlation: 5.6252e-17 - r2_keras: -243.8400 - rmse: 1.5189 - sae: 3004.9470 - sse: 6376.8384 - val_huber_loss: 0.2070 - val_loss: 0.2326 - val_mae: 0.5150 - val_mse: 0.4686 - val_pearson_correlation: 1.3418e-16 - val_r2_keras: -27.9412 - val_rmse: 0.8761 - val_sae: 355.0307 - val_sse: 405.9898 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4881 - loss: 0.5137 - mae: 0.8282 - mse: 1.7590 - pearson_correlation: -1.4961e-18 - r2_keras: -270.9313 - rmse: 1.4350 - sae: 4038.5789 - sse: 8434.9697\n","Epoch 6: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5224 - loss: 0.5346 - mae: 0.8678 - mse: 1.8075 - pearson_correlation: 4.5764e-17 - r2_keras: -243.2932 - rmse: 1.5172 - sae: 2999.0854 - sse: 6362.3716 - val_huber_loss: 0.2073 - val_loss: 0.2329 - val_mae: 0.5255 - val_mse: 0.4586 - val_pearson_correlation: 2.8965e-16 - val_r2_keras: -31.7676 - val_rmse: 0.9322 - val_sae: 375.1703 - val_sse: 459.6671 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4869 - loss: 0.5125 - mae: 0.8261 - mse: 1.7558 - pearson_correlation: 2.2623e-16 - r2_keras: -270.3489 - rmse: 1.4335 - sae: 4031.0688 - sse: 8416.9043\n","Epoch 7: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5211 - loss: 0.5333 - mae: 0.8657 - mse: 1.8042 - pearson_correlation: 1.1192e-16 - r2_keras: -242.7845 - rmse: 1.5157 - sae: 2993.6509 - sse: 6348.9155 - val_huber_loss: 0.2168 - val_loss: 0.2424 - val_mae: 0.5439 - val_mse: 0.4756 - val_pearson_correlation: 1.9457e-16 - val_r2_keras: -36.2464 - val_rmse: 0.9938 - val_sae: 399.5071 - val_sse: 522.4969 - learning_rate: 1.0000e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4858 - loss: 0.5114 - mae: 0.8240 - mse: 1.7528 - pearson_correlation: 4.7206e-16 - r2_keras: -269.8017 - rmse: 1.4320 - sae: 4024.0249 - sse: 8399.9287\n","Epoch 8: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5198 - loss: 0.5321 - mae: 0.8637 - mse: 1.8011 - pearson_correlation: 3.0051e-16 - r2_keras: -242.3064 - rmse: 1.5142 - sae: 2988.5505 - sse: 6336.2690 - val_huber_loss: 0.2314 - val_loss: 0.2570 - val_mae: 0.5629 - val_mse: 0.5107 - val_pearson_correlation: -3.1188e-16 - val_r2_keras: -41.1797 - val_rmse: 1.0576 - val_sae: 428.3581 - val_sse: 591.7014 - learning_rate: 1.0000e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4847 - loss: 0.5103 - mae: 0.8221 - mse: 1.7500 - pearson_correlation: 2.6336e-16 - r2_keras: -269.2834 - rmse: 1.4307 - sae: 4017.3901 - sse: 8383.8545\n","Epoch 9: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5186 - loss: 0.5310 - mae: 0.8619 - mse: 1.7982 - pearson_correlation: 2.6279e-16 - r2_keras: -241.8535 - rmse: 1.5128 - sae: 2983.7429 - sse: 6324.2935 - val_huber_loss: 0.2482 - val_loss: 0.2738 - val_mae: 0.5880 - val_mse: 0.5575 - val_pearson_correlation: 6.4603e-17 - val_r2_keras: -45.9152 - val_rmse: 1.1154 - val_sae: 456.6319 - val_sse: 658.1314 - learning_rate: 1.0000e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4837 - loss: 0.5093 - mae: 0.8202 - mse: 1.7472 - pearson_correlation: -4.4264e-16 - r2_keras: -268.7899 - rmse: 1.4294 - sae: 4011.1001 - sse: 8368.5459\n","Epoch 10: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5175 - loss: 0.5299 - mae: 0.8601 - mse: 1.7954 - pearson_correlation: -2.6996e-16 - r2_keras: -241.4221 - rmse: 1.5115 - sae: 2979.1816 - sse: 6312.8867 - val_huber_loss: 0.2633 - val_loss: 0.2889 - val_mae: 0.6157 - val_mse: 0.6035 - val_pearson_correlation: 3.6366e-16 - val_r2_keras: -50.1683 - val_rmse: 1.1649 - val_sae: 481.3309 - val_sse: 717.7950 - learning_rate: 1.0000e-04\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.4827 - loss: 0.5083 - mae: 0.8187 - mse: 1.7446 - pearson_correlation: 1.7565e-17 - r2_keras: -268.3177 - rmse: 1.4281 - sae: 4005.1089 - sse: 8353.8965\n","Epoch 11: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5166 - loss: 0.5289 - mae: 0.8586 - mse: 1.7928 - pearson_correlation: 5.8700e-17 - r2_keras: -241.0279 - rmse: 1.5103 - sae: 2974.9392 - sse: 6302.1899 - val_huber_loss: 0.2773 - val_loss: 0.3029 - val_mae: 0.6389 - val_mse: 0.6463 - val_pearson_correlation: -1.6700e-16 - val_r2_keras: -53.8750 - val_rmse: 1.2063 - val_sae: 501.8080 - val_sse: 769.7921 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4825 - loss: 0.5081 - mae: 0.8184 - mse: 1.7441 - pearson_correlation: 1.6565e-16 - r2_keras: -268.2270 - rmse: 1.4279 - sae: 4003.9600 - sse: 8351.0840\n","Epoch 12: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5164 - loss: 0.5287 - mae: 0.8584 - mse: 1.7923 - pearson_correlation: 1.3029e-16 - r2_keras: -240.9486 - rmse: 1.5101 - sae: 2974.1052 - sse: 6300.0942 - val_huber_loss: 0.2890 - val_loss: 0.3146 - val_mae: 0.6563 - val_mse: 0.6824 - val_pearson_correlation: -2.9876e-16 - val_r2_keras: -56.8647 - val_rmse: 1.2387 - val_sae: 517.4709 - val_sse: 811.7319 - learning_rate: 2.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4823 - loss: 0.5079 - mae: 0.8181 - mse: 1.7436 - pearson_correlation: 9.1880e-17 - r2_keras: -268.1395 - rmse: 1.4276 - sae: 4002.8508 - sse: 8348.3711\n","Epoch 13: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5162 - loss: 0.5285 - mae: 0.8581 - mse: 1.7918 - pearson_correlation: 1.3586e-17 - r2_keras: -240.8722 - rmse: 1.5098 - sae: 2973.3000 - sse: 6298.0728 - val_huber_loss: 0.2988 - val_loss: 0.3244 - val_mae: 0.6697 - val_mse: 0.7121 - val_pearson_correlation: 1.1254e-16 - val_r2_keras: -59.0362 - val_rmse: 1.2618 - val_sae: 528.5463 - val_sse: 842.1942 - learning_rate: 2.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4821 - loss: 0.5077 - mae: 0.8178 - mse: 1.7432 - pearson_correlation: 2.4456e-16 - r2_keras: -268.0549 - rmse: 1.4274 - sae: 4001.7793 - sse: 8345.7461\n","Epoch 14: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5160 - loss: 0.5283 - mae: 0.8578 - mse: 1.7913 - pearson_correlation: 2.0079e-16 - r2_keras: -240.7983 - rmse: 1.5096 - sae: 2972.5222 - sse: 6296.1177 - val_huber_loss: 0.3061 - val_loss: 0.3317 - val_mae: 0.6793 - val_mse: 0.7343 - val_pearson_correlation: -3.5235e-16 - val_r2_keras: -60.5991 - val_rmse: 1.2781 - val_sae: 536.3175 - val_sse: 864.1193 - learning_rate: 2.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4820 - loss: 0.5075 - mae: 0.8176 - mse: 1.7427 - pearson_correlation: -5.5251e-17 - r2_keras: -267.9728 - rmse: 1.4272 - sae: 4000.7415 - sse: 8343.2002\n","Epoch 15: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5158 - loss: 0.5281 - mae: 0.8576 - mse: 1.7908 - pearson_correlation: -4.0915e-19 - r2_keras: -240.7266 - rmse: 1.5094 - sae: 2971.7683 - sse: 6294.2212 - val_huber_loss: 0.3112 - val_loss: 0.3368 - val_mae: 0.6857 - val_mse: 0.7498 - val_pearson_correlation: 2.3564e-16 - val_r2_keras: -61.6766 - val_rmse: 1.2892 - val_sae: 541.5497 - val_sse: 879.2343 - learning_rate: 2.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4818 - loss: 0.5074 - mae: 0.8173 - mse: 1.7423 - pearson_correlation: -5.7673e-16 - r2_keras: -267.8931 - rmse: 1.4270 - sae: 3999.7334 - sse: 8340.7285\n","Epoch 16: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5156 - loss: 0.5280 - mae: 0.8573 - mse: 1.7904 - pearson_correlation: -3.4143e-16 - r2_keras: -240.6589 - rmse: 1.5092 - sae: 2971.0476 - sse: 6292.4019 - val_huber_loss: 0.3148 - val_loss: 0.3404 - val_mae: 0.6901 - val_mse: 0.7605 - val_pearson_correlation: -7.3691e-17 - val_r2_keras: -62.4153 - val_rmse: 1.2968 - val_sae: 545.0963 - val_sse: 889.5972 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4817 - loss: 0.5073 - mae: 0.8172 - mse: 1.7421 - pearson_correlation: -5.2252e-17 - r2_keras: -267.8544 - rmse: 1.4269 - sae: 3999.2432 - sse: 8339.5283\n","Epoch 17: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5155 - loss: 0.5279 - mae: 0.8572 - mse: 1.7902 - pearson_correlation: 4.2005e-17 - r2_keras: -240.6250 - rmse: 1.5091 - sae: 2970.6914 - sse: 6291.5078 - val_huber_loss: 0.3172 - val_loss: 0.3428 - val_mae: 0.6931 - val_mse: 0.7677 - val_pearson_correlation: 1.2814e-16 - val_r2_keras: -62.9037 - val_rmse: 1.3018 - val_sae: 547.4235 - val_sse: 896.4482 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4816 - loss: 0.5072 - mae: 0.8171 - mse: 1.7418 - pearson_correlation: 2.8339e-16 - r2_keras: -267.8166 - rmse: 1.4268 - sae: 3998.7642 - sse: 8338.3555\n","Epoch 18: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5155 - loss: 0.5278 - mae: 0.8571 - mse: 1.7900 - pearson_correlation: 1.0745e-16 - r2_keras: -240.5921 - rmse: 1.5090 - sae: 2970.3435 - sse: 6290.6343 - val_huber_loss: 0.3187 - val_loss: 0.3443 - val_mae: 0.6951 - val_mse: 0.7723 - val_pearson_correlation: -2.1878e-16 - val_r2_keras: -63.2197 - val_rmse: 1.3050 - val_sae: 548.9194 - val_sse: 900.8809 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4815 - loss: 0.5071 - mae: 0.8170 - mse: 1.7416 - pearson_correlation: -2.3568e-16 - r2_keras: -267.7798 - rmse: 1.4267 - sae: 3998.2974 - sse: 8337.2139\n","Epoch 19: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5154 - loss: 0.5277 - mae: 0.8570 - mse: 1.7898 - pearson_correlation: -9.9483e-17 - r2_keras: -240.5599 - rmse: 1.5089 - sae: 2970.0046 - sse: 6289.7837 - val_huber_loss: 0.3197 - val_loss: 0.3453 - val_mae: 0.6963 - val_mse: 0.7752 - val_pearson_correlation: -2.4246e-17 - val_r2_keras: -63.4208 - val_rmse: 1.3070 - val_sae: 549.8672 - val_sse: 903.7023 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4815 - loss: 0.5071 - mae: 0.8168 - mse: 1.7414 - pearson_correlation: 1.1207e-16 - r2_keras: -267.7437 - rmse: 1.4266 - sae: 3997.8403 - sse: 8336.0928\n","Epoch 20: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.5153 - loss: 0.5276 - mae: 0.8569 - mse: 1.7895 - pearson_correlation: 6.7426e-17 - r2_keras: -240.5283 - rmse: 1.5088 - sae: 2969.6726 - sse: 6288.9487 - val_huber_loss: 0.3203 - val_loss: 0.3459 - val_mae: 0.6971 - val_mse: 0.7771 - val_pearson_correlation: -1.8155e-17 - val_r2_keras: -63.5466 - val_rmse: 1.3083 - val_sae: 550.4568 - val_sse: 905.4661 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4814 - loss: 0.5070 - mae: 0.8167 - mse: 1.7412 - pearson_correlation: -2.5130e-18 - r2_keras: -267.7084 - rmse: 1.4265 - sae: 3997.3933 - sse: 8335.0000\n","Epoch 21: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5152 - loss: 0.5276 - mae: 0.8568 - mse: 1.7893 - pearson_correlation: 3.2117e-17 - r2_keras: -240.4976 - rmse: 1.5087 - sae: 2969.3481 - sse: 6288.1353 - val_huber_loss: 0.3207 - val_loss: 0.3463 - val_mae: 0.6975 - val_mse: 0.7782 - val_pearson_correlation: -1.0278e-16 - val_r2_keras: -63.6233 - val_rmse: 1.3091 - val_sae: 550.8144 - val_sse: 906.5425 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4813 - loss: 0.5069 - mae: 0.8166 - mse: 1.7411 - pearson_correlation: -4.0212e-17 - r2_keras: -267.6739 - rmse: 1.4264 - sae: 3996.9551 - sse: 8333.9277\n","Epoch 22: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5151 - loss: 0.5275 - mae: 0.8566 - mse: 1.7891 - pearson_correlation: -4.1386e-17 - r2_keras: -240.4674 - rmse: 1.5086 - sae: 2969.0298 - sse: 6287.3364 - val_huber_loss: 0.3209 - val_loss: 0.3465 - val_mae: 0.6978 - val_mse: 0.7789 - val_pearson_correlation: -1.1480e-16 - val_r2_keras: -63.6684 - val_rmse: 1.3095 - val_sae: 551.0228 - val_sse: 907.1754 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4813 - loss: 0.5068 - mae: 0.8165 - mse: 1.7409 - pearson_correlation: 1.6840e-16 - r2_keras: -267.6400 - rmse: 1.4263 - sae: 3996.5264 - sse: 8332.8770\n","Epoch 23: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5151 - loss: 0.5274 - mae: 0.8565 - mse: 1.7890 - pearson_correlation: 5.8590e-17 - r2_keras: -240.4379 - rmse: 1.5085 - sae: 2968.7185 - sse: 6286.5542 - val_huber_loss: 0.3210 - val_loss: 0.3466 - val_mae: 0.6979 - val_mse: 0.7792 - val_pearson_correlation: 2.4162e-17 - val_r2_keras: -63.6932 - val_rmse: 1.3098 - val_sae: 551.1357 - val_sse: 907.5234 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.4812 - loss: 0.5068 - mae: 0.8164 - mse: 1.7407 - pearson_correlation: 1.3121e-16 - r2_keras: -267.6068 - rmse: 1.4262 - sae: 3996.1050 - sse: 8331.8467\n","Epoch 24: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5150 - loss: 0.5273 - mae: 0.8564 - mse: 1.7888 - pearson_correlation: 1.2591e-16 - r2_keras: -240.4088 - rmse: 1.5084 - sae: 2968.4126 - sse: 6285.7871 - val_huber_loss: 0.3210 - val_loss: 0.3466 - val_mae: 0.6980 - val_mse: 0.7794 - val_pearson_correlation: 6.0395e-17 - val_r2_keras: -63.7050 - val_rmse: 1.3099 - val_sae: 551.1874 - val_sse: 907.6893 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.4811 - loss: 0.5067 - mae: 0.8163 - mse: 1.7405 - pearson_correlation: -2.2775e-16 - r2_keras: -267.5742 - rmse: 1.4261 - sae: 3995.6914 - sse: 8330.8359\n","Epoch 25: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.5149 - loss: 0.5273 - mae: 0.8563 - mse: 1.7886 - pearson_correlation: -9.7489e-17 - r2_keras: -240.3804 - rmse: 1.5083 - sae: 2968.1123 - sse: 6285.0347 - val_huber_loss: 0.3210 - val_loss: 0.3466 - val_mae: 0.6980 - val_mse: 0.7794 - val_pearson_correlation: -4.2274e-17 - val_r2_keras: -63.7086 - val_rmse: 1.3099 - val_sae: 551.2003 - val_sse: 907.7395 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.4810 - loss: 0.5066 - mae: 0.8162 - mse: 1.7403 - pearson_correlation: -2.6397e-16 - r2_keras: -267.5421 - rmse: 1.4261 - sae: 3995.2871 - sse: 8329.8418\n","Epoch 26: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5148 - loss: 0.5272 - mae: 0.8562 - mse: 1.7884 - pearson_correlation: -1.7731e-16 - r2_keras: -240.3524 - rmse: 1.5082 - sae: 2967.8186 - sse: 6284.2944 - val_huber_loss: 0.3210 - val_loss: 0.3466 - val_mae: 0.6980 - val_mse: 0.7794 - val_pearson_correlation: -2.1137e-16 - val_r2_keras: -63.7070 - val_rmse: 1.3099 - val_sae: 551.1887 - val_sse: 907.7164 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.4810 - loss: 0.5066 - mae: 0.8162 - mse: 1.7401 - pearson_correlation: 3.1428e-16 - r2_keras: -267.5107 - rmse: 1.4260 - sae: 3994.8887 - sse: 8328.8652\n","Epoch 27: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.5148 - loss: 0.5271 - mae: 0.8562 - mse: 1.7882 - pearson_correlation: 1.6179e-16 - r2_keras: -240.3250 - rmse: 1.5081 - sae: 2967.5293 - sse: 6283.5669 - val_huber_loss: 0.3210 - val_loss: 0.3466 - val_mae: 0.6979 - val_mse: 0.7793 - val_pearson_correlation: -2.9594e-16 - val_r2_keras: -63.7020 - val_rmse: 1.3099 - val_sae: 551.1616 - val_sse: 907.6467 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4809 - loss: 0.5065 - mae: 0.8161 - mse: 1.7400 - pearson_correlation: 4.7271e-17 - r2_keras: -267.4797 - rmse: 1.4259 - sae: 3994.4978 - sse: 8327.9043\n","Epoch 28: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.5147 - loss: 0.5271 - mae: 0.8561 - mse: 1.7880 - pearson_correlation: -2.1517e-17 - r2_keras: -240.2979 - rmse: 1.5081 - sae: 2967.2454 - sse: 6282.8521 - val_huber_loss: 0.3209 - val_loss: 0.3465 - val_mae: 0.6979 - val_mse: 0.7792 - val_pearson_correlation: -5.4361e-17 - val_r2_keras: -63.6950 - val_rmse: 1.3098 - val_sae: 551.1248 - val_sse: 907.5483 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4809 - loss: 0.5064 - mae: 0.8160 - mse: 1.7398 - pearson_correlation: 1.1064e-16 - r2_keras: -267.4492 - rmse: 1.4258 - sae: 3994.1121 - sse: 8326.9570\n","Epoch 29: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5146 - loss: 0.5270 - mae: 0.8560 - mse: 1.7879 - pearson_correlation: 7.5088e-17 - r2_keras: -240.2713 - rmse: 1.5080 - sae: 2966.9653 - sse: 6282.1465 - val_huber_loss: 0.3209 - val_loss: 0.3465 - val_mae: 0.6978 - val_mse: 0.7791 - val_pearson_correlation: 9.6652e-17 - val_r2_keras: -63.6867 - val_rmse: 1.3097 - val_sae: 551.0820 - val_sse: 907.4321 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4808 - loss: 0.5064 - mae: 0.8159 - mse: 1.7396 - pearson_correlation: -1.9565e-16 - r2_keras: -267.4191 - rmse: 1.4257 - sae: 3993.7329 - sse: 8326.0254\n","Epoch 30: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5146 - loss: 0.5269 - mae: 0.8559 - mse: 1.7877 - pearson_correlation: -8.9993e-17 - r2_keras: -240.2451 - rmse: 1.5079 - sae: 2966.6897 - sse: 6281.4526 - val_huber_loss: 0.3208 - val_loss: 0.3464 - val_mae: 0.6977 - val_mse: 0.7789 - val_pearson_correlation: -2.1749e-16 - val_r2_keras: -63.6777 - val_rmse: 1.3096 - val_sae: 551.0359 - val_sse: 907.3060 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4807 - loss: 0.5063 - mae: 0.8158 - mse: 1.7395 - pearson_correlation: -2.7564e-16 - r2_keras: -267.3896 - rmse: 1.4257 - sae: 3993.3589 - sse: 8325.1094\n","Epoch 31: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5145 - loss: 0.5269 - mae: 0.8558 - mse: 1.7875 - pearson_correlation: -2.2155e-16 - r2_keras: -240.2193 - rmse: 1.5078 - sae: 2966.4182 - sse: 6280.7710 - val_huber_loss: 0.3208 - val_loss: 0.3463 - val_mae: 0.6977 - val_mse: 0.7788 - val_pearson_correlation: -7.8548e-17 - val_r2_keras: -63.6682 - val_rmse: 1.3095 - val_sae: 550.9878 - val_sse: 907.1730 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4807 - loss: 0.5063 - mae: 0.8158 - mse: 1.7393 - pearson_correlation: 6.5394e-18 - r2_keras: -267.3604 - rmse: 1.4256 - sae: 3992.9905 - sse: 8324.2031\n","Epoch 32: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5144 - loss: 0.5268 - mae: 0.8558 - mse: 1.7874 - pearson_correlation: 1.6294e-17 - r2_keras: -240.1938 - rmse: 1.5077 - sae: 2966.1504 - sse: 6280.0962 - val_huber_loss: 0.3207 - val_loss: 0.3463 - val_mae: 0.6976 - val_mse: 0.7786 - val_pearson_correlation: 2.9006e-16 - val_r2_keras: -63.6586 - val_rmse: 1.3094 - val_sae: 550.9385 - val_sse: 907.0373 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4806 - loss: 0.5062 - mae: 0.8157 - mse: 1.7391 - pearson_correlation: 2.1632e-16 - r2_keras: -267.3317 - rmse: 1.4255 - sae: 3992.6279 - sse: 8323.3125\n","Epoch 33: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5144 - loss: 0.5267 - mae: 0.8557 - mse: 1.7872 - pearson_correlation: 9.7797e-17 - r2_keras: -240.1688 - rmse: 1.5077 - sae: 2965.8872 - sse: 6279.4331 - val_huber_loss: 0.3206 - val_loss: 0.3462 - val_mae: 0.6975 - val_mse: 0.7784 - val_pearson_correlation: 2.2966e-16 - val_r2_keras: -63.6488 - val_rmse: 1.3093 - val_sae: 550.8889 - val_sse: 906.9002 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4805 - loss: 0.5061 - mae: 0.8156 - mse: 1.7390 - pearson_correlation: -2.9633e-16 - r2_keras: -267.3033 - rmse: 1.4254 - sae: 3992.2703 - sse: 8322.4316\n","Epoch 34: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.5143 - loss: 0.5267 - mae: 0.8556 - mse: 1.7870 - pearson_correlation: -2.0418e-16 - r2_keras: -240.1440 - rmse: 1.5076 - sae: 2965.6274 - sse: 6278.7773 - val_huber_loss: 0.3206 - val_loss: 0.3462 - val_mae: 0.6974 - val_mse: 0.7783 - val_pearson_correlation: -3.3848e-16 - val_r2_keras: -63.6390 - val_rmse: 1.3092 - val_sae: 550.8392 - val_sse: 906.7629 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4805 - loss: 0.5061 - mae: 0.8156 - mse: 1.7388 - pearson_correlation: -2.8176e-16 - r2_keras: -267.2752 - rmse: 1.4254 - sae: 3991.9175 - sse: 8321.5615\n","Epoch 35: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.5142 - loss: 0.5266 - mae: 0.8555 - mse: 1.7869 - pearson_correlation: -1.7457e-16 - r2_keras: -240.1195 - rmse: 1.5075 - sae: 2965.3708 - sse: 6278.1294 - val_huber_loss: 0.3205 - val_loss: 0.3461 - val_mae: 0.6974 - val_mse: 0.7781 - val_pearson_correlation: -2.8412e-16 - val_r2_keras: -63.6292 - val_rmse: 1.3091 - val_sae: 550.7897 - val_sse: 906.6258 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4804 - loss: 0.5060 - mae: 0.8155 - mse: 1.7387 - pearson_correlation: -5.5349e-17 - r2_keras: -267.2476 - rmse: 1.4253 - sae: 3991.5701 - sse: 8320.7051\n","Epoch 36: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5142 - loss: 0.5266 - mae: 0.8555 - mse: 1.7867 - pearson_correlation: -5.3479e-17 - r2_keras: -240.0954 - rmse: 1.5074 - sae: 2965.1187 - sse: 6277.4917 - val_huber_loss: 0.3205 - val_loss: 0.3461 - val_mae: 0.6973 - val_mse: 0.7780 - val_pearson_correlation: 1.1487e-16 - val_r2_keras: -63.6195 - val_rmse: 1.3090 - val_sae: 550.7405 - val_sse: 906.4896 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4804 - loss: 0.5060 - mae: 0.8154 - mse: 1.7385 - pearson_correlation: -2.5160e-18 - r2_keras: -267.2202 - rmse: 1.4252 - sae: 3991.2261 - sse: 8319.8555\n","Epoch 37: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5141 - loss: 0.5265 - mae: 0.8554 - mse: 1.7866 - pearson_correlation: -5.9378e-17 - r2_keras: -240.0715 - rmse: 1.5074 - sae: 2964.8687 - sse: 6276.8594 - val_huber_loss: 0.3204 - val_loss: 0.3460 - val_mae: 0.6972 - val_mse: 0.7778 - val_pearson_correlation: -1.8140e-16 - val_r2_keras: -63.6099 - val_rmse: 1.3089 - val_sae: 550.6917 - val_sse: 906.3544 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4803 - loss: 0.5059 - mae: 0.8154 - mse: 1.7384 - pearson_correlation: 2.0784e-16 - r2_keras: -267.1932 - rmse: 1.4251 - sae: 3990.8867 - sse: 8319.0166\n","Epoch 38: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5140 - loss: 0.5264 - mae: 0.8553 - mse: 1.7864 - pearson_correlation: 2.7130e-17 - r2_keras: -240.0480 - rmse: 1.5073 - sae: 2964.6221 - sse: 6276.2349 - val_huber_loss: 0.3203 - val_loss: 0.3459 - val_mae: 0.6971 - val_mse: 0.7777 - val_pearson_correlation: 1.7537e-16 - val_r2_keras: -63.6004 - val_rmse: 1.3088 - val_sae: 550.6433 - val_sse: 906.2210 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4803 - loss: 0.5058 - mae: 0.8153 - mse: 1.7382 - pearson_correlation: -3.8198e-16 - r2_keras: -267.1666 - rmse: 1.4251 - sae: 3990.5513 - sse: 8318.1914\n","Epoch 39: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5140 - loss: 0.5264 - mae: 0.8553 - mse: 1.7862 - pearson_correlation: -2.7721e-16 - r2_keras: -240.0247 - rmse: 1.5072 - sae: 2964.3782 - sse: 6275.6206 - val_huber_loss: 0.3203 - val_loss: 0.3459 - val_mae: 0.6971 - val_mse: 0.7775 - val_pearson_correlation: 5.3827e-16 - val_r2_keras: -63.5909 - val_rmse: 1.3088 - val_sae: 550.5953 - val_sse: 906.0883 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.4802 - loss: 0.5058 - mae: 0.8152 - mse: 1.7381 - pearson_correlation: -3.3721e-16 - r2_keras: -267.1401 - rmse: 1.4250 - sae: 3990.2188 - sse: 8317.3721\n","Epoch 40: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5139 - loss: 0.5263 - mae: 0.8552 - mse: 1.7861 - pearson_correlation: -3.9860e-16 - r2_keras: -240.0017 - rmse: 1.5071 - sae: 2964.1367 - sse: 6275.0107 - val_huber_loss: 0.3202 - val_loss: 0.3458 - val_mae: 0.6970 - val_mse: 0.7774 - val_pearson_correlation: -2.1170e-16 - val_r2_keras: -63.5816 - val_rmse: 1.3087 - val_sae: 550.5479 - val_sse: 905.9572 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4801 - loss: 0.5057 - mae: 0.8152 - mse: 1.7379 - pearson_correlation: -2.0989e-16 - r2_keras: -267.1141 - rmse: 1.4249 - sae: 3989.8911 - sse: 8316.5645\n","Epoch 41: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5139 - loss: 0.5263 - mae: 0.8551 - mse: 1.7859 - pearson_correlation: -1.8039e-16 - r2_keras: -239.9790 - rmse: 1.5071 - sae: 2963.8987 - sse: 6274.4097 - val_huber_loss: 0.3202 - val_loss: 0.3458 - val_mae: 0.6969 - val_mse: 0.7772 - val_pearson_correlation: -1.6938e-16 - val_r2_keras: -63.5723 - val_rmse: 1.3086 - val_sae: 550.5010 - val_sse: 905.8276 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4801 - loss: 0.5057 - mae: 0.8151 - mse: 1.7378 - pearson_correlation: 2.3407e-16 - r2_keras: -267.0883 - rmse: 1.4249 - sae: 3989.5667 - sse: 8315.7656\n","Epoch 42: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.5138 - loss: 0.5262 - mae: 0.8551 - mse: 1.7858 - pearson_correlation: 1.4941e-16 - r2_keras: -239.9565 - rmse: 1.5070 - sae: 2963.6628 - sse: 6273.8149 - val_huber_loss: 0.3201 - val_loss: 0.3457 - val_mae: 0.6969 - val_mse: 0.7771 - val_pearson_correlation: 1.0890e-16 - val_r2_keras: -63.5632 - val_rmse: 1.3085 - val_sae: 550.4545 - val_sse: 905.6993 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4800 - loss: 0.5056 - mae: 0.8150 - mse: 1.7376 - pearson_correlation: 4.9635e-16 - r2_keras: -267.0629 - rmse: 1.4248 - sae: 3989.2461 - sse: 8314.9746\n","Epoch 43: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5137 - loss: 0.5261 - mae: 0.8550 - mse: 1.7857 - pearson_correlation: 3.4351e-16 - r2_keras: -239.9343 - rmse: 1.5069 - sae: 2963.4299 - sse: 6273.2261 - val_huber_loss: 0.3201 - val_loss: 0.3457 - val_mae: 0.6968 - val_mse: 0.7769 - val_pearson_correlation: -1.3312e-16 - val_r2_keras: -63.5541 - val_rmse: 1.3084 - val_sae: 550.4084 - val_sse: 905.5721 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4800 - loss: 0.5056 - mae: 0.8150 - mse: 1.7375 - pearson_correlation: 1.3190e-16 - r2_keras: -267.0376 - rmse: 1.4247 - sae: 3988.9292 - sse: 8314.1914\n","Epoch 44: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5137 - loss: 0.5261 - mae: 0.8549 - mse: 1.7855 - pearson_correlation: 2.8884e-17 - r2_keras: -239.9123 - rmse: 1.5069 - sae: 2963.1995 - sse: 6272.6431 - val_huber_loss: 0.3200 - val_loss: 0.3456 - val_mae: 0.6967 - val_mse: 0.7768 - val_pearson_correlation: 1.9364e-16 - val_r2_keras: -63.5452 - val_rmse: 1.3083 - val_sae: 550.3629 - val_sse: 905.4465 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.4799 - loss: 0.5055 - mae: 0.8149 - mse: 1.7374 - pearson_correlation: 1.4047e-16 - r2_keras: -267.0126 - rmse: 1.4247 - sae: 3988.6150 - sse: 8313.4150\n","Epoch 45: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5136 - loss: 0.5260 - mae: 0.8549 - mse: 1.7854 - pearson_correlation: 8.1037e-17 - r2_keras: -239.8904 - rmse: 1.5068 - sae: 2962.9712 - sse: 6272.0654 - val_huber_loss: 0.3200 - val_loss: 0.3455 - val_mae: 0.6966 - val_mse: 0.7767 - val_pearson_correlation: -1.1499e-16 - val_r2_keras: -63.5363 - val_rmse: 1.3082 - val_sae: 550.3180 - val_sse: 905.3220 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4799 - loss: 0.5055 - mae: 0.8149 - mse: 1.7372 - pearson_correlation: 1.2235e-16 - r2_keras: -266.9878 - rmse: 1.4246 - sae: 3988.3035 - sse: 8312.6455\n","Epoch 46: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.5136 - loss: 0.5260 - mae: 0.8548 - mse: 1.7852 - pearson_correlation: 1.3863e-16 - r2_keras: -239.8688 - rmse: 1.5067 - sae: 2962.7449 - sse: 6271.4927 - val_huber_loss: 0.3199 - val_loss: 0.3455 - val_mae: 0.6966 - val_mse: 0.7765 - val_pearson_correlation: -6.6580e-17 - val_r2_keras: -63.5275 - val_rmse: 1.3081 - val_sae: 550.2733 - val_sse: 905.1985 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.4798 - loss: 0.5054 - mae: 0.8148 - mse: 1.7371 - pearson_correlation: -5.1560e-16 - r2_keras: -266.9633 - rmse: 1.4245 - sae: 3987.9961 - sse: 8311.8867\n","Epoch 47: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5135 - loss: 0.5259 - mae: 0.8547 - mse: 1.7851 - pearson_correlation: -3.5701e-16 - r2_keras: -239.8475 - rmse: 1.5067 - sae: 2962.5215 - sse: 6270.9282 - val_huber_loss: 0.3198 - val_loss: 0.3454 - val_mae: 0.6965 - val_mse: 0.7764 - val_pearson_correlation: -3.3899e-16 - val_r2_keras: -63.5188 - val_rmse: 1.3080 - val_sae: 550.2292 - val_sse: 905.0771 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4798 - loss: 0.5054 - mae: 0.8147 - mse: 1.7370 - pearson_correlation: 2.7242e-16 - r2_keras: -266.9391 - rmse: 1.4245 - sae: 3987.6909 - sse: 8311.1348\n","Epoch 48: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5135 - loss: 0.5259 - mae: 0.8547 - mse: 1.7849 - pearson_correlation: 2.3935e-16 - r2_keras: -239.8263 - rmse: 1.5066 - sae: 2962.2998 - sse: 6270.3682 - val_huber_loss: 0.3198 - val_loss: 0.3454 - val_mae: 0.6964 - val_mse: 0.7763 - val_pearson_correlation: 3.1481e-16 - val_r2_keras: -63.5102 - val_rmse: 1.3079 - val_sae: 550.1856 - val_sse: 904.9562 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4797 - loss: 0.5053 - mae: 0.8147 - mse: 1.7368 - pearson_correlation: -1.4352e-16 - r2_keras: -266.9150 - rmse: 1.4244 - sae: 3987.3896 - sse: 8310.3896\n","Epoch 49: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5134 - loss: 0.5258 - mae: 0.8546 - mse: 1.7848 - pearson_correlation: -1.3682e-16 - r2_keras: -239.8054 - rmse: 1.5065 - sae: 2962.0808 - sse: 6269.8140 - val_huber_loss: 0.3197 - val_loss: 0.3453 - val_mae: 0.6964 - val_mse: 0.7761 - val_pearson_correlation: -6.0547e-17 - val_r2_keras: -63.5017 - val_rmse: 1.3078 - val_sae: 550.1423 - val_sse: 904.8366 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.4797 - loss: 0.5053 - mae: 0.8146 - mse: 1.7367 - pearson_correlation: 1.2540e-16 - r2_keras: -266.8912 - rmse: 1.4243 - sae: 3987.0906 - sse: 8309.6504\n","Epoch 50: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5134 - loss: 0.5258 - mae: 0.8545 - mse: 1.7847 - pearson_correlation: 1.1479e-16 - r2_keras: -239.7846 - rmse: 1.5065 - sae: 2961.8635 - sse: 6269.2637 - val_huber_loss: 0.3197 - val_loss: 0.3453 - val_mae: 0.6963 - val_mse: 0.7760 - val_pearson_correlation: 5.3287e-16 - val_r2_keras: -63.4932 - val_rmse: 1.3078 - val_sae: 550.0992 - val_sse: 904.7179 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4796 - loss: 0.5052 - mae: 0.8146 - mse: 1.7366 - pearson_correlation: -7.2020e-17 - r2_keras: -266.8677 - rmse: 1.4243 - sae: 3986.7944 - sse: 8308.9209\n","Epoch 51: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.5133 - loss: 0.5257 - mae: 0.8545 - mse: 1.7845 - pearson_correlation: -8.2525e-17 - r2_keras: -239.7641 - rmse: 1.5064 - sae: 2961.6482 - sse: 6268.7207 - val_huber_loss: 0.3196 - val_loss: 0.3452 - val_mae: 0.6963 - val_mse: 0.7759 - val_pearson_correlation: -1.1506e-16 - val_r2_keras: -63.4849 - val_rmse: 1.3077 - val_sae: 550.0568 - val_sse: 904.6005 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.4796 - loss: 0.5052 - mae: 0.8145 - mse: 1.7364 - pearson_correlation: 6.7491e-17 - r2_keras: -266.8443 - rmse: 1.4242 - sae: 3986.5007 - sse: 8308.1953\n","Epoch 52: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5133 - loss: 0.5257 - mae: 0.8544 - mse: 1.7844 - pearson_correlation: 9.1454e-17 - r2_keras: -239.7437 - rmse: 1.5063 - sae: 2961.4348 - sse: 6268.1807 - val_huber_loss: 0.3196 - val_loss: 0.3452 - val_mae: 0.6962 - val_mse: 0.7757 - val_pearson_correlation: 2.4226e-17 - val_r2_keras: -63.4766 - val_rmse: 1.3076 - val_sae: 550.0145 - val_sse: 904.4841 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.4795 - loss: 0.5051 - mae: 0.8144 - mse: 1.7363 - pearson_correlation: 6.2458e-17 - r2_keras: -266.8211 - rmse: 1.4241 - sae: 3986.2102 - sse: 8307.4766\n","Epoch 53: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5132 - loss: 0.5256 - mae: 0.8544 - mse: 1.7843 - pearson_correlation: 5.5577e-17 - r2_keras: -239.7235 - rmse: 1.5063 - sae: 2961.2236 - sse: 6267.6455 - val_huber_loss: 0.3195 - val_loss: 0.3451 - val_mae: 0.6961 - val_mse: 0.7756 - val_pearson_correlation: 3.6949e-16 - val_r2_keras: -63.4683 - val_rmse: 1.3075 - val_sae: 549.9728 - val_sse: 904.3687 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.4795 - loss: 0.5051 - mae: 0.8144 - mse: 1.7362 - pearson_correlation: -1.2744e-16 - r2_keras: -266.7982 - rmse: 1.4241 - sae: 3985.9216 - sse: 8306.7637\n","Epoch 54: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5131 - loss: 0.5256 - mae: 0.8543 - mse: 1.7841 - pearson_correlation: -3.3851e-17 - r2_keras: -239.7035 - rmse: 1.5062 - sae: 2961.0139 - sse: 6267.1152 - val_huber_loss: 0.3195 - val_loss: 0.3451 - val_mae: 0.6961 - val_mse: 0.7755 - val_pearson_correlation: -8.4809e-17 - val_r2_keras: -63.4601 - val_rmse: 1.3074 - val_sae: 549.9311 - val_sse: 904.2538 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4794 - loss: 0.5050 - mae: 0.8143 - mse: 1.7360 - pearson_correlation: 4.1610e-16 - r2_keras: -266.7754 - rmse: 1.4240 - sae: 3985.6355 - sse: 8306.0566\n","Epoch 55: val_loss did not improve from 0.23262\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5131 - loss: 0.5255 - mae: 0.8542 - mse: 1.7840 - pearson_correlation: 3.6037e-16 - r2_keras: -239.6836 - rmse: 1.5062 - sae: 2960.8059 - sse: 6266.5889 - val_huber_loss: 0.3194 - val_loss: 0.3450 - val_mae: 0.6960 - val_mse: 0.7753 - val_pearson_correlation: -7.2701e-17 - val_r2_keras: -63.4520 - val_rmse: 1.3073 - val_sae: 549.8899 - val_sse: 904.1404 - learning_rate: 1.0000e-05\n","| \u001b[39m5        \u001b[39m | \u001b[39m-0.345   \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m19.7     \u001b[39m | \u001b[39m18.3     \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.9995 - loss: 1.0229 - mae: 1.4447 - mse: 3.2424 - pearson_correlation: 6.0995e-18 - r2_keras: -334.8939 - rmse: 1.5949 - sae: 5268.2295 - sse: 10419.0098\n","Epoch 1: val_loss improved from inf to 0.26177, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 488ms/step - huber_loss: 0.9775 - loss: 1.0095 - mae: 1.4372 - mse: 3.1008 - pearson_correlation: 8.7310e-17 - r2_keras: -262.0094 - rmse: 1.5047 - sae: 3797.8845 - sse: 7404.4180 - val_huber_loss: 0.2384 - val_loss: 0.2618 - val_mae: 0.5705 - val_mse: 0.5206 - val_pearson_correlation: 3.7816e-17 - val_r2_keras: -27.9620 - val_rmse: 0.8764 - val_sae: 345.4819 - val_sse: 406.2822 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.9933 - loss: 1.0167 - mae: 1.4378 - mse: 3.2170 - pearson_correlation: -3.0547e-16 - r2_keras: -332.4679 - rmse: 1.5891 - sae: 5247.5371 - sse: 10343.7559\n","Epoch 2: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9715 - loss: 1.0034 - mae: 1.4305 - mse: 3.0762 - pearson_correlation: -2.6064e-16 - r2_keras: -260.0638 - rmse: 1.4990 - sae: 3782.7983 - sse: 7350.3975 - val_huber_loss: 0.2725 - val_loss: 0.2959 - val_mae: 0.5832 - val_mse: 0.5927 - val_pearson_correlation: 7.6774e-17 - val_r2_keras: -30.1813 - val_rmse: 0.9093 - val_sae: 347.9474 - val_sse: 437.4148 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9886 - loss: 1.0120 - mae: 1.4326 - mse: 3.1981 - pearson_correlation: -3.9080e-17 - r2_keras: -330.6602 - rmse: 1.5848 - sae: 5231.9697 - sse: 10287.6846\n","Epoch 3: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9669 - loss: 0.9988 - mae: 1.4254 - mse: 3.0576 - pearson_correlation: -3.6788e-17 - r2_keras: -258.5959 - rmse: 1.4947 - sae: 3771.3840 - sse: 7309.9346 - val_huber_loss: 0.3152 - val_loss: 0.3386 - val_mae: 0.6438 - val_mse: 0.6922 - val_pearson_correlation: 5.3585e-16 - val_r2_keras: -33.4114 - val_rmse: 0.9553 - val_sae: 366.2272 - val_sse: 482.7272 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9847 - loss: 1.0081 - mae: 1.4282 - mse: 3.1821 - pearson_correlation: -1.7658e-16 - r2_keras: -329.1453 - rmse: 1.5812 - sae: 5218.8374 - sse: 10240.6943\n","Epoch 4: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.9630 - loss: 0.9949 - mae: 1.4210 - mse: 3.0418 - pearson_correlation: -1.3029e-16 - r2_keras: -257.3596 - rmse: 1.4910 - sae: 3761.7344 - sse: 7275.9526 - val_huber_loss: 0.3647 - val_loss: 0.3881 - val_mae: 0.7135 - val_mse: 0.8243 - val_pearson_correlation: 3.4069e-16 - val_r2_keras: -37.6118 - val_rmse: 1.0119 - val_sae: 395.3398 - val_sse: 541.6504 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9812 - loss: 1.0046 - mae: 1.4243 - mse: 3.1680 - pearson_correlation: 1.5098e-16 - r2_keras: -327.8071 - rmse: 1.5780 - sae: 5207.1948 - sse: 10199.1846\n","Epoch 5: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9595 - loss: 0.9914 - mae: 1.4171 - mse: 3.0278 - pearson_correlation: 8.6235e-17 - r2_keras: -256.2654 - rmse: 1.4877 - sae: 3753.1685 - sse: 7245.9087 - val_huber_loss: 0.4189 - val_loss: 0.4423 - val_mae: 0.7834 - val_mse: 0.9918 - val_pearson_correlation: -8.3588e-18 - val_r2_keras: -43.0548 - val_rmse: 1.0809 - val_sae: 427.6706 - val_sse: 618.0056 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9781 - loss: 1.0015 - mae: 1.4207 - mse: 3.1552 - pearson_correlation: -2.0309e-16 - r2_keras: -326.5936 - rmse: 1.5751 - sae: 5196.6157 - sse: 10161.5430\n","Epoch 6: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9563 - loss: 0.9882 - mae: 1.4136 - mse: 3.0152 - pearson_correlation: -1.3720e-16 - r2_keras: -255.2710 - rmse: 1.4847 - sae: 3745.3762 - sse: 7218.6401 - val_huber_loss: 0.4829 - val_loss: 0.5063 - val_mae: 0.8589 - val_mse: 1.2129 - val_pearson_correlation: 8.5168e-16 - val_r2_keras: -49.8130 - val_rmse: 1.1608 - val_sae: 461.6400 - val_sse: 712.8101 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9751 - loss: 0.9985 - mae: 1.4174 - mse: 3.1434 - pearson_correlation: 1.6451e-16 - r2_keras: -325.4745 - rmse: 1.5724 - sae: 5186.8262 - sse: 10126.8320\n","Epoch 7: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.9536 - loss: 0.9855 - mae: 1.4105 - mse: 3.0042 - pearson_correlation: 1.2960e-16 - r2_keras: -254.4083 - rmse: 1.4822 - sae: 3738.3792 - sse: 7194.1313 - val_huber_loss: 0.5502 - val_loss: 0.5736 - val_mae: 0.9367 - val_mse: 1.4646 - val_pearson_correlation: 3.2148e-16 - val_r2_keras: -57.1759 - val_rmse: 1.2421 - val_sae: 493.4579 - val_sse: 816.0984 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9746 - loss: 0.9980 - mae: 1.4168 - mse: 3.1412 - pearson_correlation: -3.1273e-16 - r2_keras: -325.2651 - rmse: 1.5719 - sae: 5184.9951 - sse: 10120.3369\n","Epoch 8: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.9531 - loss: 0.9849 - mae: 1.4099 - mse: 3.0020 - pearson_correlation: -1.6317e-16 - r2_keras: -254.2365 - rmse: 1.4817 - sae: 3737.0291 - sse: 7189.4229 - val_huber_loss: 0.6198 - val_loss: 0.6432 - val_mae: 1.0192 - val_mse: 1.7297 - val_pearson_correlation: -8.9828e-17 - val_r2_keras: -65.0913 - val_rmse: 1.3239 - val_sae: 525.7323 - val_sse: 927.1354 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9741 - loss: 0.9975 - mae: 1.4162 - mse: 3.1391 - pearson_correlation: 1.4644e-17 - r2_keras: -325.0678 - rmse: 1.5714 - sae: 5183.2671 - sse: 10114.2148\n","Epoch 9: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.9526 - loss: 0.9844 - mae: 1.4093 - mse: 2.9999 - pearson_correlation: 3.8783e-17 - r2_keras: -254.0744 - rmse: 1.4812 - sae: 3735.7546 - sse: 7184.9839 - val_huber_loss: 0.6833 - val_loss: 0.7067 - val_mae: 1.0955 - val_mse: 1.9785 - val_pearson_correlation: 2.9352e-16 - val_r2_keras: -72.6602 - val_rmse: 1.3976 - val_sae: 555.3375 - val_sse: 1033.3130 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9736 - loss: 0.9970 - mae: 1.4156 - mse: 3.1372 - pearson_correlation: 3.0630e-16 - r2_keras: -324.8803 - rmse: 1.5709 - sae: 5181.6250 - sse: 10108.4004\n","Epoch 10: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9521 - loss: 0.9839 - mae: 1.4088 - mse: 2.9979 - pearson_correlation: 2.6590e-16 - r2_keras: -253.9204 - rmse: 1.4807 - sae: 3734.5435 - sse: 7180.7671 - val_huber_loss: 0.7409 - val_loss: 0.7643 - val_mae: 1.1640 - val_mse: 2.2007 - val_pearson_correlation: 1.0507e-16 - val_r2_keras: -79.5607 - val_rmse: 1.4616 - val_sae: 582.4962 - val_sse: 1130.1140 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9731 - loss: 0.9965 - mae: 1.4151 - mse: 3.1353 - pearson_correlation: 2.5001e-16 - r2_keras: -324.7015 - rmse: 1.5705 - sae: 5180.0596 - sse: 10102.8545\n","Epoch 11: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9516 - loss: 0.9834 - mae: 1.4083 - mse: 2.9961 - pearson_correlation: 1.9027e-16 - r2_keras: -253.7735 - rmse: 1.4803 - sae: 3733.3884 - sse: 7176.7446 - val_huber_loss: 0.7865 - val_loss: 0.8099 - val_mae: 1.2181 - val_mse: 2.3754 - val_pearson_correlation: -3.8742e-16 - val_r2_keras: -84.9762 - val_rmse: 1.5099 - val_sae: 603.5178 - val_sse: 1206.0837 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9727 - loss: 0.9961 - mae: 1.4146 - mse: 3.1335 - pearson_correlation: -2.3454e-16 - r2_keras: -324.5301 - rmse: 1.5701 - sae: 5178.5601 - sse: 10097.5371\n","Epoch 12: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.9512 - loss: 0.9830 - mae: 1.4078 - mse: 2.9943 - pearson_correlation: -1.5999e-16 - r2_keras: -253.6380 - rmse: 1.4799 - sae: 3732.3030 - sse: 7172.9507 - val_huber_loss: 0.8216 - val_loss: 0.8450 - val_mae: 1.2592 - val_mse: 2.5077 - val_pearson_correlation: 3.7092e-17 - val_r2_keras: -89.0418 - val_rmse: 1.5452 - val_sae: 619.2825 - val_sse: 1263.1163 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9724 - loss: 0.9958 - mae: 1.4144 - mse: 3.1326 - pearson_correlation: -1.6438e-17 - r2_keras: -324.4476 - rmse: 1.5699 - sae: 5177.8374 - sse: 10094.9785\n","Epoch 13: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.9510 - loss: 0.9828 - mae: 1.4075 - mse: 2.9935 - pearson_correlation: -7.2726e-17 - r2_keras: -253.5702 - rmse: 1.4797 - sae: 3731.7698 - sse: 7171.0947 - val_huber_loss: 0.8471 - val_loss: 0.8705 - val_mae: 1.2889 - val_mse: 2.6036 - val_pearson_correlation: -2.0428e-16 - val_r2_keras: -91.9676 - val_rmse: 1.5701 - val_sae: 630.5256 - val_sse: 1304.1599 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9722 - loss: 0.9956 - mae: 1.4141 - mse: 3.1318 - pearson_correlation: 3.1682e-16 - r2_keras: -324.3680 - rmse: 1.5697 - sae: 5177.1416 - sse: 10092.5098\n","Epoch 14: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9507 - loss: 0.9826 - mae: 1.4073 - mse: 2.9926 - pearson_correlation: 4.9492e-17 - r2_keras: -253.5047 - rmse: 1.4795 - sae: 3731.2561 - sse: 7169.3037 - val_huber_loss: 0.8646 - val_loss: 0.8880 - val_mae: 1.3092 - val_mse: 2.6703 - val_pearson_correlation: -1.0297e-16 - val_r2_keras: -93.9613 - val_rmse: 1.5869 - val_sae: 638.1631 - val_sse: 1332.1270 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9720 - loss: 0.9954 - mae: 1.4139 - mse: 3.1310 - pearson_correlation: -3.6531e-16 - r2_keras: -324.2911 - rmse: 1.5695 - sae: 5176.4688 - sse: 10090.1240\n","Epoch 15: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9505 - loss: 0.9823 - mae: 1.4071 - mse: 2.9918 - pearson_correlation: -2.2900e-16 - r2_keras: -253.4415 - rmse: 1.4793 - sae: 3730.7595 - sse: 7167.5728 - val_huber_loss: 0.8767 - val_loss: 0.9001 - val_mae: 1.3231 - val_mse: 2.7163 - val_pearson_correlation: 4.7018e-16 - val_r2_keras: -95.3255 - val_rmse: 1.5982 - val_sae: 643.4495 - val_sse: 1351.2639 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9718 - loss: 0.9952 - mae: 1.4137 - mse: 3.1302 - pearson_correlation: 3.1824e-16 - r2_keras: -324.2165 - rmse: 1.5693 - sae: 5175.8164 - sse: 10087.8086\n","Epoch 16: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.9503 - loss: 0.9822 - mae: 1.4069 - mse: 2.9911 - pearson_correlation: 2.2125e-16 - r2_keras: -253.3801 - rmse: 1.4791 - sae: 3730.2778 - sse: 7165.8931 - val_huber_loss: 0.8848 - val_loss: 0.9082 - val_mae: 1.3325 - val_mse: 2.7471 - val_pearson_correlation: -1.3667e-16 - val_r2_keras: -96.2351 - val_rmse: 1.6058 - val_sae: 646.9692 - val_sse: 1364.0245 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.9716 - loss: 0.9950 - mae: 1.4135 - mse: 3.1294 - pearson_correlation: 1.5559e-17 - r2_keras: -324.1441 - rmse: 1.5692 - sae: 5175.1826 - sse: 10085.5625\n","Epoch 17: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9501 - loss: 0.9820 - mae: 1.4066 - mse: 2.9903 - pearson_correlation: 5.0373e-17 - r2_keras: -253.3206 - rmse: 1.4789 - sae: 3729.8098 - sse: 7164.2632 - val_huber_loss: 0.8902 - val_loss: 0.9136 - val_mae: 1.3387 - val_mse: 2.7673 - val_pearson_correlation: 2.2397e-16 - val_r2_keras: -96.8299 - val_rmse: 1.6107 - val_sae: 649.2648 - val_sse: 1372.3690 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9715 - loss: 0.9949 - mae: 1.4133 - mse: 3.1287 - pearson_correlation: -4.6683e-17 - r2_keras: -324.0735 - rmse: 1.5690 - sae: 5174.5659 - sse: 10083.3750\n","Epoch 18: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9500 - loss: 0.9818 - mae: 1.4064 - mse: 2.9896 - pearson_correlation: -6.9311e-17 - r2_keras: -253.2626 - rmse: 1.4787 - sae: 3729.3547 - sse: 7162.6763 - val_huber_loss: 0.8936 - val_loss: 0.9170 - val_mae: 1.3426 - val_mse: 2.7803 - val_pearson_correlation: -2.5407e-16 - val_r2_keras: -97.2120 - val_rmse: 1.6138 - val_sae: 650.7362 - val_sse: 1377.7280 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9713 - loss: 0.9947 - mae: 1.4130 - mse: 3.1280 - pearson_correlation: -2.0454e-17 - r2_keras: -324.0049 - rmse: 1.5688 - sae: 5173.9648 - sse: 10081.2451\n","Epoch 19: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9498 - loss: 0.9816 - mae: 1.4062 - mse: 2.9888 - pearson_correlation: 6.2758e-17 - r2_keras: -253.2061 - rmse: 1.4786 - sae: 3728.9109 - sse: 7161.1304 - val_huber_loss: 0.8958 - val_loss: 0.9192 - val_mae: 1.3451 - val_mse: 2.7885 - val_pearson_correlation: 8.3098e-17 - val_r2_keras: -97.4527 - val_rmse: 1.6158 - val_sae: 651.6629 - val_sse: 1381.1053 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9711 - loss: 0.9945 - mae: 1.4128 - mse: 3.1273 - pearson_correlation: -3.7356e-17 - r2_keras: -323.9379 - rmse: 1.5687 - sae: 5173.3789 - sse: 10079.1660\n","Epoch 20: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.9496 - loss: 0.9814 - mae: 1.4060 - mse: 2.9881 - pearson_correlation: -1.0495e-16 - r2_keras: -253.1510 - rmse: 1.4784 - sae: 3728.4783 - sse: 7159.6221 - val_huber_loss: 0.8971 - val_loss: 0.9205 - val_mae: 1.3467 - val_mse: 2.7936 - val_pearson_correlation: -1.0050e-16 - val_r2_keras: -97.6010 - val_rmse: 1.6170 - val_sae: 652.2338 - val_sse: 1383.1848 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9709 - loss: 0.9943 - mae: 1.4127 - mse: 3.1266 - pearson_correlation: -1.5745e-16 - r2_keras: -323.8724 - rmse: 1.5685 - sae: 5172.8057 - sse: 10077.1348\n","Epoch 21: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.9494 - loss: 0.9812 - mae: 1.4058 - mse: 2.9875 - pearson_correlation: -1.9230e-16 - r2_keras: -253.0971 - rmse: 1.4782 - sae: 3728.0549 - sse: 7158.1484 - val_huber_loss: 0.8979 - val_loss: 0.9213 - val_mae: 1.3476 - val_mse: 2.7966 - val_pearson_correlation: -4.5416e-16 - val_r2_keras: -97.6892 - val_rmse: 1.6177 - val_sae: 652.5745 - val_sse: 1384.4227 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9708 - loss: 0.9942 - mae: 1.4125 - mse: 3.1259 - pearson_correlation: 7.0282e-17 - r2_keras: -323.8085 - rmse: 1.5684 - sae: 5172.2456 - sse: 10075.1523\n","Epoch 22: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9493 - loss: 0.9811 - mae: 1.4057 - mse: 2.9868 - pearson_correlation: 2.5016e-17 - r2_keras: -253.0445 - rmse: 1.4781 - sae: 3727.6414 - sse: 7156.7095 - val_huber_loss: 0.8984 - val_loss: 0.9218 - val_mae: 1.3481 - val_mse: 2.7983 - val_pearson_correlation: -3.9289e-17 - val_r2_keras: -97.7387 - val_rmse: 1.6181 - val_sae: 652.7672 - val_sse: 1385.1174 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.9706 - loss: 0.9940 - mae: 1.4123 - mse: 3.1252 - pearson_correlation: -7.3849e-17 - r2_keras: -323.7459 - rmse: 1.5682 - sae: 5171.6973 - sse: 10073.2109\n","Epoch 23: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9491 - loss: 0.9809 - mae: 1.4055 - mse: 2.9861 - pearson_correlation: -7.1075e-17 - r2_keras: -252.9930 - rmse: 1.4779 - sae: 3727.2366 - sse: 7155.3008 - val_huber_loss: 0.8986 - val_loss: 0.9220 - val_mae: 1.3484 - val_mse: 2.7991 - val_pearson_correlation: -2.1387e-16 - val_r2_keras: -97.7635 - val_rmse: 1.6183 - val_sae: 652.8647 - val_sse: 1385.4652 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9704 - loss: 0.9938 - mae: 1.4121 - mse: 3.1246 - pearson_correlation: -2.8831e-16 - r2_keras: -323.6844 - rmse: 1.5681 - sae: 5171.1592 - sse: 10071.3027\n","Epoch 24: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9489 - loss: 0.9807 - mae: 1.4053 - mse: 2.9855 - pearson_correlation: -2.5411e-16 - r2_keras: -252.9425 - rmse: 1.4778 - sae: 3726.8391 - sse: 7153.9165 - val_huber_loss: 0.8987 - val_loss: 0.9221 - val_mae: 1.3485 - val_mse: 2.7994 - val_pearson_correlation: 2.5751e-16 - val_r2_keras: -97.7725 - val_rmse: 1.6184 - val_sae: 652.9015 - val_sse: 1385.5913 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9703 - loss: 0.9937 - mae: 1.4119 - mse: 3.1240 - pearson_correlation: -2.8167e-16 - r2_keras: -323.6242 - rmse: 1.5679 - sae: 5170.6328 - sse: 10069.4375\n","Epoch 25: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9488 - loss: 0.9806 - mae: 1.4051 - mse: 2.9849 - pearson_correlation: -1.0584e-16 - r2_keras: -252.8930 - rmse: 1.4776 - sae: 3726.4504 - sse: 7152.5630 - val_huber_loss: 0.8987 - val_loss: 0.9221 - val_mae: 1.3485 - val_mse: 2.7994 - val_pearson_correlation: 2.9679e-16 - val_r2_keras: -97.7714 - val_rmse: 1.6184 - val_sae: 652.8997 - val_sse: 1385.5764 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9701 - loss: 0.9935 - mae: 1.4117 - mse: 3.1234 - pearson_correlation: -8.5445e-17 - r2_keras: -323.5652 - rmse: 1.5678 - sae: 5170.1162 - sse: 10067.6055\n","Epoch 26: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.9486 - loss: 0.9804 - mae: 1.4049 - mse: 2.9842 - pearson_correlation: 4.1376e-17 - r2_keras: -252.8444 - rmse: 1.4775 - sae: 3726.0691 - sse: 7151.2334 - val_huber_loss: 0.8986 - val_loss: 0.9220 - val_mae: 1.3484 - val_mse: 2.7991 - val_pearson_correlation: 1.3967e-16 - val_r2_keras: -97.7641 - val_rmse: 1.6183 - val_sae: 652.8738 - val_sse: 1385.4740 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9700 - loss: 0.9934 - mae: 1.4116 - mse: 3.1227 - pearson_correlation: -8.4565e-17 - r2_keras: -323.5071 - rmse: 1.5676 - sae: 5169.6074 - sse: 10065.8047\n","Epoch 27: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9485 - loss: 0.9803 - mae: 1.4048 - mse: 2.9836 - pearson_correlation: -6.3662e-17 - r2_keras: -252.7966 - rmse: 1.4773 - sae: 3725.6934 - sse: 7149.9268 - val_huber_loss: 0.8985 - val_loss: 0.9219 - val_mae: 1.3483 - val_mse: 2.7987 - val_pearson_correlation: -1.3095e-17 - val_r2_keras: -97.7529 - val_rmse: 1.6183 - val_sae: 652.8329 - val_sse: 1385.3165 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9698 - loss: 0.9932 - mae: 1.4114 - mse: 3.1221 - pearson_correlation: -6.8104e-17 - r2_keras: -323.4502 - rmse: 1.5675 - sae: 5169.1104 - sse: 10064.0391\n","Epoch 28: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9483 - loss: 0.9801 - mae: 1.4046 - mse: 2.9830 - pearson_correlation: -1.6256e-17 - r2_keras: -252.7498 - rmse: 1.4772 - sae: 3725.3259 - sse: 7148.6455 - val_huber_loss: 0.8984 - val_loss: 0.9218 - val_mae: 1.3482 - val_mse: 2.7983 - val_pearson_correlation: 2.0518e-16 - val_r2_keras: -97.7392 - val_rmse: 1.6181 - val_sae: 652.7823 - val_sse: 1385.1248 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9697 - loss: 0.9931 - mae: 1.4112 - mse: 3.1216 - pearson_correlation: -1.3711e-16 - r2_keras: -323.3941 - rmse: 1.5674 - sae: 5168.6201 - sse: 10062.2998\n","Epoch 29: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.9482 - loss: 0.9800 - mae: 1.4044 - mse: 2.9825 - pearson_correlation: -1.6064e-16 - r2_keras: -252.7037 - rmse: 1.4770 - sae: 3724.9641 - sse: 7147.3833 - val_huber_loss: 0.8982 - val_loss: 0.9216 - val_mae: 1.3480 - val_mse: 2.7977 - val_pearson_correlation: -2.6196e-17 - val_r2_keras: -97.7241 - val_rmse: 1.6180 - val_sae: 652.7261 - val_sse: 1384.9127 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9695 - loss: 0.9929 - mae: 1.4111 - mse: 3.1210 - pearson_correlation: 2.9741e-16 - r2_keras: -323.3389 - rmse: 1.5672 - sae: 5168.1372 - sse: 10060.5879\n","Epoch 30: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9480 - loss: 0.9798 - mae: 1.4043 - mse: 2.9819 - pearson_correlation: 2.4929e-16 - r2_keras: -252.6583 - rmse: 1.4769 - sae: 3724.6074 - sse: 7146.1411 - val_huber_loss: 0.8981 - val_loss: 0.9215 - val_mae: 1.3478 - val_mse: 2.7972 - val_pearson_correlation: -2.1832e-17 - val_r2_keras: -97.7082 - val_rmse: 1.6179 - val_sae: 652.6668 - val_sse: 1384.6890 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9694 - loss: 0.9928 - mae: 1.4109 - mse: 3.1204 - pearson_correlation: 1.9547e-16 - r2_keras: -323.2846 - rmse: 1.5671 - sae: 5167.6631 - sse: 10058.9043\n","Epoch 31: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9479 - loss: 0.9797 - mae: 1.4041 - mse: 2.9813 - pearson_correlation: 1.3031e-16 - r2_keras: -252.6136 - rmse: 1.4768 - sae: 3724.2573 - sse: 7144.9194 - val_huber_loss: 0.8979 - val_loss: 0.9213 - val_mae: 1.3477 - val_mse: 2.7966 - val_pearson_correlation: -5.6769e-17 - val_r2_keras: -97.6918 - val_rmse: 1.6178 - val_sae: 652.6058 - val_sse: 1384.4590 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9693 - loss: 0.9927 - mae: 1.4108 - mse: 3.1199 - pearson_correlation: 1.4250e-17 - r2_keras: -323.2313 - rmse: 1.5670 - sae: 5167.1963 - sse: 10057.2480\n","Epoch 32: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9477 - loss: 0.9795 - mae: 1.4040 - mse: 2.9808 - pearson_correlation: 1.3146e-17 - r2_keras: -252.5697 - rmse: 1.4766 - sae: 3723.9126 - sse: 7143.7173 - val_huber_loss: 0.8978 - val_loss: 0.9212 - val_mae: 1.3475 - val_mse: 2.7961 - val_pearson_correlation: -2.3147e-16 - val_r2_keras: -97.6752 - val_rmse: 1.6176 - val_sae: 652.5439 - val_sse: 1384.2267 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9691 - loss: 0.9925 - mae: 1.4106 - mse: 3.1193 - pearson_correlation: -1.3806e-16 - r2_keras: -323.1786 - rmse: 1.5668 - sae: 5166.7354 - sse: 10055.6152\n","Epoch 33: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9476 - loss: 0.9794 - mae: 1.4038 - mse: 2.9802 - pearson_correlation: -8.4748e-17 - r2_keras: -252.5264 - rmse: 1.4765 - sae: 3723.5723 - sse: 7142.5327 - val_huber_loss: 0.8976 - val_loss: 0.9210 - val_mae: 1.3473 - val_mse: 2.7955 - val_pearson_correlation: 1.5287e-16 - val_r2_keras: -97.6585 - val_rmse: 1.6175 - val_sae: 652.4819 - val_sse: 1383.9928 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9690 - loss: 0.9924 - mae: 1.4105 - mse: 3.1188 - pearson_correlation: -1.1447e-16 - r2_keras: -323.1267 - rmse: 1.5667 - sae: 5166.2812 - sse: 10054.0039\n","Epoch 34: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.9474 - loss: 0.9793 - mae: 1.4037 - mse: 2.9797 - pearson_correlation: 1.8501e-17 - r2_keras: -252.4837 - rmse: 1.4764 - sae: 3723.2371 - sse: 7141.3638 - val_huber_loss: 0.8975 - val_loss: 0.9209 - val_mae: 1.3472 - val_mse: 2.7949 - val_pearson_correlation: -1.7036e-16 - val_r2_keras: -97.6420 - val_rmse: 1.6173 - val_sae: 652.4202 - val_sse: 1383.7605 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9688 - loss: 0.9922 - mae: 1.4103 - mse: 3.1182 - pearson_correlation: -3.0825e-16 - r2_keras: -323.0755 - rmse: 1.5666 - sae: 5165.8335 - sse: 10052.4160\n","Epoch 35: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9473 - loss: 0.9791 - mae: 1.4035 - mse: 2.9791 - pearson_correlation: -1.3256e-16 - r2_keras: -252.4416 - rmse: 1.4762 - sae: 3722.9062 - sse: 7140.2114 - val_huber_loss: 0.8973 - val_loss: 0.9207 - val_mae: 1.3470 - val_mse: 2.7943 - val_pearson_correlation: 2.5776e-16 - val_r2_keras: -97.6255 - val_rmse: 1.6172 - val_sae: 652.3589 - val_sse: 1383.5297 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9687 - loss: 0.9921 - mae: 1.4102 - mse: 3.1177 - pearson_correlation: 1.6305e-16 - r2_keras: -323.0249 - rmse: 1.5665 - sae: 5165.3906 - sse: 10050.8477\n","Epoch 36: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9472 - loss: 0.9790 - mae: 1.4034 - mse: 2.9786 - pearson_correlation: 5.3984e-17 - r2_keras: -252.4000 - rmse: 1.4761 - sae: 3722.5793 - sse: 7139.0732 - val_huber_loss: 0.8972 - val_loss: 0.9206 - val_mae: 1.3468 - val_mse: 2.7938 - val_pearson_correlation: 3.8886e-16 - val_r2_keras: -97.6092 - val_rmse: 1.6171 - val_sae: 652.2980 - val_sse: 1383.3008 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9686 - loss: 0.9920 - mae: 1.4100 - mse: 3.1172 - pearson_correlation: -1.6485e-17 - r2_keras: -322.9750 - rmse: 1.5663 - sae: 5164.9541 - sse: 10049.2988\n","Epoch 37: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9470 - loss: 0.9789 - mae: 1.4032 - mse: 2.9781 - pearson_correlation: 1.8196e-17 - r2_keras: -252.3589 - rmse: 1.4760 - sae: 3722.2571 - sse: 7137.9497 - val_huber_loss: 0.8970 - val_loss: 0.9204 - val_mae: 1.3467 - val_mse: 2.7932 - val_pearson_correlation: 2.2285e-16 - val_r2_keras: -97.5930 - val_rmse: 1.6169 - val_sae: 652.2377 - val_sse: 1383.0740 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9685 - loss: 0.9919 - mae: 1.4099 - mse: 3.1167 - pearson_correlation: 6.9064e-17 - r2_keras: -322.9258 - rmse: 1.5662 - sae: 5164.5244 - sse: 10047.7744\n","Epoch 38: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.9469 - loss: 0.9787 - mae: 1.4031 - mse: 2.9776 - pearson_correlation: 8.9827e-17 - r2_keras: -252.3185 - rmse: 1.4759 - sae: 3721.9397 - sse: 7136.8433 - val_huber_loss: 0.8969 - val_loss: 0.9203 - val_mae: 1.3465 - val_mse: 2.7927 - val_pearson_correlation: -3.4087e-16 - val_r2_keras: -97.5771 - val_rmse: 1.6168 - val_sae: 652.1780 - val_sse: 1382.8497 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9683 - loss: 0.9917 - mae: 1.4097 - mse: 3.1161 - pearson_correlation: 4.0105e-17 - r2_keras: -322.8773 - rmse: 1.5661 - sae: 5164.0986 - sse: 10046.2686\n","Epoch 39: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9468 - loss: 0.9786 - mae: 1.4029 - mse: 2.9771 - pearson_correlation: 6.1404e-17 - r2_keras: -252.2786 - rmse: 1.4757 - sae: 3721.6252 - sse: 7135.7510 - val_huber_loss: 0.8967 - val_loss: 0.9201 - val_mae: 1.3463 - val_mse: 2.7921 - val_pearson_correlation: 9.1783e-17 - val_r2_keras: -97.5613 - val_rmse: 1.6167 - val_sae: 652.1190 - val_sse: 1382.6282 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9682 - loss: 0.9916 - mae: 1.4096 - mse: 3.1156 - pearson_correlation: 3.1196e-18 - r2_keras: -322.8293 - rmse: 1.5660 - sae: 5163.6782 - sse: 10044.7803\n","Epoch 40: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.9466 - loss: 0.9785 - mae: 1.4028 - mse: 2.9766 - pearson_correlation: -1.2519e-17 - r2_keras: -252.2391 - rmse: 1.4756 - sae: 3721.3147 - sse: 7134.6704 - val_huber_loss: 0.8966 - val_loss: 0.9200 - val_mae: 1.3462 - val_mse: 2.7916 - val_pearson_correlation: -1.3987e-16 - val_r2_keras: -97.5456 - val_rmse: 1.6166 - val_sae: 652.0606 - val_sse: 1382.4089 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9681 - loss: 0.9915 - mae: 1.4094 - mse: 3.1151 - pearson_correlation: -9.8053e-18 - r2_keras: -322.7819 - rmse: 1.5659 - sae: 5163.2627 - sse: 10043.3086\n","Epoch 41: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9465 - loss: 0.9784 - mae: 1.4026 - mse: 2.9761 - pearson_correlation: 9.8887e-18 - r2_keras: -252.2001 - rmse: 1.4755 - sae: 3721.0081 - sse: 7133.6030 - val_huber_loss: 0.8965 - val_loss: 0.9199 - val_mae: 1.3460 - val_mse: 2.7910 - val_pearson_correlation: -1.5737e-16 - val_r2_keras: -97.5302 - val_rmse: 1.6164 - val_sae: 652.0027 - val_sse: 1382.1917 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9680 - loss: 0.9914 - mae: 1.4093 - mse: 3.1147 - pearson_correlation: -2.2554e-16 - r2_keras: -322.7351 - rmse: 1.5658 - sae: 5162.8525 - sse: 10041.8574\n","Epoch 42: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9464 - loss: 0.9782 - mae: 1.4025 - mse: 2.9756 - pearson_correlation: -2.2590e-17 - r2_keras: -252.1616 - rmse: 1.4754 - sae: 3720.7051 - sse: 7132.5493 - val_huber_loss: 0.8963 - val_loss: 0.9197 - val_mae: 1.3459 - val_mse: 2.7905 - val_pearson_correlation: 2.0548e-16 - val_r2_keras: -97.5149 - val_rmse: 1.6163 - val_sae: 651.9457 - val_sse: 1381.9777 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9678 - loss: 0.9912 - mae: 1.4092 - mse: 3.1142 - pearson_correlation: 3.3879e-17 - r2_keras: -322.6886 - rmse: 1.5657 - sae: 5162.4463 - sse: 10040.4150\n","Epoch 43: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.9463 - loss: 0.9781 - mae: 1.4024 - mse: 2.9751 - pearson_correlation: 6.4573e-17 - r2_keras: -252.1233 - rmse: 1.4753 - sae: 3720.4050 - sse: 7131.5034 - val_huber_loss: 0.8962 - val_loss: 0.9196 - val_mae: 1.3457 - val_mse: 2.7900 - val_pearson_correlation: 4.7659e-16 - val_r2_keras: -97.4997 - val_rmse: 1.6162 - val_sae: 651.8892 - val_sse: 1381.7651 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9677 - loss: 0.9911 - mae: 1.4090 - mse: 3.1137 - pearson_correlation: -2.9780e-16 - r2_keras: -322.6427 - rmse: 1.5655 - sae: 5162.0454 - sse: 10038.9932\n","Epoch 44: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9462 - loss: 0.9780 - mae: 1.4022 - mse: 2.9746 - pearson_correlation: -1.8758e-16 - r2_keras: -252.0856 - rmse: 1.4751 - sae: 3720.1091 - sse: 7130.4717 - val_huber_loss: 0.8960 - val_loss: 0.9194 - val_mae: 1.3455 - val_mse: 2.7895 - val_pearson_correlation: 8.7456e-17 - val_r2_keras: -97.4848 - val_rmse: 1.6161 - val_sae: 651.8334 - val_sse: 1381.5554 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9676 - loss: 0.9910 - mae: 1.4089 - mse: 3.1132 - pearson_correlation: -3.2101e-17 - r2_keras: -322.5974 - rmse: 1.5654 - sae: 5161.6489 - sse: 10037.5859\n","Epoch 45: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9460 - loss: 0.9779 - mae: 1.4021 - mse: 2.9741 - pearson_correlation: -7.9833e-17 - r2_keras: -252.0483 - rmse: 1.4750 - sae: 3719.8162 - sse: 7129.4507 - val_huber_loss: 0.8959 - val_loss: 0.9193 - val_mae: 1.3454 - val_mse: 2.7889 - val_pearson_correlation: -2.2741e-16 - val_r2_keras: -97.4700 - val_rmse: 1.6159 - val_sae: 651.7781 - val_sse: 1381.3483 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9675 - loss: 0.9909 - mae: 1.4088 - mse: 3.1127 - pearson_correlation: 1.4581e-16 - r2_keras: -322.5525 - rmse: 1.5653 - sae: 5161.2554 - sse: 10036.1934\n","Epoch 46: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.9459 - loss: 0.9778 - mae: 1.4020 - mse: 2.9737 - pearson_correlation: 2.4155e-17 - r2_keras: -252.0114 - rmse: 1.4749 - sae: 3719.5256 - sse: 7128.4399 - val_huber_loss: 0.8958 - val_loss: 0.9192 - val_mae: 1.3452 - val_mse: 2.7884 - val_pearson_correlation: -5.1609e-16 - val_r2_keras: -97.4554 - val_rmse: 1.6158 - val_sae: 651.7231 - val_sse: 1381.1425 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9674 - loss: 0.9908 - mae: 1.4086 - mse: 3.1123 - pearson_correlation: 1.1594e-17 - r2_keras: -322.5081 - rmse: 1.5652 - sae: 5160.8662 - sse: 10034.8164\n","Epoch 47: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9458 - loss: 0.9776 - mae: 1.4018 - mse: 2.9732 - pearson_correlation: 8.2614e-17 - r2_keras: -251.9749 - rmse: 1.4748 - sae: 3719.2383 - sse: 7127.4409 - val_huber_loss: 0.8956 - val_loss: 0.9190 - val_mae: 1.3451 - val_mse: 2.7879 - val_pearson_correlation: -1.8371e-16 - val_r2_keras: -97.4409 - val_rmse: 1.6157 - val_sae: 651.6689 - val_sse: 1380.9393 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.9673 - loss: 0.9907 - mae: 1.4085 - mse: 3.1118 - pearson_correlation: -2.2120e-16 - r2_keras: -322.4642 - rmse: 1.5651 - sae: 5160.4824 - sse: 10033.4551\n","Epoch 48: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9457 - loss: 0.9775 - mae: 1.4017 - mse: 2.9728 - pearson_correlation: -8.7186e-17 - r2_keras: -251.9388 - rmse: 1.4747 - sae: 3718.9548 - sse: 7126.4531 - val_huber_loss: 0.8955 - val_loss: 0.9189 - val_mae: 1.3449 - val_mse: 2.7874 - val_pearson_correlation: 4.3745e-18 - val_r2_keras: -97.4265 - val_rmse: 1.6156 - val_sae: 651.6153 - val_sse: 1380.7379 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9671 - loss: 0.9905 - mae: 1.4084 - mse: 3.1114 - pearson_correlation: 7.4037e-17 - r2_keras: -322.4206 - rmse: 1.5650 - sae: 5160.1016 - sse: 10032.1035\n","Epoch 49: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9456 - loss: 0.9774 - mae: 1.4016 - mse: 2.9723 - pearson_correlation: -2.5545e-17 - r2_keras: -251.9030 - rmse: 1.4746 - sae: 3718.6736 - sse: 7125.4727 - val_huber_loss: 0.8954 - val_loss: 0.9188 - val_mae: 1.3448 - val_mse: 2.7870 - val_pearson_correlation: 1.3125e-16 - val_r2_keras: -97.4123 - val_rmse: 1.6155 - val_sae: 651.5621 - val_sse: 1380.5387 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9670 - loss: 0.9904 - mae: 1.4082 - mse: 3.1109 - pearson_correlation: 2.4532e-16 - r2_keras: -322.3775 - rmse: 1.5649 - sae: 5159.7251 - sse: 10030.7666\n","Epoch 50: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.9454 - loss: 0.9773 - mae: 1.4015 - mse: 2.9719 - pearson_correlation: 2.3115e-16 - r2_keras: -251.8675 - rmse: 1.4745 - sae: 3718.3953 - sse: 7124.5024 - val_huber_loss: 0.8953 - val_loss: 0.9187 - val_mae: 1.3447 - val_mse: 2.7865 - val_pearson_correlation: -1.7939e-16 - val_r2_keras: -97.3983 - val_rmse: 1.6153 - val_sae: 651.5095 - val_sse: 1380.3416 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9669 - loss: 0.9903 - mae: 1.4081 - mse: 3.1105 - pearson_correlation: -1.6817e-16 - r2_keras: -322.3349 - rmse: 1.5648 - sae: 5159.3530 - sse: 10029.4453\n","Epoch 51: val_loss did not improve from 0.26177\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.9453 - loss: 0.9772 - mae: 1.4013 - mse: 2.9714 - pearson_correlation: -2.2724e-16 - r2_keras: -251.8324 - rmse: 1.4744 - sae: 3718.1206 - sse: 7123.5435 - val_huber_loss: 0.8951 - val_loss: 0.9185 - val_mae: 1.3445 - val_mse: 2.7860 - val_pearson_correlation: -2.1879e-17 - val_r2_keras: -97.3843 - val_rmse: 1.6152 - val_sae: 651.4573 - val_sse: 1380.1458 - learning_rate: 1.0000e-05\n","| \u001b[39m6        \u001b[39m | \u001b[39m-0.9185  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m18.74    \u001b[39m | \u001b[39m21.06    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 1.0416 - loss: 1.0655 - mae: 1.4925 - mse: 3.7014 - pearson_correlation: -4.1193e-16 - r2_keras: -619.3718 - rmse: 2.1675 - sae: 7307.8833 - sse: 19243.1582\n","Epoch 1: val_loss improved from inf to 0.36226, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - huber_loss: 1.0273 - loss: 1.0569 - mae: 1.4845 - mse: 3.5057 - pearson_correlation: -4.7759e-16 - r2_keras: -458.0330 - rmse: 1.9211 - sae: 5191.2681 - sse: 13361.9229 - val_huber_loss: 0.3374 - val_loss: 0.3623 - val_mae: 0.7419 - val_mse: 0.8260 - val_pearson_correlation: 6.0180e-16 - val_r2_keras: -23.9157 - val_rmse: 0.8128 - val_sae: 349.0514 - val_sse: 349.5207 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3606 - loss: 0.3855 - mae: 0.7639 - mse: 0.8524 - pearson_correlation: 6.3226e-16 - r2_keras: -102.8079 - rmse: 0.8866 - sae: 2946.5183 - sse: 3219.9912\n","Epoch 2: val_loss improved from 0.36226 to 0.26981, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.2816 - loss: 0.3374 - mae: 0.6885 - mse: 0.7297 - pearson_correlation: 4.6424e-16 - r2_keras: -82.1299 - rmse: 0.8546 - sae: 2122.2915 - sse: 2309.9976 - val_huber_loss: 0.2449 - val_loss: 0.2698 - val_mae: 0.5862 - val_mse: 0.6306 - val_pearson_correlation: 4.8088e-16 - val_r2_keras: -22.4141 - val_rmse: 0.7880 - val_sae: 318.2504 - val_sse: 328.4554 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1648 - loss: 0.1897 - mae: 0.4423 - mse: 0.3814 - pearson_correlation: 6.0132e-16 - r2_keras: -89.5077 - rmse: 0.8279 - sae: 2451.6216 - sse: 2807.4358\n","Epoch 3: val_loss improved from 0.26981 to 0.25210, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.1528 - loss: 0.1824 - mae: 0.4301 - mse: 0.3577 - pearson_correlation: 3.6517e-16 - r2_keras: -73.9834 - rmse: 0.8222 - sae: 1795.0337 - sse: 2043.4093 - val_huber_loss: 0.2272 - val_loss: 0.2521 - val_mae: 0.5391 - val_mse: 0.5941 - val_pearson_correlation: -3.7327e-17 - val_r2_keras: -24.6561 - val_rmse: 0.8248 - val_sae: 310.0552 - val_sse: 359.9061 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1971 - loss: 0.2220 - mae: 0.4989 - mse: 0.4378 - pearson_correlation: 4.1817e-17 - r2_keras: -98.9129 - rmse: 0.8698 - sae: 2635.8987 - sse: 3099.1741\n","Epoch 4: val_loss improved from 0.25210 to 0.19459, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1688 - loss: 0.2048 - mae: 0.4661 - mse: 0.3955 - pearson_correlation: -3.2956e-17 - r2_keras: -80.2896 - rmse: 0.8505 - sae: 1916.8168 - sse: 2238.3247 - val_huber_loss: 0.1698 - val_loss: 0.1946 - val_mae: 0.4418 - val_mse: 0.4235 - val_pearson_correlation: 1.6571e-16 - val_r2_keras: -24.2611 - val_rmse: 0.8185 - val_sae: 313.0857 - val_sse: 354.3648 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1296 - loss: 0.1544 - mae: 0.3588 - mse: 0.2985 - pearson_correlation: 1.4383e-16 - r2_keras: -96.3382 - rmse: 0.8586 - sae: 2486.1074 - sse: 3019.3083\n","Epoch 5: val_loss improved from 0.19459 to 0.17354, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.1173 - loss: 0.1470 - mae: 0.3484 - mse: 0.2764 - pearson_correlation: 1.6016e-16 - r2_keras: -77.7083 - rmse: 0.8349 - sae: 1811.4706 - sse: 2174.9360 - val_huber_loss: 0.1488 - val_loss: 0.1735 - val_mae: 0.4012 - val_mse: 0.3617 - val_pearson_correlation: -1.0058e-17 - val_r2_keras: -25.5640 - val_rmse: 0.8393 - val_sae: 323.7862 - val_sse: 372.6430 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1193 - loss: 0.1440 - mae: 0.3217 - mse: 0.2768 - pearson_correlation: -3.9152e-16 - r2_keras: -101.4262 - rmse: 0.8807 - sae: 2568.6902 - sse: 3177.1335\n","Epoch 6: val_loss improved from 0.17354 to 0.16211, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1098 - loss: 0.1382 - mae: 0.3224 - mse: 0.2583 - pearson_correlation: -2.3030e-16 - r2_keras: -80.8542 - rmse: 0.8473 - sae: 1866.2810 - sse: 2277.2656 - val_huber_loss: 0.1374 - val_loss: 0.1621 - val_mae: 0.3779 - val_mse: 0.3235 - val_pearson_correlation: -8.3876e-18 - val_r2_keras: -27.1209 - val_rmse: 0.8635 - val_sae: 334.2662 - val_sse: 394.4826 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1182 - loss: 0.1429 - mae: 0.3236 - mse: 0.2752 - pearson_correlation: -3.6423e-16 - r2_keras: -102.6865 - rmse: 0.8861 - sae: 2597.9790 - sse: 3216.2256\n","Epoch 7: val_loss improved from 0.16211 to 0.15352, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.1099 - loss: 0.1378 - mae: 0.3274 - mse: 0.2579 - pearson_correlation: -2.8398e-16 - r2_keras: -81.7334 - rmse: 0.8513 - sae: 1888.3204 - sse: 2303.7854 - val_huber_loss: 0.1289 - val_loss: 0.1535 - val_mae: 0.3512 - val_mse: 0.2994 - val_pearson_correlation: 1.8498e-16 - val_r2_keras: -28.0785 - val_rmse: 0.8781 - val_sae: 334.4030 - val_sse: 407.9160 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1131 - loss: 0.1378 - mae: 0.3118 - mse: 0.2627 - pearson_correlation: 1.3066e-16 - r2_keras: -99.3293 - rmse: 0.8717 - sae: 2557.1079 - sse: 3112.0886\n","Epoch 8: val_loss improved from 0.15352 to 0.14848, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1043 - loss: 0.1324 - mae: 0.3102 - mse: 0.2454 - pearson_correlation: 2.9462e-17 - r2_keras: -79.1546 - rmse: 0.8383 - sae: 1856.0316 - sse: 2230.3647 - val_huber_loss: 0.1239 - val_loss: 0.1485 - val_mae: 0.3336 - val_mse: 0.2844 - val_pearson_correlation: -8.5536e-17 - val_r2_keras: -29.1457 - val_rmse: 0.8941 - val_sae: 335.7607 - val_sse: 422.8873 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1091 - loss: 0.1337 - mae: 0.3039 - mse: 0.2496 - pearson_correlation: 5.9597e-19 - r2_keras: -99.0762 - rmse: 0.8706 - sae: 2551.4822 - sse: 3104.2400\n","Epoch 9: val_loss improved from 0.14848 to 0.14337, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.1008 - loss: 0.1287 - mae: 0.3017 - mse: 0.2341 - pearson_correlation: -1.3225e-16 - r2_keras: -78.9714 - rmse: 0.8375 - sae: 1852.1434 - sse: 2224.9619 - val_huber_loss: 0.1188 - val_loss: 0.1434 - val_mae: 0.3221 - val_mse: 0.2683 - val_pearson_correlation: 7.9415e-17 - val_r2_keras: -30.2791 - val_rmse: 0.9107 - val_sae: 341.5519 - val_sse: 438.7860 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1060 - loss: 0.1305 - mae: 0.2990 - mse: 0.2396 - pearson_correlation: -9.6704e-16 - r2_keras: -99.8975 - rmse: 0.8741 - sae: 2564.3616 - sse: 3129.7139\n","Epoch 10: val_loss improved from 0.14337 to 0.13812, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0981 - loss: 0.1257 - mae: 0.2972 - mse: 0.2253 - pearson_correlation: -5.7842e-16 - r2_keras: -79.5219 - rmse: 0.8399 - sae: 1860.8309 - sse: 2241.9795 - val_huber_loss: 0.1136 - val_loss: 0.1381 - val_mae: 0.3122 - val_mse: 0.2541 - val_pearson_correlation: 2.5347e-17 - val_r2_keras: -31.0033 - val_rmse: 0.9212 - val_sae: 346.4258 - val_sse: 448.9452 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1034 - loss: 0.1279 - mae: 0.2965 - mse: 0.2331 - pearson_correlation: 6.3441e-16 - r2_keras: -101.2444 - rmse: 0.8799 - sae: 2583.7314 - sse: 3171.4927\n","Epoch 11: val_loss improved from 0.13812 to 0.13665, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0960 - loss: 0.1234 - mae: 0.2964 - mse: 0.2195 - pearson_correlation: 4.0041e-16 - r2_keras: -80.4800 - rmse: 0.8443 - sae: 1874.3209 - sse: 2270.5378 - val_huber_loss: 0.1122 - val_loss: 0.1367 - val_mae: 0.3111 - val_mse: 0.2493 - val_pearson_correlation: -1.1056e-16 - val_r2_keras: -31.6023 - val_rmse: 0.9298 - val_sae: 349.2040 - val_sse: 457.3483 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1011 - loss: 0.1256 - mae: 0.2907 - mse: 0.2275 - pearson_correlation: -2.5045e-16 - r2_keras: -100.2498 - rmse: 0.8756 - sae: 2573.7739 - sse: 3140.6433\n","Epoch 12: val_loss improved from 0.13665 to 0.13438, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0940 - loss: 0.1212 - mae: 0.2903 - mse: 0.2145 - pearson_correlation: -1.4731e-16 - r2_keras: -79.7459 - rmse: 0.8408 - sae: 1867.1719 - sse: 2249.1387 - val_huber_loss: 0.1100 - val_loss: 0.1344 - val_mae: 0.3064 - val_mse: 0.2424 - val_pearson_correlation: -1.3176e-16 - val_r2_keras: -32.0676 - val_rmse: 0.9364 - val_sae: 352.3326 - val_sse: 463.8763 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0991 - loss: 0.1235 - mae: 0.2874 - mse: 0.2215 - pearson_correlation: -8.4076e-16 - r2_keras: -101.6424 - rmse: 0.8816 - sae: 2587.2871 - sse: 3183.8394\n","Epoch 13: val_loss improved from 0.13438 to 0.13425, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0922 - loss: 0.1193 - mae: 0.2881 - mse: 0.2091 - pearson_correlation: -5.5930e-16 - r2_keras: -80.7659 - rmse: 0.8457 - sae: 1876.8354 - sse: 2279.0103 - val_huber_loss: 0.1099 - val_loss: 0.1342 - val_mae: 0.3103 - val_mse: 0.2412 - val_pearson_correlation: 8.2315e-17 - val_r2_keras: -32.4522 - val_rmse: 0.9419 - val_sae: 354.3407 - val_sse: 469.2711 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0973 - loss: 0.1216 - mae: 0.2827 - mse: 0.2165 - pearson_correlation: -9.6355e-17 - r2_keras: -100.5802 - rmse: 0.8771 - sae: 2577.2627 - sse: 3150.8906\n","Epoch 14: val_loss improved from 0.13425 to 0.13266, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0904 - loss: 0.1175 - mae: 0.2822 - mse: 0.2044 - pearson_correlation: -6.7895e-17 - r2_keras: -80.0212 - rmse: 0.8423 - sae: 1869.7550 - sse: 2256.6160 - val_huber_loss: 0.1084 - val_loss: 0.1327 - val_mae: 0.3054 - val_mse: 0.2371 - val_pearson_correlation: -1.1682e-17 - val_r2_keras: -32.5657 - val_rmse: 0.9435 - val_sae: 355.7732 - val_sse: 470.8632 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0958 - loss: 0.1201 - mae: 0.2815 - mse: 0.2120 - pearson_correlation: 1.5910e-16 - r2_keras: -101.8487 - rmse: 0.8825 - sae: 2590.7351 - sse: 3190.2388\n","Epoch 15: val_loss did not improve from 0.13266\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0891 - loss: 0.1160 - mae: 0.2828 - mse: 0.2002 - pearson_correlation: 1.9774e-16 - r2_keras: -81.0567 - rmse: 0.8477 - sae: 1880.0679 - sse: 2285.0740 - val_huber_loss: 0.1084 - val_loss: 0.1327 - val_mae: 0.3091 - val_mse: 0.2368 - val_pearson_correlation: -1.2803e-16 - val_r2_keras: -32.6462 - val_rmse: 0.9446 - val_sae: 357.1515 - val_sse: 471.9926 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0938 - loss: 0.1180 - mae: 0.2760 - mse: 0.2073 - pearson_correlation: -1.2563e-16 - r2_keras: -100.5357 - rmse: 0.8769 - sae: 2577.7368 - sse: 3149.5103\n","Epoch 16: val_loss improved from 0.13266 to 0.13192, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0873 - loss: 0.1141 - mae: 0.2761 - mse: 0.1960 - pearson_correlation: -7.1805e-17 - r2_keras: -80.1481 - rmse: 0.8437 - sae: 1870.8513 - sse: 2257.5325 - val_huber_loss: 0.1077 - val_loss: 0.1319 - val_mae: 0.3063 - val_mse: 0.2348 - val_pearson_correlation: 2.5363e-16 - val_r2_keras: -32.8452 - val_rmse: 0.9474 - val_sae: 357.8186 - val_sse: 474.7837 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0923 - loss: 0.1165 - mae: 0.2728 - mse: 0.2028 - pearson_correlation: -8.1556e-16 - r2_keras: -101.9105 - rmse: 0.8828 - sae: 2587.9795 - sse: 3192.1538\n","Epoch 17: val_loss improved from 0.13192 to 0.13074, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0861 - loss: 0.1127 - mae: 0.2750 - mse: 0.1919 - pearson_correlation: -5.4312e-16 - r2_keras: -81.1575 - rmse: 0.8485 - sae: 1878.6063 - sse: 2287.0505 - val_huber_loss: 0.1066 - val_loss: 0.1307 - val_mae: 0.3047 - val_mse: 0.2322 - val_pearson_correlation: 1.3848e-16 - val_r2_keras: -32.8188 - val_rmse: 0.9470 - val_sae: 358.9084 - val_sse: 474.4140 - learning_rate: 0.1000\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0909 - loss: 0.1151 - mae: 0.2698 - mse: 0.1996 - pearson_correlation: -9.2036e-18 - r2_keras: -101.7395 - rmse: 0.8821 - sae: 2588.2778 - sse: 3186.8494\n","Epoch 18: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0850 - loss: 0.1114 - mae: 0.2733 - mse: 0.1890 - pearson_correlation: 1.7354e-17 - r2_keras: -81.1982 - rmse: 0.8495 - sae: 1880.0267 - sse: 2285.3296 - val_huber_loss: 0.1072 - val_loss: 0.1312 - val_mae: 0.3084 - val_mse: 0.2328 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.8081 - val_rmse: 0.9469 - val_sae: 360.4902 - val_sse: 474.2634 - learning_rate: 0.1000\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0895 - loss: 0.1136 - mae: 0.2675 - mse: 0.1957 - pearson_correlation: 6.3646e-16 - r2_keras: -101.3618 - rmse: 0.8804 - sae: 2586.2261 - sse: 3175.1338\n","Epoch 19: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0836 - loss: 0.1100 - mae: 0.2703 - mse: 0.1855 - pearson_correlation: 4.6291e-16 - r2_keras: -80.9370 - rmse: 0.8483 - sae: 1878.4501 - sse: 2277.4087 - val_huber_loss: 0.1080 - val_loss: 0.1321 - val_mae: 0.3110 - val_mse: 0.2346 - val_pearson_correlation: -1.9389e-16 - val_r2_keras: -33.0750 - val_rmse: 0.9506 - val_sae: 362.2267 - val_sse: 478.0079 - learning_rate: 0.1000\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0879 - loss: 0.1120 - mae: 0.2638 - mse: 0.1911 - pearson_correlation: -3.6768e-16 - r2_keras: -101.7218 - rmse: 0.8820 - sae: 2589.0347 - sse: 3186.3030\n","Epoch 20: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0820 - loss: 0.1084 - mae: 0.2650 - mse: 0.1811 - pearson_correlation: -2.3383e-16 - r2_keras: -81.1976 - rmse: 0.8495 - sae: 1879.9749 - sse: 2285.0952 - val_huber_loss: 0.1099 - val_loss: 0.1338 - val_mae: 0.3143 - val_mse: 0.2394 - val_pearson_correlation: -2.3173e-16 - val_r2_keras: -32.7315 - val_rmse: 0.9458 - val_sae: 359.3933 - val_sse: 473.1890 - learning_rate: 0.1000\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0862 - loss: 0.1101 - mae: 0.2637 - mse: 0.1860 - pearson_correlation: 1.5339e-16 - r2_keras: -100.6912 - rmse: 0.8776 - sae: 2573.8672 - sse: 3154.3347\n","Epoch 21: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0804 - loss: 0.1066 - mae: 0.2629 - mse: 0.1765 - pearson_correlation: 8.2885e-17 - r2_keras: -80.5174 - rmse: 0.8466 - sae: 1869.9094 - sse: 2263.8635 - val_huber_loss: 0.1128 - val_loss: 0.1367 - val_mae: 0.3313 - val_mse: 0.2454 - val_pearson_correlation: -9.1687e-17 - val_r2_keras: -32.9677 - val_rmse: 0.9491 - val_sae: 361.3777 - val_sse: 476.5026 - learning_rate: 0.1000\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0855 - loss: 0.1094 - mae: 0.2629 - mse: 0.1832 - pearson_correlation: 2.3887e-16 - r2_keras: -102.0744 - rmse: 0.8835 - sae: 2588.1494 - sse: 3197.2397\n","Epoch 22: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0798 - loss: 0.1059 - mae: 0.2619 - mse: 0.1740 - pearson_correlation: 1.3674e-16 - r2_keras: -81.4558 - rmse: 0.8508 - sae: 1879.6376 - sse: 2292.6582 - val_huber_loss: 0.1144 - val_loss: 0.1383 - val_mae: 0.3368 - val_mse: 0.2495 - val_pearson_correlation: -3.8524e-16 - val_r2_keras: -33.2214 - val_rmse: 0.9526 - val_sae: 363.1331 - val_sse: 480.0614 - learning_rate: 0.1000\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0847 - loss: 0.1086 - mae: 0.2620 - mse: 0.1805 - pearson_correlation: 6.0835e-16 - r2_keras: -103.1114 - rmse: 0.8879 - sae: 2601.5874 - sse: 3229.4062\n","Epoch 23: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0777 - loss: 0.1043 - mae: 0.2618 - mse: 0.1697 - pearson_correlation: 3.5466e-16 - r2_keras: -83.1412 - rmse: 0.8630 - sae: 1894.8514 - sse: 2325.7632 - val_huber_loss: 0.1098 - val_loss: 0.1337 - val_mae: 0.3176 - val_mse: 0.2403 - val_pearson_correlation: -1.3796e-16 - val_r2_keras: -32.8998 - val_rmse: 0.9481 - val_sae: 360.4171 - val_sse: 475.5498 - learning_rate: 0.0200\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0831 - loss: 0.1070 - mae: 0.2593 - mse: 0.1775 - pearson_correlation: 3.8772e-16 - r2_keras: -102.2059 - rmse: 0.8841 - sae: 2591.5210 - sse: 3201.3176\n","Epoch 24: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0765 - loss: 0.1029 - mae: 0.2579 - mse: 0.1671 - pearson_correlation: 2.4789e-16 - r2_keras: -82.3358 - rmse: 0.8586 - sae: 1886.6549 - sse: 2304.6709 - val_huber_loss: 0.1086 - val_loss: 0.1325 - val_mae: 0.3127 - val_mse: 0.2380 - val_pearson_correlation: 9.2802e-17 - val_r2_keras: -32.7058 - val_rmse: 0.9454 - val_sae: 359.2038 - val_sse: 472.8292 - learning_rate: 0.0200\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0825 - loss: 0.1064 - mae: 0.2591 - mse: 0.1762 - pearson_correlation: 2.3920e-16 - r2_keras: -101.5904 - rmse: 0.8814 - sae: 2584.8337 - sse: 3182.2251\n","Epoch 25: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0760 - loss: 0.1024 - mae: 0.2572 - mse: 0.1660 - pearson_correlation: 1.7763e-16 - r2_keras: -81.8377 - rmse: 0.8560 - sae: 1881.6196 - sse: 2290.9136 - val_huber_loss: 0.1082 - val_loss: 0.1320 - val_mae: 0.3101 - val_mse: 0.2371 - val_pearson_correlation: -3.5859e-16 - val_r2_keras: -32.7675 - val_rmse: 0.9463 - val_sae: 359.6158 - val_sse: 473.6935 - learning_rate: 0.0200\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0821 - loss: 0.1060 - mae: 0.2578 - mse: 0.1752 - pearson_correlation: 2.9139e-16 - r2_keras: -101.6554 - rmse: 0.8817 - sae: 2585.5383 - sse: 3184.2427\n","Epoch 26: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0757 - loss: 0.1020 - mae: 0.2560 - mse: 0.1652 - pearson_correlation: 1.4929e-16 - r2_keras: -81.8578 - rmse: 0.8560 - sae: 1881.9271 - sse: 2291.9861 - val_huber_loss: 0.1082 - val_loss: 0.1320 - val_mae: 0.3108 - val_mse: 0.2370 - val_pearson_correlation: -2.2030e-16 - val_r2_keras: -32.7165 - val_rmse: 0.9456 - val_sae: 359.4231 - val_sse: 472.9789 - learning_rate: 0.0200\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0817 - loss: 0.1055 - mae: 0.2572 - mse: 0.1741 - pearson_correlation: 2.8153e-16 - r2_keras: -101.5149 - rmse: 0.8811 - sae: 2583.3916 - sse: 3179.8828\n","Epoch 27: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0753 - loss: 0.1017 - mae: 0.2554 - mse: 0.1643 - pearson_correlation: 1.5013e-16 - r2_keras: -81.7442 - rmse: 0.8554 - sae: 1880.3763 - sse: 2288.8459 - val_huber_loss: 0.1087 - val_loss: 0.1325 - val_mae: 0.3132 - val_mse: 0.2383 - val_pearson_correlation: -4.6427e-17 - val_r2_keras: -32.6944 - val_rmse: 0.9453 - val_sae: 359.3900 - val_sse: 472.6690 - learning_rate: 0.0200\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0814 - loss: 0.1052 - mae: 0.2567 - mse: 0.1733 - pearson_correlation: -2.2644e-16 - r2_keras: -101.4133 - rmse: 0.8807 - sae: 2582.1929 - sse: 3176.7314\n","Epoch 28: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0749 - loss: 0.1012 - mae: 0.2543 - mse: 0.1632 - pearson_correlation: -1.1899e-16 - r2_keras: -81.7408 - rmse: 0.8557 - sae: 1879.9497 - sse: 2287.4990 - val_huber_loss: 0.1087 - val_loss: 0.1325 - val_mae: 0.3139 - val_mse: 0.2381 - val_pearson_correlation: -4.2845e-16 - val_r2_keras: -32.7450 - val_rmse: 0.9460 - val_sae: 359.6504 - val_sse: 473.3786 - learning_rate: 0.0040\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0813 - loss: 0.1051 - mae: 0.2564 - mse: 0.1729 - pearson_correlation: -1.5617e-16 - r2_keras: -101.3158 - rmse: 0.8802 - sae: 2580.8936 - sse: 3173.7080\n","Epoch 29: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0748 - loss: 0.1011 - mae: 0.2541 - mse: 0.1630 - pearson_correlation: -1.3076e-16 - r2_keras: -81.6753 - rmse: 0.8554 - sae: 1879.0846 - sse: 2285.4778 - val_huber_loss: 0.1086 - val_loss: 0.1324 - val_mae: 0.3140 - val_mse: 0.2380 - val_pearson_correlation: 2.7740e-16 - val_r2_keras: -32.7849 - val_rmse: 0.9465 - val_sae: 359.8784 - val_sse: 473.9389 - learning_rate: 0.0040\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0812 - loss: 0.1050 - mae: 0.2563 - mse: 0.1728 - pearson_correlation: 7.7488e-17 - r2_keras: -101.3326 - rmse: 0.8803 - sae: 2581.0420 - sse: 3174.2285\n","Epoch 30: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0747 - loss: 0.1011 - mae: 0.2540 - mse: 0.1628 - pearson_correlation: 1.8705e-16 - r2_keras: -81.6858 - rmse: 0.8555 - sae: 1879.1835 - sse: 2285.8164 - val_huber_loss: 0.1086 - val_loss: 0.1324 - val_mae: 0.3139 - val_mse: 0.2378 - val_pearson_correlation: 4.6149e-17 - val_r2_keras: -32.8246 - val_rmse: 0.9471 - val_sae: 360.0913 - val_sse: 474.4951 - learning_rate: 0.0040\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0811 - loss: 0.1049 - mae: 0.2562 - mse: 0.1726 - pearson_correlation: -5.8898e-16 - r2_keras: -101.3683 - rmse: 0.8805 - sae: 2581.4824 - sse: 3175.3359\n","Epoch 31: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0747 - loss: 0.1010 - mae: 0.2539 - mse: 0.1627 - pearson_correlation: -3.5641e-16 - r2_keras: -81.7104 - rmse: 0.8556 - sae: 1879.4845 - sse: 2286.5640 - val_huber_loss: 0.1086 - val_loss: 0.1324 - val_mae: 0.3140 - val_mse: 0.2378 - val_pearson_correlation: 1.7298e-16 - val_r2_keras: -32.8345 - val_rmse: 0.9472 - val_sae: 360.1604 - val_sse: 474.6341 - learning_rate: 0.0040\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0811 - loss: 0.1049 - mae: 0.2561 - mse: 0.1724 - pearson_correlation: 5.8134e-16 - r2_keras: -101.3840 - rmse: 0.8805 - sae: 2581.6353 - sse: 3175.8242\n","Epoch 32: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0746 - loss: 0.1010 - mae: 0.2539 - mse: 0.1625 - pearson_correlation: 3.8543e-16 - r2_keras: -81.7193 - rmse: 0.8556 - sae: 1879.5824 - sse: 2286.8713 - val_huber_loss: 0.1086 - val_loss: 0.1324 - val_mae: 0.3144 - val_mse: 0.2380 - val_pearson_correlation: -1.1533e-16 - val_r2_keras: -32.8330 - val_rmse: 0.9472 - val_sae: 360.1608 - val_sse: 474.6132 - learning_rate: 0.0040\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0810 - loss: 0.1048 - mae: 0.2560 - mse: 0.1723 - pearson_correlation: -2.9485e-17 - r2_keras: -101.3485 - rmse: 0.8804 - sae: 2581.2031 - sse: 3174.7212\n","Epoch 33: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0745 - loss: 0.1009 - mae: 0.2537 - mse: 0.1623 - pearson_correlation: -1.7527e-17 - r2_keras: -81.7077 - rmse: 0.8556 - sae: 1879.3643 - sse: 2286.2776 - val_huber_loss: 0.1086 - val_loss: 0.1324 - val_mae: 0.3144 - val_mse: 0.2378 - val_pearson_correlation: 1.4980e-16 - val_r2_keras: -32.8512 - val_rmse: 0.9475 - val_sae: 360.2486 - val_sse: 474.8686 - learning_rate: 8.0000e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0810 - loss: 0.1048 - mae: 0.2560 - mse: 0.1722 - pearson_correlation: 2.6015e-17 - r2_keras: -101.3520 - rmse: 0.8804 - sae: 2581.2383 - sse: 3174.8306\n","Epoch 34: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0745 - loss: 0.1009 - mae: 0.2536 - mse: 0.1623 - pearson_correlation: 4.2900e-17 - r2_keras: -81.7100 - rmse: 0.8556 - sae: 1879.3878 - sse: 2286.3496 - val_huber_loss: 0.1086 - val_loss: 0.1324 - val_mae: 0.3143 - val_mse: 0.2377 - val_pearson_correlation: -1.0366e-16 - val_r2_keras: -32.8626 - val_rmse: 0.9476 - val_sae: 360.3048 - val_sse: 475.0282 - learning_rate: 8.0000e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0810 - loss: 0.1048 - mae: 0.2560 - mse: 0.1722 - pearson_correlation: -4.6247e-17 - r2_keras: -101.3556 - rmse: 0.8804 - sae: 2581.2747 - sse: 3174.9426\n","Epoch 35: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1009 - mae: 0.2536 - mse: 0.1623 - pearson_correlation: -6.2777e-17 - r2_keras: -81.7123 - rmse: 0.8556 - sae: 1879.4124 - sse: 2286.4233 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2377 - val_pearson_correlation: -3.5687e-16 - val_r2_keras: -32.8728 - val_rmse: 0.9478 - val_sae: 360.3577 - val_sse: 475.1711 - learning_rate: 8.0000e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0810 - loss: 0.1048 - mae: 0.2560 - mse: 0.1722 - pearson_correlation: -2.8033e-16 - r2_keras: -101.3657 - rmse: 0.8805 - sae: 2581.3945 - sse: 3175.2554\n","Epoch 36: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1623 - pearson_correlation: -2.8911e-16 - r2_keras: -81.7192 - rmse: 0.8557 - sae: 1879.4938 - sse: 2286.6340 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2377 - val_pearson_correlation: 4.7191e-16 - val_r2_keras: -32.8763 - val_rmse: 0.9478 - val_sae: 360.3777 - val_sse: 475.2208 - learning_rate: 8.0000e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0810 - loss: 0.1048 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -6.4156e-17 - r2_keras: -101.3693 - rmse: 0.8805 - sae: 2581.4312 - sse: 3175.3667\n","Epoch 37: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1622 - pearson_correlation: -1.7214e-17 - r2_keras: -81.7213 - rmse: 0.8557 - sae: 1879.5172 - sse: 2286.7048 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2377 - val_pearson_correlation: -2.8775e-16 - val_r2_keras: -32.8767 - val_rmse: 0.9478 - val_sae: 360.3788 - val_sse: 475.2254 - learning_rate: 8.0000e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -2.5432e-17 - r2_keras: -101.3654 - rmse: 0.8805 - sae: 2581.3848 - sse: 3175.2480\n","Epoch 38: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1622 - pearson_correlation: 9.6604e-18 - r2_keras: -81.7212 - rmse: 0.8557 - sae: 1879.5001 - sse: 2286.6538 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2377 - val_pearson_correlation: 2.6467e-16 - val_r2_keras: -32.8815 - val_rmse: 0.9479 - val_sae: 360.4021 - val_sse: 475.2934 - learning_rate: 1.6000e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: 7.2828e-16 - r2_keras: -101.3673 - rmse: 0.8805 - sae: 2581.4062 - sse: 3175.3044\n","Epoch 39: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1622 - pearson_correlation: 4.3761e-16 - r2_keras: -81.7224 - rmse: 0.8557 - sae: 1879.5148 - sse: 2286.6917 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.4958e-16 - val_r2_keras: -32.8846 - val_rmse: 0.9479 - val_sae: 360.4175 - val_sse: 475.3373 - learning_rate: 1.6000e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -3.2598e-16 - r2_keras: -101.3691 - rmse: 0.8805 - sae: 2581.4277 - sse: 3175.3608\n","Epoch 40: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1622 - pearson_correlation: -1.7900e-16 - r2_keras: -81.7236 - rmse: 0.8557 - sae: 1879.5294 - sse: 2286.7297 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -1.0355e-16 - val_r2_keras: -32.8860 - val_rmse: 0.9479 - val_sae: 360.4246 - val_sse: 475.3571 - learning_rate: 1.6000e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -2.2888e-16 - r2_keras: -101.3696 - rmse: 0.8805 - sae: 2581.4329 - sse: 3175.3774\n","Epoch 41: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1622 - pearson_correlation: -1.9624e-16 - r2_keras: -81.7239 - rmse: 0.8557 - sae: 1879.5327 - sse: 2286.7402 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -8.0532e-17 - val_r2_keras: -32.8868 - val_rmse: 0.9480 - val_sae: 360.4285 - val_sse: 475.3682 - learning_rate: 1.6000e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: 7.6467e-16 - r2_keras: -101.3694 - rmse: 0.8805 - sae: 2581.4287 - sse: 3175.3701\n","Epoch 42: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2536 - mse: 0.1622 - pearson_correlation: 5.3426e-16 - r2_keras: -81.7238 - rmse: 0.8557 - sae: 1879.5300 - sse: 2286.7354 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.4955e-16 - val_r2_keras: -32.8879 - val_rmse: 0.9480 - val_sae: 360.4344 - val_sse: 475.3832 - learning_rate: 1.6000e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -2.8667e-16 - r2_keras: -101.3712 - rmse: 0.8805 - sae: 2581.4504 - sse: 3175.4275\n","Epoch 43: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -2.7202e-16 - r2_keras: -81.7255 - rmse: 0.8557 - sae: 1879.5475 - sse: 2286.7795 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 3.2210e-16 - val_r2_keras: -32.8887 - val_rmse: 0.9480 - val_sae: 360.4377 - val_sse: 475.3941 - learning_rate: 3.2000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: 3.0979e-16 - r2_keras: -101.3711 - rmse: 0.8805 - sae: 2581.4482 - sse: 3175.4224\n","Epoch 44: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 2.3208e-16 - r2_keras: -81.7254 - rmse: 0.8557 - sae: 1879.5460 - sse: 2286.7759 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -6.9021e-17 - val_r2_keras: -32.8892 - val_rmse: 0.9480 - val_sae: 360.4397 - val_sse: 475.4008 - learning_rate: 3.2000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -3.1095e-16 - r2_keras: -101.3709 - rmse: 0.8805 - sae: 2581.4463 - sse: 3175.4165\n","Epoch 45: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -1.7643e-16 - r2_keras: -81.7253 - rmse: 0.8557 - sae: 1879.5446 - sse: 2286.7720 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 4.6013e-17 - val_r2_keras: -32.8894 - val_rmse: 0.9480 - val_sae: 360.4407 - val_sse: 475.4045 - learning_rate: 3.2000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -1.6761e-17 - r2_keras: -101.3706 - rmse: 0.8805 - sae: 2581.4429 - sse: 3175.4082\n","Epoch 46: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 1.3311e-17 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5424 - sse: 2286.7664 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.2654e-16 - val_r2_keras: -32.8896 - val_rmse: 0.9480 - val_sae: 360.4413 - val_sse: 475.4065 - learning_rate: 3.2000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -2.1905e-16 - r2_keras: -101.3704 - rmse: 0.8805 - sae: 2581.4409 - sse: 3175.4026\n","Epoch 47: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -1.9820e-16 - r2_keras: -81.7250 - rmse: 0.8557 - sae: 1879.5410 - sse: 2286.7625 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -9.2025e-17 - val_r2_keras: -32.8897 - val_rmse: 0.9480 - val_sae: 360.4419 - val_sse: 475.4080 - learning_rate: 3.2000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: 3.9533e-16 - r2_keras: -101.3704 - rmse: 0.8805 - sae: 2581.4402 - sse: 3175.4019\n","Epoch 48: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 2.2736e-16 - r2_keras: -81.7250 - rmse: 0.8557 - sae: 1879.5410 - sse: 2286.7629 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 2.6457e-16 - val_r2_keras: -32.8899 - val_rmse: 0.9480 - val_sae: 360.4428 - val_sse: 475.4109 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -5.6641e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4407 - sse: 3175.4033\n","Epoch 49: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -4.1593e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5414 - sse: 2286.7639 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -8.0521e-17 - val_r2_keras: -32.8900 - val_rmse: 0.9480 - val_sae: 360.4432 - val_sse: 475.4121 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: 1.1444e-16 - r2_keras: -101.3704 - rmse: 0.8805 - sae: 2581.4399 - sse: 3175.4016\n","Epoch 50: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 2.4129e-17 - r2_keras: -81.7250 - rmse: 0.8557 - sae: 1879.5409 - sse: 2286.7627 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -3.5659e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4436 - val_sse: 475.4134 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: 2.5084e-16 - r2_keras: -101.3704 - rmse: 0.8805 - sae: 2581.4404 - sse: 3175.4028\n","Epoch 51: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 9.5901e-17 - r2_keras: -81.7250 - rmse: 0.8557 - sae: 1879.5411 - sse: 2286.7637 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -1.7254e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4438 - val_sse: 475.4138 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1721 - pearson_correlation: -3.0921e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4409 - sse: 3175.4038\n","Epoch 52: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -2.1360e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5415 - sse: 2286.7642 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.1503e-17 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4438 - val_sse: 475.4138 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -4.1614e-17 - r2_keras: -101.3704 - rmse: 0.8805 - sae: 2581.4399 - sse: 3175.4009\n","Epoch 53: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 1.0004e-18 - r2_keras: -81.7250 - rmse: 0.8557 - sae: 1879.5409 - sse: 2286.7625 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -1.8405e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4441 - val_sse: 475.4144 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 5.6699e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4409 - sse: 3175.4038\n","Epoch 54: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 4.1099e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5416 - sse: 2286.7644 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.1503e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4440 - val_sse: 475.4142 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 5.7855e-16 - r2_keras: -101.3704 - rmse: 0.8805 - sae: 2581.4404 - sse: 3175.4026\n","Epoch 55: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 3.9315e-16 - r2_keras: -81.7250 - rmse: 0.8557 - sae: 1879.5413 - sse: 2286.7634 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -2.1856e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4442 - val_sse: 475.4147 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -3.9533e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4414 - sse: 3175.4053\n","Epoch 56: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -2.1991e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5419 - sse: 2286.7654 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 2.3006e-17 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4440 - val_sse: 475.4142 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 3.1153e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4407 - sse: 3175.4038\n","Epoch 57: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 1.5126e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5414 - sse: 2286.7644 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.7254e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4442 - val_sse: 475.4146 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 1.3756e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4414 - sse: 3175.4058\n","Epoch 58: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 1.3109e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5419 - sse: 2286.7656 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.2653e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4441 - val_sse: 475.4142 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 4.6238e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4407 - sse: 3175.4043\n","Epoch 59: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 2.9122e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5414 - sse: 2286.7646 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -1.2653e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4442 - val_sse: 475.4145 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -4.0978e-16 - r2_keras: -101.3706 - rmse: 0.8805 - sae: 2581.4414 - sse: 3175.4065\n","Epoch 60: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -2.3486e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5420 - sse: 2286.7661 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.4954e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4440 - val_sse: 475.4139 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 5.9531e-17 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4409 - sse: 3175.4048\n","Epoch 61: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 7.7506e-18 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5416 - sse: 2286.7649 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 2.3006e-17 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4442 - val_sse: 475.4142 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -1.7802e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4417 - sse: 3175.4058\n","Epoch 62: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -1.9745e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5421 - sse: 2286.7656 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -8.0521e-17 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4441 - val_sse: 475.4138 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 7.1842e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4412 - sse: 3175.4050\n","Epoch 63: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 4.5765e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5419 - sse: 2286.7651 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: 1.2653e-16 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4439 - val_sse: 475.4134 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -1.8495e-17 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4404 - sse: 3175.4036\n","Epoch 64: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: 8.8803e-17 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5414 - sse: 2286.7642 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -3.4509e-17 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4442 - val_sse: 475.4138 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -4.7105e-16 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4417 - sse: 3175.4062\n","Epoch 65: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -3.4810e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5421 - sse: 2286.7659 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -2.4156e-16 - val_r2_keras: -32.8900 - val_rmse: 0.9480 - val_sae: 360.4440 - val_sse: 475.4132 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: 5.4329e-17 - r2_keras: -101.3705 - rmse: 0.8805 - sae: 2581.4409 - sse: 3175.4048\n","Epoch 66: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -3.1691e-18 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5416 - sse: 2286.7649 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -3.4509e-17 - val_r2_keras: -32.8901 - val_rmse: 0.9480 - val_sae: 360.4442 - val_sse: 475.4136 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0809 - loss: 0.1047 - mae: 0.2559 - mse: 0.1720 - pearson_correlation: -4.3752e-16 - r2_keras: -101.3706 - rmse: 0.8805 - sae: 2581.4419 - sse: 3175.4075\n","Epoch 67: val_loss did not improve from 0.13074\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0745 - loss: 0.1008 - mae: 0.2535 - mse: 0.1621 - pearson_correlation: -2.0865e-16 - r2_keras: -81.7251 - rmse: 0.8557 - sae: 1879.5424 - sse: 2286.7668 - val_huber_loss: 0.1085 - val_loss: 0.1323 - val_mae: 0.3143 - val_mse: 0.2376 - val_pearson_correlation: -2.4156e-16 - val_r2_keras: -32.8900 - val_rmse: 0.9480 - val_sae: 360.4440 - val_sse: 475.4131 - learning_rate: 1.0000e-05\n","| \u001b[39m7        \u001b[39m | \u001b[39m-0.1323  \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m20.47    \u001b[39m | \u001b[39m19.21    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.6457 - loss: 0.6725 - mae: 1.1192 - mse: 1.6020 - pearson_correlation: 7.0349e-16 - r2_keras: -176.5731 - rmse: 1.1596 - sae: 4061.7271 - sse: 5508.0942\n","Epoch 1: val_loss improved from inf to 0.45028, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 469ms/step - huber_loss: 0.5900 - loss: 0.6386 - mae: 1.0749 - mse: 1.5114 - pearson_correlation: 2.7422e-16 - r2_keras: -144.9593 - rmse: 1.1439 - sae: 2954.5540 - sse: 3995.5452 - val_huber_loss: 0.4235 - val_loss: 0.4503 - val_mae: 0.8358 - val_mse: 1.1444 - val_pearson_correlation: -4.2032e-17 - val_r2_keras: -31.0897 - val_rmse: 0.9225 - val_sae: 378.0544 - val_sse: 450.1581 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6414 - loss: 0.6682 - mae: 1.1146 - mse: 1.5890 - pearson_correlation: 2.0805e-16 - r2_keras: -175.3654 - rmse: 1.1557 - sae: 4047.2993 - sse: 5470.6357\n","Epoch 2: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5860 - loss: 0.6345 - mae: 1.0704 - mse: 1.4993 - pearson_correlation: 2.8881e-16 - r2_keras: -144.0014 - rmse: 1.1403 - sae: 2944.2385 - sse: 3968.7803 - val_huber_loss: 0.4877 - val_loss: 0.5145 - val_mae: 0.9186 - val_mse: 1.2487 - val_pearson_correlation: -1.9807e-16 - val_r2_keras: -34.0887 - val_rmse: 0.9646 - val_sae: 419.2268 - val_sse: 492.2276 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6382 - loss: 0.6650 - mae: 1.1111 - mse: 1.5793 - pearson_correlation: 1.9486e-16 - r2_keras: -174.4833 - rmse: 1.1528 - sae: 4036.6538 - sse: 5443.2720\n","Epoch 3: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5831 - loss: 0.6314 - mae: 1.0671 - mse: 1.4902 - pearson_correlation: 1.4360e-16 - r2_keras: -143.2919 - rmse: 1.1375 - sae: 2936.5808 - sse: 3949.1140 - val_huber_loss: 0.5549 - val_loss: 0.5818 - val_mae: 0.9946 - val_mse: 1.3948 - val_pearson_correlation: 4.3169e-17 - val_r2_keras: -38.6621 - val_rmse: 1.0256 - val_sae: 456.0008 - val_sse: 556.3848 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6354 - loss: 0.6623 - mae: 1.1082 - mse: 1.5712 - pearson_correlation: 1.9448e-16 - r2_keras: -173.7445 - rmse: 1.1504 - sae: 4027.6680 - sse: 5420.3564\n","Epoch 4: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5805 - loss: 0.6288 - mae: 1.0642 - mse: 1.4825 - pearson_correlation: 1.9832e-16 - r2_keras: -142.6949 - rmse: 1.1352 - sae: 2930.1028 - sse: 3932.6116 - val_huber_loss: 0.6063 - val_loss: 0.6331 - val_mae: 1.0526 - val_mse: 1.5280 - val_pearson_correlation: -9.4085e-17 - val_r2_keras: -43.0591 - val_rmse: 1.0809 - val_sae: 485.6479 - val_sse: 618.0655 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6330 - loss: 0.6599 - mae: 1.1056 - mse: 1.5640 - pearson_correlation: 1.6044e-16 - r2_keras: -173.0925 - rmse: 1.1482 - sae: 4019.6885 - sse: 5400.1318\n","Epoch 5: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5783 - loss: 0.6265 - mae: 1.0616 - mse: 1.4757 - pearson_correlation: 5.6475e-17 - r2_keras: -142.1671 - rmse: 1.1331 - sae: 2924.3484 - sse: 3918.0359 - val_huber_loss: 0.6393 - val_loss: 0.6661 - val_mae: 1.0858 - val_mse: 1.6293 - val_pearson_correlation: -1.4094e-16 - val_r2_keras: -46.6451 - val_rmse: 1.1240 - val_sae: 506.4996 - val_sse: 668.3702 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6309 - loss: 0.6577 - mae: 1.1033 - mse: 1.5575 - pearson_correlation: -1.8580e-16 - r2_keras: -172.5036 - rmse: 1.1463 - sae: 4012.4487 - sse: 5381.8652\n","Epoch 6: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5762 - loss: 0.6244 - mae: 1.0593 - mse: 1.4695 - pearson_correlation: -1.4687e-16 - r2_keras: -141.6896 - rmse: 1.1313 - sae: 2919.1250 - sse: 3904.8616 - val_huber_loss: 0.6549 - val_loss: 0.6818 - val_mae: 1.0987 - val_mse: 1.6946 - val_pearson_correlation: 3.9940e-16 - val_r2_keras: -49.0013 - val_rmse: 1.1515 - val_sae: 517.0928 - val_sse: 701.4232 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6288 - loss: 0.6557 - mae: 1.1011 - mse: 1.5515 - pearson_correlation: 1.1505e-16 - r2_keras: -171.9623 - rmse: 1.1445 - sae: 4005.7651 - sse: 5365.0757\n","Epoch 7: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5745 - loss: 0.6226 - mae: 1.0573 - mse: 1.4642 - pearson_correlation: 1.5042e-16 - r2_keras: -141.2775 - rmse: 1.1297 - sae: 2914.4331 - sse: 3893.0671 - val_huber_loss: 0.6583 - val_loss: 0.6851 - val_mae: 1.0973 - val_mse: 1.7324 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -50.4775 - val_rmse: 1.1684 - val_sae: 521.0871 - val_sse: 722.1317 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6285 - loss: 0.6553 - mae: 1.1007 - mse: 1.5504 - pearson_correlation: 1.4097e-16 - r2_keras: -171.8614 - rmse: 1.1441 - sae: 4004.5161 - sse: 5361.9453\n","Epoch 8: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5741 - loss: 0.6222 - mae: 1.0569 - mse: 1.4631 - pearson_correlation: 1.7695e-16 - r2_keras: -141.1954 - rmse: 1.1294 - sae: 2913.5315 - sse: 3890.8071 - val_huber_loss: 0.6539 - val_loss: 0.6808 - val_mae: 1.0874 - val_mse: 1.7474 - val_pearson_correlation: -1.2658e-16 - val_r2_keras: -51.2040 - val_rmse: 1.1766 - val_sae: 520.6239 - val_sse: 732.3229 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6281 - loss: 0.6549 - mae: 1.1003 - mse: 1.5493 - pearson_correlation: -1.3766e-16 - r2_keras: -171.7661 - rmse: 1.1438 - sae: 4003.3359 - sse: 5358.9883\n","Epoch 9: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5738 - loss: 0.6219 - mae: 1.0565 - mse: 1.4621 - pearson_correlation: -2.7222e-17 - r2_keras: -141.1179 - rmse: 1.1291 - sae: 2912.6790 - sse: 3888.6716 - val_huber_loss: 0.6465 - val_loss: 0.6733 - val_mae: 1.0763 - val_mse: 1.7475 - val_pearson_correlation: 1.9593e-16 - val_r2_keras: -51.4275 - val_rmse: 1.1791 - val_sae: 518.1193 - val_sse: 735.4590 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6278 - loss: 0.6546 - mae: 1.1000 - mse: 1.5483 - pearson_correlation: 2.7518e-16 - r2_keras: -171.6756 - rmse: 1.1435 - sae: 4002.2136 - sse: 5356.1802\n","Epoch 10: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5735 - loss: 0.6215 - mae: 1.0561 - mse: 1.4611 - pearson_correlation: 8.1723e-18 - r2_keras: -141.0442 - rmse: 1.1288 - sae: 2911.8682 - sse: 3886.6433 - val_huber_loss: 0.6391 - val_loss: 0.6660 - val_mae: 1.0655 - val_mse: 1.7423 - val_pearson_correlation: 2.7999e-17 - val_r2_keras: -51.4076 - val_rmse: 1.1789 - val_sae: 515.4854 - val_sse: 735.1796 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6275 - loss: 0.6543 - mae: 1.0996 - mse: 1.5474 - pearson_correlation: -2.1041e-16 - r2_keras: -171.5891 - rmse: 1.1432 - sae: 4001.1399 - sse: 5353.4971\n","Epoch 11: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5732 - loss: 0.6212 - mae: 1.0558 - mse: 1.4602 - pearson_correlation: -1.7257e-16 - r2_keras: -140.9738 - rmse: 1.1285 - sae: 2911.0923 - sse: 3884.7051 - val_huber_loss: 0.6330 - val_loss: 0.6598 - val_mae: 1.0566 - val_mse: 1.7356 - val_pearson_correlation: -1.1225e-16 - val_r2_keras: -51.2943 - val_rmse: 1.1776 - val_sae: 513.3647 - val_sse: 733.5898 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6271 - loss: 0.6540 - mae: 1.0993 - mse: 1.5464 - pearson_correlation: 3.0330e-18 - r2_keras: -171.5063 - rmse: 1.1430 - sae: 4000.1113 - sse: 5350.9282\n","Epoch 12: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5729 - loss: 0.6209 - mae: 1.0555 - mse: 1.4594 - pearson_correlation: 8.5101e-17 - r2_keras: -140.9090 - rmse: 1.1283 - sae: 2910.3616 - sse: 3882.8801 - val_huber_loss: 0.6285 - val_loss: 0.6554 - val_mae: 1.0500 - val_mse: 1.7301 - val_pearson_correlation: -2.5316e-16 - val_r2_keras: -51.1810 - val_rmse: 1.1763 - val_sae: 511.8931 - val_sse: 732.0008 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6270 - loss: 0.6538 - mae: 1.0991 - mse: 1.5460 - pearson_correlation: 5.2367e-16 - r2_keras: -171.4664 - rmse: 1.1428 - sae: 3999.6155 - sse: 5349.6904\n","Epoch 13: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5728 - loss: 0.6208 - mae: 1.0553 - mse: 1.4590 - pearson_correlation: 3.3527e-16 - r2_keras: -140.8765 - rmse: 1.1282 - sae: 2910.0034 - sse: 3881.9856 - val_huber_loss: 0.6253 - val_loss: 0.6521 - val_mae: 1.0453 - val_mse: 1.7255 - val_pearson_correlation: 1.2685e-16 - val_r2_keras: -51.0780 - val_rmse: 1.1752 - val_sae: 510.8489 - val_sse: 730.5552 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6269 - loss: 0.6537 - mae: 1.0990 - mse: 1.5456 - pearson_correlation: 9.5096e-17 - r2_keras: -171.4279 - rmse: 1.1427 - sae: 3999.1372 - sse: 5348.4971\n","Epoch 14: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5726 - loss: 0.6207 - mae: 1.0552 - mse: 1.4586 - pearson_correlation: -2.8944e-17 - r2_keras: -140.8451 - rmse: 1.1280 - sae: 2909.6575 - sse: 3881.1230 - val_huber_loss: 0.6230 - val_loss: 0.6498 - val_mae: 1.0420 - val_mse: 1.7217 - val_pearson_correlation: 2.2589e-16 - val_r2_keras: -50.9927 - val_rmse: 1.1742 - val_sae: 510.0826 - val_sse: 729.3598 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6267 - loss: 0.6535 - mae: 1.0988 - mse: 1.5451 - pearson_correlation: 1.0521e-16 - r2_keras: -171.3906 - rmse: 1.1426 - sae: 3998.6743 - sse: 5347.3418\n","Epoch 15: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5725 - loss: 0.6205 - mae: 1.0550 - mse: 1.4582 - pearson_correlation: 4.7053e-17 - r2_keras: -140.8148 - rmse: 1.1279 - sae: 2909.3228 - sse: 3880.2881 - val_huber_loss: 0.6215 - val_loss: 0.6483 - val_mae: 1.0397 - val_mse: 1.7189 - val_pearson_correlation: -2.4031e-16 - val_r2_keras: -50.9298 - val_rmse: 1.1735 - val_sae: 509.5476 - val_sse: 728.4771 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.6266 - loss: 0.6534 - mae: 1.0987 - mse: 1.5447 - pearson_correlation: 1.1958e-16 - r2_keras: -171.3545 - rmse: 1.1425 - sae: 3998.2249 - sse: 5346.2207\n","Epoch 16: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5723 - loss: 0.6204 - mae: 1.0549 - mse: 1.4578 - pearson_correlation: 3.8155e-17 - r2_keras: -140.7853 - rmse: 1.1278 - sae: 2908.9978 - sse: 3879.4775 - val_huber_loss: 0.6204 - val_loss: 0.6472 - val_mae: 1.0381 - val_mse: 1.7169 - val_pearson_correlation: 2.8297e-17 - val_r2_keras: -50.8841 - val_rmse: 1.1730 - val_sae: 509.1782 - val_sse: 727.8359 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.6264 - loss: 0.6533 - mae: 1.0985 - mse: 1.5444 - pearson_correlation: -1.5178e-18 - r2_keras: -171.3193 - rmse: 1.1423 - sae: 3997.7876 - sse: 5345.1289\n","Epoch 17: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.5722 - loss: 0.6203 - mae: 1.0547 - mse: 1.4574 - pearson_correlation: -1.2111e-16 - r2_keras: -140.7566 - rmse: 1.1277 - sae: 2908.6816 - sse: 3878.6887 - val_huber_loss: 0.6196 - val_loss: 0.6464 - val_mae: 1.0371 - val_mse: 1.7154 - val_pearson_correlation: -1.8405e-16 - val_r2_keras: -50.8507 - val_rmse: 1.1726 - val_sae: 508.9174 - val_sse: 727.3677 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6263 - loss: 0.6531 - mae: 1.0984 - mse: 1.5440 - pearson_correlation: 1.5922e-16 - r2_keras: -171.2852 - rmse: 1.1422 - sae: 3997.3633 - sse: 5344.0703\n","Epoch 18: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5721 - loss: 0.6201 - mae: 1.0546 - mse: 1.4570 - pearson_correlation: 1.3387e-16 - r2_keras: -140.7288 - rmse: 1.1276 - sae: 2908.3748 - sse: 3877.9231 - val_huber_loss: 0.6191 - val_loss: 0.6459 - val_mae: 1.0363 - val_mse: 1.7142 - val_pearson_correlation: -4.9578e-16 - val_r2_keras: -50.8248 - val_rmse: 1.1723 - val_sae: 508.7169 - val_sse: 727.0045 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6262 - loss: 0.6530 - mae: 1.0982 - mse: 1.5436 - pearson_correlation: -2.5464e-16 - r2_keras: -171.2518 - rmse: 1.1421 - sae: 3996.9482 - sse: 5343.0366\n","Epoch 19: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5720 - loss: 0.6200 - mae: 1.0544 - mse: 1.4567 - pearson_correlation: -1.5590e-16 - r2_keras: -140.7016 - rmse: 1.1275 - sae: 2908.0745 - sse: 3877.1758 - val_huber_loss: 0.6187 - val_loss: 0.6455 - val_mae: 1.0357 - val_mse: 1.7133 - val_pearson_correlation: -5.2431e-16 - val_r2_keras: -50.8047 - val_rmse: 1.1721 - val_sae: 508.5636 - val_sse: 726.7214 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6261 - loss: 0.6529 - mae: 1.0981 - mse: 1.5432 - pearson_correlation: -2.1910e-17 - r2_keras: -171.2193 - rmse: 1.1420 - sae: 3996.5435 - sse: 5342.0269\n","Epoch 20: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5719 - loss: 0.6199 - mae: 1.0543 - mse: 1.4563 - pearson_correlation: -1.0241e-16 - r2_keras: -140.6751 - rmse: 1.1274 - sae: 2907.7815 - sse: 3876.4458 - val_huber_loss: 0.6184 - val_loss: 0.6452 - val_mae: 1.0353 - val_mse: 1.7126 - val_pearson_correlation: 8.5048e-17 - val_r2_keras: -50.7887 - val_rmse: 1.1719 - val_sae: 508.4452 - val_sse: 726.4969 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6259 - loss: 0.6528 - mae: 1.0980 - mse: 1.5429 - pearson_correlation: 3.9053e-17 - r2_keras: -171.1876 - rmse: 1.1419 - sae: 3996.1484 - sse: 5341.0435\n","Epoch 21: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5718 - loss: 0.6198 - mae: 1.0542 - mse: 1.4560 - pearson_correlation: -2.3278e-16 - r2_keras: -140.6492 - rmse: 1.1273 - sae: 2907.4958 - sse: 3875.7346 - val_huber_loss: 0.6182 - val_loss: 0.6450 - val_mae: 1.0350 - val_mse: 1.7120 - val_pearson_correlation: 1.2760e-16 - val_r2_keras: -50.7754 - val_rmse: 1.1717 - val_sae: 508.3497 - val_sse: 726.3113 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6258 - loss: 0.6526 - mae: 1.0979 - mse: 1.5425 - pearson_correlation: 2.4863e-16 - r2_keras: -171.1565 - rmse: 1.1418 - sae: 3995.7617 - sse: 5340.0801\n","Epoch 22: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.5716 - loss: 0.6197 - mae: 1.0541 - mse: 1.4557 - pearson_correlation: 1.0104e-16 - r2_keras: -140.6238 - rmse: 1.1272 - sae: 2907.2161 - sse: 3875.0378 - val_huber_loss: 0.6180 - val_loss: 0.6448 - val_mae: 1.0348 - val_mse: 1.7115 - val_pearson_correlation: 3.2616e-16 - val_r2_keras: -50.7640 - val_rmse: 1.1716 - val_sae: 508.2693 - val_sse: 726.1517 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6257 - loss: 0.6525 - mae: 1.0977 - mse: 1.5422 - pearson_correlation: -1.9571e-16 - r2_keras: -171.1261 - rmse: 1.1417 - sae: 3995.3821 - sse: 5339.1357\n","Epoch 23: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5715 - loss: 0.6195 - mae: 1.0539 - mse: 1.4553 - pearson_correlation: 5.9068e-17 - r2_keras: -140.5990 - rmse: 1.1271 - sae: 2906.9414 - sse: 3874.3550 - val_huber_loss: 0.6178 - val_loss: 0.6446 - val_mae: 1.0346 - val_mse: 1.7110 - val_pearson_correlation: -1.4184e-17 - val_r2_keras: -50.7539 - val_rmse: 1.1715 - val_sae: 508.1991 - val_sse: 726.0092 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.6256 - loss: 0.6524 - mae: 1.0976 - mse: 1.5419 - pearson_correlation: 1.0340e-16 - r2_keras: -171.0963 - rmse: 1.1416 - sae: 3995.0105 - sse: 5338.2109\n","Epoch 24: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5714 - loss: 0.6194 - mae: 1.0538 - mse: 1.4550 - pearson_correlation: 8.2806e-17 - r2_keras: -140.5747 - rmse: 1.1270 - sae: 2906.6726 - sse: 3873.6863 - val_huber_loss: 0.6177 - val_loss: 0.6445 - val_mae: 1.0344 - val_mse: 1.7106 - val_pearson_correlation: 2.5535e-16 - val_r2_keras: -50.7446 - val_rmse: 1.1714 - val_sae: 508.1357 - val_sse: 725.8788 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6255 - loss: 0.6523 - mae: 1.0975 - mse: 1.5415 - pearson_correlation: 4.5644e-16 - r2_keras: -171.0671 - rmse: 1.1415 - sae: 3994.6467 - sse: 5337.3052\n","Epoch 25: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5713 - loss: 0.6193 - mae: 1.0537 - mse: 1.4547 - pearson_correlation: 1.7482e-16 - r2_keras: -140.5508 - rmse: 1.1269 - sae: 2906.4092 - sse: 3873.0310 - val_huber_loss: 0.6175 - val_loss: 0.6443 - val_mae: 1.0342 - val_mse: 1.7102 - val_pearson_correlation: -1.9863e-16 - val_r2_keras: -50.7359 - val_rmse: 1.1713 - val_sae: 508.0768 - val_sse: 725.7566 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6254 - loss: 0.6522 - mae: 1.0974 - mse: 1.5412 - pearson_correlation: -2.7920e-16 - r2_keras: -171.0384 - rmse: 1.1414 - sae: 3994.2888 - sse: 5336.4150\n","Epoch 26: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5712 - loss: 0.6192 - mae: 1.0536 - mse: 1.4544 - pearson_correlation: -2.9713e-16 - r2_keras: -140.5274 - rmse: 1.1268 - sae: 2906.1504 - sse: 3872.3875 - val_huber_loss: 0.6174 - val_loss: 0.6442 - val_mae: 1.0341 - val_mse: 1.7098 - val_pearson_correlation: -1.8447e-16 - val_r2_keras: -50.7276 - val_rmse: 1.1712 - val_sae: 508.0212 - val_sse: 725.6401 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.6253 - loss: 0.6521 - mae: 1.0973 - mse: 1.5409 - pearson_correlation: 7.4522e-17 - r2_keras: -171.0101 - rmse: 1.1413 - sae: 3993.9370 - sse: 5335.5391\n","Epoch 27: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5711 - loss: 0.6191 - mae: 1.0535 - mse: 1.4541 - pearson_correlation: 1.7456e-16 - r2_keras: -140.5044 - rmse: 1.1267 - sae: 2905.8958 - sse: 3871.7542 - val_huber_loss: 0.6173 - val_loss: 0.6441 - val_mae: 1.0339 - val_mse: 1.7094 - val_pearson_correlation: -1.4192e-17 - val_r2_keras: -50.7196 - val_rmse: 1.1711 - val_sae: 507.9680 - val_sse: 725.5281 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6252 - loss: 0.6520 - mae: 1.0971 - mse: 1.5406 - pearson_correlation: 6.1111e-17 - r2_keras: -170.9824 - rmse: 1.1412 - sae: 3993.5918 - sse: 5334.6802\n","Epoch 28: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5710 - loss: 0.6190 - mae: 1.0533 - mse: 1.4538 - pearson_correlation: -7.9530e-17 - r2_keras: -140.4818 - rmse: 1.1266 - sae: 2905.6460 - sse: 3871.1328 - val_huber_loss: 0.6172 - val_loss: 0.6440 - val_mae: 1.0338 - val_mse: 1.7091 - val_pearson_correlation: 9.9359e-17 - val_r2_keras: -50.7118 - val_rmse: 1.1710 - val_sae: 507.9164 - val_sse: 725.4189 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6251 - loss: 0.6519 - mae: 1.0970 - mse: 1.5403 - pearson_correlation: -5.8556e-17 - r2_keras: -170.9552 - rmse: 1.1411 - sae: 3993.2515 - sse: 5333.8350\n","Epoch 29: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5709 - loss: 0.6189 - mae: 1.0532 - mse: 1.4535 - pearson_correlation: -3.9037e-17 - r2_keras: -140.4595 - rmse: 1.1265 - sae: 2905.3997 - sse: 3870.5215 - val_huber_loss: 0.6171 - val_loss: 0.6439 - val_mae: 1.0336 - val_mse: 1.7087 - val_pearson_correlation: -3.5490e-16 - val_r2_keras: -50.7043 - val_rmse: 1.1709 - val_sae: 507.8665 - val_sse: 725.3132 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6250 - loss: 0.6518 - mae: 1.0969 - mse: 1.5400 - pearson_correlation: 1.5032e-17 - r2_keras: -170.9284 - rmse: 1.1411 - sae: 3992.9170 - sse: 5333.0049\n","Epoch 30: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5708 - loss: 0.6188 - mae: 1.0531 - mse: 1.4532 - pearson_correlation: 8.8678e-17 - r2_keras: -140.4377 - rmse: 1.1264 - sae: 2905.1575 - sse: 3869.9211 - val_huber_loss: 0.6170 - val_loss: 0.6438 - val_mae: 1.0335 - val_mse: 1.7084 - val_pearson_correlation: -1.2778e-16 - val_r2_keras: -50.6969 - val_rmse: 1.1709 - val_sae: 507.8174 - val_sse: 725.2092 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6249 - loss: 0.6517 - mae: 1.0968 - mse: 1.5397 - pearson_correlation: 2.2763e-16 - r2_keras: -170.9021 - rmse: 1.1410 - sae: 3992.5879 - sse: 5332.1870\n","Epoch 31: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5707 - loss: 0.6187 - mae: 1.0530 - mse: 1.4530 - pearson_correlation: 5.9208e-17 - r2_keras: -140.4162 - rmse: 1.1263 - sae: 2904.9194 - sse: 3869.3293 - val_huber_loss: 0.6169 - val_loss: 0.6437 - val_mae: 1.0334 - val_mse: 1.7080 - val_pearson_correlation: -8.5198e-17 - val_r2_keras: -50.6896 - val_rmse: 1.1708 - val_sae: 507.7695 - val_sse: 725.1077 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.6248 - loss: 0.6516 - mae: 1.0967 - mse: 1.5394 - pearson_correlation: 2.1632e-16 - r2_keras: -170.8761 - rmse: 1.1409 - sae: 3992.2637 - sse: 5331.3813\n","Epoch 32: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5706 - loss: 0.6186 - mae: 1.0529 - mse: 1.4527 - pearson_correlation: 2.5065e-16 - r2_keras: -140.3949 - rmse: 1.1263 - sae: 2904.6848 - sse: 3868.7466 - val_huber_loss: 0.6168 - val_loss: 0.6436 - val_mae: 1.0333 - val_mse: 1.7077 - val_pearson_correlation: -4.2604e-17 - val_r2_keras: -50.6825 - val_rmse: 1.1707 - val_sae: 507.7223 - val_sse: 725.0075 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6247 - loss: 0.6515 - mae: 1.0966 - mse: 1.5391 - pearson_correlation: 8.6529e-17 - r2_keras: -170.8504 - rmse: 1.1408 - sae: 3991.9431 - sse: 5330.5859\n","Epoch 33: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5705 - loss: 0.6185 - mae: 1.0528 - mse: 1.4524 - pearson_correlation: 4.3801e-17 - r2_keras: -140.3740 - rmse: 1.1262 - sae: 2904.4526 - sse: 3868.1711 - val_huber_loss: 0.6167 - val_loss: 0.6435 - val_mae: 1.0331 - val_mse: 1.7074 - val_pearson_correlation: -1.2783e-16 - val_r2_keras: -50.6754 - val_rmse: 1.1706 - val_sae: 507.6758 - val_sse: 724.9088 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6246 - loss: 0.6514 - mae: 1.0965 - mse: 1.5388 - pearson_correlation: 6.6415e-17 - r2_keras: -170.8251 - rmse: 1.1407 - sae: 3991.6270 - sse: 5329.8008\n","Epoch 34: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5704 - loss: 0.6184 - mae: 1.0527 - mse: 1.4521 - pearson_correlation: -4.8302e-17 - r2_keras: -140.3533 - rmse: 1.1261 - sae: 2904.2239 - sse: 3867.6035 - val_huber_loss: 0.6166 - val_loss: 0.6434 - val_mae: 1.0330 - val_mse: 1.7070 - val_pearson_correlation: -2.9830e-16 - val_r2_keras: -50.6685 - val_rmse: 1.1705 - val_sae: 507.6299 - val_sse: 724.8114 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.6245 - loss: 0.6513 - mae: 1.0964 - mse: 1.5386 - pearson_correlation: 1.1867e-17 - r2_keras: -170.8002 - rmse: 1.1406 - sae: 3991.3154 - sse: 5329.0264\n","Epoch 35: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.5704 - loss: 0.6184 - mae: 1.0526 - mse: 1.4519 - pearson_correlation: -5.6900e-17 - r2_keras: -140.3330 - rmse: 1.1260 - sae: 2903.9985 - sse: 3867.0435 - val_huber_loss: 0.6165 - val_loss: 0.6433 - val_mae: 1.0329 - val_mse: 1.7067 - val_pearson_correlation: 1.7048e-16 - val_r2_keras: -50.6617 - val_rmse: 1.1705 - val_sae: 507.5848 - val_sse: 724.7156 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.6244 - loss: 0.6512 - mae: 1.0963 - mse: 1.5383 - pearson_correlation: -1.8016e-16 - r2_keras: -170.7755 - rmse: 1.1405 - sae: 3991.0073 - sse: 5328.2617\n","Epoch 36: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5703 - loss: 0.6183 - mae: 1.0525 - mse: 1.4516 - pearson_correlation: -1.2937e-16 - r2_keras: -140.3128 - rmse: 1.1259 - sae: 2903.7756 - sse: 3866.4905 - val_huber_loss: 0.6164 - val_loss: 0.6432 - val_mae: 1.0328 - val_mse: 1.7064 - val_pearson_correlation: -3.4100e-16 - val_r2_keras: -50.6549 - val_rmse: 1.1704 - val_sae: 507.5403 - val_sse: 724.6211 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6243 - loss: 0.6511 - mae: 1.0962 - mse: 1.5380 - pearson_correlation: 6.6307e-17 - r2_keras: -170.7511 - rmse: 1.1405 - sae: 3990.7026 - sse: 5327.5049\n","Epoch 37: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5702 - loss: 0.6182 - mae: 1.0524 - mse: 1.4513 - pearson_correlation: 1.1829e-16 - r2_keras: -140.2929 - rmse: 1.1259 - sae: 2903.5552 - sse: 3865.9431 - val_huber_loss: 0.6163 - val_loss: 0.6431 - val_mae: 1.0327 - val_mse: 1.7061 - val_pearson_correlation: 8.5259e-17 - val_r2_keras: -50.6483 - val_rmse: 1.1703 - val_sae: 507.4964 - val_sse: 724.5279 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6242 - loss: 0.6510 - mae: 1.0961 - mse: 1.5378 - pearson_correlation: 5.4269e-17 - r2_keras: -170.7272 - rmse: 1.1404 - sae: 3990.4033 - sse: 5326.7617\n","Epoch 38: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5701 - loss: 0.6181 - mae: 1.0523 - mse: 1.4511 - pearson_correlation: 6.3965e-17 - r2_keras: -140.2734 - rmse: 1.1258 - sae: 2903.3386 - sse: 3865.4058 - val_huber_loss: 0.6162 - val_loss: 0.6430 - val_mae: 1.0326 - val_mse: 1.7058 - val_pearson_correlation: -3.8371e-16 - val_r2_keras: -50.6417 - val_rmse: 1.1702 - val_sae: 507.4529 - val_sse: 724.4356 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6241 - loss: 0.6509 - mae: 1.0960 - mse: 1.5375 - pearson_correlation: -5.5885e-17 - r2_keras: -170.7034 - rmse: 1.1403 - sae: 3990.1069 - sse: 5326.0259\n","Epoch 39: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5700 - loss: 0.6180 - mae: 1.0522 - mse: 1.4508 - pearson_correlation: 4.6107e-17 - r2_keras: -140.2540 - rmse: 1.1257 - sae: 2903.1238 - sse: 3864.8735 - val_huber_loss: 0.6161 - val_loss: 0.6429 - val_mae: 1.0325 - val_mse: 1.7055 - val_pearson_correlation: -2.1320e-16 - val_r2_keras: -50.6352 - val_rmse: 1.1702 - val_sae: 507.4099 - val_sse: 724.3446 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.6240 - loss: 0.6509 - mae: 1.0959 - mse: 1.5372 - pearson_correlation: 7.7073e-17 - r2_keras: -170.6800 - rmse: 1.1402 - sae: 3989.8137 - sse: 5325.2988\n","Epoch 40: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5699 - loss: 0.6179 - mae: 1.0521 - mse: 1.4506 - pearson_correlation: 6.0645e-17 - r2_keras: -140.2349 - rmse: 1.1256 - sae: 2902.9116 - sse: 3864.3477 - val_huber_loss: 0.6160 - val_loss: 0.6428 - val_mae: 1.0323 - val_mse: 1.7052 - val_pearson_correlation: -1.4215e-17 - val_r2_keras: -50.6288 - val_rmse: 1.1701 - val_sae: 507.3675 - val_sse: 724.2545 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6240 - loss: 0.6508 - mae: 1.0958 - mse: 1.5370 - pearson_correlation: -4.7762e-17 - r2_keras: -170.6568 - rmse: 1.1402 - sae: 3989.5239 - sse: 5324.5801\n","Epoch 41: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.5698 - loss: 0.6178 - mae: 1.0520 - mse: 1.4503 - pearson_correlation: 1.5808e-16 - r2_keras: -140.2160 - rmse: 1.1255 - sae: 2902.7021 - sse: 3863.8279 - val_huber_loss: 0.6159 - val_loss: 0.6427 - val_mae: 1.0322 - val_mse: 1.7049 - val_pearson_correlation: 1.4216e-16 - val_r2_keras: -50.6225 - val_rmse: 1.1700 - val_sae: 507.3259 - val_sse: 724.1656 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6239 - loss: 0.6507 - mae: 1.0957 - mse: 1.5367 - pearson_correlation: 2.9922e-16 - r2_keras: -170.6339 - rmse: 1.1401 - sae: 3989.2373 - sse: 5323.8691\n","Epoch 42: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5698 - loss: 0.6177 - mae: 1.0519 - mse: 1.4501 - pearson_correlation: 4.1722e-16 - r2_keras: -140.1973 - rmse: 1.1255 - sae: 2902.4949 - sse: 3863.3137 - val_huber_loss: 0.6158 - val_loss: 0.6426 - val_mae: 1.0321 - val_mse: 1.7046 - val_pearson_correlation: 8.5307e-17 - val_r2_keras: -50.6162 - val_rmse: 1.1699 - val_sae: 507.2848 - val_sse: 724.0776 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6238 - loss: 0.6506 - mae: 1.0956 - mse: 1.5365 - pearson_correlation: -1.7647e-16 - r2_keras: -170.6113 - rmse: 1.1400 - sae: 3988.9541 - sse: 5323.1665\n","Epoch 43: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5697 - loss: 0.6177 - mae: 1.0518 - mse: 1.4498 - pearson_correlation: -3.4467e-16 - r2_keras: -140.1788 - rmse: 1.1254 - sae: 2902.2900 - sse: 3862.8054 - val_huber_loss: 0.6157 - val_loss: 0.6425 - val_mae: 1.0320 - val_mse: 1.7043 - val_pearson_correlation: 1.5641e-16 - val_r2_keras: -50.6100 - val_rmse: 1.1699 - val_sae: 507.2442 - val_sse: 723.9909 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6237 - loss: 0.6505 - mae: 1.0955 - mse: 1.5362 - pearson_correlation: 1.5334e-16 - r2_keras: -170.5890 - rmse: 1.1399 - sae: 3988.6753 - sse: 5322.4756\n","Epoch 44: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5696 - loss: 0.6176 - mae: 1.0517 - mse: 1.4496 - pearson_correlation: 3.7357e-17 - r2_keras: -140.1606 - rmse: 1.1253 - sae: 2902.0881 - sse: 3862.3057 - val_huber_loss: 0.6156 - val_loss: 0.6425 - val_mae: 1.0319 - val_mse: 1.7040 - val_pearson_correlation: -1.9909e-16 - val_r2_keras: -50.6039 - val_rmse: 1.1698 - val_sae: 507.2039 - val_sse: 723.9047 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6236 - loss: 0.6504 - mae: 1.0955 - mse: 1.5360 - pearson_correlation: -1.0444e-16 - r2_keras: -170.5668 - rmse: 1.1399 - sae: 3988.3984 - sse: 5321.7891\n","Epoch 45: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5695 - loss: 0.6175 - mae: 1.0516 - mse: 1.4494 - pearson_correlation: -4.7519e-18 - r2_keras: -140.1425 - rmse: 1.1253 - sae: 2901.8879 - sse: 3861.8091 - val_huber_loss: 0.6156 - val_loss: 0.6424 - val_mae: 1.0318 - val_mse: 1.7038 - val_pearson_correlation: -4.2667e-16 - val_r2_keras: -50.5978 - val_rmse: 1.1697 - val_sae: 507.1641 - val_sse: 723.8195 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.6235 - loss: 0.6503 - mae: 1.0954 - mse: 1.5357 - pearson_correlation: -8.3911e-17 - r2_keras: -170.5450 - rmse: 1.1398 - sae: 3988.1243 - sse: 5321.1104\n","Epoch 46: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5694 - loss: 0.6174 - mae: 1.0516 - mse: 1.4491 - pearson_correlation: -7.4478e-17 - r2_keras: -140.1246 - rmse: 1.1252 - sae: 2901.6897 - sse: 3861.3181 - val_huber_loss: 0.6155 - val_loss: 0.6423 - val_mae: 1.0317 - val_mse: 1.7035 - val_pearson_correlation: 2.4181e-16 - val_r2_keras: -50.5918 - val_rmse: 1.1697 - val_sae: 507.1247 - val_sse: 723.7353 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6234 - loss: 0.6503 - mae: 1.0953 - mse: 1.5355 - pearson_correlation: 3.9174e-19 - r2_keras: -170.5233 - rmse: 1.1397 - sae: 3987.8530 - sse: 5320.4375\n","Epoch 47: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5694 - loss: 0.6173 - mae: 1.0515 - mse: 1.4489 - pearson_correlation: -2.2913e-17 - r2_keras: -140.1069 - rmse: 1.1251 - sae: 2901.4934 - sse: 3860.8313 - val_huber_loss: 0.6154 - val_loss: 0.6422 - val_mae: 1.0316 - val_mse: 1.7032 - val_pearson_correlation: -3.6986e-16 - val_r2_keras: -50.5859 - val_rmse: 1.1696 - val_sae: 507.0857 - val_sse: 723.6520 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.6234 - loss: 0.6502 - mae: 1.0952 - mse: 1.5352 - pearson_correlation: 7.3132e-17 - r2_keras: -170.5018 - rmse: 1.1396 - sae: 3987.5850 - sse: 5319.7725\n","Epoch 48: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5693 - loss: 0.6173 - mae: 1.0514 - mse: 1.4487 - pearson_correlation: 8.1202e-17 - r2_keras: -140.0894 - rmse: 1.1250 - sae: 2901.2996 - sse: 3860.3503 - val_huber_loss: 0.6153 - val_loss: 0.6421 - val_mae: 1.0315 - val_mse: 1.7029 - val_pearson_correlation: -7.1135e-17 - val_r2_keras: -50.5799 - val_rmse: 1.1695 - val_sae: 507.0468 - val_sse: 723.5690 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6233 - loss: 0.6501 - mae: 1.0951 - mse: 1.5350 - pearson_correlation: -3.1911e-17 - r2_keras: -170.4807 - rmse: 1.1396 - sae: 3987.3196 - sse: 5319.1162\n","Epoch 49: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.5692 - loss: 0.6172 - mae: 1.0513 - mse: 1.4484 - pearson_correlation: -2.5910e-17 - r2_keras: -140.0721 - rmse: 1.1250 - sae: 2901.1074 - sse: 3859.8755 - val_huber_loss: 0.6152 - val_loss: 0.6420 - val_mae: 1.0314 - val_mse: 1.7026 - val_pearson_correlation: 1.8497e-16 - val_r2_keras: -50.5741 - val_rmse: 1.1695 - val_sae: 507.0085 - val_sse: 723.4871 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6232 - loss: 0.6500 - mae: 1.0950 - mse: 1.5348 - pearson_correlation: 1.3584e-17 - r2_keras: -170.4597 - rmse: 1.1395 - sae: 3987.0562 - sse: 5318.4648\n","Epoch 50: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.5691 - loss: 0.6171 - mae: 1.0512 - mse: 1.4482 - pearson_correlation: -7.4395e-17 - r2_keras: -140.0550 - rmse: 1.1249 - sae: 2900.9167 - sse: 3859.4043 - val_huber_loss: 0.6151 - val_loss: 0.6420 - val_mae: 1.0313 - val_mse: 1.7024 - val_pearson_correlation: 7.1149e-17 - val_r2_keras: -50.5683 - val_rmse: 1.1694 - val_sae: 506.9705 - val_sse: 723.4061 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.6231 - loss: 0.6499 - mae: 1.0949 - mse: 1.5345 - pearson_correlation: 3.6572e-16 - r2_keras: -170.4388 - rmse: 1.1394 - sae: 3986.7949 - sse: 5317.8169\n","Epoch 51: val_loss did not improve from 0.45028\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5690 - loss: 0.6170 - mae: 1.0511 - mse: 1.4480 - pearson_correlation: 3.2727e-16 - r2_keras: -140.0379 - rmse: 1.1248 - sae: 2900.7278 - sse: 3858.9358 - val_huber_loss: 0.6151 - val_loss: 0.6419 - val_mae: 1.0312 - val_mse: 1.7021 - val_pearson_correlation: 4.1271e-16 - val_r2_keras: -50.5626 - val_rmse: 1.1693 - val_sae: 506.9330 - val_sse: 723.3259 - learning_rate: 1.0000e-05\n","| \u001b[39m8        \u001b[39m | \u001b[39m-0.6419  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m21.5     \u001b[39m | \u001b[39m20.25    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 1.1422 - loss: 1.2334 - mae: 1.5702 - mse: 3.9510 - pearson_correlation: 6.6348e-16 - r2_keras: -436.6549 - rmse: 1.8205 - sae: 5995.5005 - sse: 13575.5088\n","Epoch 1: val_loss improved from inf to 0.59976, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 478ms/step - huber_loss: 1.5285 - loss: 1.4688 - mae: 1.8191 - mse: 5.1571 - pearson_correlation: 4.0385e-16 - r2_keras: -511.5649 - rmse: 2.2630 - sae: 4730.8696 - sse: 11640.2715 - val_huber_loss: 0.5066 - val_loss: 0.5998 - val_mae: 0.9168 - val_mse: 1.1883 - val_pearson_correlation: 4.8251e-16 - val_r2_keras: -34.2240 - val_rmse: 0.9665 - val_sae: 424.6720 - val_sse: 494.1266 - learning_rate: 0.0742\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.2224 - loss: 1.3155 - mae: 1.6581 - mse: 4.0003 - pearson_correlation: -2.5411e-16 - r2_keras: -461.5617 - rmse: 1.8716 - sae: 6400.5610 - sse: 14348.0850\n","Epoch 2: val_loss improved from 0.59976 to 0.46424, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 1.2364 - loss: 1.3241 - mae: 1.6637 - mse: 4.1327 - pearson_correlation: -2.1196e-16 - r2_keras: -434.8975 - rmse: 2.0452 - sae: 4767.2979 - sse: 11061.2393 - val_huber_loss: 0.3707 - val_loss: 0.4642 - val_mae: 0.7537 - val_mse: 0.8149 - val_pearson_correlation: -8.3484e-17 - val_r2_keras: -30.4190 - val_rmse: 0.9128 - val_sae: 418.2561 - val_sse: 440.7489 - learning_rate: 0.0742\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4042 - loss: 0.4977 - mae: 0.7766 - mse: 0.9039 - pearson_correlation: -2.0834e-16 - r2_keras: -116.4394 - rmse: 0.9431 - sae: 2972.4866 - sse: 3642.8235\n","Epoch 3: val_loss did not improve from 0.46424\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.4698 - loss: 0.5377 - mae: 0.8266 - mse: 1.0321 - pearson_correlation: -2.0565e-16 - r2_keras: -130.9547 - rmse: 1.1460 - sae: 2307.1045 - sse: 3058.0034 - val_huber_loss: 0.3912 - val_loss: 0.4847 - val_mae: 0.7858 - val_mse: 0.8507 - val_pearson_correlation: -7.4009e-17 - val_r2_keras: -31.2139 - val_rmse: 0.9243 - val_sae: 426.8673 - val_sse: 451.9008 - learning_rate: 0.0742\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3296 - loss: 0.4231 - mae: 0.6898 - mse: 0.7242 - pearson_correlation: -2.2373e-16 - r2_keras: -107.7798 - rmse: 0.9076 - sae: 2851.3115 - sse: 3374.2124\n","Epoch 4: val_loss improved from 0.46424 to 0.44181, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.3641 - loss: 0.4441 - mae: 0.7143 - mse: 0.7827 - pearson_correlation: -8.8041e-17 - r2_keras: -106.7804 - rmse: 1.0244 - sae: 2157.5886 - sse: 2663.0820 - val_huber_loss: 0.3484 - val_loss: 0.4418 - val_mae: 0.7296 - val_mse: 0.7618 - val_pearson_correlation: 1.1502e-16 - val_r2_keras: -31.1501 - val_rmse: 0.9233 - val_sae: 413.2905 - val_sse: 451.0056 - learning_rate: 0.0742\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2581 - loss: 0.3515 - mae: 0.5629 - mse: 0.5703 - pearson_correlation: 4.3878e-16 - r2_keras: -123.2084 - rmse: 0.9699 - sae: 2917.6555 - sse: 3852.7881\n","Epoch 5: val_loss improved from 0.44181 to 0.43818, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.2457 - loss: 0.3439 - mae: 0.5626 - mse: 0.5474 - pearson_correlation: 3.0941e-16 - r2_keras: -102.2407 - rmse: 0.9658 - sae: 2143.3628 - sse: 2808.2295 - val_huber_loss: 0.3449 - val_loss: 0.4382 - val_mae: 0.7295 - val_mse: 0.7402 - val_pearson_correlation: -1.3319e-16 - val_r2_keras: -31.8434 - val_rmse: 0.9332 - val_sae: 422.4777 - val_sse: 460.7313 - learning_rate: 0.0742\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2008 - loss: 0.2941 - mae: 0.4957 - mse: 0.4355 - pearson_correlation: -7.9260e-16 - r2_keras: -96.8570 - rmse: 0.8609 - sae: 2655.2734 - sse: 3035.4026\n","Epoch 6: val_loss improved from 0.43818 to 0.39679, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.1889 - loss: 0.2868 - mae: 0.4910 - mse: 0.4152 - pearson_correlation: -5.2504e-16 - r2_keras: -85.3665 - rmse: 0.8985 - sae: 1968.4065 - sse: 2271.4399 - val_huber_loss: 0.3036 - val_loss: 0.3968 - val_mae: 0.6784 - val_mse: 0.6406 - val_pearson_correlation: -4.6216e-17 - val_r2_keras: -30.8646 - val_rmse: 0.9192 - val_sae: 420.2864 - val_sse: 446.9996 - learning_rate: 0.0742\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1725 - loss: 0.2657 - mae: 0.4522 - mse: 0.3797 - pearson_correlation: -7.8575e-17 - r2_keras: -74.5568 - rmse: 0.7564 - sae: 2292.4065 - sse: 2343.6780\n","Epoch 7: val_loss improved from 0.39679 to 0.30219, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1670 - loss: 0.2623 - mae: 0.4502 - mse: 0.3689 - pearson_correlation: -3.2096e-17 - r2_keras: -71.5164 - rmse: 0.8366 - sae: 1728.4513 - sse: 1822.2162 - val_huber_loss: 0.2091 - val_loss: 0.3022 - val_mae: 0.5820 - val_mse: 0.4300 - val_pearson_correlation: -2.1713e-16 - val_r2_keras: -31.7194 - val_rmse: 0.9315 - val_sae: 414.3279 - val_sse: 458.9910 - learning_rate: 0.0742\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1333 - loss: 0.2264 - mae: 0.3676 - mse: 0.3015 - pearson_correlation: -5.8985e-16 - r2_keras: -83.3870 - rmse: 0.7994 - sae: 2349.7056 - sse: 2617.5801\n","Epoch 8: val_loss improved from 0.30219 to 0.24617, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.1258 - loss: 0.2218 - mae: 0.3654 - mse: 0.2872 - pearson_correlation: -3.7745e-16 - r2_keras: -69.9344 - rmse: 0.8035 - sae: 1730.5206 - sse: 1917.2084 - val_huber_loss: 0.1532 - val_loss: 0.2462 - val_mae: 0.4407 - val_mse: 0.3112 - val_pearson_correlation: 1.4808e-16 - val_r2_keras: -37.5752 - val_rmse: 1.0114 - val_sae: 412.1212 - val_sse: 541.1369 - learning_rate: 0.0742\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1518 - loss: 0.2448 - mae: 0.4176 - mse: 0.3426 - pearson_correlation: -4.7769e-17 - r2_keras: -127.2807 - rmse: 0.9856 - sae: 3024.9849 - sse: 3979.1055\n","Epoch 9: val_loss did not improve from 0.24617\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1489 - loss: 0.2430 - mae: 0.4225 - mse: 0.3327 - pearson_correlation: 5.8720e-17 - r2_keras: -97.2109 - rmse: 0.9087 - sae: 2172.4949 - sse: 2801.5964 - val_huber_loss: 0.1574 - val_loss: 0.2502 - val_mae: 0.4279 - val_mse: 0.3193 - val_pearson_correlation: -1.2780e-16 - val_r2_keras: -41.0373 - val_rmse: 1.0558 - val_sae: 422.3502 - val_sse: 589.7045 - learning_rate: 0.0742\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1612 - loss: 0.2540 - mae: 0.4469 - mse: 0.3651 - pearson_correlation: 5.1080e-17 - r2_keras: -132.5287 - rmse: 1.0056 - sae: 3095.8794 - sse: 4141.8936\n","Epoch 10: val_loss improved from 0.24617 to 0.23898, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1452 - loss: 0.2443 - mae: 0.4312 - mse: 0.3388 - pearson_correlation: 4.2536e-17 - r2_keras: -102.5935 - rmse: 0.9400 - sae: 2225.7273 - sse: 2932.2200 - val_huber_loss: 0.1463 - val_loss: 0.2390 - val_mae: 0.4296 - val_mse: 0.2993 - val_pearson_correlation: 4.0905e-17 - val_r2_keras: -37.4325 - val_rmse: 1.0095 - val_sae: 406.6568 - val_sse: 539.1354 - learning_rate: 0.0742\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1217 - loss: 0.2144 - mae: 0.3575 - mse: 0.2801 - pearson_correlation: 1.5917e-16 - r2_keras: -97.3151 - rmse: 0.8629 - sae: 2619.7722 - sse: 3049.6121\n","Epoch 11: val_loss improved from 0.23898 to 0.21718, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.1121 - loss: 0.2085 - mae: 0.3463 - mse: 0.2627 - pearson_correlation: 6.6046e-17 - r2_keras: -80.9535 - rmse: 0.8613 - sae: 1911.8043 - sse: 2225.5659 - val_huber_loss: 0.1247 - val_loss: 0.2172 - val_mae: 0.3916 - val_mse: 0.2620 - val_pearson_correlation: 1.9102e-16 - val_r2_keras: -33.2181 - val_rmse: 0.9526 - val_sae: 381.6811 - val_sse: 480.0155 - learning_rate: 0.0742\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1062 - loss: 0.1987 - mae: 0.3184 - mse: 0.2300 - pearson_correlation: 1.9515e-16 - r2_keras: -85.2622 - rmse: 0.8082 - sae: 2415.1187 - sse: 2675.7451\n","Epoch 12: val_loss did not improve from 0.21718\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0979 - loss: 0.1936 - mae: 0.3081 - mse: 0.2166 - pearson_correlation: 1.1298e-16 - r2_keras: -72.3252 - rmse: 0.8197 - sae: 1774.7317 - sse: 1969.3647 - val_huber_loss: 0.1425 - val_loss: 0.2348 - val_mae: 0.4154 - val_mse: 0.3131 - val_pearson_correlation: -1.4437e-16 - val_r2_keras: -30.7892 - val_rmse: 0.9181 - val_sae: 362.9195 - val_sse: 445.9417 - learning_rate: 0.0742\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1165 - loss: 0.2088 - mae: 0.3608 - mse: 0.2427 - pearson_correlation: -1.5300e-16 - r2_keras: -90.7108 - rmse: 0.8334 - sae: 2491.7051 - sse: 2844.7539\n","Epoch 13: val_loss did not improve from 0.21718\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1139 - loss: 0.2072 - mae: 0.3633 - mse: 0.2376 - pearson_correlation: -2.1386e-16 - r2_keras: -77.3662 - rmse: 0.8487 - sae: 1837.6705 - sse: 2098.5598 - val_huber_loss: 0.1795 - val_loss: 0.2717 - val_mae: 0.5057 - val_mse: 0.4040 - val_pearson_correlation: -9.3997e-17 - val_r2_keras: -30.0530 - val_rmse: 0.9075 - val_sae: 361.3971 - val_sse: 435.6142 - learning_rate: 0.0742\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1284 - loss: 0.2206 - mae: 0.4002 - mse: 0.2678 - pearson_correlation: -7.8629e-16 - r2_keras: -90.9557 - rmse: 0.8345 - sae: 2548.0579 - sse: 2852.3496\n","Epoch 14: val_loss did not improve from 0.21718\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1201 - loss: 0.2155 - mae: 0.3921 - mse: 0.2554 - pearson_correlation: -5.5737e-16 - r2_keras: -78.1208 - rmse: 0.8544 - sae: 1877.8508 - sse: 2110.5610 - val_huber_loss: 0.1627 - val_loss: 0.2548 - val_mae: 0.4647 - val_mse: 0.3714 - val_pearson_correlation: 1.3211e-16 - val_r2_keras: -28.6866 - val_rmse: 0.8873 - val_sae: 347.4294 - val_sse: 416.4469 - learning_rate: 0.0742\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1150 - loss: 0.2071 - mae: 0.3618 - mse: 0.2446 - pearson_correlation: -3.5799e-16 - r2_keras: -85.2570 - rmse: 0.8082 - sae: 2447.7778 - sse: 2675.5835\n","Epoch 15: val_loss improved from 0.21718 to 0.21609, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - huber_loss: 0.1048 - loss: 0.2008 - mae: 0.3512 - mse: 0.2294 - pearson_correlation: -2.1837e-16 - r2_keras: -73.3447 - rmse: 0.8286 - sae: 1804.4930 - sse: 1981.2567 - val_huber_loss: 0.1242 - val_loss: 0.2161 - val_mae: 0.3709 - val_mse: 0.2816 - val_pearson_correlation: 4.1895e-17 - val_r2_keras: -29.4062 - val_rmse: 0.8980 - val_sae: 338.7335 - val_sse: 426.5411 - learning_rate: 0.0742\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0974 - loss: 0.1893 - mae: 0.2923 - mse: 0.2130 - pearson_correlation: -1.7985e-16 - r2_keras: -86.0295 - rmse: 0.8118 - sae: 2416.7549 - sse: 2699.5466\n","Epoch 16: val_loss improved from 0.21609 to 0.20111, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0897 - loss: 0.1846 - mae: 0.2872 - mse: 0.2004 - pearson_correlation: -3.0587e-16 - r2_keras: -72.5878 - rmse: 0.8199 - sae: 1775.7225 - sse: 1982.3129 - val_huber_loss: 0.1094 - val_loss: 0.2011 - val_mae: 0.3214 - val_mse: 0.2398 - val_pearson_correlation: 2.4483e-16 - val_r2_keras: -32.6221 - val_rmse: 0.9442 - val_sae: 353.9066 - val_sse: 471.6541 - learning_rate: 0.0742\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0932 - loss: 0.1849 - mae: 0.2764 - mse: 0.2072 - pearson_correlation: -2.4990e-16 - r2_keras: -92.1723 - rmse: 0.8400 - sae: 2482.3784 - sse: 2890.0874\n","Epoch 17: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0869 - loss: 0.1811 - mae: 0.2755 - mse: 0.1960 - pearson_correlation: -1.1214e-16 - r2_keras: -75.9968 - rmse: 0.8324 - sae: 1815.4635 - sse: 2101.2908 - val_huber_loss: 0.1110 - val_loss: 0.2026 - val_mae: 0.3411 - val_mse: 0.2366 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.4492 - val_rmse: 0.9831 - val_sae: 377.4054 - val_sse: 511.3127 - learning_rate: 0.0742\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0955 - loss: 0.1871 - mae: 0.2774 - mse: 0.2115 - pearson_correlation: -2.5967e-16 - r2_keras: -97.1682 - rmse: 0.8622 - sae: 2556.9761 - sse: 3045.0549\n","Epoch 18: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0883 - loss: 0.1826 - mae: 0.2773 - mse: 0.1992 - pearson_correlation: -1.6166e-16 - r2_keras: -79.1832 - rmse: 0.8459 - sae: 1864.8004 - sse: 2202.9111 - val_huber_loss: 0.1128 - val_loss: 0.2042 - val_mae: 0.3478 - val_mse: 0.2405 - val_pearson_correlation: 1.8495e-16 - val_r2_keras: -35.6499 - val_rmse: 0.9858 - val_sae: 379.6197 - val_sse: 514.1292 - learning_rate: 0.0742\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0931 - loss: 0.1845 - mae: 0.2735 - mse: 0.2046 - pearson_correlation: -1.8206e-16 - r2_keras: -96.3050 - rmse: 0.8584 - sae: 2547.6021 - sse: 3018.2808\n","Epoch 19: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0850 - loss: 0.1796 - mae: 0.2702 - mse: 0.1916 - pearson_correlation: 4.6654e-17 - r2_keras: -78.7862 - rmse: 0.8450 - sae: 1858.2147 - sse: 2187.1538 - val_huber_loss: 0.1129 - val_loss: 0.2041 - val_mae: 0.3319 - val_mse: 0.2443 - val_pearson_correlation: 8.6285e-17 - val_r2_keras: -34.3907 - val_rmse: 0.9688 - val_sae: 368.7245 - val_sse: 496.4649 - learning_rate: 0.0742\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0885 - loss: 0.1797 - mae: 0.2681 - mse: 0.1921 - pearson_correlation: 2.5963e-16 - r2_keras: -93.4190 - rmse: 0.8456 - sae: 2504.4573 - sse: 2928.7603\n","Epoch 20: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0809 - loss: 0.1751 - mae: 0.2620 - mse: 0.1800 - pearson_correlation: 1.4825e-16 - r2_keras: -77.2103 - rmse: 0.8396 - sae: 1830.9376 - sse: 2131.5579 - val_huber_loss: 0.1168 - val_loss: 0.2079 - val_mae: 0.3307 - val_mse: 0.2579 - val_pearson_correlation: -2.8960e-16 - val_r2_keras: -32.7397 - val_rmse: 0.9459 - val_sae: 356.3510 - val_sse: 473.3045 - learning_rate: 0.0742\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0875 - loss: 0.1785 - mae: 0.2703 - mse: 0.1864 - pearson_correlation: 4.5465e-16 - r2_keras: -91.5911 - rmse: 0.8374 - sae: 2483.2043 - sse: 2872.0596\n","Epoch 21: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0805 - loss: 0.1743 - mae: 0.2646 - mse: 0.1758 - pearson_correlation: 3.2205e-16 - r2_keras: -76.5719 - rmse: 0.8394 - sae: 1821.0345 - sse: 2100.5632 - val_huber_loss: 0.1244 - val_loss: 0.2153 - val_mae: 0.3561 - val_mse: 0.2791 - val_pearson_correlation: -3.1050e-16 - val_r2_keras: -31.3474 - val_rmse: 0.9262 - val_sae: 349.0590 - val_sse: 453.7726 - learning_rate: 0.0742\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0890 - loss: 0.1799 - mae: 0.2826 - mse: 0.1879 - pearson_correlation: -2.3897e-16 - r2_keras: -89.3414 - rmse: 0.8271 - sae: 2460.3501 - sse: 2802.2786\n","Epoch 22: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0802 - loss: 0.1745 - mae: 0.2746 - mse: 0.1753 - pearson_correlation: -1.9394e-16 - r2_keras: -74.1829 - rmse: 0.8245 - sae: 1800.7084 - sse: 2043.6112 - val_huber_loss: 0.1178 - val_loss: 0.2086 - val_mae: 0.3379 - val_mse: 0.2604 - val_pearson_correlation: 2.3361e-17 - val_r2_keras: -32.5689 - val_rmse: 0.9435 - val_sae: 354.4473 - val_sse: 470.9088 - learning_rate: 0.0148\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0861 - loss: 0.1769 - mae: 0.2676 - mse: 0.1832 - pearson_correlation: 7.7693e-17 - r2_keras: -91.0921 - rmse: 0.8351 - sae: 2476.4990 - sse: 2856.5815\n","Epoch 23: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0780 - loss: 0.1720 - mae: 0.2607 - mse: 0.1712 - pearson_correlation: 6.6736e-17 - r2_keras: -75.6041 - rmse: 0.8322 - sae: 1812.5981 - sse: 2082.7937 - val_huber_loss: 0.1161 - val_loss: 0.2069 - val_mae: 0.3324 - val_mse: 0.2551 - val_pearson_correlation: 2.3927e-16 - val_r2_keras: -33.1065 - val_rmse: 0.9510 - val_sae: 357.6942 - val_sse: 478.4499 - learning_rate: 0.0148\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0853 - loss: 0.1761 - mae: 0.2645 - mse: 0.1819 - pearson_correlation: 4.8999e-16 - r2_keras: -92.0044 - rmse: 0.8392 - sae: 2486.2544 - sse: 2884.8813\n","Epoch 24: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0774 - loss: 0.1713 - mae: 0.2579 - mse: 0.1701 - pearson_correlation: 2.6553e-16 - r2_keras: -76.3326 - rmse: 0.8360 - sae: 1819.7557 - sse: 2103.0713 - val_huber_loss: 0.1153 - val_loss: 0.2061 - val_mae: 0.3298 - val_mse: 0.2524 - val_pearson_correlation: 3.0386e-16 - val_r2_keras: -33.3838 - val_rmse: 0.9549 - val_sae: 359.4507 - val_sse: 482.3390 - learning_rate: 0.0148\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0849 - loss: 0.1757 - mae: 0.2634 - mse: 0.1810 - pearson_correlation: 5.9275e-16 - r2_keras: -92.5220 - rmse: 0.8416 - sae: 2491.6934 - sse: 2900.9365\n","Epoch 25: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0771 - loss: 0.1709 - mae: 0.2568 - mse: 0.1694 - pearson_correlation: 4.4327e-16 - r2_keras: -76.7295 - rmse: 0.8380 - sae: 1823.6851 - sse: 2114.3823 - val_huber_loss: 0.1151 - val_loss: 0.2058 - val_mae: 0.3289 - val_mse: 0.2515 - val_pearson_correlation: -3.3554e-17 - val_r2_keras: -33.5259 - val_rmse: 0.9569 - val_sae: 360.4052 - val_sse: 484.3324 - learning_rate: 0.0148\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0845 - loss: 0.1753 - mae: 0.2626 - mse: 0.1803 - pearson_correlation: 1.5358e-16 - r2_keras: -92.7587 - rmse: 0.8426 - sae: 2494.1167 - sse: 2908.2764\n","Epoch 26: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0768 - loss: 0.1706 - mae: 0.2561 - mse: 0.1687 - pearson_correlation: 1.0924e-16 - r2_keras: -76.9245 - rmse: 0.8391 - sae: 1825.5355 - sse: 2119.7131 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3281 - val_mse: 0.2508 - val_pearson_correlation: -1.6727e-16 - val_r2_keras: -33.5956 - val_rmse: 0.9578 - val_sae: 360.8270 - val_sse: 485.3102 - learning_rate: 0.0148\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0843 - loss: 0.1750 - mae: 0.2620 - mse: 0.1798 - pearson_correlation: 1.9907e-16 - r2_keras: -92.8928 - rmse: 0.8432 - sae: 2495.1719 - sse: 2912.4387\n","Epoch 27: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0764 - loss: 0.1702 - mae: 0.2552 - mse: 0.1680 - pearson_correlation: 1.5729e-16 - r2_keras: -76.9625 - rmse: 0.8390 - sae: 1825.9132 - sse: 2121.8838 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3279 - val_mse: 0.2507 - val_pearson_correlation: 2.2235e-17 - val_r2_keras: -33.6671 - val_rmse: 0.9588 - val_sae: 361.3209 - val_sse: 486.3133 - learning_rate: 0.0030\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0842 - loss: 0.1749 - mae: 0.2619 - mse: 0.1796 - pearson_correlation: -2.3031e-16 - r2_keras: -92.9449 - rmse: 0.8435 - sae: 2495.7673 - sse: 2914.0520\n","Epoch 28: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0764 - loss: 0.1702 - mae: 0.2551 - mse: 0.1679 - pearson_correlation: -1.5059e-16 - r2_keras: -77.0047 - rmse: 0.8392 - sae: 1826.3646 - sse: 2123.0481 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3278 - val_mse: 0.2507 - val_pearson_correlation: -8.8757e-17 - val_r2_keras: -33.7156 - val_rmse: 0.9595 - val_sae: 361.6590 - val_sse: 486.9938 - learning_rate: 0.0030\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0841 - loss: 0.1749 - mae: 0.2617 - mse: 0.1794 - pearson_correlation: 2.1706e-16 - r2_keras: -92.9900 - rmse: 0.8437 - sae: 2496.2764 - sse: 2915.4524\n","Epoch 29: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0763 - loss: 0.1701 - mae: 0.2550 - mse: 0.1677 - pearson_correlation: 1.7710e-16 - r2_keras: -77.0412 - rmse: 0.8394 - sae: 1826.7506 - sse: 2124.0574 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3276 - val_mse: 0.2507 - val_pearson_correlation: -5.5393e-17 - val_r2_keras: -33.7501 - val_rmse: 0.9600 - val_sae: 361.8875 - val_sse: 487.4779 - learning_rate: 0.0030\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0841 - loss: 0.1748 - mae: 0.2616 - mse: 0.1793 - pearson_correlation: 4.9385e-16 - r2_keras: -93.0390 - rmse: 0.8439 - sae: 2496.8245 - sse: 2916.9712\n","Epoch 30: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0763 - loss: 0.1700 - mae: 0.2549 - mse: 0.1676 - pearson_correlation: 4.3226e-16 - r2_keras: -77.0808 - rmse: 0.8396 - sae: 1827.1556 - sse: 2125.1509 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3275 - val_mse: 0.2505 - val_pearson_correlation: 3.3188e-17 - val_r2_keras: -33.7840 - val_rmse: 0.9604 - val_sae: 362.1227 - val_sse: 487.9540 - learning_rate: 0.0030\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0840 - loss: 0.1747 - mae: 0.2614 - mse: 0.1791 - pearson_correlation: -2.9604e-16 - r2_keras: -93.0800 - rmse: 0.8441 - sae: 2497.2483 - sse: 2918.2446\n","Epoch 31: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0762 - loss: 0.1700 - mae: 0.2548 - mse: 0.1675 - pearson_correlation: -1.8854e-16 - r2_keras: -77.1142 - rmse: 0.8398 - sae: 1827.4792 - sse: 2126.0706 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3274 - val_mse: 0.2505 - val_pearson_correlation: -9.9503e-17 - val_r2_keras: -33.7991 - val_rmse: 0.9606 - val_sae: 362.2003 - val_sse: 488.1656 - learning_rate: 0.0030\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0840 - loss: 0.1747 - mae: 0.2613 - mse: 0.1790 - pearson_correlation: -1.9147e-16 - r2_keras: -93.1180 - rmse: 0.8442 - sae: 2497.6353 - sse: 2919.4241\n","Epoch 32: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0762 - loss: 0.1699 - mae: 0.2547 - mse: 0.1673 - pearson_correlation: -1.2961e-16 - r2_keras: -77.1315 - rmse: 0.8398 - sae: 1827.6879 - sse: 2126.7629 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3273 - val_mse: 0.2505 - val_pearson_correlation: -6.6296e-17 - val_r2_keras: -33.8136 - val_rmse: 0.9608 - val_sae: 362.2948 - val_sse: 488.3688 - learning_rate: 5.9340e-04\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0840 - loss: 0.1747 - mae: 0.2613 - mse: 0.1789 - pearson_correlation: -5.2381e-16 - r2_keras: -93.1243 - rmse: 0.8443 - sae: 2497.7065 - sse: 2919.6194\n","Epoch 33: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0762 - loss: 0.1699 - mae: 0.2546 - mse: 0.1673 - pearson_correlation: -4.0808e-16 - r2_keras: -77.1364 - rmse: 0.8399 - sae: 1827.7417 - sse: 2126.9014 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3273 - val_mse: 0.2505 - val_pearson_correlation: 2.2089e-17 - val_r2_keras: -33.8243 - val_rmse: 0.9610 - val_sae: 362.3635 - val_sse: 488.5194 - learning_rate: 5.9340e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2613 - mse: 0.1789 - pearson_correlation: 1.7513e-16 - r2_keras: -93.1301 - rmse: 0.8443 - sae: 2497.7605 - sse: 2919.7996\n","Epoch 34: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2546 - mse: 0.1673 - pearson_correlation: 7.2602e-17 - r2_keras: -77.1412 - rmse: 0.8399 - sae: 1827.7850 - sse: 2127.0315 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3273 - val_mse: 0.2505 - val_pearson_correlation: 2.6498e-16 - val_r2_keras: -33.8321 - val_rmse: 0.9611 - val_sae: 362.4118 - val_sse: 488.6279 - learning_rate: 5.9340e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1789 - pearson_correlation: -4.0338e-16 - r2_keras: -93.1360 - rmse: 0.8443 - sae: 2497.8206 - sse: 2919.9819\n","Epoch 35: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2546 - mse: 0.1672 - pearson_correlation: -2.1790e-16 - r2_keras: -77.1463 - rmse: 0.8399 - sae: 1827.8336 - sse: 2127.1680 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3273 - val_mse: 0.2505 - val_pearson_correlation: -4.4152e-17 - val_r2_keras: -33.8383 - val_rmse: 0.9612 - val_sae: 362.4529 - val_sse: 488.7149 - learning_rate: 5.9340e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1789 - pearson_correlation: 4.4247e-16 - r2_keras: -93.1414 - rmse: 0.8444 - sae: 2497.8755 - sse: 2920.1489\n","Epoch 36: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2546 - mse: 0.1672 - pearson_correlation: 2.6947e-16 - r2_keras: -77.1511 - rmse: 0.8399 - sae: 1827.8793 - sse: 2127.2927 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 2.8695e-16 - val_r2_keras: -33.8419 - val_rmse: 0.9612 - val_sae: 362.4767 - val_sse: 488.7666 - learning_rate: 5.9340e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: 3.4104e-16 - r2_keras: -93.1458 - rmse: 0.8444 - sae: 2497.9175 - sse: 2920.2861\n","Epoch 37: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2546 - mse: 0.1672 - pearson_correlation: 3.1860e-16 - r2_keras: -77.1522 - rmse: 0.8399 - sae: 1827.8977 - sse: 2127.3623 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -8.8280e-17 - val_r2_keras: -33.8451 - val_rmse: 0.9613 - val_sae: 362.4953 - val_sse: 488.8112 - learning_rate: 1.1868e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: -4.8253e-17 - r2_keras: -93.1474 - rmse: 0.8444 - sae: 2497.9314 - sse: 2920.3335\n","Epoch 38: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2546 - mse: 0.1672 - pearson_correlation: 1.1880e-18 - r2_keras: -77.1535 - rmse: 0.8399 - sae: 1827.9087 - sse: 2127.3972 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 8.8272e-17 - val_r2_keras: -33.8473 - val_rmse: 0.9613 - val_sae: 362.5088 - val_sse: 488.8421 - learning_rate: 1.1868e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: -6.0575e-16 - r2_keras: -93.1488 - rmse: 0.8444 - sae: 2497.9458 - sse: 2920.3779\n","Epoch 39: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2546 - mse: 0.1672 - pearson_correlation: -4.1855e-16 - r2_keras: -77.1546 - rmse: 0.8400 - sae: 1827.9200 - sse: 2127.4297 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -1.1033e-17 - val_r2_keras: -33.8490 - val_rmse: 0.9613 - val_sae: 362.5195 - val_sse: 488.8654 - learning_rate: 1.1868e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: 1.3986e-16 - r2_keras: -93.1502 - rmse: 0.8444 - sae: 2497.9597 - sse: 2920.4199\n","Epoch 40: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2545 - mse: 0.1672 - pearson_correlation: 1.0698e-16 - r2_keras: -77.1558 - rmse: 0.8400 - sae: 1827.9310 - sse: 2127.4602 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -3.1995e-16 - val_r2_keras: -33.8502 - val_rmse: 0.9613 - val_sae: 362.5271 - val_sse: 488.8823 - learning_rate: 1.1868e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: -1.6529e-16 - r2_keras: -93.1516 - rmse: 0.8444 - sae: 2497.9741 - sse: 2920.4641\n","Epoch 41: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0761 - loss: 0.1699 - mae: 0.2545 - mse: 0.1672 - pearson_correlation: -7.6837e-17 - r2_keras: -77.1570 - rmse: 0.8400 - sae: 1827.9425 - sse: 2127.4929 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 1.4342e-16 - val_r2_keras: -33.8511 - val_rmse: 0.9613 - val_sae: 362.5318 - val_sse: 488.8947 - learning_rate: 1.1868e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: -2.2657e-16 - r2_keras: -93.1528 - rmse: 0.8444 - sae: 2497.9841 - sse: 2920.5017\n","Epoch 42: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1672 - pearson_correlation: -1.9716e-16 - r2_keras: -77.1576 - rmse: 0.8400 - sae: 1827.9479 - sse: 2127.5149 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 3.3096e-17 - val_r2_keras: -33.8517 - val_rmse: 0.9614 - val_sae: 362.5357 - val_sse: 488.9040 - learning_rate: 2.3736e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: -6.1288e-17 - r2_keras: -93.1531 - rmse: 0.8444 - sae: 2497.9868 - sse: 2920.5105\n","Epoch 43: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -4.1840e-17 - r2_keras: -77.1578 - rmse: 0.8400 - sae: 1827.9501 - sse: 2127.5215 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -2.2064e-16 - val_r2_keras: -33.8522 - val_rmse: 0.9614 - val_sae: 362.5385 - val_sse: 488.9104 - learning_rate: 2.3736e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2612 - mse: 0.1788 - pearson_correlation: -3.4165e-16 - r2_keras: -93.1533 - rmse: 0.8444 - sae: 2497.9897 - sse: 2920.5186\n","Epoch 44: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -2.6014e-16 - r2_keras: -77.1580 - rmse: 0.8400 - sae: 1827.9523 - sse: 2127.5273 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -5.5158e-17 - val_r2_keras: -33.8525 - val_rmse: 0.9614 - val_sae: 362.5403 - val_sse: 488.9148 - learning_rate: 2.3736e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -1.6626e-17 - r2_keras: -93.1536 - rmse: 0.8444 - sae: 2497.9927 - sse: 2920.5278\n","Epoch 45: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -6.1788e-18 - r2_keras: -77.1583 - rmse: 0.8400 - sae: 1827.9546 - sse: 2127.5339 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 8.8252e-17 - val_r2_keras: -33.8527 - val_rmse: 0.9614 - val_sae: 362.5417 - val_sse: 488.9181 - learning_rate: 2.3736e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 7.1393e-17 - r2_keras: -93.1539 - rmse: 0.8444 - sae: 2497.9951 - sse: 2920.5356\n","Epoch 46: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 7.6045e-17 - r2_keras: -77.1585 - rmse: 0.8400 - sae: 1827.9565 - sse: 2127.5398 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 1.4341e-16 - val_r2_keras: -33.8529 - val_rmse: 0.9614 - val_sae: 362.5429 - val_sse: 488.9207 - learning_rate: 2.3736e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -3.1393e-16 - r2_keras: -93.1541 - rmse: 0.8444 - sae: 2497.9973 - sse: 2920.5420\n","Epoch 47: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -1.8673e-16 - r2_keras: -77.1586 - rmse: 0.8400 - sae: 1827.9579 - sse: 2127.5437 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 1.6547e-16 - val_r2_keras: -33.8531 - val_rmse: 0.9614 - val_sae: 362.5437 - val_sse: 488.9228 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -5.1507e-17 - r2_keras: -93.1542 - rmse: 0.8444 - sae: 2497.9988 - sse: 2920.5461\n","Epoch 48: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -9.7123e-17 - r2_keras: -77.1587 - rmse: 0.8400 - sae: 1827.9591 - sse: 2127.5466 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -2.0960e-16 - val_r2_keras: -33.8532 - val_rmse: 0.9614 - val_sae: 362.5442 - val_sse: 488.9240 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 9.4245e-16 - r2_keras: -93.1543 - rmse: 0.8444 - sae: 2497.9995 - sse: 2920.5493\n","Epoch 49: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 5.5276e-16 - r2_keras: -77.1588 - rmse: 0.8400 - sae: 1827.9596 - sse: 2127.5491 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -1.4341e-16 - val_r2_keras: -33.8532 - val_rmse: 0.9614 - val_sae: 362.5447 - val_sse: 488.9251 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 1.0334e-16 - r2_keras: -93.1544 - rmse: 0.8444 - sae: 2498.0005 - sse: 2920.5525\n","Epoch 50: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 5.1274e-18 - r2_keras: -77.1589 - rmse: 0.8400 - sae: 1827.9604 - sse: 2127.5515 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -3.3094e-17 - val_r2_keras: -33.8533 - val_rmse: 0.9614 - val_sae: 362.5451 - val_sse: 488.9260 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 3.7098e-16 - r2_keras: -93.1545 - rmse: 0.8444 - sae: 2498.0020 - sse: 2920.5554\n","Epoch 51: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 2.0808e-16 - r2_keras: -77.1590 - rmse: 0.8400 - sae: 1827.9615 - sse: 2127.5537 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -9.9281e-17 - val_r2_keras: -33.8534 - val_rmse: 0.9614 - val_sae: 362.5454 - val_sse: 488.9267 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 2.2135e-16 - r2_keras: -93.1546 - rmse: 0.8444 - sae: 2498.0032 - sse: 2920.5591\n","Epoch 52: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 1.6326e-16 - r2_keras: -77.1590 - rmse: 0.8400 - sae: 1827.9625 - sse: 2127.5564 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -8.8250e-17 - val_r2_keras: -33.8534 - val_rmse: 0.9614 - val_sae: 362.5457 - val_sse: 488.9275 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 2.9339e-18 - r2_keras: -93.1547 - rmse: 0.8444 - sae: 2498.0034 - sse: 2920.5615\n","Epoch 53: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 2.8443e-17 - r2_keras: -77.1591 - rmse: 0.8400 - sae: 1827.9629 - sse: 2127.5583 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -5.5156e-17 - val_r2_keras: -33.8535 - val_rmse: 0.9614 - val_sae: 362.5461 - val_sse: 488.9281 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -3.0448e-16 - r2_keras: -93.1548 - rmse: 0.8444 - sae: 2498.0046 - sse: 2920.5649\n","Epoch 54: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -1.6669e-16 - r2_keras: -77.1592 - rmse: 0.8400 - sae: 1827.9637 - sse: 2127.5608 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -6.6187e-17 - val_r2_keras: -33.8535 - val_rmse: 0.9614 - val_sae: 362.5463 - val_sse: 488.9286 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 5.3137e-17 - r2_keras: -93.1549 - rmse: 0.8444 - sae: 2498.0059 - sse: 2920.5684\n","Epoch 55: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 1.0815e-19 - r2_keras: -77.1593 - rmse: 0.8400 - sae: 1827.9647 - sse: 2127.5632 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 2.6475e-16 - val_r2_keras: -33.8535 - val_rmse: 0.9614 - val_sae: 362.5467 - val_sse: 488.9293 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 3.1230e-16 - r2_keras: -93.1550 - rmse: 0.8444 - sae: 2498.0063 - sse: 2920.5708\n","Epoch 56: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 1.2579e-16 - r2_keras: -77.1594 - rmse: 0.8400 - sae: 1827.9652 - sse: 2127.5652 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -2.8681e-16 - val_r2_keras: -33.8536 - val_rmse: 0.9614 - val_sae: 362.5468 - val_sse: 488.9297 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 5.5418e-17 - r2_keras: -93.1551 - rmse: 0.8444 - sae: 2498.0073 - sse: 2920.5740\n","Epoch 57: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -1.7991e-17 - r2_keras: -77.1595 - rmse: 0.8400 - sae: 1827.9659 - sse: 2127.5674 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -5.5156e-17 - val_r2_keras: -33.8536 - val_rmse: 0.9614 - val_sae: 362.5471 - val_sse: 488.9302 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -1.3561e-16 - r2_keras: -93.1552 - rmse: 0.8444 - sae: 2498.0085 - sse: 2920.5771\n","Epoch 58: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -2.0757e-17 - r2_keras: -77.1596 - rmse: 0.8400 - sae: 1827.9669 - sse: 2127.5698 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 1.1031e-16 - val_r2_keras: -33.8536 - val_rmse: 0.9614 - val_sae: 362.5474 - val_sse: 488.9308 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -2.5753e-17 - r2_keras: -93.1553 - rmse: 0.8444 - sae: 2498.0093 - sse: 2920.5801\n","Epoch 59: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 3.8748e-17 - r2_keras: -77.1597 - rmse: 0.8400 - sae: 1827.9677 - sse: 2127.5720 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -5.5155e-17 - val_r2_keras: -33.8537 - val_rmse: 0.9614 - val_sae: 362.5477 - val_sse: 488.9314 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 5.0202e-17 - r2_keras: -93.1554 - rmse: 0.8444 - sae: 2498.0107 - sse: 2920.5830\n","Epoch 60: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -1.0387e-16 - r2_keras: -77.1597 - rmse: 0.8400 - sae: 1827.9688 - sse: 2127.5742 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -2.4268e-16 - val_r2_keras: -33.8537 - val_rmse: 0.9614 - val_sae: 362.5479 - val_sse: 488.9317 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 3.7489e-17 - r2_keras: -93.1555 - rmse: 0.8444 - sae: 2498.0112 - sse: 2920.5862\n","Epoch 61: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 2.1068e-17 - r2_keras: -77.1598 - rmse: 0.8400 - sae: 1827.9691 - sse: 2127.5767 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -4.4124e-17 - val_r2_keras: -33.8538 - val_rmse: 0.9614 - val_sae: 362.5483 - val_sse: 488.9325 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -9.5188e-17 - r2_keras: -93.1556 - rmse: 0.8444 - sae: 2498.0122 - sse: 2920.5889\n","Epoch 62: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -7.8174e-17 - r2_keras: -77.1599 - rmse: 0.8400 - sae: 1827.9700 - sse: 2127.5786 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 6.6186e-17 - val_r2_keras: -33.8538 - val_rmse: 0.9614 - val_sae: 362.5485 - val_sse: 488.9330 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -1.0813e-15 - r2_keras: -93.1557 - rmse: 0.8444 - sae: 2498.0132 - sse: 2920.5918\n","Epoch 63: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -7.7580e-16 - r2_keras: -77.1600 - rmse: 0.8400 - sae: 1827.9708 - sse: 2127.5808 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 2.2062e-17 - val_r2_keras: -33.8538 - val_rmse: 0.9614 - val_sae: 362.5487 - val_sse: 488.9334 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: -3.4000e-16 - r2_keras: -93.1558 - rmse: 0.8444 - sae: 2498.0142 - sse: 2920.5950\n","Epoch 64: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: -1.4132e-16 - r2_keras: -77.1601 - rmse: 0.8400 - sae: 1827.9716 - sse: 2127.5833 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: 3.8609e-16 - val_r2_keras: -33.8539 - val_rmse: 0.9614 - val_sae: 362.5490 - val_sse: 488.9341 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 3.9444e-17 - r2_keras: -93.1559 - rmse: 0.8444 - sae: 2498.0151 - sse: 2920.5977\n","Epoch 65: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 4.1011e-17 - r2_keras: -77.1601 - rmse: 0.8400 - sae: 1827.9723 - sse: 2127.5852 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -4.4124e-17 - val_r2_keras: -33.8539 - val_rmse: 0.9614 - val_sae: 362.5492 - val_sse: 488.9345 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0839 - loss: 0.1746 - mae: 0.2611 - mse: 0.1788 - pearson_correlation: 4.9876e-16 - r2_keras: -93.1560 - rmse: 0.8444 - sae: 2498.0159 - sse: 2920.6006\n","Epoch 66: val_loss did not improve from 0.20111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0761 - loss: 0.1698 - mae: 0.2545 - mse: 0.1671 - pearson_correlation: 3.4133e-16 - r2_keras: -77.1602 - rmse: 0.8400 - sae: 1827.9730 - sse: 2127.5874 - val_huber_loss: 0.1149 - val_loss: 0.2056 - val_mae: 0.3272 - val_mse: 0.2505 - val_pearson_correlation: -9.9279e-17 - val_r2_keras: -33.8540 - val_rmse: 0.9614 - val_sae: 362.5495 - val_sse: 488.9351 - learning_rate: 1.0000e-05\n","| \u001b[39m9        \u001b[39m | \u001b[39m-0.2056  \u001b[39m | \u001b[39m0.07418  \u001b[39m | \u001b[39m96.27    \u001b[39m | \u001b[39m75.43    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - huber_loss: 0.6388 - loss: 0.7285 - mae: 1.0045 - mse: 1.6677 - pearson_correlation: 1.8309e-16 - r2_keras: -198.8639 - rmse: 1.2303 - sae: 4025.0500 - sse: 6199.5278\n","Epoch 1: val_loss improved from inf to 0.37486, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 479ms/step - huber_loss: 1.0017 - loss: 0.9494 - mae: 1.2493 - mse: 2.6553 - pearson_correlation: 1.1347e-16 - r2_keras: -323.0701 - rmse: 1.7957 - sae: 3330.0107 - sse: 6371.4316 - val_huber_loss: 0.2845 - val_loss: 0.3749 - val_mae: 0.6705 - val_mse: 0.6554 - val_pearson_correlation: -1.6270e-17 - val_r2_keras: -24.3630 - val_rmse: 0.8201 - val_sae: 351.0662 - val_sse: 355.7952 - learning_rate: 0.0361\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.3851 - loss: 0.4755 - mae: 0.6960 - mse: 1.0059 - pearson_correlation: 1.9635e-16 - r2_keras: -177.4165 - rmse: 1.1624 - sae: 3641.3533 - sse: 5534.2578\n","Epoch 2: val_loss improved from 0.37486 to 0.32772, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.3193 - loss: 0.4354 - mae: 0.6640 - mse: 0.8781 - pearson_correlation: 1.1844e-16 - r2_keras: -134.6135 - rmse: 1.0633 - sae: 2615.5352 - sse: 3885.0349 - val_huber_loss: 0.2374 - val_loss: 0.3277 - val_mae: 0.6003 - val_mse: 0.5451 - val_pearson_correlation: -4.5481e-16 - val_r2_keras: -24.0896 - val_rmse: 0.8157 - val_sae: 347.9533 - val_sse: 351.9599 - learning_rate: 0.0361\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1968 - loss: 0.2871 - mae: 0.4811 - mse: 0.4588 - pearson_correlation: -4.3015e-16 - r2_keras: -130.5516 - rmse: 0.9981 - sae: 3051.6667 - sse: 4080.5669\n","Epoch 3: val_loss improved from 0.32772 to 0.30441, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1764 - loss: 0.2747 - mae: 0.4703 - mse: 0.4208 - pearson_correlation: -3.0449e-16 - r2_keras: -107.1540 - rmse: 0.9848 - sae: 2233.3772 - sse: 2960.2913 - val_huber_loss: 0.2141 - val_loss: 0.3044 - val_mae: 0.5502 - val_mse: 0.4879 - val_pearson_correlation: -4.1235e-16 - val_r2_keras: -25.4191 - val_rmse: 0.8370 - val_sae: 348.7029 - val_sse: 370.6101 - learning_rate: 0.0361\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2340 - loss: 0.3244 - mae: 0.5964 - mse: 0.5143 - pearson_correlation: -2.6567e-16 - r2_keras: -131.7311 - rmse: 1.0026 - sae: 3320.1350 - sse: 4117.1528\n","Epoch 4: val_loss improved from 0.30441 to 0.28924, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.3102 - loss: 0.3707 - mae: 0.6374 - mse: 0.6474 - pearson_correlation: -1.2490e-16 - r2_keras: -118.1472 - rmse: 1.0594 - sae: 2450.0554 - sse: 3104.4089 - val_huber_loss: 0.1989 - val_loss: 0.2892 - val_mae: 0.4976 - val_mse: 0.4373 - val_pearson_correlation: -1.2021e-16 - val_r2_keras: -30.1727 - val_rmse: 0.9092 - val_sae: 373.6933 - val_sse: 437.2945 - learning_rate: 0.0361\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2394 - loss: 0.3298 - mae: 0.6185 - mse: 0.4968 - pearson_correlation: 4.4855e-17 - r2_keras: -164.5512 - rmse: 1.1197 - sae: 3766.3345 - sse: 5135.1914\n","Epoch 5: val_loss improved from 0.28924 to 0.27525, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.2383 - loss: 0.3291 - mae: 0.6025 - mse: 0.4960 - pearson_correlation: 7.1646e-17 - r2_keras: -125.7525 - rmse: 1.0323 - sae: 2688.0403 - sse: 3615.6575 - val_huber_loss: 0.1849 - val_loss: 0.2753 - val_mae: 0.4968 - val_mse: 0.4123 - val_pearson_correlation: -3.8786e-16 - val_r2_keras: -27.6061 - val_rmse: 0.8710 - val_sae: 369.0219 - val_sse: 401.2894 - learning_rate: 0.0361\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1228 - loss: 0.2131 - mae: 0.3677 - mse: 0.2528 - pearson_correlation: 5.9464e-16 - r2_keras: -111.1123 - rmse: 0.9214 - sae: 2809.5298 - sse: 3477.5825\n","Epoch 6: val_loss did not improve from 0.27525\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1295 - loss: 0.2172 - mae: 0.3777 - mse: 0.2605 - pearson_correlation: 4.2190e-16 - r2_keras: -94.6799 - rmse: 0.9374 - sae: 2074.5032 - sse: 2563.9963 - val_huber_loss: 0.2814 - val_loss: 0.3718 - val_mae: 0.6497 - val_mse: 0.6542 - val_pearson_correlation: -5.2791e-17 - val_r2_keras: -24.7389 - val_rmse: 0.8262 - val_sae: 356.0102 - val_sse: 361.0674 - learning_rate: 0.0361\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3365 - loss: 0.4268 - mae: 0.7458 - mse: 0.7094 - pearson_correlation: -6.1781e-17 - r2_keras: -110.8566 - rmse: 0.9204 - sae: 3049.7214 - sse: 3469.6514\n","Epoch 7: val_loss did not improve from 0.27525\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3368 - loss: 0.4270 - mae: 0.7419 - mse: 0.7118 - pearson_correlation: -9.8452e-17 - r2_keras: -109.2921 - rmse: 1.0357 - sae: 2305.5825 - sse: 2732.1096 - val_huber_loss: 0.2768 - val_loss: 0.3671 - val_mae: 0.6463 - val_mse: 0.6389 - val_pearson_correlation: -3.0869e-16 - val_r2_keras: -25.5686 - val_rmse: 0.8394 - val_sae: 346.6214 - val_sse: 372.7076 - learning_rate: 0.0361\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.2090 - loss: 0.2993 - mae: 0.5665 - mse: 0.4260 - pearson_correlation: -6.8665e-16 - r2_keras: -96.4865 - rmse: 0.8592 - sae: 2725.0693 - sse: 3023.9087\n","Epoch 8: val_loss improved from 0.27525 to 0.26671, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.1837 - loss: 0.2839 - mae: 0.5353 - mse: 0.3946 - pearson_correlation: -5.2304e-16 - r2_keras: -84.8984 - rmse: 0.8957 - sae: 2017.5809 - sse: 2261.1836 - val_huber_loss: 0.1764 - val_loss: 0.2667 - val_mae: 0.4717 - val_mse: 0.4187 - val_pearson_correlation: -4.3326e-17 - val_r2_keras: -25.0857 - val_rmse: 0.8317 - val_sae: 322.1043 - val_sse: 365.9333 - learning_rate: 0.0361\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0960 - loss: 0.1863 - mae: 0.3261 - mse: 0.2000 - pearson_correlation: -4.4942e-17 - r2_keras: -88.5893 - rmse: 0.8237 - sae: 2478.8687 - sse: 2778.9482\n","Epoch 9: val_loss improved from 0.26671 to 0.23102, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0889 - loss: 0.1819 - mae: 0.3164 - mse: 0.1898 - pearson_correlation: -4.0657e-17 - r2_keras: -75.4042 - rmse: 0.8375 - sae: 1826.4059 - sse: 2048.2654 - val_huber_loss: 0.1408 - val_loss: 0.2310 - val_mae: 0.3740 - val_mse: 0.3407 - val_pearson_correlation: -2.6601e-16 - val_r2_keras: -26.7713 - val_rmse: 0.8582 - val_sae: 320.3141 - val_sse: 389.5790 - learning_rate: 0.0361\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0828 - loss: 0.1730 - mae: 0.2743 - mse: 0.1758 - pearson_correlation: 3.5845e-16 - r2_keras: -90.7618 - rmse: 0.8336 - sae: 2471.3801 - sse: 2846.3364\n","Epoch 10: val_loss improved from 0.23102 to 0.21901, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0759 - loss: 0.1688 - mae: 0.2665 - mse: 0.1653 - pearson_correlation: 2.5752e-16 - r2_keras: -76.2915 - rmse: 0.8393 - sae: 1815.2719 - sse: 2086.6101 - val_huber_loss: 0.1289 - val_loss: 0.2190 - val_mae: 0.3455 - val_mse: 0.3121 - val_pearson_correlation: -2.4224e-16 - val_r2_keras: -28.6002 - val_rmse: 0.8860 - val_sae: 328.1507 - val_sse: 415.2353 - learning_rate: 0.0361\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0812 - loss: 0.1714 - mae: 0.2596 - mse: 0.1729 - pearson_correlation: 8.1164e-17 - r2_keras: -92.4439 - rmse: 0.8412 - sae: 2495.1672 - sse: 2898.5142\n","Epoch 11: val_loss improved from 0.21901 to 0.21628, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0729 - loss: 0.1663 - mae: 0.2523 - mse: 0.1606 - pearson_correlation: 7.4665e-17 - r2_keras: -77.3140 - rmse: 0.8435 - sae: 1829.7721 - sse: 2120.2351 - val_huber_loss: 0.1262 - val_loss: 0.2163 - val_mae: 0.3338 - val_mse: 0.3068 - val_pearson_correlation: 2.6561e-16 - val_r2_keras: -29.7310 - val_rmse: 0.9027 - val_sae: 334.9035 - val_sse: 431.0978 - learning_rate: 0.0361\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0799 - loss: 0.1700 - mae: 0.2555 - mse: 0.1689 - pearson_correlation: -1.6629e-16 - r2_keras: -92.6814 - rmse: 0.8423 - sae: 2501.6226 - sse: 2905.8787\n","Epoch 12: val_loss improved from 0.21628 to 0.21301, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0708 - loss: 0.1644 - mae: 0.2475 - mse: 0.1560 - pearson_correlation: -1.0254e-16 - r2_keras: -77.6190 - rmse: 0.8455 - sae: 1834.5853 - sse: 2126.8657 - val_huber_loss: 0.1230 - val_loss: 0.2130 - val_mae: 0.3223 - val_mse: 0.2965 - val_pearson_correlation: 1.3176e-16 - val_r2_keras: -30.6437 - val_rmse: 0.9160 - val_sae: 341.0743 - val_sse: 443.9011 - learning_rate: 0.0361\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0779 - loss: 0.1679 - mae: 0.2517 - mse: 0.1640 - pearson_correlation: 4.4411e-17 - r2_keras: -93.0661 - rmse: 0.8440 - sae: 2504.2205 - sse: 2917.8125\n","Epoch 13: val_loss improved from 0.21301 to 0.20989, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0686 - loss: 0.1623 - mae: 0.2436 - mse: 0.1510 - pearson_correlation: 1.7705e-17 - r2_keras: -78.0004 - rmse: 0.8477 - sae: 1836.9611 - sse: 2136.2871 - val_huber_loss: 0.1200 - val_loss: 0.2099 - val_mae: 0.3151 - val_mse: 0.2868 - val_pearson_correlation: -1.2687e-16 - val_r2_keras: -31.2249 - val_rmse: 0.9244 - val_sae: 345.4972 - val_sse: 452.0540 - learning_rate: 0.0361\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0763 - loss: 0.1662 - mae: 0.2476 - mse: 0.1599 - pearson_correlation: 3.0555e-16 - r2_keras: -93.1538 - rmse: 0.8444 - sae: 2502.7971 - sse: 2920.5332\n","Epoch 14: val_loss improved from 0.20989 to 0.20820, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0669 - loss: 0.1605 - mae: 0.2397 - mse: 0.1470 - pearson_correlation: 1.9462e-16 - r2_keras: -78.1767 - rmse: 0.8490 - sae: 1836.5588 - sse: 2139.4822 - val_huber_loss: 0.1184 - val_loss: 0.2082 - val_mae: 0.3125 - val_mse: 0.2806 - val_pearson_correlation: -2.9495e-16 - val_r2_keras: -31.7460 - val_rmse: 0.9319 - val_sae: 349.6346 - val_sse: 459.3639 - learning_rate: 0.0361\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0747 - loss: 0.1646 - mae: 0.2434 - mse: 0.1563 - pearson_correlation: -5.4883e-16 - r2_keras: -93.7667 - rmse: 0.8471 - sae: 2508.7920 - sse: 2939.5449\n","Epoch 15: val_loss improved from 0.20820 to 0.20693, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0651 - loss: 0.1587 - mae: 0.2351 - mse: 0.1432 - pearson_correlation: -4.1110e-16 - r2_keras: -78.6385 - rmse: 0.8513 - sae: 1840.6744 - sse: 2152.7808 - val_huber_loss: 0.1172 - val_loss: 0.2069 - val_mae: 0.3095 - val_mse: 0.2758 - val_pearson_correlation: 1.7991e-16 - val_r2_keras: -32.1739 - val_rmse: 0.9379 - val_sae: 352.7760 - val_sse: 465.3666 - learning_rate: 0.0361\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0732 - loss: 0.1629 - mae: 0.2403 - mse: 0.1527 - pearson_correlation: -2.8909e-16 - r2_keras: -94.3593 - rmse: 0.8498 - sae: 2515.7537 - sse: 2957.9255\n","Epoch 16: val_loss improved from 0.20693 to 0.20577, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0636 - loss: 0.1571 - mae: 0.2321 - mse: 0.1397 - pearson_correlation: -1.9992e-16 - r2_keras: -79.1036 - rmse: 0.8537 - sae: 1845.7682 - sse: 2165.8564 - val_huber_loss: 0.1161 - val_loss: 0.2058 - val_mae: 0.3073 - val_mse: 0.2721 - val_pearson_correlation: 8.3022e-17 - val_r2_keras: -32.3769 - val_rmse: 0.9408 - val_sae: 354.3477 - val_sse: 468.2144 - learning_rate: 0.0361\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0721 - loss: 0.1618 - mae: 0.2386 - mse: 0.1504 - pearson_correlation: -5.2909e-16 - r2_keras: -94.1156 - rmse: 0.8487 - sae: 2511.6069 - sse: 2950.3667\n","Epoch 17: val_loss did not improve from 0.20577\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0625 - loss: 0.1560 - mae: 0.2298 - mse: 0.1374 - pearson_correlation: -2.8074e-16 - r2_keras: -79.1195 - rmse: 0.8545 - sae: 1843.7540 - sse: 2162.9089 - val_huber_loss: 0.1164 - val_loss: 0.2060 - val_mae: 0.3097 - val_mse: 0.2719 - val_pearson_correlation: -2.3343e-17 - val_r2_keras: -32.6958 - val_rmse: 0.9453 - val_sae: 356.9879 - val_sse: 472.6889 - learning_rate: 0.0361\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0712 - loss: 0.1608 - mae: 0.2363 - mse: 0.1482 - pearson_correlation: 7.7377e-16 - r2_keras: -94.5284 - rmse: 0.8505 - sae: 2516.4438 - sse: 2963.1719\n","Epoch 18: val_loss improved from 0.20577 to 0.20549, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0613 - loss: 0.1548 - mae: 0.2275 - mse: 0.1349 - pearson_correlation: 5.2923e-16 - r2_keras: -79.3311 - rmse: 0.8552 - sae: 1846.7888 - sse: 2170.6995 - val_huber_loss: 0.1159 - val_loss: 0.2055 - val_mae: 0.3088 - val_mse: 0.2694 - val_pearson_correlation: -8.0690e-17 - val_r2_keras: -32.9411 - val_rmse: 0.9487 - val_sae: 358.4601 - val_sse: 476.1295 - learning_rate: 0.0361\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0699 - loss: 0.1594 - mae: 0.2318 - mse: 0.1453 - pearson_correlation: 1.8894e-16 - r2_keras: -95.3434 - rmse: 0.8542 - sae: 2522.9829 - sse: 2988.4514\n","Epoch 19: val_loss improved from 0.20549 to 0.20497, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0600 - loss: 0.1534 - mae: 0.2236 - mse: 0.1321 - pearson_correlation: 9.0475e-17 - r2_keras: -79.9634 - rmse: 0.8583 - sae: 1851.6539 - sse: 2188.5967 - val_huber_loss: 0.1155 - val_loss: 0.2050 - val_mae: 0.3087 - val_mse: 0.2679 - val_pearson_correlation: 1.2701e-16 - val_r2_keras: -32.8934 - val_rmse: 0.9480 - val_sae: 358.3254 - val_sse: 475.4597 - learning_rate: 0.0361\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0692 - loss: 0.1587 - mae: 0.2313 - mse: 0.1439 - pearson_correlation: -2.7243e-16 - r2_keras: -95.0380 - rmse: 0.8528 - sae: 2518.5635 - sse: 2978.9790\n","Epoch 20: val_loss improved from 0.20497 to 0.20419, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0592 - loss: 0.1526 - mae: 0.2226 - mse: 0.1307 - pearson_correlation: -1.8427e-16 - r2_keras: -79.8016 - rmse: 0.8578 - sae: 1848.7985 - sse: 2182.7717 - val_huber_loss: 0.1148 - val_loss: 0.2042 - val_mae: 0.3033 - val_mse: 0.2655 - val_pearson_correlation: 1.0275e-16 - val_r2_keras: -33.1204 - val_rmse: 0.9512 - val_sae: 360.5131 - val_sse: 478.6453 - learning_rate: 0.0361\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0684 - loss: 0.1578 - mae: 0.2292 - mse: 0.1416 - pearson_correlation: -4.9447e-16 - r2_keras: -95.3771 - rmse: 0.8543 - sae: 2522.5337 - sse: 2989.4973\n","Epoch 21: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0583 - loss: 0.1516 - mae: 0.2203 - mse: 0.1283 - pearson_correlation: -3.3843e-16 - r2_keras: -80.1262 - rmse: 0.8596 - sae: 1851.8844 - sse: 2190.9404 - val_huber_loss: 0.1166 - val_loss: 0.2059 - val_mae: 0.3081 - val_mse: 0.2717 - val_pearson_correlation: -2.3161e-17 - val_r2_keras: -32.8295 - val_rmse: 0.9472 - val_sae: 358.6355 - val_sse: 474.5643 - learning_rate: 0.0361\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0673 - loss: 0.1566 - mae: 0.2270 - mse: 0.1391 - pearson_correlation: -1.9247e-16 - r2_keras: -95.3265 - rmse: 0.8541 - sae: 2521.3037 - sse: 2987.9268\n","Epoch 22: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0574 - loss: 0.1506 - mae: 0.2182 - mse: 0.1262 - pearson_correlation: -1.7036e-16 - r2_keras: -80.1398 - rmse: 0.8599 - sae: 1851.2504 - sse: 2190.4482 - val_huber_loss: 0.1164 - val_loss: 0.2057 - val_mae: 0.3054 - val_mse: 0.2699 - val_pearson_correlation: 1.4901e-16 - val_r2_keras: -33.0024 - val_rmse: 0.9496 - val_sae: 360.2962 - val_sse: 476.9892 - learning_rate: 0.0361\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0664 - loss: 0.1557 - mae: 0.2241 - mse: 0.1373 - pearson_correlation: 3.5715e-17 - r2_keras: -96.2553 - rmse: 0.8582 - sae: 2530.5054 - sse: 3016.7383\n","Epoch 23: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0563 - loss: 0.1495 - mae: 0.2157 - mse: 0.1240 - pearson_correlation: -4.4801e-18 - r2_keras: -80.6218 - rmse: 0.8615 - sae: 1856.9384 - sse: 2208.0471 - val_huber_loss: 0.1164 - val_loss: 0.2055 - val_mae: 0.3086 - val_mse: 0.2676 - val_pearson_correlation: -1.1211e-16 - val_r2_keras: -33.5217 - val_rmse: 0.9568 - val_sae: 362.4730 - val_sse: 484.2745 - learning_rate: 0.0361\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0652 - loss: 0.1544 - mae: 0.2195 - mse: 0.1351 - pearson_correlation: 8.2113e-16 - r2_keras: -97.1167 - rmse: 0.8620 - sae: 2536.5454 - sse: 3043.4565\n","Epoch 24: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0551 - loss: 0.1482 - mae: 0.2119 - mse: 0.1218 - pearson_correlation: 6.0382e-16 - r2_keras: -81.2447 - rmse: 0.8644 - sae: 1860.9688 - sse: 2226.4299 - val_huber_loss: 0.1151 - val_loss: 0.2042 - val_mae: 0.3021 - val_mse: 0.2651 - val_pearson_correlation: -1.8100e-16 - val_r2_keras: -33.3035 - val_rmse: 0.9538 - val_sae: 361.5660 - val_sse: 481.2133 - learning_rate: 0.0361\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0644 - loss: 0.1535 - mae: 0.2178 - mse: 0.1330 - pearson_correlation: 1.0273e-15 - r2_keras: -97.1491 - rmse: 0.8621 - sae: 2536.2480 - sse: 3044.4619\n","Epoch 25: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0542 - loss: 0.1473 - mae: 0.2101 - mse: 0.1197 - pearson_correlation: 6.8049e-16 - r2_keras: -81.3430 - rmse: 0.8652 - sae: 1861.2190 - sse: 2227.9998 - val_huber_loss: 0.1173 - val_loss: 0.2064 - val_mae: 0.3050 - val_mse: 0.2710 - val_pearson_correlation: -2.6213e-16 - val_r2_keras: -33.1226 - val_rmse: 0.9512 - val_sae: 361.1538 - val_sse: 478.6753 - learning_rate: 0.0361\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0635 - loss: 0.1525 - mae: 0.2154 - mse: 0.1307 - pearson_correlation: -1.9196e-16 - r2_keras: -97.7670 - rmse: 0.8648 - sae: 2543.9678 - sse: 3063.6274\n","Epoch 26: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0527 - loss: 0.1459 - mae: 0.2064 - mse: 0.1168 - pearson_correlation: -1.6571e-16 - r2_keras: -81.0484 - rmse: 0.8608 - sae: 1862.4385 - sse: 2232.4895 - val_huber_loss: 0.1161 - val_loss: 0.2051 - val_mae: 0.3018 - val_mse: 0.2664 - val_pearson_correlation: -1.4530e-16 - val_r2_keras: -33.5698 - val_rmse: 0.9575 - val_sae: 363.9130 - val_sse: 484.9496 - learning_rate: 0.0072\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0628 - loss: 0.1518 - mae: 0.2137 - mse: 0.1293 - pearson_correlation: 4.8992e-17 - r2_keras: -98.9388 - rmse: 0.8700 - sae: 2556.9609 - sse: 3099.9761\n","Epoch 27: val_loss did not improve from 0.20419\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0521 - loss: 0.1453 - mae: 0.2049 - mse: 0.1155 - pearson_correlation: 5.2587e-17 - r2_keras: -82.0515 - rmse: 0.8662 - sae: 1872.1847 - sse: 2259.3242 - val_huber_loss: 0.1154 - val_loss: 0.2044 - val_mae: 0.2995 - val_mse: 0.2640 - val_pearson_correlation: 1.5559e-16 - val_r2_keras: -33.7060 - val_rmse: 0.9593 - val_sae: 364.8223 - val_sse: 486.8592 - learning_rate: 0.0072\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0624 - loss: 0.1514 - mae: 0.2129 - mse: 0.1286 - pearson_correlation: -7.2258e-16 - r2_keras: -99.4500 - rmse: 0.8722 - sae: 2562.1021 - sse: 3115.8340\n","Epoch 28: val_loss improved from 0.20419 to 0.20414, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0518 - loss: 0.1450 - mae: 0.2042 - mse: 0.1149 - pearson_correlation: -4.4124e-16 - r2_keras: -82.4907 - rmse: 0.8685 - sae: 1876.0975 - sse: 2271.0498 - val_huber_loss: 0.1152 - val_loss: 0.2041 - val_mae: 0.2980 - val_mse: 0.2630 - val_pearson_correlation: 3.3277e-17 - val_r2_keras: -33.7488 - val_rmse: 0.9599 - val_sae: 365.3129 - val_sse: 487.4598 - learning_rate: 0.0072\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0622 - loss: 0.1511 - mae: 0.2123 - mse: 0.1280 - pearson_correlation: 2.1860e-16 - r2_keras: -99.7503 - rmse: 0.8735 - sae: 2565.1216 - sse: 3125.1477\n","Epoch 29: val_loss improved from 0.20414 to 0.20410, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0516 - loss: 0.1447 - mae: 0.2037 - mse: 0.1144 - pearson_correlation: 1.4752e-16 - r2_keras: -82.7560 - rmse: 0.8700 - sae: 1878.4213 - sse: 2278.0229 - val_huber_loss: 0.1151 - val_loss: 0.2041 - val_mae: 0.2956 - val_mse: 0.2634 - val_pearson_correlation: 3.4668e-16 - val_r2_keras: -33.5676 - val_rmse: 0.9574 - val_sae: 364.3213 - val_sse: 484.9178 - learning_rate: 0.0072\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0620 - loss: 0.1509 - mae: 0.2117 - mse: 0.1275 - pearson_correlation: 4.7215e-16 - r2_keras: -99.9188 - rmse: 0.8742 - sae: 2566.5867 - sse: 3130.3755\n","Epoch 30: val_loss improved from 0.20410 to 0.20397, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0514 - loss: 0.1445 - mae: 0.2032 - mse: 0.1140 - pearson_correlation: 2.7809e-16 - r2_keras: -82.8851 - rmse: 0.8706 - sae: 1879.4926 - sse: 2281.7043 - val_huber_loss: 0.1150 - val_loss: 0.2040 - val_mae: 0.2956 - val_mse: 0.2628 - val_pearson_correlation: 2.6745e-16 - val_r2_keras: -33.6462 - val_rmse: 0.9585 - val_sae: 364.8719 - val_sse: 486.0213 - learning_rate: 0.0072\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0618 - loss: 0.1507 - mae: 0.2112 - mse: 0.1271 - pearson_correlation: 2.2052e-16 - r2_keras: -99.9942 - rmse: 0.8745 - sae: 2567.0332 - sse: 3132.7153\n","Epoch 31: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0513 - loss: 0.1443 - mae: 0.2027 - mse: 0.1136 - pearson_correlation: 1.2024e-16 - r2_keras: -82.9693 - rmse: 0.8711 - sae: 1879.9211 - sse: 2283.6624 - val_huber_loss: 0.1152 - val_loss: 0.2042 - val_mae: 0.2938 - val_mse: 0.2637 - val_pearson_correlation: 1.1223e-17 - val_r2_keras: -33.4895 - val_rmse: 0.9563 - val_sae: 364.0348 - val_sse: 483.8224 - learning_rate: 0.0072\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0616 - loss: 0.1505 - mae: 0.2105 - mse: 0.1268 - pearson_correlation: -8.3744e-17 - r2_keras: -100.1399 - rmse: 0.8752 - sae: 2568.1284 - sse: 3137.2334\n","Epoch 32: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0511 - loss: 0.1441 - mae: 0.2022 - mse: 0.1133 - pearson_correlation: -5.9394e-17 - r2_keras: -83.0867 - rmse: 0.8717 - sae: 1880.7675 - sse: 2286.9124 - val_huber_loss: 0.1151 - val_loss: 0.2040 - val_mae: 0.2946 - val_mse: 0.2627 - val_pearson_correlation: 2.5657e-16 - val_r2_keras: -33.6243 - val_rmse: 0.9582 - val_sae: 364.8816 - val_sse: 485.7140 - learning_rate: 0.0072\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0614 - loss: 0.1504 - mae: 0.2101 - mse: 0.1264 - pearson_correlation: 3.7387e-16 - r2_keras: -100.1769 - rmse: 0.8753 - sae: 2568.1003 - sse: 3138.3799\n","Epoch 33: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0509 - loss: 0.1440 - mae: 0.2017 - mse: 0.1129 - pearson_correlation: 1.9678e-16 - r2_keras: -83.1428 - rmse: 0.8721 - sae: 1880.8588 - sse: 2288.0454 - val_huber_loss: 0.1153 - val_loss: 0.2042 - val_mae: 0.2929 - val_mse: 0.2640 - val_pearson_correlation: 2.8116e-16 - val_r2_keras: -33.4458 - val_rmse: 0.9557 - val_sae: 363.8674 - val_sse: 483.2090 - learning_rate: 0.0072\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0613 - loss: 0.1502 - mae: 0.2095 - mse: 0.1261 - pearson_correlation: 2.2606e-16 - r2_keras: -100.2025 - rmse: 0.8754 - sae: 2568.0376 - sse: 3139.1743\n","Epoch 34: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0508 - loss: 0.1438 - mae: 0.2013 - mse: 0.1126 - pearson_correlation: 2.0942e-16 - r2_keras: -83.1544 - rmse: 0.8721 - sae: 1880.8021 - sse: 2288.5115 - val_huber_loss: 0.1153 - val_loss: 0.2041 - val_mae: 0.2939 - val_mse: 0.2633 - val_pearson_correlation: -7.8266e-17 - val_r2_keras: -33.5729 - val_rmse: 0.9575 - val_sae: 364.6635 - val_sse: 484.9919 - learning_rate: 0.0072\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0612 - loss: 0.1501 - mae: 0.2092 - mse: 0.1259 - pearson_correlation: -6.0540e-16 - r2_keras: -100.2356 - rmse: 0.8756 - sae: 2568.0796 - sse: 3140.2031\n","Epoch 35: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0507 - loss: 0.1437 - mae: 0.2010 - mse: 0.1124 - pearson_correlation: -3.4675e-16 - r2_keras: -83.1998 - rmse: 0.8724 - sae: 1880.9252 - sse: 2289.4697 - val_huber_loss: 0.1157 - val_loss: 0.2046 - val_mae: 0.2925 - val_mse: 0.2650 - val_pearson_correlation: 1.0155e-16 - val_r2_keras: -33.3696 - val_rmse: 0.9547 - val_sae: 363.5250 - val_sse: 482.1406 - learning_rate: 0.0072\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0610 - loss: 0.1499 - mae: 0.2087 - mse: 0.1255 - pearson_correlation: 5.3204e-16 - r2_keras: -100.3165 - rmse: 0.8759 - sae: 2568.9980 - sse: 3142.7109\n","Epoch 36: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0505 - loss: 0.1435 - mae: 0.2003 - mse: 0.1119 - pearson_correlation: 3.7518e-16 - r2_keras: -83.2097 - rmse: 0.8723 - sae: 1881.3165 - sse: 2290.6255 - val_huber_loss: 0.1157 - val_loss: 0.2046 - val_mae: 0.2927 - val_mse: 0.2648 - val_pearson_correlation: 1.4627e-16 - val_r2_keras: -33.4329 - val_rmse: 0.9556 - val_sae: 363.9740 - val_sse: 483.0290 - learning_rate: 0.0014\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0610 - loss: 0.1499 - mae: 0.2087 - mse: 0.1254 - pearson_correlation: -2.0661e-16 - r2_keras: -100.3354 - rmse: 0.8760 - sae: 2569.1455 - sse: 3143.2961\n","Epoch 37: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0504 - loss: 0.1434 - mae: 0.2002 - mse: 0.1118 - pearson_correlation: -1.2082e-16 - r2_keras: -83.2310 - rmse: 0.8724 - sae: 1881.4502 - sse: 2291.1179 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2929 - val_mse: 0.2646 - val_pearson_correlation: -1.2353e-16 - val_r2_keras: -33.4745 - val_rmse: 0.9561 - val_sae: 364.2659 - val_sse: 483.6123 - learning_rate: 0.0014\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0610 - loss: 0.1498 - mae: 0.2086 - mse: 0.1253 - pearson_correlation: 2.4172e-16 - r2_keras: -100.3521 - rmse: 0.8761 - sae: 2569.2676 - sse: 3143.8142\n","Epoch 38: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0504 - loss: 0.1434 - mae: 0.2001 - mse: 0.1118 - pearson_correlation: 1.3801e-16 - r2_keras: -83.2512 - rmse: 0.8725 - sae: 1881.5651 - sse: 2291.5698 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2929 - val_mse: 0.2646 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4957 - val_rmse: 0.9564 - val_sae: 364.4408 - val_sse: 483.9097 - learning_rate: 0.0014\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0609 - loss: 0.1498 - mae: 0.2085 - mse: 0.1252 - pearson_correlation: 5.1287e-16 - r2_keras: -100.3757 - rmse: 0.8762 - sae: 2569.4592 - sse: 3144.5483\n","Epoch 39: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0504 - loss: 0.1434 - mae: 0.2000 - mse: 0.1117 - pearson_correlation: 2.7432e-16 - r2_keras: -83.2712 - rmse: 0.8726 - sae: 1881.7097 - sse: 2292.1096 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2928 - val_mse: 0.2645 - val_pearson_correlation: 1.9060e-16 - val_r2_keras: -33.5120 - val_rmse: 0.9567 - val_sae: 364.5650 - val_sse: 484.1381 - learning_rate: 0.0014\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0609 - loss: 0.1497 - mae: 0.2084 - mse: 0.1251 - pearson_correlation: -2.1815e-16 - r2_keras: -100.3975 - rmse: 0.8763 - sae: 2569.6125 - sse: 3145.2236\n","Epoch 40: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0503 - loss: 0.1433 - mae: 0.1999 - mse: 0.1116 - pearson_correlation: -8.4967e-17 - r2_keras: -83.2900 - rmse: 0.8727 - sae: 1881.8306 - sse: 2292.6099 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2926 - val_mse: 0.2646 - val_pearson_correlation: -2.8055e-16 - val_r2_keras: -33.4937 - val_rmse: 0.9564 - val_sae: 364.4469 - val_sse: 483.8819 - learning_rate: 0.0014\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0609 - loss: 0.1497 - mae: 0.2083 - mse: 0.1251 - pearson_correlation: -7.9925e-17 - r2_keras: -100.4096 - rmse: 0.8763 - sae: 2569.6509 - sse: 3145.5986\n","Epoch 41: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0503 - loss: 0.1433 - mae: 0.1998 - mse: 0.1115 - pearson_correlation: -1.0043e-16 - r2_keras: -83.2908 - rmse: 0.8727 - sae: 1881.8121 - sse: 2292.7747 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2925 - val_mse: 0.2645 - val_pearson_correlation: 2.3561e-16 - val_r2_keras: -33.4988 - val_rmse: 0.9565 - val_sae: 364.5090 - val_sse: 483.9536 - learning_rate: 2.8888e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0609 - loss: 0.1497 - mae: 0.2083 - mse: 0.1251 - pearson_correlation: -2.2541e-16 - r2_keras: -100.4170 - rmse: 0.8764 - sae: 2569.7148 - sse: 3145.8271\n","Epoch 42: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0503 - loss: 0.1433 - mae: 0.1997 - mse: 0.1115 - pearson_correlation: -1.3604e-16 - r2_keras: -83.2967 - rmse: 0.8727 - sae: 1881.8593 - sse: 2292.9380 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2924 - val_mse: 0.2645 - val_pearson_correlation: -4.9359e-16 - val_r2_keras: -33.5013 - val_rmse: 0.9565 - val_sae: 364.5423 - val_sse: 483.9876 - learning_rate: 2.8888e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2083 - mse: 0.1250 - pearson_correlation: 1.7447e-16 - r2_keras: -100.4191 - rmse: 0.8764 - sae: 2569.7241 - sse: 3145.8933\n","Epoch 43: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0503 - loss: 0.1433 - mae: 0.1997 - mse: 0.1115 - pearson_correlation: 7.5395e-17 - r2_keras: -83.2992 - rmse: 0.8727 - sae: 1881.8699 - sse: 2292.9949 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2924 - val_mse: 0.2645 - val_pearson_correlation: 3.4772e-16 - val_r2_keras: -33.5035 - val_rmse: 0.9565 - val_sae: 364.5694 - val_sse: 484.0189 - learning_rate: 2.8888e-04\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 4.6248e-17 - r2_keras: -100.4248 - rmse: 0.8764 - sae: 2569.7788 - sse: 3146.0698\n","Epoch 44: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0503 - loss: 0.1433 - mae: 0.1997 - mse: 0.1115 - pearson_correlation: 4.2394e-17 - r2_keras: -83.3038 - rmse: 0.8728 - sae: 1881.9098 - sse: 2293.1223 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2923 - val_mse: 0.2645 - val_pearson_correlation: 8.9727e-17 - val_r2_keras: -33.5052 - val_rmse: 0.9566 - val_sae: 364.5869 - val_sse: 484.0425 - learning_rate: 2.8888e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -2.4294e-16 - r2_keras: -100.4274 - rmse: 0.8764 - sae: 2569.7900 - sse: 3146.1523\n","Epoch 45: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0503 - loss: 0.1432 - mae: 0.1997 - mse: 0.1115 - pearson_correlation: -7.7469e-17 - r2_keras: -83.3067 - rmse: 0.8728 - sae: 1881.9222 - sse: 2293.1907 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2923 - val_mse: 0.2645 - val_pearson_correlation: 1.2340e-16 - val_r2_keras: -33.5009 - val_rmse: 0.9565 - val_sae: 364.5637 - val_sse: 483.9823 - learning_rate: 2.8888e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -8.4289e-17 - r2_keras: -100.4343 - rmse: 0.8764 - sae: 2569.8447 - sse: 3146.3652\n","Epoch 46: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0503 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: -1.5277e-17 - r2_keras: -83.3095 - rmse: 0.8728 - sae: 1881.9493 - sse: 2293.3120 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -1.5705e-16 - val_r2_keras: -33.5011 - val_rmse: 0.9565 - val_sae: 364.5707 - val_sse: 483.9850 - learning_rate: 5.7777e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 8.6015e-16 - r2_keras: -100.4348 - rmse: 0.8764 - sae: 2569.8491 - sse: 3146.3801\n","Epoch 47: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0503 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: 5.7165e-16 - r2_keras: -83.3100 - rmse: 0.8728 - sae: 1881.9530 - sse: 2293.3240 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.2436e-17 - val_r2_keras: -33.5012 - val_rmse: 0.9565 - val_sae: 364.5750 - val_sse: 483.9866 - learning_rate: 5.7777e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -2.9530e-16 - r2_keras: -100.4352 - rmse: 0.8764 - sae: 2569.8521 - sse: 3146.3936\n","Epoch 48: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: -1.7908e-16 - r2_keras: -83.3105 - rmse: 0.8728 - sae: 1881.9557 - sse: 2293.3352 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 1.1218e-16 - val_r2_keras: -33.5015 - val_rmse: 0.9565 - val_sae: 364.5793 - val_sse: 483.9905 - learning_rate: 5.7777e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 2.7218e-16 - r2_keras: -100.4356 - rmse: 0.8765 - sae: 2569.8538 - sse: 3146.4060\n","Epoch 49: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: 1.5566e-16 - r2_keras: -83.3108 - rmse: 0.8728 - sae: 1881.9572 - sse: 2293.3440 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -3.5899e-16 - val_r2_keras: -33.5002 - val_rmse: 0.9565 - val_sae: 364.5724 - val_sse: 483.9725 - learning_rate: 5.7777e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 6.3069e-16 - r2_keras: -100.4362 - rmse: 0.8765 - sae: 2569.8584 - sse: 3146.4248\n","Epoch 50: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: 4.1690e-16 - r2_keras: -83.3113 - rmse: 0.8728 - sae: 1881.9604 - sse: 2293.3569 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -3.3657e-17 - val_r2_keras: -33.4994 - val_rmse: 0.9565 - val_sae: 364.5686 - val_sse: 483.9619 - learning_rate: 5.7777e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 9.1924e-16 - r2_keras: -100.4367 - rmse: 0.8765 - sae: 2569.8623 - sse: 3146.4395\n","Epoch 51: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: 6.4129e-16 - r2_keras: -83.3112 - rmse: 0.8728 - sae: 1881.9608 - sse: 2293.3618 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -1.1219e-16 - val_r2_keras: -33.4998 - val_rmse: 0.9565 - val_sae: 364.5723 - val_sse: 483.9670 - learning_rate: 1.1555e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 1.6096e-16 - r2_keras: -100.4368 - rmse: 0.8765 - sae: 2569.8628 - sse: 3146.4431\n","Epoch 52: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: 1.7580e-16 - r2_keras: -83.3113 - rmse: 0.8728 - sae: 1881.9614 - sse: 2293.3647 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 8.9749e-17 - val_r2_keras: -33.5000 - val_rmse: 0.9565 - val_sae: 364.5747 - val_sse: 483.9704 - learning_rate: 1.1555e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -7.5594e-16 - r2_keras: -100.4369 - rmse: 0.8765 - sae: 2569.8638 - sse: 3146.4468\n","Epoch 53: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1997 - mse: 0.1114 - pearson_correlation: -4.5860e-16 - r2_keras: -83.3114 - rmse: 0.8728 - sae: 1881.9623 - sse: 2293.3679 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 1.9071e-16 - val_r2_keras: -33.5002 - val_rmse: 0.9565 - val_sae: 364.5763 - val_sse: 483.9727 - learning_rate: 1.1555e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -3.9275e-16 - r2_keras: -100.4371 - rmse: 0.8765 - sae: 2569.8643 - sse: 3146.4507\n","Epoch 54: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -2.0935e-16 - r2_keras: -83.3115 - rmse: 0.8728 - sae: 1881.9628 - sse: 2293.3708 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.8046e-16 - val_r2_keras: -33.5003 - val_rmse: 0.9565 - val_sae: 364.5774 - val_sse: 483.9744 - learning_rate: 1.1555e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 3.2865e-16 - r2_keras: -100.4371 - rmse: 0.8765 - sae: 2569.8645 - sse: 3146.4531\n","Epoch 55: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.6396e-16 - r2_keras: -83.3116 - rmse: 0.8728 - sae: 1881.9631 - sse: 2293.3730 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.0193e-16 - val_r2_keras: -33.5004 - val_rmse: 0.9565 - val_sae: 364.5782 - val_sse: 483.9757 - learning_rate: 1.1555e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 3.5675e-16 - r2_keras: -100.4373 - rmse: 0.8765 - sae: 2569.8660 - sse: 3146.4585\n","Epoch 56: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 2.3694e-16 - r2_keras: -83.3118 - rmse: 0.8728 - sae: 1881.9641 - sse: 2293.3767 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 7.8530e-17 - val_r2_keras: -33.5002 - val_rmse: 0.9565 - val_sae: 364.5771 - val_sse: 483.9731 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 5.1625e-16 - r2_keras: -100.4374 - rmse: 0.8765 - sae: 2569.8662 - sse: 3146.4609\n","Epoch 57: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 2.4810e-16 - r2_keras: -83.3118 - rmse: 0.8728 - sae: 1881.9644 - sse: 2293.3784 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.8046e-16 - val_r2_keras: -33.5001 - val_rmse: 0.9565 - val_sae: 364.5766 - val_sse: 483.9716 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 5.8063e-16 - r2_keras: -100.4375 - rmse: 0.8765 - sae: 2569.8667 - sse: 3146.4639\n","Epoch 58: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 5.5964e-16 - r2_keras: -83.3119 - rmse: 0.8728 - sae: 1881.9647 - sse: 2293.3804 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.6924e-16 - val_r2_keras: -33.5003 - val_rmse: 0.9565 - val_sae: 364.5777 - val_sse: 483.9739 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -9.8040e-17 - r2_keras: -100.4376 - rmse: 0.8765 - sae: 2569.8677 - sse: 3146.4668\n","Epoch 59: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -9.3822e-17 - r2_keras: -83.3120 - rmse: 0.8728 - sae: 1881.9655 - sse: 2293.3828 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 1.9072e-16 - val_r2_keras: -33.5002 - val_rmse: 0.9565 - val_sae: 364.5771 - val_sse: 483.9726 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -4.5918e-16 - r2_keras: -100.4377 - rmse: 0.8765 - sae: 2569.8682 - sse: 3146.4705\n","Epoch 60: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -2.7588e-16 - r2_keras: -83.3120 - rmse: 0.8728 - sae: 1881.9658 - sse: 2293.3853 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.2437e-17 - val_r2_keras: -33.5003 - val_rmse: 0.9565 - val_sae: 364.5782 - val_sse: 483.9746 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -9.0723e-17 - r2_keras: -100.4378 - rmse: 0.8765 - sae: 2569.8694 - sse: 3146.4744\n","Epoch 61: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -7.0266e-17 - r2_keras: -83.3122 - rmse: 0.8728 - sae: 1881.9667 - sse: 2293.3879 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 1.1219e-17 - val_r2_keras: -33.5002 - val_rmse: 0.9565 - val_sae: 364.5775 - val_sse: 483.9731 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 1.3726e-16 - r2_keras: -100.4379 - rmse: 0.8765 - sae: 2569.8701 - sse: 3146.4775\n","Epoch 62: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.6977e-16 - r2_keras: -83.3122 - rmse: 0.8728 - sae: 1881.9673 - sse: 2293.3904 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 4.4874e-17 - val_r2_keras: -33.5004 - val_rmse: 0.9565 - val_sae: 364.5786 - val_sse: 483.9757 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -2.8680e-16 - r2_keras: -100.4381 - rmse: 0.8765 - sae: 2569.8713 - sse: 3146.4819\n","Epoch 63: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -1.8942e-16 - r2_keras: -83.3124 - rmse: 0.8728 - sae: 1881.9681 - sse: 2293.3933 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -2.0193e-16 - val_r2_keras: -33.5003 - val_rmse: 0.9565 - val_sae: 364.5780 - val_sse: 483.9742 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -2.9792e-16 - r2_keras: -100.4383 - rmse: 0.8765 - sae: 2569.8730 - sse: 3146.4878\n","Epoch 64: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -2.1196e-16 - r2_keras: -83.3125 - rmse: 0.8728 - sae: 1881.9694 - sse: 2293.3975 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 5.6092e-17 - val_r2_keras: -33.5005 - val_rmse: 0.9565 - val_sae: 364.5790 - val_sse: 483.9764 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 9.7571e-16 - r2_keras: -100.4384 - rmse: 0.8765 - sae: 2569.8735 - sse: 3146.4910\n","Epoch 65: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 6.2290e-16 - r2_keras: -83.3126 - rmse: 0.8728 - sae: 1881.9698 - sse: 2293.3999 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -7.8529e-17 - val_r2_keras: -33.5004 - val_rmse: 0.9565 - val_sae: 364.5786 - val_sse: 483.9754 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 3.2748e-16 - r2_keras: -100.4386 - rmse: 0.8765 - sae: 2569.8755 - sse: 3146.4973\n","Epoch 66: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 2.0231e-16 - r2_keras: -83.3127 - rmse: 0.8728 - sae: 1881.9712 - sse: 2293.4043 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -4.8240e-16 - val_r2_keras: -33.5003 - val_rmse: 0.9565 - val_sae: 364.5779 - val_sse: 483.9741 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 2.1744e-16 - r2_keras: -100.4386 - rmse: 0.8765 - sae: 2569.8760 - sse: 3146.4995\n","Epoch 67: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.7075e-16 - r2_keras: -83.3128 - rmse: 0.8728 - sae: 1881.9714 - sse: 2293.4055 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -2.3559e-16 - val_r2_keras: -33.5005 - val_rmse: 0.9565 - val_sae: 364.5792 - val_sse: 483.9770 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 5.5809e-16 - r2_keras: -100.4387 - rmse: 0.8765 - sae: 2569.8767 - sse: 3146.5027\n","Epoch 68: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 4.2453e-16 - r2_keras: -83.3129 - rmse: 0.8728 - sae: 1881.9720 - sse: 2293.4080 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -2.0193e-16 - val_r2_keras: -33.5004 - val_rmse: 0.9565 - val_sae: 364.5787 - val_sse: 483.9757 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 4.3312e-16 - r2_keras: -100.4389 - rmse: 0.8765 - sae: 2569.8779 - sse: 3146.5073\n","Epoch 69: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 3.0387e-16 - r2_keras: -83.3130 - rmse: 0.8728 - sae: 1881.9730 - sse: 2293.4114 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -1.9071e-16 - val_r2_keras: -33.5006 - val_rmse: 0.9565 - val_sae: 364.5798 - val_sse: 483.9784 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -1.5510e-17 - r2_keras: -100.4390 - rmse: 0.8765 - sae: 2569.8789 - sse: 3146.5117\n","Epoch 70: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -2.6350e-17 - r2_keras: -83.3131 - rmse: 0.8728 - sae: 1881.9738 - sse: 2293.4143 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -1.1218e-16 - val_r2_keras: -33.5005 - val_rmse: 0.9565 - val_sae: 364.5792 - val_sse: 483.9768 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 1.5159e-16 - r2_keras: -100.4392 - rmse: 0.8765 - sae: 2569.8804 - sse: 3146.5176\n","Epoch 71: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.3664e-16 - r2_keras: -83.3132 - rmse: 0.8728 - sae: 1881.9747 - sse: 2293.4185 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -6.7310e-17 - val_r2_keras: -33.5007 - val_rmse: 0.9565 - val_sae: 364.5803 - val_sse: 483.9794 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 7.0002e-16 - r2_keras: -100.4393 - rmse: 0.8765 - sae: 2569.8813 - sse: 3146.5205\n","Epoch 72: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 4.8358e-16 - r2_keras: -83.3133 - rmse: 0.8728 - sae: 1881.9755 - sse: 2293.4207 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -1.0097e-16 - val_r2_keras: -33.5006 - val_rmse: 0.9565 - val_sae: 364.5798 - val_sse: 483.9782 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -1.4603e-16 - r2_keras: -100.4395 - rmse: 0.8765 - sae: 2569.8828 - sse: 3146.5264\n","Epoch 73: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -1.2671e-16 - r2_keras: -83.3134 - rmse: 0.8728 - sae: 1881.9764 - sse: 2293.4246 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 3.8142e-16 - val_r2_keras: -33.5007 - val_rmse: 0.9565 - val_sae: 364.5806 - val_sse: 483.9802 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -6.7309e-17 - r2_keras: -100.4396 - rmse: 0.8765 - sae: 2569.8833 - sse: 3146.5283\n","Epoch 74: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -5.7325e-17 - r2_keras: -83.3135 - rmse: 0.8728 - sae: 1881.9769 - sse: 2293.4260 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -6.7310e-17 - val_r2_keras: -33.5006 - val_rmse: 0.9565 - val_sae: 364.5799 - val_sse: 483.9786 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 2.7480e-16 - r2_keras: -100.4397 - rmse: 0.8765 - sae: 2569.8843 - sse: 3146.5312\n","Epoch 75: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.4584e-16 - r2_keras: -83.3136 - rmse: 0.8728 - sae: 1881.9777 - sse: 2293.4282 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 3.1411e-16 - val_r2_keras: -33.5006 - val_rmse: 0.9565 - val_sae: 364.5797 - val_sse: 483.9784 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 5.1623e-16 - r2_keras: -100.4399 - rmse: 0.8765 - sae: 2569.8860 - sse: 3146.5378\n","Epoch 76: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 3.0057e-16 - r2_keras: -83.3137 - rmse: 0.8728 - sae: 1881.9788 - sse: 2293.4326 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.3558e-16 - val_r2_keras: -33.5008 - val_rmse: 0.9565 - val_sae: 364.5808 - val_sse: 483.9807 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 9.1306e-17 - r2_keras: -100.4399 - rmse: 0.8765 - sae: 2569.8865 - sse: 3146.5403\n","Epoch 77: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.4620e-17 - r2_keras: -83.3138 - rmse: 0.8728 - sae: 1881.9791 - sse: 2293.4346 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -1.2340e-16 - val_r2_keras: -33.5007 - val_rmse: 0.9565 - val_sae: 364.5803 - val_sse: 483.9795 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: -1.9081e-16 - r2_keras: -100.4402 - rmse: 0.8765 - sae: 2569.8882 - sse: 3146.5469\n","Epoch 78: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: -1.7523e-16 - r2_keras: -83.3139 - rmse: 0.8728 - sae: 1881.9803 - sse: 2293.4390 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -5.3847e-16 - val_r2_keras: -33.5009 - val_rmse: 0.9565 - val_sae: 364.5815 - val_sse: 483.9823 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 1.4925e-16 - r2_keras: -100.4403 - rmse: 0.8765 - sae: 2569.8892 - sse: 3146.5505\n","Epoch 79: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 8.5269e-17 - r2_keras: -83.3140 - rmse: 0.8728 - sae: 1881.9811 - sse: 2293.4419 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: -3.3655e-16 - val_r2_keras: -33.5008 - val_rmse: 0.9565 - val_sae: 364.5808 - val_sse: 483.9809 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0608 - loss: 0.1497 - mae: 0.2082 - mse: 0.1250 - pearson_correlation: 2.5372e-16 - r2_keras: -100.4403 - rmse: 0.8765 - sae: 2569.8896 - sse: 3146.5522\n","Epoch 80: val_loss did not improve from 0.20397\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0502 - loss: 0.1432 - mae: 0.1996 - mse: 0.1114 - pearson_correlation: 1.4069e-16 - r2_keras: -83.3141 - rmse: 0.8728 - sae: 1881.9814 - sse: 2293.4431 - val_huber_loss: 0.1157 - val_loss: 0.2045 - val_mae: 0.2922 - val_mse: 0.2645 - val_pearson_correlation: 2.2436e-17 - val_r2_keras: -33.5010 - val_rmse: 0.9565 - val_sae: 364.5819 - val_sse: 483.9832 - learning_rate: 1.0000e-05\n","| \u001b[39m10       \u001b[39m | \u001b[39m-0.2045  \u001b[39m | \u001b[39m0.03611  \u001b[39m | \u001b[39m94.86    \u001b[39m | \u001b[39m75.92    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.5521 - loss: 0.6424 - mae: 0.9856 - mse: 1.2426 - pearson_correlation: 5.3218e-17 - r2_keras: -181.4510 - rmse: 1.1755 - sae: 4015.1421 - sse: 5659.4028\n","Epoch 1: val_loss improved from inf to 0.36958, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 469ms/step - huber_loss: 1.4839 - loss: 1.2102 - mae: 1.5558 - mse: 5.8086 - pearson_correlation: -2.1446e-17 - r2_keras: -708.0675 - rmse: 2.4953 - sae: 3728.1599 - sse: 10663.5498 - val_huber_loss: 0.2755 - val_loss: 0.3696 - val_mae: 0.5391 - val_mse: 0.7537 - val_pearson_correlation: -4.8727e-16 - val_r2_keras: -28.3674 - val_rmse: 0.8825 - val_sae: 290.5088 - val_sse: 411.9687 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.9331 - loss: 1.0272 - mae: 1.3211 - mse: 2.6231 - pearson_correlation: 2.1482e-16 - r2_keras: -277.9808 - rmse: 1.4535 - sae: 4772.0674 - sse: 8653.6348\n","Epoch 2: val_loss did not improve from 0.36958\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9102 - loss: 1.0134 - mae: 1.3148 - mse: 2.5878 - pearson_correlation: -4.5761e-17 - r2_keras: -257.8767 - rmse: 1.5719 - sae: 3569.4766 - sse: 6624.0864 - val_huber_loss: 0.5222 - val_loss: 0.6169 - val_mae: 0.9143 - val_mse: 1.2858 - val_pearson_correlation: 3.0414e-16 - val_r2_keras: -32.6761 - val_rmse: 0.9450 - val_sae: 384.9534 - val_sse: 472.4118 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.0319 - loss: 1.1266 - mae: 1.4595 - mse: 2.9487 - pearson_correlation: -1.5423e-16 - r2_keras: -323.3951 - rmse: 1.5674 - sae: 5339.7939 - sse: 10062.3301\n","Epoch 3: val_loss did not improve from 0.36958\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.8591 - loss: 1.0214 - mae: 1.3458 - mse: 2.5926 - pearson_correlation: -2.6277e-16 - r2_keras: -255.1668 - rmse: 1.4910 - sae: 3845.8494 - sse: 7176.2886 - val_huber_loss: 0.3108 - val_loss: 0.4056 - val_mae: 0.6389 - val_mse: 0.8104 - val_pearson_correlation: -4.3296e-16 - val_r2_keras: -25.1608 - val_rmse: 0.8329 - val_sae: 304.1647 - val_sse: 366.9868 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4193 - loss: 0.5141 - mae: 0.8046 - mse: 0.9775 - pearson_correlation: 9.8658e-17 - r2_keras: -126.7058 - rmse: 0.9834 - sae: 3200.3750 - sse: 3961.2734\n","Epoch 4: val_loss did not improve from 0.36958\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3954 - loss: 0.4996 - mae: 0.7834 - mse: 0.9257 - pearson_correlation: 4.5889e-17 - r2_keras: -110.6577 - rmse: 1.0193 - sae: 2364.0327 - sse: 2951.9353 - val_huber_loss: 0.3148 - val_loss: 0.4094 - val_mae: 0.6252 - val_mse: 0.8678 - val_pearson_correlation: -3.1287e-16 - val_r2_keras: -28.9633 - val_rmse: 0.8914 - val_sae: 305.4274 - val_sse: 420.3279 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.3154 - loss: 0.4101 - mae: 0.6669 - mse: 0.7124 - pearson_correlation: -6.1378e-16 - r2_keras: -117.5261 - rmse: 0.9474 - sae: 2944.5806 - sse: 3676.5308\n","Epoch 5: val_loss did not improve from 0.36958\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.2870 - loss: 0.3927 - mae: 0.6487 - mse: 0.6617 - pearson_correlation: -3.3464e-16 - r2_keras: -97.9593 - rmse: 0.9470 - sae: 2161.3342 - sse: 2684.9404 - val_huber_loss: 0.2903 - val_loss: 0.3848 - val_mae: 0.5795 - val_mse: 0.7987 - val_pearson_correlation: -2.3193e-16 - val_r2_keras: -29.5640 - val_rmse: 0.9003 - val_sae: 309.1637 - val_sse: 428.7547 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2458 - loss: 0.3404 - mae: 0.5691 - mse: 0.5518 - pearson_correlation: 2.8219e-16 - r2_keras: -113.8223 - rmse: 0.9325 - sae: 2738.9954 - sse: 3561.6445\n","Epoch 6: val_loss improved from 0.36958 to 0.30625, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.2174 - loss: 0.3230 - mae: 0.5402 - mse: 0.5064 - pearson_correlation: 3.1693e-16 - r2_keras: -89.0673 - rmse: 0.8813 - sae: 1982.9633 - sse: 2533.0093 - val_huber_loss: 0.2119 - val_loss: 0.3063 - val_mae: 0.4741 - val_mse: 0.5481 - val_pearson_correlation: 8.0582e-17 - val_r2_keras: -31.3486 - val_rmse: 0.9262 - val_sae: 331.1169 - val_sse: 453.7899 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2772 - loss: 0.3715 - mae: 0.6220 - mse: 0.6281 - pearson_correlation: -2.2847e-16 - r2_keras: -149.0274 - rmse: 1.0659 - sae: 3258.8599 - sse: 4653.6611\n","Epoch 7: val_loss improved from 0.30625 to 0.27301, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.2844 - loss: 0.3759 - mae: 0.6215 - mse: 0.6294 - pearson_correlation: -2.1454e-16 - r2_keras: -115.3301 - rmse: 0.9958 - sae: 2345.1528 - sse: 3293.7791 - val_huber_loss: 0.1788 - val_loss: 0.2730 - val_mae: 0.4842 - val_mse: 0.3968 - val_pearson_correlation: 1.7391e-16 - val_r2_keras: -37.6448 - val_rmse: 1.0123 - val_sae: 409.9643 - val_sse: 542.1133 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3405 - loss: 0.4348 - mae: 0.7082 - mse: 0.8520 - pearson_correlation: 4.3038e-16 - r2_keras: -182.0519 - rmse: 1.1774 - sae: 3806.2754 - sse: 5678.0410\n","Epoch 8: val_loss improved from 0.27301 to 0.23731, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.2927 - loss: 0.4057 - mae: 0.6574 - mse: 0.7624 - pearson_correlation: 1.9501e-16 - r2_keras: -136.0044 - rmse: 1.0582 - sae: 2701.1965 - sse: 3960.9573 - val_huber_loss: 0.1432 - val_loss: 0.2373 - val_mae: 0.4283 - val_mse: 0.3048 - val_pearson_correlation: -1.4228e-16 - val_r2_keras: -35.9519 - val_rmse: 0.9899 - val_sae: 402.8954 - val_sse: 518.3649 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1883 - loss: 0.2824 - mae: 0.4963 - mse: 0.4337 - pearson_correlation: -2.8841e-16 - r2_keras: -123.7407 - rmse: 0.9719 - sae: 3028.4761 - sse: 3869.3005\n","Epoch 9: val_loss improved from 0.23731 to 0.23313, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.1732 - loss: 0.2732 - mae: 0.4854 - mse: 0.4051 - pearson_correlation: -1.4139e-16 - r2_keras: -97.6381 - rmse: 0.9258 - sae: 2190.3662 - sse: 2761.0864 - val_huber_loss: 0.1392 - val_loss: 0.2331 - val_mae: 0.3916 - val_mse: 0.2920 - val_pearson_correlation: -9.3998e-17 - val_r2_keras: -35.3890 - val_rmse: 0.9823 - val_sae: 396.5681 - val_sse: 510.4691 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1657 - loss: 0.2596 - mae: 0.4158 - mse: 0.3900 - pearson_correlation: 5.1055e-16 - r2_keras: -106.6573 - rmse: 0.9029 - sae: 2738.5154 - sse: 3339.3953\n","Epoch 10: val_loss improved from 0.23313 to 0.21977, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.1417 - loss: 0.2450 - mae: 0.4007 - mse: 0.3494 - pearson_correlation: 2.1036e-16 - r2_keras: -86.9370 - rmse: 0.8859 - sae: 1994.6986 - sse: 2415.8843 - val_huber_loss: 0.1261 - val_loss: 0.2198 - val_mae: 0.3690 - val_mse: 0.2826 - val_pearson_correlation: 2.4633e-16 - val_r2_keras: -29.7292 - val_rmse: 0.9027 - val_sae: 353.4476 - val_sse: 431.0723 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1225 - loss: 0.2162 - mae: 0.3472 - mse: 0.2729 - pearson_correlation: -5.3178e-16 - r2_keras: -83.1994 - rmse: 0.7985 - sae: 2383.4255 - sse: 2611.7605\n","Epoch 11: val_loss did not improve from 0.21977\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1156 - loss: 0.2120 - mae: 0.3423 - mse: 0.2590 - pearson_correlation: -2.8874e-16 - r2_keras: -74.0069 - rmse: 0.8392 - sae: 1767.7245 - sse: 1962.5657 - val_huber_loss: 0.1545 - val_loss: 0.2480 - val_mae: 0.4258 - val_mse: 0.3758 - val_pearson_correlation: 7.5365e-17 - val_r2_keras: -26.0621 - val_rmse: 0.8471 - val_sae: 329.3775 - val_sse: 379.6307 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1525 - loss: 0.2460 - mae: 0.4215 - mse: 0.3358 - pearson_correlation: -3.7235e-16 - r2_keras: -78.7270 - rmse: 0.7770 - sae: 2384.7942 - sse: 2473.0325\n","Epoch 12: val_loss did not improve from 0.21977\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1377 - loss: 0.2370 - mae: 0.4122 - mse: 0.3117 - pearson_correlation: -2.6627e-16 - r2_keras: -71.8427 - rmse: 0.8314 - sae: 1779.1394 - sse: 1879.6683 - val_huber_loss: 0.1867 - val_loss: 0.2800 - val_mae: 0.5136 - val_mse: 0.4453 - val_pearson_correlation: 2.7180e-16 - val_r2_keras: -27.7026 - val_rmse: 0.8724 - val_sae: 341.4807 - val_sse: 402.6430 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1444 - loss: 0.2377 - mae: 0.4291 - mse: 0.3040 - pearson_correlation: 7.5732e-17 - r2_keras: -80.0118 - rmse: 0.7833 - sae: 2392.1353 - sse: 2512.8853\n","Epoch 13: val_loss did not improve from 0.21977\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1326 - loss: 0.2305 - mae: 0.4171 - mse: 0.2867 - pearson_correlation: 1.4793e-16 - r2_keras: -72.1068 - rmse: 0.8308 - sae: 1782.1530 - sse: 1899.2880 - val_huber_loss: 0.1580 - val_loss: 0.2512 - val_mae: 0.4563 - val_mse: 0.3663 - val_pearson_correlation: 8.4786e-17 - val_r2_keras: -29.2149 - val_rmse: 0.8951 - val_sae: 351.2300 - val_sse: 423.8585 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1276 - loss: 0.2208 - mae: 0.3837 - mse: 0.2742 - pearson_correlation: -2.2196e-16 - r2_keras: -84.8849 - rmse: 0.8065 - sae: 2435.3303 - sse: 2664.0415\n","Epoch 14: val_loss did not improve from 0.21977\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1104 - loss: 0.2103 - mae: 0.3636 - mse: 0.2495 - pearson_correlation: -1.2237e-16 - r2_keras: -72.0997 - rmse: 0.8187 - sae: 1792.3160 - sse: 1961.8683 - val_huber_loss: 0.1297 - val_loss: 0.2227 - val_mae: 0.3545 - val_mse: 0.2994 - val_pearson_correlation: 2.3075e-16 - val_r2_keras: -31.7929 - val_rmse: 0.9325 - val_sae: 352.4907 - val_sse: 460.0230 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0983 - loss: 0.1912 - mae: 0.2925 - mse: 0.2112 - pearson_correlation: 4.2255e-16 - r2_keras: -92.4088 - rmse: 0.8411 - sae: 2473.0283 - sse: 2897.4253\n","Epoch 15: val_loss improved from 0.21977 to 0.21455, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0892 - loss: 0.1856 - mae: 0.2866 - mse: 0.1972 - pearson_correlation: 1.1973e-16 - r2_keras: -75.4369 - rmse: 0.8265 - sae: 1805.4249 - sse: 2097.7656 - val_huber_loss: 0.1218 - val_loss: 0.2146 - val_mae: 0.3395 - val_mse: 0.2654 - val_pearson_correlation: 2.2915e-16 - val_r2_keras: -36.5140 - val_rmse: 0.9974 - val_sae: 387.7888 - val_sse: 526.2508 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1045 - loss: 0.1972 - mae: 0.3097 - mse: 0.2270 - pearson_correlation: -7.7160e-17 - r2_keras: -104.0066 - rmse: 0.8917 - sae: 2635.6060 - sse: 3257.1729\n","Epoch 16: val_loss did not improve from 0.21455\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0958 - loss: 0.1919 - mae: 0.3122 - mse: 0.2129 - pearson_correlation: -3.7784e-17 - r2_keras: -82.8685 - rmse: 0.8574 - sae: 1915.4033 - sse: 2334.0752 - val_huber_loss: 0.1334 - val_loss: 0.2259 - val_mae: 0.3872 - val_mse: 0.2797 - val_pearson_correlation: 1.4054e-16 - val_r2_keras: -40.7248 - val_rmse: 1.0519 - val_sae: 426.2285 - val_sse: 585.3207 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1125 - loss: 0.2050 - mae: 0.3318 - mse: 0.2458 - pearson_correlation: -5.5852e-16 - r2_keras: -110.4019 - rmse: 0.9185 - sae: 2744.2090 - sse: 3455.5461\n","Epoch 17: val_loss did not improve from 0.21455\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1014 - loss: 0.1982 - mae: 0.3318 - mse: 0.2281 - pearson_correlation: -3.9168e-16 - r2_keras: -87.6827 - rmse: 0.8805 - sae: 1992.5342 - sse: 2472.7830 - val_huber_loss: 0.1321 - val_loss: 0.2244 - val_mae: 0.3848 - val_mse: 0.2787 - val_pearson_correlation: 7.2452e-17 - val_r2_keras: -39.5941 - val_rmse: 1.0375 - val_sae: 420.7642 - val_sse: 569.4578 - learning_rate: 0.1000\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1036 - loss: 0.1959 - mae: 0.3068 - mse: 0.2282 - pearson_correlation: 5.5488e-16 - r2_keras: -103.0755 - rmse: 0.8878 - sae: 2639.5352 - sse: 3228.2915\n","Epoch 18: val_loss did not improve from 0.21455\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0898 - loss: 0.1875 - mae: 0.2989 - mse: 0.2072 - pearson_correlation: 3.8421e-16 - r2_keras: -83.3360 - rmse: 0.8649 - sae: 1921.1107 - sse: 2327.5854 - val_huber_loss: 0.1234 - val_loss: 0.2155 - val_mae: 0.3476 - val_mse: 0.2697 - val_pearson_correlation: 4.3091e-16 - val_r2_keras: -35.7112 - val_rmse: 0.9867 - val_sae: 390.2020 - val_sse: 514.9883 - learning_rate: 0.1000\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0918 - loss: 0.1839 - mae: 0.2786 - mse: 0.1996 - pearson_correlation: 6.9548e-17 - r2_keras: -92.5129 - rmse: 0.8415 - sae: 2488.5264 - sse: 2900.6536\n","Epoch 19: val_loss improved from 0.21455 to 0.21412, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0807 - loss: 0.1771 - mae: 0.2700 - mse: 0.1829 - pearson_correlation: -1.2358e-17 - r2_keras: -77.9456 - rmse: 0.8488 - sae: 1827.4764 - sse: 2128.5310 - val_huber_loss: 0.1223 - val_loss: 0.2141 - val_mae: 0.3333 - val_mse: 0.2854 - val_pearson_correlation: 1.2769e-17 - val_r2_keras: -30.8398 - val_rmse: 0.9189 - val_sae: 349.8389 - val_sse: 446.6528 - learning_rate: 0.1000\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0940 - loss: 0.1859 - mae: 0.2882 - mse: 0.2004 - pearson_correlation: 4.0409e-16 - r2_keras: -85.1608 - rmse: 0.8078 - sae: 2404.0532 - sse: 2672.5996\n","Epoch 20: val_loss did not improve from 0.21412\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0846 - loss: 0.1802 - mae: 0.2845 - mse: 0.1864 - pearson_correlation: 2.8475e-16 - r2_keras: -74.6981 - rmse: 0.8403 - sae: 1780.4747 - sse: 1995.8954 - val_huber_loss: 0.1340 - val_loss: 0.2257 - val_mae: 0.3688 - val_mse: 0.3211 - val_pearson_correlation: 1.0306e-16 - val_r2_keras: -28.6806 - val_rmse: 0.8872 - val_sae: 335.8270 - val_sse: 416.3628 - learning_rate: 0.1000\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0995 - loss: 0.1912 - mae: 0.3128 - mse: 0.2100 - pearson_correlation: 2.0681e-17 - r2_keras: -83.6870 - rmse: 0.8008 - sae: 2390.1150 - sse: 2626.8843\n","Epoch 21: val_loss did not improve from 0.21412\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0900 - loss: 0.1854 - mae: 0.3090 - mse: 0.1962 - pearson_correlation: 6.8491e-18 - r2_keras: -74.5998 - rmse: 0.8429 - sae: 1775.1141 - sse: 1975.7902 - val_huber_loss: 0.1262 - val_loss: 0.2177 - val_mae: 0.3484 - val_mse: 0.2985 - val_pearson_correlation: -1.0421e-16 - val_r2_keras: -28.5196 - val_rmse: 0.8848 - val_sae: 335.3091 - val_sse: 414.1046 - learning_rate: 0.1000\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0999 - loss: 0.1914 - mae: 0.3141 - mse: 0.2118 - pearson_correlation: -1.3014e-16 - r2_keras: -85.7602 - rmse: 0.8106 - sae: 2409.7324 - sse: 2691.1941\n","Epoch 22: val_loss improved from 0.21412 to 0.20714, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0887 - loss: 0.1845 - mae: 0.3080 - mse: 0.1956 - pearson_correlation: -4.0880e-17 - r2_keras: -75.1753 - rmse: 0.8428 - sae: 1785.0671 - sse: 2009.2014 - val_huber_loss: 0.1159 - val_loss: 0.2071 - val_mae: 0.3187 - val_mse: 0.2713 - val_pearson_correlation: 2.7004e-17 - val_r2_keras: -29.9198 - val_rmse: 0.9055 - val_sae: 342.9369 - val_sse: 433.7463 - learning_rate: 0.1000\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0931 - loss: 0.1843 - mae: 0.2868 - mse: 0.1986 - pearson_correlation: -9.5481e-17 - r2_keras: -91.3915 - rmse: 0.8365 - sae: 2465.7515 - sse: 2865.8687\n","Epoch 23: val_loss improved from 0.20714 to 0.20642, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0808 - loss: 0.1768 - mae: 0.2803 - mse: 0.1811 - pearson_correlation: -7.0817e-17 - r2_keras: -77.2101 - rmse: 0.8455 - sae: 1813.5425 - sse: 2105.4832 - val_huber_loss: 0.1154 - val_loss: 0.2064 - val_mae: 0.3069 - val_mse: 0.2625 - val_pearson_correlation: -3.4362e-16 - val_r2_keras: -32.9959 - val_rmse: 0.9495 - val_sae: 361.3112 - val_sse: 476.8980 - learning_rate: 0.1000\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0857 - loss: 0.1768 - mae: 0.2633 - mse: 0.1831 - pearson_correlation: -2.7172e-16 - r2_keras: -96.7235 - rmse: 0.8603 - sae: 2526.7441 - sse: 3031.2600\n","Epoch 24: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0742 - loss: 0.1698 - mae: 0.2561 - mse: 0.1668 - pearson_correlation: -2.3170e-16 - r2_keras: -78.9752 - rmse: 0.8454 - sae: 1844.5573 - sse: 2194.7524 - val_huber_loss: 0.1305 - val_loss: 0.2213 - val_mae: 0.3477 - val_mse: 0.2856 - val_pearson_correlation: -1.9323e-16 - val_r2_keras: -37.4345 - val_rmse: 1.0096 - val_sae: 393.2474 - val_sse: 539.1633 - learning_rate: 0.1000\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0880 - loss: 0.1788 - mae: 0.2762 - mse: 0.1852 - pearson_correlation: 2.2806e-16 - r2_keras: -103.8497 - rmse: 0.8911 - sae: 2627.9553 - sse: 3252.3066\n","Epoch 25: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0784 - loss: 0.1730 - mae: 0.2725 - mse: 0.1717 - pearson_correlation: 1.4330e-16 - r2_keras: -83.1357 - rmse: 0.8605 - sae: 1909.0209 - sse: 2335.1917 - val_huber_loss: 0.1466 - val_loss: 0.2373 - val_mae: 0.3894 - val_mse: 0.3164 - val_pearson_correlation: 3.1614e-16 - val_r2_keras: -40.7172 - val_rmse: 1.0518 - val_sae: 417.7448 - val_sse: 585.2132 - learning_rate: 0.1000\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0966 - loss: 0.1872 - mae: 0.2974 - mse: 0.2029 - pearson_correlation: -1.0926e-16 - r2_keras: -106.4046 - rmse: 0.9019 - sae: 2679.0947 - sse: 3331.5576\n","Epoch 26: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0843 - loss: 0.1797 - mae: 0.2898 - mse: 0.1860 - pearson_correlation: -1.7108e-16 - r2_keras: -85.1756 - rmse: 0.8708 - sae: 1944.7173 - sse: 2391.9741 - val_huber_loss: 0.1399 - val_loss: 0.2304 - val_mae: 0.3788 - val_mse: 0.3023 - val_pearson_correlation: -1.8166e-17 - val_r2_keras: -39.5176 - val_rmse: 1.0366 - val_sae: 410.8651 - val_sse: 568.3847 - learning_rate: 0.1000\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0944 - loss: 0.1849 - mae: 0.2915 - mse: 0.1985 - pearson_correlation: -2.1624e-17 - r2_keras: -100.5540 - rmse: 0.8770 - sae: 2605.1799 - sse: 3150.0771\n","Epoch 27: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0820 - loss: 0.1773 - mae: 0.2794 - mse: 0.1815 - pearson_correlation: -7.4447e-17 - r2_keras: -82.8790 - rmse: 0.8687 - sae: 1902.2222 - sse: 2289.8005 - val_huber_loss: 0.1239 - val_loss: 0.2141 - val_mae: 0.3360 - val_mse: 0.2716 - val_pearson_correlation: -3.9334e-16 - val_r2_keras: -35.6356 - val_rmse: 0.9857 - val_sae: 383.9787 - val_sse: 513.9278 - learning_rate: 0.1000\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0960 - loss: 0.1862 - mae: 0.2937 - mse: 0.2020 - pearson_correlation: 1.6302e-16 - r2_keras: -92.6966 - rmse: 0.8424 - sae: 2493.5381 - sse: 2906.3501\n","Epoch 28: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0817 - loss: 0.1775 - mae: 0.2828 - mse: 0.1825 - pearson_correlation: 1.5554e-16 - r2_keras: -79.4270 - rmse: 0.8609 - sae: 1837.7760 - sse: 2148.2693 - val_huber_loss: 0.1181 - val_loss: 0.2082 - val_mae: 0.3288 - val_mse: 0.2729 - val_pearson_correlation: -3.7768e-17 - val_r2_keras: -31.1223 - val_rmse: 0.9229 - val_sae: 353.7403 - val_sse: 450.6155 - learning_rate: 0.1000\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0902 - loss: 0.1802 - mae: 0.2981 - mse: 0.1881 - pearson_correlation: 1.0504e-16 - r2_keras: -87.8849 - rmse: 0.8204 - sae: 2434.7053 - sse: 2757.0994\n","Epoch 29: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0757 - loss: 0.1714 - mae: 0.2823 - mse: 0.1689 - pearson_correlation: 6.3958e-17 - r2_keras: -73.2811 - rmse: 0.8207 - sae: 1784.3907 - sse: 2014.3041 - val_huber_loss: 0.1201 - val_loss: 0.2101 - val_mae: 0.3168 - val_mse: 0.2742 - val_pearson_correlation: 2.5772e-16 - val_r2_keras: -33.4824 - val_rmse: 0.9562 - val_sae: 367.2219 - val_sse: 483.7233 - learning_rate: 0.0200\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0790 - loss: 0.1690 - mae: 0.2558 - mse: 0.1659 - pearson_correlation: 6.7884e-16 - r2_keras: -95.3536 - rmse: 0.8542 - sae: 2517.2412 - sse: 2988.7681\n","Epoch 30: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0667 - loss: 0.1615 - mae: 0.2456 - mse: 0.1492 - pearson_correlation: 4.4211e-16 - r2_keras: -79.0266 - rmse: 0.8501 - sae: 1842.8451 - sse: 2177.7397 - val_huber_loss: 0.1225 - val_loss: 0.2124 - val_mae: 0.3207 - val_mse: 0.2786 - val_pearson_correlation: 4.3514e-17 - val_r2_keras: -34.1786 - val_rmse: 0.9659 - val_sae: 371.4311 - val_sse: 493.4893 - learning_rate: 0.0200\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0774 - loss: 0.1674 - mae: 0.2476 - mse: 0.1627 - pearson_correlation: -4.9818e-16 - r2_keras: -97.9215 - rmse: 0.8655 - sae: 2544.2356 - sse: 3068.4221\n","Epoch 31: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0653 - loss: 0.1600 - mae: 0.2387 - mse: 0.1464 - pearson_correlation: -3.3305e-16 - r2_keras: -81.0299 - rmse: 0.8602 - sae: 1862.0829 - sse: 2234.2595 - val_huber_loss: 0.1227 - val_loss: 0.2126 - val_mae: 0.3214 - val_mse: 0.2779 - val_pearson_correlation: 4.3121e-17 - val_r2_keras: -34.4054 - val_rmse: 0.9690 - val_sae: 372.7417 - val_sse: 496.6711 - learning_rate: 0.0200\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0765 - loss: 0.1664 - mae: 0.2441 - mse: 0.1607 - pearson_correlation: -7.0374e-17 - r2_keras: -98.4514 - rmse: 0.8678 - sae: 2547.6763 - sse: 3084.8579\n","Epoch 32: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0646 - loss: 0.1592 - mae: 0.2356 - mse: 0.1446 - pearson_correlation: -1.0592e-16 - r2_keras: -81.4843 - rmse: 0.8627 - sae: 1864.8955 - sse: 2246.4036 - val_huber_loss: 0.1219 - val_loss: 0.2118 - val_mae: 0.3207 - val_mse: 0.2751 - val_pearson_correlation: 1.8237e-16 - val_r2_keras: -34.5315 - val_rmse: 0.9707 - val_sae: 373.6705 - val_sse: 498.4397 - learning_rate: 0.0200\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0758 - loss: 0.1657 - mae: 0.2420 - mse: 0.1592 - pearson_correlation: -2.2222e-16 - r2_keras: -98.9411 - rmse: 0.8700 - sae: 2552.2200 - sse: 3100.0476\n","Epoch 33: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0640 - loss: 0.1585 - mae: 0.2339 - mse: 0.1434 - pearson_correlation: -1.8671e-16 - r2_keras: -81.8654 - rmse: 0.8646 - sae: 1868.2498 - sse: 2257.1702 - val_huber_loss: 0.1222 - val_loss: 0.2120 - val_mae: 0.3211 - val_mse: 0.2754 - val_pearson_correlation: -6.4430e-17 - val_r2_keras: -34.5088 - val_rmse: 0.9704 - val_sae: 373.4408 - val_sse: 498.1218 - learning_rate: 0.0200\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0753 - loss: 0.1651 - mae: 0.2400 - mse: 0.1579 - pearson_correlation: -5.0282e-16 - r2_keras: -98.7066 - rmse: 0.8689 - sae: 2548.3733 - sse: 3092.7725\n","Epoch 34: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0634 - loss: 0.1579 - mae: 0.2307 - mse: 0.1419 - pearson_correlation: -3.2324e-16 - r2_keras: -81.6639 - rmse: 0.8635 - sae: 1865.4855 - sse: 2251.7917 - val_huber_loss: 0.1218 - val_loss: 0.2116 - val_mae: 0.3209 - val_mse: 0.2743 - val_pearson_correlation: -1.7146e-16 - val_r2_keras: -34.5632 - val_rmse: 0.9711 - val_sae: 373.9380 - val_sse: 498.8838 - learning_rate: 0.0040\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0751 - loss: 0.1649 - mae: 0.2397 - mse: 0.1575 - pearson_correlation: -3.1736e-16 - r2_keras: -98.9024 - rmse: 0.8698 - sae: 2550.6729 - sse: 3098.8477\n","Epoch 35: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0632 - loss: 0.1577 - mae: 0.2304 - mse: 0.1416 - pearson_correlation: -2.3551e-16 - r2_keras: -81.8000 - rmse: 0.8641 - sae: 1867.0627 - sse: 2255.9060 - val_huber_loss: 0.1216 - val_loss: 0.2114 - val_mae: 0.3208 - val_mse: 0.2737 - val_pearson_correlation: -3.9574e-16 - val_r2_keras: -34.6132 - val_rmse: 0.9718 - val_sae: 374.3547 - val_sse: 499.5860 - learning_rate: 0.0040\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0749 - loss: 0.1647 - mae: 0.2393 - mse: 0.1572 - pearson_correlation: -5.4912e-16 - r2_keras: -99.0761 - rmse: 0.8706 - sae: 2552.7742 - sse: 3104.2358\n","Epoch 36: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0631 - loss: 0.1576 - mae: 0.2302 - mse: 0.1414 - pearson_correlation: -3.5780e-16 - r2_keras: -81.9353 - rmse: 0.8648 - sae: 1868.5619 - sse: 2259.7266 - val_huber_loss: 0.1215 - val_loss: 0.2113 - val_mae: 0.3206 - val_mse: 0.2730 - val_pearson_correlation: -1.0687e-17 - val_r2_keras: -34.6346 - val_rmse: 0.9721 - val_sae: 374.4785 - val_sse: 499.8865 - learning_rate: 0.0040\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0748 - loss: 0.1646 - mae: 0.2388 - mse: 0.1569 - pearson_correlation: 3.7032e-16 - r2_keras: -99.0614 - rmse: 0.8705 - sae: 2552.2749 - sse: 3103.7798\n","Epoch 37: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0630 - loss: 0.1574 - mae: 0.2299 - mse: 0.1411 - pearson_correlation: 2.8915e-16 - r2_keras: -81.9339 - rmse: 0.8648 - sae: 1868.2767 - sse: 2259.5220 - val_huber_loss: 0.1215 - val_loss: 0.2113 - val_mae: 0.3206 - val_mse: 0.2731 - val_pearson_correlation: -1.0684e-17 - val_r2_keras: -34.6427 - val_rmse: 0.9722 - val_sae: 374.5185 - val_sse: 499.9996 - learning_rate: 0.0040\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0747 - loss: 0.1645 - mae: 0.2385 - mse: 0.1567 - pearson_correlation: -2.2043e-16 - r2_keras: -99.0343 - rmse: 0.8704 - sae: 2551.8159 - sse: 3102.9399\n","Epoch 38: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0629 - loss: 0.1573 - mae: 0.2297 - mse: 0.1409 - pearson_correlation: -1.6531e-16 - r2_keras: -81.9300 - rmse: 0.8648 - sae: 1868.0529 - sse: 2259.1274 - val_huber_loss: 0.1213 - val_loss: 0.2111 - val_mae: 0.3203 - val_mse: 0.2724 - val_pearson_correlation: -1.1741e-16 - val_r2_keras: -34.6682 - val_rmse: 0.9726 - val_sae: 374.6807 - val_sse: 500.3577 - learning_rate: 0.0040\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0746 - loss: 0.1644 - mae: 0.2381 - mse: 0.1564 - pearson_correlation: -4.3215e-17 - r2_keras: -99.0928 - rmse: 0.8706 - sae: 2552.2983 - sse: 3104.7539\n","Epoch 39: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0628 - loss: 0.1572 - mae: 0.2291 - mse: 0.1406 - pearson_correlation: -1.5921e-16 - r2_keras: -81.9637 - rmse: 0.8650 - sae: 1868.3379 - sse: 2260.2744 - val_huber_loss: 0.1213 - val_loss: 0.2111 - val_mae: 0.3203 - val_mse: 0.2724 - val_pearson_correlation: 1.0672e-16 - val_r2_keras: -34.6731 - val_rmse: 0.9726 - val_sae: 374.7082 - val_sse: 500.4262 - learning_rate: 8.0000e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0745 - loss: 0.1643 - mae: 0.2381 - mse: 0.1564 - pearson_correlation: -2.3485e-16 - r2_keras: -99.0920 - rmse: 0.8706 - sae: 2552.2576 - sse: 3104.7300\n","Epoch 40: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0628 - loss: 0.1572 - mae: 0.2291 - mse: 0.1406 - pearson_correlation: -1.5381e-16 - r2_keras: -81.9638 - rmse: 0.8650 - sae: 1868.3149 - sse: 2260.2664 - val_huber_loss: 0.1213 - val_loss: 0.2111 - val_mae: 0.3202 - val_mse: 0.2723 - val_pearson_correlation: -2.1341e-17 - val_r2_keras: -34.6758 - val_rmse: 0.9727 - val_sae: 374.7257 - val_sse: 500.4647 - learning_rate: 8.0000e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0745 - loss: 0.1643 - mae: 0.2380 - mse: 0.1563 - pearson_correlation: 3.7103e-16 - r2_keras: -99.0962 - rmse: 0.8706 - sae: 2552.3027 - sse: 3104.8594\n","Epoch 41: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0628 - loss: 0.1572 - mae: 0.2290 - mse: 0.1405 - pearson_correlation: 2.5746e-16 - r2_keras: -81.9680 - rmse: 0.8650 - sae: 1868.3550 - sse: 2260.3696 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3202 - val_mse: 0.2722 - val_pearson_correlation: 1.3869e-16 - val_r2_keras: -34.6804 - val_rmse: 0.9727 - val_sae: 374.7530 - val_sse: 500.5278 - learning_rate: 8.0000e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0745 - loss: 0.1643 - mae: 0.2379 - mse: 0.1563 - pearson_correlation: -7.3789e-16 - r2_keras: -99.0972 - rmse: 0.8706 - sae: 2552.2668 - sse: 3104.8887\n","Epoch 42: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0628 - loss: 0.1571 - mae: 0.2290 - mse: 0.1405 - pearson_correlation: -4.4877e-16 - r2_keras: -81.9698 - rmse: 0.8650 - sae: 1868.3374 - sse: 2260.4023 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3202 - val_mse: 0.2722 - val_pearson_correlation: 3.9470e-16 - val_r2_keras: -34.6828 - val_rmse: 0.9728 - val_sae: 374.7696 - val_sse: 500.5627 - learning_rate: 8.0000e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0745 - loss: 0.1643 - mae: 0.2379 - mse: 0.1562 - pearson_correlation: -1.5019e-16 - r2_keras: -99.1039 - rmse: 0.8707 - sae: 2552.3391 - sse: 3105.0977\n","Epoch 43: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2290 - mse: 0.1405 - pearson_correlation: -1.7356e-16 - r2_keras: -81.9762 - rmse: 0.8650 - sae: 1868.3976 - sse: 2260.5637 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3202 - val_mse: 0.2722 - val_pearson_correlation: 2.2400e-16 - val_r2_keras: -34.6852 - val_rmse: 0.9728 - val_sae: 374.7801 - val_sse: 500.5957 - learning_rate: 8.0000e-04\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2378 - mse: 0.1562 - pearson_correlation: -5.1554e-17 - r2_keras: -99.1006 - rmse: 0.8707 - sae: 2552.2524 - sse: 3104.9966\n","Epoch 44: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2289 - mse: 0.1404 - pearson_correlation: -1.1419e-17 - r2_keras: -81.9731 - rmse: 0.8650 - sae: 1868.3330 - sse: 2260.4863 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3202 - val_mse: 0.2722 - val_pearson_correlation: 4.2665e-17 - val_r2_keras: -34.6865 - val_rmse: 0.9728 - val_sae: 374.7896 - val_sse: 500.6140 - learning_rate: 1.6000e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2378 - mse: 0.1562 - pearson_correlation: 7.7479e-18 - r2_keras: -99.1022 - rmse: 0.8707 - sae: 2552.2690 - sse: 3105.0437\n","Epoch 45: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 2.9033e-17 - r2_keras: -81.9745 - rmse: 0.8650 - sae: 1868.3466 - sse: 2260.5222 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3202 - val_mse: 0.2722 - val_pearson_correlation: -1.1732e-16 - val_r2_keras: -34.6875 - val_rmse: 0.9728 - val_sae: 374.7960 - val_sse: 500.6278 - learning_rate: 1.6000e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2378 - mse: 0.1561 - pearson_correlation: 1.3439e-16 - r2_keras: -99.1029 - rmse: 0.8707 - sae: 2552.2710 - sse: 3105.0679\n","Epoch 46: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 4.3698e-17 - r2_keras: -81.9753 - rmse: 0.8650 - sae: 1868.3492 - sse: 2260.5408 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2722 - val_pearson_correlation: 1.3865e-16 - val_r2_keras: -34.6880 - val_rmse: 0.9728 - val_sae: 374.7992 - val_sse: 500.6347 - learning_rate: 1.6000e-04\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2378 - mse: 0.1561 - pearson_correlation: 3.3583e-16 - r2_keras: -99.1032 - rmse: 0.8707 - sae: 2552.2705 - sse: 3105.0762\n","Epoch 47: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 1.5872e-16 - r2_keras: -81.9758 - rmse: 0.8650 - sae: 1868.3508 - sse: 2260.5503 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 3.1996e-17 - val_r2_keras: -34.6888 - val_rmse: 0.9728 - val_sae: 374.8044 - val_sse: 500.6457 - learning_rate: 1.6000e-04\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2378 - mse: 0.1561 - pearson_correlation: 1.1401e-15 - r2_keras: -99.1052 - rmse: 0.8707 - sae: 2552.2891 - sse: 3105.1392\n","Epoch 48: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 7.2150e-16 - r2_keras: -81.9775 - rmse: 0.8651 - sae: 1868.3655 - sse: 2260.5964 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 1.3865e-16 - val_r2_keras: -34.6889 - val_rmse: 0.9728 - val_sae: 374.8044 - val_sse: 500.6473 - learning_rate: 1.6000e-04\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 1.6329e-16 - r2_keras: -99.1055 - rmse: 0.8707 - sae: 2552.2874 - sse: 3105.1475\n","Epoch 49: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 1.4191e-16 - r2_keras: -81.9773 - rmse: 0.8651 - sae: 1868.3618 - sse: 2260.5974 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -2.7729e-16 - val_r2_keras: -34.6891 - val_rmse: 0.9728 - val_sae: 374.8065 - val_sse: 500.6511 - learning_rate: 3.2000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -4.2015e-16 - r2_keras: -99.1056 - rmse: 0.8707 - sae: 2552.2876 - sse: 3105.1509\n","Epoch 50: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -2.9295e-16 - r2_keras: -81.9774 - rmse: 0.8651 - sae: 1868.3622 - sse: 2260.6001 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 6.3990e-17 - val_r2_keras: -34.6893 - val_rmse: 0.9728 - val_sae: 374.8078 - val_sse: 500.6533 - learning_rate: 3.2000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 2.5924e-16 - r2_keras: -99.1058 - rmse: 0.8707 - sae: 2552.2881 - sse: 3105.1553\n","Epoch 51: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 1.7925e-16 - r2_keras: -81.9775 - rmse: 0.8651 - sae: 1868.3628 - sse: 2260.6035 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -2.0263e-16 - val_r2_keras: -34.6895 - val_rmse: 0.9728 - val_sae: 374.8091 - val_sse: 500.6555 - learning_rate: 3.2000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 4.8630e-16 - r2_keras: -99.1061 - rmse: 0.8707 - sae: 2552.2915 - sse: 3105.1658\n","Epoch 52: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 3.1594e-16 - r2_keras: -81.9778 - rmse: 0.8651 - sae: 1868.3654 - sse: 2260.6111 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 3.1994e-17 - val_r2_keras: -34.6895 - val_rmse: 0.9728 - val_sae: 374.8096 - val_sse: 500.6568 - learning_rate: 3.2000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 7.0621e-17 - r2_keras: -99.1061 - rmse: 0.8707 - sae: 2552.2913 - sse: 3105.1675\n","Epoch 53: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 6.5439e-17 - r2_keras: -81.9779 - rmse: 0.8651 - sae: 1868.3656 - sse: 2260.6130 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 9.5983e-17 - val_r2_keras: -34.6897 - val_rmse: 0.9728 - val_sae: 374.8105 - val_sse: 500.6586 - learning_rate: 3.2000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 5.7211e-17 - r2_keras: -99.1066 - rmse: 0.8707 - sae: 2552.2949 - sse: 3105.1807\n","Epoch 54: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 2.0700e-17 - r2_keras: -81.9782 - rmse: 0.8651 - sae: 1868.3678 - sse: 2260.6213 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 3.1994e-16 - val_r2_keras: -34.6897 - val_rmse: 0.9728 - val_sae: 374.8110 - val_sse: 500.6595 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -7.8397e-16 - r2_keras: -99.1066 - rmse: 0.8707 - sae: 2552.2949 - sse: 3105.1814\n","Epoch 55: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -5.1806e-16 - r2_keras: -81.9782 - rmse: 0.8651 - sae: 1868.3679 - sse: 2260.6221 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -2.1329e-16 - val_r2_keras: -34.6898 - val_rmse: 0.9728 - val_sae: 374.8112 - val_sse: 500.6599 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 4.9404e-16 - r2_keras: -99.1066 - rmse: 0.8707 - sae: 2552.2949 - sse: 3105.1816\n","Epoch 56: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 3.0458e-16 - r2_keras: -81.9782 - rmse: 0.8651 - sae: 1868.3680 - sse: 2260.6223 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -5.3324e-17 - val_r2_keras: -34.6898 - val_rmse: 0.9728 - val_sae: 374.8114 - val_sse: 500.6605 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 4.1478e-16 - r2_keras: -99.1067 - rmse: 0.8707 - sae: 2552.2952 - sse: 3105.1831\n","Epoch 57: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 2.6275e-16 - r2_keras: -81.9783 - rmse: 0.8651 - sae: 1868.3683 - sse: 2260.6235 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -1.9196e-16 - val_r2_keras: -34.6898 - val_rmse: 0.9728 - val_sae: 374.8115 - val_sse: 500.6606 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -2.9500e-16 - r2_keras: -99.1067 - rmse: 0.8707 - sae: 2552.2954 - sse: 3105.1841\n","Epoch 58: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -1.4342e-16 - r2_keras: -81.9783 - rmse: 0.8651 - sae: 1868.3685 - sse: 2260.6245 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -3.1994e-17 - val_r2_keras: -34.6898 - val_rmse: 0.9728 - val_sae: 374.8117 - val_sse: 500.6611 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 5.6943e-16 - r2_keras: -99.1068 - rmse: 0.8707 - sae: 2552.2961 - sse: 3105.1877\n","Epoch 59: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 3.7411e-16 - r2_keras: -81.9784 - rmse: 0.8651 - sae: 1868.3691 - sse: 2260.6272 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -1.9196e-16 - val_r2_keras: -34.6899 - val_rmse: 0.9728 - val_sae: 374.8118 - val_sse: 500.6614 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 1.0042e-16 - r2_keras: -99.1068 - rmse: 0.8707 - sae: 2552.2964 - sse: 3105.1890\n","Epoch 60: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 3.7571e-17 - r2_keras: -81.9784 - rmse: 0.8651 - sae: 1868.3694 - sse: 2260.6282 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -2.9861e-16 - val_r2_keras: -34.6899 - val_rmse: 0.9728 - val_sae: 374.8119 - val_sse: 500.6617 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -8.5519e-17 - r2_keras: -99.1069 - rmse: 0.8707 - sae: 2552.2974 - sse: 3105.1921\n","Epoch 61: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -1.2035e-16 - r2_keras: -81.9785 - rmse: 0.8651 - sae: 1868.3702 - sse: 2260.6306 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -3.0928e-16 - val_r2_keras: -34.6899 - val_rmse: 0.9728 - val_sae: 374.8120 - val_sse: 500.6618 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -1.2843e-16 - r2_keras: -99.1070 - rmse: 0.8707 - sae: 2552.2974 - sse: 3105.1934\n","Epoch 62: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -9.4797e-17 - r2_keras: -81.9786 - rmse: 0.8651 - sae: 1868.3702 - sse: 2260.6313 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 9.5982e-17 - val_r2_keras: -34.6899 - val_rmse: 0.9728 - val_sae: 374.8120 - val_sse: 500.6620 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 5.5483e-16 - r2_keras: -99.1070 - rmse: 0.8707 - sae: 2552.2974 - sse: 3105.1941\n","Epoch 63: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 3.6071e-16 - r2_keras: -81.9786 - rmse: 0.8651 - sae: 1868.3704 - sse: 2260.6323 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -5.3323e-17 - val_r2_keras: -34.6899 - val_rmse: 0.9728 - val_sae: 374.8122 - val_sse: 500.6623 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -5.8284e-16 - r2_keras: -99.1071 - rmse: 0.8707 - sae: 2552.2983 - sse: 3105.1978\n","Epoch 64: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -4.0600e-16 - r2_keras: -81.9787 - rmse: 0.8651 - sae: 1868.3712 - sse: 2260.6350 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 8.5317e-17 - val_r2_keras: -34.6900 - val_rmse: 0.9728 - val_sae: 374.8123 - val_sse: 500.6626 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -2.0530e-16 - r2_keras: -99.1072 - rmse: 0.8707 - sae: 2552.2983 - sse: 3105.1990\n","Epoch 65: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -8.0876e-17 - r2_keras: -81.9787 - rmse: 0.8651 - sae: 1868.3712 - sse: 2260.6357 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -6.3988e-17 - val_r2_keras: -34.6900 - val_rmse: 0.9728 - val_sae: 374.8124 - val_sse: 500.6628 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -2.0322e-16 - r2_keras: -99.1073 - rmse: 0.8707 - sae: 2552.2996 - sse: 3105.2021\n","Epoch 66: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -1.0427e-16 - r2_keras: -81.9788 - rmse: 0.8651 - sae: 1868.3722 - sse: 2260.6382 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 4.2659e-17 - val_r2_keras: -34.6900 - val_rmse: 0.9728 - val_sae: 374.8125 - val_sse: 500.6631 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 6.6239e-16 - r2_keras: -99.1073 - rmse: 0.8707 - sae: 2552.2993 - sse: 3105.2031\n","Epoch 67: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 4.7005e-16 - r2_keras: -81.9789 - rmse: 0.8651 - sae: 1868.3721 - sse: 2260.6389 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -2.1329e-17 - val_r2_keras: -34.6900 - val_rmse: 0.9728 - val_sae: 374.8126 - val_sse: 500.6633 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -3.7842e-17 - r2_keras: -99.1074 - rmse: 0.8707 - sae: 2552.3003 - sse: 3105.2063\n","Epoch 68: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: -7.1124e-17 - r2_keras: -81.9790 - rmse: 0.8651 - sae: 1868.3729 - sse: 2260.6414 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 1.3864e-16 - val_r2_keras: -34.6900 - val_rmse: 0.9728 - val_sae: 374.8127 - val_sse: 500.6636 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 5.4291e-16 - r2_keras: -99.1075 - rmse: 0.8707 - sae: 2552.3008 - sse: 3105.2080\n","Epoch 69: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1404 - pearson_correlation: 3.8672e-16 - r2_keras: -81.9790 - rmse: 0.8651 - sae: 1868.3733 - sse: 2260.6428 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -4.4791e-16 - val_r2_keras: -34.6900 - val_rmse: 0.9728 - val_sae: 374.8127 - val_sse: 500.6636 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 2.2408e-16 - r2_keras: -99.1075 - rmse: 0.8707 - sae: 2552.3003 - sse: 3105.2080\n","Epoch 70: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1403 - pearson_correlation: 1.8518e-16 - r2_keras: -81.9790 - rmse: 0.8651 - sae: 1868.3730 - sse: 2260.6431 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 8.5317e-17 - val_r2_keras: -34.6901 - val_rmse: 0.9728 - val_sae: 374.8129 - val_sse: 500.6641 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 1.0638e-16 - r2_keras: -99.1076 - rmse: 0.8707 - sae: 2552.3018 - sse: 3105.2124\n","Epoch 71: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1403 - pearson_correlation: 9.1111e-17 - r2_keras: -81.9791 - rmse: 0.8651 - sae: 1868.3741 - sse: 2260.6462 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: -3.1994e-16 - val_r2_keras: -34.6901 - val_rmse: 0.9728 - val_sae: 374.8129 - val_sse: 500.6644 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: -7.2109e-17 - r2_keras: -99.1076 - rmse: 0.8707 - sae: 2552.3018 - sse: 3105.2134\n","Epoch 72: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1403 - pearson_correlation: -1.4110e-17 - r2_keras: -81.9792 - rmse: 0.8651 - sae: 1868.3743 - sse: 2260.6470 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 1.0665e-16 - val_r2_keras: -34.6901 - val_rmse: 0.9728 - val_sae: 374.8130 - val_sse: 500.6645 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0744 - loss: 0.1642 - mae: 0.2377 - mse: 0.1561 - pearson_correlation: 3.9362e-16 - r2_keras: -99.1077 - rmse: 0.8707 - sae: 2552.3027 - sse: 3105.2168\n","Epoch 73: val_loss did not improve from 0.20642\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0627 - loss: 0.1571 - mae: 0.2288 - mse: 0.1403 - pearson_correlation: 2.1927e-16 - r2_keras: -81.9793 - rmse: 0.8651 - sae: 1868.3751 - sse: 2260.6494 - val_huber_loss: 0.1212 - val_loss: 0.2110 - val_mae: 0.3201 - val_mse: 0.2721 - val_pearson_correlation: 3.1994e-16 - val_r2_keras: -34.6901 - val_rmse: 0.9728 - val_sae: 374.8130 - val_sse: 500.6648 - learning_rate: 1.0000e-05\n","| \u001b[39m11       \u001b[39m | \u001b[39m-0.211   \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m93.66    \u001b[39m | \u001b[39m74.74    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 1.0368 - loss: 1.1253 - mae: 1.4859 - mse: 3.3118 - pearson_correlation: 2.7454e-16 - r2_keras: -333.9092 - rmse: 1.5926 - sae: 5318.4136 - sse: 10388.4658\n","Epoch 1: val_loss improved from inf to 0.42485, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 465ms/step - huber_loss: 1.0048 - loss: 1.1058 - mae: 1.4554 - mse: 3.3768 - pearson_correlation: 1.6795e-16 - r2_keras: -290.5656 - rmse: 1.6453 - sae: 3898.7556 - sse: 7726.7207 - val_huber_loss: 0.3364 - val_loss: 0.4249 - val_mae: 0.6917 - val_mse: 0.8987 - val_pearson_correlation: -2.3034e-16 - val_r2_keras: -25.1227 - val_rmse: 0.8323 - val_sae: 314.2090 - val_sse: 366.4518 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 1.0198 - loss: 1.1083 - mae: 1.4655 - mse: 3.2416 - pearson_correlation: -7.0972e-16 - r2_keras: -326.9871 - rmse: 1.5760 - sae: 5252.5327 - sse: 10173.7480\n","Epoch 2: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9900 - loss: 1.0902 - mae: 1.4372 - mse: 3.3092 - pearson_correlation: -4.2749e-16 - r2_keras: -284.8763 - rmse: 1.6297 - sae: 3852.3894 - sse: 7570.9717 - val_huber_loss: 0.3877 - val_loss: 0.4762 - val_mae: 0.7686 - val_mse: 1.0097 - val_pearson_correlation: 3.2434e-16 - val_r2_keras: -26.9750 - val_rmse: 0.8613 - val_sae: 344.9519 - val_sse: 392.4362 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 1.0058 - loss: 1.0943 - mae: 1.4489 - mse: 3.1846 - pearson_correlation: -7.5095e-17 - r2_keras: -321.3840 - rmse: 1.5625 - sae: 5198.3916 - sse: 9999.9492\n","Epoch 3: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9778 - loss: 1.0773 - mae: 1.4223 - mse: 3.2537 - pearson_correlation: -9.0977e-17 - r2_keras: -280.2182 - rmse: 1.6167 - sae: 3814.1494 - sse: 7444.2812 - val_huber_loss: 0.4578 - val_loss: 0.5463 - val_mae: 0.8523 - val_mse: 1.1837 - val_pearson_correlation: -4.1320e-16 - val_r2_keras: -30.5563 - val_rmse: 0.9148 - val_sae: 377.7079 - val_sse: 442.6758 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9936 - loss: 1.0821 - mae: 1.4343 - mse: 3.1349 - pearson_correlation: 4.6348e-16 - r2_keras: -316.5121 - rmse: 1.5506 - sae: 5150.8628 - sse: 9848.8291\n","Epoch 4: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9671 - loss: 1.0659 - mae: 1.4091 - mse: 3.2052 - pearson_correlation: 2.1110e-16 - r2_keras: -276.1433 - rmse: 1.6052 - sae: 3780.5085 - sse: 7333.8350 - val_huber_loss: 0.5328 - val_loss: 0.6213 - val_mae: 0.9363 - val_mse: 1.4035 - val_pearson_correlation: -3.2183e-17 - val_r2_keras: -35.3577 - val_rmse: 0.9819 - val_sae: 413.3015 - val_sse: 510.0299 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9827 - loss: 1.0712 - mae: 1.4213 - mse: 3.0904 - pearson_correlation: -4.7390e-16 - r2_keras: -312.1697 - rmse: 1.5400 - sae: 5108.4287 - sse: 9714.1318\n","Epoch 5: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.9574 - loss: 1.0558 - mae: 1.3973 - mse: 3.1616 - pearson_correlation: -3.8596e-16 - r2_keras: -272.4839 - rmse: 1.5947 - sae: 3750.3823 - sse: 7235.0693 - val_huber_loss: 0.6032 - val_loss: 0.6917 - val_mae: 1.0168 - val_mse: 1.6395 - val_pearson_correlation: 8.9616e-17 - val_r2_keras: -40.8188 - val_rmse: 1.0531 - val_sae: 449.0547 - val_sse: 586.6384 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9726 - loss: 1.0611 - mae: 1.4094 - mse: 3.0495 - pearson_correlation: 3.0291e-16 - r2_keras: -308.1754 - rmse: 1.5302 - sae: 5069.3350 - sse: 9590.2324\n","Epoch 6: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9485 - loss: 1.0464 - mae: 1.3864 - mse: 3.1213 - pearson_correlation: 2.5154e-16 - r2_keras: -269.1063 - rmse: 1.5850 - sae: 3722.5759 - sse: 7144.0859 - val_huber_loss: 0.6695 - val_loss: 0.7580 - val_mae: 1.0862 - val_mse: 1.8878 - val_pearson_correlation: -1.6964e-16 - val_r2_keras: -46.9180 - val_rmse: 1.1273 - val_sae: 485.8436 - val_sse: 672.1984 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9632 - loss: 1.0517 - mae: 1.3982 - mse: 3.0114 - pearson_correlation: 2.7749e-18 - r2_keras: -304.4669 - rmse: 1.5209 - sae: 5032.8916 - sse: 9475.2002\n","Epoch 7: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9407 - loss: 1.0380 - mae: 1.3766 - mse: 3.0861 - pearson_correlation: -4.0098e-17 - r2_keras: -266.1705 - rmse: 1.5768 - sae: 3697.0955 - sse: 7061.9614 - val_huber_loss: 0.7314 - val_loss: 0.8199 - val_mae: 1.1445 - val_mse: 2.1374 - val_pearson_correlation: 7.4777e-17 - val_r2_keras: -53.5722 - val_rmse: 1.2030 - val_sae: 522.0280 - val_sse: 765.5451 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9615 - loss: 1.0500 - mae: 1.3962 - mse: 3.0042 - pearson_correlation: 3.3208e-16 - r2_keras: -303.7708 - rmse: 1.5192 - sae: 5026.0605 - sse: 9453.6074\n","Epoch 8: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9392 - loss: 1.0364 - mae: 1.3747 - mse: 3.0790 - pearson_correlation: 3.2638e-16 - r2_keras: -265.5784 - rmse: 1.5751 - sae: 3692.2261 - sse: 7046.0649 - val_huber_loss: 0.7847 - val_loss: 0.8732 - val_mae: 1.1906 - val_mse: 2.3698 - val_pearson_correlation: -2.4589e-17 - val_r2_keras: -60.2817 - val_rmse: 1.2748 - val_sae: 554.0643 - val_sse: 859.6667 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9598 - loss: 1.0483 - mae: 1.3942 - mse: 2.9974 - pearson_correlation: 4.7957e-16 - r2_keras: -303.1060 - rmse: 1.5176 - sae: 5019.5337 - sse: 9432.9863\n","Epoch 9: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9376 - loss: 1.0348 - mae: 1.3728 - mse: 3.0722 - pearson_correlation: 2.3825e-16 - r2_keras: -265.0124 - rmse: 1.5735 - sae: 3687.5718 - sse: 7030.8765 - val_huber_loss: 0.8279 - val_loss: 0.9164 - val_mae: 1.2212 - val_mse: 2.5704 - val_pearson_correlation: -2.2751e-17 - val_r2_keras: -66.5639 - val_rmse: 1.3385 - val_sae: 580.3950 - val_sse: 947.7944 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9582 - loss: 1.0467 - mae: 1.3923 - mse: 2.9909 - pearson_correlation: 2.2617e-16 - r2_keras: -302.4680 - rmse: 1.5160 - sae: 5013.2725 - sse: 9413.1982\n","Epoch 10: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9362 - loss: 1.0333 - mae: 1.3711 - mse: 3.0657 - pearson_correlation: 1.6394e-16 - r2_keras: -264.4688 - rmse: 1.5719 - sae: 3683.1052 - sse: 7016.2964 - val_huber_loss: 0.8614 - val_loss: 0.9499 - val_mae: 1.2476 - val_mse: 2.7302 - val_pearson_correlation: -2.3605e-16 - val_r2_keras: -72.0543 - val_rmse: 1.3919 - val_sae: 601.9699 - val_sse: 1024.8131 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9566 - loss: 1.0451 - mae: 1.3904 - mse: 2.9846 - pearson_correlation: -6.0453e-17 - r2_keras: -301.8553 - rmse: 1.5144 - sae: 5007.2666 - sse: 9394.1943\n","Epoch 11: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9348 - loss: 1.0318 - mae: 1.3694 - mse: 3.0595 - pearson_correlation: -2.4501e-17 - r2_keras: -263.9463 - rmse: 1.5703 - sae: 3678.8181 - sse: 7002.2891 - val_huber_loss: 0.8871 - val_loss: 0.9756 - val_mae: 1.2665 - val_mse: 2.8517 - val_pearson_correlation: -2.0544e-17 - val_r2_keras: -76.6315 - val_rmse: 1.4348 - val_sae: 619.1132 - val_sse: 1089.0237 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9552 - loss: 1.0436 - mae: 1.3887 - mse: 2.9785 - pearson_correlation: 3.8039e-16 - r2_keras: -301.2660 - rmse: 1.5130 - sae: 5001.5005 - sse: 9375.9121\n","Epoch 12: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9335 - loss: 1.0305 - mae: 1.3678 - mse: 3.0537 - pearson_correlation: 2.1670e-16 - r2_keras: -263.4641 - rmse: 1.5690 - sae: 3674.7471 - sse: 6989.0532 - val_huber_loss: 0.9057 - val_loss: 0.9942 - val_mae: 1.2848 - val_mse: 2.9372 - val_pearson_correlation: 1.9924e-16 - val_r2_keras: -80.1182 - val_rmse: 1.4667 - val_sae: 631.8839 - val_sse: 1137.9348 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.9544 - loss: 1.0429 - mae: 1.3878 - mse: 2.9756 - pearson_correlation: -1.1694e-16 - r2_keras: -300.9809 - rmse: 1.5122 - sae: 4998.7119 - sse: 9367.0684\n","Epoch 13: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9329 - loss: 1.0298 - mae: 1.3670 - mse: 3.0508 - pearson_correlation: -1.3070e-16 - r2_keras: -263.2203 - rmse: 1.5682 - sae: 3672.7542 - sse: 6982.5283 - val_huber_loss: 0.9184 - val_loss: 1.0069 - val_mae: 1.2957 - val_mse: 2.9929 - val_pearson_correlation: -5.1702e-16 - val_r2_keras: -82.6405 - val_rmse: 1.4893 - val_sae: 641.0502 - val_sse: 1173.3184 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9537 - loss: 1.0422 - mae: 1.3870 - mse: 2.9727 - pearson_correlation: -1.6315e-16 - r2_keras: -300.7039 - rmse: 1.5116 - sae: 4996.0039 - sse: 9358.4795\n","Epoch 14: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.9322 - loss: 1.0291 - mae: 1.3663 - mse: 3.0480 - pearson_correlation: -1.0349e-16 - r2_keras: -262.9834 - rmse: 1.5676 - sae: 3670.8184 - sse: 6976.1890 - val_huber_loss: 0.9271 - val_loss: 1.0156 - val_mae: 1.3072 - val_mse: 3.0284 - val_pearson_correlation: -3.8470e-17 - val_r2_keras: -84.4170 - val_rmse: 1.5050 - val_sae: 648.0318 - val_sse: 1198.2384 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9531 - loss: 1.0415 - mae: 1.3862 - mse: 2.9700 - pearson_correlation: 1.8284e-16 - r2_keras: -300.4344 - rmse: 1.5109 - sae: 4993.3682 - sse: 9350.1191\n","Epoch 15: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.9316 - loss: 1.0285 - mae: 1.3655 - mse: 3.0452 - pearson_correlation: 2.3539e-16 - r2_keras: -262.7527 - rmse: 1.5669 - sae: 3668.9338 - sse: 6970.0171 - val_huber_loss: 0.9324 - val_loss: 1.0209 - val_mae: 1.3140 - val_mse: 3.0485 - val_pearson_correlation: -1.2391e-16 - val_r2_keras: -85.5735 - val_rmse: 1.5152 - val_sae: 652.7806 - val_sse: 1214.4622 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9524 - loss: 1.0409 - mae: 1.3854 - mse: 2.9673 - pearson_correlation: 1.4234e-16 - r2_keras: -300.1717 - rmse: 1.5102 - sae: 4990.7983 - sse: 9341.9688\n","Epoch 16: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9310 - loss: 1.0279 - mae: 1.3648 - mse: 3.0426 - pearson_correlation: 1.7412e-16 - r2_keras: -262.5278 - rmse: 1.5662 - sae: 3667.0959 - sse: 6963.9995 - val_huber_loss: 0.9353 - val_loss: 1.0238 - val_mae: 1.3175 - val_mse: 3.0583 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -86.2947 - val_rmse: 1.5215 - val_sae: 656.0427 - val_sse: 1224.5798 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9517 - loss: 1.0402 - mae: 1.3846 - mse: 2.9647 - pearson_correlation: 1.3915e-16 - r2_keras: -299.9152 - rmse: 1.5096 - sae: 4988.2900 - sse: 9334.0127\n","Epoch 17: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.9304 - loss: 1.0273 - mae: 1.3641 - mse: 3.0399 - pearson_correlation: 9.0122e-17 - r2_keras: -262.3081 - rmse: 1.5656 - sae: 3665.3018 - sse: 6958.1245 - val_huber_loss: 0.9370 - val_loss: 1.0255 - val_mae: 1.3194 - val_mse: 3.0630 - val_pearson_correlation: -2.8340e-17 - val_r2_keras: -86.7579 - val_rmse: 1.5255 - val_sae: 658.3057 - val_sse: 1231.0779 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9511 - loss: 1.0396 - mae: 1.3839 - mse: 2.9621 - pearson_correlation: -1.4950e-17 - r2_keras: -299.6645 - rmse: 1.5089 - sae: 4985.8354 - sse: 9326.2363\n","Epoch 18: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9299 - loss: 1.0267 - mae: 1.3634 - mse: 3.0374 - pearson_correlation: -7.0760e-17 - r2_keras: -262.0933 - rmse: 1.5649 - sae: 3663.5459 - sse: 6952.3813 - val_huber_loss: 0.9379 - val_loss: 1.0264 - val_mae: 1.3202 - val_mse: 3.0648 - val_pearson_correlation: -4.5252e-16 - val_r2_keras: -87.0370 - val_rmse: 1.5279 - val_sae: 659.7568 - val_sse: 1234.9924 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9505 - loss: 1.0390 - mae: 1.3832 - mse: 2.9596 - pearson_correlation: -1.7996e-16 - r2_keras: -299.4193 - rmse: 1.5083 - sae: 4983.4355 - sse: 9318.6299\n","Epoch 19: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9293 - loss: 1.0261 - mae: 1.3627 - mse: 3.0349 - pearson_correlation: -9.3529e-17 - r2_keras: -261.8831 - rmse: 1.5643 - sae: 3661.8286 - sse: 6946.7627 - val_huber_loss: 0.9383 - val_loss: 1.0268 - val_mae: 1.3205 - val_mse: 3.0649 - val_pearson_correlation: 6.5915e-17 - val_r2_keras: -87.1965 - val_rmse: 1.5293 - val_sae: 660.6738 - val_sse: 1237.2307 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9499 - loss: 1.0384 - mae: 1.3824 - mse: 2.9571 - pearson_correlation: -2.8527e-16 - r2_keras: -299.1790 - rmse: 1.5077 - sae: 4981.0830 - sse: 9311.1758\n","Epoch 20: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9287 - loss: 1.0255 - mae: 1.3620 - mse: 3.0324 - pearson_correlation: -2.8013e-16 - r2_keras: -261.6771 - rmse: 1.5637 - sae: 3660.1450 - sse: 6941.2554 - val_huber_loss: 0.9383 - val_loss: 1.0268 - val_mae: 1.3204 - val_mse: 3.0642 - val_pearson_correlation: -3.7644e-17 - val_r2_keras: -87.2794 - val_rmse: 1.5300 - val_sae: 661.2153 - val_sse: 1238.3931 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9493 - loss: 1.0378 - mae: 1.3817 - mse: 2.9547 - pearson_correlation: 2.7887e-16 - r2_keras: -298.9435 - rmse: 1.5071 - sae: 4978.7778 - sse: 9303.8721\n","Epoch 21: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.9282 - loss: 1.0249 - mae: 1.3614 - mse: 3.0300 - pearson_correlation: 2.0179e-16 - r2_keras: -261.4752 - rmse: 1.5631 - sae: 3658.4951 - sse: 6935.8594 - val_huber_loss: 0.9382 - val_loss: 1.0267 - val_mae: 1.3201 - val_mse: 3.0629 - val_pearson_correlation: -9.4088e-17 - val_r2_keras: -87.3125 - val_rmse: 1.5303 - val_sae: 661.4888 - val_sse: 1238.8567 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9487 - loss: 1.0372 - mae: 1.3811 - mse: 2.9523 - pearson_correlation: -1.3810e-16 - r2_keras: -298.7124 - rmse: 1.5066 - sae: 4976.5137 - sse: 9296.7051\n","Epoch 22: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9277 - loss: 1.0244 - mae: 1.3608 - mse: 3.0276 - pearson_correlation: -3.3816e-17 - r2_keras: -261.2770 - rmse: 1.5625 - sae: 3656.8745 - sse: 6930.5630 - val_huber_loss: 0.9379 - val_loss: 1.0264 - val_mae: 1.3197 - val_mse: 3.0614 - val_pearson_correlation: 1.5054e-16 - val_r2_keras: -87.3135 - val_rmse: 1.5303 - val_sae: 661.5801 - val_sse: 1238.8711 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9481 - loss: 1.0366 - mae: 1.3804 - mse: 2.9500 - pearson_correlation: 1.0351e-16 - r2_keras: -298.4854 - rmse: 1.5060 - sae: 4974.2891 - sse: 9289.6621\n","Epoch 23: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9272 - loss: 1.0238 - mae: 1.3601 - mse: 3.0253 - pearson_correlation: 5.8409e-17 - r2_keras: -261.0822 - rmse: 1.5620 - sae: 3655.2820 - sse: 6925.3584 - val_huber_loss: 0.9376 - val_loss: 1.0261 - val_mae: 1.3193 - val_mse: 3.0596 - val_pearson_correlation: 5.6463e-17 - val_r2_keras: -87.2941 - val_rmse: 1.5302 - val_sae: 661.5576 - val_sse: 1238.5989 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9476 - loss: 1.0360 - mae: 1.3797 - mse: 2.9477 - pearson_correlation: 6.7335e-16 - r2_keras: -298.2621 - rmse: 1.5054 - sae: 4972.1001 - sse: 9282.7363\n","Epoch 24: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.9266 - loss: 1.0233 - mae: 1.3595 - mse: 3.0230 - pearson_correlation: 3.9590e-16 - r2_keras: -260.8906 - rmse: 1.5614 - sae: 3653.7146 - sse: 6920.2397 - val_huber_loss: 0.9372 - val_loss: 1.0257 - val_mae: 1.3188 - val_mse: 3.0577 - val_pearson_correlation: -2.1650e-16 - val_r2_keras: -87.2618 - val_rmse: 1.5299 - val_sae: 661.4584 - val_sse: 1238.1464 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9470 - loss: 1.0355 - mae: 1.3790 - mse: 2.9454 - pearson_correlation: -1.3126e-17 - r2_keras: -298.0425 - rmse: 1.5049 - sae: 4969.9473 - sse: 9275.9258\n","Epoch 25: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9261 - loss: 1.0228 - mae: 1.3589 - mse: 3.0208 - pearson_correlation: 4.1616e-17 - r2_keras: -260.7021 - rmse: 1.5608 - sae: 3652.1731 - sse: 6915.2065 - val_huber_loss: 0.9368 - val_loss: 1.0253 - val_mae: 1.3183 - val_mse: 3.0558 - val_pearson_correlation: -1.4124e-16 - val_r2_keras: -87.2216 - val_rmse: 1.5295 - val_sae: 661.3114 - val_sse: 1237.5826 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.9465 - loss: 1.0349 - mae: 1.3784 - mse: 2.9432 - pearson_correlation: 7.6825e-16 - r2_keras: -297.8266 - rmse: 1.5043 - sae: 4967.8296 - sse: 9269.2275\n","Epoch 26: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9256 - loss: 1.0223 - mae: 1.3583 - mse: 3.0186 - pearson_correlation: 4.7504e-16 - r2_keras: -260.5168 - rmse: 1.5603 - sae: 3650.6565 - sse: 6910.2549 - val_huber_loss: 0.9364 - val_loss: 1.0249 - val_mae: 1.3177 - val_mse: 3.0539 - val_pearson_correlation: 3.9560e-16 - val_r2_keras: -87.1765 - val_rmse: 1.5291 - val_sae: 661.1348 - val_sse: 1236.9492 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9459 - loss: 1.0344 - mae: 1.3778 - mse: 2.9410 - pearson_correlation: -3.4488e-16 - r2_keras: -297.6144 - rmse: 1.5038 - sae: 4965.7495 - sse: 9262.6465\n","Epoch 27: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9252 - loss: 1.0218 - mae: 1.3577 - mse: 3.0164 - pearson_correlation: -2.2462e-16 - r2_keras: -260.3346 - rmse: 1.5598 - sae: 3649.1663 - sse: 6905.3892 - val_huber_loss: 0.9360 - val_loss: 1.0244 - val_mae: 1.3172 - val_mse: 3.0519 - val_pearson_correlation: -3.2979e-16 - val_r2_keras: -87.1285 - val_rmse: 1.5287 - val_sae: 660.9411 - val_sse: 1236.2765 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9454 - loss: 1.0339 - mae: 1.3771 - mse: 2.9389 - pearson_correlation: 1.3520e-16 - r2_keras: -297.4052 - rmse: 1.5033 - sae: 4963.6982 - sse: 9256.1572\n","Epoch 28: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9247 - loss: 1.0213 - mae: 1.3571 - mse: 3.0143 - pearson_correlation: 3.7053e-17 - r2_keras: -260.1549 - rmse: 1.5592 - sae: 3647.6970 - sse: 6900.5918 - val_huber_loss: 0.9355 - val_loss: 1.0240 - val_mae: 1.3167 - val_mse: 3.0500 - val_pearson_correlation: -1.2254e-16 - val_r2_keras: -87.0791 - val_rmse: 1.5283 - val_sae: 660.7369 - val_sse: 1235.5825 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9449 - loss: 1.0334 - mae: 1.3765 - mse: 2.9368 - pearson_correlation: -1.6438e-16 - r2_keras: -297.1991 - rmse: 1.5027 - sae: 4961.6753 - sse: 9249.7637\n","Epoch 29: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9242 - loss: 1.0208 - mae: 1.3566 - mse: 3.0122 - pearson_correlation: -1.3082e-16 - r2_keras: -259.9778 - rmse: 1.5587 - sae: 3646.2473 - sse: 6895.8638 - val_huber_loss: 0.9351 - val_loss: 1.0236 - val_mae: 1.3161 - val_mse: 3.0481 - val_pearson_correlation: 5.6579e-17 - val_r2_keras: -87.0288 - val_rmse: 1.5279 - val_sae: 660.5269 - val_sse: 1234.8776 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9443 - loss: 1.0328 - mae: 1.3759 - mse: 2.9347 - pearson_correlation: -2.3916e-16 - r2_keras: -296.9956 - rmse: 1.5022 - sae: 4959.6772 - sse: 9243.4521\n","Epoch 30: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.9237 - loss: 1.0203 - mae: 1.3560 - mse: 3.0101 - pearson_correlation: -2.1256e-16 - r2_keras: -259.8030 - rmse: 1.5582 - sae: 3644.8157 - sse: 6891.1968 - val_huber_loss: 0.9346 - val_loss: 1.0231 - val_mae: 1.3156 - val_mse: 3.0462 - val_pearson_correlation: -3.3961e-16 - val_r2_keras: -86.9783 - val_rmse: 1.5274 - val_sae: 660.3140 - val_sse: 1234.1697 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9438 - loss: 1.0323 - mae: 1.3753 - mse: 2.9326 - pearson_correlation: -5.3727e-16 - r2_keras: -296.7950 - rmse: 1.5017 - sae: 4957.7080 - sse: 9237.2285\n","Epoch 31: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9233 - loss: 1.0198 - mae: 1.3555 - mse: 3.0080 - pearson_correlation: -3.7944e-16 - r2_keras: -259.6306 - rmse: 1.5577 - sae: 3643.4045 - sse: 6886.5947 - val_huber_loss: 0.9342 - val_loss: 1.0227 - val_mae: 1.3151 - val_mse: 3.0443 - val_pearson_correlation: -3.5861e-16 - val_r2_keras: -86.9280 - val_rmse: 1.5270 - val_sae: 660.1013 - val_sse: 1233.4629 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9433 - loss: 1.0318 - mae: 1.3747 - mse: 2.9306 - pearson_correlation: -3.1977e-17 - r2_keras: -296.5970 - rmse: 1.5012 - sae: 4955.7637 - sse: 9231.0879\n","Epoch 32: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9228 - loss: 1.0193 - mae: 1.3549 - mse: 3.0060 - pearson_correlation: -4.2581e-17 - r2_keras: -259.4605 - rmse: 1.5572 - sae: 3642.0112 - sse: 6882.0532 - val_huber_loss: 0.9338 - val_loss: 1.0223 - val_mae: 1.3146 - val_mse: 3.0424 - val_pearson_correlation: 8.4968e-17 - val_r2_keras: -86.8779 - val_rmse: 1.5266 - val_sae: 659.8890 - val_sse: 1232.7603 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9428 - loss: 1.0313 - mae: 1.3742 - mse: 2.9286 - pearson_correlation: 1.3032e-16 - r2_keras: -296.4018 - rmse: 1.5007 - sae: 4953.8447 - sse: 9225.0303\n","Epoch 33: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9224 - loss: 1.0189 - mae: 1.3544 - mse: 3.0040 - pearson_correlation: 2.4375e-16 - r2_keras: -259.2926 - rmse: 1.5567 - sae: 3640.6360 - sse: 6877.5728 - val_huber_loss: 0.9334 - val_loss: 1.0218 - val_mae: 1.3141 - val_mse: 3.0406 - val_pearson_correlation: 1.7945e-16 - val_r2_keras: -86.8282 - val_rmse: 1.5261 - val_sae: 659.6780 - val_sse: 1232.0631 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.9424 - loss: 1.0308 - mae: 1.3736 - mse: 2.9266 - pearson_correlation: 2.8521e-16 - r2_keras: -296.2088 - rmse: 1.5002 - sae: 4951.9492 - sse: 9219.0459\n","Epoch 34: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9219 - loss: 1.0184 - mae: 1.3538 - mse: 3.0020 - pearson_correlation: 2.6728e-16 - r2_keras: -259.1268 - rmse: 1.5562 - sae: 3639.2773 - sse: 6873.1470 - val_huber_loss: 0.9329 - val_loss: 1.0214 - val_mae: 1.3136 - val_mse: 3.0387 - val_pearson_correlation: 1.7951e-16 - val_r2_keras: -86.7789 - val_rmse: 1.5257 - val_sae: 659.4684 - val_sse: 1231.3723 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9419 - loss: 1.0304 - mae: 1.3730 - mse: 2.9246 - pearson_correlation: 2.7168e-16 - r2_keras: -296.0184 - rmse: 1.4998 - sae: 4950.0771 - sse: 9213.1406\n","Epoch 35: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9215 - loss: 1.0179 - mae: 1.3533 - mse: 3.0001 - pearson_correlation: 2.1305e-16 - r2_keras: -258.9631 - rmse: 1.5557 - sae: 3637.9353 - sse: 6868.7788 - val_huber_loss: 0.9325 - val_loss: 1.0210 - val_mae: 1.3131 - val_mse: 3.0369 - val_pearson_correlation: -1.2287e-16 - val_r2_keras: -86.7302 - val_rmse: 1.5253 - val_sae: 659.2608 - val_sse: 1230.6886 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9414 - loss: 1.0299 - mae: 1.3724 - mse: 2.9227 - pearson_correlation: 6.7358e-17 - r2_keras: -295.8303 - rmse: 1.4993 - sae: 4948.2290 - sse: 9207.3037\n","Epoch 36: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9210 - loss: 1.0175 - mae: 1.3528 - mse: 2.9981 - pearson_correlation: 6.0875e-17 - r2_keras: -258.8013 - rmse: 1.5552 - sae: 3636.6106 - sse: 6864.4614 - val_huber_loss: 0.9321 - val_loss: 1.0206 - val_mae: 1.3126 - val_mse: 3.0351 - val_pearson_correlation: -3.5930e-16 - val_r2_keras: -86.6819 - val_rmse: 1.5248 - val_sae: 659.0551 - val_sse: 1230.0118 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9409 - loss: 1.0294 - mae: 1.3719 - mse: 2.9208 - pearson_correlation: -4.0337e-16 - r2_keras: -295.6443 - rmse: 1.4988 - sae: 4946.4023 - sse: 9201.5352\n","Epoch 37: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9206 - loss: 1.0170 - mae: 1.3523 - mse: 2.9962 - pearson_correlation: -3.3015e-16 - r2_keras: -258.6414 - rmse: 1.5547 - sae: 3635.3008 - sse: 6860.1938 - val_huber_loss: 0.9317 - val_loss: 1.0202 - val_mae: 1.3121 - val_mse: 3.0334 - val_pearson_correlation: 4.8239e-16 - val_r2_keras: -86.6343 - val_rmse: 1.5244 - val_sae: 658.8517 - val_sse: 1229.3430 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9405 - loss: 1.0289 - mae: 1.3713 - mse: 2.9189 - pearson_correlation: 8.4854e-17 - r2_keras: -295.4604 - rmse: 1.4984 - sae: 4944.5957 - sse: 9195.8320\n","Epoch 38: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9202 - loss: 1.0166 - mae: 1.3518 - mse: 2.9943 - pearson_correlation: -5.2632e-17 - r2_keras: -258.4833 - rmse: 1.5543 - sae: 3634.0056 - sse: 6855.9751 - val_huber_loss: 0.9313 - val_loss: 1.0198 - val_mae: 1.3116 - val_mse: 3.0316 - val_pearson_correlation: 1.8924e-16 - val_r2_keras: -86.5871 - val_rmse: 1.5240 - val_sae: 658.6503 - val_sse: 1228.6808 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.9400 - loss: 1.0285 - mae: 1.3708 - mse: 2.9170 - pearson_correlation: -2.8107e-16 - r2_keras: -295.2787 - rmse: 1.4979 - sae: 4942.8086 - sse: 9190.1934\n","Epoch 39: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9198 - loss: 1.0162 - mae: 1.3513 - mse: 2.9925 - pearson_correlation: -3.5411e-18 - r2_keras: -258.3269 - rmse: 1.5538 - sae: 3632.7239 - sse: 6851.8032 - val_huber_loss: 0.9309 - val_loss: 1.0194 - val_mae: 1.3111 - val_mse: 3.0299 - val_pearson_correlation: 1.0412e-16 - val_r2_keras: -86.5404 - val_rmse: 1.5236 - val_sae: 658.4510 - val_sse: 1228.0264 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9395 - loss: 1.0280 - mae: 1.3703 - mse: 2.9152 - pearson_correlation: 1.1889e-16 - r2_keras: -295.0989 - rmse: 1.4974 - sae: 4941.0410 - sse: 9184.6172\n","Epoch 40: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9193 - loss: 1.0157 - mae: 1.3508 - mse: 2.9906 - pearson_correlation: 9.5250e-17 - r2_keras: -258.1723 - rmse: 1.5533 - sae: 3631.4563 - sse: 6847.6777 - val_huber_loss: 0.9305 - val_loss: 1.0190 - val_mae: 1.3106 - val_mse: 3.0282 - val_pearson_correlation: -3.7876e-17 - val_r2_keras: -86.4943 - val_rmse: 1.5232 - val_sae: 658.2538 - val_sse: 1227.3790 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9391 - loss: 1.0276 - mae: 1.3697 - mse: 2.9133 - pearson_correlation: -2.7232e-16 - r2_keras: -294.9211 - rmse: 1.4970 - sae: 4939.2944 - sse: 9179.1035\n","Epoch 41: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9189 - loss: 1.0153 - mae: 1.3503 - mse: 2.9888 - pearson_correlation: -2.1887e-16 - r2_keras: -258.0193 - rmse: 1.5529 - sae: 3630.2039 - sse: 6843.5977 - val_huber_loss: 0.9301 - val_loss: 1.0186 - val_mae: 1.3102 - val_mse: 3.0265 - val_pearson_correlation: -6.6307e-17 - val_r2_keras: -86.4485 - val_rmse: 1.5228 - val_sae: 658.0584 - val_sse: 1226.7374 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9386 - loss: 1.0271 - mae: 1.3692 - mse: 2.9115 - pearson_correlation: 3.2436e-16 - r2_keras: -294.7454 - rmse: 1.4965 - sae: 4937.5664 - sse: 9173.6523\n","Epoch 42: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9185 - loss: 1.0149 - mae: 1.3498 - mse: 2.9870 - pearson_correlation: 9.8894e-17 - r2_keras: -257.8681 - rmse: 1.5524 - sae: 3628.9644 - sse: 6839.5640 - val_huber_loss: 0.9297 - val_loss: 1.0182 - val_mae: 1.3097 - val_mse: 3.0248 - val_pearson_correlation: -1.9899e-16 - val_r2_keras: -86.4033 - val_rmse: 1.5224 - val_sae: 657.8651 - val_sse: 1226.1031 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.9382 - loss: 1.0267 - mae: 1.3687 - mse: 2.9098 - pearson_correlation: -4.4398e-17 - r2_keras: -294.5717 - rmse: 1.4961 - sae: 4935.8604 - sse: 9168.2637\n","Epoch 43: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9181 - loss: 1.0145 - mae: 1.3493 - mse: 2.9852 - pearson_correlation: 7.7115e-17 - r2_keras: -257.7185 - rmse: 1.5520 - sae: 3627.7402 - sse: 6835.5757 - val_huber_loss: 0.9294 - val_loss: 1.0179 - val_mae: 1.3092 - val_mse: 3.0232 - val_pearson_correlation: 1.3271e-16 - val_r2_keras: -86.3585 - val_rmse: 1.5220 - val_sae: 657.6733 - val_sse: 1225.4746 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.9378 - loss: 1.0262 - mae: 1.3682 - mse: 2.9080 - pearson_correlation: 1.5120e-17 - r2_keras: -294.3997 - rmse: 1.4957 - sae: 4934.1709 - sse: 9162.9277\n","Epoch 44: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9177 - loss: 1.0141 - mae: 1.3488 - mse: 2.9834 - pearson_correlation: -6.7312e-17 - r2_keras: -257.5704 - rmse: 1.5516 - sae: 3626.5283 - sse: 6831.6255 - val_huber_loss: 0.9290 - val_loss: 1.0175 - val_mae: 1.3088 - val_mse: 3.0215 - val_pearson_correlation: 1.8965e-17 - val_r2_keras: -86.3141 - val_rmse: 1.5216 - val_sae: 657.4833 - val_sse: 1224.8519 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9373 - loss: 1.0258 - mae: 1.3677 - mse: 2.9062 - pearson_correlation: -8.8862e-17 - r2_keras: -294.2295 - rmse: 1.4952 - sae: 4932.4971 - sse: 9157.6484\n","Epoch 45: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9173 - loss: 1.0136 - mae: 1.3483 - mse: 2.9817 - pearson_correlation: -4.3224e-17 - r2_keras: -257.4238 - rmse: 1.5511 - sae: 3625.3274 - sse: 6827.7173 - val_huber_loss: 0.9286 - val_loss: 1.0171 - val_mae: 1.3083 - val_mse: 3.0199 - val_pearson_correlation: -7.5884e-17 - val_r2_keras: -86.2702 - val_rmse: 1.5213 - val_sae: 657.2953 - val_sse: 1224.2361 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9369 - loss: 1.0254 - mae: 1.3672 - mse: 2.9045 - pearson_correlation: 5.6694e-16 - r2_keras: -294.0608 - rmse: 1.4948 - sae: 4930.8398 - sse: 9152.4180\n","Epoch 46: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9169 - loss: 1.0132 - mae: 1.3479 - mse: 2.9800 - pearson_correlation: 3.4058e-16 - r2_keras: -257.2785 - rmse: 1.5507 - sae: 3624.1384 - sse: 6823.8457 - val_huber_loss: 0.9282 - val_loss: 1.0167 - val_mae: 1.3079 - val_mse: 3.0183 - val_pearson_correlation: 1.1387e-16 - val_r2_keras: -86.2267 - val_rmse: 1.5209 - val_sae: 657.1088 - val_sse: 1223.6254 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9365 - loss: 1.0250 - mae: 1.3667 - mse: 2.9028 - pearson_correlation: 2.6158e-16 - r2_keras: -293.8939 - rmse: 1.4944 - sae: 4929.1997 - sse: 9147.2402\n","Epoch 47: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9166 - loss: 1.0128 - mae: 1.3474 - mse: 2.9782 - pearson_correlation: 2.9192e-16 - r2_keras: -257.1347 - rmse: 1.5503 - sae: 3622.9617 - sse: 6820.0122 - val_huber_loss: 0.9279 - val_loss: 1.0164 - val_mae: 1.3074 - val_mse: 3.0167 - val_pearson_correlation: -3.6069e-16 - val_r2_keras: -86.1836 - val_rmse: 1.5205 - val_sae: 656.9240 - val_sse: 1223.0209 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9361 - loss: 1.0245 - mae: 1.3662 - mse: 2.9011 - pearson_correlation: 2.8486e-16 - r2_keras: -293.7284 - rmse: 1.4940 - sae: 4927.5732 - sse: 9142.1074\n","Epoch 48: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9162 - loss: 1.0124 - mae: 1.3469 - mse: 2.9765 - pearson_correlation: 1.6586e-16 - r2_keras: -256.9922 - rmse: 1.5498 - sae: 3621.7947 - sse: 6816.2124 - val_huber_loss: 0.9275 - val_loss: 1.0160 - val_mae: 1.3070 - val_mse: 3.0151 - val_pearson_correlation: 4.7476e-17 - val_r2_keras: -86.1410 - val_rmse: 1.5201 - val_sae: 656.7413 - val_sse: 1222.4236 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.9356 - loss: 1.0241 - mae: 1.3657 - mse: 2.8994 - pearson_correlation: -4.1087e-16 - r2_keras: -293.5645 - rmse: 1.4936 - sae: 4925.9619 - sse: 9137.0234\n","Epoch 49: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9158 - loss: 1.0120 - mae: 1.3465 - mse: 2.9749 - pearson_correlation: -3.3539e-16 - r2_keras: -256.8510 - rmse: 1.5494 - sae: 3620.6384 - sse: 6812.4478 - val_huber_loss: 0.9272 - val_loss: 1.0156 - val_mae: 1.3066 - val_mse: 3.0136 - val_pearson_correlation: -4.7491e-16 - val_r2_keras: -86.0988 - val_rmse: 1.5198 - val_sae: 656.5602 - val_sse: 1221.8313 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9352 - loss: 1.0237 - mae: 1.3652 - mse: 2.8977 - pearson_correlation: 2.5428e-16 - r2_keras: -293.4021 - rmse: 1.4931 - sae: 4924.3633 - sse: 9131.9844\n","Epoch 50: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.9154 - loss: 1.0117 - mae: 1.3460 - mse: 2.9732 - pearson_correlation: 1.6417e-16 - r2_keras: -256.7109 - rmse: 1.5490 - sae: 3619.4912 - sse: 6808.7168 - val_huber_loss: 0.9268 - val_loss: 1.0153 - val_mae: 1.3061 - val_mse: 3.0120 - val_pearson_correlation: -3.2305e-16 - val_r2_keras: -86.0570 - val_rmse: 1.5194 - val_sae: 656.3813 - val_sse: 1221.2446 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.9348 - loss: 1.0233 - mae: 1.3647 - mse: 2.8961 - pearson_correlation: -3.3158e-16 - r2_keras: -293.2411 - rmse: 1.4927 - sae: 4922.7803 - sse: 9126.9922\n","Epoch 51: val_loss did not improve from 0.42485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9150 - loss: 1.0113 - mae: 1.3456 - mse: 2.9715 - pearson_correlation: -2.8524e-16 - r2_keras: -256.5722 - rmse: 1.5486 - sae: 3618.3547 - sse: 6805.0195 - val_huber_loss: 0.9264 - val_loss: 1.0149 - val_mae: 1.3057 - val_mse: 3.0105 - val_pearson_correlation: 3.4216e-16 - val_r2_keras: -86.0155 - val_rmse: 1.5190 - val_sae: 656.2037 - val_sse: 1220.6630 - learning_rate: 1.0000e-05\n","| \u001b[39m12       \u001b[39m | \u001b[39m-1.015   \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m96.93    \u001b[39m | \u001b[39m73.78    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.5163 - loss: 0.6053 - mae: 0.9157 - mse: 1.2946 - pearson_correlation: -4.2725e-16 - r2_keras: -235.7180 - rmse: 1.3389 - sae: 4113.4043 - sse: 7342.6973\n","Epoch 1: val_loss improved from inf to 0.44911, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - huber_loss: 0.4964 - loss: 0.5933 - mae: 0.9067 - mse: 1.2465 - pearson_correlation: -3.5765e-16 - r2_keras: -191.5764 - rmse: 1.3090 - sae: 2994.8174 - sse: 5302.9185 - val_huber_loss: 0.3601 - val_loss: 0.4491 - val_mae: 0.7341 - val_mse: 0.9472 - val_pearson_correlation: -2.9263e-16 - val_r2_keras: -30.0451 - val_rmse: 0.9073 - val_sae: 346.8300 - val_sse: 435.5037 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4931 - loss: 0.5821 - mae: 0.8910 - mse: 1.2271 - pearson_correlation: -7.5714e-16 - r2_keras: -226.8727 - rmse: 1.3136 - sae: 4039.1243 - sse: 7068.3247\n","Epoch 2: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.4737 - loss: 0.5703 - mae: 0.8822 - mse: 1.1823 - pearson_correlation: -4.0931e-16 - r2_keras: -184.3680 - rmse: 1.2842 - sae: 2940.5217 - sse: 5104.6196 - val_huber_loss: 0.4306 - val_loss: 0.5196 - val_mae: 0.8051 - val_mse: 1.1641 - val_pearson_correlation: -1.0530e-16 - val_r2_keras: -36.9078 - val_rmse: 1.0026 - val_sae: 377.9463 - val_sse: 531.7748 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4754 - loss: 0.5644 - mae: 0.8717 - mse: 1.1767 - pearson_correlation: 1.3439e-16 - r2_keras: -220.2741 - rmse: 1.2945 - sae: 3982.5056 - sse: 6863.6465\n","Epoch 3: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.4559 - loss: 0.5525 - mae: 0.8628 - mse: 1.1336 - pearson_correlation: 2.9196e-17 - r2_keras: -178.9010 - rmse: 1.2649 - sae: 2898.7429 - sse: 4955.6406 - val_huber_loss: 0.5087 - val_loss: 0.5978 - val_mae: 0.8809 - val_mse: 1.4160 - val_pearson_correlation: -6.5799e-17 - val_r2_keras: -44.8286 - val_rmse: 1.1024 - val_sae: 413.4606 - val_sse: 642.8887 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.4601 - loss: 0.5491 - mae: 0.8547 - mse: 1.1341 - pearson_correlation: -4.2518e-16 - r2_keras: -214.7301 - rmse: 1.2782 - sae: 3933.9033 - sse: 6691.6768\n","Epoch 4: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.4403 - loss: 0.5371 - mae: 0.8456 - mse: 1.0924 - pearson_correlation: -2.7010e-16 - r2_keras: -174.2839 - rmse: 1.2482 - sae: 2862.7366 - sse: 4830.1899 - val_huber_loss: 0.5784 - val_loss: 0.6675 - val_mae: 0.9534 - val_mse: 1.6597 - val_pearson_correlation: 2.9854e-16 - val_r2_keras: -52.4006 - val_rmse: 1.1900 - val_sae: 448.6896 - val_sse: 749.1100 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4466 - loss: 0.5356 - mae: 0.8394 - mse: 1.0975 - pearson_correlation: 4.9451e-16 - r2_keras: -209.9651 - rmse: 1.2640 - sae: 3891.0562 - sse: 6543.8750\n","Epoch 5: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.4267 - loss: 0.5235 - mae: 0.8301 - mse: 1.0569 - pearson_correlation: 2.3389e-16 - r2_keras: -170.3000 - rmse: 1.2337 - sae: 2830.9177 - sse: 4722.1860 - val_huber_loss: 0.6309 - val_loss: 0.7200 - val_mae: 1.0153 - val_mse: 1.8396 - val_pearson_correlation: -6.2754e-17 - val_r2_keras: -58.2131 - val_rmse: 1.2531 - val_sae: 477.7878 - val_sse: 830.6484 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4345 - loss: 0.5235 - mae: 0.8253 - mse: 1.0651 - pearson_correlation: -2.3340e-16 - r2_keras: -205.7858 - rmse: 1.2514 - sae: 3852.7891 - sse: 6414.2378\n","Epoch 6: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.4144 - loss: 0.5113 - mae: 0.8158 - mse: 1.0254 - pearson_correlation: -1.3430e-16 - r2_keras: -166.7941 - rmse: 1.2207 - sae: 2802.4395 - sse: 4627.3188 - val_huber_loss: 0.6634 - val_loss: 0.7524 - val_mae: 1.0606 - val_mse: 1.9272 - val_pearson_correlation: 1.1937e-16 - val_r2_keras: -61.3964 - val_rmse: 1.2863 - val_sae: 497.6986 - val_sse: 875.3031 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4235 - loss: 0.5125 - mae: 0.8123 - mse: 1.0362 - pearson_correlation: 9.7794e-18 - r2_keras: -202.0692 - rmse: 1.2401 - sae: 3817.8257 - sse: 6298.9536\n","Epoch 7: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.4045 - loss: 0.5010 - mae: 0.8036 - mse: 0.9989 - pearson_correlation: 1.6210e-17 - r2_keras: -163.8745 - rmse: 1.2103 - sae: 2777.3286 - sse: 4545.2803 - val_huber_loss: 0.6822 - val_loss: 0.7712 - val_mae: 1.0862 - val_mse: 1.9441 - val_pearson_correlation: -2.0766e-16 - val_r2_keras: -62.7439 - val_rmse: 1.3001 - val_sae: 510.0314 - val_sse: 894.2064 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4214 - loss: 0.5105 - mae: 0.8099 - mse: 1.0309 - pearson_correlation: -3.7928e-16 - r2_keras: -201.3888 - rmse: 1.2380 - sae: 3811.3164 - sse: 6277.8462\n","Epoch 8: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.4024 - loss: 0.4989 - mae: 0.8011 - mse: 0.9938 - pearson_correlation: -1.6807e-16 - r2_keras: -163.2996 - rmse: 1.2081 - sae: 2772.4736 - sse: 4529.7856 - val_huber_loss: 0.6779 - val_loss: 0.7670 - val_mae: 1.0811 - val_mse: 1.8717 - val_pearson_correlation: -8.7877e-17 - val_r2_keras: -61.6958 - val_rmse: 1.2894 - val_sae: 511.8185 - val_sse: 879.5041 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4195 - loss: 0.5086 - mae: 0.8076 - mse: 1.0259 - pearson_correlation: -1.1608e-16 - r2_keras: -200.7434 - rmse: 1.2360 - sae: 3805.1067 - sse: 6257.8281\n","Epoch 9: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.4005 - loss: 0.4970 - mae: 0.7987 - mse: 0.9889 - pearson_correlation: -1.1638e-16 - r2_keras: -162.7538 - rmse: 1.2060 - sae: 2767.8425 - sse: 4515.0854 - val_huber_loss: 0.6542 - val_loss: 0.7432 - val_mae: 1.0485 - val_mse: 1.7371 - val_pearson_correlation: -1.1779e-16 - val_r2_keras: -59.1465 - val_rmse: 1.2629 - val_sae: 504.8322 - val_sse: 843.7410 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.4176 - loss: 0.5067 - mae: 0.8053 - mse: 1.0211 - pearson_correlation: -9.0551e-16 - r2_keras: -200.1285 - rmse: 1.2342 - sae: 3799.1719 - sse: 6238.7549\n","Epoch 10: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3986 - loss: 0.4951 - mae: 0.7965 - mse: 0.9842 - pearson_correlation: -6.5799e-16 - r2_keras: -162.2335 - rmse: 1.2040 - sae: 2763.4141 - sse: 4501.0752 - val_huber_loss: 0.6202 - val_loss: 0.7092 - val_mae: 1.0228 - val_mse: 1.5866 - val_pearson_correlation: -3.9550e-16 - val_r2_keras: -56.5085 - val_rmse: 1.2349 - val_sae: 495.1991 - val_sse: 806.7352 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4159 - loss: 0.5049 - mae: 0.8032 - mse: 1.0166 - pearson_correlation: 2.6034e-16 - r2_keras: -199.5404 - rmse: 1.2323 - sae: 3793.4775 - sse: 6220.5117\n","Epoch 11: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3968 - loss: 0.4933 - mae: 0.7943 - mse: 0.9797 - pearson_correlation: 2.0242e-16 - r2_keras: -161.7355 - rmse: 1.2021 - sae: 2759.1628 - sse: 4487.6709 - val_huber_loss: 0.5852 - val_loss: 0.6742 - val_mae: 0.9935 - val_mse: 1.4468 - val_pearson_correlation: -3.1235e-16 - val_r2_keras: -54.4617 - val_rmse: 1.2127 - val_sae: 490.0135 - val_sse: 778.0230 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4141 - loss: 0.5032 - mae: 0.8011 - mse: 1.0122 - pearson_correlation: -2.9612e-16 - r2_keras: -198.9763 - rmse: 1.2306 - sae: 3787.9893 - sse: 6203.0151\n","Epoch 12: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3952 - loss: 0.4916 - mae: 0.7922 - mse: 0.9756 - pearson_correlation: -2.2361e-16 - r2_keras: -161.2786 - rmse: 1.2005 - sae: 2755.1614 - sse: 4475.0571 - val_huber_loss: 0.5542 - val_loss: 0.6433 - val_mae: 0.9636 - val_mse: 1.3315 - val_pearson_correlation: -2.7042e-16 - val_r2_keras: -53.0540 - val_rmse: 1.1973 - val_sae: 487.5201 - val_sse: 758.2751 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4133 - loss: 0.5024 - mae: 0.8001 - mse: 1.0100 - pearson_correlation: 1.4790e-16 - r2_keras: -198.7044 - rmse: 1.2298 - sae: 3785.3330 - sse: 6194.5811\n","Epoch 13: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3943 - loss: 0.4908 - mae: 0.7912 - mse: 0.9735 - pearson_correlation: 3.2489e-17 - r2_keras: -161.0480 - rmse: 1.1996 - sae: 2753.1785 - sse: 4468.8569 - val_huber_loss: 0.5290 - val_loss: 0.6180 - val_mae: 0.9370 - val_mse: 1.2448 - val_pearson_correlation: 1.1239e-16 - val_r2_keras: -52.1883 - val_rmse: 1.1876 - val_sae: 485.4772 - val_sse: 746.1318 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4125 - loss: 0.5016 - mae: 0.7991 - mse: 1.0080 - pearson_correlation: 1.0778e-16 - r2_keras: -198.4419 - rmse: 1.2290 - sae: 3782.7617 - sse: 6186.4385\n","Epoch 14: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3935 - loss: 0.4900 - mae: 0.7902 - mse: 0.9715 - pearson_correlation: 9.6474e-17 - r2_keras: -160.8251 - rmse: 1.1987 - sae: 2751.2581 - sse: 4462.8662 - val_huber_loss: 0.5070 - val_loss: 0.5960 - val_mae: 0.9132 - val_mse: 1.1793 - val_pearson_correlation: -5.5948e-17 - val_r2_keras: -51.4583 - val_rmse: 1.1794 - val_sae: 482.3475 - val_sse: 735.8911 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4117 - loss: 0.5008 - mae: 0.7982 - mse: 1.0060 - pearson_correlation: -3.0940e-16 - r2_keras: -198.1885 - rmse: 1.2282 - sae: 3780.2744 - sse: 6178.5791\n","Epoch 15: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.3927 - loss: 0.4892 - mae: 0.7893 - mse: 0.9695 - pearson_correlation: -1.5533e-16 - r2_keras: -160.6096 - rmse: 1.1979 - sae: 2749.3987 - sse: 4457.0806 - val_huber_loss: 0.4899 - val_loss: 0.5789 - val_mae: 0.8948 - val_mse: 1.1323 - val_pearson_correlation: 1.8324e-16 - val_r2_keras: -51.0155 - val_rmse: 1.1745 - val_sae: 479.9738 - val_sse: 729.6793 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4110 - loss: 0.5000 - mae: 0.7972 - mse: 1.0041 - pearson_correlation: -7.1556e-16 - r2_keras: -197.9422 - rmse: 1.2274 - sae: 3777.8540 - sse: 6170.9390\n","Epoch 16: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3920 - loss: 0.4884 - mae: 0.7883 - mse: 0.9677 - pearson_correlation: -4.6827e-16 - r2_keras: -160.4001 - rmse: 1.1971 - sae: 2747.5891 - sse: 4451.4556 - val_huber_loss: 0.4772 - val_loss: 0.5663 - val_mae: 0.8813 - val_mse: 1.0997 - val_pearson_correlation: 5.6708e-17 - val_r2_keras: -50.7184 - val_rmse: 1.1711 - val_sae: 477.8514 - val_sse: 725.5107 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4102 - loss: 0.4993 - mae: 0.7963 - mse: 1.0022 - pearson_correlation: -6.3359e-17 - r2_keras: -197.7025 - rmse: 1.2267 - sae: 3775.4937 - sse: 6163.5029\n","Epoch 17: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.3912 - loss: 0.4877 - mae: 0.7874 - mse: 0.9658 - pearson_correlation: 6.9755e-17 - r2_keras: -160.1961 - rmse: 1.1963 - sae: 2745.8240 - sse: 4445.9800 - val_huber_loss: 0.4681 - val_loss: 0.5572 - val_mae: 0.8716 - val_mse: 1.0772 - val_pearson_correlation: -6.5855e-17 - val_r2_keras: -50.5078 - val_rmse: 1.1687 - val_sae: 476.0778 - val_sse: 722.5564 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4095 - loss: 0.4986 - mae: 0.7955 - mse: 1.0004 - pearson_correlation: -1.0631e-16 - r2_keras: -197.4688 - rmse: 1.2260 - sae: 3773.1853 - sse: 6156.2549\n","Epoch 18: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3905 - loss: 0.4870 - mae: 0.7865 - mse: 0.9640 - pearson_correlation: -2.6907e-17 - r2_keras: -159.9972 - rmse: 1.1955 - sae: 2744.0977 - sse: 4440.6421 - val_huber_loss: 0.4618 - val_loss: 0.5508 - val_mae: 0.8648 - val_mse: 1.0618 - val_pearson_correlation: 5.2860e-16 - val_r2_keras: -50.3517 - val_rmse: 1.1669 - val_sae: 474.6738 - val_sse: 720.3668 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.4088 - loss: 0.4979 - mae: 0.7946 - mse: 0.9986 - pearson_correlation: -4.0446e-16 - r2_keras: -197.2408 - rmse: 1.2253 - sae: 3770.9263 - sse: 6149.1807\n","Epoch 19: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3898 - loss: 0.4863 - mae: 0.7856 - mse: 0.9623 - pearson_correlation: -2.7129e-16 - r2_keras: -159.8031 - rmse: 1.1948 - sae: 2742.4084 - sse: 4435.4321 - val_huber_loss: 0.4574 - val_loss: 0.5464 - val_mae: 0.8600 - val_mse: 1.0511 - val_pearson_correlation: 1.7544e-16 - val_r2_keras: -50.2355 - val_rmse: 1.1656 - val_sae: 473.6079 - val_sse: 718.7368 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4081 - loss: 0.4972 - mae: 0.7937 - mse: 0.9969 - pearson_correlation: 1.4012e-16 - r2_keras: -197.0180 - rmse: 1.2246 - sae: 3768.7146 - sse: 6142.2720\n","Epoch 20: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.3891 - loss: 0.4856 - mae: 0.7848 - mse: 0.9606 - pearson_correlation: 1.5400e-16 - r2_keras: -159.6134 - rmse: 1.1941 - sae: 2740.7544 - sse: 4430.3438 - val_huber_loss: 0.4542 - val_loss: 0.5433 - val_mae: 0.8564 - val_mse: 1.0435 - val_pearson_correlation: 5.2024e-17 - val_r2_keras: -50.1370 - val_rmse: 1.1645 - val_sae: 472.7567 - val_sse: 717.3552 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4075 - loss: 0.4965 - mae: 0.7929 - mse: 0.9952 - pearson_correlation: -9.3493e-18 - r2_keras: -196.8001 - rmse: 1.2239 - sae: 3766.5469 - sse: 6135.5132\n","Epoch 21: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3884 - loss: 0.4849 - mae: 0.7839 - mse: 0.9589 - pearson_correlation: -6.1922e-17 - r2_keras: -159.4279 - rmse: 1.1933 - sae: 2739.1331 - sse: 4425.3652 - val_huber_loss: 0.4518 - val_loss: 0.5409 - val_mae: 0.8537 - val_mse: 1.0377 - val_pearson_correlation: 7.7275e-17 - val_r2_keras: -50.0500 - val_rmse: 1.1635 - val_sae: 472.0638 - val_sse: 716.1354 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4068 - loss: 0.4958 - mae: 0.7921 - mse: 0.9935 - pearson_correlation: -5.3583e-16 - r2_keras: -196.5869 - rmse: 1.2232 - sae: 3764.4224 - sse: 6128.8989\n","Epoch 22: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3877 - loss: 0.4842 - mae: 0.7831 - mse: 0.9572 - pearson_correlation: -3.3128e-16 - r2_keras: -159.2463 - rmse: 1.1926 - sae: 2737.5437 - sse: 4420.4927 - val_huber_loss: 0.4500 - val_loss: 0.5390 - val_mae: 0.8516 - val_mse: 1.0333 - val_pearson_correlation: 2.6999e-16 - val_r2_keras: -49.9708 - val_rmse: 1.1626 - val_sae: 471.4813 - val_sse: 715.0243 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4061 - loss: 0.4952 - mae: 0.7913 - mse: 0.9919 - pearson_correlation: 6.1554e-16 - r2_keras: -196.3782 - rmse: 1.2226 - sae: 3762.3389 - sse: 6122.4248\n","Epoch 23: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3871 - loss: 0.4836 - mae: 0.7823 - mse: 0.9556 - pearson_correlation: 4.3743e-16 - r2_keras: -159.0685 - rmse: 1.1920 - sae: 2735.9851 - sse: 4415.7231 - val_huber_loss: 0.4485 - val_loss: 0.5375 - val_mae: 0.8499 - val_mse: 1.0297 - val_pearson_correlation: 1.8385e-16 - val_r2_keras: -49.8970 - val_rmse: 1.1618 - val_sae: 470.9831 - val_sse: 713.9887 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.4055 - loss: 0.4946 - mae: 0.7905 - mse: 0.9903 - pearson_correlation: 8.8592e-16 - r2_keras: -196.1736 - rmse: 1.2220 - sae: 3760.2910 - sse: 6116.0771\n","Epoch 24: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3864 - loss: 0.4829 - mae: 0.7815 - mse: 0.9541 - pearson_correlation: 8.1073e-16 - r2_keras: -158.8941 - rmse: 1.1913 - sae: 2734.4529 - sse: 4411.0464 - val_huber_loss: 0.4472 - val_loss: 0.5363 - val_mae: 0.8484 - val_mse: 1.0266 - val_pearson_correlation: 1.6786e-16 - val_r2_keras: -49.8272 - val_rmse: 1.1610 - val_sae: 470.5419 - val_sse: 713.0093 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4049 - loss: 0.4939 - mae: 0.7897 - mse: 0.9887 - pearson_correlation: -4.3767e-18 - r2_keras: -195.9729 - rmse: 1.2213 - sae: 3758.2788 - sse: 6109.8521\n","Epoch 25: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.3858 - loss: 0.4823 - mae: 0.7807 - mse: 0.9525 - pearson_correlation: -7.4886e-17 - r2_keras: -158.7231 - rmse: 1.1906 - sae: 2732.9475 - sse: 4406.4595 - val_huber_loss: 0.4461 - val_loss: 0.5351 - val_mae: 0.8471 - val_mse: 1.0239 - val_pearson_correlation: 9.7588e-17 - val_r2_keras: -49.7603 - val_rmse: 1.1602 - val_sae: 470.1373 - val_sse: 712.0709 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.4043 - loss: 0.4933 - mae: 0.7890 - mse: 0.9871 - pearson_correlation: 3.9983e-16 - r2_keras: -195.7760 - rmse: 1.2207 - sae: 3756.3000 - sse: 6103.7466\n","Epoch 26: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3852 - loss: 0.4817 - mae: 0.7799 - mse: 0.9510 - pearson_correlation: 2.9869e-16 - r2_keras: -158.5553 - rmse: 1.1900 - sae: 2731.4670 - sse: 4401.9600 - val_huber_loss: 0.4451 - val_loss: 0.5341 - val_mae: 0.8458 - val_mse: 1.0215 - val_pearson_correlation: 2.2798e-16 - val_r2_keras: -49.6956 - val_rmse: 1.1595 - val_sae: 469.7567 - val_sse: 711.1636 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4037 - loss: 0.4927 - mae: 0.7882 - mse: 0.9856 - pearson_correlation: 1.8284e-16 - r2_keras: -195.5827 - rmse: 1.2201 - sae: 3754.3516 - sse: 6097.7480\n","Epoch 27: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.3845 - loss: 0.4811 - mae: 0.7791 - mse: 0.9495 - pearson_correlation: 1.0193e-16 - r2_keras: -158.3904 - rmse: 1.1893 - sae: 2730.0095 - sse: 4397.5396 - val_huber_loss: 0.4441 - val_loss: 0.5332 - val_mae: 0.8447 - val_mse: 1.0192 - val_pearson_correlation: -4.1665e-17 - val_r2_keras: -49.6328 - val_rmse: 1.1587 - val_sae: 469.3937 - val_sse: 710.2820 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4031 - loss: 0.4921 - mae: 0.7875 - mse: 0.9841 - pearson_correlation: -1.0045e-15 - r2_keras: -195.3927 - rmse: 1.2195 - sae: 3752.4373 - sse: 6091.8574\n","Epoch 28: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3839 - loss: 0.4805 - mae: 0.7784 - mse: 0.9480 - pearson_correlation: -6.4523e-16 - r2_keras: -158.2285 - rmse: 1.1887 - sae: 2728.5771 - sse: 4393.1982 - val_huber_loss: 0.4432 - val_loss: 0.5323 - val_mae: 0.8436 - val_mse: 1.0170 - val_pearson_correlation: 1.1426e-16 - val_r2_keras: -49.5714 - val_rmse: 1.1580 - val_sae: 469.0435 - val_sse: 709.4211 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.4025 - loss: 0.4915 - mae: 0.7868 - mse: 0.9827 - pearson_correlation: -6.7097e-17 - r2_keras: -195.2060 - rmse: 1.2190 - sae: 3750.5518 - sse: 6086.0654\n","Epoch 29: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.3834 - loss: 0.4799 - mae: 0.7776 - mse: 0.9466 - pearson_correlation: -9.1670e-18 - r2_keras: -158.0693 - rmse: 1.1881 - sae: 2727.1660 - sse: 4388.9292 - val_huber_loss: 0.4424 - val_loss: 0.5314 - val_mae: 0.8425 - val_mse: 1.0149 - val_pearson_correlation: 5.4469e-18 - val_r2_keras: -49.5113 - val_rmse: 1.1574 - val_sae: 468.7031 - val_sse: 708.5782 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4019 - loss: 0.4910 - mae: 0.7861 - mse: 0.9812 - pearson_correlation: 8.0950e-17 - r2_keras: -195.0225 - rmse: 1.2184 - sae: 3748.6948 - sse: 6080.3726\n","Epoch 30: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.3828 - loss: 0.4793 - mae: 0.7769 - mse: 0.9452 - pearson_correlation: 5.3410e-17 - r2_keras: -157.9127 - rmse: 1.1875 - sae: 2725.7761 - sse: 4384.7329 - val_huber_loss: 0.4415 - val_loss: 0.5306 - val_mae: 0.8415 - val_mse: 1.0129 - val_pearson_correlation: -9.6335e-17 - val_r2_keras: -49.4524 - val_rmse: 1.1567 - val_sae: 468.3706 - val_sse: 707.7513 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4013 - loss: 0.4904 - mae: 0.7854 - mse: 0.9798 - pearson_correlation: 3.1084e-16 - r2_keras: -194.8419 - rmse: 1.2178 - sae: 3746.8638 - sse: 6074.7705\n","Epoch 31: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3822 - loss: 0.4787 - mae: 0.7762 - mse: 0.9438 - pearson_correlation: 3.1801e-16 - r2_keras: -157.7587 - rmse: 1.1869 - sae: 2724.4060 - sse: 4380.6035 - val_huber_loss: 0.4407 - val_loss: 0.5298 - val_mae: 0.8405 - val_mse: 1.0109 - val_pearson_correlation: 2.0744e-16 - val_r2_keras: -49.3945 - val_rmse: 1.1560 - val_sae: 468.0446 - val_sse: 706.9392 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4008 - loss: 0.4898 - mae: 0.7847 - mse: 0.9784 - pearson_correlation: 4.3358e-17 - r2_keras: -194.6641 - rmse: 1.2173 - sae: 3745.0574 - sse: 6069.2554\n","Epoch 32: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.3816 - loss: 0.4782 - mae: 0.7755 - mse: 0.9424 - pearson_correlation: 4.2278e-17 - r2_keras: -157.6070 - rmse: 1.1863 - sae: 2723.0544 - sse: 4376.5376 - val_huber_loss: 0.4399 - val_loss: 0.5290 - val_mae: 0.8395 - val_mse: 1.0090 - val_pearson_correlation: -1.9309e-16 - val_r2_keras: -49.3375 - val_rmse: 1.1554 - val_sae: 467.7242 - val_sse: 706.1404 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.4002 - loss: 0.4893 - mae: 0.7840 - mse: 0.9770 - pearson_correlation: -1.5154e-16 - r2_keras: -194.4892 - rmse: 1.2167 - sae: 3743.2766 - sse: 6063.8291\n","Epoch 33: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3811 - loss: 0.4776 - mae: 0.7748 - mse: 0.9411 - pearson_correlation: -1.5847e-16 - r2_keras: -157.4577 - rmse: 1.1857 - sae: 2721.7224 - sse: 4372.5371 - val_huber_loss: 0.4391 - val_loss: 0.5282 - val_mae: 0.8386 - val_mse: 1.0071 - val_pearson_correlation: 1.3129e-16 - val_r2_keras: -49.2815 - val_rmse: 1.1547 - val_sae: 467.4090 - val_sse: 705.3548 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.3997 - loss: 0.4887 - mae: 0.7833 - mse: 0.9757 - pearson_correlation: -5.6630e-17 - r2_keras: -194.3167 - rmse: 1.2162 - sae: 3741.5176 - sse: 6058.4810\n","Epoch 34: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.3805 - loss: 0.4771 - mae: 0.7741 - mse: 0.9397 - pearson_correlation: 1.9737e-17 - r2_keras: -157.3106 - rmse: 1.1851 - sae: 2720.4065 - sse: 4368.5942 - val_huber_loss: 0.4384 - val_loss: 0.5274 - val_mae: 0.8376 - val_mse: 1.0053 - val_pearson_correlation: -4.9285e-17 - val_r2_keras: -49.2263 - val_rmse: 1.1541 - val_sae: 467.0979 - val_sse: 704.5804 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.3992 - loss: 0.4882 - mae: 0.7826 - mse: 0.9744 - pearson_correlation: 4.0297e-17 - r2_keras: -194.1469 - rmse: 1.2157 - sae: 3739.7827 - sse: 6053.2139\n","Epoch 35: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.3800 - loss: 0.4765 - mae: 0.7734 - mse: 0.9384 - pearson_correlation: 1.5133e-17 - r2_keras: -157.1656 - rmse: 1.1846 - sae: 2719.1086 - sse: 4364.7104 - val_huber_loss: 0.4376 - val_loss: 0.5267 - val_mae: 0.8367 - val_mse: 1.0034 - val_pearson_correlation: 1.5166e-16 - val_r2_keras: -49.1720 - val_rmse: 1.1535 - val_sae: 466.7914 - val_sse: 703.8182 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3986 - loss: 0.4877 - mae: 0.7820 - mse: 0.9730 - pearson_correlation: -3.8118e-16 - r2_keras: -193.9794 - rmse: 1.2151 - sae: 3738.0669 - sse: 6048.0186\n","Epoch 36: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3795 - loss: 0.4760 - mae: 0.7727 - mse: 0.9371 - pearson_correlation: -3.1282e-16 - r2_keras: -157.0227 - rmse: 1.1840 - sae: 2717.8252 - sse: 4360.8799 - val_huber_loss: 0.4369 - val_loss: 0.5259 - val_mae: 0.8358 - val_mse: 1.0016 - val_pearson_correlation: -5.4873e-18 - val_r2_keras: -49.1184 - val_rmse: 1.1528 - val_sae: 466.4885 - val_sse: 703.0663 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3981 - loss: 0.4872 - mae: 0.7813 - mse: 0.9717 - pearson_correlation: -1.0781e-16 - r2_keras: -193.8144 - rmse: 1.2146 - sae: 3736.3728 - sse: 6042.8994\n","Epoch 37: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3789 - loss: 0.4755 - mae: 0.7721 - mse: 0.9359 - pearson_correlation: -5.4524e-17 - r2_keras: -156.8818 - rmse: 1.1835 - sae: 2716.5581 - sse: 4357.1050 - val_huber_loss: 0.4361 - val_loss: 0.5252 - val_mae: 0.8349 - val_mse: 0.9999 - val_pearson_correlation: 1.1901e-16 - val_r2_keras: -49.0656 - val_rmse: 1.1522 - val_sae: 466.1895 - val_sse: 702.3253 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3976 - loss: 0.4866 - mae: 0.7807 - mse: 0.9705 - pearson_correlation: 7.1475e-16 - r2_keras: -193.6515 - rmse: 1.2141 - sae: 3734.7021 - sse: 6037.8462\n","Epoch 38: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3784 - loss: 0.4750 - mae: 0.7714 - mse: 0.9346 - pearson_correlation: 4.3506e-16 - r2_keras: -156.7427 - rmse: 1.1829 - sae: 2715.3079 - sse: 4353.3789 - val_huber_loss: 0.4354 - val_loss: 0.5244 - val_mae: 0.8340 - val_mse: 0.9981 - val_pearson_correlation: -1.8327e-17 - val_r2_keras: -49.0134 - val_rmse: 1.1516 - val_sae: 465.8939 - val_sse: 701.5939 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3971 - loss: 0.4861 - mae: 0.7800 - mse: 0.9692 - pearson_correlation: -1.3887e-16 - r2_keras: -193.4909 - rmse: 1.2136 - sae: 3733.0503 - sse: 6032.8633\n","Epoch 39: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3779 - loss: 0.4745 - mae: 0.7708 - mse: 0.9334 - pearson_correlation: -6.7920e-17 - r2_keras: -156.6055 - rmse: 1.1824 - sae: 2714.0720 - sse: 4349.7041 - val_huber_loss: 0.4347 - val_loss: 0.5237 - val_mae: 0.8331 - val_mse: 0.9964 - val_pearson_correlation: 1.3575e-16 - val_r2_keras: -48.9620 - val_rmse: 1.1510 - val_sae: 465.6018 - val_sse: 700.8729 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.3966 - loss: 0.4856 - mae: 0.7794 - mse: 0.9680 - pearson_correlation: -4.6740e-16 - r2_keras: -193.3321 - rmse: 1.2131 - sae: 3731.4141 - sse: 6027.9375\n","Epoch 40: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3774 - loss: 0.4740 - mae: 0.7701 - mse: 0.9321 - pearson_correlation: -3.3741e-16 - r2_keras: -156.4699 - rmse: 1.1819 - sae: 2712.8477 - sse: 4346.0713 - val_huber_loss: 0.4340 - val_loss: 0.5230 - val_mae: 0.8322 - val_mse: 0.9947 - val_pearson_correlation: 2.8463e-16 - val_r2_keras: -48.9113 - val_rmse: 1.1505 - val_sae: 465.3130 - val_sse: 700.1607 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3961 - loss: 0.4851 - mae: 0.7788 - mse: 0.9667 - pearson_correlation: 6.1748e-16 - r2_keras: -193.1747 - rmse: 1.2126 - sae: 3729.7905 - sse: 6023.0547\n","Epoch 41: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3769 - loss: 0.4734 - mae: 0.7695 - mse: 0.9309 - pearson_correlation: 4.7340e-16 - r2_keras: -156.3355 - rmse: 1.1813 - sae: 2711.6331 - sse: 4342.4707 - val_huber_loss: 0.4333 - val_loss: 0.5223 - val_mae: 0.8313 - val_mse: 0.9930 - val_pearson_correlation: -3.4923e-16 - val_r2_keras: -48.8612 - val_rmse: 1.1499 - val_sae: 465.0273 - val_sse: 699.4578 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3956 - loss: 0.4846 - mae: 0.7781 - mse: 0.9655 - pearson_correlation: 4.9200e-16 - r2_keras: -193.0193 - rmse: 1.2121 - sae: 3728.1846 - sse: 6018.2363\n","Epoch 42: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3764 - loss: 0.4730 - mae: 0.7688 - mse: 0.9297 - pearson_correlation: 3.5385e-16 - r2_keras: -156.2029 - rmse: 1.1808 - sae: 2710.4314 - sse: 4338.9175 - val_huber_loss: 0.4326 - val_loss: 0.5216 - val_mae: 0.8305 - val_mse: 0.9913 - val_pearson_correlation: 7.3592e-18 - val_r2_keras: -48.8117 - val_rmse: 1.1493 - val_sae: 464.7446 - val_sse: 698.7637 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3951 - loss: 0.4842 - mae: 0.7775 - mse: 0.9643 - pearson_correlation: -1.4491e-16 - r2_keras: -192.8658 - rmse: 1.2117 - sae: 3726.5955 - sse: 6013.4756\n","Epoch 43: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3759 - loss: 0.4725 - mae: 0.7682 - mse: 0.9285 - pearson_correlation: -5.6120e-17 - r2_keras: -156.0719 - rmse: 1.1803 - sae: 2709.2427 - sse: 4335.4067 - val_huber_loss: 0.4319 - val_loss: 0.5209 - val_mae: 0.8296 - val_mse: 0.9897 - val_pearson_correlation: -4.9721e-17 - val_r2_keras: -48.7628 - val_rmse: 1.1487 - val_sae: 464.4648 - val_sse: 698.0779 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.3946 - loss: 0.4837 - mae: 0.7769 - mse: 0.9631 - pearson_correlation: -1.8298e-16 - r2_keras: -192.7143 - rmse: 1.2112 - sae: 3725.0266 - sse: 6008.7759\n","Epoch 44: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3754 - loss: 0.4720 - mae: 0.7676 - mse: 0.9274 - pearson_correlation: -2.1826e-17 - r2_keras: -155.9424 - rmse: 1.1798 - sae: 2708.0686 - sse: 4331.9404 - val_huber_loss: 0.4312 - val_loss: 0.5203 - val_mae: 0.8288 - val_mse: 0.9881 - val_pearson_correlation: -5.3454e-17 - val_r2_keras: -48.7145 - val_rmse: 1.1482 - val_sae: 464.1880 - val_sse: 697.4008 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3941 - loss: 0.4832 - mae: 0.7763 - mse: 0.9619 - pearson_correlation: -2.3757e-16 - r2_keras: -192.5645 - rmse: 1.2107 - sae: 3723.4744 - sse: 6004.1299\n","Epoch 45: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.3749 - loss: 0.4715 - mae: 0.7670 - mse: 0.9262 - pearson_correlation: -1.9780e-16 - r2_keras: -155.8145 - rmse: 1.1793 - sae: 2706.9067 - sse: 4328.5137 - val_huber_loss: 0.4305 - val_loss: 0.5196 - val_mae: 0.8280 - val_mse: 0.9864 - val_pearson_correlation: 6.2727e-17 - val_r2_keras: -48.6668 - val_rmse: 1.1476 - val_sae: 463.9137 - val_sse: 696.7311 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3937 - loss: 0.4827 - mae: 0.7757 - mse: 0.9608 - pearson_correlation: 3.4230e-17 - r2_keras: -192.4165 - rmse: 1.2103 - sae: 3721.9380 - sse: 5999.5391\n","Epoch 46: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.3745 - loss: 0.4710 - mae: 0.7664 - mse: 0.9251 - pearson_correlation: -2.5646e-17 - r2_keras: -155.6881 - rmse: 1.1788 - sae: 2705.7571 - sse: 4325.1279 - val_huber_loss: 0.4299 - val_loss: 0.5189 - val_mae: 0.8271 - val_mse: 0.9849 - val_pearson_correlation: 4.8011e-16 - val_r2_keras: -48.6196 - val_rmse: 1.1471 - val_sae: 463.6423 - val_sse: 696.0697 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3932 - loss: 0.4823 - mae: 0.7751 - mse: 0.9596 - pearson_correlation: 1.2875e-16 - r2_keras: -192.2703 - rmse: 1.2098 - sae: 3720.4160 - sse: 5995.0029\n","Epoch 47: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3740 - loss: 0.4706 - mae: 0.7658 - mse: 0.9239 - pearson_correlation: 2.0596e-16 - r2_keras: -155.5631 - rmse: 1.1783 - sae: 2704.6184 - sse: 4321.7817 - val_huber_loss: 0.4292 - val_loss: 0.5183 - val_mae: 0.8263 - val_mse: 0.9833 - val_pearson_correlation: 1.5710e-16 - val_r2_keras: -48.5730 - val_rmse: 1.1466 - val_sae: 463.3733 - val_sse: 695.4155 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3927 - loss: 0.4818 - mae: 0.7745 - mse: 0.9585 - pearson_correlation: 3.9028e-16 - r2_keras: -192.1256 - rmse: 1.2094 - sae: 3718.9089 - sse: 5990.5156\n","Epoch 48: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3735 - loss: 0.4701 - mae: 0.7652 - mse: 0.9228 - pearson_correlation: 1.9754e-16 - r2_keras: -155.4396 - rmse: 1.1778 - sae: 2703.4910 - sse: 4318.4717 - val_huber_loss: 0.4286 - val_loss: 0.5176 - val_mae: 0.8255 - val_mse: 0.9817 - val_pearson_correlation: -1.2949e-16 - val_r2_keras: -48.5269 - val_rmse: 1.1460 - val_sae: 463.1072 - val_sse: 694.7693 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3923 - loss: 0.4813 - mae: 0.7740 - mse: 0.9573 - pearson_correlation: 6.1528e-16 - r2_keras: -191.9827 - rmse: 1.2089 - sae: 3717.4175 - sse: 5986.0825\n","Epoch 49: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3731 - loss: 0.4696 - mae: 0.7646 - mse: 0.9217 - pearson_correlation: 4.5707e-16 - r2_keras: -155.3174 - rmse: 1.1774 - sae: 2702.3752 - sse: 4315.2012 - val_huber_loss: 0.4279 - val_loss: 0.5170 - val_mae: 0.8247 - val_mse: 0.9802 - val_pearson_correlation: 3.1476e-16 - val_r2_keras: -48.4813 - val_rmse: 1.1455 - val_sae: 462.8432 - val_sse: 694.1296 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3918 - loss: 0.4809 - mae: 0.7734 - mse: 0.9562 - pearson_correlation: 3.8055e-16 - r2_keras: -191.8412 - rmse: 1.2085 - sae: 3715.9399 - sse: 5981.6943\n","Epoch 50: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3726 - loss: 0.4692 - mae: 0.7640 - mse: 0.9206 - pearson_correlation: 3.0514e-16 - r2_keras: -155.1965 - rmse: 1.1769 - sae: 2701.2695 - sse: 4311.9639 - val_huber_loss: 0.4273 - val_loss: 0.5163 - val_mae: 0.8239 - val_mse: 0.9787 - val_pearson_correlation: -3.7434e-16 - val_r2_keras: -48.4363 - val_rmse: 1.1450 - val_sae: 462.5818 - val_sse: 693.4973 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3914 - loss: 0.4804 - mae: 0.7728 - mse: 0.9551 - pearson_correlation: 1.2141e-16 - r2_keras: -191.7014 - rmse: 1.2080 - sae: 3714.4761 - sse: 5977.3564\n","Epoch 51: val_loss did not improve from 0.44911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3722 - loss: 0.4687 - mae: 0.7634 - mse: 0.9195 - pearson_correlation: 1.5165e-16 - r2_keras: -155.0770 - rmse: 1.1764 - sae: 2700.1743 - sse: 4308.7632 - val_huber_loss: 0.4267 - val_loss: 0.5157 - val_mae: 0.8231 - val_mse: 0.9772 - val_pearson_correlation: 2.8563e-16 - val_r2_keras: -48.3917 - val_rmse: 1.1445 - val_sae: 462.3226 - val_sse: 692.8716 - learning_rate: 1.0000e-05\n","| \u001b[39m13       \u001b[39m | \u001b[39m-0.5157  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m93.24    \u001b[39m | \u001b[39m76.21    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.7855 - loss: 0.8759 - mae: 1.1651 - mse: 2.1973 - pearson_correlation: -3.8766e-16 - r2_keras: -260.8495 - rmse: 1.4082 - sae: 4657.0342 - sse: 8122.2456\n","Epoch 1: val_loss improved from inf to 0.55706, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 470ms/step - huber_loss: 1.6901 - loss: 1.4271 - mae: 1.7372 - mse: 6.3198 - pearson_correlation: -3.7092e-16 - r2_keras: -694.7977 - rmse: 2.5511 - sae: 4181.8623 - sse: 11528.8916 - val_huber_loss: 0.4625 - val_loss: 0.5571 - val_mae: 0.8433 - val_mse: 1.0900 - val_pearson_correlation: -8.8774e-17 - val_r2_keras: -30.0064 - val_rmse: 0.9068 - val_sae: 376.2773 - val_sse: 434.9612 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 1.3465 - loss: 1.4410 - mae: 1.8128 - mse: 4.3036 - pearson_correlation: -1.0178e-16 - r2_keras: -549.2463 - rmse: 2.0413 - sae: 7299.7676 - sse: 17067.9531\n","Epoch 2: val_loss improved from 0.55706 to 0.42204, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 1.0644 - loss: 1.2694 - mae: 1.6316 - mse: 3.6601 - pearson_correlation: -1.6181e-16 - r2_keras: -399.5254 - rmse: 1.7708 - sae: 5135.0679 - sse: 11773.8730 - val_huber_loss: 0.3271 - val_loss: 0.4220 - val_mae: 0.6875 - val_mse: 0.8208 - val_pearson_correlation: -1.6109e-16 - val_r2_keras: -27.9761 - val_rmse: 0.8766 - val_sae: 333.0692 - val_sse: 406.4803 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6258 - loss: 0.7208 - mae: 1.0558 - mse: 1.4591 - pearson_correlation: 4.1260e-16 - r2_keras: -195.2697 - rmse: 1.2192 - sae: 4078.6499 - sse: 6088.0420\n","Epoch 3: val_loss improved from 0.42204 to 0.34648, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.6523 - loss: 0.7369 - mae: 1.0685 - mse: 1.5841 - pearson_correlation: 1.8083e-16 - r2_keras: -182.0280 - rmse: 1.3229 - sae: 3042.9980 - sse: 4670.7856 - val_huber_loss: 0.2516 - val_loss: 0.3465 - val_mae: 0.5636 - val_mse: 0.6367 - val_pearson_correlation: -7.3290e-17 - val_r2_keras: -24.2131 - val_rmse: 0.8177 - val_sae: 301.9987 - val_sse: 353.6924 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3107 - loss: 0.4056 - mae: 0.7235 - mse: 0.7395 - pearson_correlation: 3.8477e-17 - r2_keras: -129.8484 - rmse: 0.9954 - sae: 3258.4814 - sse: 4058.7534\n","Epoch 4: val_loss did not improve from 0.34648\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3278 - loss: 0.4160 - mae: 0.7125 - mse: 0.7613 - pearson_correlation: 5.1373e-17 - r2_keras: -109.6116 - rmse: 1.0051 - sae: 2375.4187 - sse: 2980.0764 - val_huber_loss: 0.2872 - val_loss: 0.3820 - val_mae: 0.5917 - val_mse: 0.7699 - val_pearson_correlation: 2.1786e-17 - val_r2_keras: -29.9031 - val_rmse: 0.9053 - val_sae: 312.5691 - val_sse: 433.5119 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3005 - loss: 0.3953 - mae: 0.6601 - mse: 0.6497 - pearson_correlation: 6.4708e-16 - r2_keras: -146.8978 - rmse: 1.0583 - sae: 3217.7524 - sse: 4587.6045\n","Epoch 5: val_loss did not improve from 0.34648\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.3057 - loss: 0.3985 - mae: 0.6509 - mse: 0.6591 - pearson_correlation: 4.6623e-16 - r2_keras: -117.9487 - rmse: 1.0241 - sae: 2337.4111 - sse: 3297.1106 - val_huber_loss: 0.2643 - val_loss: 0.3590 - val_mae: 0.5504 - val_mse: 0.7060 - val_pearson_correlation: -2.2603e-16 - val_r2_keras: -28.9403 - val_rmse: 0.8910 - val_sae: 301.7575 - val_sse: 420.0056 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2402 - loss: 0.3349 - mae: 0.5603 - mse: 0.5562 - pearson_correlation: 2.9915e-16 - r2_keras: -138.1432 - rmse: 1.0265 - sae: 2995.4646 - sse: 4316.0483\n","Epoch 6: val_loss improved from 0.34648 to 0.34316, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.2212 - loss: 0.3234 - mae: 0.5375 - mse: 0.5206 - pearson_correlation: 1.9348e-16 - r2_keras: -108.0290 - rmse: 0.9692 - sae: 2170.0083 - sse: 3068.1765 - val_huber_loss: 0.2486 - val_loss: 0.3432 - val_mae: 0.5830 - val_mse: 0.6261 - val_pearson_correlation: -1.0951e-16 - val_r2_keras: -28.0917 - val_rmse: 0.8783 - val_sae: 320.2980 - val_sse: 408.1013 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2108 - loss: 0.3054 - mae: 0.5447 - mse: 0.4355 - pearson_correlation: 6.2265e-16 - r2_keras: -106.0983 - rmse: 0.9006 - sae: 2881.5908 - sse: 3322.0547\n","Epoch 7: val_loss improved from 0.34316 to 0.27209, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1997 - loss: 0.2986 - mae: 0.5251 - mse: 0.4237 - pearson_correlation: 4.3110e-16 - r2_keras: -88.8330 - rmse: 0.9036 - sae: 2105.7703 - sse: 2430.9363 - val_huber_loss: 0.1777 - val_loss: 0.2721 - val_mae: 0.4652 - val_mse: 0.4400 - val_pearson_correlation: 2.4581e-17 - val_r2_keras: -25.6179 - val_rmse: 0.8402 - val_sae: 300.7551 - val_sse: 373.3981 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1630 - loss: 0.2574 - mae: 0.4454 - mse: 0.3794 - pearson_correlation: -1.3403e-16 - r2_keras: -97.8303 - rmse: 0.8651 - sae: 2671.0835 - sse: 3065.5908\n","Epoch 8: val_loss improved from 0.27209 to 0.22608, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1401 - loss: 0.2434 - mae: 0.4129 - mse: 0.3436 - pearson_correlation: -1.5286e-16 - r2_keras: -80.0084 - rmse: 0.8514 - sae: 1943.1848 - sse: 2221.1042 - val_huber_loss: 0.1319 - val_loss: 0.2261 - val_mae: 0.3752 - val_mse: 0.3106 - val_pearson_correlation: 7.8027e-18 - val_r2_keras: -28.8564 - val_rmse: 0.8898 - val_sae: 328.0595 - val_sse: 418.8289 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1205 - loss: 0.2147 - mae: 0.3532 - mse: 0.2617 - pearson_correlation: 1.1906e-17 - r2_keras: -106.7428 - rmse: 0.9033 - sae: 2736.5679 - sse: 3342.0459\n","Epoch 9: val_loss did not improve from 0.22608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1556 - loss: 0.2361 - mae: 0.3952 - mse: 0.3041 - pearson_correlation: 6.9905e-17 - r2_keras: -88.9700 - rmse: 0.9030 - sae: 2011.0150 - sse: 2440.8308 - val_huber_loss: 0.2656 - val_loss: 0.3597 - val_mae: 0.6160 - val_mse: 0.5413 - val_pearson_correlation: 4.5718e-17 - val_r2_keras: -55.8071 - val_rmse: 1.2274 - val_sae: 527.2042 - val_sse: 796.8964 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.4180 - loss: 0.5120 - mae: 0.7978 - mse: 0.9802 - pearson_correlation: 2.2203e-16 - r2_keras: -229.7504 - rmse: 1.3219 - sae: 4270.7256 - sse: 7157.5884\n","Epoch 10: val_loss did not improve from 0.22608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3744 - loss: 0.4855 - mae: 0.7677 - mse: 0.9041 - pearson_correlation: 1.8458e-16 - r2_keras: -170.6064 - rmse: 1.1790 - sae: 3033.8140 - sse: 4980.2007 - val_huber_loss: 0.1569 - val_loss: 0.2509 - val_mae: 0.4418 - val_mse: 0.3214 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -42.2256 - val_rmse: 1.0706 - val_sae: 438.7839 - val_sse: 606.3729 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1970 - loss: 0.2910 - mae: 0.4861 - mse: 0.4329 - pearson_correlation: -2.6313e-16 - r2_keras: -141.1061 - rmse: 1.0374 - sae: 3164.7219 - sse: 4407.9521\n","Epoch 11: val_loss improved from 0.22608 to 0.21192, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.1757 - loss: 0.2779 - mae: 0.4738 - mse: 0.4006 - pearson_correlation: -1.0434e-16 - r2_keras: -108.9021 - rmse: 0.9666 - sae: 2280.1401 - sse: 3116.5178 - val_huber_loss: 0.1182 - val_loss: 0.2119 - val_mae: 0.3763 - val_mse: 0.2514 - val_pearson_correlation: 9.4053e-17 - val_r2_keras: -35.2112 - val_rmse: 0.9799 - val_sae: 387.5778 - val_sse: 507.9748 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1395 - loss: 0.2332 - mae: 0.3792 - mse: 0.3088 - pearson_correlation: 8.8748e-17 - r2_keras: -105.4499 - rmse: 0.8979 - sae: 2741.2241 - sse: 3301.9441\n","Epoch 12: val_loss improved from 0.21192 to 0.19648, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.1232 - loss: 0.2233 - mae: 0.3691 - mse: 0.2842 - pearson_correlation: 8.3493e-17 - r2_keras: -86.2525 - rmse: 0.8836 - sae: 1994.0895 - sse: 2392.3306 - val_huber_loss: 0.1029 - val_loss: 0.1965 - val_mae: 0.3267 - val_mse: 0.2315 - val_pearson_correlation: -2.0597e-16 - val_r2_keras: -30.6952 - val_rmse: 0.9168 - val_sae: 350.8367 - val_sse: 444.6238 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1110 - loss: 0.2045 - mae: 0.3245 - mse: 0.2354 - pearson_correlation: 3.9595e-16 - r2_keras: -88.8387 - rmse: 0.8248 - sae: 2459.4446 - sse: 2786.6831\n","Epoch 13: val_loss improved from 0.19648 to 0.19493, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.1021 - loss: 0.1991 - mae: 0.3152 - mse: 0.2228 - pearson_correlation: 2.8211e-16 - r2_keras: -75.3341 - rmse: 0.8362 - sae: 1804.9454 - sse: 2050.6501 - val_huber_loss: 0.1016 - val_loss: 0.1949 - val_mae: 0.2921 - val_mse: 0.2316 - val_pearson_correlation: -5.2040e-17 - val_r2_keras: -30.5186 - val_rmse: 0.9142 - val_sae: 345.1266 - val_sse: 442.1458 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1108 - loss: 0.2041 - mae: 0.3229 - mse: 0.2325 - pearson_correlation: 2.7440e-16 - r2_keras: -90.9840 - rmse: 0.8346 - sae: 2475.8811 - sse: 2853.2275\n","Epoch 14: val_loss did not improve from 0.19493\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1005 - loss: 0.1978 - mae: 0.3116 - mse: 0.2183 - pearson_correlation: 2.1898e-16 - r2_keras: -75.0258 - rmse: 0.8272 - sae: 1809.6058 - sse: 2074.6208 - val_huber_loss: 0.1324 - val_loss: 0.2255 - val_mae: 0.3798 - val_mse: 0.2979 - val_pearson_correlation: -3.0294e-16 - val_r2_keras: -32.6210 - val_rmse: 0.9442 - val_sae: 361.9985 - val_sse: 471.6388 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1078 - loss: 0.2009 - mae: 0.3414 - mse: 0.2218 - pearson_correlation: 5.1623e-16 - r2_keras: -98.9800 - rmse: 0.8701 - sae: 2589.5437 - sse: 3101.2544\n","Epoch 15: val_loss did not improve from 0.19493\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1039 - loss: 0.1985 - mae: 0.3362 - mse: 0.2165 - pearson_correlation: 2.6169e-16 - r2_keras: -79.6356 - rmse: 0.8442 - sae: 1883.3503 - sse: 2231.5149 - val_huber_loss: 0.1673 - val_loss: 0.2603 - val_mae: 0.4366 - val_mse: 0.3758 - val_pearson_correlation: -9.8742e-18 - val_r2_keras: -36.9549 - val_rmse: 1.0032 - val_sae: 386.0898 - val_sse: 532.4357 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1216 - loss: 0.2145 - mae: 0.3702 - mse: 0.2493 - pearson_correlation: -1.2890e-16 - r2_keras: -105.6000 - rmse: 0.8985 - sae: 2664.4419 - sse: 3306.5991\n","Epoch 16: val_loss did not improve from 0.19493\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1119 - loss: 0.2086 - mae: 0.3586 - mse: 0.2371 - pearson_correlation: -2.9526e-17 - r2_keras: -83.9946 - rmse: 0.8625 - sae: 1932.6746 - sse: 2367.7747 - val_huber_loss: 0.1451 - val_loss: 0.2379 - val_mae: 0.4032 - val_mse: 0.3250 - val_pearson_correlation: -1.0889e-16 - val_r2_keras: -34.2347 - val_rmse: 0.9666 - val_sae: 368.6873 - val_sse: 494.2766 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1031 - loss: 0.1958 - mae: 0.3287 - mse: 0.2132 - pearson_correlation: 3.1271e-16 - r2_keras: -97.0960 - rmse: 0.8619 - sae: 2559.1292 - sse: 3042.8145\n","Epoch 17: val_loss did not improve from 0.19493\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0945 - loss: 0.1906 - mae: 0.3158 - mse: 0.2023 - pearson_correlation: 3.0943e-16 - r2_keras: -80.1675 - rmse: 0.8550 - sae: 1869.3651 - sse: 2213.5276 - val_huber_loss: 0.1090 - val_loss: 0.2015 - val_mae: 0.3184 - val_mse: 0.2492 - val_pearson_correlation: 1.3308e-17 - val_r2_keras: -30.1806 - val_rmse: 0.9093 - val_sae: 339.3076 - val_sse: 437.4054 - learning_rate: 0.1000\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1012 - loss: 0.1937 - mae: 0.3229 - mse: 0.2120 - pearson_correlation: 4.4215e-16 - r2_keras: -88.2715 - rmse: 0.8222 - sae: 2449.1797 - sse: 2769.0908\n","Epoch 18: val_loss did not improve from 0.19493\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1005 - loss: 0.1933 - mae: 0.3235 - mse: 0.2100 - pearson_correlation: 3.2364e-16 - r2_keras: -78.4881 - rmse: 0.8638 - sae: 1814.2987 - sse: 2080.3533 - val_huber_loss: 0.1123 - val_loss: 0.2046 - val_mae: 0.3278 - val_mse: 0.2604 - val_pearson_correlation: -1.9507e-16 - val_r2_keras: -30.7767 - val_rmse: 0.9180 - val_sae: 344.8153 - val_sse: 445.7667 - learning_rate: 0.1000\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1076 - loss: 0.2000 - mae: 0.3144 - mse: 0.2257 - pearson_correlation: 1.0965e-16 - r2_keras: -95.0057 - rmse: 0.8527 - sae: 2511.8591 - sse: 2977.9761\n","Epoch 19: val_loss improved from 0.19493 to 0.19458, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0980 - loss: 0.1941 - mae: 0.3087 - mse: 0.2120 - pearson_correlation: 7.3101e-17 - r2_keras: -75.8405 - rmse: 0.8215 - sae: 1825.7528 - sse: 2135.8928 - val_huber_loss: 0.1023 - val_loss: 0.1946 - val_mae: 0.2858 - val_mse: 0.2357 - val_pearson_correlation: -2.2133e-16 - val_r2_keras: -31.6830 - val_rmse: 0.9310 - val_sae: 350.1042 - val_sse: 458.4805 - learning_rate: 0.0200\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0901 - loss: 0.1824 - mae: 0.2753 - mse: 0.1887 - pearson_correlation: 3.6406e-16 - r2_keras: -97.5860 - rmse: 0.8641 - sae: 2551.3899 - sse: 3058.0149\n","Epoch 20: val_loss improved from 0.19458 to 0.19432, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0820 - loss: 0.1774 - mae: 0.2716 - mse: 0.1772 - pearson_correlation: 2.8387e-16 - r2_keras: -78.5239 - rmse: 0.8384 - sae: 1856.1163 - sse: 2200.5500 - val_huber_loss: 0.1021 - val_loss: 0.1943 - val_mae: 0.2770 - val_mse: 0.2316 - val_pearson_correlation: 2.7107e-16 - val_r2_keras: -32.4592 - val_rmse: 0.9420 - val_sae: 354.6034 - val_sse: 469.3699 - learning_rate: 0.0200\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0869 - loss: 0.1791 - mae: 0.2638 - mse: 0.1819 - pearson_correlation: 1.6500e-16 - r2_keras: -99.2571 - rmse: 0.8713 - sae: 2569.4536 - sse: 3109.8501\n","Epoch 21: val_loss improved from 0.19432 to 0.19368, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0788 - loss: 0.1742 - mae: 0.2607 - mse: 0.1705 - pearson_correlation: 8.3003e-17 - r2_keras: -80.1773 - rmse: 0.8483 - sae: 1870.3682 - sse: 2241.4333 - val_huber_loss: 0.1015 - val_loss: 0.1937 - val_mae: 0.2752 - val_mse: 0.2277 - val_pearson_correlation: 4.6172e-17 - val_r2_keras: -32.8615 - val_rmse: 0.9476 - val_sae: 357.1005 - val_sse: 475.0135 - learning_rate: 0.0200\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0855 - loss: 0.1777 - mae: 0.2577 - mse: 0.1793 - pearson_correlation: -4.4142e-16 - r2_keras: -99.7566 - rmse: 0.8735 - sae: 2571.5803 - sse: 3125.3428\n","Epoch 22: val_loss improved from 0.19368 to 0.19307, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0775 - loss: 0.1728 - mae: 0.2552 - mse: 0.1680 - pearson_correlation: -3.1530e-16 - r2_keras: -80.7873 - rmse: 0.8523 - sae: 1872.9005 - sse: 2255.0107 - val_huber_loss: 0.1009 - val_loss: 0.1931 - val_mae: 0.2743 - val_mse: 0.2250 - val_pearson_correlation: -2.8579e-16 - val_r2_keras: -33.0529 - val_rmse: 0.9503 - val_sae: 358.3452 - val_sse: 477.6972 - learning_rate: 0.0200\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0846 - loss: 0.1768 - mae: 0.2542 - mse: 0.1776 - pearson_correlation: 5.6725e-16 - r2_keras: -99.8259 - rmse: 0.8738 - sae: 2569.6392 - sse: 3127.4946\n","Epoch 23: val_loss improved from 0.19307 to 0.19264, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.0767 - loss: 0.1720 - mae: 0.2520 - mse: 0.1664 - pearson_correlation: 3.8646e-16 - r2_keras: -80.9823 - rmse: 0.8539 - sae: 1872.1654 - sse: 2258.1902 - val_huber_loss: 0.1005 - val_loss: 0.1926 - val_mae: 0.2745 - val_mse: 0.2234 - val_pearson_correlation: 2.5049e-16 - val_r2_keras: -33.1316 - val_rmse: 0.9514 - val_sae: 358.9574 - val_sse: 478.8015 - learning_rate: 0.0200\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0839 - loss: 0.1760 - mae: 0.2519 - mse: 0.1762 - pearson_correlation: 4.1167e-16 - r2_keras: -99.7423 - rmse: 0.8734 - sae: 2566.9714 - sse: 3124.8992\n","Epoch 24: val_loss improved from 0.19264 to 0.19223, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0761 - loss: 0.1713 - mae: 0.2499 - mse: 0.1651 - pearson_correlation: 3.7725e-16 - r2_keras: -81.0152 - rmse: 0.8545 - sae: 1870.7147 - sse: 2257.5007 - val_huber_loss: 0.1002 - val_loss: 0.1922 - val_mae: 0.2734 - val_mse: 0.2219 - val_pearson_correlation: -1.0215e-16 - val_r2_keras: -33.1946 - val_rmse: 0.9522 - val_sae: 359.5851 - val_sse: 479.6855 - learning_rate: 0.0200\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0833 - loss: 0.1754 - mae: 0.2502 - mse: 0.1750 - pearson_correlation: 6.0540e-16 - r2_keras: -99.7423 - rmse: 0.8735 - sae: 2566.0063 - sse: 3124.9014\n","Epoch 25: val_loss improved from 0.19223 to 0.19206, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0756 - loss: 0.1707 - mae: 0.2482 - mse: 0.1639 - pearson_correlation: 3.4634e-16 - r2_keras: -81.0740 - rmse: 0.8550 - sae: 1870.3037 - sse: 2258.1909 - val_huber_loss: 0.1001 - val_loss: 0.1921 - val_mae: 0.2731 - val_mse: 0.2215 - val_pearson_correlation: -1.1335e-16 - val_r2_keras: -33.2218 - val_rmse: 0.9526 - val_sae: 359.8921 - val_sse: 480.0674 - learning_rate: 0.0200\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0828 - loss: 0.1748 - mae: 0.2490 - mse: 0.1739 - pearson_correlation: -2.8926e-16 - r2_keras: -99.7055 - rmse: 0.8733 - sae: 2565.1665 - sse: 3123.7573\n","Epoch 26: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0752 - loss: 0.1702 - mae: 0.2469 - mse: 0.1630 - pearson_correlation: -1.9895e-16 - r2_keras: -81.0894 - rmse: 0.8553 - sae: 1869.9037 - sse: 2257.8977 - val_huber_loss: 0.1002 - val_loss: 0.1921 - val_mae: 0.2725 - val_mse: 0.2217 - val_pearson_correlation: 2.4821e-16 - val_r2_keras: -33.3280 - val_rmse: 0.9541 - val_sae: 360.6546 - val_sse: 481.5575 - learning_rate: 0.0200\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0824 - loss: 0.1744 - mae: 0.2481 - mse: 0.1730 - pearson_correlation: 1.1899e-16 - r2_keras: -99.7580 - rmse: 0.8735 - sae: 2565.9299 - sse: 3125.3867\n","Epoch 27: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0748 - loss: 0.1697 - mae: 0.2459 - mse: 0.1620 - pearson_correlation: 5.9009e-17 - r2_keras: -81.1580 - rmse: 0.8557 - sae: 1870.5455 - sse: 2259.3779 - val_huber_loss: 0.1004 - val_loss: 0.1924 - val_mae: 0.2729 - val_mse: 0.2223 - val_pearson_correlation: 6.7578e-17 - val_r2_keras: -33.3677 - val_rmse: 0.9547 - val_sae: 360.9929 - val_sse: 482.1139 - learning_rate: 0.0200\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0820 - loss: 0.1739 - mae: 0.2474 - mse: 0.1720 - pearson_correlation: -5.0737e-16 - r2_keras: -99.7835 - rmse: 0.8736 - sae: 2566.6531 - sse: 3126.1787\n","Epoch 28: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0744 - loss: 0.1693 - mae: 0.2452 - mse: 0.1612 - pearson_correlation: -3.3419e-16 - r2_keras: -81.1960 - rmse: 0.8560 - sae: 1871.1255 - sse: 2260.1514 - val_huber_loss: 0.1006 - val_loss: 0.1925 - val_mae: 0.2730 - val_mse: 0.2227 - val_pearson_correlation: 4.5029e-16 - val_r2_keras: -33.3791 - val_rmse: 0.9548 - val_sae: 360.9488 - val_sse: 482.2735 - learning_rate: 0.0200\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0816 - loss: 0.1735 - mae: 0.2465 - mse: 0.1710 - pearson_correlation: 1.6876e-16 - r2_keras: -99.8129 - rmse: 0.8738 - sae: 2566.9766 - sse: 3127.0889\n","Epoch 29: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0740 - loss: 0.1688 - mae: 0.2444 - mse: 0.1603 - pearson_correlation: 1.5909e-16 - r2_keras: -81.2307 - rmse: 0.8562 - sae: 1871.4344 - sse: 2260.9353 - val_huber_loss: 0.1009 - val_loss: 0.1927 - val_mae: 0.2734 - val_mse: 0.2234 - val_pearson_correlation: 4.4932e-17 - val_r2_keras: -33.4305 - val_rmse: 0.9555 - val_sae: 361.3566 - val_sse: 482.9946 - learning_rate: 0.0200\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2462 - mse: 0.1703 - pearson_correlation: 5.9832e-17 - r2_keras: -99.8876 - rmse: 0.8741 - sae: 2568.3958 - sse: 3129.4067\n","Epoch 30: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0737 - loss: 0.1685 - mae: 0.2438 - mse: 0.1595 - pearson_correlation: 5.6066e-17 - r2_keras: -81.2964 - rmse: 0.8566 - sae: 1872.4583 - sse: 2262.6675 - val_huber_loss: 0.1011 - val_loss: 0.1928 - val_mae: 0.2737 - val_mse: 0.2239 - val_pearson_correlation: -1.8017e-16 - val_r2_keras: -33.3709 - val_rmse: 0.9547 - val_sae: 361.0448 - val_sse: 482.1594 - learning_rate: 0.0200\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0809 - loss: 0.1726 - mae: 0.2455 - mse: 0.1693 - pearson_correlation: 2.2234e-16 - r2_keras: -99.8515 - rmse: 0.8739 - sae: 2568.1304 - sse: 3128.2881\n","Epoch 31: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0729 - loss: 0.1678 - mae: 0.2414 - mse: 0.1581 - pearson_correlation: 1.4421e-16 - r2_keras: -81.3388 - rmse: 0.8571 - sae: 1872.8699 - sse: 2262.7004 - val_huber_loss: 0.1010 - val_loss: 0.1928 - val_mae: 0.2739 - val_mse: 0.2235 - val_pearson_correlation: 8.9849e-17 - val_r2_keras: -33.4292 - val_rmse: 0.9555 - val_sae: 361.4709 - val_sse: 482.9760 - learning_rate: 0.0040\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1724 - mae: 0.2452 - mse: 0.1688 - pearson_correlation: -1.2101e-17 - r2_keras: -99.7872 - rmse: 0.8736 - sae: 2567.3962 - sse: 3126.2935\n","Epoch 32: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0728 - loss: 0.1676 - mae: 0.2414 - mse: 0.1577 - pearson_correlation: -4.1232e-17 - r2_keras: -81.2958 - rmse: 0.8569 - sae: 1872.3683 - sse: 2261.3694 - val_huber_loss: 0.1010 - val_loss: 0.1928 - val_mae: 0.2740 - val_mse: 0.2233 - val_pearson_correlation: -2.1297e-16 - val_r2_keras: -33.4733 - val_rmse: 0.9561 - val_sae: 361.7803 - val_sse: 483.5958 - learning_rate: 0.0040\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0805 - loss: 0.1723 - mae: 0.2450 - mse: 0.1684 - pearson_correlation: -9.6859e-17 - r2_keras: -99.7468 - rmse: 0.8735 - sae: 2566.8926 - sse: 3125.0398\n","Epoch 33: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0726 - loss: 0.1675 - mae: 0.2412 - mse: 0.1574 - pearson_correlation: -8.2991e-18 - r2_keras: -81.2700 - rmse: 0.8568 - sae: 1872.0258 - sse: 2260.5474 - val_huber_loss: 0.1010 - val_loss: 0.1927 - val_mae: 0.2741 - val_mse: 0.2231 - val_pearson_correlation: 2.0151e-16 - val_r2_keras: -33.5015 - val_rmse: 0.9565 - val_sae: 361.9530 - val_sse: 483.9902 - learning_rate: 0.0040\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0804 - loss: 0.1721 - mae: 0.2448 - mse: 0.1681 - pearson_correlation: -6.0776e-16 - r2_keras: -99.7076 - rmse: 0.8733 - sae: 2566.4424 - sse: 3123.8247\n","Epoch 34: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0725 - loss: 0.1674 - mae: 0.2412 - mse: 0.1571 - pearson_correlation: -3.6599e-16 - r2_keras: -81.2449 - rmse: 0.8567 - sae: 1871.7238 - sse: 2259.7500 - val_huber_loss: 0.1010 - val_loss: 0.1927 - val_mae: 0.2741 - val_mse: 0.2230 - val_pearson_correlation: 3.3551e-16 - val_r2_keras: -33.5238 - val_rmse: 0.9568 - val_sae: 362.1111 - val_sse: 484.3036 - learning_rate: 0.0040\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0802 - loss: 0.1720 - mae: 0.2446 - mse: 0.1677 - pearson_correlation: 2.8576e-16 - r2_keras: -99.6943 - rmse: 0.8732 - sae: 2566.3103 - sse: 3123.4121\n","Epoch 35: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0724 - loss: 0.1672 - mae: 0.2410 - mse: 0.1568 - pearson_correlation: 2.0257e-16 - r2_keras: -81.2368 - rmse: 0.8566 - sae: 1871.6320 - sse: 2259.4834 - val_huber_loss: 0.1010 - val_loss: 0.1927 - val_mae: 0.2742 - val_mse: 0.2229 - val_pearson_correlation: 2.4591e-16 - val_r2_keras: -33.5353 - val_rmse: 0.9570 - val_sae: 362.1790 - val_sse: 484.4651 - learning_rate: 0.0040\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0801 - loss: 0.1718 - mae: 0.2444 - mse: 0.1675 - pearson_correlation: 8.8675e-18 - r2_keras: -99.6770 - rmse: 0.8732 - sae: 2566.0923 - sse: 3122.8757\n","Epoch 36: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0723 - loss: 0.1671 - mae: 0.2406 - mse: 0.1565 - pearson_correlation: 4.2036e-17 - r2_keras: -81.2393 - rmse: 0.8567 - sae: 1871.5977 - sse: 2259.2898 - val_huber_loss: 0.1009 - val_loss: 0.1927 - val_mae: 0.2741 - val_mse: 0.2227 - val_pearson_correlation: -2.4565e-16 - val_r2_keras: -33.5593 - val_rmse: 0.9573 - val_sae: 362.3322 - val_sse: 484.8011 - learning_rate: 8.0000e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0801 - loss: 0.1718 - mae: 0.2444 - mse: 0.1674 - pearson_correlation: 3.1186e-16 - r2_keras: -99.6734 - rmse: 0.8732 - sae: 2566.0530 - sse: 3122.7632\n","Epoch 37: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0723 - loss: 0.1671 - mae: 0.2406 - mse: 0.1564 - pearson_correlation: 1.8784e-16 - r2_keras: -81.2369 - rmse: 0.8567 - sae: 1871.5704 - sse: 2259.2151 - val_huber_loss: 0.1009 - val_loss: 0.1927 - val_mae: 0.2741 - val_mse: 0.2226 - val_pearson_correlation: -2.1204e-16 - val_r2_keras: -33.5709 - val_rmse: 0.9575 - val_sae: 362.4098 - val_sse: 484.9649 - learning_rate: 8.0000e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0800 - loss: 0.1718 - mae: 0.2443 - mse: 0.1673 - pearson_correlation: 5.5163e-16 - r2_keras: -99.6674 - rmse: 0.8731 - sae: 2565.9700 - sse: 3122.5762\n","Epoch 38: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0722 - loss: 0.1670 - mae: 0.2406 - mse: 0.1564 - pearson_correlation: 3.1256e-16 - r2_keras: -81.2322 - rmse: 0.8567 - sae: 1871.5117 - sse: 2259.0828 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2225 - val_pearson_correlation: 3.3465e-16 - val_r2_keras: -33.5818 - val_rmse: 0.9576 - val_sae: 362.4751 - val_sse: 485.1169 - learning_rate: 8.0000e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0800 - loss: 0.1717 - mae: 0.2443 - mse: 0.1672 - pearson_correlation: 2.6666e-16 - r2_keras: -99.6645 - rmse: 0.8731 - sae: 2565.9429 - sse: 3122.4878\n","Epoch 39: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0722 - loss: 0.1670 - mae: 0.2406 - mse: 0.1563 - pearson_correlation: 1.2258e-16 - r2_keras: -81.2304 - rmse: 0.8567 - sae: 1871.4932 - sse: 2259.0254 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2225 - val_pearson_correlation: 2.2306e-16 - val_r2_keras: -33.5859 - val_rmse: 0.9577 - val_sae: 362.5018 - val_sse: 485.1745 - learning_rate: 8.0000e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0800 - loss: 0.1717 - mae: 0.2442 - mse: 0.1672 - pearson_correlation: 9.7270e-16 - r2_keras: -99.6602 - rmse: 0.8731 - sae: 2565.8848 - sse: 3122.3540\n","Epoch 40: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0722 - loss: 0.1670 - mae: 0.2406 - mse: 0.1563 - pearson_correlation: 5.8424e-16 - r2_keras: -81.2272 - rmse: 0.8567 - sae: 1871.4525 - sse: 2258.9316 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2225 - val_pearson_correlation: 3.1221e-16 - val_r2_keras: -33.5907 - val_rmse: 0.9577 - val_sae: 362.5313 - val_sse: 485.2427 - learning_rate: 8.0000e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0800 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: 7.5098e-17 - r2_keras: -99.6577 - rmse: 0.8731 - sae: 2565.8579 - sse: 3122.2744\n","Epoch 41: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0722 - loss: 0.1669 - mae: 0.2405 - mse: 0.1562 - pearson_correlation: 6.3109e-17 - r2_keras: -81.2279 - rmse: 0.8567 - sae: 1871.4545 - sse: 2258.9075 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2224 - val_pearson_correlation: -2.0066e-16 - val_r2_keras: -33.5959 - val_rmse: 0.9578 - val_sae: 362.5649 - val_sse: 485.3156 - learning_rate: 1.6000e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: 2.2619e-16 - r2_keras: -99.6562 - rmse: 0.8731 - sae: 2565.8384 - sse: 3122.2290\n","Epoch 42: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0722 - loss: 0.1669 - mae: 0.2405 - mse: 0.1562 - pearson_correlation: 1.4678e-16 - r2_keras: -81.2268 - rmse: 0.8567 - sae: 1871.4407 - sse: 2258.8755 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2224 - val_pearson_correlation: 2.3407e-16 - val_r2_keras: -33.5991 - val_rmse: 0.9579 - val_sae: 362.5861 - val_sse: 485.3598 - learning_rate: 1.6000e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: -1.0319e-16 - r2_keras: -99.6550 - rmse: 0.8731 - sae: 2565.8232 - sse: 3122.1926\n","Epoch 43: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0722 - loss: 0.1669 - mae: 0.2405 - mse: 0.1562 - pearson_correlation: -2.3643e-17 - r2_keras: -81.2259 - rmse: 0.8567 - sae: 1871.4299 - sse: 2258.8499 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2224 - val_pearson_correlation: -3.3435e-17 - val_r2_keras: -33.6018 - val_rmse: 0.9579 - val_sae: 362.6038 - val_sse: 485.3972 - learning_rate: 1.6000e-04\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: 2.5428e-16 - r2_keras: -99.6545 - rmse: 0.8731 - sae: 2565.8186 - sse: 3122.1777\n","Epoch 44: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0722 - loss: 0.1669 - mae: 0.2405 - mse: 0.1562 - pearson_correlation: 1.8156e-16 - r2_keras: -81.2256 - rmse: 0.8567 - sae: 1871.4266 - sse: 2258.8401 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2224 - val_pearson_correlation: 1.1144e-17 - val_r2_keras: -33.6034 - val_rmse: 0.9579 - val_sae: 362.6140 - val_sse: 485.4201 - learning_rate: 1.6000e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: 3.2465e-16 - r2_keras: -99.6540 - rmse: 0.8731 - sae: 2565.8140 - sse: 3122.1606\n","Epoch 45: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0722 - loss: 0.1669 - mae: 0.2405 - mse: 0.1562 - pearson_correlation: 2.1343e-16 - r2_keras: -81.2252 - rmse: 0.8567 - sae: 1871.4232 - sse: 2258.8286 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.1144e-17 - val_r2_keras: -33.6041 - val_rmse: 0.9579 - val_sae: 362.6170 - val_sse: 485.4299 - learning_rate: 1.6000e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: 2.2974e-16 - r2_keras: -99.6529 - rmse: 0.8731 - sae: 2565.8003 - sse: 3122.1279\n","Epoch 46: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1562 - pearson_correlation: 1.3410e-16 - r2_keras: -81.2249 - rmse: 0.8567 - sae: 1871.4180 - sse: 2258.8118 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -6.6859e-17 - val_r2_keras: -33.6056 - val_rmse: 0.9580 - val_sae: 362.6273 - val_sse: 485.4518 - learning_rate: 3.2000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: -2.1023e-16 - r2_keras: -99.6528 - rmse: 0.8731 - sae: 2565.7993 - sse: 3122.1255\n","Epoch 47: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1562 - pearson_correlation: -1.0704e-16 - r2_keras: -81.2249 - rmse: 0.8567 - sae: 1871.4172 - sse: 2258.8101 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -2.1171e-16 - val_r2_keras: -33.6066 - val_rmse: 0.9580 - val_sae: 362.6335 - val_sse: 485.4651 - learning_rate: 3.2000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: 5.9284e-16 - r2_keras: -99.6527 - rmse: 0.8731 - sae: 2565.7981 - sse: 3122.1218\n","Epoch 48: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 4.2533e-16 - r2_keras: -81.2248 - rmse: 0.8567 - sae: 1871.4164 - sse: 2258.8076 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -5.1255e-16 - val_r2_keras: -33.6073 - val_rmse: 0.9580 - val_sae: 362.6377 - val_sse: 485.4743 - learning_rate: 3.2000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1671 - pearson_correlation: -2.1289e-17 - r2_keras: -99.6527 - rmse: 0.8731 - sae: 2565.7976 - sse: 3122.1196\n","Epoch 49: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -8.3420e-17 - r2_keras: -81.2247 - rmse: 0.8567 - sae: 1871.4160 - sse: 2258.8062 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.2256e-16 - val_r2_keras: -33.6076 - val_rmse: 0.9580 - val_sae: 362.6400 - val_sse: 485.4797 - learning_rate: 3.2000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 2.0106e-16 - r2_keras: -99.6525 - rmse: 0.8731 - sae: 2565.7961 - sse: 3122.1162\n","Epoch 50: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 5.2776e-17 - r2_keras: -81.2247 - rmse: 0.8567 - sae: 1871.4150 - sse: 2258.8040 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -3.3426e-17 - val_r2_keras: -33.6078 - val_rmse: 0.9580 - val_sae: 362.6410 - val_sse: 485.4822 - learning_rate: 3.2000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -4.5683e-16 - r2_keras: -99.6524 - rmse: 0.8731 - sae: 2565.7939 - sse: 3122.1113\n","Epoch 51: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -3.2161e-16 - r2_keras: -81.2246 - rmse: 0.8567 - sae: 1871.4142 - sse: 2258.8015 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.8941e-16 - val_r2_keras: -33.6081 - val_rmse: 0.9580 - val_sae: 362.6429 - val_sse: 485.4864 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -4.7605e-17 - r2_keras: -99.6523 - rmse: 0.8731 - sae: 2565.7935 - sse: 3122.1096\n","Epoch 52: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -2.6720e-17 - r2_keras: -81.2246 - rmse: 0.8567 - sae: 1871.4139 - sse: 2258.8003 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 7.7993e-17 - val_r2_keras: -33.6083 - val_rmse: 0.9580 - val_sae: 362.6437 - val_sse: 485.4885 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 6.7446e-16 - r2_keras: -99.6523 - rmse: 0.8731 - sae: 2565.7927 - sse: 3122.1079\n","Epoch 53: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 4.4261e-16 - r2_keras: -81.2246 - rmse: 0.8567 - sae: 1871.4133 - sse: 2258.7991 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -2.6740e-16 - val_r2_keras: -33.6084 - val_rmse: 0.9580 - val_sae: 362.6447 - val_sse: 485.4904 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 1.2093e-16 - r2_keras: -99.6523 - rmse: 0.8731 - sae: 2565.7922 - sse: 3122.1069\n","Epoch 54: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 8.2630e-17 - r2_keras: -81.2246 - rmse: 0.8567 - sae: 1871.4130 - sse: 2258.7986 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -6.6851e-17 - val_r2_keras: -33.6085 - val_rmse: 0.9580 - val_sae: 362.6451 - val_sse: 485.4915 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0799 - loss: 0.1717 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 5.8841e-17 - r2_keras: -99.6522 - rmse: 0.8731 - sae: 2565.7917 - sse: 3122.1055\n","Epoch 55: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 1.7155e-17 - r2_keras: -81.2245 - rmse: 0.8567 - sae: 1871.4127 - sse: 2258.7976 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -5.5709e-17 - val_r2_keras: -33.6085 - val_rmse: 0.9580 - val_sae: 362.6453 - val_sse: 485.4920 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 1.8214e-16 - r2_keras: -99.6522 - rmse: 0.8731 - sae: 2565.7913 - sse: 3122.1045\n","Epoch 56: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 6.1230e-17 - r2_keras: -81.2245 - rmse: 0.8567 - sae: 1871.4124 - sse: 2258.7969 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 2.2284e-17 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4926 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -2.8386e-16 - r2_keras: -99.6521 - rmse: 0.8731 - sae: 2565.7910 - sse: 3122.1035\n","Epoch 57: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -2.8054e-16 - r2_keras: -81.2245 - rmse: 0.8567 - sae: 1871.4122 - sse: 2258.7964 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -7.7992e-17 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4927 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -1.0257e-15 - r2_keras: -99.6521 - rmse: 0.8731 - sae: 2565.7903 - sse: 3122.1023\n","Epoch 58: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -6.5773e-16 - r2_keras: -81.2244 - rmse: 0.8567 - sae: 1871.4117 - sse: 2258.7954 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -2.5626e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6455 - val_sse: 485.4930 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -6.0615e-17 - r2_keras: -99.6521 - rmse: 0.8731 - sae: 2565.7900 - sse: 3122.1008\n","Epoch 59: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -5.3453e-17 - r2_keras: -81.2244 - rmse: 0.8567 - sae: 1871.4115 - sse: 2258.7944 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.3370e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6457 - val_sse: 485.4935 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -4.1692e-17 - r2_keras: -99.6520 - rmse: 0.8731 - sae: 2565.7898 - sse: 3122.1001\n","Epoch 60: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 1.3011e-18 - r2_keras: -81.2244 - rmse: 0.8567 - sae: 1871.4114 - sse: 2258.7939 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -3.0083e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4931 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 3.3028e-16 - r2_keras: -99.6520 - rmse: 0.8731 - sae: 2565.7891 - sse: 3122.0984\n","Epoch 61: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 2.4828e-16 - r2_keras: -81.2244 - rmse: 0.8567 - sae: 1871.4108 - sse: 2258.7930 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 1.8941e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6456 - val_sse: 485.4935 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 3.2200e-16 - r2_keras: -99.6520 - rmse: 0.8731 - sae: 2565.7891 - sse: 3122.0977\n","Epoch 62: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 1.8457e-16 - r2_keras: -81.2244 - rmse: 0.8567 - sae: 1871.4108 - sse: 2258.7925 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.7827e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6456 - val_sse: 485.4937 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -1.4873e-16 - r2_keras: -99.6519 - rmse: 0.8731 - sae: 2565.7883 - sse: 3122.0964\n","Epoch 63: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -5.5008e-17 - r2_keras: -81.2243 - rmse: 0.8567 - sae: 1871.4103 - sse: 2258.7915 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.6713e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4934 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -5.4702e-17 - r2_keras: -99.6519 - rmse: 0.8731 - sae: 2565.7876 - sse: 3122.0952\n","Epoch 64: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -7.7603e-17 - r2_keras: -81.2243 - rmse: 0.8567 - sae: 1871.4098 - sse: 2258.7908 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -3.6768e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4936 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -3.2644e-16 - r2_keras: -99.6518 - rmse: 0.8731 - sae: 2565.7874 - sse: 3122.0945\n","Epoch 65: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -1.9455e-16 - r2_keras: -81.2243 - rmse: 0.8567 - sae: 1871.4097 - sse: 2258.7903 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 1.1142e-17 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4938 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 4.6718e-17 - r2_keras: -99.6518 - rmse: 0.8731 - sae: 2565.7866 - sse: 3122.0933\n","Epoch 66: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 2.6129e-17 - r2_keras: -81.2243 - rmse: 0.8567 - sae: 1871.4092 - sse: 2258.7896 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 2.6740e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6453 - val_sse: 485.4934 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -5.5589e-17 - r2_keras: -99.6518 - rmse: 0.8731 - sae: 2565.7861 - sse: 3122.0918\n","Epoch 67: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 3.0161e-17 - r2_keras: -81.2242 - rmse: 0.8567 - sae: 1871.4088 - sse: 2258.7886 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 5.5709e-17 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6454 - val_sse: 485.4937 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 2.2620e-16 - r2_keras: -99.6517 - rmse: 0.8731 - sae: 2565.7861 - sse: 3122.0911\n","Epoch 68: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 1.1869e-16 - r2_keras: -81.2242 - rmse: 0.8567 - sae: 1871.4088 - sse: 2258.7881 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.8941e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6451 - val_sse: 485.4934 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 1.3454e-16 - r2_keras: -99.6517 - rmse: 0.8731 - sae: 2565.7852 - sse: 3122.0889\n","Epoch 69: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 1.7397e-16 - r2_keras: -81.2242 - rmse: 0.8567 - sae: 1871.4081 - sse: 2258.7866 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 1.6713e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6453 - val_sse: 485.4938 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -8.5158e-17 - r2_keras: -99.6516 - rmse: 0.8731 - sae: 2565.7849 - sse: 3122.0884\n","Epoch 70: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -1.0894e-16 - r2_keras: -81.2242 - rmse: 0.8567 - sae: 1871.4080 - sse: 2258.7864 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -4.2339e-16 - val_r2_keras: -33.6087 - val_rmse: 0.9580 - val_sae: 362.6453 - val_sse: 485.4939 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 3.5305e-16 - r2_keras: -99.6516 - rmse: 0.8731 - sae: 2565.7847 - sse: 3122.0879\n","Epoch 71: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 2.4540e-16 - r2_keras: -81.2242 - rmse: 0.8567 - sae: 1871.4078 - sse: 2258.7859 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 1.1142e-17 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6451 - val_sse: 485.4937 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: 3.2023e-16 - r2_keras: -99.6516 - rmse: 0.8731 - sae: 2565.7839 - sse: 3122.0859\n","Epoch 72: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: 2.0245e-16 - r2_keras: -81.2241 - rmse: 0.8567 - sae: 1871.4073 - sse: 2258.7847 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 8.9134e-17 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6451 - val_sse: 485.4937 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -8.0723e-17 - r2_keras: -99.6515 - rmse: 0.8731 - sae: 2565.7837 - sse: 3122.0850\n","Epoch 73: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -1.4687e-17 - r2_keras: -81.2241 - rmse: 0.8567 - sae: 1871.4071 - sse: 2258.7839 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -4.4567e-17 - val_r2_keras: -33.6087 - val_rmse: 0.9580 - val_sae: 362.6452 - val_sse: 485.4940 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -2.1674e-16 - r2_keras: -99.6515 - rmse: 0.8731 - sae: 2565.7834 - sse: 3122.0845\n","Epoch 74: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -1.2744e-16 - r2_keras: -81.2241 - rmse: 0.8567 - sae: 1871.4070 - sse: 2258.7837 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: -1.4484e-16 - val_r2_keras: -33.6086 - val_rmse: 0.9580 - val_sae: 362.6450 - val_sse: 485.4937 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1716 - mae: 0.2442 - mse: 0.1670 - pearson_correlation: -2.7322e-16 - r2_keras: -99.6515 - rmse: 0.8731 - sae: 2565.7827 - sse: 3122.0825\n","Epoch 75: val_loss did not improve from 0.19206\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1669 - mae: 0.2404 - mse: 0.1561 - pearson_correlation: -1.7010e-16 - r2_keras: -81.2240 - rmse: 0.8567 - sae: 1871.4065 - sse: 2258.7825 - val_huber_loss: 0.1009 - val_loss: 0.1926 - val_mae: 0.2741 - val_mse: 0.2223 - val_pearson_correlation: 2.6740e-16 - val_r2_keras: -33.6087 - val_rmse: 0.9580 - val_sae: 362.6451 - val_sse: 485.4940 - learning_rate: 1.0000e-05\n","| \u001b[39m14       \u001b[39m | \u001b[39m-0.1926  \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m96.05    \u001b[39m | \u001b[39m76.77    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.8210 - loss: 0.9112 - mae: 1.2861 - mse: 2.2590 - pearson_correlation: -6.9747e-17 - r2_keras: -312.3226 - rmse: 1.5404 - sae: 5531.3838 - sse: 9718.8760\n","Epoch 1: val_loss improved from inf to 0.35106, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 471ms/step - huber_loss: 0.7764 - loss: 0.8841 - mae: 1.2454 - mse: 2.1572 - pearson_correlation: -1.0074e-16 - r2_keras: -257.1395 - rmse: 1.5226 - sae: 4010.2883 - sse: 7057.0454 - val_huber_loss: 0.2608 - val_loss: 0.3511 - val_mae: 0.5913 - val_mse: 0.6721 - val_pearson_correlation: -3.1019e-16 - val_r2_keras: -22.5022 - val_rmse: 0.7895 - val_sae: 301.2440 - val_sse: 329.6909 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7915 - loss: 0.8817 - mae: 1.2534 - mse: 2.1736 - pearson_correlation: 3.5001e-17 - r2_keras: -300.2050 - rmse: 1.5103 - sae: 5405.2178 - sse: 9343.0010\n","Epoch 2: val_loss improved from 0.35106 to 0.34056, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.7489 - loss: 0.8558 - mae: 1.2144 - mse: 2.0733 - pearson_correlation: 5.2264e-17 - r2_keras: -247.2579 - rmse: 1.4934 - sae: 3920.1462 - sse: 6785.3115 - val_huber_loss: 0.2503 - val_loss: 0.3406 - val_mae: 0.5692 - val_mse: 0.6497 - val_pearson_correlation: 2.5584e-16 - val_r2_keras: -22.8822 - val_rmse: 0.7958 - val_sae: 300.5548 - val_sse: 335.0218 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7683 - loss: 0.8586 - mae: 1.2271 - mse: 2.1072 - pearson_correlation: -2.3875e-16 - r2_keras: -290.7893 - rmse: 1.4865 - sae: 5304.7666 - sse: 9050.9395\n","Epoch 3: val_loss improved from 0.34056 to 0.33172, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.7269 - loss: 0.8333 - mae: 1.1893 - mse: 2.0074 - pearson_correlation: -1.8229e-16 - r2_keras: -239.5051 - rmse: 1.4699 - sae: 3848.1018 - sse: 6573.2939 - val_huber_loss: 0.2415 - val_loss: 0.3317 - val_mae: 0.5477 - val_mse: 0.6301 - val_pearson_correlation: 1.4836e-16 - val_r2_keras: -23.5664 - val_rmse: 0.8071 - val_sae: 303.8695 - val_sse: 344.6197 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7486 - loss: 0.8388 - mae: 1.2041 - mse: 2.0508 - pearson_correlation: -1.0874e-16 - r2_keras: -282.8464 - rmse: 1.4661 - sae: 5218.0884 - sse: 8804.5596\n","Epoch 4: val_loss improved from 0.33172 to 0.32710, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.7079 - loss: 0.8141 - mae: 1.1672 - mse: 1.9514 - pearson_correlation: -1.0821e-16 - r2_keras: -232.9388 - rmse: 1.4496 - sae: 3785.8420 - sse: 6394.1313 - val_huber_loss: 0.2369 - val_loss: 0.3271 - val_mae: 0.5339 - val_mse: 0.6159 - val_pearson_correlation: -7.2061e-17 - val_r2_keras: -24.6578 - val_rmse: 0.8249 - val_sae: 312.9666 - val_sse: 359.9307 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7313 - loss: 0.8215 - mae: 1.1834 - mse: 2.0014 - pearson_correlation: 6.6156e-17 - r2_keras: -275.9251 - rmse: 1.4481 - sae: 5141.1074 - sse: 8589.8701\n","Epoch 5: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.6911 - loss: 0.7970 - mae: 1.1474 - mse: 1.9020 - pearson_correlation: -2.5200e-17 - r2_keras: -227.1999 - rmse: 1.4317 - sae: 3730.5061 - sse: 6237.8120 - val_huber_loss: 0.2385 - val_loss: 0.3288 - val_mae: 0.5234 - val_mse: 0.6102 - val_pearson_correlation: 5.3919e-17 - val_r2_keras: -26.5054 - val_rmse: 0.8540 - val_sae: 327.9702 - val_sse: 385.8488 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7157 - loss: 0.8059 - mae: 1.1644 - mse: 1.9569 - pearson_correlation: -4.9265e-17 - r2_keras: -269.7405 - rmse: 1.4319 - sae: 5070.9521 - sse: 8398.0312\n","Epoch 6: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.6759 - loss: 0.7817 - mae: 1.1291 - mse: 1.8576 - pearson_correlation: -3.9544e-17 - r2_keras: -222.0617 - rmse: 1.4153 - sae: 3680.0911 - sse: 6098.0122 - val_huber_loss: 0.2494 - val_loss: 0.3397 - val_mae: 0.5343 - val_mse: 0.6203 - val_pearson_correlation: 2.4985e-16 - val_r2_keras: -29.4777 - val_rmse: 0.8990 - val_sae: 351.4892 - val_sse: 427.5439 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7015 - loss: 0.7917 - mae: 1.1467 - mse: 1.9163 - pearson_correlation: 1.3287e-16 - r2_keras: -264.1200 - rmse: 1.4169 - sae: 5005.8545 - sse: 8223.6914\n","Epoch 7: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6620 - loss: 0.7677 - mae: 1.1121 - mse: 1.8171 - pearson_correlation: 4.6956e-17 - r2_keras: -217.3895 - rmse: 1.4004 - sae: 3633.3367 - sse: 5970.9321 - val_huber_loss: 0.2707 - val_loss: 0.3610 - val_mae: 0.5829 - val_mse: 0.6551 - val_pearson_correlation: -8.8692e-17 - val_r2_keras: -33.8042 - val_rmse: 0.9607 - val_sae: 384.3368 - val_sse: 488.2372 - learning_rate: 1.0000e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.6885 - loss: 0.7787 - mae: 1.1308 - mse: 1.8789 - pearson_correlation: 2.9289e-17 - r2_keras: -258.9678 - rmse: 1.4031 - sae: 4944.9844 - sse: 8063.8760\n","Epoch 8: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.6491 - loss: 0.7548 - mae: 1.0968 - mse: 1.7797 - pearson_correlation: 2.1248e-17 - r2_keras: -213.1061 - rmse: 1.3865 - sae: 3589.6311 - sse: 5854.4351 - val_huber_loss: 0.3024 - val_loss: 0.3926 - val_mae: 0.6523 - val_mse: 0.7150 - val_pearson_correlation: -1.8393e-16 - val_r2_keras: -39.3427 - val_rmse: 1.0343 - val_sae: 422.4028 - val_sse: 565.9324 - learning_rate: 1.0000e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6766 - loss: 0.7668 - mae: 1.1168 - mse: 1.8442 - pearson_correlation: -8.6357e-17 - r2_keras: -254.2243 - rmse: 1.3903 - sae: 4888.2041 - sse: 7916.7378\n","Epoch 9: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.6373 - loss: 0.7428 - mae: 1.0831 - mse: 1.7452 - pearson_correlation: -5.2567e-18 - r2_keras: -209.1603 - rmse: 1.3735 - sae: 3548.8308 - sse: 5747.1533 - val_huber_loss: 0.3391 - val_loss: 0.4293 - val_mae: 0.7163 - val_mse: 0.7873 - val_pearson_correlation: 1.1078e-16 - val_r2_keras: -45.6574 - val_rmse: 1.1123 - val_sae: 460.2943 - val_sse: 654.5155 - learning_rate: 1.0000e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.6655 - loss: 0.7557 - mae: 1.1037 - mse: 1.8120 - pearson_correlation: -5.3556e-17 - r2_keras: -249.8377 - rmse: 1.3783 - sae: 4834.9858 - sse: 7780.6704\n","Epoch 10: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.6274 - loss: 0.7325 - mae: 1.0712 - mse: 1.7152 - pearson_correlation: -3.0431e-17 - r2_keras: -205.7572 - rmse: 1.3629 - sae: 3511.4814 - sse: 5650.8262 - val_huber_loss: 0.3790 - val_loss: 0.4692 - val_mae: 0.7791 - val_mse: 0.8742 - val_pearson_correlation: -1.2608e-16 - val_r2_keras: -52.4311 - val_rmse: 1.1903 - val_sae: 497.4432 - val_sse: 749.5374 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6634 - loss: 0.7536 - mae: 1.1012 - mse: 1.8060 - pearson_correlation: 8.3613e-17 - r2_keras: -249.0110 - rmse: 1.3760 - sae: 4824.8906 - sse: 7755.0273\n","Epoch 11: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6253 - loss: 0.7305 - mae: 1.0687 - mse: 1.7091 - pearson_correlation: 5.3980e-17 - r2_keras: -205.0659 - rmse: 1.3606 - sae: 3504.2151 - sse: 5632.0864 - val_huber_loss: 0.4159 - val_loss: 0.5061 - val_mae: 0.8310 - val_mse: 0.9593 - val_pearson_correlation: 2.5590e-17 - val_r2_keras: -58.6588 - val_rmse: 1.2578 - val_sae: 529.2708 - val_sse: 836.9005 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6614 - loss: 0.7516 - mae: 1.0988 - mse: 1.8001 - pearson_correlation: -2.6777e-16 - r2_keras: -248.2129 - rmse: 1.3738 - sae: 4815.1270 - sse: 7730.2729\n","Epoch 12: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6233 - loss: 0.7284 - mae: 1.0664 - mse: 1.7033 - pearson_correlation: -1.4497e-16 - r2_keras: -204.3983 - rmse: 1.3583 - sae: 3497.1855 - sse: 5613.9932 - val_huber_loss: 0.4474 - val_loss: 0.5376 - val_mae: 0.8712 - val_mse: 1.0334 - val_pearson_correlation: -1.2006e-16 - val_r2_keras: -63.7763 - val_rmse: 1.3106 - val_sae: 554.4331 - val_sse: 908.6889 - learning_rate: 2.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6595 - loss: 0.7497 - mae: 1.0965 - mse: 1.7944 - pearson_correlation: -2.9536e-16 - r2_keras: -247.4426 - rmse: 1.3717 - sae: 4805.6689 - sse: 7706.3799\n","Epoch 13: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6214 - loss: 0.7265 - mae: 1.0641 - mse: 1.6976 - pearson_correlation: -2.4468e-16 - r2_keras: -203.7538 - rmse: 1.3562 - sae: 3490.3757 - sse: 5596.5278 - val_huber_loss: 0.4706 - val_loss: 0.5608 - val_mae: 0.8988 - val_mse: 1.0891 - val_pearson_correlation: -1.3822e-16 - val_r2_keras: -67.5032 - val_rmse: 1.3478 - val_sae: 572.6685 - val_sse: 960.9706 - learning_rate: 2.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6576 - loss: 0.7478 - mae: 1.0942 - mse: 1.7890 - pearson_correlation: 1.9111e-16 - r2_keras: -246.6975 - rmse: 1.3696 - sae: 4796.4897 - sse: 7683.2666\n","Epoch 14: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.6195 - loss: 0.7246 - mae: 1.0619 - mse: 1.6921 - pearson_correlation: 1.4160e-16 - r2_keras: -203.1301 - rmse: 1.3541 - sae: 3483.7656 - sse: 5579.6304 - val_huber_loss: 0.4870 - val_loss: 0.5772 - val_mae: 0.9179 - val_mse: 1.1283 - val_pearson_correlation: -3.1427e-16 - val_r2_keras: -70.0045 - val_rmse: 1.3722 - val_sae: 585.1146 - val_sse: 996.0588 - learning_rate: 2.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6558 - loss: 0.7460 - mae: 1.0920 - mse: 1.7836 - pearson_correlation: 9.9869e-17 - r2_keras: -245.9752 - rmse: 1.3676 - sae: 4787.5723 - sse: 7660.8604\n","Epoch 15: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6178 - loss: 0.7229 - mae: 1.0598 - mse: 1.6870 - pearson_correlation: 4.8816e-17 - r2_keras: -202.5519 - rmse: 1.3522 - sae: 3477.4417 - sse: 5563.5601 - val_huber_loss: 0.4988 - val_loss: 0.5890 - val_mae: 0.9310 - val_mse: 1.1556 - val_pearson_correlation: -2.2082e-17 - val_r2_keras: -71.6739 - val_rmse: 1.3882 - val_sae: 593.7079 - val_sse: 1019.4778 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6549 - loss: 0.7451 - mae: 1.0910 - mse: 1.7811 - pearson_correlation: 3.6871e-17 - r2_keras: -245.6246 - rmse: 1.3666 - sae: 4783.2334 - sse: 7649.9873\n","Epoch 16: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.6169 - loss: 0.7220 - mae: 1.0587 - mse: 1.6844 - pearson_correlation: 4.2362e-17 - r2_keras: -202.2584 - rmse: 1.3512 - sae: 3474.3164 - sse: 5555.6089 - val_huber_loss: 0.5063 - val_loss: 0.5965 - val_mae: 0.9390 - val_mse: 1.1720 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -72.7028 - val_rmse: 1.3980 - val_sae: 599.3500 - val_sse: 1033.9104 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6541 - loss: 0.7443 - mae: 1.0899 - mse: 1.7785 - pearson_correlation: 1.4096e-16 - r2_keras: -245.2829 - rmse: 1.3657 - sae: 4778.9971 - sse: 7639.3862\n","Epoch 17: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.6160 - loss: 0.7211 - mae: 1.0577 - mse: 1.6819 - pearson_correlation: 6.7277e-17 - r2_keras: -201.9721 - rmse: 1.3503 - sae: 3471.2651 - sse: 5547.8564 - val_huber_loss: 0.5109 - val_loss: 0.6011 - val_mae: 0.9437 - val_mse: 1.1813 - val_pearson_correlation: -3.0453e-16 - val_r2_keras: -73.2752 - val_rmse: 1.4034 - val_sae: 602.7821 - val_sse: 1041.9412 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6532 - loss: 0.7434 - mae: 1.0889 - mse: 1.7761 - pearson_correlation: 1.3883e-16 - r2_keras: -244.9492 - rmse: 1.3648 - sae: 4774.8555 - sse: 7629.0352\n","Epoch 18: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6152 - loss: 0.7203 - mae: 1.0567 - mse: 1.6794 - pearson_correlation: 8.8988e-17 - r2_keras: -201.6926 - rmse: 1.3493 - sae: 3468.2825 - sse: 5540.2866 - val_huber_loss: 0.5138 - val_loss: 0.6040 - val_mae: 0.9467 - val_mse: 1.1868 - val_pearson_correlation: -2.1687e-17 - val_r2_keras: -73.6030 - val_rmse: 1.4065 - val_sae: 604.8741 - val_sse: 1046.5396 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6524 - loss: 0.7426 - mae: 1.0879 - mse: 1.7737 - pearson_correlation: -1.7713e-16 - r2_keras: -244.6230 - rmse: 1.3639 - sae: 4770.8062 - sse: 7618.9185\n","Epoch 19: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.6143 - loss: 0.7194 - mae: 1.0557 - mse: 1.6770 - pearson_correlation: -1.1452e-16 - r2_keras: -201.4194 - rmse: 1.3484 - sae: 3465.3679 - sse: 5532.8877 - val_huber_loss: 0.5154 - val_loss: 0.6057 - val_mae: 0.9484 - val_mse: 1.1897 - val_pearson_correlation: 6.4967e-17 - val_r2_keras: -73.7683 - val_rmse: 1.4081 - val_sae: 606.0543 - val_sse: 1048.8584 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.6516 - loss: 0.7418 - mae: 1.0869 - mse: 1.7713 - pearson_correlation: 1.0447e-16 - r2_keras: -244.3036 - rmse: 1.3630 - sae: 4766.8389 - sse: 7609.0107\n","Epoch 20: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.6135 - loss: 0.7186 - mae: 1.0548 - mse: 1.6747 - pearson_correlation: 1.1070e-16 - r2_keras: -201.1518 - rmse: 1.3475 - sae: 3462.5127 - sse: 5525.6416 - val_huber_loss: 0.5163 - val_loss: 0.6065 - val_mae: 0.9493 - val_mse: 1.1911 - val_pearson_correlation: 1.0821e-16 - val_r2_keras: -73.8464 - val_rmse: 1.4088 - val_sae: 606.6829 - val_sse: 1049.9528 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6508 - loss: 0.7410 - mae: 1.0860 - mse: 1.7690 - pearson_correlation: -4.8137e-18 - r2_keras: -243.9905 - rmse: 1.3621 - sae: 4762.9438 - sse: 7599.2998\n","Epoch 21: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.6127 - loss: 0.7178 - mae: 1.0538 - mse: 1.6724 - pearson_correlation: -2.6436e-17 - r2_keras: -200.8896 - rmse: 1.3466 - sae: 3459.7095 - sse: 5518.5396 - val_huber_loss: 0.5166 - val_loss: 0.6068 - val_mae: 0.9496 - val_mse: 1.1914 - val_pearson_correlation: 3.8952e-16 - val_r2_keras: -73.8627 - val_rmse: 1.4090 - val_sae: 606.9370 - val_sse: 1050.1818 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.6501 - loss: 0.7403 - mae: 1.0850 - mse: 1.7668 - pearson_correlation: 7.7755e-17 - r2_keras: -243.6836 - rmse: 1.3612 - sae: 4759.1226 - sse: 7589.7793\n","Epoch 22: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6119 - loss: 0.7171 - mae: 1.0529 - mse: 1.6701 - pearson_correlation: 5.1837e-17 - r2_keras: -200.6324 - rmse: 1.3457 - sae: 3456.9595 - sse: 5511.5767 - val_huber_loss: 0.5165 - val_loss: 0.6067 - val_mae: 0.9495 - val_mse: 1.1909 - val_pearson_correlation: 4.3291e-17 - val_r2_keras: -73.8415 - val_rmse: 1.4088 - val_sae: 606.9487 - val_sse: 1049.8853 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6493 - loss: 0.7395 - mae: 1.0841 - mse: 1.7646 - pearson_correlation: 4.0584e-17 - r2_keras: -243.3826 - rmse: 1.3604 - sae: 4755.3740 - sse: 7580.4438\n","Epoch 23: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.6112 - loss: 0.7163 - mae: 1.0520 - mse: 1.6679 - pearson_correlation: -1.5900e-17 - r2_keras: -200.3803 - rmse: 1.3449 - sae: 3454.2620 - sse: 5504.7490 - val_huber_loss: 0.5162 - val_loss: 0.6065 - val_mae: 0.9493 - val_mse: 1.1900 - val_pearson_correlation: -1.5159e-16 - val_r2_keras: -73.7983 - val_rmse: 1.4084 - val_sae: 606.8130 - val_sse: 1049.2792 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6486 - loss: 0.7388 - mae: 1.0832 - mse: 1.7624 - pearson_correlation: 6.1664e-18 - r2_keras: -243.0872 - rmse: 1.3596 - sae: 4751.6904 - sse: 7571.2783\n","Epoch 24: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.6104 - loss: 0.7156 - mae: 1.0511 - mse: 1.6657 - pearson_correlation: -2.8135e-17 - r2_keras: -200.1328 - rmse: 1.3441 - sae: 3451.6121 - sse: 5498.0459 - val_huber_loss: 0.5158 - val_loss: 0.6060 - val_mae: 0.9489 - val_mse: 1.1888 - val_pearson_correlation: 8.6669e-17 - val_r2_keras: -73.7427 - val_rmse: 1.4078 - val_sae: 606.5910 - val_sse: 1048.4985 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.6478 - loss: 0.7380 - mae: 1.0823 - mse: 1.7602 - pearson_correlation: 2.1734e-17 - r2_keras: -242.7970 - rmse: 1.3588 - sae: 4748.0698 - sse: 7562.2773\n","Epoch 25: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6097 - loss: 0.7148 - mae: 1.0502 - mse: 1.6635 - pearson_correlation: 1.0952e-16 - r2_keras: -199.8896 - rmse: 1.3432 - sae: 3449.0068 - sse: 5491.4624 - val_huber_loss: 0.5153 - val_loss: 0.6055 - val_mae: 0.9484 - val_mse: 1.1874 - val_pearson_correlation: -6.5042e-17 - val_r2_keras: -73.6793 - val_rmse: 1.4073 - val_sae: 606.3126 - val_sse: 1047.6091 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6471 - loss: 0.7373 - mae: 1.0814 - mse: 1.7581 - pearson_correlation: -7.6265e-17 - r2_keras: -242.5118 - rmse: 1.3580 - sae: 4744.5068 - sse: 7553.4326\n","Epoch 26: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.6090 - loss: 0.7141 - mae: 1.0493 - mse: 1.6614 - pearson_correlation: -1.0468e-16 - r2_keras: -199.6507 - rmse: 1.3424 - sae: 3446.4434 - sse: 5484.9932 - val_huber_loss: 0.5147 - val_loss: 0.6049 - val_mae: 0.9478 - val_mse: 1.1860 - val_pearson_correlation: -1.9526e-16 - val_r2_keras: -73.6111 - val_rmse: 1.4066 - val_sae: 605.9984 - val_sse: 1046.6525 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6464 - loss: 0.7366 - mae: 1.0805 - mse: 1.7561 - pearson_correlation: -4.8778e-17 - r2_keras: -242.2314 - rmse: 1.3572 - sae: 4740.9995 - sse: 7544.7354\n","Epoch 27: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.6082 - loss: 0.7134 - mae: 1.0485 - mse: 1.6594 - pearson_correlation: -1.9947e-17 - r2_keras: -199.4158 - rmse: 1.3416 - sae: 3443.9197 - sse: 5478.6318 - val_huber_loss: 0.5141 - val_loss: 0.6043 - val_mae: 0.9473 - val_mse: 1.1845 - val_pearson_correlation: -2.1710e-16 - val_r2_keras: -73.5404 - val_rmse: 1.4059 - val_sae: 605.6637 - val_sse: 1045.6602 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6457 - loss: 0.7359 - mae: 1.0797 - mse: 1.7540 - pearson_correlation: -2.9881e-16 - r2_keras: -241.9556 - rmse: 1.3564 - sae: 4737.5439 - sse: 7536.1782\n","Epoch 28: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6075 - loss: 0.7127 - mae: 1.0477 - mse: 1.6573 - pearson_correlation: -1.6326e-16 - r2_keras: -199.1846 - rmse: 1.3408 - sae: 3441.4333 - sse: 5472.3726 - val_huber_loss: 0.5135 - val_loss: 0.6037 - val_mae: 0.9467 - val_mse: 1.1830 - val_pearson_correlation: 2.3898e-16 - val_r2_keras: -73.4686 - val_rmse: 1.4053 - val_sae: 605.3184 - val_sse: 1044.6532 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.6450 - loss: 0.7353 - mae: 1.0788 - mse: 1.7520 - pearson_correlation: 7.3886e-17 - r2_keras: -241.6840 - rmse: 1.3557 - sae: 4734.1387 - sse: 7527.7549\n","Epoch 29: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6069 - loss: 0.7120 - mae: 1.0468 - mse: 1.6553 - pearson_correlation: 8.1637e-17 - r2_keras: -198.9570 - rmse: 1.3401 - sae: 3438.9832 - sse: 5466.2114 - val_huber_loss: 0.5129 - val_loss: 0.6031 - val_mae: 0.9460 - val_mse: 1.1814 - val_pearson_correlation: 4.3482e-17 - val_r2_keras: -73.3965 - val_rmse: 1.4046 - val_sae: 604.9682 - val_sse: 1043.6423 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6444 - loss: 0.7346 - mae: 1.0780 - mse: 1.7501 - pearson_correlation: -1.7401e-16 - r2_keras: -241.4168 - rmse: 1.3549 - sae: 4730.7842 - sse: 7519.4653\n","Epoch 30: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.6062 - loss: 0.7113 - mae: 1.0460 - mse: 1.6533 - pearson_correlation: -9.9805e-17 - r2_keras: -198.7330 - rmse: 1.3393 - sae: 3436.5691 - sse: 5460.1475 - val_huber_loss: 0.5123 - val_loss: 0.6025 - val_mae: 0.9454 - val_mse: 1.1799 - val_pearson_correlation: -2.1756e-16 - val_r2_keras: -73.3246 - val_rmse: 1.4039 - val_sae: 604.6162 - val_sse: 1042.6337 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.6437 - loss: 0.7339 - mae: 1.0772 - mse: 1.7481 - pearson_correlation: -4.2147e-16 - r2_keras: -241.1533 - rmse: 1.3542 - sae: 4727.4727 - sse: 7511.2930\n","Epoch 31: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.6055 - loss: 0.7107 - mae: 1.0452 - mse: 1.6514 - pearson_correlation: -3.1161e-16 - r2_keras: -198.5122 - rmse: 1.3386 - sae: 3434.1863 - sse: 5454.1694 - val_huber_loss: 0.5116 - val_loss: 0.6019 - val_mae: 0.9448 - val_mse: 1.1784 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -73.2531 - val_rmse: 1.4032 - val_sae: 604.2644 - val_sse: 1041.6307 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6431 - loss: 0.7333 - mae: 1.0764 - mse: 1.7462 - pearson_correlation: -1.4851e-16 - r2_keras: -240.8938 - rmse: 1.3535 - sae: 4724.2065 - sse: 7503.2432\n","Epoch 32: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.6048 - loss: 0.7100 - mae: 1.0444 - mse: 1.6495 - pearson_correlation: -9.1792e-17 - r2_keras: -198.2947 - rmse: 1.3378 - sae: 3431.8357 - sse: 5448.2808 - val_huber_loss: 0.5110 - val_loss: 0.6012 - val_mae: 0.9442 - val_mse: 1.1769 - val_pearson_correlation: -1.0893e-16 - val_r2_keras: -73.1823 - val_rmse: 1.4026 - val_sae: 603.9148 - val_sse: 1040.6370 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.6424 - loss: 0.7326 - mae: 1.0756 - mse: 1.7443 - pearson_correlation: 3.0911e-17 - r2_keras: -240.6378 - rmse: 1.3527 - sae: 4720.9844 - sse: 7495.3008\n","Epoch 33: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6042 - loss: 0.7094 - mae: 1.0436 - mse: 1.6476 - pearson_correlation: -4.6562e-18 - r2_keras: -198.0801 - rmse: 1.3371 - sae: 3429.5168 - sse: 5442.4707 - val_huber_loss: 0.5104 - val_loss: 0.6006 - val_mae: 0.9436 - val_mse: 1.1754 - val_pearson_correlation: 1.9622e-16 - val_r2_keras: -73.1122 - val_rmse: 1.4019 - val_sae: 603.5711 - val_sse: 1039.6538 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6418 - loss: 0.7320 - mae: 1.0748 - mse: 1.7425 - pearson_correlation: 7.8481e-17 - r2_keras: -240.3854 - rmse: 1.3520 - sae: 4717.8057 - sse: 7487.4722\n","Epoch 34: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6035 - loss: 0.7087 - mae: 1.0429 - mse: 1.6457 - pearson_correlation: 9.3856e-17 - r2_keras: -197.8686 - rmse: 1.3364 - sae: 3427.2292 - sse: 5436.7441 - val_huber_loss: 0.5098 - val_loss: 0.6000 - val_mae: 0.9430 - val_mse: 1.1740 - val_pearson_correlation: -6.5450e-17 - val_r2_keras: -73.0429 - val_rmse: 1.4012 - val_sae: 603.2314 - val_sse: 1038.6823 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6412 - loss: 0.7314 - mae: 1.0740 - mse: 1.7406 - pearson_correlation: -7.3265e-17 - r2_keras: -240.1364 - rmse: 1.3513 - sae: 4714.6670 - sse: 7479.7510\n","Epoch 35: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6029 - loss: 0.7081 - mae: 1.0421 - mse: 1.6439 - pearson_correlation: -3.9807e-17 - r2_keras: -197.6599 - rmse: 1.3357 - sae: 3424.9700 - sse: 5431.0952 - val_huber_loss: 0.5092 - val_loss: 0.5994 - val_mae: 0.9424 - val_mse: 1.1725 - val_pearson_correlation: 3.4930e-16 - val_r2_keras: -72.9745 - val_rmse: 1.4006 - val_sae: 602.8950 - val_sse: 1037.7220 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6406 - loss: 0.7308 - mae: 1.0732 - mse: 1.7388 - pearson_correlation: 1.9925e-16 - r2_keras: -239.8907 - rmse: 1.3506 - sae: 4711.5649 - sse: 7472.1274\n","Epoch 36: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6023 - loss: 0.7075 - mae: 1.0413 - mse: 1.6421 - pearson_correlation: 1.4188e-16 - r2_keras: -197.4539 - rmse: 1.3350 - sae: 3422.7375 - sse: 5425.5186 - val_huber_loss: 0.5086 - val_loss: 0.5988 - val_mae: 0.9418 - val_mse: 1.1711 - val_pearson_correlation: -1.9661e-16 - val_r2_keras: -72.9068 - val_rmse: 1.4000 - val_sae: 602.5626 - val_sse: 1036.7731 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6399 - loss: 0.7302 - mae: 1.0725 - mse: 1.7370 - pearson_correlation: 2.7357e-16 - r2_keras: -239.6481 - rmse: 1.3500 - sae: 4708.5005 - sse: 7464.6035\n","Epoch 37: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.6017 - loss: 0.7068 - mae: 1.0406 - mse: 1.6403 - pearson_correlation: 1.3532e-16 - r2_keras: -197.2505 - rmse: 1.3343 - sae: 3420.5317 - sse: 5420.0142 - val_huber_loss: 0.5081 - val_loss: 0.5983 - val_mae: 0.9413 - val_mse: 1.1697 - val_pearson_correlation: -1.0930e-16 - val_r2_keras: -72.8400 - val_rmse: 1.3993 - val_sae: 602.2354 - val_sse: 1035.8362 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6393 - loss: 0.7296 - mae: 1.0717 - mse: 1.7352 - pearson_correlation: -3.6383e-16 - r2_keras: -239.4086 - rmse: 1.3493 - sae: 4705.4697 - sse: 7457.1738\n","Epoch 38: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.6010 - loss: 0.7062 - mae: 1.0398 - mse: 1.6385 - pearson_correlation: -3.1863e-16 - r2_keras: -197.0497 - rmse: 1.3336 - sae: 3418.3503 - sse: 5414.5786 - val_huber_loss: 0.5075 - val_loss: 0.5977 - val_mae: 0.9407 - val_mse: 1.1683 - val_pearson_correlation: -1.3125e-16 - val_r2_keras: -72.7741 - val_rmse: 1.3987 - val_sae: 601.9119 - val_sse: 1034.9111 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6388 - loss: 0.7290 - mae: 1.0710 - mse: 1.7335 - pearson_correlation: 6.5876e-17 - r2_keras: -239.1720 - rmse: 1.3486 - sae: 4702.4731 - sse: 7449.8350\n","Epoch 39: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.6004 - loss: 0.7056 - mae: 1.0391 - mse: 1.6367 - pearson_correlation: 3.4855e-17 - r2_keras: -196.8514 - rmse: 1.3329 - sae: 3416.1946 - sse: 5409.2095 - val_huber_loss: 0.5069 - val_loss: 0.5971 - val_mae: 0.9401 - val_mse: 1.1669 - val_pearson_correlation: -1.9700e-16 - val_r2_keras: -72.7089 - val_rmse: 1.3981 - val_sae: 601.5915 - val_sse: 1033.9960 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6382 - loss: 0.7284 - mae: 1.0702 - mse: 1.7318 - pearson_correlation: -1.2370e-16 - r2_keras: -238.9383 - rmse: 1.3480 - sae: 4699.5117 - sse: 7442.5850\n","Epoch 40: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5998 - loss: 0.7050 - mae: 1.0384 - mse: 1.6350 - pearson_correlation: -8.6096e-17 - r2_keras: -196.6554 - rmse: 1.3322 - sae: 3414.0637 - sse: 5403.9058 - val_huber_loss: 0.5064 - val_loss: 0.5966 - val_mae: 0.9396 - val_mse: 1.1656 - val_pearson_correlation: 3.0664e-16 - val_r2_keras: -72.6445 - val_rmse: 1.3975 - val_sae: 601.2747 - val_sse: 1033.0924 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6376 - loss: 0.7278 - mae: 1.0695 - mse: 1.7301 - pearson_correlation: -3.9497e-16 - r2_keras: -238.7073 - rmse: 1.3473 - sae: 4696.5825 - sse: 7435.4209\n","Epoch 41: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.5993 - loss: 0.7045 - mae: 1.0377 - mse: 1.6333 - pearson_correlation: -2.5968e-16 - r2_keras: -196.4618 - rmse: 1.3316 - sae: 3411.9563 - sse: 5398.6641 - val_huber_loss: 0.5058 - val_loss: 0.5960 - val_mae: 0.9390 - val_mse: 1.1642 - val_pearson_correlation: 1.0958e-16 - val_r2_keras: -72.5808 - val_rmse: 1.3969 - val_sae: 600.9611 - val_sse: 1032.1991 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.6370 - loss: 0.7272 - mae: 1.0688 - mse: 1.7284 - pearson_correlation: 2.2002e-16 - r2_keras: -238.4788 - rmse: 1.3467 - sae: 4693.6836 - sse: 7428.3340\n","Epoch 42: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5987 - loss: 0.7039 - mae: 1.0370 - mse: 1.6316 - pearson_correlation: 1.2489e-16 - r2_keras: -196.2702 - rmse: 1.3309 - sae: 3409.8704 - sse: 5393.4790 - val_huber_loss: 0.5052 - val_loss: 0.5955 - val_mae: 0.9385 - val_mse: 1.1629 - val_pearson_correlation: 1.0965e-16 - val_r2_keras: -72.5179 - val_rmse: 1.3963 - val_sae: 600.6510 - val_sse: 1031.3164 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6364 - loss: 0.7267 - mae: 1.0681 - mse: 1.7267 - pearson_correlation: -2.3987e-16 - r2_keras: -238.2531 - rmse: 1.3460 - sae: 4690.8159 - sse: 7421.3311\n","Epoch 43: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5981 - loss: 0.7033 - mae: 1.0363 - mse: 1.6299 - pearson_correlation: -2.0172e-16 - r2_keras: -196.0809 - rmse: 1.3303 - sae: 3407.8069 - sse: 5388.3555 - val_huber_loss: 0.5047 - val_loss: 0.5949 - val_mae: 0.9379 - val_mse: 1.1616 - val_pearson_correlation: -8.7776e-17 - val_r2_keras: -72.4557 - val_rmse: 1.3957 - val_sae: 600.3445 - val_sse: 1030.4449 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6359 - loss: 0.7261 - mae: 1.0674 - mse: 1.7250 - pearson_correlation: 2.6655e-17 - r2_keras: -238.0299 - rmse: 1.3454 - sae: 4687.9785 - sse: 7414.4097\n","Epoch 44: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5975 - loss: 0.7027 - mae: 1.0356 - mse: 1.6283 - pearson_correlation: 3.2320e-17 - r2_keras: -195.8938 - rmse: 1.3296 - sae: 3405.7649 - sse: 5383.2910 - val_huber_loss: 0.5042 - val_loss: 0.5944 - val_mae: 0.9374 - val_mse: 1.1603 - val_pearson_correlation: -2.1957e-17 - val_r2_keras: -72.3944 - val_rmse: 1.3951 - val_sae: 600.0417 - val_sse: 1029.5847 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.6353 - loss: 0.7255 - mae: 1.0667 - mse: 1.7234 - pearson_correlation: 2.3896e-16 - r2_keras: -237.8092 - rmse: 1.3448 - sae: 4685.1709 - sse: 7407.5630\n","Epoch 45: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5970 - loss: 0.7022 - mae: 1.0349 - mse: 1.6266 - pearson_correlation: 2.3757e-16 - r2_keras: -195.7086 - rmse: 1.3290 - sae: 3403.7446 - sse: 5378.2808 - val_huber_loss: 0.5036 - val_loss: 0.5938 - val_mae: 0.9369 - val_mse: 1.1590 - val_pearson_correlation: -2.1971e-17 - val_r2_keras: -72.3337 - val_rmse: 1.3945 - val_sae: 599.7418 - val_sse: 1028.7334 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6348 - loss: 0.7250 - mae: 1.0660 - mse: 1.7218 - pearson_correlation: -2.5000e-16 - r2_keras: -237.5908 - rmse: 1.3442 - sae: 4682.3916 - sse: 7400.7871\n","Epoch 46: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5964 - loss: 0.7016 - mae: 1.0342 - mse: 1.6250 - pearson_correlation: -1.6302e-16 - r2_keras: -195.5254 - rmse: 1.3284 - sae: 3401.7444 - sse: 5373.3228 - val_huber_loss: 0.5031 - val_loss: 0.5933 - val_mae: 0.9363 - val_mse: 1.1577 - val_pearson_correlation: 1.0992e-16 - val_r2_keras: -72.2737 - val_rmse: 1.3939 - val_sae: 599.4449 - val_sse: 1027.8916 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6342 - loss: 0.7245 - mae: 1.0653 - mse: 1.7202 - pearson_correlation: 4.9459e-17 - r2_keras: -237.3747 - rmse: 1.3436 - sae: 4679.6426 - sse: 7394.0845\n","Epoch 47: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5958 - loss: 0.7011 - mae: 1.0335 - mse: 1.6234 - pearson_correlation: 9.3115e-17 - r2_keras: -195.3442 - rmse: 1.3278 - sae: 3399.7659 - sse: 5368.4180 - val_huber_loss: 0.5026 - val_loss: 0.5928 - val_mae: 0.9358 - val_mse: 1.1565 - val_pearson_correlation: 1.9797e-16 - val_r2_keras: -72.2143 - val_rmse: 1.3934 - val_sae: 599.1510 - val_sse: 1027.0581 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6337 - loss: 0.7239 - mae: 1.0646 - mse: 1.7186 - pearson_correlation: 3.2652e-16 - r2_keras: -237.1607 - rmse: 1.3430 - sae: 4676.9180 - sse: 7387.4473\n","Epoch 48: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5953 - loss: 0.7005 - mae: 1.0329 - mse: 1.6218 - pearson_correlation: 2.2862e-16 - r2_keras: -195.1647 - rmse: 1.3271 - sae: 3397.8047 - sse: 5363.5615 - val_huber_loss: 0.5021 - val_loss: 0.5923 - val_mae: 0.9353 - val_mse: 1.1552 - val_pearson_correlation: -1.9809e-16 - val_r2_keras: -72.1555 - val_rmse: 1.3928 - val_sae: 598.8627 - val_sse: 1026.2339 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6332 - loss: 0.7234 - mae: 1.0639 - mse: 1.7170 - pearson_correlation: -2.5237e-17 - r2_keras: -236.9494 - rmse: 1.3424 - sae: 4674.2236 - sse: 7380.8921\n","Epoch 49: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.5947 - loss: 0.7000 - mae: 1.0322 - mse: 1.6202 - pearson_correlation: -5.5148e-17 - r2_keras: -194.9874 - rmse: 1.3265 - sae: 3395.8655 - sse: 5358.7646 - val_huber_loss: 0.5016 - val_loss: 0.5918 - val_mae: 0.9348 - val_mse: 1.1540 - val_pearson_correlation: -1.5416e-16 - val_r2_keras: -72.0975 - val_rmse: 1.3923 - val_sae: 598.5773 - val_sse: 1025.4192 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.6327 - loss: 0.7229 - mae: 1.0633 - mse: 1.7155 - pearson_correlation: 3.5381e-16 - r2_keras: -236.7410 - rmse: 1.3418 - sae: 4671.5654 - sse: 7374.4277\n","Epoch 50: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.5942 - loss: 0.6995 - mae: 1.0316 - mse: 1.6187 - pearson_correlation: 2.0300e-16 - r2_keras: -194.8125 - rmse: 1.3259 - sae: 3393.9514 - sse: 5354.0322 - val_huber_loss: 0.5011 - val_loss: 0.5913 - val_mae: 0.9343 - val_mse: 1.1528 - val_pearson_correlation: -1.9832e-16 - val_r2_keras: -72.0400 - val_rmse: 1.3917 - val_sae: 598.2946 - val_sse: 1024.6127 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6321 - loss: 0.7224 - mae: 1.0626 - mse: 1.7140 - pearson_correlation: 2.8300e-16 - r2_keras: -236.5346 - rmse: 1.3412 - sae: 4668.9326 - sse: 7368.0254\n","Epoch 51: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5937 - loss: 0.6989 - mae: 1.0309 - mse: 1.6172 - pearson_correlation: 1.6857e-16 - r2_keras: -194.6392 - rmse: 1.3253 - sae: 3392.0554 - sse: 5349.3452 - val_huber_loss: 0.5006 - val_loss: 0.5908 - val_mae: 0.9338 - val_mse: 1.1516 - val_pearson_correlation: 4.4096e-17 - val_r2_keras: -71.9831 - val_rmse: 1.3912 - val_sae: 598.0143 - val_sse: 1023.8145 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6316 - loss: 0.7218 - mae: 1.0620 - mse: 1.7124 - pearson_correlation: -1.3953e-16 - r2_keras: -236.3302 - rmse: 1.3406 - sae: 4666.3262 - sse: 7361.6846\n","Epoch 52: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.5932 - loss: 0.6984 - mae: 1.0303 - mse: 1.6156 - pearson_correlation: -1.1313e-16 - r2_keras: -194.4676 - rmse: 1.3248 - sae: 3390.1785 - sse: 5344.7036 - val_huber_loss: 0.5001 - val_loss: 0.5903 - val_mae: 0.9333 - val_mse: 1.1504 - val_pearson_correlation: 1.7648e-16 - val_r2_keras: -71.9267 - val_rmse: 1.3906 - val_sae: 597.7367 - val_sse: 1023.0241 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.6311 - loss: 0.7213 - mae: 1.0613 - mse: 1.7109 - pearson_correlation: -3.1178e-17 - r2_keras: -236.1276 - rmse: 1.3401 - sae: 4663.7422 - sse: 7355.4019\n","Epoch 53: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.5926 - loss: 0.6979 - mae: 1.0296 - mse: 1.6141 - pearson_correlation: -1.7126e-17 - r2_keras: -194.2975 - rmse: 1.3242 - sae: 3388.3174 - sse: 5340.1045 - val_huber_loss: 0.4996 - val_loss: 0.5898 - val_mae: 0.9328 - val_mse: 1.1492 - val_pearson_correlation: -6.6219e-17 - val_r2_keras: -71.8709 - val_rmse: 1.3901 - val_sae: 597.4612 - val_sse: 1022.2407 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.6306 - loss: 0.7208 - mae: 1.0607 - mse: 1.7095 - pearson_correlation: 5.1309e-17 - r2_keras: -235.9269 - rmse: 1.3395 - sae: 4661.1846 - sse: 7349.1768\n","Epoch 54: val_loss did not improve from 0.32710\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.5921 - loss: 0.6974 - mae: 1.0290 - mse: 1.6126 - pearson_correlation: 7.8143e-17 - r2_keras: -194.1290 - rmse: 1.3236 - sae: 3386.4751 - sse: 5335.5474 - val_huber_loss: 0.4991 - val_loss: 0.5893 - val_mae: 0.9323 - val_mse: 1.1481 - val_pearson_correlation: 4.4170e-17 - val_r2_keras: -71.8156 - val_rmse: 1.3896 - val_sae: 597.1879 - val_sse: 1021.4647 - learning_rate: 1.0000e-05\n","| \u001b[39m15       \u001b[39m | \u001b[39m-0.5893  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m97.58    \u001b[39m | \u001b[39m76.75    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.9303 - loss: 1.0157 - mae: 1.3623 - mse: 3.5463 - pearson_correlation: -5.5525e-17 - r2_keras: -416.8046 - rmse: 1.7788 - sae: 4905.6543 - sse: 12959.7754\n","Epoch 1: val_loss improved from inf to 0.35684, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 507ms/step - huber_loss: 1.0183 - loss: 1.0693 - mae: 1.4235 - mse: 3.7684 - pearson_correlation: -2.6176e-17 - r2_keras: -366.0518 - rmse: 1.8503 - sae: 3644.3870 - sse: 9678.1396 - val_huber_loss: 0.2715 - val_loss: 0.3568 - val_mae: 0.5856 - val_mse: 0.7004 - val_pearson_correlation: -1.7080e-16 - val_r2_keras: -23.5206 - val_rmse: 0.8064 - val_sae: 289.3486 - val_sse: 343.9778 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.9016 - loss: 0.9870 - mae: 1.3289 - mse: 3.4357 - pearson_correlation: -2.2363e-16 - r2_keras: -405.7541 - rmse: 1.7551 - sae: 4797.3896 - sse: 12617.0020\n","Epoch 2: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.9889 - loss: 1.0401 - mae: 1.3902 - mse: 3.6553 - pearson_correlation: -1.7327e-16 - r2_keras: -356.5240 - rmse: 1.8263 - sae: 3564.9060 - sse: 9424.2773 - val_huber_loss: 0.3289 - val_loss: 0.4143 - val_mae: 0.5904 - val_mse: 0.9208 - val_pearson_correlation: 6.9860e-17 - val_r2_keras: -30.7580 - val_rmse: 0.9177 - val_sae: 299.1475 - val_sse: 445.5050 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.8801 - loss: 0.9654 - mae: 1.3037 - mse: 3.3529 - pearson_correlation: 2.6827e-16 - r2_keras: -397.5652 - rmse: 1.7373 - sae: 4717.8564 - sse: 12362.9922\n","Epoch 3: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.9662 - loss: 1.0179 - mae: 1.3646 - mse: 3.5693 - pearson_correlation: 1.1881e-16 - r2_keras: -349.3334 - rmse: 1.8079 - sae: 3506.1123 - sse: 9234.6289 - val_huber_loss: 0.4164 - val_loss: 0.5018 - val_mae: 0.6941 - val_mse: 1.2143 - val_pearson_correlation: 1.9238e-16 - val_r2_keras: -40.4934 - val_rmse: 1.0490 - val_sae: 370.5526 - val_sse: 582.0745 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.8618 - loss: 0.9472 - mae: 1.2821 - mse: 3.2833 - pearson_correlation: -5.9487e-17 - r2_keras: -390.7395 - rmse: 1.7224 - sae: 4651.3418 - sse: 12151.2705\n","Epoch 4: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9468 - loss: 0.9989 - mae: 1.3426 - mse: 3.4966 - pearson_correlation: -9.3558e-17 - r2_keras: -343.3027 - rmse: 1.7922 - sae: 3456.8015 - sse: 9076.1182 - val_huber_loss: 0.5008 - val_loss: 0.5862 - val_mae: 0.8191 - val_mse: 1.4964 - val_pearson_correlation: 2.2753e-16 - val_r2_keras: -49.3545 - val_rmse: 1.1556 - val_sae: 436.3422 - val_sse: 706.3787 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.8460 - loss: 0.9314 - mae: 1.2632 - mse: 3.2238 - pearson_correlation: 1.6982e-16 - r2_keras: -384.9502 - rmse: 1.7096 - sae: 4594.1406 - sse: 11971.6924\n","Epoch 5: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.9298 - loss: 0.9824 - mae: 1.3233 - mse: 3.4337 - pearson_correlation: 1.7100e-16 - r2_keras: -338.1256 - rmse: 1.7786 - sae: 3414.2312 - sse: 8940.9443 - val_huber_loss: 0.5628 - val_loss: 0.6482 - val_mae: 0.8958 - val_mse: 1.7165 - val_pearson_correlation: -1.5605e-16 - val_r2_keras: -55.4272 - val_rmse: 1.2233 - val_sae: 475.2025 - val_sse: 791.5665 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.8318 - loss: 0.9172 - mae: 1.2460 - mse: 3.1701 - pearson_correlation: 3.1670e-17 - r2_keras: -379.7648 - rmse: 1.6981 - sae: 4542.5117 - sse: 11810.8467\n","Epoch 6: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.9144 - loss: 0.9675 - mae: 1.3057 - mse: 3.3770 - pearson_correlation: 9.7659e-17 - r2_keras: -333.4831 - rmse: 1.7662 - sae: 3375.8369 - sse: 8819.8066 - val_huber_loss: 0.5991 - val_loss: 0.6845 - val_mae: 0.9273 - val_mse: 1.8622 - val_pearson_correlation: 1.7009e-16 - val_r2_keras: -58.3029 - val_rmse: 1.2540 - val_sae: 488.3804 - val_sse: 831.9072 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.8189 - loss: 0.9043 - mae: 1.2303 - mse: 3.1220 - pearson_correlation: -8.8803e-17 - r2_keras: -375.1558 - rmse: 1.6878 - sae: 4496.2539 - sse: 11667.8809\n","Epoch 7: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.9019 - loss: 0.9548 - mae: 1.2906 - mse: 3.3294 - pearson_correlation: -8.6775e-17 - r2_keras: -329.6191 - rmse: 1.7562 - sae: 3342.4075 - sse: 8715.2139 - val_huber_loss: 0.6216 - val_loss: 0.7070 - val_mae: 0.9606 - val_mse: 1.9625 - val_pearson_correlation: -5.8424e-17 - val_r2_keras: -58.9242 - val_rmse: 1.2606 - val_sae: 489.1110 - val_sse: 840.6234 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.8165 - loss: 0.9019 - mae: 1.2275 - mse: 3.1133 - pearson_correlation: -1.1024e-16 - r2_keras: -374.3330 - rmse: 1.6859 - sae: 4487.7832 - sse: 11642.3604\n","Epoch 8: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8993 - loss: 0.9523 - mae: 1.2876 - mse: 3.3200 - pearson_correlation: -1.9414e-17 - r2_keras: -328.8658 - rmse: 1.7542 - sae: 3336.0681 - sse: 8695.7988 - val_huber_loss: 0.6451 - val_loss: 0.7305 - val_mae: 1.0132 - val_mse: 2.0563 - val_pearson_correlation: 5.8772e-17 - val_r2_keras: -58.7853 - val_rmse: 1.2591 - val_sae: 496.5734 - val_sse: 838.6744 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.8143 - loss: 0.8997 - mae: 1.2248 - mse: 3.1050 - pearson_correlation: -1.6391e-16 - r2_keras: -373.5512 - rmse: 1.6842 - sae: 4479.7173 - sse: 11618.1094\n","Epoch 9: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8968 - loss: 0.9499 - mae: 1.2848 - mse: 3.3111 - pearson_correlation: -1.1618e-16 - r2_keras: -328.1496 - rmse: 1.7523 - sae: 3330.0305 - sse: 8677.3438 - val_huber_loss: 0.6804 - val_loss: 0.7657 - val_mae: 1.0698 - val_mse: 2.1623 - val_pearson_correlation: 2.1805e-16 - val_r2_keras: -58.9490 - val_rmse: 1.2608 - val_sae: 514.2745 - val_sse: 840.9714 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.8121 - loss: 0.8975 - mae: 1.2222 - mse: 3.0971 - pearson_correlation: 2.9879e-16 - r2_keras: -372.8048 - rmse: 1.6825 - sae: 4471.9922 - sse: 11594.9590\n","Epoch 10: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.8944 - loss: 0.9476 - mae: 1.2821 - mse: 3.3026 - pearson_correlation: 1.7612e-16 - r2_keras: -327.4656 - rmse: 1.7504 - sae: 3324.2537 - sse: 8659.7227 - val_huber_loss: 0.7315 - val_loss: 0.8168 - val_mae: 1.1479 - val_mse: 2.2943 - val_pearson_correlation: -5.8915e-17 - val_r2_keras: -60.1477 - val_rmse: 1.2734 - val_sae: 537.4418 - val_sse: 857.7867 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.8101 - loss: 0.8955 - mae: 1.2198 - mse: 3.0896 - pearson_correlation: -7.4490e-17 - r2_keras: -372.0894 - rmse: 1.6809 - sae: 4464.5781 - sse: 11572.7666\n","Epoch 11: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.8922 - loss: 0.9454 - mae: 1.2796 - mse: 3.2944 - pearson_correlation: 2.6582e-17 - r2_keras: -326.8096 - rmse: 1.7486 - sae: 3318.7080 - sse: 8642.8281 - val_huber_loss: 0.7894 - val_loss: 0.8748 - val_mae: 1.2184 - val_mse: 2.4418 - val_pearson_correlation: -2.9224e-16 - val_r2_keras: -62.3908 - val_rmse: 1.2965 - val_sae: 562.6359 - val_sse: 889.2532 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.8081 - loss: 0.8935 - mae: 1.2174 - mse: 3.0823 - pearson_correlation: -3.1148e-16 - r2_keras: -371.4019 - rmse: 1.6793 - sae: 4457.4468 - sse: 11551.4414\n","Epoch 12: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.8901 - loss: 0.9434 - mae: 1.2772 - mse: 3.2870 - pearson_correlation: -2.4003e-16 - r2_keras: -326.2083 - rmse: 1.7470 - sae: 3313.4783 - sse: 8626.9346 - val_huber_loss: 0.8457 - val_loss: 0.9310 - val_mae: 1.2825 - val_mse: 2.5892 - val_pearson_correlation: -2.2090e-16 - val_r2_keras: -65.1831 - val_rmse: 1.3248 - val_sae: 586.2875 - val_sse: 928.4243 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.8071 - loss: 0.8925 - mae: 1.2163 - mse: 3.0787 - pearson_correlation: 2.9764e-17 - r2_keras: -371.0699 - rmse: 1.6786 - sae: 4454.0000 - sse: 11541.1445\n","Epoch 13: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8891 - loss: 0.9424 - mae: 1.2760 - mse: 3.2832 - pearson_correlation: 1.5214e-17 - r2_keras: -325.9036 - rmse: 1.7462 - sae: 3310.8989 - sse: 8619.0918 - val_huber_loss: 0.8967 - val_loss: 0.9821 - val_mae: 1.3418 - val_mse: 2.7264 - val_pearson_correlation: 2.6574e-16 - val_r2_keras: -68.0991 - val_rmse: 1.3537 - val_sae: 607.0491 - val_sse: 969.3297 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.8062 - loss: 0.8916 - mae: 1.2152 - mse: 3.0753 - pearson_correlation: -7.3067e-17 - r2_keras: -370.7484 - rmse: 1.6779 - sae: 4450.6582 - sse: 11531.1699\n","Epoch 14: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.8880 - loss: 0.9414 - mae: 1.2749 - mse: 3.2795 - pearson_correlation: -4.9869e-17 - r2_keras: -325.6084 - rmse: 1.7454 - sae: 3308.3979 - sse: 8611.4941 - val_huber_loss: 0.9403 - val_loss: 1.0257 - val_mae: 1.3953 - val_mse: 2.8491 - val_pearson_correlation: 6.6286e-17 - val_r2_keras: -70.9137 - val_rmse: 1.3809 - val_sae: 624.7088 - val_sse: 1008.8138 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.8053 - loss: 0.8907 - mae: 1.2141 - mse: 3.0720 - pearson_correlation: -9.8291e-18 - r2_keras: -370.4362 - rmse: 1.6772 - sae: 4447.4092 - sse: 11521.4863\n","Epoch 15: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.8870 - loss: 0.9404 - mae: 1.2737 - mse: 3.2759 - pearson_correlation: 5.3684e-17 - r2_keras: -325.3218 - rmse: 1.7446 - sae: 3305.9666 - sse: 8604.1172 - val_huber_loss: 0.9754 - val_loss: 1.0608 - val_mae: 1.4359 - val_mse: 2.9528 - val_pearson_correlation: 2.9950e-16 - val_r2_keras: -73.3525 - val_rmse: 1.4042 - val_sae: 638.7515 - val_sse: 1043.0247 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.8044 - loss: 0.8898 - mae: 1.2130 - mse: 3.0688 - pearson_correlation: -8.5535e-17 - r2_keras: -370.1326 - rmse: 1.6765 - sae: 4444.2490 - sse: 11512.0703\n","Epoch 16: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8861 - loss: 0.9395 - mae: 1.2726 - mse: 3.2725 - pearson_correlation: -8.6000e-17 - r2_keras: -325.0430 - rmse: 1.7438 - sae: 3303.6013 - sse: 8596.9443 - val_huber_loss: 1.0016 - val_loss: 1.0870 - val_mae: 1.4648 - val_mse: 3.0319 - val_pearson_correlation: 1.8834e-16 - val_r2_keras: -75.2238 - val_rmse: 1.4217 - val_sae: 649.1535 - val_sse: 1069.2753 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.8036 - loss: 0.8889 - mae: 1.2120 - mse: 3.0657 - pearson_correlation: 2.5724e-17 - r2_keras: -369.8369 - rmse: 1.6758 - sae: 4441.1670 - sse: 11502.8975\n","Epoch 17: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.8851 - loss: 0.9386 - mae: 1.2716 - mse: 3.2691 - pearson_correlation: -5.5909e-17 - r2_keras: -324.7715 - rmse: 1.7431 - sae: 3301.2942 - sse: 8589.9551 - val_huber_loss: 1.0196 - val_loss: 1.1050 - val_mae: 1.4839 - val_mse: 3.0878 - val_pearson_correlation: 3.0947e-17 - val_r2_keras: -76.5171 - val_rmse: 1.4337 - val_sae: 655.9208 - val_sse: 1087.4182 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.8027 - loss: 0.8881 - mae: 1.2110 - mse: 3.0626 - pearson_correlation: 2.1153e-16 - r2_keras: -369.5485 - rmse: 1.6752 - sae: 4438.1582 - sse: 11493.9521\n","Epoch 18: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.8842 - loss: 0.9377 - mae: 1.2705 - mse: 3.2658 - pearson_correlation: 1.7119e-16 - r2_keras: -324.5065 - rmse: 1.7424 - sae: 3299.0422 - sse: 8583.1396 - val_huber_loss: 1.0326 - val_loss: 1.1180 - val_mae: 1.4973 - val_mse: 3.1289 - val_pearson_correlation: -4.0853e-17 - val_r2_keras: -77.4802 - val_rmse: 1.4426 - val_sae: 660.6744 - val_sse: 1100.9290 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.8019 - loss: 0.8873 - mae: 1.2101 - mse: 3.0596 - pearson_correlation: -8.2733e-17 - r2_keras: -369.2668 - rmse: 1.6745 - sae: 4435.2183 - sse: 11485.2129\n","Epoch 19: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.8833 - loss: 0.9368 - mae: 1.2695 - mse: 3.2625 - pearson_correlation: -4.9351e-17 - r2_keras: -324.2477 - rmse: 1.7417 - sae: 3296.8416 - sse: 8576.4805 - val_huber_loss: 1.0413 - val_loss: 1.1267 - val_mae: 1.5060 - val_mse: 3.1562 - val_pearson_correlation: -3.4501e-16 - val_r2_keras: -78.1269 - val_rmse: 1.4486 - val_sae: 663.8210 - val_sse: 1110.0007 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.8011 - loss: 0.8865 - mae: 1.2092 - mse: 3.0567 - pearson_correlation: 1.4830e-17 - r2_keras: -368.9916 - rmse: 1.6739 - sae: 4432.3477 - sse: 11476.6758\n","Epoch 20: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8824 - loss: 0.9360 - mae: 1.2686 - mse: 3.2594 - pearson_correlation: 5.6345e-17 - r2_keras: -323.9949 - rmse: 1.7410 - sae: 3294.6921 - sse: 8569.9756 - val_huber_loss: 1.0468 - val_loss: 1.1322 - val_mae: 1.5115 - val_mse: 3.1734 - val_pearson_correlation: -4.2451e-16 - val_r2_keras: -78.5322 - val_rmse: 1.4523 - val_sae: 665.7596 - val_sse: 1115.6865 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.8003 - loss: 0.8857 - mae: 1.2083 - mse: 3.0538 - pearson_correlation: 2.1644e-16 - r2_keras: -368.7215 - rmse: 1.6733 - sae: 4429.5303 - sse: 11468.2988\n","Epoch 21: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8815 - loss: 0.9352 - mae: 1.2676 - mse: 3.2563 - pearson_correlation: 1.3267e-16 - r2_keras: -323.7467 - rmse: 1.7403 - sae: 3292.5837 - sse: 8563.5928 - val_huber_loss: 1.0501 - val_loss: 1.1355 - val_mae: 1.5147 - val_mse: 3.1838 - val_pearson_correlation: 3.0251e-17 - val_r2_keras: -78.7719 - val_rmse: 1.4544 - val_sae: 666.8823 - val_sse: 1119.0493 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7996 - loss: 0.8850 - mae: 1.2074 - mse: 3.0510 - pearson_correlation: -8.0430e-17 - r2_keras: -368.4564 - rmse: 1.6727 - sae: 4426.7656 - sse: 11460.0752\n","Epoch 22: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8807 - loss: 0.9343 - mae: 1.2667 - mse: 3.2532 - pearson_correlation: -1.5709e-16 - r2_keras: -323.5033 - rmse: 1.7396 - sae: 3290.5159 - sse: 8557.3281 - val_huber_loss: 1.0520 - val_loss: 1.1374 - val_mae: 1.5164 - val_mse: 3.1895 - val_pearson_correlation: -1.0071e-17 - val_r2_keras: -78.8991 - val_rmse: 1.4556 - val_sae: 667.4539 - val_sse: 1120.8331 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7988 - loss: 0.8842 - mae: 1.2065 - mse: 3.0482 - pearson_correlation: 1.1402e-16 - r2_keras: -368.1965 - rmse: 1.6721 - sae: 4424.0566 - sse: 11452.0146\n","Epoch 23: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8799 - loss: 0.9335 - mae: 1.2658 - mse: 3.2503 - pearson_correlation: 2.0163e-16 - r2_keras: -323.2646 - rmse: 1.7390 - sae: 3288.4905 - sse: 8551.1865 - val_huber_loss: 1.0529 - val_loss: 1.1383 - val_mae: 1.5171 - val_mse: 3.1921 - val_pearson_correlation: 1.0066e-17 - val_r2_keras: -78.9541 - val_rmse: 1.4561 - val_sae: 667.6718 - val_sse: 1121.6052 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7981 - loss: 0.8835 - mae: 1.2057 - mse: 3.0455 - pearson_correlation: -1.6413e-16 - r2_keras: -367.9416 - rmse: 1.6715 - sae: 4421.3975 - sse: 11444.1055\n","Epoch 24: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8790 - loss: 0.9328 - mae: 1.2649 - mse: 3.2473 - pearson_correlation: -1.7459e-16 - r2_keras: -323.0305 - rmse: 1.7383 - sae: 3286.5024 - sse: 8545.1611 - val_huber_loss: 1.0532 - val_loss: 1.1386 - val_mae: 1.5173 - val_mse: 3.1927 - val_pearson_correlation: 1.7110e-16 - val_r2_keras: -78.9625 - val_rmse: 1.4562 - val_sae: 667.6649 - val_sse: 1121.7222 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7974 - loss: 0.8827 - mae: 1.2048 - mse: 3.0428 - pearson_correlation: -2.2164e-17 - r2_keras: -367.6913 - rmse: 1.6710 - sae: 4418.7886 - sse: 11436.3447\n","Epoch 25: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8782 - loss: 0.9320 - mae: 1.2640 - mse: 3.2445 - pearson_correlation: 2.9464e-17 - r2_keras: -322.8007 - rmse: 1.7377 - sae: 3284.5515 - sse: 8539.2480 - val_huber_loss: 1.0531 - val_loss: 1.1385 - val_mae: 1.5171 - val_mse: 3.1920 - val_pearson_correlation: -1.4093e-16 - val_r2_keras: -78.9410 - val_rmse: 1.4560 - val_sae: 667.5184 - val_sse: 1121.4214 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7967 - loss: 0.8820 - mae: 1.2040 - mse: 3.0402 - pearson_correlation: 5.8700e-17 - r2_keras: -367.4454 - rmse: 1.6704 - sae: 4416.2266 - sse: 11428.7148\n","Epoch 26: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8775 - loss: 0.9312 - mae: 1.2631 - mse: 3.2416 - pearson_correlation: 1.3348e-16 - r2_keras: -322.5747 - rmse: 1.7371 - sae: 3282.6353 - sse: 8533.4346 - val_huber_loss: 1.0528 - val_loss: 1.1381 - val_mae: 1.5166 - val_mse: 3.1905 - val_pearson_correlation: 3.8264e-16 - val_r2_keras: -78.9005 - val_rmse: 1.4556 - val_sae: 667.2793 - val_sse: 1120.8534 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7960 - loss: 0.8813 - mae: 1.2032 - mse: 3.0376 - pearson_correlation: 1.6840e-16 - r2_keras: -367.2039 - rmse: 1.6698 - sae: 4413.7080 - sse: 11421.2246\n","Epoch 27: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8767 - loss: 0.9305 - mae: 1.2623 - mse: 3.2388 - pearson_correlation: 1.8218e-16 - r2_keras: -322.3529 - rmse: 1.7365 - sae: 3280.7512 - sse: 8527.7275 - val_huber_loss: 1.0522 - val_loss: 1.1376 - val_mae: 1.5159 - val_mse: 3.1885 - val_pearson_correlation: 6.1452e-16 - val_r2_keras: -78.8482 - val_rmse: 1.4551 - val_sae: 666.9823 - val_sse: 1120.1185 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7953 - loss: 0.8807 - mae: 1.2024 - mse: 3.0351 - pearson_correlation: 2.8318e-18 - r2_keras: -366.9663 - rmse: 1.6693 - sae: 4411.2305 - sse: 11413.8535\n","Epoch 28: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.8759 - loss: 0.9297 - mae: 1.2614 - mse: 3.2361 - pearson_correlation: -5.1068e-18 - r2_keras: -322.1346 - rmse: 1.7359 - sae: 3278.8979 - sse: 8522.1104 - val_huber_loss: 1.0516 - val_loss: 1.1370 - val_mae: 1.5152 - val_mse: 3.1862 - val_pearson_correlation: -3.1246e-16 - val_r2_keras: -78.7886 - val_rmse: 1.4546 - val_sae: 666.6505 - val_sse: 1119.2830 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7946 - loss: 0.8800 - mae: 1.2016 - mse: 3.0326 - pearson_correlation: -9.7656e-17 - r2_keras: -366.7324 - rmse: 1.6688 - sae: 4408.7930 - sse: 11406.5977\n","Epoch 29: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8752 - loss: 0.9290 - mae: 1.2606 - mse: 3.2334 - pearson_correlation: -7.9566e-18 - r2_keras: -321.9196 - rmse: 1.7353 - sae: 3277.0742 - sse: 8516.5811 - val_huber_loss: 1.0510 - val_loss: 1.1363 - val_mae: 1.5144 - val_mse: 3.1837 - val_pearson_correlation: -3.4289e-16 - val_r2_keras: -78.7248 - val_rmse: 1.4540 - val_sae: 666.2983 - val_sse: 1118.3877 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7939 - loss: 0.8793 - mae: 1.2008 - mse: 3.0302 - pearson_correlation: -3.8748e-17 - r2_keras: -366.5021 - rmse: 1.6683 - sae: 4406.3936 - sse: 11399.4570\n","Epoch 30: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8744 - loss: 0.9283 - mae: 1.2598 - mse: 3.2308 - pearson_correlation: -1.8831e-17 - r2_keras: -321.7081 - rmse: 1.7347 - sae: 3275.2788 - sse: 8511.1396 - val_huber_loss: 1.0503 - val_loss: 1.1356 - val_mae: 1.5136 - val_mse: 3.1811 - val_pearson_correlation: 8.0728e-17 - val_r2_keras: -78.6586 - val_rmse: 1.4534 - val_sae: 665.9348 - val_sse: 1117.4598 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7933 - loss: 0.8787 - mae: 1.2001 - mse: 3.0277 - pearson_correlation: 1.9613e-16 - r2_keras: -366.2754 - rmse: 1.6677 - sae: 4404.0273 - sse: 11392.4238\n","Epoch 31: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8737 - loss: 0.9276 - mae: 1.2590 - mse: 3.2282 - pearson_correlation: 2.0663e-16 - r2_keras: -321.4998 - rmse: 1.7341 - sae: 3273.5083 - sse: 8505.7803 - val_huber_loss: 1.0495 - val_loss: 1.1349 - val_mae: 1.5127 - val_mse: 3.1785 - val_pearson_correlation: 3.4330e-16 - val_r2_keras: -78.5914 - val_rmse: 1.4528 - val_sae: 665.5661 - val_sse: 1116.5164 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7926 - loss: 0.8780 - mae: 1.1993 - mse: 3.0253 - pearson_correlation: 8.5597e-18 - r2_keras: -366.0520 - rmse: 1.6672 - sae: 4401.6973 - sse: 11385.4951\n","Epoch 32: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8730 - loss: 0.9269 - mae: 1.2582 - mse: 3.2256 - pearson_correlation: 1.5048e-17 - r2_keras: -321.2945 - rmse: 1.7336 - sae: 3271.7644 - sse: 8500.5000 - val_huber_loss: 1.0488 - val_loss: 1.1342 - val_mae: 1.5119 - val_mse: 3.1758 - val_pearson_correlation: -2.5258e-16 - val_r2_keras: -78.5237 - val_rmse: 1.4522 - val_sae: 665.1956 - val_sse: 1115.5675 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7920 - loss: 0.8774 - mae: 1.1986 - mse: 3.0230 - pearson_correlation: -3.4468e-16 - r2_keras: -365.8316 - rmse: 1.6667 - sae: 4399.4014 - sse: 11378.6582\n","Epoch 33: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8723 - loss: 0.9262 - mae: 1.2574 - mse: 3.2230 - pearson_correlation: -1.7254e-16 - r2_keras: -321.0919 - rmse: 1.7330 - sae: 3270.0459 - sse: 8495.2900 - val_huber_loss: 1.0481 - val_loss: 1.1335 - val_mae: 1.5110 - val_mse: 3.1731 - val_pearson_correlation: -3.2349e-16 - val_r2_keras: -78.4562 - val_rmse: 1.4516 - val_sae: 664.8258 - val_sse: 1114.6200 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.7914 - loss: 0.8767 - mae: 1.1978 - mse: 3.0207 - pearson_correlation: 1.2163e-16 - r2_keras: -365.6144 - rmse: 1.6662 - sae: 4397.1396 - sse: 11371.9219\n","Epoch 34: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8716 - loss: 0.9256 - mae: 1.2566 - mse: 3.2205 - pearson_correlation: 8.5759e-17 - r2_keras: -320.8923 - rmse: 1.7325 - sae: 3268.3535 - sse: 8490.1562 - val_huber_loss: 1.0473 - val_loss: 1.1327 - val_mae: 1.5102 - val_mse: 3.1705 - val_pearson_correlation: -2.1242e-16 - val_r2_keras: -78.3890 - val_rmse: 1.4509 - val_sae: 664.4578 - val_sse: 1113.6776 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.7907 - loss: 0.8761 - mae: 1.1971 - mse: 3.0184 - pearson_correlation: -2.7927e-16 - r2_keras: -365.4001 - rmse: 1.6658 - sae: 4394.9067 - sse: 11365.2734\n","Epoch 35: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8709 - loss: 0.9249 - mae: 1.2558 - mse: 3.2181 - pearson_correlation: -1.1369e-16 - r2_keras: -320.6954 - rmse: 1.7319 - sae: 3266.6829 - sse: 8485.0889 - val_huber_loss: 1.0466 - val_loss: 1.1320 - val_mae: 1.5093 - val_mse: 3.1678 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -78.3224 - val_rmse: 1.4503 - val_sae: 664.0926 - val_sse: 1112.7428 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7901 - loss: 0.8755 - mae: 1.1964 - mse: 3.0161 - pearson_correlation: 2.3186e-17 - r2_keras: -365.1886 - rmse: 1.6653 - sae: 4392.7061 - sse: 11358.7109\n","Epoch 36: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8702 - loss: 0.9243 - mae: 1.2551 - mse: 3.2156 - pearson_correlation: 2.0136e-17 - r2_keras: -320.5009 - rmse: 1.7314 - sae: 3265.0359 - sse: 8480.0879 - val_huber_loss: 1.0459 - val_loss: 1.1313 - val_mae: 1.5085 - val_mse: 3.1652 - val_pearson_correlation: 3.5445e-16 - val_r2_keras: -78.2564 - val_rmse: 1.4497 - val_sae: 663.7340 - val_sse: 1111.8175 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7895 - loss: 0.8749 - mae: 1.1957 - mse: 3.0139 - pearson_correlation: -4.7989e-17 - r2_keras: -364.9795 - rmse: 1.6648 - sae: 4390.5303 - sse: 11352.2256\n","Epoch 37: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.8695 - loss: 0.9236 - mae: 1.2543 - mse: 3.2132 - pearson_correlation: -6.0074e-17 - r2_keras: -320.3088 - rmse: 1.7309 - sae: 3263.4077 - sse: 8475.1455 - val_huber_loss: 1.0452 - val_loss: 1.1306 - val_mae: 1.5077 - val_mse: 3.1626 - val_pearson_correlation: -1.7226e-16 - val_r2_keras: -78.1910 - val_rmse: 1.4491 - val_sae: 663.3782 - val_sse: 1110.9001 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7889 - loss: 0.8743 - mae: 1.1950 - mse: 3.0117 - pearson_correlation: 9.8078e-17 - r2_keras: -364.7727 - rmse: 1.6643 - sae: 4388.3784 - sse: 11345.8125\n","Epoch 38: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.8689 - loss: 0.9230 - mae: 1.2536 - mse: 3.2108 - pearson_correlation: 6.8897e-17 - r2_keras: -320.1188 - rmse: 1.7303 - sae: 3261.7974 - sse: 8470.2588 - val_huber_loss: 1.0445 - val_loss: 1.1299 - val_mae: 1.5068 - val_mse: 3.1600 - val_pearson_correlation: -1.0139e-17 - val_r2_keras: -78.1264 - val_rmse: 1.4485 - val_sae: 663.0265 - val_sse: 1109.9932 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7883 - loss: 0.8737 - mae: 1.1943 - mse: 3.0095 - pearson_correlation: 3.6701e-18 - r2_keras: -364.5683 - rmse: 1.6639 - sae: 4386.2598 - sse: 11339.4727\n","Epoch 39: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.8682 - loss: 0.9223 - mae: 1.2529 - mse: 3.2085 - pearson_correlation: -2.5656e-17 - r2_keras: -319.9310 - rmse: 1.7298 - sae: 3260.2112 - sse: 8465.4277 - val_huber_loss: 1.0438 - val_loss: 1.1292 - val_mae: 1.5060 - val_mse: 3.1575 - val_pearson_correlation: 2.6376e-16 - val_r2_keras: -78.0625 - val_rmse: 1.4480 - val_sae: 662.6808 - val_sse: 1109.0973 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.7877 - loss: 0.8731 - mae: 1.1936 - mse: 3.0073 - pearson_correlation: 6.4430e-17 - r2_keras: -364.3663 - rmse: 1.6634 - sae: 4384.1641 - sse: 11333.2070\n","Epoch 40: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.8676 - loss: 0.9217 - mae: 1.2522 - mse: 3.2062 - pearson_correlation: 6.8724e-17 - r2_keras: -319.7455 - rmse: 1.7293 - sae: 3258.6423 - sse: 8460.6533 - val_huber_loss: 1.0431 - val_loss: 1.1285 - val_mae: 1.5052 - val_mse: 3.1550 - val_pearson_correlation: 2.0301e-17 - val_r2_keras: -77.9994 - val_rmse: 1.4474 - val_sae: 662.3392 - val_sse: 1108.2124 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.7872 - loss: 0.8726 - mae: 1.1930 - mse: 3.0052 - pearson_correlation: -7.5004e-18 - r2_keras: -364.1667 - rmse: 1.6629 - sae: 4382.0938 - sse: 11327.0127\n","Epoch 41: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.8669 - loss: 0.9211 - mae: 1.2515 - mse: 3.2039 - pearson_correlation: -5.4218e-17 - r2_keras: -319.5620 - rmse: 1.7288 - sae: 3257.0920 - sse: 8455.9336 - val_huber_loss: 1.0424 - val_loss: 1.1278 - val_mae: 1.5044 - val_mse: 3.1525 - val_pearson_correlation: 2.8437e-16 - val_r2_keras: -77.9370 - val_rmse: 1.4468 - val_sae: 662.0009 - val_sse: 1107.3374 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7866 - loss: 0.8720 - mae: 1.1923 - mse: 3.0031 - pearson_correlation: 1.3971e-17 - r2_keras: -363.9691 - rmse: 1.6625 - sae: 4380.0469 - sse: 11320.8867\n","Epoch 42: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8663 - loss: 0.9205 - mae: 1.2508 - mse: 3.2016 - pearson_correlation: -1.2366e-18 - r2_keras: -319.3806 - rmse: 1.7283 - sae: 3255.5593 - sse: 8451.2666 - val_huber_loss: 1.0417 - val_loss: 1.1271 - val_mae: 1.5037 - val_mse: 3.1500 - val_pearson_correlation: -5.0809e-17 - val_r2_keras: -77.8754 - val_rmse: 1.4462 - val_sae: 661.6660 - val_sse: 1106.4722 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7860 - loss: 0.8714 - mae: 1.1916 - mse: 3.0010 - pearson_correlation: -3.0849e-17 - r2_keras: -363.7740 - rmse: 1.6621 - sae: 4378.0225 - sse: 11314.8330\n","Epoch 43: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.8657 - loss: 0.9199 - mae: 1.2501 - mse: 3.1993 - pearson_correlation: 1.9306e-17 - r2_keras: -319.2013 - rmse: 1.7278 - sae: 3254.0437 - sse: 8446.6533 - val_huber_loss: 1.0410 - val_loss: 1.1264 - val_mae: 1.5029 - val_mse: 3.1476 - val_pearson_correlation: 6.1004e-17 - val_r2_keras: -77.8144 - val_rmse: 1.4457 - val_sae: 661.3347 - val_sse: 1105.6169 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.7855 - loss: 0.8709 - mae: 1.1910 - mse: 2.9989 - pearson_correlation: 6.5188e-17 - r2_keras: -363.5810 - rmse: 1.6616 - sae: 4376.0264 - sse: 11308.8457\n","Epoch 44: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8650 - loss: 0.9193 - mae: 1.2494 - mse: 3.1971 - pearson_correlation: -4.8045e-17 - r2_keras: -319.0239 - rmse: 1.7273 - sae: 3252.5481 - sse: 8442.0908 - val_huber_loss: 1.0404 - val_loss: 1.1258 - val_mae: 1.5021 - val_mse: 3.1452 - val_pearson_correlation: 2.5432e-16 - val_r2_keras: -77.7541 - val_rmse: 1.4451 - val_sae: 661.0063 - val_sse: 1104.7706 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7849 - loss: 0.8703 - mae: 1.1904 - mse: 2.9969 - pearson_correlation: 5.7802e-17 - r2_keras: -363.3900 - rmse: 1.6612 - sae: 4374.0527 - sse: 11302.9209\n","Epoch 45: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8644 - loss: 0.9187 - mae: 1.2487 - mse: 3.1949 - pearson_correlation: 7.1394e-17 - r2_keras: -318.8484 - rmse: 1.7268 - sae: 3251.0693 - sse: 8437.5762 - val_huber_loss: 1.0397 - val_loss: 1.1251 - val_mae: 1.5013 - val_mse: 3.1428 - val_pearson_correlation: -9.1606e-17 - val_r2_keras: -77.6944 - val_rmse: 1.4446 - val_sae: 660.6815 - val_sse: 1103.9337 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7844 - loss: 0.8698 - mae: 1.1897 - mse: 2.9949 - pearson_correlation: -4.3210e-17 - r2_keras: -363.2011 - rmse: 1.6607 - sae: 4372.1006 - sse: 11297.0615\n","Epoch 46: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8638 - loss: 0.9181 - mae: 1.2480 - mse: 3.1927 - pearson_correlation: -5.6982e-17 - r2_keras: -318.6748 - rmse: 1.7263 - sae: 3249.6062 - sse: 8433.1094 - val_huber_loss: 1.0391 - val_loss: 1.1245 - val_mae: 1.5006 - val_mse: 3.1405 - val_pearson_correlation: 1.5276e-16 - val_r2_keras: -77.6354 - val_rmse: 1.4440 - val_sae: 660.3598 - val_sse: 1103.1061 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7838 - loss: 0.8692 - mae: 1.1891 - mse: 2.9929 - pearson_correlation: -5.6854e-17 - r2_keras: -363.0140 - rmse: 1.6603 - sae: 4370.1670 - sse: 11291.2578\n","Epoch 47: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8632 - loss: 0.9175 - mae: 1.2474 - mse: 3.1906 - pearson_correlation: -5.6692e-17 - r2_keras: -318.5028 - rmse: 1.7259 - sae: 3248.1572 - sse: 8428.6865 - val_huber_loss: 1.0384 - val_loss: 1.1238 - val_mae: 1.4998 - val_mse: 3.1381 - val_pearson_correlation: -6.0116e-16 - val_r2_keras: -77.5770 - val_rmse: 1.4435 - val_sae: 660.0411 - val_sse: 1102.2871 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7833 - loss: 0.8687 - mae: 1.1885 - mse: 2.9909 - pearson_correlation: 1.3199e-16 - r2_keras: -362.8288 - rmse: 1.6599 - sae: 4368.2510 - sse: 11285.5146\n","Epoch 48: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8626 - loss: 0.9170 - mae: 1.2467 - mse: 3.1884 - pearson_correlation: 1.5731e-16 - r2_keras: -318.3326 - rmse: 1.7254 - sae: 3246.7212 - sse: 8424.3086 - val_huber_loss: 1.0378 - val_loss: 1.1232 - val_mae: 1.4991 - val_mse: 3.1358 - val_pearson_correlation: -2.1409e-16 - val_r2_keras: -77.5191 - val_rmse: 1.4430 - val_sae: 659.7248 - val_sse: 1101.4747 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.7828 - loss: 0.8682 - mae: 1.1878 - mse: 2.9889 - pearson_correlation: -7.1980e-17 - r2_keras: -362.6453 - rmse: 1.6595 - sae: 4366.3511 - sse: 11279.8232\n","Epoch 49: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8620 - loss: 0.9164 - mae: 1.2460 - mse: 3.1863 - pearson_correlation: -4.3286e-17 - r2_keras: -318.1639 - rmse: 1.7249 - sae: 3245.2971 - sse: 8419.9707 - val_huber_loss: 1.0372 - val_loss: 1.1225 - val_mae: 1.4984 - val_mse: 3.1335 - val_pearson_correlation: 2.8560e-16 - val_r2_keras: -77.4619 - val_rmse: 1.4425 - val_sae: 659.4135 - val_sse: 1100.6714 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.7822 - loss: 0.8676 - mae: 1.1872 - mse: 2.9870 - pearson_correlation: 1.4369e-17 - r2_keras: -362.4638 - rmse: 1.6591 - sae: 4364.4712 - sse: 11274.1924\n","Epoch 50: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.8614 - loss: 0.9158 - mae: 1.2454 - mse: 3.1842 - pearson_correlation: 4.3671e-17 - r2_keras: -317.9970 - rmse: 1.7245 - sae: 3243.8882 - sse: 8415.6787 - val_huber_loss: 1.0365 - val_loss: 1.1219 - val_mae: 1.4976 - val_mse: 3.1313 - val_pearson_correlation: 2.0410e-17 - val_r2_keras: -77.4052 - val_rmse: 1.4419 - val_sae: 659.1060 - val_sse: 1099.8763 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7817 - loss: 0.8671 - mae: 1.1866 - mse: 2.9851 - pearson_correlation: -5.4121e-17 - r2_keras: -362.2839 - rmse: 1.6587 - sae: 4362.6084 - sse: 11268.6113\n","Epoch 51: val_loss did not improve from 0.35684\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.8609 - loss: 0.9153 - mae: 1.2448 - mse: 3.1821 - pearson_correlation: -5.8425e-17 - r2_keras: -317.8315 - rmse: 1.7240 - sae: 3242.4919 - sse: 8411.4238 - val_huber_loss: 1.0359 - val_loss: 1.1213 - val_mae: 1.4969 - val_mse: 3.1290 - val_pearson_correlation: 8.1683e-17 - val_r2_keras: -77.3491 - val_rmse: 1.4414 - val_sae: 658.8014 - val_sse: 1099.0898 - learning_rate: 1.0000e-05\n","| \u001b[39m16       \u001b[39m | \u001b[39m-1.121   \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m94.17    \u001b[39m | \u001b[39m73.49    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3s/step - huber_loss: 0.9518 - loss: 1.0410 - mae: 1.4275 - mse: 2.5172 - pearson_correlation: -3.1239e-16 - r2_keras: -251.4478 - rmse: 1.3827 - sae: 4839.6987 - sse: 7830.6152\n","Epoch 1: val_loss improved from inf to 0.50312, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 504ms/step - huber_loss: 2.0533 - loss: 1.7123 - mae: 2.0994 - mse: 8.1717 - pearson_correlation: -8.8941e-17 - r2_keras: -913.7894 - rmse: 2.8513 - sae: 4525.2168 - sse: 13976.7725 - val_huber_loss: 0.4084 - val_loss: 0.5031 - val_mae: 0.8289 - val_mse: 0.9031 - val_pearson_correlation: 5.9708e-16 - val_r2_keras: -32.2005 - val_rmse: 0.9383 - val_sae: 421.1376 - val_sse: 465.7402 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7263 - loss: 0.8210 - mae: 1.0921 - mse: 2.8898 - pearson_correlation: 2.0493e-16 - r2_keras: -492.5926 - rmse: 1.9334 - sae: 5360.8926 - sse: 15310.6240\n","Epoch 2: val_loss did not improve from 0.50312\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.7631 - loss: 0.8435 - mae: 1.1212 - mse: 2.8144 - pearson_correlation: 6.7465e-17 - r2_keras: -392.2950 - rmse: 1.8549 - sae: 3918.9629 - sse: 10960.5410 - val_huber_loss: 0.4788 - val_loss: 0.5740 - val_mae: 0.8621 - val_mse: 1.1242 - val_pearson_correlation: -1.2434e-16 - val_r2_keras: -32.7893 - val_rmse: 0.9466 - val_sae: 395.1583 - val_sse: 474.0001 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.9216 - loss: 1.0169 - mae: 1.3449 - mse: 2.5545 - pearson_correlation: 6.8367e-16 - r2_keras: -326.4619 - rmse: 1.5748 - sae: 5479.0527 - sse: 10157.4590\n","Epoch 3: val_loss improved from 0.50312 to 0.47499, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.8431 - loss: 0.9691 - mae: 1.2970 - mse: 2.3870 - pearson_correlation: 4.8323e-16 - r2_keras: -273.2461 - rmse: 1.5780 - sae: 3990.3284 - sse: 7427.7954 - val_huber_loss: 0.3796 - val_loss: 0.4750 - val_mae: 0.7630 - val_mse: 0.8765 - val_pearson_correlation: -1.7043e-16 - val_r2_keras: -25.8299 - val_rmse: 0.8435 - val_sae: 356.7061 - val_sse: 376.3721 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.5845 - loss: 0.6798 - mae: 1.0116 - mse: 1.3630 - pearson_correlation: 1.1577e-17 - r2_keras: -128.3381 - rmse: 0.9897 - sae: 3190.8054 - sse: 4011.9065\n","Epoch 4: val_loss improved from 0.47499 to 0.43400, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.5669 - loss: 0.6692 - mae: 0.9944 - mse: 1.3328 - pearson_correlation: 1.1146e-16 - r2_keras: -131.0354 - rmse: 1.1378 - sae: 2418.8616 - sse: 3211.9568 - val_huber_loss: 0.3386 - val_loss: 0.4340 - val_mae: 0.7088 - val_mse: 0.8202 - val_pearson_correlation: 2.2496e-16 - val_r2_keras: -26.1906 - val_rmse: 0.8491 - val_sae: 336.2983 - val_sse: 381.4330 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.3898 - loss: 0.4852 - mae: 0.7854 - mse: 0.8679 - pearson_correlation: 4.1644e-16 - r2_keras: -118.9305 - rmse: 0.9530 - sae: 3090.3914 - sse: 3720.0957\n","Epoch 5: val_loss improved from 0.43400 to 0.41702, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.3704 - loss: 0.4733 - mae: 0.7652 - mse: 0.8306 - pearson_correlation: 1.4322e-16 - r2_keras: -107.9738 - rmse: 1.0158 - sae: 2298.2222 - sse: 2820.4709 - val_huber_loss: 0.3217 - val_loss: 0.4170 - val_mae: 0.6882 - val_mse: 0.8069 - val_pearson_correlation: 6.2626e-18 - val_r2_keras: -27.7011 - val_rmse: 0.8724 - val_sae: 337.8441 - val_sse: 402.6225 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3348 - loss: 0.4301 - mae: 0.7149 - mse: 0.7359 - pearson_correlation: 2.3896e-16 - r2_keras: -112.1491 - rmse: 0.9257 - sae: 2999.8240 - sse: 3509.7451\n","Epoch 6: val_loss improved from 0.41702 to 0.31533, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.3022 - loss: 0.4103 - mae: 0.6801 - mse: 0.6849 - pearson_correlation: 2.2239e-16 - r2_keras: -96.8304 - rmse: 0.9513 - sae: 2206.2588 - sse: 2602.5549 - val_huber_loss: 0.2201 - val_loss: 0.3153 - val_mae: 0.5111 - val_mse: 0.5517 - val_pearson_correlation: -1.1207e-16 - val_r2_keras: -26.7934 - val_rmse: 0.8585 - val_sae: 309.7154 - val_sse: 389.8890 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1723 - loss: 0.2676 - mae: 0.4700 - mse: 0.3714 - pearson_correlation: -3.9732e-16 - r2_keras: -86.9535 - rmse: 0.8161 - sae: 2456.4653 - sse: 2728.2068\n","Epoch 7: val_loss improved from 0.31533 to 0.24113, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.1571 - loss: 0.2583 - mae: 0.4446 - mse: 0.3498 - pearson_correlation: -2.1386e-16 - r2_keras: -70.8328 - rmse: 0.8006 - sae: 1789.2247 - sse: 1973.6078 - val_huber_loss: 0.1461 - val_loss: 0.2411 - val_mae: 0.4044 - val_mse: 0.3256 - val_pearson_correlation: -2.6259e-16 - val_r2_keras: -34.5450 - val_rmse: 0.9709 - val_sae: 374.2395 - val_sse: 498.6292 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2410 - loss: 0.3361 - mae: 0.5771 - mse: 0.5441 - pearson_correlation: -5.5767e-17 - r2_keras: -153.2313 - rmse: 1.0807 - sae: 3416.0637 - sse: 4784.0625\n","Epoch 8: val_loss did not improve from 0.24113\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2725 - loss: 0.3553 - mae: 0.5952 - mse: 0.5838 - pearson_correlation: 3.4998e-18 - r2_keras: -120.7162 - rmse: 1.0275 - sae: 2462.2087 - sse: 3411.0183 - val_huber_loss: 0.1763 - val_loss: 0.2712 - val_mae: 0.4927 - val_mse: 0.3611 - val_pearson_correlation: 1.3391e-16 - val_r2_keras: -45.2614 - val_rmse: 1.1076 - val_sae: 455.8351 - val_sse: 648.9593 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3182 - loss: 0.4132 - mae: 0.6991 - mse: 0.7326 - pearson_correlation: 1.1005e-16 - r2_keras: -192.7481 - rmse: 1.2113 - sae: 3836.6909 - sse: 6009.8232\n","Epoch 9: val_loss did not improve from 0.24113\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3092 - loss: 0.4076 - mae: 0.6840 - mse: 0.7094 - pearson_correlation: 1.0399e-16 - r2_keras: -147.4208 - rmse: 1.1174 - sae: 2749.6978 - sse: 4232.4150 - val_huber_loss: 0.1582 - val_loss: 0.2530 - val_mae: 0.4476 - val_mse: 0.3246 - val_pearson_correlation: -3.0058e-16 - val_r2_keras: -41.9585 - val_rmse: 1.0673 - val_sae: 433.2849 - val_sse: 602.6259 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2186 - loss: 0.3133 - mae: 0.5488 - mse: 0.4910 - pearson_correlation: 4.6086e-16 - r2_keras: -148.4551 - rmse: 1.0639 - sae: 3316.9370 - sse: 4635.9097\n","Epoch 10: val_loss did not improve from 0.24113\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1963 - loss: 0.2998 - mae: 0.5262 - mse: 0.4538 - pearson_correlation: 2.6980e-16 - r2_keras: -113.3510 - rmse: 0.9801 - sae: 2377.6099 - sse: 3263.2053 - val_huber_loss: 0.1567 - val_loss: 0.2513 - val_mae: 0.4293 - val_mse: 0.3288 - val_pearson_correlation: -3.6115e-17 - val_r2_keras: -39.9046 - val_rmse: 1.0415 - val_sae: 420.4413 - val_sse: 573.8146 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1709 - loss: 0.2655 - mae: 0.4782 - mse: 0.3756 - pearson_correlation: -1.2110e-17 - r2_keras: -126.7648 - rmse: 0.9836 - sae: 3096.6318 - sse: 3963.1038\n","Epoch 11: val_loss did not improve from 0.24113\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1505 - loss: 0.2530 - mae: 0.4510 - mse: 0.3443 - pearson_correlation: 1.8146e-17 - r2_keras: -97.6346 - rmse: 0.9148 - sae: 2218.9390 - sse: 2799.9331 - val_huber_loss: 0.1492 - val_loss: 0.2435 - val_mae: 0.3955 - val_mse: 0.3192 - val_pearson_correlation: 1.5650e-16 - val_r2_keras: -37.1788 - val_rmse: 1.0062 - val_sae: 395.5006 - val_sse: 535.5757 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1297 - loss: 0.2241 - mae: 0.3750 - mse: 0.2820 - pearson_correlation: -3.0614e-16 - r2_keras: -109.9826 - rmse: 0.9168 - sae: 2812.4932 - sse: 3442.5425\n","Epoch 12: val_loss improved from 0.24113 to 0.23761, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1144 - loss: 0.2147 - mae: 0.3564 - mse: 0.2590 - pearson_correlation: -1.9997e-16 - r2_keras: -86.5461 - rmse: 0.8712 - sae: 2028.5614 - sse: 2454.0601 - val_huber_loss: 0.1434 - val_loss: 0.2376 - val_mae: 0.3730 - val_mse: 0.3119 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.5527 - val_rmse: 0.9710 - val_sae: 375.6525 - val_sse: 498.7370 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1100 - loss: 0.2042 - mae: 0.3233 - mse: 0.2377 - pearson_correlation: 2.5940e-16 - r2_keras: -99.3937 - rmse: 0.8719 - sae: 2625.2522 - sse: 3114.0872\n","Epoch 13: val_loss improved from 0.23761 to 0.23462, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0989 - loss: 0.1974 - mae: 0.3123 - mse: 0.2208 - pearson_correlation: 1.9707e-16 - r2_keras: -80.3578 - rmse: 0.8495 - sae: 1906.8223 - sse: 2245.3066 - val_huber_loss: 0.1407 - val_loss: 0.2346 - val_mae: 0.3655 - val_mse: 0.3095 - val_pearson_correlation: 1.1350e-17 - val_r2_keras: -33.1903 - val_rmse: 0.9522 - val_sae: 364.6428 - val_sse: 479.6247 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1079 - loss: 0.2018 - mae: 0.3109 - mse: 0.2309 - pearson_correlation: 7.5040e-17 - r2_keras: -97.4540 - rmse: 0.8635 - sae: 2553.3364 - sse: 3053.9202\n","Epoch 14: val_loss improved from 0.23462 to 0.23412, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0981 - loss: 0.1959 - mae: 0.3004 - mse: 0.2160 - pearson_correlation: 4.6118e-17 - r2_keras: -80.1019 - rmse: 0.8534 - sae: 1864.7465 - sse: 2217.3623 - val_huber_loss: 0.1404 - val_loss: 0.2341 - val_mae: 0.3658 - val_mse: 0.3129 - val_pearson_correlation: 5.8387e-17 - val_r2_keras: -32.5683 - val_rmse: 0.9435 - val_sae: 359.5689 - val_sse: 470.8999 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1066 - loss: 0.2004 - mae: 0.3054 - mse: 0.2277 - pearson_correlation: 1.3426e-16 - r2_keras: -96.5062 - rmse: 0.8593 - sae: 2524.6731 - sse: 3024.5205\n","Epoch 15: val_loss improved from 0.23412 to 0.22865, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0935 - loss: 0.1924 - mae: 0.2905 - mse: 0.2089 - pearson_correlation: 1.3505e-16 - r2_keras: -79.5654 - rmse: 0.8515 - sae: 1845.4210 - sse: 2198.8811 - val_huber_loss: 0.1351 - val_loss: 0.2287 - val_mae: 0.3591 - val_mse: 0.3014 - val_pearson_correlation: 2.7207e-16 - val_r2_keras: -32.2954 - val_rmse: 0.9396 - val_sae: 359.5357 - val_sse: 467.0720 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0925 - loss: 0.1861 - mae: 0.2847 - mse: 0.1959 - pearson_correlation: -2.2329e-16 - r2_keras: -88.4596 - rmse: 0.8231 - sae: 2463.3008 - sse: 2774.9253\n","Epoch 16: val_loss improved from 0.22865 to 0.22345, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0838 - loss: 0.1807 - mae: 0.2743 - mse: 0.1831 - pearson_correlation: -1.3419e-16 - r2_keras: -74.9232 - rmse: 0.8337 - sae: 1809.0472 - sse: 2040.9557 - val_huber_loss: 0.1301 - val_loss: 0.2235 - val_mae: 0.3480 - val_mse: 0.2904 - val_pearson_correlation: -1.4516e-16 - val_r2_keras: -31.8712 - val_rmse: 0.9336 - val_sae: 359.3342 - val_sse: 461.1214 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0987 - loss: 0.1920 - mae: 0.3043 - mse: 0.2067 - pearson_correlation: 6.3973e-18 - r2_keras: -85.6627 - rmse: 0.8101 - sae: 2429.0000 - sse: 2688.1694\n","Epoch 17: val_loss improved from 0.22345 to 0.21901, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0918 - loss: 0.1878 - mae: 0.2966 - mse: 0.1965 - pearson_correlation: -8.1813e-17 - r2_keras: -74.3815 - rmse: 0.8364 - sae: 1793.0099 - sse: 1998.6361 - val_huber_loss: 0.1259 - val_loss: 0.2190 - val_mae: 0.3476 - val_mse: 0.2804 - val_pearson_correlation: -6.1195e-17 - val_r2_keras: -31.6935 - val_rmse: 0.9311 - val_sae: 360.1270 - val_sse: 458.6286 - learning_rate: 0.1000\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1153 - loss: 0.2084 - mae: 0.3310 - mse: 0.2495 - pearson_correlation: -4.3880e-16 - r2_keras: -87.4845 - rmse: 0.8186 - sae: 2476.0420 - sse: 2744.6787\n","Epoch 18: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0983 - loss: 0.1981 - mae: 0.3133 - mse: 0.2250 - pearson_correlation: -3.1511e-16 - r2_keras: -75.0697 - rmse: 0.8376 - sae: 1821.9830 - sse: 2030.1351 - val_huber_loss: 0.1289 - val_loss: 0.2218 - val_mae: 0.3392 - val_mse: 0.2891 - val_pearson_correlation: -8.2977e-17 - val_r2_keras: -32.2560 - val_rmse: 0.9391 - val_sae: 360.1020 - val_sse: 466.5194 - learning_rate: 0.1000\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1875 - mae: 0.2978 - mse: 0.1973 - pearson_correlation: -4.6638e-16 - r2_keras: -87.2444 - rmse: 0.8175 - sae: 2445.5732 - sse: 2737.2295\n","Epoch 19: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0853 - loss: 0.1818 - mae: 0.2864 - mse: 0.1843 - pearson_correlation: -3.5121e-16 - r2_keras: -74.4472 - rmse: 0.8329 - sae: 1800.0271 - sse: 2019.7455 - val_huber_loss: 0.1312 - val_loss: 0.2239 - val_mae: 0.3463 - val_mse: 0.2899 - val_pearson_correlation: 2.6460e-16 - val_r2_keras: -33.8665 - val_rmse: 0.9616 - val_sae: 369.9734 - val_sse: 489.1109 - learning_rate: 0.1000\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0989 - loss: 0.1916 - mae: 0.2972 - mse: 0.2061 - pearson_correlation: -2.1320e-16 - r2_keras: -91.2911 - rmse: 0.8360 - sae: 2490.7344 - sse: 2862.7539\n","Epoch 20: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0869 - loss: 0.1843 - mae: 0.2852 - mse: 0.1898 - pearson_correlation: -2.3537e-16 - r2_keras: -76.5789 - rmse: 0.8403 - sae: 1827.0057 - sse: 2096.7876 - val_huber_loss: 0.1329 - val_loss: 0.2254 - val_mae: 0.3474 - val_mse: 0.2919 - val_pearson_correlation: 1.9206e-16 - val_r2_keras: -34.6772 - val_rmse: 0.9727 - val_sae: 375.0160 - val_sse: 500.4830 - learning_rate: 0.1000\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0960 - loss: 0.1885 - mae: 0.2922 - mse: 0.2000 - pearson_correlation: 2.0024e-16 - r2_keras: -93.4691 - rmse: 0.8458 - sae: 2516.7515 - sse: 2930.3145\n","Epoch 21: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0851 - loss: 0.1818 - mae: 0.2817 - mse: 0.1851 - pearson_correlation: 1.6733e-16 - r2_keras: -77.9198 - rmse: 0.8458 - sae: 1843.4473 - sse: 2140.5237 - val_huber_loss: 0.1351 - val_loss: 0.2274 - val_mae: 0.3508 - val_mse: 0.2947 - val_pearson_correlation: 3.4456e-16 - val_r2_keras: -36.0374 - val_rmse: 0.9910 - val_sae: 383.8597 - val_sse: 519.5641 - learning_rate: 0.1000\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0958 - loss: 0.1881 - mae: 0.2914 - mse: 0.1994 - pearson_correlation: 2.9211e-16 - r2_keras: -94.9696 - rmse: 0.8525 - sae: 2537.3757 - sse: 2976.8564\n","Epoch 22: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0837 - loss: 0.1807 - mae: 0.2799 - mse: 0.1830 - pearson_correlation: 1.2831e-16 - r2_keras: -78.7970 - rmse: 0.8492 - sae: 1856.2913 - sse: 2170.1086 - val_huber_loss: 0.1373 - val_loss: 0.2293 - val_mae: 0.3543 - val_mse: 0.2990 - val_pearson_correlation: -3.0174e-17 - val_r2_keras: -36.2533 - val_rmse: 0.9939 - val_sae: 385.2315 - val_sse: 522.5928 - learning_rate: 0.1000\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0902 - loss: 0.1823 - mae: 0.2837 - mse: 0.1877 - pearson_correlation: -3.5696e-16 - r2_keras: -95.4993 - rmse: 0.8549 - sae: 2547.6348 - sse: 2993.2869\n","Epoch 23: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1754 - mae: 0.2748 - mse: 0.1726 - pearson_correlation: -2.5485e-16 - r2_keras: -79.2889 - rmse: 0.8520 - sae: 1865.1964 - sse: 2182.6890 - val_huber_loss: 0.1364 - val_loss: 0.2285 - val_mae: 0.3505 - val_mse: 0.2982 - val_pearson_correlation: 1.1149e-16 - val_r2_keras: -36.0228 - val_rmse: 0.9908 - val_sae: 382.3482 - val_sse: 519.3602 - learning_rate: 0.0200\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0836 - loss: 0.1756 - mae: 0.2624 - mse: 0.1751 - pearson_correlation: 7.5783e-17 - r2_keras: -96.2587 - rmse: 0.8582 - sae: 2551.3418 - sse: 3016.8423\n","Epoch 24: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0727 - loss: 0.1690 - mae: 0.2542 - mse: 0.1603 - pearson_correlation: 1.2048e-16 - r2_keras: -79.5098 - rmse: 0.8517 - sae: 1865.4204 - sse: 2195.0464 - val_huber_loss: 0.1356 - val_loss: 0.2276 - val_mae: 0.3484 - val_mse: 0.2965 - val_pearson_correlation: -1.1207e-16 - val_r2_keras: -35.8797 - val_rmse: 0.9889 - val_sae: 380.7444 - val_sse: 517.3531 - learning_rate: 0.0200\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0829 - loss: 0.1749 - mae: 0.2602 - mse: 0.1741 - pearson_correlation: -1.6494e-16 - r2_keras: -96.7487 - rmse: 0.8604 - sae: 2551.7961 - sse: 3032.0437\n","Epoch 25: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0720 - loss: 0.1683 - mae: 0.2514 - mse: 0.1591 - pearson_correlation: -1.7637e-16 - r2_keras: -79.7829 - rmse: 0.8527 - sae: 1865.4220 - sse: 2204.5508 - val_huber_loss: 0.1354 - val_loss: 0.2274 - val_mae: 0.3477 - val_mse: 0.2960 - val_pearson_correlation: 2.0373e-17 - val_r2_keras: -35.8869 - val_rmse: 0.9890 - val_sae: 380.6089 - val_sse: 517.4533 - learning_rate: 0.0200\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0826 - loss: 0.1746 - mae: 0.2595 - mse: 0.1734 - pearson_correlation: 5.8115e-16 - r2_keras: -96.9565 - rmse: 0.8613 - sae: 2552.4072 - sse: 3038.4878\n","Epoch 26: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0716 - loss: 0.1679 - mae: 0.2504 - mse: 0.1584 - pearson_correlation: 3.5374e-16 - r2_keras: -79.9191 - rmse: 0.8533 - sae: 1865.8077 - sse: 2208.8208 - val_huber_loss: 0.1352 - val_loss: 0.2271 - val_mae: 0.3473 - val_mse: 0.2953 - val_pearson_correlation: 1.3236e-16 - val_r2_keras: -35.9016 - val_rmse: 0.9892 - val_sae: 380.5863 - val_sse: 517.6594 - learning_rate: 0.0200\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0822 - loss: 0.1741 - mae: 0.2587 - mse: 0.1726 - pearson_correlation: -4.9482e-16 - r2_keras: -96.9913 - rmse: 0.8614 - sae: 2551.5864 - sse: 3039.5681\n","Epoch 27: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0713 - loss: 0.1675 - mae: 0.2496 - mse: 0.1577 - pearson_correlation: -3.3565e-16 - r2_keras: -79.9619 - rmse: 0.8535 - sae: 1865.3423 - sse: 2209.7700 - val_huber_loss: 0.1350 - val_loss: 0.2269 - val_mae: 0.3473 - val_mse: 0.2948 - val_pearson_correlation: -1.5266e-16 - val_r2_keras: -35.9125 - val_rmse: 0.9894 - val_sae: 380.5056 - val_sse: 517.8126 - learning_rate: 0.0200\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0818 - loss: 0.1737 - mae: 0.2579 - mse: 0.1718 - pearson_correlation: 6.4423e-16 - r2_keras: -97.0713 - rmse: 0.8618 - sae: 2551.9419 - sse: 3042.0491\n","Epoch 28: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0708 - loss: 0.1670 - mae: 0.2483 - mse: 0.1567 - pearson_correlation: 4.5248e-16 - r2_keras: -80.0573 - rmse: 0.8541 - sae: 1865.9182 - sse: 2211.9180 - val_huber_loss: 0.1349 - val_loss: 0.2267 - val_mae: 0.3467 - val_mse: 0.2944 - val_pearson_correlation: -4.0723e-17 - val_r2_keras: -35.9036 - val_rmse: 0.9893 - val_sae: 380.4679 - val_sse: 517.6881 - learning_rate: 0.0040\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0817 - loss: 0.1736 - mae: 0.2576 - mse: 0.1715 - pearson_correlation: -1.2060e-16 - r2_keras: -97.0515 - rmse: 0.8617 - sae: 2551.7383 - sse: 3041.4338\n","Epoch 29: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0707 - loss: 0.1669 - mae: 0.2481 - mse: 0.1565 - pearson_correlation: -6.8903e-17 - r2_keras: -80.0445 - rmse: 0.8541 - sae: 1865.7759 - sse: 2211.5120 - val_huber_loss: 0.1347 - val_loss: 0.2266 - val_mae: 0.3464 - val_mse: 0.2941 - val_pearson_correlation: 2.4438e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4290 - val_sse: 517.6107 - learning_rate: 0.0040\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0816 - loss: 0.1735 - mae: 0.2574 - mse: 0.1713 - pearson_correlation: -5.1952e-16 - r2_keras: -97.0504 - rmse: 0.8617 - sae: 2551.7266 - sse: 3041.3994\n","Epoch 30: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0707 - loss: 0.1668 - mae: 0.2479 - mse: 0.1563 - pearson_correlation: -3.0038e-16 - r2_keras: -80.0469 - rmse: 0.8541 - sae: 1865.7760 - sse: 2211.5264 - val_huber_loss: 0.1346 - val_loss: 0.2264 - val_mae: 0.3460 - val_mse: 0.2938 - val_pearson_correlation: 2.0364e-16 - val_r2_keras: -35.9001 - val_rmse: 0.9892 - val_sae: 380.4438 - val_sse: 517.6391 - learning_rate: 0.0040\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0815 - loss: 0.1734 - mae: 0.2571 - mse: 0.1711 - pearson_correlation: -1.1724e-16 - r2_keras: -97.0391 - rmse: 0.8617 - sae: 2551.5330 - sse: 3041.0510\n","Epoch 31: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0706 - loss: 0.1667 - mae: 0.2477 - mse: 0.1562 - pearson_correlation: -5.1349e-17 - r2_keras: -80.0417 - rmse: 0.8541 - sae: 1865.6510 - sse: 2211.3213 - val_huber_loss: 0.1345 - val_loss: 0.2264 - val_mae: 0.3459 - val_mse: 0.2936 - val_pearson_correlation: -1.1198e-16 - val_r2_keras: -35.9057 - val_rmse: 0.9893 - val_sae: 380.4763 - val_sse: 517.7176 - learning_rate: 0.0040\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0815 - loss: 0.1733 - mae: 0.2569 - mse: 0.1709 - pearson_correlation: -1.4273e-16 - r2_keras: -97.0309 - rmse: 0.8616 - sae: 2551.3711 - sse: 3040.7952\n","Epoch 32: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0705 - loss: 0.1666 - mae: 0.2475 - mse: 0.1560 - pearson_correlation: -1.6217e-16 - r2_keras: -80.0379 - rmse: 0.8541 - sae: 1865.5449 - sse: 2211.1699 - val_huber_loss: 0.1345 - val_loss: 0.2263 - val_mae: 0.3458 - val_mse: 0.2935 - val_pearson_correlation: -1.5273e-16 - val_r2_keras: -35.9006 - val_rmse: 0.9892 - val_sae: 380.4423 - val_sse: 517.6461 - learning_rate: 0.0040\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0814 - loss: 0.1732 - mae: 0.2567 - mse: 0.1707 - pearson_correlation: 4.6836e-16 - r2_keras: -97.0366 - rmse: 0.8616 - sae: 2551.4805 - sse: 3040.9741\n","Epoch 33: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2472 - mse: 0.1558 - pearson_correlation: 3.3712e-16 - r2_keras: -80.0475 - rmse: 0.8542 - sae: 1865.6649 - sse: 2211.3577 - val_huber_loss: 0.1344 - val_loss: 0.2262 - val_mae: 0.3456 - val_mse: 0.2933 - val_pearson_correlation: -5.0911e-17 - val_r2_keras: -35.9002 - val_rmse: 0.9892 - val_sae: 380.4424 - val_sse: 517.6403 - learning_rate: 8.0000e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0814 - loss: 0.1732 - mae: 0.2566 - mse: 0.1707 - pearson_correlation: 5.3987e-16 - r2_keras: -97.0361 - rmse: 0.8616 - sae: 2551.4578 - sse: 3040.9568\n","Epoch 34: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2472 - mse: 0.1558 - pearson_correlation: 3.9723e-16 - r2_keras: -80.0478 - rmse: 0.8542 - sae: 1865.6520 - sse: 2211.3538 - val_huber_loss: 0.1343 - val_loss: 0.2262 - val_mae: 0.3455 - val_mse: 0.2932 - val_pearson_correlation: 4.0732e-17 - val_r2_keras: -35.8982 - val_rmse: 0.9892 - val_sae: 380.4276 - val_sse: 517.6123 - learning_rate: 8.0000e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1732 - mae: 0.2566 - mse: 0.1707 - pearson_correlation: 9.8767e-16 - r2_keras: -97.0362 - rmse: 0.8616 - sae: 2551.4482 - sse: 3040.9597\n","Epoch 35: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2471 - mse: 0.1557 - pearson_correlation: 6.2591e-16 - r2_keras: -80.0485 - rmse: 0.8542 - sae: 1865.6483 - sse: 2211.3635 - val_huber_loss: 0.1343 - val_loss: 0.2261 - val_mae: 0.3454 - val_mse: 0.2932 - val_pearson_correlation: 4.0732e-17 - val_r2_keras: -35.8984 - val_rmse: 0.9892 - val_sae: 380.4296 - val_sse: 517.6144 - learning_rate: 8.0000e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0813 - loss: 0.1732 - mae: 0.2566 - mse: 0.1706 - pearson_correlation: 1.3689e-16 - r2_keras: -97.0349 - rmse: 0.8616 - sae: 2551.4238 - sse: 3040.9207\n","Epoch 36: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2471 - mse: 0.1557 - pearson_correlation: 7.6906e-17 - r2_keras: -80.0480 - rmse: 0.8542 - sae: 1865.6329 - sse: 2211.3413 - val_huber_loss: 0.1343 - val_loss: 0.2261 - val_mae: 0.3453 - val_mse: 0.2931 - val_pearson_correlation: 5.0916e-17 - val_r2_keras: -35.8978 - val_rmse: 0.9892 - val_sae: 380.4254 - val_sse: 517.6057 - learning_rate: 8.0000e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2565 - mse: 0.1706 - pearson_correlation: -1.1859e-15 - r2_keras: -97.0376 - rmse: 0.8616 - sae: 2551.4573 - sse: 3041.0044\n","Epoch 37: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2471 - mse: 0.1557 - pearson_correlation: -7.6860e-16 - r2_keras: -80.0507 - rmse: 0.8542 - sae: 1865.6586 - sse: 2211.4077 - val_huber_loss: 0.1343 - val_loss: 0.2261 - val_mae: 0.3453 - val_mse: 0.2931 - val_pearson_correlation: -4.0732e-17 - val_r2_keras: -35.8984 - val_rmse: 0.9892 - val_sae: 380.4305 - val_sse: 517.6152 - learning_rate: 8.0000e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2565 - mse: 0.1706 - pearson_correlation: -2.7622e-16 - r2_keras: -97.0368 - rmse: 0.8616 - sae: 2551.4399 - sse: 3040.9805\n","Epoch 38: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -8.3696e-17 - r2_keras: -80.0511 - rmse: 0.8542 - sae: 1865.6548 - sse: 2211.4021 - val_huber_loss: 0.1343 - val_loss: 0.2261 - val_mae: 0.3453 - val_mse: 0.2930 - val_pearson_correlation: 4.0733e-17 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4286 - val_sse: 517.6102 - learning_rate: 1.6000e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2565 - mse: 0.1705 - pearson_correlation: 8.8084e-17 - r2_keras: -97.0374 - rmse: 0.8616 - sae: 2551.4463 - sse: 3040.9963\n","Epoch 39: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 6.2549e-17 - r2_keras: -80.0516 - rmse: 0.8542 - sae: 1865.6595 - sse: 2211.4143 - val_huber_loss: 0.1343 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 1.5275e-16 - val_r2_keras: -35.8978 - val_rmse: 0.9892 - val_sae: 380.4271 - val_sse: 517.6057 - learning_rate: 1.6000e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -5.6165e-17 - r2_keras: -97.0378 - rmse: 0.8616 - sae: 2551.4524 - sse: 3041.0107\n","Epoch 40: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0704 - loss: 0.1665 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.3024e-16 - r2_keras: -80.0520 - rmse: 0.8542 - sae: 1865.6642 - sse: 2211.4255 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -4.0733e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4291 - val_sse: 517.6093 - learning_rate: 1.6000e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -2.5197e-16 - r2_keras: -97.0376 - rmse: 0.8616 - sae: 2551.4475 - sse: 3041.0039\n","Epoch 41: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1665 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.9573e-16 - r2_keras: -80.0520 - rmse: 0.8542 - sae: 1865.6613 - sse: 2211.4221 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 9.1649e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4294 - val_sse: 517.6088 - learning_rate: 1.6000e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 9.3300e-17 - r2_keras: -97.0379 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0127\n","Epoch 42: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -2.5812e-17 - r2_keras: -80.0523 - rmse: 0.8542 - sae: 1865.6648 - sse: 2211.4292 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 1.5275e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4289 - val_sse: 517.6090 - learning_rate: 1.6000e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 1.2000e-16 - r2_keras: -97.0380 - rmse: 0.8616 - sae: 2551.4504 - sse: 3041.0156\n","Epoch 43: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 6.7565e-17 - r2_keras: -80.0526 - rmse: 0.8542 - sae: 1865.6655 - sse: 2211.4343 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 3.0550e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4294 - val_sse: 517.6091 - learning_rate: 3.2000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.1356e-16 - r2_keras: -97.0380 - rmse: 0.8616 - sae: 2551.4512 - sse: 3041.0173\n","Epoch 44: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -8.0487e-17 - r2_keras: -80.0527 - rmse: 0.8542 - sae: 1865.6660 - sse: 2211.4355 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -1.5275e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4297 - val_sse: 517.6093 - learning_rate: 3.2000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 3.3944e-16 - r2_keras: -97.0381 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0195\n","Epoch 45: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 2.1577e-16 - r2_keras: -80.0527 - rmse: 0.8542 - sae: 1865.6666 - sse: 2211.4373 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 1.0183e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4301 - val_sse: 517.6099 - learning_rate: 3.2000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.1908e-16 - r2_keras: -97.0381 - rmse: 0.8616 - sae: 2551.4526 - sse: 3041.0200\n","Epoch 46: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.3487e-16 - r2_keras: -80.0527 - rmse: 0.8542 - sae: 1865.6671 - sse: 2211.4377 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.1385e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4297 - val_sse: 517.6092 - learning_rate: 3.2000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 4.9013e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4526 - sse: 3041.0210\n","Epoch 47: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 2.6649e-16 - r2_keras: -80.0528 - rmse: 0.8542 - sae: 1865.6672 - sse: 2211.4387 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -6.1099e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6098 - learning_rate: 3.2000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 4.3397e-16 - r2_keras: -97.0381 - rmse: 0.8616 - sae: 2551.4517 - sse: 3041.0193\n","Epoch 48: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 3.2566e-16 - r2_keras: -80.0528 - rmse: 0.8542 - sae: 1865.6669 - sse: 2211.4380 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -4.8879e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6097 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -4.4686e-16 - r2_keras: -97.0381 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0205\n","Epoch 49: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -3.4765e-16 - r2_keras: -80.0528 - rmse: 0.8542 - sae: 1865.6671 - sse: 2211.4390 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -1.1202e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4299 - val_sse: 517.6094 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.2031e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4524 - sse: 3041.0215\n","Epoch 50: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -6.6812e-17 - r2_keras: -80.0528 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4397 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 1.2220e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6096 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -3.9438e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4526 - sse: 3041.0215\n","Epoch 51: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.8447e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6676 - sse: 2211.4397 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.0366e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4301 - val_sse: 517.6098 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 7.8630e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4526 - sse: 3041.0220\n","Epoch 52: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 5.4429e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6676 - sse: 2211.4402 - val_huber_loss: 0.1342 - val_loss: 0.2261 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -6.1099e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6097 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -9.1765e-17 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0217\n","Epoch 53: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -7.8396e-17 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4399 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -9.1649e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6097 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 2.9770e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0220\n","Epoch 54: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 1.4585e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4402 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -6.1099e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6097 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.6420e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0215\n","Epoch 55: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.2668e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4399 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 2.3421e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4300 - val_sse: 517.6097 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -3.5417e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4526 - sse: 3041.0222\n","Epoch 56: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.7489e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6677 - sse: 2211.4407 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 1.2220e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4301 - val_sse: 517.6098 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.3688e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0222\n","Epoch 57: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -4.0553e-17 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4407 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 2.9531e-16 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4301 - val_sse: 517.6098 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 2.9310e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4526 - sse: 3041.0229\n","Epoch 58: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 2.8341e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6677 - sse: 2211.4412 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -4.0733e-17 - val_r2_keras: -35.8980 - val_rmse: 0.9892 - val_sae: 380.4301 - val_sse: 517.6098 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.9090e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0225\n","Epoch 59: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.4353e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4409 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 5.0916e-17 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4301 - val_sse: 517.6099 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -6.1289e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0225\n","Epoch 60: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -3.7894e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6675 - sse: 2211.4412 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.6476e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4303 - val_sse: 517.6102 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 2.0808e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4524 - sse: 3041.0227\n","Epoch 61: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 1.4446e-16 - r2_keras: -80.0529 - rmse: 0.8542 - sae: 1865.6676 - sse: 2211.4414 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.2403e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4302 - val_sse: 517.6101 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -1.8813e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0229\n","Epoch 62: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.3595e-16 - r2_keras: -80.0530 - rmse: 0.8542 - sae: 1865.6675 - sse: 2211.4417 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.0366e-17 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4302 - val_sse: 517.6100 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 3.9376e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4524 - sse: 3041.0234\n","Epoch 63: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 2.7686e-16 - r2_keras: -80.0530 - rmse: 0.8542 - sae: 1865.6677 - sse: 2211.4419 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 1.3238e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4303 - val_sse: 517.6104 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 3.2225e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0232\n","Epoch 64: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 2.9424e-16 - r2_keras: -80.0530 - rmse: 0.8542 - sae: 1865.6676 - sse: 2211.4419 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.3421e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4302 - val_sse: 517.6101 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: 8.1637e-17 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0229\n","Epoch 65: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: 1.3669e-16 - r2_keras: -80.0530 - rmse: 0.8542 - sae: 1865.6676 - sse: 2211.4419 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -1.6293e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4303 - val_sse: 517.6104 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -2.7376e-16 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4521 - sse: 3041.0234\n","Epoch 66: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -1.5764e-16 - r2_keras: -80.0530 - rmse: 0.8542 - sae: 1865.6676 - sse: 2211.4421 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: 7.1282e-17 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4303 - val_sse: 517.6104 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0813 - loss: 0.1731 - mae: 0.2564 - mse: 0.1705 - pearson_correlation: -3.6829e-17 - r2_keras: -97.0382 - rmse: 0.8616 - sae: 2551.4517 - sse: 3041.0234\n","Epoch 67: val_loss did not improve from 0.21901\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0703 - loss: 0.1664 - mae: 0.2470 - mse: 0.1556 - pearson_correlation: -2.1683e-17 - r2_keras: -80.0530 - rmse: 0.8542 - sae: 1865.6674 - sse: 2211.4424 - val_huber_loss: 0.1342 - val_loss: 0.2260 - val_mae: 0.3452 - val_mse: 0.2930 - val_pearson_correlation: -2.6476e-16 - val_r2_keras: -35.8981 - val_rmse: 0.9892 - val_sae: 380.4302 - val_sse: 517.6104 - learning_rate: 1.0000e-05\n","| \u001b[39m17       \u001b[39m | \u001b[39m-0.226   \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m95.44    \u001b[39m | \u001b[39m75.36    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.7383 - loss: 0.7624 - mae: 1.1148 - mse: 2.5884 - pearson_correlation: 3.4298e-16 - r2_keras: -429.2280 - rmse: 1.8050 - sae: 5584.8940 - sse: 13345.1357\n","Epoch 1: val_loss improved from inf to 0.19408, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 468ms/step - huber_loss: 0.7092 - loss: 0.7448 - mae: 1.1073 - mse: 2.4075 - pearson_correlation: 2.4160e-16 - r2_keras: -319.3269 - rmse: 1.6121 - sae: 3974.6895 - sse: 9289.8105 - val_huber_loss: 0.1694 - val_loss: 0.1941 - val_mae: 0.4349 - val_mse: 0.4048 - val_pearson_correlation: -1.0784e-16 - val_r2_keras: -25.1896 - val_rmse: 0.8334 - val_sae: 320.6740 - val_sse: 367.3901 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.4667 - loss: 0.4914 - mae: 0.8111 - mse: 1.2282 - pearson_correlation: 1.7448e-16 - r2_keras: -223.4874 - rmse: 1.3039 - sae: 4009.0979 - sse: 6963.3193\n","Epoch 2: val_loss did not improve from 0.19408\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3855 - loss: 0.4420 - mae: 0.7544 - mse: 1.0812 - pearson_correlation: 1.8086e-16 - r2_keras: -173.0812 - rmse: 1.2182 - sae: 2868.5752 - sse: 4928.6948 - val_huber_loss: 0.3039 - val_loss: 0.3287 - val_mae: 0.6387 - val_mse: 0.7883 - val_pearson_correlation: 1.8401e-16 - val_r2_keras: -28.1649 - val_rmse: 0.8794 - val_sae: 323.1350 - val_sse: 409.1281 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2401 - loss: 0.2649 - mae: 0.5549 - mse: 0.5648 - pearson_correlation: -4.4323e-16 - r2_keras: -73.6168 - rmse: 0.7517 - sae: 2376.6567 - sse: 2314.5195\n","Epoch 3: val_loss did not improve from 0.19408\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1945 - loss: 0.2372 - mae: 0.5011 - mse: 0.4940 - pearson_correlation: 7.4971e-18 - r2_keras: -65.8143 - rmse: 0.7929 - sae: 1749.3761 - sse: 1743.2426 - val_huber_loss: 0.2641 - val_loss: 0.2889 - val_mae: 0.5843 - val_mse: 0.6731 - val_pearson_correlation: 1.9008e-17 - val_r2_keras: -28.5647 - val_rmse: 0.8854 - val_sae: 317.0995 - val_sse: 414.7375 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1659 - loss: 0.1907 - mae: 0.4369 - mse: 0.3735 - pearson_correlation: -6.5463e-16 - r2_keras: -76.2203 - rmse: 0.7647 - sae: 2334.5645 - sse: 2395.2769\n","Epoch 4: val_loss did not improve from 0.19408\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1432 - loss: 0.1769 - mae: 0.4157 - mse: 0.3377 - pearson_correlation: -4.4944e-16 - r2_keras: -66.6736 - rmse: 0.7940 - sae: 1721.8126 - sse: 1786.8005 - val_huber_loss: 0.2623 - val_loss: 0.2871 - val_mae: 0.5810 - val_mse: 0.6540 - val_pearson_correlation: -1.5332e-16 - val_r2_keras: -31.6360 - val_rmse: 0.9303 - val_sae: 339.2294 - val_sse: 457.8217 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1555 - loss: 0.1802 - mae: 0.4049 - mse: 0.3482 - pearson_correlation: -2.3742e-16 - r2_keras: -94.4403 - rmse: 0.8502 - sae: 2514.4790 - sse: 2960.4373\n","Epoch 5: val_loss did not improve from 0.19408\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1350 - loss: 0.1678 - mae: 0.3917 - mse: 0.3160 - pearson_correlation: -2.1466e-16 - r2_keras: -78.1953 - rmse: 0.8454 - sae: 1841.0487 - sse: 2156.2439 - val_huber_loss: 0.2354 - val_loss: 0.2601 - val_mae: 0.5427 - val_mse: 0.5782 - val_pearson_correlation: -1.4393e-16 - val_r2_keras: -32.2182 - val_rmse: 0.9386 - val_sae: 346.2395 - val_sse: 465.9885 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1390 - loss: 0.1637 - mae: 0.3751 - mse: 0.3105 - pearson_correlation: -3.5297e-16 - r2_keras: -92.4144 - rmse: 0.8411 - sae: 2495.8726 - sse: 2897.5972\n","Epoch 6: val_loss did not improve from 0.19408\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1201 - loss: 0.1522 - mae: 0.3589 - mse: 0.2814 - pearson_correlation: -3.4834e-16 - r2_keras: -76.7109 - rmse: 0.8382 - sae: 1827.1143 - sse: 2112.7800 - val_huber_loss: 0.1962 - val_loss: 0.2208 - val_mae: 0.4926 - val_mse: 0.4783 - val_pearson_correlation: 2.8036e-16 - val_r2_keras: -31.1308 - val_rmse: 0.9231 - val_sae: 342.6552 - val_sse: 450.7350 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1236 - loss: 0.1482 - mae: 0.3447 - mse: 0.2796 - pearson_correlation: -2.3896e-17 - r2_keras: -86.0484 - rmse: 0.8119 - sae: 2437.1997 - sse: 2700.1323\n","Epoch 7: val_loss improved from 0.19408 to 0.19371, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.1072 - loss: 0.1383 - mae: 0.3279 - mse: 0.2537 - pearson_correlation: -2.4781e-17 - r2_keras: -72.3890 - rmse: 0.8180 - sae: 1787.1371 - sse: 1980.2230 - val_huber_loss: 0.1691 - val_loss: 0.1937 - val_mae: 0.4470 - val_mse: 0.4059 - val_pearson_correlation: 1.4982e-16 - val_r2_keras: -30.8699 - val_rmse: 0.9193 - val_sae: 343.0442 - val_sse: 447.0743 - learning_rate: 0.0200\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1203 - loss: 0.1449 - mae: 0.3364 - mse: 0.2749 - pearson_correlation: 6.4561e-16 - r2_keras: -85.2708 - rmse: 0.8083 - sae: 2424.3630 - sse: 2676.0127\n","Epoch 8: val_loss improved from 0.19371 to 0.17716, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.1046 - loss: 0.1354 - mae: 0.3197 - mse: 0.2494 - pearson_correlation: 5.4098e-16 - r2_keras: -71.7794 - rmse: 0.8148 - sae: 1778.2006 - sse: 1963.0732 - val_huber_loss: 0.1525 - val_loss: 0.1772 - val_mae: 0.4132 - val_mse: 0.3606 - val_pearson_correlation: 7.8611e-17 - val_r2_keras: -31.0108 - val_rmse: 0.9213 - val_sae: 345.9219 - val_sse: 449.0516 - learning_rate: 0.0200\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1184 - loss: 0.1430 - mae: 0.3328 - mse: 0.2720 - pearson_correlation: -2.3009e-16 - r2_keras: -85.1621 - rmse: 0.8078 - sae: 2419.2249 - sse: 2672.6411\n","Epoch 9: val_loss improved from 0.17716 to 0.16707, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.1031 - loss: 0.1337 - mae: 0.3160 - mse: 0.2468 - pearson_correlation: -1.8462e-16 - r2_keras: -71.7199 - rmse: 0.8146 - sae: 1774.8168 - sse: 1960.9781 - val_huber_loss: 0.1424 - val_loss: 0.1671 - val_mae: 0.3879 - val_mse: 0.3319 - val_pearson_correlation: 1.1398e-16 - val_r2_keras: -31.3174 - val_rmse: 0.9257 - val_sae: 350.0055 - val_sse: 453.3523 - learning_rate: 0.0200\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1170 - loss: 0.1416 - mae: 0.3298 - mse: 0.2694 - pearson_correlation: 8.2590e-16 - r2_keras: -85.2624 - rmse: 0.8082 - sae: 2417.1677 - sse: 2675.7515\n","Epoch 10: val_loss improved from 0.16707 to 0.16212, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.1021 - loss: 0.1325 - mae: 0.3131 - mse: 0.2445 - pearson_correlation: 5.7730e-16 - r2_keras: -71.8206 - rmse: 0.8152 - sae: 1773.6046 - sse: 1963.4481 - val_huber_loss: 0.1375 - val_loss: 0.1621 - val_mae: 0.3728 - val_mse: 0.3165 - val_pearson_correlation: -5.0543e-16 - val_r2_keras: -31.6597 - val_rmse: 0.9306 - val_sae: 354.2184 - val_sse: 458.1537 - learning_rate: 0.0200\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1158 - loss: 0.1404 - mae: 0.3269 - mse: 0.2670 - pearson_correlation: -1.8970e-16 - r2_keras: -85.4333 - rmse: 0.8090 - sae: 2416.9377 - sse: 2681.0518\n","Epoch 11: val_loss improved from 0.16212 to 0.15935, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1012 - loss: 0.1315 - mae: 0.3104 - mse: 0.2425 - pearson_correlation: -1.0971e-16 - r2_keras: -71.9766 - rmse: 0.8161 - sae: 1773.6544 - sse: 1967.4757 - val_huber_loss: 0.1347 - val_loss: 0.1593 - val_mae: 0.3622 - val_mse: 0.3072 - val_pearson_correlation: 3.3822e-16 - val_r2_keras: -31.9713 - val_rmse: 0.9351 - val_sae: 357.8462 - val_sse: 462.5254 - learning_rate: 0.0200\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1148 - loss: 0.1394 - mae: 0.3243 - mse: 0.2646 - pearson_correlation: -9.4155e-18 - r2_keras: -85.5821 - rmse: 0.8097 - sae: 2417.2593 - sse: 2685.6682\n","Epoch 12: val_loss improved from 0.15935 to 0.15781, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1003 - loss: 0.1306 - mae: 0.3079 - mse: 0.2404 - pearson_correlation: -1.4134e-17 - r2_keras: -72.1213 - rmse: 0.8170 - sae: 1774.1237 - sse: 1971.0875 - val_huber_loss: 0.1332 - val_loss: 0.1578 - val_mae: 0.3546 - val_mse: 0.3017 - val_pearson_correlation: 2.7367e-16 - val_r2_keras: -32.2296 - val_rmse: 0.9387 - val_sae: 360.6884 - val_sse: 466.1480 - learning_rate: 0.0200\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1138 - loss: 0.1384 - mae: 0.3221 - mse: 0.2622 - pearson_correlation: 6.9681e-16 - r2_keras: -85.7233 - rmse: 0.8104 - sae: 2418.1216 - sse: 2690.0491\n","Epoch 13: val_loss improved from 0.15781 to 0.15687, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0995 - loss: 0.1297 - mae: 0.3059 - mse: 0.2383 - pearson_correlation: 3.8779e-16 - r2_keras: -72.2716 - rmse: 0.8179 - sae: 1775.0585 - sse: 1974.6663 - val_huber_loss: 0.1323 - val_loss: 0.1569 - val_mae: 0.3499 - val_mse: 0.2981 - val_pearson_correlation: -2.4701e-16 - val_r2_keras: -32.4448 - val_rmse: 0.9418 - val_sae: 362.8837 - val_sse: 469.1671 - learning_rate: 0.0200\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1129 - loss: 0.1375 - mae: 0.3200 - mse: 0.2598 - pearson_correlation: -2.3993e-16 - r2_keras: -85.8598 - rmse: 0.8110 - sae: 2419.2686 - sse: 2694.2815\n","Epoch 14: val_loss improved from 0.15687 to 0.15624, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0988 - loss: 0.1289 - mae: 0.3041 - mse: 0.2362 - pearson_correlation: -1.7455e-16 - r2_keras: -72.4190 - rmse: 0.8188 - sae: 1776.2062 - sse: 1978.1492 - val_huber_loss: 0.1317 - val_loss: 0.1562 - val_mae: 0.3479 - val_mse: 0.2957 - val_pearson_correlation: -5.2460e-16 - val_r2_keras: -32.6217 - val_rmse: 0.9442 - val_sae: 364.5477 - val_sse: 471.6493 - learning_rate: 0.0200\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1121 - loss: 0.1366 - mae: 0.3179 - mse: 0.2576 - pearson_correlation: -2.2797e-16 - r2_keras: -86.0075 - rmse: 0.8117 - sae: 2420.7649 - sse: 2698.8652\n","Epoch 15: val_loss improved from 0.15624 to 0.15545, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0980 - loss: 0.1281 - mae: 0.3024 - mse: 0.2342 - pearson_correlation: -9.5724e-17 - r2_keras: -72.5610 - rmse: 0.8197 - sae: 1777.5311 - sse: 1981.7159 - val_huber_loss: 0.1309 - val_loss: 0.1555 - val_mae: 0.3456 - val_mse: 0.2933 - val_pearson_correlation: -1.1568e-17 - val_r2_keras: -32.7822 - val_rmse: 0.9465 - val_sae: 365.7940 - val_sse: 473.9002 - learning_rate: 0.0200\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1112 - loss: 0.1357 - mae: 0.3156 - mse: 0.2553 - pearson_correlation: 8.6721e-16 - r2_keras: -86.2391 - rmse: 0.8128 - sae: 2423.3774 - sse: 2706.0474\n","Epoch 16: val_loss improved from 0.15545 to 0.15534, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0973 - loss: 0.1273 - mae: 0.3005 - mse: 0.2321 - pearson_correlation: 6.1579e-16 - r2_keras: -72.7752 - rmse: 0.8209 - sae: 1779.6964 - sse: 1987.2052 - val_huber_loss: 0.1308 - val_loss: 0.1553 - val_mae: 0.3442 - val_mse: 0.2927 - val_pearson_correlation: -4.2522e-16 - val_r2_keras: -32.9204 - val_rmse: 0.9484 - val_sae: 366.9152 - val_sse: 475.8393 - learning_rate: 0.0200\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1104 - loss: 0.1350 - mae: 0.3138 - mse: 0.2531 - pearson_correlation: 5.0843e-16 - r2_keras: -86.4247 - rmse: 0.8137 - sae: 2425.9707 - sse: 2711.8037\n","Epoch 17: val_loss improved from 0.15534 to 0.15522, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - huber_loss: 0.0966 - loss: 0.1266 - mae: 0.2990 - mse: 0.2302 - pearson_correlation: 3.7936e-16 - r2_keras: -72.9381 - rmse: 0.8219 - sae: 1781.7308 - sse: 1991.5023 - val_huber_loss: 0.1307 - val_loss: 0.1552 - val_mae: 0.3435 - val_mse: 0.2922 - val_pearson_correlation: -4.5735e-17 - val_r2_keras: -33.0305 - val_rmse: 0.9500 - val_sae: 367.7717 - val_sse: 477.3829 - learning_rate: 0.0200\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1097 - loss: 0.1343 - mae: 0.3121 - mse: 0.2512 - pearson_correlation: -6.4861e-17 - r2_keras: -86.5823 - rmse: 0.8144 - sae: 2428.2207 - sse: 2716.6946\n","Epoch 18: val_loss improved from 0.15522 to 0.15476, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0960 - loss: 0.1259 - mae: 0.2975 - mse: 0.2284 - pearson_correlation: -4.8388e-18 - r2_keras: -73.0713 - rmse: 0.8226 - sae: 1783.4597 - sse: 1995.0930 - val_huber_loss: 0.1302 - val_loss: 0.1548 - val_mae: 0.3424 - val_mse: 0.2910 - val_pearson_correlation: -3.1895e-16 - val_r2_keras: -33.1114 - val_rmse: 0.9511 - val_sae: 368.3748 - val_sse: 478.5184 - learning_rate: 0.0200\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1091 - loss: 0.1336 - mae: 0.3106 - mse: 0.2493 - pearson_correlation: -3.6774e-16 - r2_keras: -86.7304 - rmse: 0.8151 - sae: 2430.2812 - sse: 2721.2881\n","Epoch 19: val_loss did not improve from 0.15476\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0954 - loss: 0.1253 - mae: 0.2962 - mse: 0.2267 - pearson_correlation: -2.5378e-16 - r2_keras: -73.2028 - rmse: 0.8234 - sae: 1785.0916 - sse: 1998.5391 - val_huber_loss: 0.1304 - val_loss: 0.1549 - val_mae: 0.3420 - val_mse: 0.2912 - val_pearson_correlation: -2.2680e-16 - val_r2_keras: -33.2105 - val_rmse: 0.9525 - val_sae: 369.1505 - val_sse: 479.9087 - learning_rate: 0.0200\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1085 - loss: 0.1330 - mae: 0.3093 - mse: 0.2475 - pearson_correlation: 2.0976e-16 - r2_keras: -86.9000 - rmse: 0.8159 - sae: 2432.5032 - sse: 2726.5491\n","Epoch 20: val_loss improved from 0.15476 to 0.15457, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0949 - loss: 0.1247 - mae: 0.2951 - mse: 0.2251 - pearson_correlation: 1.9139e-16 - r2_keras: -73.3545 - rmse: 0.8242 - sae: 1786.8325 - sse: 2002.4998 - val_huber_loss: 0.1301 - val_loss: 0.1546 - val_mae: 0.3414 - val_mse: 0.2904 - val_pearson_correlation: 1.3565e-16 - val_r2_keras: -33.2803 - val_rmse: 0.9534 - val_sae: 369.6505 - val_sse: 480.8878 - learning_rate: 0.0200\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1078 - loss: 0.1323 - mae: 0.3080 - mse: 0.2457 - pearson_correlation: 7.6020e-16 - r2_keras: -87.0465 - rmse: 0.8166 - sae: 2434.3296 - sse: 2731.0918\n","Epoch 21: val_loss did not improve from 0.15457\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0943 - loss: 0.1241 - mae: 0.2941 - mse: 0.2235 - pearson_correlation: 3.9815e-16 - r2_keras: -73.4728 - rmse: 0.8249 - sae: 1788.2167 - sse: 2005.7711 - val_huber_loss: 0.1302 - val_loss: 0.1547 - val_mae: 0.3420 - val_mse: 0.2907 - val_pearson_correlation: 7.5551e-16 - val_r2_keras: -33.3350 - val_rmse: 0.9542 - val_sae: 370.1868 - val_sse: 481.6547 - learning_rate: 0.0200\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1073 - loss: 0.1318 - mae: 0.3071 - mse: 0.2441 - pearson_correlation: 8.8901e-17 - r2_keras: -87.1266 - rmse: 0.8169 - sae: 2435.4419 - sse: 2733.5779\n","Epoch 22: val_loss did not improve from 0.15457\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0938 - loss: 0.1236 - mae: 0.2933 - mse: 0.2220 - pearson_correlation: 3.9278e-17 - r2_keras: -73.5415 - rmse: 0.8252 - sae: 1789.0751 - sse: 2007.6074 - val_huber_loss: 0.1303 - val_loss: 0.1547 - val_mae: 0.3423 - val_mse: 0.2909 - val_pearson_correlation: -6.9804e-16 - val_r2_keras: -33.3700 - val_rmse: 0.9547 - val_sae: 370.5244 - val_sse: 482.1459 - learning_rate: 0.0200\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1067 - loss: 0.1312 - mae: 0.3061 - mse: 0.2426 - pearson_correlation: -9.9344e-17 - r2_keras: -87.1864 - rmse: 0.8172 - sae: 2436.1099 - sse: 2735.4319\n","Epoch 23: val_loss improved from 0.15457 to 0.15440, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0933 - loss: 0.1230 - mae: 0.2924 - mse: 0.2207 - pearson_correlation: -1.7185e-16 - r2_keras: -73.5852 - rmse: 0.8255 - sae: 1789.5623 - sse: 2008.8888 - val_huber_loss: 0.1299 - val_loss: 0.1544 - val_mae: 0.3420 - val_mse: 0.2902 - val_pearson_correlation: -1.3503e-16 - val_r2_keras: -33.3819 - val_rmse: 0.9549 - val_sae: 370.6512 - val_sse: 482.3128 - learning_rate: 0.0200\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1062 - loss: 0.1307 - mae: 0.3051 - mse: 0.2412 - pearson_correlation: 4.2383e-16 - r2_keras: -87.2408 - rmse: 0.8175 - sae: 2436.5396 - sse: 2737.1199\n","Epoch 24: val_loss did not improve from 0.15440\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0929 - loss: 0.1225 - mae: 0.2915 - mse: 0.2194 - pearson_correlation: 2.4070e-16 - r2_keras: -73.6255 - rmse: 0.8257 - sae: 1789.9021 - sse: 2010.0607 - val_huber_loss: 0.1303 - val_loss: 0.1547 - val_mae: 0.3426 - val_mse: 0.2912 - val_pearson_correlation: 1.0117e-16 - val_r2_keras: -33.4053 - val_rmse: 0.9552 - val_sae: 370.9433 - val_sse: 482.6406 - learning_rate: 0.0200\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1057 - loss: 0.1302 - mae: 0.3042 - mse: 0.2398 - pearson_correlation: -4.3648e-16 - r2_keras: -87.3302 - rmse: 0.8179 - sae: 2437.7305 - sse: 2739.8921\n","Epoch 25: val_loss improved from 0.15440 to 0.15439, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0925 - loss: 0.1221 - mae: 0.2908 - mse: 0.2182 - pearson_correlation: -2.5770e-16 - r2_keras: -73.6871 - rmse: 0.8260 - sae: 1790.7328 - sse: 2011.9332 - val_huber_loss: 0.1300 - val_loss: 0.1544 - val_mae: 0.3425 - val_mse: 0.2906 - val_pearson_correlation: 2.8110e-16 - val_r2_keras: -33.3984 - val_rmse: 0.9551 - val_sae: 370.9323 - val_sse: 482.5440 - learning_rate: 0.0200\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1052 - loss: 0.1297 - mae: 0.3030 - mse: 0.2384 - pearson_correlation: 1.9376e-16 - r2_keras: -87.4196 - rmse: 0.8183 - sae: 2438.4795 - sse: 2742.6655\n","Epoch 26: val_loss did not improve from 0.15439\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0921 - loss: 0.1217 - mae: 0.2899 - mse: 0.2170 - pearson_correlation: 9.6879e-17 - r2_keras: -73.7641 - rmse: 0.8264 - sae: 1791.3889 - sse: 2013.9862 - val_huber_loss: 0.1300 - val_loss: 0.1544 - val_mae: 0.3433 - val_mse: 0.2909 - val_pearson_correlation: -2.1343e-16 - val_r2_keras: -33.4200 - val_rmse: 0.9554 - val_sae: 371.1380 - val_sse: 482.8479 - learning_rate: 0.0200\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1047 - loss: 0.1291 - mae: 0.3018 - mse: 0.2370 - pearson_correlation: -7.2194e-18 - r2_keras: -87.5809 - rmse: 0.8190 - sae: 2440.0718 - sse: 2747.6677\n","Epoch 27: val_loss did not improve from 0.15439\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0917 - loss: 0.1212 - mae: 0.2889 - mse: 0.2159 - pearson_correlation: 9.4284e-18 - r2_keras: -73.8753 - rmse: 0.8269 - sae: 1792.5087 - sse: 2017.3641 - val_huber_loss: 0.1300 - val_loss: 0.1544 - val_mae: 0.3436 - val_mse: 0.2911 - val_pearson_correlation: -7.8580e-17 - val_r2_keras: -33.4347 - val_rmse: 0.9556 - val_sae: 371.3286 - val_sse: 483.0543 - learning_rate: 0.0200\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1042 - loss: 0.1286 - mae: 0.3007 - mse: 0.2357 - pearson_correlation: 1.3357e-16 - r2_keras: -87.7105 - rmse: 0.8196 - sae: 2441.4304 - sse: 2751.6880\n","Epoch 28: val_loss did not improve from 0.15439\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0913 - loss: 0.1207 - mae: 0.2880 - mse: 0.2147 - pearson_correlation: 9.2584e-18 - r2_keras: -73.9556 - rmse: 0.8273 - sae: 1793.4014 - sse: 2019.9727 - val_huber_loss: 0.1301 - val_loss: 0.1545 - val_mae: 0.3440 - val_mse: 0.2915 - val_pearson_correlation: 6.1685e-16 - val_r2_keras: -33.4553 - val_rmse: 0.9559 - val_sae: 371.5493 - val_sse: 483.3421 - learning_rate: 0.0200\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1037 - loss: 0.1281 - mae: 0.2995 - mse: 0.2343 - pearson_correlation: 5.0271e-18 - r2_keras: -87.8409 - rmse: 0.8202 - sae: 2442.7703 - sse: 2755.7339\n","Epoch 29: val_loss improved from 0.15439 to 0.15431, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0906 - loss: 0.1201 - mae: 0.2864 - mse: 0.2131 - pearson_correlation: 5.2769e-18 - r2_keras: -73.8620 - rmse: 0.8261 - sae: 1793.5632 - sse: 2020.5514 - val_huber_loss: 0.1299 - val_loss: 0.1543 - val_mae: 0.3436 - val_mse: 0.2907 - val_pearson_correlation: -2.2389e-17 - val_r2_keras: -33.4972 - val_rmse: 0.9565 - val_sae: 371.9901 - val_sse: 483.9307 - learning_rate: 0.0040\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1036 - loss: 0.1280 - mae: 0.2991 - mse: 0.2339 - pearson_correlation: -3.6784e-16 - r2_keras: -87.9187 - rmse: 0.8206 - sae: 2443.4707 - sse: 2758.1460\n","Epoch 30: val_loss improved from 0.15431 to 0.15417, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0905 - loss: 0.1200 - mae: 0.2861 - mse: 0.2128 - pearson_correlation: -2.0868e-16 - r2_keras: -73.9274 - rmse: 0.8264 - sae: 1794.1012 - sse: 2022.3185 - val_huber_loss: 0.1298 - val_loss: 0.1542 - val_mae: 0.3434 - val_mse: 0.2901 - val_pearson_correlation: -8.9417e-17 - val_r2_keras: -33.5322 - val_rmse: 0.9569 - val_sae: 372.3200 - val_sse: 484.4212 - learning_rate: 0.0040\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1035 - loss: 0.1278 - mae: 0.2987 - mse: 0.2336 - pearson_correlation: -4.1744e-16 - r2_keras: -87.9895 - rmse: 0.8209 - sae: 2444.1086 - sse: 2760.3428\n","Epoch 31: val_loss improved from 0.15417 to 0.15408, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0904 - loss: 0.1199 - mae: 0.2858 - mse: 0.2125 - pearson_correlation: -2.8502e-16 - r2_keras: -73.9863 - rmse: 0.8267 - sae: 1794.5879 - sse: 2023.9203 - val_huber_loss: 0.1297 - val_loss: 0.1541 - val_mae: 0.3433 - val_mse: 0.2898 - val_pearson_correlation: -6.6975e-16 - val_r2_keras: -33.5619 - val_rmse: 0.9574 - val_sae: 372.5742 - val_sse: 484.8386 - learning_rate: 0.0040\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1033 - loss: 0.1277 - mae: 0.2983 - mse: 0.2332 - pearson_correlation: 5.0163e-16 - r2_keras: -88.0548 - rmse: 0.8212 - sae: 2444.7002 - sse: 2762.3696\n","Epoch 32: val_loss improved from 0.15408 to 0.15402, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0903 - loss: 0.1198 - mae: 0.2855 - mse: 0.2122 - pearson_correlation: 4.1700e-16 - r2_keras: -74.0382 - rmse: 0.8270 - sae: 1795.0259 - sse: 2025.3696 - val_huber_loss: 0.1296 - val_loss: 0.1540 - val_mae: 0.3432 - val_mse: 0.2896 - val_pearson_correlation: 2.4533e-16 - val_r2_keras: -33.5848 - val_rmse: 0.9577 - val_sae: 372.7633 - val_sse: 485.1590 - learning_rate: 0.0040\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1032 - loss: 0.1276 - mae: 0.2979 - mse: 0.2329 - pearson_correlation: 1.3307e-15 - r2_keras: -88.1124 - rmse: 0.8215 - sae: 2445.2280 - sse: 2764.1558\n","Epoch 33: val_loss improved from 0.15402 to 0.15392, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0902 - loss: 0.1197 - mae: 0.2853 - mse: 0.2119 - pearson_correlation: 9.1013e-16 - r2_keras: -74.0872 - rmse: 0.8273 - sae: 1795.4380 - sse: 2026.6847 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3431 - val_mse: 0.2892 - val_pearson_correlation: -1.1142e-17 - val_r2_keras: -33.6038 - val_rmse: 0.9579 - val_sae: 372.8792 - val_sse: 485.4262 - learning_rate: 0.0040\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1031 - loss: 0.1274 - mae: 0.2976 - mse: 0.2325 - pearson_correlation: 1.1202e-16 - r2_keras: -88.1656 - rmse: 0.8217 - sae: 2445.7051 - sse: 2765.8042\n","Epoch 34: val_loss improved from 0.15392 to 0.15388, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0901 - loss: 0.1195 - mae: 0.2850 - mse: 0.2116 - pearson_correlation: 2.2897e-17 - r2_keras: -74.1293 - rmse: 0.8275 - sae: 1795.7903 - sse: 2027.8615 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3428 - val_mse: 0.2891 - val_pearson_correlation: 5.1239e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 372.9689 - val_sse: 485.5277 - learning_rate: 0.0040\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1030 - loss: 0.1273 - mae: 0.2974 - mse: 0.2322 - pearson_correlation: -5.4216e-16 - r2_keras: -88.1749 - rmse: 0.8218 - sae: 2445.7710 - sse: 2766.0928\n","Epoch 35: val_loss improved from 0.15388 to 0.15386, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0900 - loss: 0.1195 - mae: 0.2848 - mse: 0.2114 - pearson_correlation: -3.9981e-16 - r2_keras: -74.1324 - rmse: 0.8275 - sae: 1795.8064 - sse: 2028.0177 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3426 - val_mse: 0.2890 - val_pearson_correlation: -2.2274e-17 - val_r2_keras: -33.6153 - val_rmse: 0.9581 - val_sae: 373.0229 - val_sse: 485.5865 - learning_rate: 0.0040\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1029 - loss: 0.1272 - mae: 0.2972 - mse: 0.2320 - pearson_correlation: 1.0128e-16 - r2_keras: -88.1862 - rmse: 0.8218 - sae: 2445.8457 - sse: 2766.4453\n","Epoch 36: val_loss improved from 0.15386 to 0.15381, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0899 - loss: 0.1194 - mae: 0.2846 - mse: 0.2112 - pearson_correlation: 1.0973e-16 - r2_keras: -74.1380 - rmse: 0.8275 - sae: 1795.8363 - sse: 2028.2299 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3424 - val_mse: 0.2889 - val_pearson_correlation: 1.3365e-16 - val_r2_keras: -33.6138 - val_rmse: 0.9581 - val_sae: 373.0212 - val_sse: 485.5657 - learning_rate: 0.0040\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1028 - loss: 0.1271 - mae: 0.2970 - mse: 0.2317 - pearson_correlation: 7.5185e-16 - r2_keras: -88.2012 - rmse: 0.8219 - sae: 2445.9688 - sse: 2766.9102\n","Epoch 37: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0899 - loss: 0.1193 - mae: 0.2844 - mse: 0.2109 - pearson_correlation: 6.0102e-16 - r2_keras: -74.1459 - rmse: 0.8276 - sae: 1795.8990 - sse: 2028.5150 - val_huber_loss: 0.1295 - val_loss: 0.1538 - val_mae: 0.3422 - val_mse: 0.2890 - val_pearson_correlation: 1.7821e-16 - val_r2_keras: -33.6130 - val_rmse: 0.9581 - val_sae: 373.0331 - val_sse: 485.5554 - learning_rate: 0.0040\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1027 - loss: 0.1270 - mae: 0.2968 - mse: 0.2315 - pearson_correlation: 7.3673e-16 - r2_keras: -88.2112 - rmse: 0.8219 - sae: 2446.0427 - sse: 2767.2212\n","Epoch 38: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0898 - loss: 0.1192 - mae: 0.2842 - mse: 0.2107 - pearson_correlation: 5.2858e-16 - r2_keras: -74.1511 - rmse: 0.8276 - sae: 1795.9335 - sse: 2028.7052 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3422 - val_mse: 0.2891 - val_pearson_correlation: 2.2277e-17 - val_r2_keras: -33.6122 - val_rmse: 0.9580 - val_sae: 373.0314 - val_sse: 485.5441 - learning_rate: 0.0040\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1026 - loss: 0.1269 - mae: 0.2966 - mse: 0.2312 - pearson_correlation: -3.2354e-16 - r2_keras: -88.2268 - rmse: 0.8220 - sae: 2446.1719 - sse: 2767.7031\n","Epoch 39: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0897 - loss: 0.1191 - mae: 0.2840 - mse: 0.2105 - pearson_correlation: -1.4275e-16 - r2_keras: -74.1605 - rmse: 0.8276 - sae: 1796.0074 - sse: 2029.0150 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3421 - val_mse: 0.2893 - val_pearson_correlation: -2.2281e-17 - val_r2_keras: -33.6077 - val_rmse: 0.9580 - val_sae: 373.0029 - val_sse: 485.4803 - learning_rate: 0.0040\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1025 - loss: 0.1269 - mae: 0.2964 - mse: 0.2309 - pearson_correlation: -5.1725e-16 - r2_keras: -88.2384 - rmse: 0.8221 - sae: 2446.2729 - sse: 2768.0635\n","Epoch 40: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0897 - loss: 0.1190 - mae: 0.2838 - mse: 0.2103 - pearson_correlation: -3.7555e-16 - r2_keras: -74.1670 - rmse: 0.8276 - sae: 1796.0619 - sse: 2029.2404 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3420 - val_mse: 0.2893 - val_pearson_correlation: -8.9128e-17 - val_r2_keras: -33.6065 - val_rmse: 0.9580 - val_sae: 372.9949 - val_sse: 485.4634 - learning_rate: 0.0040\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1024 - loss: 0.1268 - mae: 0.2961 - mse: 0.2307 - pearson_correlation: -3.3832e-17 - r2_keras: -88.2535 - rmse: 0.8221 - sae: 2446.4026 - sse: 2768.5320\n","Epoch 41: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0896 - loss: 0.1190 - mae: 0.2836 - mse: 0.2101 - pearson_correlation: 5.4231e-17 - r2_keras: -74.1768 - rmse: 0.8277 - sae: 1796.1432 - sse: 2029.5497 - val_huber_loss: 0.1296 - val_loss: 0.1539 - val_mae: 0.3420 - val_mse: 0.2895 - val_pearson_correlation: 4.5688e-16 - val_r2_keras: -33.6016 - val_rmse: 0.9579 - val_sae: 372.9598 - val_sse: 485.3954 - learning_rate: 0.0040\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1023 - loss: 0.1267 - mae: 0.2959 - mse: 0.2304 - pearson_correlation: 4.9814e-16 - r2_keras: -88.2617 - rmse: 0.8222 - sae: 2446.4644 - sse: 2768.7856\n","Epoch 42: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0895 - loss: 0.1188 - mae: 0.2833 - mse: 0.2098 - pearson_correlation: 3.6770e-16 - r2_keras: -74.1490 - rmse: 0.8274 - sae: 1796.0399 - sse: 2029.3285 - val_huber_loss: 0.1295 - val_loss: 0.1539 - val_mae: 0.3419 - val_mse: 0.2893 - val_pearson_correlation: 2.0055e-16 - val_r2_keras: -33.6046 - val_rmse: 0.9579 - val_sae: 373.0012 - val_sse: 485.4369 - learning_rate: 8.0000e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1023 - loss: 0.1266 - mae: 0.2959 - mse: 0.2304 - pearson_correlation: -9.3676e-16 - r2_keras: -88.2651 - rmse: 0.8222 - sae: 2446.4829 - sse: 2768.8904\n","Epoch 43: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0894 - loss: 0.1188 - mae: 0.2833 - mse: 0.2098 - pearson_correlation: -6.2932e-16 - r2_keras: -74.1516 - rmse: 0.8274 - sae: 1796.0530 - sse: 2029.4030 - val_huber_loss: 0.1295 - val_loss: 0.1538 - val_mae: 0.3419 - val_mse: 0.2892 - val_pearson_correlation: -6.1276e-16 - val_r2_keras: -33.6065 - val_rmse: 0.9580 - val_sae: 373.0288 - val_sse: 485.4632 - learning_rate: 8.0000e-04\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1266 - mae: 0.2958 - mse: 0.2303 - pearson_correlation: -2.4850e-16 - r2_keras: -88.2688 - rmse: 0.8222 - sae: 2446.5083 - sse: 2769.0068\n","Epoch 44: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0894 - loss: 0.1188 - mae: 0.2832 - mse: 0.2097 - pearson_correlation: -2.6477e-16 - r2_keras: -74.1545 - rmse: 0.8274 - sae: 1796.0704 - sse: 2029.4849 - val_huber_loss: 0.1295 - val_loss: 0.1538 - val_mae: 0.3419 - val_mse: 0.2892 - val_pearson_correlation: -2.5623e-16 - val_r2_keras: -33.6077 - val_rmse: 0.9580 - val_sae: 373.0460 - val_sse: 485.4803 - learning_rate: 8.0000e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1022 - loss: 0.1266 - mae: 0.2958 - mse: 0.2302 - pearson_correlation: 2.0968e-16 - r2_keras: -88.2725 - rmse: 0.8222 - sae: 2446.5334 - sse: 2769.1211\n","Epoch 45: val_loss did not improve from 0.15381\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0894 - loss: 0.1188 - mae: 0.2832 - mse: 0.2097 - pearson_correlation: 1.8116e-16 - r2_keras: -74.1573 - rmse: 0.8275 - sae: 1796.0878 - sse: 2029.5651 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2891 - val_pearson_correlation: 4.7902e-16 - val_r2_keras: -33.6085 - val_rmse: 0.9580 - val_sae: 373.0563 - val_sse: 485.4913 - learning_rate: 8.0000e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1266 - mae: 0.2957 - mse: 0.2302 - pearson_correlation: 1.1416e-15 - r2_keras: -88.2761 - rmse: 0.8222 - sae: 2446.5576 - sse: 2769.2329\n","Epoch 46: val_loss improved from 0.15381 to 0.15381, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0894 - loss: 0.1188 - mae: 0.2831 - mse: 0.2096 - pearson_correlation: 7.5432e-16 - r2_keras: -74.1600 - rmse: 0.8275 - sae: 1796.1042 - sse: 2029.6431 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2891 - val_pearson_correlation: 3.2306e-16 - val_r2_keras: -33.6088 - val_rmse: 0.9580 - val_sae: 373.0619 - val_sse: 485.4959 - learning_rate: 8.0000e-04\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2957 - mse: 0.2301 - pearson_correlation: 2.3350e-16 - r2_keras: -88.2800 - rmse: 0.8223 - sae: 2446.5867 - sse: 2769.3545\n","Epoch 47: val_loss improved from 0.15381 to 0.15379, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2831 - mse: 0.2096 - pearson_correlation: 1.4700e-16 - r2_keras: -74.1567 - rmse: 0.8274 - sae: 1796.0983 - sse: 2029.6547 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2891 - val_pearson_correlation: 1.1140e-17 - val_r2_keras: -33.6095 - val_rmse: 0.9580 - val_sae: 373.0751 - val_sse: 485.5058 - learning_rate: 1.6000e-04\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2957 - mse: 0.2301 - pearson_correlation: 4.8122e-16 - r2_keras: -88.2809 - rmse: 0.8223 - sae: 2446.5923 - sse: 2769.3804\n","Epoch 48: val_loss improved from 0.15379 to 0.15378, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2831 - mse: 0.2095 - pearson_correlation: 3.9878e-16 - r2_keras: -74.1574 - rmse: 0.8274 - sae: 1796.1024 - sse: 2029.6736 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2891 - val_pearson_correlation: 6.4608e-16 - val_r2_keras: -33.6100 - val_rmse: 0.9580 - val_sae: 373.0839 - val_sse: 485.5127 - learning_rate: 1.6000e-04\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2957 - mse: 0.2301 - pearson_correlation: 3.3991e-16 - r2_keras: -88.2816 - rmse: 0.8223 - sae: 2446.5974 - sse: 2769.4045\n","Epoch 49: val_loss improved from 0.15378 to 0.15378, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 5.6233e-17 - r2_keras: -74.1580 - rmse: 0.8274 - sae: 1796.1061 - sse: 2029.6907 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.0025e-16 - val_r2_keras: -33.6103 - val_rmse: 0.9580 - val_sae: 373.0894 - val_sse: 485.5172 - learning_rate: 1.6000e-04\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2957 - mse: 0.2301 - pearson_correlation: 2.6481e-16 - r2_keras: -88.2824 - rmse: 0.8223 - sae: 2446.6021 - sse: 2769.4272\n","Epoch 50: val_loss improved from 0.15378 to 0.15378, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.6114e-16 - r2_keras: -74.1585 - rmse: 0.8274 - sae: 1796.1093 - sse: 2029.7067 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.6105 - val_rmse: 0.9580 - val_sae: 373.0928 - val_sse: 485.5202 - learning_rate: 1.6000e-04\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2957 - mse: 0.2301 - pearson_correlation: -1.1033e-17 - r2_keras: -88.2831 - rmse: 0.8223 - sae: 2446.6074 - sse: 2769.4507\n","Epoch 51: val_loss improved from 0.15378 to 0.15377, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.3607e-16 - r2_keras: -74.1591 - rmse: 0.8274 - sae: 1796.1130 - sse: 2029.7231 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 6.7948e-16 - val_r2_keras: -33.6106 - val_rmse: 0.9580 - val_sae: 373.0946 - val_sse: 485.5219 - learning_rate: 1.6000e-04\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -1.8543e-16 - r2_keras: -88.2839 - rmse: 0.8223 - sae: 2446.6123 - sse: 2769.4758\n","Epoch 52: val_loss improved from 0.15377 to 0.15377, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.2373e-16 - r2_keras: -74.1585 - rmse: 0.8274 - sae: 1796.1116 - sse: 2029.7268 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.1189e-16 - val_r2_keras: -33.6108 - val_rmse: 0.9580 - val_sae: 373.0980 - val_sse: 485.5243 - learning_rate: 3.2000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 2.7761e-17 - r2_keras: -88.2841 - rmse: 0.8223 - sae: 2446.6138 - sse: 2769.4807\n","Epoch 53: val_loss improved from 0.15377 to 0.15377, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.4811e-17 - r2_keras: -74.1586 - rmse: 0.8274 - sae: 1796.1127 - sse: 2029.7303 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.6708e-16 - val_r2_keras: -33.6109 - val_rmse: 0.9580 - val_sae: 373.1002 - val_sse: 485.5259 - learning_rate: 3.2000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -6.9047e-17 - r2_keras: -88.2842 - rmse: 0.8223 - sae: 2446.6147 - sse: 2769.4849\n","Epoch 54: val_loss improved from 0.15377 to 0.15377, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0894 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.1438e-16 - r2_keras: -74.1587 - rmse: 0.8274 - sae: 1796.1133 - sse: 2029.7333 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 2.8961e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1016 - val_sse: 485.5269 - learning_rate: 3.2000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 3.4025e-16 - r2_keras: -88.2844 - rmse: 0.8223 - sae: 2446.6157 - sse: 2769.4897\n","Epoch 55: val_loss improved from 0.15377 to 0.15377, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 2.0277e-16 - r2_keras: -74.1589 - rmse: 0.8274 - sae: 1796.1139 - sse: 2029.7367 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 2.2278e-17 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1024 - val_sse: 485.5276 - learning_rate: 3.2000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 6.4562e-16 - r2_keras: -88.2845 - rmse: 0.8223 - sae: 2446.6167 - sse: 2769.4934\n","Epoch 56: val_loss improved from 0.15377 to 0.15377, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 3.0046e-16 - r2_keras: -74.1590 - rmse: 0.8274 - sae: 1796.1146 - sse: 2029.7393 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.3392e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1029 - val_sse: 485.5280 - learning_rate: 3.2000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -5.6198e-16 - r2_keras: -88.2847 - rmse: 0.8223 - sae: 2446.6177 - sse: 2769.4983\n","Epoch 57: val_loss improved from 0.15377 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.0546e-16 - r2_keras: -74.1589 - rmse: 0.8274 - sae: 1796.1144 - sse: 2029.7401 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.2278e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1036 - val_sse: 485.5285 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 8.3781e-16 - r2_keras: -88.2847 - rmse: 0.8223 - sae: 2446.6177 - sse: 2769.4990\n","Epoch 58: val_loss improved from 0.15376 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 6.1822e-16 - r2_keras: -74.1589 - rmse: 0.8274 - sae: 1796.1144 - sse: 2029.7407 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 4.2327e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1040 - val_sse: 485.5287 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 3.7726e-17 - r2_keras: -88.2847 - rmse: 0.8223 - sae: 2446.6182 - sse: 2769.5007\n","Epoch 59: val_loss improved from 0.15376 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.1674e-17 - r2_keras: -74.1589 - rmse: 0.8274 - sae: 1796.1147 - sse: 2029.7419 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -4.3441e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1042 - val_sse: 485.5288 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -9.8586e-17 - r2_keras: -88.2848 - rmse: 0.8223 - sae: 2446.6187 - sse: 2769.5022\n","Epoch 60: val_loss improved from 0.15376 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -9.8905e-18 - r2_keras: -74.1590 - rmse: 0.8274 - sae: 1796.1151 - sse: 2029.7429 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.2278e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1044 - val_sse: 485.5289 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -2.8117e-16 - r2_keras: -88.2848 - rmse: 0.8223 - sae: 2446.6187 - sse: 2769.5034\n","Epoch 61: val_loss improved from 0.15376 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -9.7918e-17 - r2_keras: -74.1590 - rmse: 0.8274 - sae: 1796.1151 - sse: 2029.7438 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.1139e-17 - val_r2_keras: -33.6112 - val_rmse: 0.9580 - val_sae: 373.1045 - val_sse: 485.5291 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 6.9046e-17 - r2_keras: -88.2849 - rmse: 0.8223 - sae: 2446.6189 - sse: 2769.5046\n","Epoch 62: val_loss improved from 0.15376 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 2.9666e-17 - r2_keras: -74.1590 - rmse: 0.8274 - sae: 1796.1154 - sse: 2029.7448 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.2278e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1045 - val_sse: 485.5289 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 8.3745e-16 - r2_keras: -88.2849 - rmse: 0.8223 - sae: 2446.6189 - sse: 2769.5054\n","Epoch 63: val_loss improved from 0.15376 to 0.15376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 5.1017e-16 - r2_keras: -74.1590 - rmse: 0.8274 - sae: 1796.1154 - sse: 2029.7452 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.7822e-16 - val_r2_keras: -33.6112 - val_rmse: 0.9580 - val_sae: 373.1046 - val_sse: 485.5291 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -2.8935e-16 - r2_keras: -88.2849 - rmse: 0.8223 - sae: 2446.6191 - sse: 2769.5068\n","Epoch 64: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.3911e-16 - r2_keras: -74.1591 - rmse: 0.8274 - sae: 1796.1155 - sse: 2029.7462 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.4530e-16 - val_r2_keras: -33.6112 - val_rmse: 0.9580 - val_sae: 373.1045 - val_sse: 485.5290 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1022 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 5.2638e-16 - r2_keras: -88.2850 - rmse: 0.8223 - sae: 2446.6196 - sse: 2769.5081\n","Epoch 65: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 2.5947e-16 - r2_keras: -74.1591 - rmse: 0.8274 - sae: 1796.1158 - sse: 2029.7471 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.7822e-16 - val_r2_keras: -33.6112 - val_rmse: 0.9580 - val_sae: 373.1045 - val_sse: 485.5290 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 2.6337e-17 - r2_keras: -88.2850 - rmse: 0.8223 - sae: 2446.6191 - sse: 2769.5090\n","Epoch 66: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 5.4139e-17 - r2_keras: -74.1591 - rmse: 0.8274 - sae: 1796.1155 - sse: 2029.7478 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 5.0125e-16 - val_r2_keras: -33.6112 - val_rmse: 0.9580 - val_sae: 373.1045 - val_sse: 485.5290 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 2.8828e-17 - r2_keras: -88.2850 - rmse: 0.8223 - sae: 2446.6196 - sse: 2769.5103\n","Epoch 67: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.8324e-17 - r2_keras: -74.1592 - rmse: 0.8274 - sae: 1796.1158 - sse: 2029.7487 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.4480e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1045 - val_sse: 485.5289 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -8.8976e-18 - r2_keras: -88.2851 - rmse: 0.8223 - sae: 2446.6201 - sse: 2769.5115\n","Epoch 68: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -6.4653e-17 - r2_keras: -74.1592 - rmse: 0.8274 - sae: 1796.1161 - sse: 2029.7495 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.5619e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1044 - val_sse: 485.5289 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 1.5162e-16 - r2_keras: -88.2851 - rmse: 0.8223 - sae: 2446.6206 - sse: 2769.5129\n","Epoch 69: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.8290e-16 - r2_keras: -74.1592 - rmse: 0.8274 - sae: 1796.1165 - sse: 2029.7506 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.1139e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1043 - val_sse: 485.5289 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -1.1816e-16 - r2_keras: -88.2852 - rmse: 0.8223 - sae: 2446.6206 - sse: 2769.5139\n","Epoch 70: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.8931e-17 - r2_keras: -74.1592 - rmse: 0.8274 - sae: 1796.1163 - sse: 2029.7512 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.3416e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1043 - val_sse: 485.5288 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -3.1391e-16 - r2_keras: -88.2852 - rmse: 0.8223 - sae: 2446.6206 - sse: 2769.5151\n","Epoch 71: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.2467e-16 - r2_keras: -74.1593 - rmse: 0.8274 - sae: 1796.1165 - sse: 2029.7521 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.1139e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1043 - val_sse: 485.5288 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -1.9504e-16 - r2_keras: -88.2852 - rmse: 0.8223 - sae: 2446.6211 - sse: 2769.5161\n","Epoch 72: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.3385e-17 - r2_keras: -74.1593 - rmse: 0.8274 - sae: 1796.1168 - sse: 2029.7528 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1042 - val_sse: 485.5288 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -8.3993e-17 - r2_keras: -88.2853 - rmse: 0.8223 - sae: 2446.6211 - sse: 2769.5171\n","Epoch 73: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.5033e-16 - r2_keras: -74.1593 - rmse: 0.8274 - sae: 1796.1167 - sse: 2029.7534 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1042 - val_sse: 485.5287 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -1.3809e-16 - r2_keras: -88.2853 - rmse: 0.8223 - sae: 2446.6213 - sse: 2769.5181\n","Epoch 74: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -7.8583e-17 - r2_keras: -74.1594 - rmse: 0.8274 - sae: 1796.1169 - sse: 2029.7542 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.1164e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1042 - val_sse: 485.5287 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 8.0434e-17 - r2_keras: -88.2853 - rmse: 0.8223 - sae: 2446.6216 - sse: 2769.5193\n","Epoch 75: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.0874e-17 - r2_keras: -74.1594 - rmse: 0.8274 - sae: 1796.1171 - sse: 2029.7550 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.2303e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1041 - val_sse: 485.5286 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -6.1571e-17 - r2_keras: -88.2854 - rmse: 0.8223 - sae: 2446.6216 - sse: 2769.5205\n","Epoch 76: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.3442e-16 - r2_keras: -74.1594 - rmse: 0.8274 - sae: 1796.1171 - sse: 2029.7559 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.6708e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1041 - val_sse: 485.5285 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: 2.6693e-17 - r2_keras: -88.2854 - rmse: 0.8223 - sae: 2446.6216 - sse: 2769.5212\n","Epoch 77: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 9.5769e-17 - r2_keras: -74.1594 - rmse: 0.8274 - sae: 1796.1171 - sse: 2029.7563 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.6708e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1040 - val_sse: 485.5285 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -1.9824e-16 - r2_keras: -88.2854 - rmse: 0.8223 - sae: 2446.6221 - sse: 2769.5229\n","Epoch 78: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.8222e-16 - r2_keras: -74.1595 - rmse: 0.8274 - sae: 1796.1174 - sse: 2029.7574 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.6758e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1039 - val_sse: 485.5284 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -2.6443e-16 - r2_keras: -88.2855 - rmse: 0.8223 - sae: 2446.6223 - sse: 2769.5242\n","Epoch 79: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.0794e-16 - r2_keras: -74.1595 - rmse: 0.8274 - sae: 1796.1176 - sse: 2029.7584 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -5.5694e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1039 - val_sse: 485.5284 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -2.0251e-16 - r2_keras: -88.2855 - rmse: 0.8223 - sae: 2446.6226 - sse: 2769.5251\n","Epoch 80: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.2057e-16 - r2_keras: -74.1595 - rmse: 0.8274 - sae: 1796.1177 - sse: 2029.7590 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.1139e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1039 - val_sse: 485.5283 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2301 - pearson_correlation: -3.5946e-17 - r2_keras: -88.2856 - rmse: 0.8223 - sae: 2446.6226 - sse: 2769.5261\n","Epoch 81: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.0329e-17 - r2_keras: -74.1595 - rmse: 0.8274 - sae: 1796.1177 - sse: 2029.7596 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 2.8961e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1038 - val_sse: 485.5282 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 3.4166e-17 - r2_keras: -88.2856 - rmse: 0.8223 - sae: 2446.6228 - sse: 2769.5271\n","Epoch 82: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 6.6097e-17 - r2_keras: -74.1596 - rmse: 0.8274 - sae: 1796.1179 - sse: 2029.7604 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.0075e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1038 - val_sse: 485.5282 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 2.2635e-16 - r2_keras: -88.2856 - rmse: 0.8223 - sae: 2446.6230 - sse: 2769.5278\n","Epoch 83: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.3935e-16 - r2_keras: -74.1596 - rmse: 0.8274 - sae: 1796.1180 - sse: 2029.7609 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.7872e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1037 - val_sse: 485.5281 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 2.6621e-16 - r2_keras: -88.2857 - rmse: 0.8223 - sae: 2446.6230 - sse: 2769.5298\n","Epoch 84: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.7266e-16 - r2_keras: -74.1596 - rmse: 0.8274 - sae: 1796.1180 - sse: 2029.7622 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 6.6833e-17 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1037 - val_sse: 485.5281 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -3.5875e-16 - r2_keras: -88.2857 - rmse: 0.8223 - sae: 2446.6235 - sse: 2769.5303\n","Epoch 85: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.1221e-16 - r2_keras: -74.1596 - rmse: 0.8274 - sae: 1796.1183 - sse: 2029.7626 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.2253e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1036 - val_sse: 485.5280 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 1.0036e-16 - r2_keras: -88.2857 - rmse: 0.8223 - sae: 2446.6238 - sse: 2769.5312\n","Epoch 86: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.1312e-16 - r2_keras: -74.1597 - rmse: 0.8274 - sae: 1796.1185 - sse: 2029.7633 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.8936e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1036 - val_sse: 485.5280 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 6.8262e-16 - r2_keras: -88.2858 - rmse: 0.8223 - sae: 2446.6238 - sse: 2769.5322\n","Epoch 87: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 5.8311e-16 - r2_keras: -74.1597 - rmse: 0.8274 - sae: 1796.1185 - sse: 2029.7640 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.5594e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1035 - val_sse: 485.5279 - learning_rate: 1.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -9.8584e-17 - r2_keras: -88.2858 - rmse: 0.8223 - sae: 2446.6243 - sse: 2769.5334\n","Epoch 88: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.1482e-16 - r2_keras: -74.1597 - rmse: 0.8274 - sae: 1796.1189 - sse: 2029.7649 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 8.2427e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1035 - val_sse: 485.5279 - learning_rate: 1.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 6.8475e-16 - r2_keras: -88.2858 - rmse: 0.8223 - sae: 2446.6240 - sse: 2769.5347\n","Epoch 89: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 3.9874e-16 - r2_keras: -74.1598 - rmse: 0.8274 - sae: 1796.1187 - sse: 2029.7657 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.4505e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1034 - val_sse: 485.5278 - learning_rate: 1.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 6.6340e-16 - r2_keras: -88.2859 - rmse: 0.8223 - sae: 2446.6243 - sse: 2769.5356\n","Epoch 90: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 3.2386e-16 - r2_keras: -74.1598 - rmse: 0.8274 - sae: 1796.1188 - sse: 2029.7665 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 2.0050e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1034 - val_sse: 485.5277 - learning_rate: 1.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 2.6016e-16 - r2_keras: -88.2859 - rmse: 0.8223 - sae: 2446.6245 - sse: 2769.5369\n","Epoch 91: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 1.7248e-16 - r2_keras: -74.1598 - rmse: 0.8274 - sae: 1796.1190 - sse: 2029.7672 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.2303e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1033 - val_sse: 485.5277 - learning_rate: 1.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 5.0858e-16 - r2_keras: -88.2859 - rmse: 0.8223 - sae: 2446.6248 - sse: 2769.5376\n","Epoch 92: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 2.6012e-16 - r2_keras: -74.1598 - rmse: 0.8274 - sae: 1796.1191 - sse: 2029.7677 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.8936e-16 - val_r2_keras: -33.6111 - val_rmse: 0.9580 - val_sae: 373.1032 - val_sse: 485.5276 - learning_rate: 1.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -6.3777e-16 - r2_keras: -88.2859 - rmse: 0.8223 - sae: 2446.6250 - sse: 2769.5386\n","Epoch 93: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.9930e-16 - r2_keras: -74.1598 - rmse: 0.8274 - sae: 1796.1193 - sse: 2029.7684 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.2278e-17 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1032 - val_sse: 485.5275 - learning_rate: 1.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -5.9115e-16 - r2_keras: -88.2860 - rmse: 0.8223 - sae: 2446.6250 - sse: 2769.5393\n","Epoch 94: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.0180e-16 - r2_keras: -74.1599 - rmse: 0.8274 - sae: 1796.1193 - sse: 2029.7689 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 5.3466e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1031 - val_sse: 485.5274 - learning_rate: 1.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -2.5589e-16 - r2_keras: -88.2860 - rmse: 0.8223 - sae: 2446.6252 - sse: 2769.5410\n","Epoch 95: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.5904e-16 - r2_keras: -74.1599 - rmse: 0.8274 - sae: 1796.1195 - sse: 2029.7700 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -5.5694e-17 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1030 - val_sse: 485.5273 - learning_rate: 1.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -3.5483e-16 - r2_keras: -88.2861 - rmse: 0.8223 - sae: 2446.6255 - sse: 2769.5420\n","Epoch 96: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.7795e-16 - r2_keras: -74.1599 - rmse: 0.8274 - sae: 1796.1196 - sse: 2029.7709 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 4.6783e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1030 - val_sse: 485.5272 - learning_rate: 1.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 5.4096e-17 - r2_keras: -88.2861 - rmse: 0.8223 - sae: 2446.6255 - sse: 2769.5430\n","Epoch 97: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 5.8205e-17 - r2_keras: -74.1599 - rmse: 0.8274 - sae: 1796.1195 - sse: 2029.7714 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 3.1189e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1028 - val_sse: 485.5270 - learning_rate: 1.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -2.1994e-16 - r2_keras: -88.2861 - rmse: 0.8223 - sae: 2446.6257 - sse: 2769.5439\n","Epoch 98: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.8899e-16 - r2_keras: -74.1600 - rmse: 0.8274 - sae: 1796.1198 - sse: 2029.7721 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.3417e-17 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1028 - val_sse: 485.5271 - learning_rate: 1.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 7.1891e-17 - r2_keras: -88.2861 - rmse: 0.8223 - sae: 2446.6260 - sse: 2769.5447\n","Epoch 99: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 9.0284e-17 - r2_keras: -74.1600 - rmse: 0.8274 - sae: 1796.1199 - sse: 2029.7726 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.2303e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1027 - val_sse: 485.5270 - learning_rate: 1.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -1.6585e-16 - r2_keras: -88.2862 - rmse: 0.8223 - sae: 2446.6265 - sse: 2769.5464\n","Epoch 100: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -1.4618e-16 - r2_keras: -74.1600 - rmse: 0.8274 - sae: 1796.1202 - sse: 2029.7738 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.3417e-17 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1027 - val_sse: 485.5270 - learning_rate: 1.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -2.9041e-16 - r2_keras: -88.2862 - rmse: 0.8223 - sae: 2446.6265 - sse: 2769.5474\n","Epoch 101: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.6003e-16 - r2_keras: -74.1601 - rmse: 0.8274 - sae: 1796.1202 - sse: 2029.7745 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 1.5594e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1026 - val_sse: 485.5268 - learning_rate: 1.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 4.2103e-16 - r2_keras: -88.2863 - rmse: 0.8223 - sae: 2446.6265 - sse: 2769.5479\n","Epoch 102: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 3.1534e-16 - r2_keras: -74.1601 - rmse: 0.8274 - sae: 1796.1202 - sse: 2029.7748 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.3392e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1025 - val_sse: 485.5267 - learning_rate: 1.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -1.5588e-16 - r2_keras: -88.2863 - rmse: 0.8223 - sae: 2446.6270 - sse: 2769.5491\n","Epoch 103: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.1270e-16 - r2_keras: -74.1601 - rmse: 0.8274 - sae: 1796.1205 - sse: 2029.7756 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -5.5694e-17 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1025 - val_sse: 485.5267 - learning_rate: 1.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -6.4310e-16 - r2_keras: -88.2863 - rmse: 0.8223 - sae: 2446.6272 - sse: 2769.5500\n","Epoch 104: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -3.9889e-16 - r2_keras: -74.1601 - rmse: 0.8274 - sae: 1796.1207 - sse: 2029.7762 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.4481e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1024 - val_sse: 485.5266 - learning_rate: 1.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 9.0326e-16 - r2_keras: -88.2864 - rmse: 0.8223 - sae: 2446.6277 - sse: 2769.5518\n","Epoch 105: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 6.7630e-16 - r2_keras: -74.1601 - rmse: 0.8274 - sae: 1796.1210 - sse: 2029.7775 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.3417e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1024 - val_sse: 485.5265 - learning_rate: 1.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -2.0357e-16 - r2_keras: -88.2864 - rmse: 0.8223 - sae: 2446.6277 - sse: 2769.5527\n","Epoch 106: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -7.2181e-17 - r2_keras: -74.1602 - rmse: 0.8274 - sae: 1796.1210 - sse: 2029.7782 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.5644e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1023 - val_sse: 485.5264 - learning_rate: 1.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -3.7511e-16 - r2_keras: -88.2864 - rmse: 0.8223 - sae: 2446.6279 - sse: 2769.5532\n","Epoch 107: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -2.5970e-16 - r2_keras: -74.1602 - rmse: 0.8274 - sae: 1796.1211 - sse: 2029.7784 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -2.1164e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1022 - val_sse: 485.5263 - learning_rate: 1.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -1.8542e-16 - r2_keras: -88.2865 - rmse: 0.8223 - sae: 2446.6284 - sse: 2769.5547\n","Epoch 108: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.3715e-17 - r2_keras: -74.1602 - rmse: 0.8274 - sae: 1796.1215 - sse: 2029.7797 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -5.0125e-16 - val_r2_keras: -33.6110 - val_rmse: 0.9580 - val_sae: 373.1022 - val_sse: 485.5263 - learning_rate: 1.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: -6.5164e-16 - r2_keras: -88.2865 - rmse: 0.8223 - sae: 2446.6284 - sse: 2769.5557\n","Epoch 109: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: -4.3347e-16 - r2_keras: -74.1602 - rmse: 0.8274 - sae: 1796.1215 - sse: 2029.7802 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 6.6833e-16 - val_r2_keras: -33.6109 - val_rmse: 0.9580 - val_sae: 373.1021 - val_sse: 485.5261 - learning_rate: 1.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 3.6337e-16 - r2_keras: -88.2865 - rmse: 0.8223 - sae: 2446.6287 - sse: 2769.5564\n","Epoch 110: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 2.7594e-16 - r2_keras: -74.1603 - rmse: 0.8274 - sae: 1796.1217 - sse: 2029.7806 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.3367e-16 - val_r2_keras: -33.6109 - val_rmse: 0.9580 - val_sae: 373.1020 - val_sse: 485.5261 - learning_rate: 1.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 4.8081e-16 - r2_keras: -88.2866 - rmse: 0.8223 - sae: 2446.6284 - sse: 2769.5576\n","Epoch 111: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 4.5050e-16 - r2_keras: -74.1603 - rmse: 0.8274 - sae: 1796.1215 - sse: 2029.7816 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: 2.1164e-16 - val_r2_keras: -33.6109 - val_rmse: 0.9580 - val_sae: 373.1020 - val_sse: 485.5260 - learning_rate: 1.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 6.0004e-16 - r2_keras: -88.2866 - rmse: 0.8223 - sae: 2446.6289 - sse: 2769.5586\n","Epoch 112: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 3.7211e-16 - r2_keras: -74.1603 - rmse: 0.8274 - sae: 1796.1217 - sse: 2029.7822 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -1.1139e-17 - val_r2_keras: -33.6109 - val_rmse: 0.9580 - val_sae: 373.1019 - val_sse: 485.5259 - learning_rate: 1.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1021 - loss: 0.1265 - mae: 0.2956 - mse: 0.2300 - pearson_correlation: 4.8330e-16 - r2_keras: -88.2866 - rmse: 0.8223 - sae: 2446.6292 - sse: 2769.5596\n","Epoch 113: val_loss did not improve from 0.15376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0893 - loss: 0.1187 - mae: 0.2830 - mse: 0.2095 - pearson_correlation: 3.2316e-16 - r2_keras: -74.1603 - rmse: 0.8274 - sae: 1796.1219 - sse: 2029.7828 - val_huber_loss: 0.1294 - val_loss: 0.1538 - val_mae: 0.3418 - val_mse: 0.2890 - val_pearson_correlation: -3.7872e-16 - val_r2_keras: -33.6109 - val_rmse: 0.9580 - val_sae: 373.1018 - val_sse: 485.5258 - learning_rate: 1.0000e-05\n","| \u001b[39m18       \u001b[39m | \u001b[39m-0.1538  \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m19.39    \u001b[39m | \u001b[39m19.17    \u001b[39m |\n","Epoch 1/1000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 1.4520 - loss: 1.5422 - mae: 1.8967 - mse: 6.4509 - pearson_correlation: -7.6874e-17 - r2_keras: -824.6533 - rmse: 2.5005 - sae: 7657.3184 - sse: 25610.7324\n","Epoch 1: val_loss improved from inf to 0.34639, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 472ms/step - huber_loss: 1.7617 - loss: 1.7314 - mae: 2.0930 - mse: 7.1744 - pearson_correlation: -1.7427e-19 - r2_keras: -810.0500 - rmse: 2.8071 - sae: 5895.7197 - sse: 20130.8379 - val_huber_loss: 0.2518 - val_loss: 0.3464 - val_mae: 0.5798 - val_mse: 0.6161 - val_pearson_correlation: -3.8516e-17 - val_r2_keras: -23.2601 - val_rmse: 0.8021 - val_sae: 309.8691 - val_sse: 340.3232 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2141 - loss: 0.3087 - mae: 0.5179 - mse: 0.4642 - pearson_correlation: -3.5752e-16 - r2_keras: -132.1797 - rmse: 1.0043 - sae: 3151.7595 - sse: 4131.0693\n","Epoch 2: val_loss did not improve from 0.34639\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.3511 - loss: 0.3921 - mae: 0.6198 - mse: 0.6910 - pearson_correlation: -3.0540e-16 - r2_keras: -139.0972 - rmse: 1.1754 - sae: 2411.9407 - sse: 3355.9221 - val_huber_loss: 0.6996 - val_loss: 0.7942 - val_mae: 1.1422 - val_mse: 1.9401 - val_pearson_correlation: -1.4853e-17 - val_r2_keras: -56.1004 - val_rmse: 1.2305 - val_sae: 502.5245 - val_sse: 801.0109 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 1.3512 - loss: 1.4458 - mae: 1.8101 - mse: 5.2180 - pearson_correlation: -1.0743e-16 - r2_keras: -635.9466 - rmse: 2.1963 - sae: 6915.6484 - sse: 19757.2871\n","Epoch 3: val_loss did not improve from 0.34639\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 1.0544 - loss: 1.2652 - mae: 1.6145 - mse: 4.3710 - pearson_correlation: -3.9300e-17 - r2_keras: -469.8592 - rmse: 1.9443 - sae: 4907.5352 - sse: 13713.7822 - val_huber_loss: 0.3945 - val_loss: 0.4892 - val_mae: 0.7648 - val_mse: 1.0445 - val_pearson_correlation: 2.2807e-16 - val_r2_keras: -32.4677 - val_rmse: 0.9421 - val_sae: 350.2219 - val_sse: 469.4892 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.5618 - loss: 0.6565 - mae: 0.9964 - mse: 1.3517 - pearson_correlation: -8.7313e-17 - r2_keras: -155.4496 - rmse: 1.0885 - sae: 3519.9934 - sse: 4852.8721\n","Epoch 4: val_loss did not improve from 0.34639\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.4915 - loss: 0.6137 - mae: 0.9349 - mse: 1.2302 - pearson_correlation: -2.4024e-16 - r2_keras: -136.2585 - rmse: 1.1311 - sae: 2596.7109 - sse: 3621.8547 - val_huber_loss: 0.4227 - val_loss: 0.5174 - val_mae: 0.7763 - val_mse: 1.1357 - val_pearson_correlation: -3.6475e-16 - val_r2_keras: -38.2696 - val_rmse: 1.0205 - val_sae: 373.7067 - val_sse: 550.8781 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.4044 - loss: 0.4991 - mae: 0.7482 - mse: 0.9429 - pearson_correlation: -3.7742e-16 - r2_keras: -170.0622 - rmse: 1.1382 - sae: 3493.6641 - sse: 5306.1367\n","Epoch 5: val_loss did not improve from 0.34639\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3838 - loss: 0.4865 - mae: 0.7398 - mse: 0.9009 - pearson_correlation: -2.5039e-16 - r2_keras: -138.4369 - rmse: 1.1147 - sae: 2547.7786 - sse: 3835.3137 - val_huber_loss: 0.3706 - val_loss: 0.4652 - val_mae: 0.6793 - val_mse: 0.9809 - val_pearson_correlation: 1.7554e-16 - val_r2_keras: -37.2928 - val_rmse: 1.0077 - val_sae: 362.5141 - val_sse: 537.1758 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.3072 - loss: 0.4018 - mae: 0.6251 - mse: 0.6933 - pearson_correlation: 9.9626e-16 - r2_keras: -151.1927 - rmse: 1.0736 - sae: 3157.7671 - sse: 4720.8271\n","Epoch 6: val_loss improved from 0.34639 to 0.32551, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.2592 - loss: 0.3726 - mae: 0.5899 - mse: 0.6204 - pearson_correlation: 7.1218e-16 - r2_keras: -115.8490 - rmse: 0.9927 - sae: 2273.0242 - sse: 3327.7104 - val_huber_loss: 0.2311 - val_loss: 0.3255 - val_mae: 0.4776 - val_mse: 0.5916 - val_pearson_correlation: 2.6483e-16 - val_r2_keras: -30.3305 - val_rmse: 0.9115 - val_sae: 316.7800 - val_sse: 439.5074 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1599 - loss: 0.2544 - mae: 0.4143 - mse: 0.3582 - pearson_correlation: -5.6845e-16 - r2_keras: -116.3853 - rmse: 0.9428 - sae: 2717.9922 - sse: 3641.1450\n","Epoch 7: val_loss improved from 0.32551 to 0.22376, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1465 - loss: 0.2462 - mae: 0.4020 - mse: 0.3370 - pearson_correlation: -3.8882e-16 - r2_keras: -89.6265 - rmse: 0.8769 - sae: 1959.0465 - sse: 2572.5269 - val_huber_loss: 0.1295 - val_loss: 0.2238 - val_mae: 0.3691 - val_mse: 0.3024 - val_pearson_correlation: 2.8831e-16 - val_r2_keras: -30.9840 - val_rmse: 0.9210 - val_sae: 353.9798 - val_sse: 448.6753 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1934 - loss: 0.2876 - mae: 0.5334 - mse: 0.4355 - pearson_correlation: 2.3324e-16 - r2_keras: -138.4488 - rmse: 1.0276 - sae: 3240.4980 - sse: 4325.5273\n","Epoch 8: val_loss did not improve from 0.22376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2390 - loss: 0.3154 - mae: 0.5698 - mse: 0.4884 - pearson_correlation: 1.8182e-16 - r2_keras: -113.4895 - rmse: 1.0127 - sae: 2364.4353 - sse: 3136.1575 - val_huber_loss: 0.2260 - val_loss: 0.3200 - val_mae: 0.5362 - val_mse: 0.4656 - val_pearson_correlation: 6.0104e-17 - val_r2_keras: -47.5575 - val_rmse: 1.1347 - val_sae: 475.9921 - val_sse: 681.1695 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3774 - loss: 0.4715 - mae: 0.7722 - mse: 0.8722 - pearson_correlation: -1.2008e-16 - r2_keras: -191.6412 - rmse: 1.2078 - sae: 3860.4041 - sse: 5975.4888\n","Epoch 9: val_loss did not improve from 0.22376\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3290 - loss: 0.4420 - mae: 0.7323 - mse: 0.7938 - pearson_correlation: -5.6635e-17 - r2_keras: -145.7147 - rmse: 1.1072 - sae: 2760.0039 - sse: 4198.1694 - val_huber_loss: 0.1620 - val_loss: 0.2560 - val_mae: 0.4376 - val_mse: 0.3463 - val_pearson_correlation: 2.3015e-16 - val_r2_keras: -37.7147 - val_rmse: 1.0132 - val_sae: 419.0073 - val_sse: 543.0942 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2079 - loss: 0.3018 - mae: 0.5301 - mse: 0.4838 - pearson_correlation: -1.1511e-17 - r2_keras: -125.8812 - rmse: 0.9802 - sae: 3152.4685 - sse: 3935.6953\n","Epoch 10: val_loss improved from 0.22376 to 0.21705, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.1745 - loss: 0.2815 - mae: 0.4920 - mse: 0.4310 - pearson_correlation: -1.5447e-17 - r2_keras: -97.7123 - rmse: 0.9189 - sae: 2260.3860 - sse: 2789.4817 - val_huber_loss: 0.1233 - val_loss: 0.2170 - val_mae: 0.3519 - val_mse: 0.2782 - val_pearson_correlation: 1.0557e-16 - val_r2_keras: -32.4923 - val_rmse: 0.9424 - val_sae: 370.3549 - val_sse: 469.8329 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1188 - loss: 0.2125 - mae: 0.3486 - mse: 0.2654 - pearson_correlation: -1.4497e-16 - r2_keras: -100.3414 - rmse: 0.8760 - sae: 2679.8071 - sse: 3143.4824\n","Epoch 11: val_loss improved from 0.21705 to 0.21192, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.1062 - loss: 0.2048 - mae: 0.3318 - mse: 0.2453 - pearson_correlation: -1.2762e-16 - r2_keras: -80.3773 - rmse: 0.8465 - sae: 1940.5516 - sse: 2257.7214 - val_huber_loss: 0.1184 - val_loss: 0.2119 - val_mae: 0.3345 - val_mse: 0.2716 - val_pearson_correlation: 1.7039e-16 - val_r2_keras: -30.3901 - val_rmse: 0.9124 - val_sae: 348.7700 - val_sse: 440.3437 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1082 - loss: 0.2017 - mae: 0.3137 - mse: 0.2371 - pearson_correlation: -2.2849e-17 - r2_keras: -90.5381 - rmse: 0.8326 - sae: 2495.6763 - sse: 2839.3979\n","Epoch 12: val_loss improved from 0.21192 to 0.20959, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1001 - loss: 0.1967 - mae: 0.3007 - mse: 0.2239 - pearson_correlation: -4.7103e-17 - r2_keras: -75.2737 - rmse: 0.8308 - sae: 1824.6173 - sse: 2071.7952 - val_huber_loss: 0.1163 - val_loss: 0.2096 - val_mae: 0.3314 - val_mse: 0.2650 - val_pearson_correlation: -2.4654e-16 - val_r2_keras: -29.6937 - val_rmse: 0.9022 - val_sae: 347.2455 - val_sse: 430.5750 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1152 - loss: 0.2085 - mae: 0.3323 - mse: 0.2477 - pearson_correlation: 2.5522e-18 - r2_keras: -87.0943 - rmse: 0.8168 - sae: 2444.2456 - sse: 2732.5745\n","Epoch 13: val_loss improved from 0.20959 to 0.20745, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1071 - loss: 0.2035 - mae: 0.3163 - mse: 0.2353 - pearson_correlation: 5.9371e-17 - r2_keras: -74.2736 - rmse: 0.8318 - sae: 1796.7585 - sse: 2015.7792 - val_huber_loss: 0.1144 - val_loss: 0.2075 - val_mae: 0.3274 - val_mse: 0.2593 - val_pearson_correlation: -2.7303e-17 - val_r2_keras: -29.7668 - val_rmse: 0.9033 - val_sae: 348.8960 - val_sse: 431.5994 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1218 - loss: 0.2148 - mae: 0.3384 - mse: 0.2693 - pearson_correlation: 1.3305e-16 - r2_keras: -88.1738 - rmse: 0.8218 - sae: 2479.6436 - sse: 2766.0610\n","Epoch 14: val_loss improved from 0.20745 to 0.20244, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1075 - loss: 0.2061 - mae: 0.3180 - mse: 0.2475 - pearson_correlation: 1.1684e-16 - r2_keras: -74.4454 - rmse: 0.8303 - sae: 1817.3920 - sse: 2031.6764 - val_huber_loss: 0.1096 - val_loss: 0.2024 - val_mae: 0.3122 - val_mse: 0.2470 - val_pearson_correlation: -3.7938e-17 - val_r2_keras: -31.0085 - val_rmse: 0.9213 - val_sae: 351.8689 - val_sse: 449.0189 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1003 - loss: 0.1932 - mae: 0.3006 - mse: 0.2153 - pearson_correlation: 1.2690e-15 - r2_keras: -89.6987 - rmse: 0.8288 - sae: 2465.1272 - sse: 2813.3611\n","Epoch 15: val_loss improved from 0.20244 to 0.19903, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0931 - loss: 0.1888 - mae: 0.2888 - mse: 0.2042 - pearson_correlation: 9.4240e-16 - r2_keras: -75.1086 - rmse: 0.8318 - sae: 1805.6105 - sse: 2059.0645 - val_huber_loss: 0.1064 - val_loss: 0.1990 - val_mae: 0.3054 - val_mse: 0.2372 - val_pearson_correlation: -2.4503e-16 - val_r2_keras: -31.6059 - val_rmse: 0.9299 - val_sae: 356.3055 - val_sse: 457.3985 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1061 - loss: 0.1987 - mae: 0.3099 - mse: 0.2279 - pearson_correlation: 4.3271e-16 - r2_keras: -90.2911 - rmse: 0.8315 - sae: 2475.2686 - sse: 2831.7363\n","Epoch 16: val_loss did not improve from 0.19903\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0968 - loss: 0.1931 - mae: 0.2972 - mse: 0.2140 - pearson_correlation: 2.4206e-16 - r2_keras: -75.7206 - rmse: 0.8356 - sae: 1813.3973 - sse: 2073.8608 - val_huber_loss: 0.1092 - val_loss: 0.2016 - val_mae: 0.3074 - val_mse: 0.2455 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -31.7782 - val_rmse: 0.9323 - val_sae: 356.8444 - val_sse: 459.8160 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1042 - loss: 0.1966 - mae: 0.3102 - mse: 0.2222 - pearson_correlation: 4.1343e-16 - r2_keras: -90.3961 - rmse: 0.8319 - sae: 2485.0737 - sse: 2834.9941\n","Epoch 17: val_loss did not improve from 0.19903\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0947 - loss: 0.1908 - mae: 0.2961 - mse: 0.2083 - pearson_correlation: 2.3233e-16 - r2_keras: -75.7303 - rmse: 0.8353 - sae: 1819.7496 - sse: 2075.3252 - val_huber_loss: 0.1092 - val_loss: 0.2014 - val_mae: 0.3059 - val_mse: 0.2451 - val_pearson_correlation: -1.5451e-16 - val_r2_keras: -32.2005 - val_rmse: 0.9383 - val_sae: 358.6934 - val_sse: 465.7396 - learning_rate: 0.1000\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0994 - loss: 0.1917 - mae: 0.3001 - mse: 0.2123 - pearson_correlation: 4.0123e-16 - r2_keras: -91.6593 - rmse: 0.8377 - sae: 2493.4678 - sse: 2874.1748\n","Epoch 18: val_loss did not improve from 0.19903\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0899 - loss: 0.1858 - mae: 0.2863 - mse: 0.1982 - pearson_correlation: 2.8706e-16 - r2_keras: -76.2179 - rmse: 0.8360 - sae: 1823.9166 - sse: 2097.2878 - val_huber_loss: 0.1092 - val_loss: 0.2012 - val_mae: 0.3056 - val_mse: 0.2440 - val_pearson_correlation: 5.8531e-17 - val_r2_keras: -32.5134 - val_rmse: 0.9427 - val_sae: 360.0444 - val_sse: 470.1295 - learning_rate: 0.1000\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0938 - loss: 0.1858 - mae: 0.2893 - mse: 0.2007 - pearson_correlation: 4.0571e-16 - r2_keras: -92.3579 - rmse: 0.8408 - sae: 2505.5024 - sse: 2895.8457\n","Epoch 19: val_loss did not improve from 0.19903\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0846 - loss: 0.1802 - mae: 0.2760 - mse: 0.1870 - pearson_correlation: 2.7905e-16 - r2_keras: -76.3242 - rmse: 0.8348 - sae: 1830.2029 - sse: 2107.5183 - val_huber_loss: 0.1076 - val_loss: 0.1993 - val_mae: 0.3010 - val_mse: 0.2385 - val_pearson_correlation: -3.1731e-16 - val_r2_keras: -33.2188 - val_rmse: 0.9526 - val_sae: 364.1990 - val_sse: 480.0249 - learning_rate: 0.1000\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0911 - loss: 0.1829 - mae: 0.2776 - mse: 0.1956 - pearson_correlation: -5.7275e-17 - r2_keras: -96.8002 - rmse: 0.8606 - sae: 2552.9307 - sse: 3033.6392\n","Epoch 20: val_loss did not improve from 0.19903\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0841 - loss: 0.1786 - mae: 0.2731 - mse: 0.1845 - pearson_correlation: -2.1528e-17 - r2_keras: -78.9371 - rmse: 0.8448 - sae: 1860.1699 - sse: 2195.2910 - val_huber_loss: 0.1083 - val_loss: 0.1998 - val_mae: 0.2980 - val_mse: 0.2369 - val_pearson_correlation: 1.7941e-16 - val_r2_keras: -34.9451 - val_rmse: 0.9763 - val_sae: 374.9493 - val_sse: 504.2418 - learning_rate: 0.1000\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1048 - loss: 0.1964 - mae: 0.2906 - mse: 0.2264 - pearson_correlation: -3.7072e-16 - r2_keras: -109.5587 - rmse: 0.9150 - sae: 2672.1738 - sse: 3429.3926\n","Epoch 21: val_loss improved from 0.19903 to 0.19838, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0906 - loss: 0.1878 - mae: 0.2773 - mse: 0.2058 - pearson_correlation: -3.0843e-16 - r2_keras: -88.6933 - rmse: 0.8924 - sae: 1947.2435 - sse: 2473.7959 - val_huber_loss: 0.1069 - val_loss: 0.1984 - val_mae: 0.2957 - val_mse: 0.2362 - val_pearson_correlation: -4.4788e-17 - val_r2_keras: -33.4916 - val_rmse: 0.9564 - val_sae: 364.2429 - val_sse: 483.8520 - learning_rate: 0.0200\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0912 - loss: 0.1827 - mae: 0.2734 - mse: 0.1953 - pearson_correlation: 5.4676e-16 - r2_keras: -98.8275 - rmse: 0.8695 - sae: 2558.6050 - sse: 3096.5249\n","Epoch 22: val_loss improved from 0.19838 to 0.19757, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0804 - loss: 0.1761 - mae: 0.2616 - mse: 0.1795 - pearson_correlation: 4.2258e-16 - r2_keras: -80.9015 - rmse: 0.8563 - sae: 1868.0713 - sse: 2244.4041 - val_huber_loss: 0.1061 - val_loss: 0.1976 - val_mae: 0.2943 - val_mse: 0.2348 - val_pearson_correlation: -2.5024e-16 - val_r2_keras: -33.1354 - val_rmse: 0.9514 - val_sae: 361.8235 - val_sse: 478.8549 - learning_rate: 0.0200\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0882 - loss: 0.1797 - mae: 0.2700 - mse: 0.1884 - pearson_correlation: 6.7878e-17 - r2_keras: -96.0605 - rmse: 0.8573 - sae: 2529.4146 - sse: 3010.6963\n","Epoch 23: val_loss improved from 0.19757 to 0.19715, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0784 - loss: 0.1737 - mae: 0.2596 - mse: 0.1740 - pearson_correlation: 1.2887e-16 - r2_keras: -78.9240 - rmse: 0.8470 - sae: 1847.7845 - sse: 2185.6262 - val_huber_loss: 0.1057 - val_loss: 0.1971 - val_mae: 0.2939 - val_mse: 0.2340 - val_pearson_correlation: -3.3003e-16 - val_r2_keras: -33.1242 - val_rmse: 0.9513 - val_sae: 361.6609 - val_sse: 478.6984 - learning_rate: 0.0200\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0873 - loss: 0.1787 - mae: 0.2679 - mse: 0.1861 - pearson_correlation: 4.4467e-16 - r2_keras: -95.7304 - rmse: 0.8559 - sae: 2525.1868 - sse: 3000.4573\n","Epoch 24: val_loss improved from 0.19715 to 0.19689, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0777 - loss: 0.1729 - mae: 0.2578 - mse: 0.1721 - pearson_correlation: 2.5070e-16 - r2_keras: -78.7149 - rmse: 0.8462 - sae: 1844.9027 - sse: 2178.9285 - val_huber_loss: 0.1055 - val_loss: 0.1969 - val_mae: 0.2932 - val_mse: 0.2340 - val_pearson_correlation: -2.2888e-17 - val_r2_keras: -33.0024 - val_rmse: 0.9496 - val_sae: 360.7578 - val_sse: 476.9899 - learning_rate: 0.0200\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0867 - loss: 0.1781 - mae: 0.2670 - mse: 0.1848 - pearson_correlation: -3.3155e-16 - r2_keras: -95.3275 - rmse: 0.8541 - sae: 2520.4541 - sse: 2987.9590\n","Epoch 25: val_loss improved from 0.19689 to 0.19642, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0774 - loss: 0.1724 - mae: 0.2571 - mse: 0.1711 - pearson_correlation: -2.1208e-16 - r2_keras: -78.4409 - rmse: 0.8449 - sae: 1841.6945 - sse: 2170.5339 - val_huber_loss: 0.1051 - val_loss: 0.1964 - val_mae: 0.2927 - val_mse: 0.2328 - val_pearson_correlation: 1.1390e-16 - val_r2_keras: -33.1071 - val_rmse: 0.9510 - val_sae: 361.3522 - val_sse: 478.4587 - learning_rate: 0.0200\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0862 - loss: 0.1776 - mae: 0.2657 - mse: 0.1835 - pearson_correlation: 1.2911e-16 - r2_keras: -95.6359 - rmse: 0.8555 - sae: 2523.6680 - sse: 2997.5256\n","Epoch 26: val_loss improved from 0.19642 to 0.19568, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0770 - loss: 0.1719 - mae: 0.2559 - mse: 0.1700 - pearson_correlation: 6.6224e-17 - r2_keras: -78.6769 - rmse: 0.8461 - sae: 1843.9666 - sse: 2177.2686 - val_huber_loss: 0.1044 - val_loss: 0.1957 - val_mae: 0.2915 - val_mse: 0.2310 - val_pearson_correlation: -1.4806e-16 - val_r2_keras: -33.1093 - val_rmse: 0.9511 - val_sae: 361.5177 - val_sse: 478.4890 - learning_rate: 0.0200\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0858 - loss: 0.1771 - mae: 0.2650 - mse: 0.1825 - pearson_correlation: -1.6298e-16 - r2_keras: -95.6247 - rmse: 0.8554 - sae: 2523.3840 - sse: 2997.1782\n","Epoch 27: val_loss did not improve from 0.19568\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0767 - loss: 0.1715 - mae: 0.2553 - mse: 0.1691 - pearson_correlation: -1.8508e-16 - r2_keras: -78.6683 - rmse: 0.8461 - sae: 1843.7489 - sse: 2177.0234 - val_huber_loss: 0.1048 - val_loss: 0.1960 - val_mae: 0.2912 - val_mse: 0.2321 - val_pearson_correlation: 5.6740e-17 - val_r2_keras: -33.1921 - val_rmse: 0.9522 - val_sae: 361.6932 - val_sse: 479.6510 - learning_rate: 0.0200\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0856 - loss: 0.1769 - mae: 0.2641 - mse: 0.1821 - pearson_correlation: 1.5060e-16 - r2_keras: -95.6904 - rmse: 0.8557 - sae: 2523.6956 - sse: 2999.2153\n","Epoch 28: val_loss improved from 0.19568 to 0.19554, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0764 - loss: 0.1713 - mae: 0.2544 - mse: 0.1687 - pearson_correlation: 1.5476e-16 - r2_keras: -78.7618 - rmse: 0.8467 - sae: 1844.1873 - sse: 2178.9646 - val_huber_loss: 0.1043 - val_loss: 0.1955 - val_mae: 0.2904 - val_mse: 0.2311 - val_pearson_correlation: -3.4097e-17 - val_r2_keras: -33.1583 - val_rmse: 0.9517 - val_sae: 361.5075 - val_sse: 479.1765 - learning_rate: 0.0200\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0853 - loss: 0.1765 - mae: 0.2637 - mse: 0.1813 - pearson_correlation: 3.8139e-16 - r2_keras: -95.5776 - rmse: 0.8552 - sae: 2522.3838 - sse: 2995.7148\n","Epoch 29: val_loss improved from 0.19554 to 0.19543, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0762 - loss: 0.1710 - mae: 0.2541 - mse: 0.1681 - pearson_correlation: 3.1365e-16 - r2_keras: -78.6695 - rmse: 0.8462 - sae: 1843.2776 - sse: 2176.4302 - val_huber_loss: 0.1043 - val_loss: 0.1954 - val_mae: 0.2905 - val_mse: 0.2305 - val_pearson_correlation: -1.8089e-16 - val_r2_keras: -33.2748 - val_rmse: 0.9534 - val_sae: 362.3608 - val_sse: 480.8106 - learning_rate: 0.0200\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0850 - loss: 0.1762 - mae: 0.2629 - mse: 0.1805 - pearson_correlation: -4.9070e-16 - r2_keras: -95.9316 - rmse: 0.8568 - sae: 2526.3105 - sse: 3006.6978\n","Epoch 30: val_loss improved from 0.19543 to 0.19540, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0759 - loss: 0.1706 - mae: 0.2532 - mse: 0.1673 - pearson_correlation: -3.0741e-16 - r2_keras: -78.9484 - rmse: 0.8477 - sae: 1846.0768 - sse: 2184.2549 - val_huber_loss: 0.1043 - val_loss: 0.1954 - val_mae: 0.2898 - val_mse: 0.2310 - val_pearson_correlation: 2.2719e-17 - val_r2_keras: -33.1711 - val_rmse: 0.9519 - val_sae: 361.5074 - val_sse: 479.3560 - learning_rate: 0.0200\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0848 - loss: 0.1759 - mae: 0.2627 - mse: 0.1800 - pearson_correlation: -1.7872e-16 - r2_keras: -95.5994 - rmse: 0.8553 - sae: 2522.6555 - sse: 2996.3928\n","Epoch 31: val_loss did not improve from 0.19540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0757 - loss: 0.1704 - mae: 0.2531 - mse: 0.1668 - pearson_correlation: -1.2803e-16 - r2_keras: -78.7221 - rmse: 0.8466 - sae: 1843.6478 - sse: 2177.3286 - val_huber_loss: 0.1045 - val_loss: 0.1956 - val_mae: 0.2897 - val_mse: 0.2315 - val_pearson_correlation: 2.2637e-16 - val_r2_keras: -33.2515 - val_rmse: 0.9530 - val_sae: 361.9540 - val_sse: 480.4842 - learning_rate: 0.0200\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0846 - loss: 0.1757 - mae: 0.2619 - mse: 0.1797 - pearson_correlation: -2.5944e-16 - r2_keras: -95.8009 - rmse: 0.8562 - sae: 2524.5085 - sse: 3002.6426\n","Epoch 32: val_loss improved from 0.19540 to 0.19477, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0755 - loss: 0.1701 - mae: 0.2523 - mse: 0.1664 - pearson_correlation: -1.1404e-16 - r2_keras: -78.9128 - rmse: 0.8477 - sae: 1845.1438 - sse: 2182.1562 - val_huber_loss: 0.1037 - val_loss: 0.1948 - val_mae: 0.2885 - val_mse: 0.2294 - val_pearson_correlation: -3.6240e-16 - val_r2_keras: -33.2380 - val_rmse: 0.9529 - val_sae: 362.0550 - val_sse: 480.2942 - learning_rate: 0.0200\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0842 - loss: 0.1753 - mae: 0.2614 - mse: 0.1787 - pearson_correlation: -2.3235e-16 - r2_keras: -95.8578 - rmse: 0.8564 - sae: 2525.0977 - sse: 3004.4067\n","Epoch 33: val_loss did not improve from 0.19477\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0752 - loss: 0.1698 - mae: 0.2520 - mse: 0.1657 - pearson_correlation: -1.9830e-16 - r2_keras: -78.9002 - rmse: 0.8475 - sae: 1845.3696 - sse: 2182.7395 - val_huber_loss: 0.1044 - val_loss: 0.1954 - val_mae: 0.2896 - val_mse: 0.2312 - val_pearson_correlation: -3.3895e-17 - val_r2_keras: -33.2914 - val_rmse: 0.9536 - val_sae: 362.2784 - val_sse: 481.0435 - learning_rate: 0.0200\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0841 - loss: 0.1751 - mae: 0.2611 - mse: 0.1782 - pearson_correlation: -2.5235e-17 - r2_keras: -96.0197 - rmse: 0.8572 - sae: 2527.5852 - sse: 3009.4292\n","Epoch 34: val_loss did not improve from 0.19477\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0750 - loss: 0.1696 - mae: 0.2514 - mse: 0.1651 - pearson_correlation: -5.1099e-17 - r2_keras: -79.0921 - rmse: 0.8487 - sae: 1847.3988 - sse: 2187.0728 - val_huber_loss: 0.1040 - val_loss: 0.1949 - val_mae: 0.2882 - val_mse: 0.2301 - val_pearson_correlation: -3.2834e-16 - val_r2_keras: -33.2454 - val_rmse: 0.9530 - val_sae: 361.9890 - val_sse: 480.3978 - learning_rate: 0.0200\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0838 - loss: 0.1748 - mae: 0.2608 - mse: 0.1776 - pearson_correlation: -3.0741e-16 - r2_keras: -95.8362 - rmse: 0.8563 - sae: 2525.5620 - sse: 3003.7371\n","Epoch 35: val_loss did not improve from 0.19477\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0748 - loss: 0.1693 - mae: 0.2513 - mse: 0.1646 - pearson_correlation: -9.8892e-17 - r2_keras: -78.9376 - rmse: 0.8479 - sae: 1845.9626 - sse: 2182.9014 - val_huber_loss: 0.1039 - val_loss: 0.1948 - val_mae: 0.2878 - val_mse: 0.2299 - val_pearson_correlation: -2.2581e-16 - val_r2_keras: -33.3070 - val_rmse: 0.9538 - val_sae: 362.2410 - val_sse: 481.2619 - learning_rate: 0.0200\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0836 - loss: 0.1745 - mae: 0.2600 - mse: 0.1771 - pearson_correlation: -2.2045e-16 - r2_keras: -96.1496 - rmse: 0.8577 - sae: 2528.2388 - sse: 3013.4590\n","Epoch 36: val_loss improved from 0.19477 to 0.19454, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0746 - loss: 0.1690 - mae: 0.2504 - mse: 0.1641 - pearson_correlation: -7.1826e-17 - r2_keras: -79.2218 - rmse: 0.8495 - sae: 1848.0588 - sse: 2190.2651 - val_huber_loss: 0.1037 - val_loss: 0.1945 - val_mae: 0.2870 - val_mse: 0.2294 - val_pearson_correlation: -2.2611e-17 - val_r2_keras: -33.2782 - val_rmse: 0.9534 - val_sae: 362.1132 - val_sse: 480.8578 - learning_rate: 0.0200\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0834 - loss: 0.1742 - mae: 0.2597 - mse: 0.1766 - pearson_correlation: -3.2416e-17 - r2_keras: -95.9884 - rmse: 0.8570 - sae: 2526.6470 - sse: 3008.4583\n","Epoch 37: val_loss improved from 0.19454 to 0.19441, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0744 - loss: 0.1688 - mae: 0.2503 - mse: 0.1637 - pearson_correlation: 1.3108e-16 - r2_keras: -79.0773 - rmse: 0.8486 - sae: 1846.9077 - sse: 2186.4973 - val_huber_loss: 0.1036 - val_loss: 0.1944 - val_mae: 0.2866 - val_mse: 0.2290 - val_pearson_correlation: -3.3775e-16 - val_r2_keras: -33.3720 - val_rmse: 0.9547 - val_sae: 362.5883 - val_sse: 482.1735 - learning_rate: 0.0200\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0832 - loss: 0.1740 - mae: 0.2590 - mse: 0.1761 - pearson_correlation: 2.0922e-16 - r2_keras: -96.3574 - rmse: 0.8587 - sae: 2530.4019 - sse: 3019.9062\n","Epoch 38: val_loss improved from 0.19441 to 0.19431, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0742 - loss: 0.1685 - mae: 0.2496 - mse: 0.1632 - pearson_correlation: 1.3656e-16 - r2_keras: -79.3953 - rmse: 0.8504 - sae: 1849.7432 - sse: 2194.9734 - val_huber_loss: 0.1035 - val_loss: 0.1943 - val_mae: 0.2866 - val_mse: 0.2289 - val_pearson_correlation: -2.4823e-16 - val_r2_keras: -33.3222 - val_rmse: 0.9540 - val_sae: 362.4450 - val_sse: 481.4753 - learning_rate: 0.0200\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0829 - loss: 0.1737 - mae: 0.2590 - mse: 0.1753 - pearson_correlation: -3.9661e-16 - r2_keras: -96.2770 - rmse: 0.8583 - sae: 2530.3210 - sse: 3017.4106\n","Epoch 39: val_loss did not improve from 0.19431\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1682 - mae: 0.2496 - mse: 0.1625 - pearson_correlation: -2.4583e-16 - r2_keras: -79.2834 - rmse: 0.8496 - sae: 1849.4437 - sse: 2192.6265 - val_huber_loss: 0.1037 - val_loss: 0.1944 - val_mae: 0.2864 - val_mse: 0.2293 - val_pearson_correlation: -2.3630e-16 - val_r2_keras: -33.3842 - val_rmse: 0.9549 - val_sae: 362.6895 - val_sse: 482.3459 - learning_rate: 0.0200\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0828 - loss: 0.1735 - mae: 0.2583 - mse: 0.1750 - pearson_correlation: 1.7465e-16 - r2_keras: -96.5395 - rmse: 0.8595 - sae: 2532.5752 - sse: 3025.5527\n","Epoch 40: val_loss improved from 0.19431 to 0.19402, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0738 - loss: 0.1680 - mae: 0.2487 - mse: 0.1621 - pearson_correlation: 7.1823e-17 - r2_keras: -79.5572 - rmse: 0.8513 - sae: 1851.3662 - sse: 2199.2126 - val_huber_loss: 0.1033 - val_loss: 0.1940 - val_mae: 0.2854 - val_mse: 0.2286 - val_pearson_correlation: 2.5961e-16 - val_r2_keras: -33.3144 - val_rmse: 0.9539 - val_sae: 362.2744 - val_sse: 481.3656 - learning_rate: 0.0200\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0825 - loss: 0.1732 - mae: 0.2583 - mse: 0.1743 - pearson_correlation: -5.7975e-17 - r2_keras: -96.3435 - rmse: 0.8586 - sae: 2530.6392 - sse: 3019.4746\n","Epoch 41: val_loss did not improve from 0.19402\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0735 - loss: 0.1677 - mae: 0.2488 - mse: 0.1615 - pearson_correlation: -8.1565e-17 - r2_keras: -79.3566 - rmse: 0.8501 - sae: 1849.8287 - sse: 2194.3406 - val_huber_loss: 0.1039 - val_loss: 0.1945 - val_mae: 0.2862 - val_mse: 0.2301 - val_pearson_correlation: -5.6355e-17 - val_r2_keras: -33.3476 - val_rmse: 0.9544 - val_sae: 362.3900 - val_sse: 481.8322 - learning_rate: 0.0200\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0824 - loss: 0.1731 - mae: 0.2577 - mse: 0.1741 - pearson_correlation: -3.6535e-16 - r2_keras: -96.6021 - rmse: 0.8597 - sae: 2533.3975 - sse: 3027.4961\n","Epoch 42: val_loss did not improve from 0.19402\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0734 - loss: 0.1676 - mae: 0.2481 - mse: 0.1612 - pearson_correlation: -1.1672e-16 - r2_keras: -79.6185 - rmse: 0.8516 - sae: 1852.0266 - sse: 2200.7375 - val_huber_loss: 0.1036 - val_loss: 0.1942 - val_mae: 0.2852 - val_mse: 0.2296 - val_pearson_correlation: -1.2408e-16 - val_r2_keras: -33.3316 - val_rmse: 0.9542 - val_sae: 362.3399 - val_sse: 481.6071 - learning_rate: 0.0200\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0822 - loss: 0.1728 - mae: 0.2577 - mse: 0.1737 - pearson_correlation: -2.5272e-16 - r2_keras: -96.4125 - rmse: 0.8589 - sae: 2531.6753 - sse: 3021.6135\n","Epoch 43: val_loss did not improve from 0.19402\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0732 - loss: 0.1674 - mae: 0.2481 - mse: 0.1608 - pearson_correlation: -1.7626e-16 - r2_keras: -79.4466 - rmse: 0.8507 - sae: 1850.7290 - sse: 2196.2822 - val_huber_loss: 0.1038 - val_loss: 0.1944 - val_mae: 0.2857 - val_mse: 0.2298 - val_pearson_correlation: -3.5953e-16 - val_r2_keras: -33.4194 - val_rmse: 0.9554 - val_sae: 362.9394 - val_sse: 482.8392 - learning_rate: 0.0200\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0820 - loss: 0.1726 - mae: 0.2571 - mse: 0.1731 - pearson_correlation: -5.3148e-16 - r2_keras: -96.8397 - rmse: 0.8608 - sae: 2536.6660 - sse: 3034.8643\n","Epoch 44: val_loss did not improve from 0.19402\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0730 - loss: 0.1671 - mae: 0.2474 - mse: 0.1603 - pearson_correlation: -3.2629e-16 - r2_keras: -79.7966 - rmse: 0.8525 - sae: 1854.3447 - sse: 2205.8811 - val_huber_loss: 0.1036 - val_loss: 0.1941 - val_mae: 0.2853 - val_mse: 0.2295 - val_pearson_correlation: -4.5232e-17 - val_r2_keras: -33.2731 - val_rmse: 0.9533 - val_sae: 362.0893 - val_sse: 480.7868 - learning_rate: 0.0200\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0819 - loss: 0.1724 - mae: 0.2573 - mse: 0.1726 - pearson_correlation: -7.4644e-16 - r2_keras: -96.6040 - rmse: 0.8597 - sae: 2534.1372 - sse: 3027.5542\n","Epoch 45: val_loss did not improve from 0.19402\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0728 - loss: 0.1669 - mae: 0.2475 - mse: 0.1598 - pearson_correlation: -5.3541e-16 - r2_keras: -79.6104 - rmse: 0.8516 - sae: 1852.5792 - sse: 2200.6670 - val_huber_loss: 0.1038 - val_loss: 0.1942 - val_mae: 0.2848 - val_mse: 0.2298 - val_pearson_correlation: -1.4604e-16 - val_r2_keras: -33.4213 - val_rmse: 0.9554 - val_sae: 362.9063 - val_sse: 482.8655 - learning_rate: 0.0200\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0818 - loss: 0.1722 - mae: 0.2565 - mse: 0.1724 - pearson_correlation: -4.0569e-17 - r2_keras: -96.9294 - rmse: 0.8612 - sae: 2537.6658 - sse: 3037.6470\n","Epoch 46: val_loss did not improve from 0.19402\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0725 - loss: 0.1666 - mae: 0.2465 - mse: 0.1593 - pearson_correlation: -1.0672e-16 - r2_keras: -79.9419 - rmse: 0.8535 - sae: 1855.6106 - sse: 2208.7390 - val_huber_loss: 0.1036 - val_loss: 0.1941 - val_mae: 0.2846 - val_mse: 0.2295 - val_pearson_correlation: -1.5722e-16 - val_r2_keras: -33.4298 - val_rmse: 0.9555 - val_sae: 363.0074 - val_sse: 482.9845 - learning_rate: 0.0040\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0817 - loss: 0.1721 - mae: 0.2565 - mse: 0.1722 - pearson_correlation: 3.8082e-16 - r2_keras: -96.8706 - rmse: 0.8609 - sae: 2536.9185 - sse: 3035.8235\n","Epoch 47: val_loss improved from 0.19402 to 0.19398, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0724 - loss: 0.1665 - mae: 0.2465 - mse: 0.1591 - pearson_correlation: 3.2115e-16 - r2_keras: -79.8892 - rmse: 0.8532 - sae: 1855.0466 - sse: 2207.3647 - val_huber_loss: 0.1035 - val_loss: 0.1940 - val_mae: 0.2844 - val_mse: 0.2292 - val_pearson_correlation: -1.2355e-16 - val_r2_keras: -33.4266 - val_rmse: 0.9555 - val_sae: 363.0216 - val_sse: 482.9398 - learning_rate: 0.0040\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0816 - loss: 0.1721 - mae: 0.2565 - mse: 0.1720 - pearson_correlation: -4.9247e-17 - r2_keras: -96.8297 - rmse: 0.8607 - sae: 2536.4102 - sse: 3034.5542\n","Epoch 48: val_loss improved from 0.19398 to 0.19390, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0723 - loss: 0.1664 - mae: 0.2465 - mse: 0.1589 - pearson_correlation: -9.1512e-17 - r2_keras: -79.8482 - rmse: 0.8530 - sae: 1854.6473 - sse: 2206.3574 - val_huber_loss: 0.1035 - val_loss: 0.1939 - val_mae: 0.2843 - val_mse: 0.2290 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4317 - val_rmse: 0.9555 - val_sae: 363.0706 - val_sse: 483.0117 - learning_rate: 0.0040\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0815 - loss: 0.1720 - mae: 0.2564 - mse: 0.1718 - pearson_correlation: 1.2901e-16 - r2_keras: -96.8061 - rmse: 0.8606 - sae: 2536.1116 - sse: 3033.8228\n","Epoch 49: val_loss improved from 0.19390 to 0.19381, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0723 - loss: 0.1663 - mae: 0.2464 - mse: 0.1587 - pearson_correlation: 1.1586e-16 - r2_keras: -79.8204 - rmse: 0.8528 - sae: 1854.3997 - sse: 2205.7292 - val_huber_loss: 0.1034 - val_loss: 0.1938 - val_mae: 0.2841 - val_mse: 0.2289 - val_pearson_correlation: 1.1233e-16 - val_r2_keras: -33.4245 - val_rmse: 0.9554 - val_sae: 363.0285 - val_sse: 482.9103 - learning_rate: 0.0040\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0815 - loss: 0.1719 - mae: 0.2563 - mse: 0.1716 - pearson_correlation: -6.9850e-16 - r2_keras: -96.7892 - rmse: 0.8606 - sae: 2535.8552 - sse: 3033.2974\n","Epoch 50: val_loss improved from 0.19381 to 0.19379, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0722 - loss: 0.1663 - mae: 0.2464 - mse: 0.1586 - pearson_correlation: -3.8471e-16 - r2_keras: -79.7984 - rmse: 0.8527 - sae: 1854.1882 - sse: 2205.2527 - val_huber_loss: 0.1034 - val_loss: 0.1938 - val_mae: 0.2841 - val_mse: 0.2288 - val_pearson_correlation: -3.3676e-17 - val_r2_keras: -33.4407 - val_rmse: 0.9557 - val_sae: 363.1172 - val_sse: 483.1385 - learning_rate: 0.0040\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0814 - loss: 0.1718 - mae: 0.2562 - mse: 0.1715 - pearson_correlation: 1.5941e-16 - r2_keras: -96.8395 - rmse: 0.8608 - sae: 2536.3333 - sse: 3034.8584\n","Epoch 51: val_loss improved from 0.19379 to 0.19372, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0722 - loss: 0.1662 - mae: 0.2462 - mse: 0.1585 - pearson_correlation: 1.9632e-17 - r2_keras: -79.8451 - rmse: 0.8529 - sae: 1854.5526 - sse: 2206.4482 - val_huber_loss: 0.1033 - val_loss: 0.1937 - val_mae: 0.2840 - val_mse: 0.2287 - val_pearson_correlation: 1.3477e-16 - val_r2_keras: -33.4291 - val_rmse: 0.9555 - val_sae: 363.0441 - val_sse: 482.9748 - learning_rate: 0.0040\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0814 - loss: 0.1718 - mae: 0.2561 - mse: 0.1713 - pearson_correlation: 4.8018e-17 - r2_keras: -96.8275 - rmse: 0.8607 - sae: 2536.1914 - sse: 3034.4856\n","Epoch 52: val_loss improved from 0.19372 to 0.19369, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0721 - loss: 0.1662 - mae: 0.2462 - mse: 0.1584 - pearson_correlation: 4.1645e-17 - r2_keras: -79.8294 - rmse: 0.8528 - sae: 1854.4340 - sse: 2206.1084 - val_huber_loss: 0.1033 - val_loss: 0.1937 - val_mae: 0.2837 - val_mse: 0.2286 - val_pearson_correlation: -7.8592e-17 - val_r2_keras: -33.4370 - val_rmse: 0.9556 - val_sae: 363.0400 - val_sse: 483.0861 - learning_rate: 0.0040\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0813 - loss: 0.1717 - mae: 0.2560 - mse: 0.1713 - pearson_correlation: 3.2711e-16 - r2_keras: -96.8447 - rmse: 0.8608 - sae: 2536.1372 - sse: 3035.0190\n","Epoch 53: val_loss improved from 0.19369 to 0.19365, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0721 - loss: 0.1661 - mae: 0.2461 - mse: 0.1583 - pearson_correlation: 1.8728e-16 - r2_keras: -79.8530 - rmse: 0.8530 - sae: 1854.4391 - sse: 2206.6074 - val_huber_loss: 0.1032 - val_loss: 0.1937 - val_mae: 0.2837 - val_mse: 0.2286 - val_pearson_correlation: -2.3584e-16 - val_r2_keras: -33.4307 - val_rmse: 0.9555 - val_sae: 363.0294 - val_sse: 482.9971 - learning_rate: 0.0040\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0813 - loss: 0.1717 - mae: 0.2559 - mse: 0.1711 - pearson_correlation: 4.6123e-16 - r2_keras: -96.8520 - rmse: 0.8608 - sae: 2536.3022 - sse: 3035.2480\n","Epoch 54: val_loss improved from 0.19365 to 0.19365, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0720 - loss: 0.1661 - mae: 0.2460 - mse: 0.1582 - pearson_correlation: 3.0075e-16 - r2_keras: -79.8465 - rmse: 0.8529 - sae: 1854.5072 - sse: 2206.6252 - val_huber_loss: 0.1033 - val_loss: 0.1936 - val_mae: 0.2837 - val_mse: 0.2286 - val_pearson_correlation: 8.9804e-17 - val_r2_keras: -33.4410 - val_rmse: 0.9557 - val_sae: 363.0813 - val_sse: 483.1416 - learning_rate: 0.0040\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0812 - loss: 0.1716 - mae: 0.2558 - mse: 0.1710 - pearson_correlation: -1.0147e-16 - r2_keras: -96.9005 - rmse: 0.8610 - sae: 2536.7739 - sse: 3036.7512\n","Epoch 55: val_loss improved from 0.19365 to 0.19356, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0720 - loss: 0.1660 - mae: 0.2459 - mse: 0.1581 - pearson_correlation: -1.4460e-16 - r2_keras: -79.8962 - rmse: 0.8532 - sae: 1854.8927 - sse: 2207.8318 - val_huber_loss: 0.1032 - val_loss: 0.1936 - val_mae: 0.2835 - val_mse: 0.2284 - val_pearson_correlation: 1.1232e-16 - val_r2_keras: -33.4280 - val_rmse: 0.9555 - val_sae: 362.9820 - val_sse: 482.9603 - learning_rate: 0.0040\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0812 - loss: 0.1716 - mae: 0.2557 - mse: 0.1709 - pearson_correlation: 4.4045e-16 - r2_keras: -96.8779 - rmse: 0.8609 - sae: 2536.3701 - sse: 3036.0508\n","Epoch 56: val_loss did not improve from 0.19356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0720 - loss: 0.1660 - mae: 0.2458 - mse: 0.1580 - pearson_correlation: 2.6668e-16 - r2_keras: -79.8708 - rmse: 0.8531 - sae: 1854.5851 - sse: 2207.2434 - val_huber_loss: 0.1032 - val_loss: 0.1936 - val_mae: 0.2834 - val_mse: 0.2284 - val_pearson_correlation: 6.7350e-17 - val_r2_keras: -33.4419 - val_rmse: 0.9557 - val_sae: 363.0620 - val_sse: 483.1552 - learning_rate: 0.0040\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0811 - loss: 0.1715 - mae: 0.2556 - mse: 0.1708 - pearson_correlation: -1.3891e-16 - r2_keras: -96.9356 - rmse: 0.8612 - sae: 2536.9783 - sse: 3037.8384\n","Epoch 57: val_loss improved from 0.19356 to 0.19352, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0719 - loss: 0.1659 - mae: 0.2457 - mse: 0.1579 - pearson_correlation: -1.1761e-16 - r2_keras: -79.9226 - rmse: 0.8533 - sae: 1855.0417 - sse: 2208.5916 - val_huber_loss: 0.1031 - val_loss: 0.1935 - val_mae: 0.2834 - val_mse: 0.2283 - val_pearson_correlation: -4.9410e-16 - val_r2_keras: -33.4328 - val_rmse: 0.9556 - val_sae: 363.0111 - val_sse: 483.0264 - learning_rate: 0.0040\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0811 - loss: 0.1715 - mae: 0.2556 - mse: 0.1707 - pearson_correlation: 2.3975e-17 - r2_keras: -96.9221 - rmse: 0.8611 - sae: 2536.8433 - sse: 3037.4226\n","Epoch 58: val_loss improved from 0.19352 to 0.19347, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0719 - loss: 0.1659 - mae: 0.2457 - mse: 0.1578 - pearson_correlation: 6.2167e-17 - r2_keras: -79.9077 - rmse: 0.8533 - sae: 1854.9418 - sse: 2208.2451 - val_huber_loss: 0.1031 - val_loss: 0.1935 - val_mae: 0.2832 - val_mse: 0.2282 - val_pearson_correlation: 1.1234e-17 - val_r2_keras: -33.4247 - val_rmse: 0.9554 - val_sae: 362.9645 - val_sse: 482.9131 - learning_rate: 0.0040\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0811 - loss: 0.1714 - mae: 0.2555 - mse: 0.1706 - pearson_correlation: -4.7953e-17 - r2_keras: -96.9181 - rmse: 0.8611 - sae: 2536.7998 - sse: 3037.2969\n","Epoch 59: val_loss improved from 0.19347 to 0.19344, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0719 - loss: 0.1658 - mae: 0.2456 - mse: 0.1577 - pearson_correlation: 4.6184e-18 - r2_keras: -79.8963 - rmse: 0.8532 - sae: 1854.8817 - sse: 2208.0586 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2831 - val_mse: 0.2282 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4380 - val_rmse: 0.9556 - val_sae: 363.0198 - val_sse: 483.0999 - learning_rate: 0.0040\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0810 - loss: 0.1714 - mae: 0.2553 - mse: 0.1705 - pearson_correlation: -5.0951e-16 - r2_keras: -96.9787 - rmse: 0.8614 - sae: 2537.3650 - sse: 3039.1760\n","Epoch 60: val_loss improved from 0.19344 to 0.19340, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0718 - loss: 0.1658 - mae: 0.2455 - mse: 0.1576 - pearson_correlation: -3.2332e-16 - r2_keras: -79.9522 - rmse: 0.8535 - sae: 1855.3209 - sse: 2209.4937 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2831 - val_mse: 0.2281 - val_pearson_correlation: 1.4599e-16 - val_r2_keras: -33.4317 - val_rmse: 0.9555 - val_sae: 362.9941 - val_sse: 483.0116 - learning_rate: 0.0040\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0810 - loss: 0.1713 - mae: 0.2553 - mse: 0.1704 - pearson_correlation: -4.1184e-16 - r2_keras: -96.9803 - rmse: 0.8614 - sae: 2537.4331 - sse: 3039.2275\n","Epoch 61: val_loss did not improve from 0.19340\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0718 - loss: 0.1657 - mae: 0.2454 - mse: 0.1575 - pearson_correlation: -2.6590e-16 - r2_keras: -79.9471 - rmse: 0.8534 - sae: 1855.3467 - sse: 2209.4551 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2829 - val_mse: 0.2282 - val_pearson_correlation: -1.3471e-16 - val_r2_keras: -33.4411 - val_rmse: 0.9557 - val_sae: 363.0130 - val_sse: 483.1440 - learning_rate: 0.0040\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1713 - mae: 0.2552 - mse: 0.1703 - pearson_correlation: -8.5959e-18 - r2_keras: -97.0058 - rmse: 0.8615 - sae: 2537.5642 - sse: 3040.0166\n","Epoch 62: val_loss improved from 0.19340 to 0.19337, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0717 - loss: 0.1657 - mae: 0.2453 - mse: 0.1574 - pearson_correlation: -4.9938e-17 - r2_keras: -79.9781 - rmse: 0.8536 - sae: 1855.4921 - sse: 2210.1460 - val_huber_loss: 0.1030 - val_loss: 0.1934 - val_mae: 0.2829 - val_mse: 0.2281 - val_pearson_correlation: 1.5722e-16 - val_r2_keras: -33.4326 - val_rmse: 0.9556 - val_sae: 362.9893 - val_sse: 483.0242 - learning_rate: 0.0040\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1712 - mae: 0.2551 - mse: 0.1702 - pearson_correlation: 1.2984e-16 - r2_keras: -97.0183 - rmse: 0.8616 - sae: 2537.7571 - sse: 3040.4062\n","Epoch 63: val_loss did not improve from 0.19337\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0717 - loss: 0.1656 - mae: 0.2453 - mse: 0.1573 - pearson_correlation: 1.6062e-16 - r2_keras: -79.9757 - rmse: 0.8536 - sae: 1855.5831 - sse: 2210.2798 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2829 - val_mse: 0.2283 - val_pearson_correlation: 3.9313e-16 - val_r2_keras: -33.4281 - val_rmse: 0.9555 - val_sae: 362.9065 - val_sse: 482.9615 - learning_rate: 0.0040\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0809 - loss: 0.1712 - mae: 0.2550 - mse: 0.1702 - pearson_correlation: 1.3443e-16 - r2_keras: -97.0221 - rmse: 0.8616 - sae: 2537.7246 - sse: 3040.5215\n","Epoch 64: val_loss did not improve from 0.19337\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0717 - loss: 0.1656 - mae: 0.2451 - mse: 0.1572 - pearson_correlation: 9.0582e-17 - r2_keras: -79.9941 - rmse: 0.8537 - sae: 1855.6243 - sse: 2210.5435 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2828 - val_mse: 0.2282 - val_pearson_correlation: -8.9864e-17 - val_r2_keras: -33.4266 - val_rmse: 0.9555 - val_sae: 362.9118 - val_sse: 482.9403 - learning_rate: 0.0040\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2550 - mse: 0.1701 - pearson_correlation: 1.6667e-16 - r2_keras: -97.0172 - rmse: 0.8616 - sae: 2537.6799 - sse: 3040.3721\n","Epoch 65: val_loss did not improve from 0.19337\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0716 - loss: 0.1655 - mae: 0.2451 - mse: 0.1571 - pearson_correlation: 1.0823e-16 - r2_keras: -79.9886 - rmse: 0.8537 - sae: 1855.6249 - sse: 2210.4172 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2828 - val_mse: 0.2282 - val_pearson_correlation: 1.0106e-16 - val_r2_keras: -33.4349 - val_rmse: 0.9556 - val_sae: 362.9666 - val_sse: 483.0565 - learning_rate: 8.0000e-04\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2549 - mse: 0.1700 - pearson_correlation: 1.3165e-16 - r2_keras: -97.0301 - rmse: 0.8616 - sae: 2537.7900 - sse: 3040.7720\n","Epoch 66: val_loss improved from 0.19337 to 0.19335, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0716 - loss: 0.1655 - mae: 0.2450 - mse: 0.1571 - pearson_correlation: 5.7031e-17 - r2_keras: -80.0000 - rmse: 0.8538 - sae: 1855.7079 - sse: 2210.7158 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2827 - val_mse: 0.2281 - val_pearson_correlation: -3.4803e-16 - val_r2_keras: -33.4396 - val_rmse: 0.9557 - val_sae: 362.9936 - val_sse: 483.1220 - learning_rate: 8.0000e-04\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2549 - mse: 0.1700 - pearson_correlation: 2.5499e-16 - r2_keras: -97.0381 - rmse: 0.8616 - sae: 2537.8462 - sse: 3041.0193\n","Epoch 67: val_loss improved from 0.19335 to 0.19335, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0716 - loss: 0.1655 - mae: 0.2450 - mse: 0.1571 - pearson_correlation: 1.3446e-16 - r2_keras: -80.0077 - rmse: 0.8538 - sae: 1855.7543 - sse: 2210.9094 - val_huber_loss: 0.1031 - val_loss: 0.1934 - val_mae: 0.2827 - val_mse: 0.2281 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4454 - val_rmse: 0.9557 - val_sae: 363.0324 - val_sse: 483.2038 - learning_rate: 8.0000e-04\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2549 - mse: 0.1700 - pearson_correlation: 1.8132e-16 - r2_keras: -97.0478 - rmse: 0.8617 - sae: 2537.9407 - sse: 3041.3203\n","Epoch 68: val_loss improved from 0.19335 to 0.19334, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0716 - loss: 0.1655 - mae: 0.2450 - mse: 0.1571 - pearson_correlation: 1.1512e-16 - r2_keras: -80.0167 - rmse: 0.8538 - sae: 1855.8274 - sse: 2211.1394 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2281 - val_pearson_correlation: 5.9486e-16 - val_r2_keras: -33.4456 - val_rmse: 0.9557 - val_sae: 363.0417 - val_sse: 483.2064 - learning_rate: 8.0000e-04\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2549 - mse: 0.1700 - pearson_correlation: 3.1294e-17 - r2_keras: -97.0492 - rmse: 0.8617 - sae: 2537.9702 - sse: 3041.3625\n","Epoch 69: val_loss improved from 0.19334 to 0.19333, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0716 - loss: 0.1655 - mae: 0.2450 - mse: 0.1570 - pearson_correlation: -4.5399e-17 - r2_keras: -80.0159 - rmse: 0.8538 - sae: 1855.8419 - sse: 2211.1479 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2281 - val_pearson_correlation: 3.0302e-16 - val_r2_keras: -33.4475 - val_rmse: 0.9558 - val_sae: 363.0471 - val_sse: 483.2331 - learning_rate: 8.0000e-04\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2549 - mse: 0.1699 - pearson_correlation: -7.2857e-16 - r2_keras: -97.0561 - rmse: 0.8617 - sae: 2538.0142 - sse: 3041.5774\n","Epoch 70: val_loss improved from 0.19333 to 0.19332, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0716 - loss: 0.1655 - mae: 0.2449 - mse: 0.1570 - pearson_correlation: -4.9820e-16 - r2_keras: -80.0231 - rmse: 0.8539 - sae: 1855.8807 - sse: 2211.3208 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2280 - val_pearson_correlation: 1.1223e-16 - val_r2_keras: -33.4480 - val_rmse: 0.9558 - val_sae: 363.0574 - val_sse: 483.2396 - learning_rate: 8.0000e-04\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2548 - mse: 0.1699 - pearson_correlation: 1.6841e-16 - r2_keras: -97.0599 - rmse: 0.8617 - sae: 2538.0718 - sse: 3041.6956\n","Epoch 71: val_loss improved from 0.19332 to 0.19332, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1655 - mae: 0.2449 - mse: 0.1570 - pearson_correlation: 1.5260e-16 - r2_keras: -80.0241 - rmse: 0.8539 - sae: 1855.9150 - sse: 2211.3813 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2280 - val_pearson_correlation: 1.1221e-17 - val_r2_keras: -33.4501 - val_rmse: 0.9558 - val_sae: 363.0671 - val_sse: 483.2704 - learning_rate: 8.0000e-04\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0808 - loss: 0.1711 - mae: 0.2548 - mse: 0.1699 - pearson_correlation: -2.4230e-17 - r2_keras: -97.0682 - rmse: 0.8618 - sae: 2538.1538 - sse: 3041.9521\n","Epoch 72: val_loss improved from 0.19332 to 0.19331, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2449 - mse: 0.1570 - pearson_correlation: -6.3195e-17 - r2_keras: -80.0323 - rmse: 0.8539 - sae: 1855.9803 - sse: 2211.5840 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2280 - val_pearson_correlation: 1.3467e-16 - val_r2_keras: -33.4484 - val_rmse: 0.9558 - val_sae: 363.0580 - val_sse: 483.2453 - learning_rate: 8.0000e-04\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0808 - loss: 0.1710 - mae: 0.2548 - mse: 0.1699 - pearson_correlation: 6.7846e-16 - r2_keras: -97.0670 - rmse: 0.8618 - sae: 2538.1470 - sse: 3041.9160\n","Epoch 73: val_loss improved from 0.19331 to 0.19330, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2449 - mse: 0.1570 - pearson_correlation: 4.3503e-16 - r2_keras: -80.0299 - rmse: 0.8539 - sae: 1855.9709 - sse: 2211.5408 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2280 - val_pearson_correlation: 1.6833e-16 - val_r2_keras: -33.4491 - val_rmse: 0.9558 - val_sae: 363.0575 - val_sse: 483.2561 - learning_rate: 8.0000e-04\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1699 - pearson_correlation: -3.0361e-17 - r2_keras: -97.0769 - rmse: 0.8618 - sae: 2538.2302 - sse: 3042.2214\n","Epoch 74: val_loss improved from 0.19330 to 0.19330, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2449 - mse: 0.1569 - pearson_correlation: -5.9599e-17 - r2_keras: -80.0390 - rmse: 0.8540 - sae: 1856.0363 - sse: 2211.7744 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2827 - val_mse: 0.2280 - val_pearson_correlation: 4.0402e-16 - val_r2_keras: -33.4476 - val_rmse: 0.9558 - val_sae: 363.0531 - val_sse: 483.2348 - learning_rate: 8.0000e-04\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: 2.7907e-16 - r2_keras: -97.0774 - rmse: 0.8618 - sae: 2538.2454 - sse: 3042.2383\n","Epoch 75: val_loss improved from 0.19330 to 0.19329, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2449 - mse: 0.1569 - pearson_correlation: 2.4173e-16 - r2_keras: -80.0386 - rmse: 0.8540 - sae: 1856.0507 - sse: 2211.7771 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2280 - val_pearson_correlation: 4.8254e-16 - val_r2_keras: -33.4497 - val_rmse: 0.9558 - val_sae: 363.0642 - val_sse: 483.2635 - learning_rate: 1.6000e-04\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: -3.9345e-16 - r2_keras: -97.0793 - rmse: 0.8618 - sae: 2538.2607 - sse: 3042.2959\n","Epoch 76: val_loss improved from 0.19329 to 0.19329, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.1142e-16 - r2_keras: -80.0404 - rmse: 0.8540 - sae: 1856.0632 - sse: 2211.8220 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2280 - val_pearson_correlation: -2.4686e-16 - val_r2_keras: -33.4512 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.2849 - learning_rate: 1.6000e-04\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: -1.0386e-15 - r2_keras: -97.0812 - rmse: 0.8618 - sae: 2538.2803 - sse: 3042.3569\n","Epoch 77: val_loss improved from 0.19329 to 0.19329, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -6.6171e-16 - r2_keras: -80.0423 - rmse: 0.8540 - sae: 1856.0785 - sse: 2211.8694 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2280 - val_pearson_correlation: -1.3465e-16 - val_r2_keras: -33.4514 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.2881 - learning_rate: 1.6000e-04\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: 2.6373e-16 - r2_keras: -97.0806 - rmse: 0.8618 - sae: 2538.2700 - sse: 3042.3379\n","Epoch 78: val_loss did not improve from 0.19329\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 6.4463e-17 - r2_keras: -80.0415 - rmse: 0.8540 - sae: 1856.0706 - sse: 2211.8525 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2280 - val_pearson_correlation: -6.7323e-17 - val_r2_keras: -33.4523 - val_rmse: 0.9558 - val_sae: 363.0789 - val_sse: 483.3001 - learning_rate: 1.6000e-04\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: -5.4185e-16 - r2_keras: -97.0825 - rmse: 0.8618 - sae: 2538.2891 - sse: 3042.3953\n","Epoch 79: val_loss improved from 0.19329 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.6699e-16 - r2_keras: -80.0433 - rmse: 0.8540 - sae: 1856.0856 - sse: 2211.8977 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2280 - val_pearson_correlation: 8.9764e-17 - val_r2_keras: -33.4523 - val_rmse: 0.9558 - val_sae: 363.0792 - val_sse: 483.3004 - learning_rate: 1.6000e-04\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: -8.1139e-16 - r2_keras: -97.0826 - rmse: 0.8618 - sae: 2538.2917 - sse: 3042.3992\n","Epoch 80: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.7661e-16 - r2_keras: -80.0433 - rmse: 0.8540 - sae: 1856.0886 - sse: 2211.8992 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2280 - val_pearson_correlation: 2.6929e-16 - val_r2_keras: -33.4526 - val_rmse: 0.9558 - val_sae: 363.0813 - val_sse: 483.3052 - learning_rate: 3.2000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: 1.8399e-17 - r2_keras: -97.0825 - rmse: 0.8618 - sae: 2538.2903 - sse: 3042.3962\n","Epoch 81: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.9544e-17 - r2_keras: -80.0432 - rmse: 0.8540 - sae: 1856.0875 - sse: 2211.8965 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0834 - val_sse: 483.3104 - learning_rate: 3.2000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: -9.4447e-17 - r2_keras: -97.0829 - rmse: 0.8618 - sae: 2538.2930 - sse: 3042.4077\n","Epoch 82: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.1847e-17 - r2_keras: -80.0436 - rmse: 0.8540 - sae: 1856.0897 - sse: 2211.9055 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3114 - learning_rate: 3.2000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2548 - mse: 0.1698 - pearson_correlation: -7.7490e-16 - r2_keras: -97.0829 - rmse: 0.8618 - sae: 2538.2932 - sse: 3042.4087\n","Epoch 83: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -5.9723e-16 - r2_keras: -80.0435 - rmse: 0.8540 - sae: 1856.0896 - sse: 2211.9053 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0850 - val_sse: 483.3140 - learning_rate: 3.2000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.8147e-16 - r2_keras: -97.0831 - rmse: 0.8618 - sae: 2538.2954 - sse: 3042.4165\n","Epoch 84: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.7944e-16 - r2_keras: -80.0438 - rmse: 0.8540 - sae: 1856.0914 - sse: 2211.9116 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0850 - val_sse: 483.3138 - learning_rate: 3.2000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.0024e-16 - r2_keras: -97.0832 - rmse: 0.8618 - sae: 2538.2959 - sse: 3042.4180\n","Epoch 85: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 9.7977e-17 - r2_keras: -80.0438 - rmse: 0.8540 - sae: 1856.0919 - sse: 2211.9124 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.5806e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0857 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.6099e-16 - r2_keras: -97.0833 - rmse: 0.8618 - sae: 2538.2964 - sse: 3042.4204\n","Epoch 86: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.2460e-16 - r2_keras: -80.0439 - rmse: 0.8540 - sae: 1856.0924 - sse: 2211.9143 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -7.2062e-17 - r2_keras: -97.0834 - rmse: 0.8618 - sae: 2538.2979 - sse: 3042.4243\n","Epoch 87: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -9.5076e-17 - r2_keras: -80.0440 - rmse: 0.8540 - sae: 1856.0935 - sse: 2211.9175 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -5.1612e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0866 - val_sse: 483.3176 - learning_rate: 1.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.3663e-16 - r2_keras: -97.0835 - rmse: 0.8618 - sae: 2538.2988 - sse: 3042.4277\n","Epoch 88: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.6639e-16 - r2_keras: -80.0441 - rmse: 0.8540 - sae: 1856.0944 - sse: 2211.9202 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0866 - val_sse: 483.3176 - learning_rate: 1.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.6518e-16 - r2_keras: -97.0835 - rmse: 0.8618 - sae: 2538.2983 - sse: 3042.4270\n","Epoch 89: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.6675e-16 - r2_keras: -80.0441 - rmse: 0.8540 - sae: 1856.0939 - sse: 2211.9194 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0870 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.5203e-16 - r2_keras: -97.0836 - rmse: 0.8618 - sae: 2538.3003 - sse: 3042.4316\n","Epoch 90: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.0990e-16 - r2_keras: -80.0442 - rmse: 0.8540 - sae: 1856.0953 - sse: 2211.9229 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0868 - val_sse: 483.3179 - learning_rate: 1.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.3186e-17 - r2_keras: -97.0836 - rmse: 0.8618 - sae: 2538.2998 - sse: 3042.4307\n","Epoch 91: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -8.1743e-17 - r2_keras: -80.0442 - rmse: 0.8540 - sae: 1856.0950 - sse: 2211.9219 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0870 - val_sse: 483.3186 - learning_rate: 1.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.4801e-16 - r2_keras: -97.0837 - rmse: 0.8618 - sae: 2538.3010 - sse: 3042.4346\n","Epoch 92: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.1211e-16 - r2_keras: -80.0443 - rmse: 0.8540 - sae: 1856.0959 - sse: 2211.9250 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0869 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.0146e-16 - r2_keras: -97.0837 - rmse: 0.8618 - sae: 2538.3005 - sse: 3042.4336\n","Epoch 93: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.6311e-16 - r2_keras: -80.0442 - rmse: 0.8540 - sae: 1856.0956 - sse: 2211.9241 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0870 - val_sse: 483.3186 - learning_rate: 1.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.9008e-16 - r2_keras: -97.0838 - rmse: 0.8618 - sae: 2538.3020 - sse: 3042.4382\n","Epoch 94: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.3562e-16 - r2_keras: -80.0444 - rmse: 0.8540 - sae: 1856.0966 - sse: 2211.9275 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0869 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.8692e-16 - r2_keras: -97.0838 - rmse: 0.8618 - sae: 2538.3015 - sse: 3042.4368\n","Epoch 95: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.3351e-16 - r2_keras: -80.0443 - rmse: 0.8540 - sae: 1856.0963 - sse: 2211.9263 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9759e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0870 - val_sse: 483.3187 - learning_rate: 1.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.0412e-16 - r2_keras: -97.0839 - rmse: 0.8618 - sae: 2538.3022 - sse: 3042.4404\n","Epoch 96: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.2264e-16 - r2_keras: -80.0444 - rmse: 0.8540 - sae: 1856.0968 - sse: 2211.9292 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -8.9759e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0869 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.2252e-16 - r2_keras: -97.0839 - rmse: 0.8618 - sae: 2538.3027 - sse: 3042.4404\n","Epoch 97: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.0227e-16 - r2_keras: -80.0444 - rmse: 0.8540 - sae: 1856.0970 - sse: 2211.9290 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0870 - val_sse: 483.3186 - learning_rate: 1.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.2477e-16 - r2_keras: -97.0840 - rmse: 0.8618 - sae: 2538.3040 - sse: 3042.4443\n","Epoch 98: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -9.6092e-17 - r2_keras: -80.0445 - rmse: 0.8540 - sae: 1856.0980 - sse: 2211.9319 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.6002e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0868 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.5165e-16 - r2_keras: -97.0840 - rmse: 0.8618 - sae: 2538.3032 - sse: 3042.4429\n","Epoch 99: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.7737e-16 - r2_keras: -80.0445 - rmse: 0.8540 - sae: 1856.0975 - sse: 2211.9307 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0869 - val_sse: 483.3187 - learning_rate: 1.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.0269e-16 - r2_keras: -97.0841 - rmse: 0.8618 - sae: 2538.3040 - sse: 3042.4458\n","Epoch 100: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.4953e-16 - r2_keras: -80.0446 - rmse: 0.8540 - sae: 1856.0981 - sse: 2211.9331 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0869 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.2967e-16 - r2_keras: -97.0841 - rmse: 0.8618 - sae: 2538.3042 - sse: 3042.4460\n","Epoch 101: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.0512e-16 - r2_keras: -80.0446 - rmse: 0.8540 - sae: 1856.0983 - sse: 2211.9331 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0868 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.8211e-17 - r2_keras: -97.0841 - rmse: 0.8618 - sae: 2538.3047 - sse: 3042.4468\n","Epoch 102: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -5.8944e-17 - r2_keras: -80.0446 - rmse: 0.8540 - sae: 1856.0985 - sse: 2211.9333 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0868 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.2266e-18 - r2_keras: -97.0842 - rmse: 0.8618 - sae: 2538.3047 - sse: 3042.4485\n","Epoch 103: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -6.1291e-17 - r2_keras: -80.0446 - rmse: 0.8540 - sae: 1856.0986 - sse: 2211.9348 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -7.8539e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0867 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.1921e-16 - r2_keras: -97.0842 - rmse: 0.8619 - sae: 2538.3052 - sse: 3042.4495\n","Epoch 104: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.7616e-16 - r2_keras: -80.0446 - rmse: 0.8540 - sae: 1856.0989 - sse: 2211.9351 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0867 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.4940e-17 - r2_keras: -97.0843 - rmse: 0.8619 - sae: 2538.3062 - sse: 3042.4521\n","Epoch 105: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.4302e-16 - r2_keras: -80.0447 - rmse: 0.8540 - sae: 1856.0997 - sse: 2211.9375 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0867 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.6602e-16 - r2_keras: -97.0843 - rmse: 0.8619 - sae: 2538.3062 - sse: 3042.4517\n","Epoch 106: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.0370e-16 - r2_keras: -80.0447 - rmse: 0.8540 - sae: 1856.0996 - sse: 2211.9368 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0866 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.1802e-16 - r2_keras: -97.0844 - rmse: 0.8619 - sae: 2538.3066 - sse: 3042.4551\n","Epoch 107: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.3095e-16 - r2_keras: -80.0448 - rmse: 0.8540 - sae: 1856.1001 - sse: 2211.9395 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.9840e-16 - r2_keras: -97.0844 - rmse: 0.8619 - sae: 2538.3069 - sse: 3042.4551\n","Epoch 108: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.6202e-16 - r2_keras: -80.0448 - rmse: 0.8540 - sae: 1856.1002 - sse: 2211.9392 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0867 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.3550e-16 - r2_keras: -97.0844 - rmse: 0.8619 - sae: 2538.3071 - sse: 3042.4570\n","Epoch 109: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.6852e-16 - r2_keras: -80.0449 - rmse: 0.8540 - sae: 1856.1005 - sse: 2211.9409 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.9349e-16 - r2_keras: -97.0845 - rmse: 0.8619 - sae: 2538.3076 - sse: 3042.4580\n","Epoch 110: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.0116e-16 - r2_keras: -80.0449 - rmse: 0.8540 - sae: 1856.1007 - sse: 2211.9414 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.3186e-16 - r2_keras: -97.0846 - rmse: 0.8619 - sae: 2538.3081 - sse: 3042.4604\n","Epoch 111: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -5.3347e-17 - r2_keras: -80.0449 - rmse: 0.8540 - sae: 1856.1012 - sse: 2211.9434 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.4524e-16 - r2_keras: -97.0846 - rmse: 0.8619 - sae: 2538.3086 - sse: 3042.4604\n","Epoch 112: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.7763e-16 - r2_keras: -80.0449 - rmse: 0.8540 - sae: 1856.1014 - sse: 2211.9431 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.0702e-16 - r2_keras: -97.0846 - rmse: 0.8619 - sae: 2538.3091 - sse: 3042.4629\n","Epoch 113: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 7.4224e-17 - r2_keras: -80.0450 - rmse: 0.8540 - sae: 1856.1019 - sse: 2211.9451 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0864 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 114/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.6153e-16 - r2_keras: -97.0847 - rmse: 0.8619 - sae: 2538.3091 - sse: 3042.4634\n","Epoch 114: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.6999e-16 - r2_keras: -80.0450 - rmse: 0.8540 - sae: 1856.1018 - sse: 2211.9453 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0866 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 115/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.0664e-19 - r2_keras: -97.0848 - rmse: 0.8619 - sae: 2538.3101 - sse: 3042.4668\n","Epoch 115: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.7231e-17 - r2_keras: -80.0451 - rmse: 0.8540 - sae: 1856.1027 - sse: 2211.9480 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0864 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 116/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.5945e-16 - r2_keras: -97.0848 - rmse: 0.8619 - sae: 2538.3098 - sse: 3042.4666\n","Epoch 116: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -8.3264e-17 - r2_keras: -80.0451 - rmse: 0.8540 - sae: 1856.1024 - sse: 2211.9475 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 117/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.2711e-16 - r2_keras: -97.0848 - rmse: 0.8619 - sae: 2538.3108 - sse: 3042.4688\n","Epoch 117: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.7828e-16 - r2_keras: -80.0452 - rmse: 0.8540 - sae: 1856.1031 - sse: 2211.9495 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3179 - learning_rate: 1.0000e-05\n","Epoch 118/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 6.6847e-17 - r2_keras: -97.0848 - rmse: 0.8619 - sae: 2538.3108 - sse: 3042.4690\n","Epoch 118: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.3046e-17 - r2_keras: -80.0451 - rmse: 0.8540 - sae: 1856.1031 - sse: 2211.9492 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0865 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 119/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.6456e-16 - r2_keras: -97.0849 - rmse: 0.8619 - sae: 2538.3120 - sse: 3042.4719\n","Epoch 119: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.7114e-16 - r2_keras: -80.0452 - rmse: 0.8540 - sae: 1856.1041 - sse: 2211.9517 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0864 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 120/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.4834e-16 - r2_keras: -97.0849 - rmse: 0.8619 - sae: 2538.3120 - sse: 3042.4722\n","Epoch 120: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.7463e-16 - r2_keras: -80.0452 - rmse: 0.8540 - sae: 1856.1040 - sse: 2211.9517 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0864 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 121/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.4394e-17 - r2_keras: -97.0850 - rmse: 0.8619 - sae: 2538.3127 - sse: 3042.4751\n","Epoch 121: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.0451e-17 - r2_keras: -80.0453 - rmse: 0.8540 - sae: 1856.1046 - sse: 2211.9539 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 122/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.2810e-16 - r2_keras: -97.0850 - rmse: 0.8619 - sae: 2538.3127 - sse: 3042.4751\n","Epoch 122: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.5538e-16 - r2_keras: -80.0453 - rmse: 0.8540 - sae: 1856.1046 - sse: 2211.9536 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0864 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 123/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.0646e-17 - r2_keras: -97.0851 - rmse: 0.8619 - sae: 2538.3135 - sse: 3042.4785\n","Epoch 123: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 8.6492e-18 - r2_keras: -80.0454 - rmse: 0.8540 - sae: 1856.1052 - sse: 2211.9563 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 124/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.6472e-17 - r2_keras: -97.0851 - rmse: 0.8619 - sae: 2538.3132 - sse: 3042.4775\n","Epoch 124: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.2377e-16 - r2_keras: -80.0454 - rmse: 0.8540 - sae: 1856.1050 - sse: 2211.9556 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0864 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 125/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.4938e-17 - r2_keras: -97.0852 - rmse: 0.8619 - sae: 2538.3140 - sse: 3042.4810\n","Epoch 125: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.2471e-17 - r2_keras: -80.0455 - rmse: 0.8540 - sae: 1856.1056 - sse: 2211.9583 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -7.8539e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 126/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.7460e-18 - r2_keras: -97.0852 - rmse: 0.8619 - sae: 2538.3145 - sse: 3042.4812\n","Epoch 126: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -7.2649e-17 - r2_keras: -80.0455 - rmse: 0.8540 - sae: 1856.1058 - sse: 2211.9580 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -7.8539e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 127/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.3182e-16 - r2_keras: -97.0853 - rmse: 0.8619 - sae: 2538.3147 - sse: 3042.4832\n","Epoch 127: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.1310e-16 - r2_keras: -80.0455 - rmse: 0.8540 - sae: 1856.1061 - sse: 2211.9597 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 128/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.8663e-16 - r2_keras: -97.0853 - rmse: 0.8619 - sae: 2538.3149 - sse: 3042.4839\n","Epoch 128: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.3899e-16 - r2_keras: -80.0455 - rmse: 0.8540 - sae: 1856.1063 - sse: 2211.9600 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 129/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.2756e-16 - r2_keras: -97.0854 - rmse: 0.8619 - sae: 2538.3162 - sse: 3042.4873\n","Epoch 129: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 7.3522e-17 - r2_keras: -80.0456 - rmse: 0.8540 - sae: 1856.1072 - sse: 2211.9626 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 130/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.2588e-16 - r2_keras: -97.0854 - rmse: 0.8619 - sae: 2538.3162 - sse: 3042.4868\n","Epoch 130: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.5731e-16 - r2_keras: -80.0456 - rmse: 0.8540 - sae: 1856.1072 - sse: 2211.9622 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 131/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.8122e-16 - r2_keras: -97.0855 - rmse: 0.8619 - sae: 2538.3169 - sse: 3042.4900\n","Epoch 131: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.9473e-16 - r2_keras: -80.0457 - rmse: 0.8540 - sae: 1856.1078 - sse: 2211.9646 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 132/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 9.8430e-17 - r2_keras: -97.0855 - rmse: 0.8619 - sae: 2538.3169 - sse: 3042.4902\n","Epoch 132: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 5.7941e-17 - r2_keras: -80.0457 - rmse: 0.8540 - sae: 1856.1078 - sse: 2211.9646 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -7.8539e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0863 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 133/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.4922e-16 - r2_keras: -97.0856 - rmse: 0.8619 - sae: 2538.3184 - sse: 3042.4939\n","Epoch 133: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.7644e-16 - r2_keras: -80.0458 - rmse: 0.8540 - sae: 1856.1088 - sse: 2211.9675 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0861 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 134/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.2170e-16 - r2_keras: -97.0856 - rmse: 0.8619 - sae: 2538.3174 - sse: 3042.4922\n","Epoch 134: val_loss did not improve from 0.19328\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.3436e-16 - r2_keras: -80.0458 - rmse: 0.8540 - sae: 1856.1080 - sse: 2211.9661 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 135/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.7601e-16 - r2_keras: -97.0857 - rmse: 0.8619 - sae: 2538.3188 - sse: 3042.4963\n","Epoch 135: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.2581e-16 - r2_keras: -80.0459 - rmse: 0.8540 - sae: 1856.1093 - sse: 2211.9692 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 7.8539e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 136/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.4325e-16 - r2_keras: -97.0857 - rmse: 0.8619 - sae: 2538.3188 - sse: 3042.4961\n","Epoch 136: val_loss improved from 0.19328 to 0.19328, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 5.2953e-16 - r2_keras: -80.0459 - rmse: 0.8540 - sae: 1856.1091 - sse: 2211.9690 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0861 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 137/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.0518e-16 - r2_keras: -97.0858 - rmse: 0.8619 - sae: 2538.3191 - sse: 3042.4985\n","Epoch 137: val_loss improved from 0.19328 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.4043e-17 - r2_keras: -80.0459 - rmse: 0.8540 - sae: 1856.1095 - sse: 2211.9709 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0860 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 138/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.8030e-16 - r2_keras: -97.0858 - rmse: 0.8619 - sae: 2538.3193 - sse: 3042.4985\n","Epoch 138: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.0774e-17 - r2_keras: -80.0459 - rmse: 0.8540 - sae: 1856.1095 - sse: 2211.9707 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0862 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 139/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 7.5892e-16 - r2_keras: -97.0859 - rmse: 0.8619 - sae: 2538.3203 - sse: 3042.5024\n","Epoch 139: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 5.1938e-16 - r2_keras: -80.0460 - rmse: 0.8540 - sae: 1856.1104 - sse: 2211.9736 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.4782e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0859 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 140/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.6773e-16 - r2_keras: -97.0859 - rmse: 0.8619 - sae: 2538.3196 - sse: 3042.5012\n","Epoch 140: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.0222e-16 - r2_keras: -80.0460 - rmse: 0.8540 - sae: 1856.1097 - sse: 2211.9727 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0861 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 141/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.9594e-16 - r2_keras: -97.0860 - rmse: 0.8619 - sae: 2538.3208 - sse: 3042.5044\n","Epoch 141: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.8478e-17 - r2_keras: -80.0461 - rmse: 0.8540 - sae: 1856.1107 - sse: 2211.9751 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0859 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 142/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.4355e-16 - r2_keras: -97.0860 - rmse: 0.8619 - sae: 2538.3208 - sse: 3042.5044\n","Epoch 142: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -5.9596e-16 - r2_keras: -80.0461 - rmse: 0.8540 - sae: 1856.1107 - sse: 2211.9749 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 6.7319e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0861 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 143/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.0426e-16 - r2_keras: -97.0861 - rmse: 0.8619 - sae: 2538.3223 - sse: 3042.5083\n","Epoch 143: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.2871e-17 - r2_keras: -80.0462 - rmse: 0.8540 - sae: 1856.1118 - sse: 2211.9778 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0859 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 144/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.9548e-16 - r2_keras: -97.0861 - rmse: 0.8619 - sae: 2538.3213 - sse: 3042.5066\n","Epoch 144: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 4.2770e-16 - r2_keras: -80.0461 - rmse: 0.8540 - sae: 1856.1110 - sse: 2211.9766 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0861 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 145/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.4799e-16 - r2_keras: -97.0862 - rmse: 0.8619 - sae: 2538.3228 - sse: 3042.5107\n","Epoch 145: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.0075e-16 - r2_keras: -80.0463 - rmse: 0.8540 - sae: 1856.1122 - sse: 2211.9797 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.5806e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0859 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 146/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.6213e-16 - r2_keras: -97.0862 - rmse: 0.8619 - sae: 2538.3223 - sse: 3042.5098\n","Epoch 146: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.9439e-16 - r2_keras: -80.0462 - rmse: 0.8540 - sae: 1856.1117 - sse: 2211.9788 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0861 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 147/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.3404e-17 - r2_keras: -97.0863 - rmse: 0.8619 - sae: 2538.3240 - sse: 3042.5139\n","Epoch 147: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 5.7522e-17 - r2_keras: -80.0463 - rmse: 0.8540 - sae: 1856.1130 - sse: 2211.9819 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0857 - val_sse: 483.3179 - learning_rate: 1.0000e-05\n","Epoch 148/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.9962e-16 - r2_keras: -97.0862 - rmse: 0.8619 - sae: 2538.3228 - sse: 3042.5122\n","Epoch 148: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.5228e-16 - r2_keras: -80.0463 - rmse: 0.8540 - sae: 1856.1122 - sse: 2211.9807 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0860 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 149/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 7.6873e-16 - r2_keras: -97.0864 - rmse: 0.8619 - sae: 2538.3242 - sse: 3042.5161\n","Epoch 149: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 5.3840e-16 - r2_keras: -80.0464 - rmse: 0.8540 - sae: 1856.1133 - sse: 2211.9836 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0858 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 150/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.9368e-17 - r2_keras: -97.0863 - rmse: 0.8619 - sae: 2538.3237 - sse: 3042.5156\n","Epoch 150: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -8.0905e-17 - r2_keras: -80.0464 - rmse: 0.8540 - sae: 1856.1129 - sse: 2211.9832 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0859 - val_sse: 483.3184 - learning_rate: 1.0000e-05\n","Epoch 151/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.9314e-16 - r2_keras: -97.0864 - rmse: 0.8619 - sae: 2538.3250 - sse: 3042.5190\n","Epoch 151: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.6855e-16 - r2_keras: -80.0465 - rmse: 0.8540 - sae: 1856.1139 - sse: 2211.9856 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0858 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 152/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.8574e-16 - r2_keras: -97.0864 - rmse: 0.8619 - sae: 2538.3247 - sse: 3042.5183\n","Epoch 152: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.7365e-16 - r2_keras: -80.0464 - rmse: 0.8540 - sae: 1856.1136 - sse: 2211.9849 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.1416e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0859 - val_sse: 483.3185 - learning_rate: 1.0000e-05\n","Epoch 153/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.5941e-16 - r2_keras: -97.0865 - rmse: 0.8619 - sae: 2538.3257 - sse: 3042.5220\n","Epoch 153: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.6238e-16 - r2_keras: -80.0466 - rmse: 0.8540 - sae: 1856.1144 - sse: 2211.9878 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0858 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 154/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.2790e-17 - r2_keras: -97.0865 - rmse: 0.8619 - sae: 2538.3257 - sse: 3042.5210\n","Epoch 154: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.1950e-16 - r2_keras: -80.0465 - rmse: 0.8540 - sae: 1856.1144 - sse: 2211.9871 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.9172e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0858 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 155/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.7259e-16 - r2_keras: -97.0866 - rmse: 0.8619 - sae: 2538.3262 - sse: 3042.5242\n","Epoch 155: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.2396e-16 - r2_keras: -80.0466 - rmse: 0.8540 - sae: 1856.1147 - sse: 2211.9895 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0857 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 156/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 9.6343e-16 - r2_keras: -97.0866 - rmse: 0.8619 - sae: 2538.3264 - sse: 3042.5239\n","Epoch 156: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 7.1716e-16 - r2_keras: -80.0466 - rmse: 0.8540 - sae: 1856.1149 - sse: 2211.9890 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0857 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 157/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.5596e-16 - r2_keras: -97.0867 - rmse: 0.8619 - sae: 2538.3274 - sse: 3042.5273\n","Epoch 157: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 3.1069e-16 - r2_keras: -80.0467 - rmse: 0.8540 - sae: 1856.1156 - sse: 2211.9917 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0857 - val_sse: 483.3181 - learning_rate: 1.0000e-05\n","Epoch 158/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.8693e-16 - r2_keras: -97.0867 - rmse: 0.8619 - sae: 2538.3271 - sse: 3042.5269\n","Epoch 158: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -2.9582e-16 - r2_keras: -80.0467 - rmse: 0.8540 - sae: 1856.1154 - sse: 2211.9912 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0857 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 159/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.0782e-17 - r2_keras: -97.0868 - rmse: 0.8619 - sae: 2538.3279 - sse: 3042.5300\n","Epoch 159: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.6629e-17 - r2_keras: -80.0468 - rmse: 0.8540 - sae: 1856.1161 - sse: 2211.9937 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0855 - val_sse: 483.3179 - learning_rate: 1.0000e-05\n","Epoch 160/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.7049e-16 - r2_keras: -97.0868 - rmse: 0.8619 - sae: 2538.3276 - sse: 3042.5291\n","Epoch 160: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.4245e-16 - r2_keras: -80.0467 - rmse: 0.8540 - sae: 1856.1158 - sse: 2211.9927 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0856 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 161/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.5696e-16 - r2_keras: -97.0869 - rmse: 0.8619 - sae: 2538.3286 - sse: 3042.5322\n","Epoch 161: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.9434e-16 - r2_keras: -80.0468 - rmse: 0.8540 - sae: 1856.1166 - sse: 2211.9954 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0854 - val_sse: 483.3178 - learning_rate: 1.0000e-05\n","Epoch 162/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.8060e-16 - r2_keras: -97.0868 - rmse: 0.8619 - sae: 2538.3281 - sse: 3042.5312\n","Epoch 162: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 9.4487e-17 - r2_keras: -80.0468 - rmse: 0.8540 - sae: 1856.1162 - sse: 2211.9944 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.8050e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0856 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 163/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.1311e-16 - r2_keras: -97.0870 - rmse: 0.8619 - sae: 2538.3293 - sse: 3042.5354\n","Epoch 163: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.2287e-16 - r2_keras: -80.0469 - rmse: 0.8540 - sae: 1856.1171 - sse: 2211.9976 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0854 - val_sse: 483.3178 - learning_rate: 1.0000e-05\n","Epoch 164/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.2051e-16 - r2_keras: -97.0869 - rmse: 0.8619 - sae: 2538.3291 - sse: 3042.5344\n","Epoch 164: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -5.2501e-17 - r2_keras: -80.0469 - rmse: 0.8540 - sae: 1856.1169 - sse: 2211.9966 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0855 - val_sse: 483.3183 - learning_rate: 1.0000e-05\n","Epoch 165/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.3967e-17 - r2_keras: -97.0870 - rmse: 0.8619 - sae: 2538.3298 - sse: 3042.5371\n","Epoch 165: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.5821e-17 - r2_keras: -80.0470 - rmse: 0.8540 - sae: 1856.1176 - sse: 2211.9988 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0854 - val_sse: 483.3179 - learning_rate: 1.0000e-05\n","Epoch 166/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.0076e-16 - r2_keras: -97.0870 - rmse: 0.8619 - sae: 2538.3301 - sse: 3042.5374\n","Epoch 166: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.6910e-16 - r2_keras: -80.0469 - rmse: 0.8540 - sae: 1856.1177 - sse: 2211.9988 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0854 - val_sse: 483.3180 - learning_rate: 1.0000e-05\n","Epoch 167/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.7784e-17 - r2_keras: -97.0871 - rmse: 0.8619 - sae: 2538.3306 - sse: 3042.5398\n","Epoch 167: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.3375e-17 - r2_keras: -80.0470 - rmse: 0.8540 - sae: 1856.1180 - sse: 2212.0007 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0853 - val_sse: 483.3178 - learning_rate: 1.0000e-05\n","Epoch 168/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.4779e-16 - r2_keras: -97.0871 - rmse: 0.8619 - sae: 2538.3301 - sse: 3042.5391\n","Epoch 168: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 8.2212e-17 - r2_keras: -80.0470 - rmse: 0.8540 - sae: 1856.1177 - sse: 2212.0000 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4536 - val_rmse: 0.9558 - val_sae: 363.0854 - val_sse: 483.3182 - learning_rate: 1.0000e-05\n","Epoch 169/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.9271e-16 - r2_keras: -97.0872 - rmse: 0.8619 - sae: 2538.3315 - sse: 3042.5432\n","Epoch 169: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 4.0474e-16 - r2_keras: -80.0471 - rmse: 0.8540 - sae: 1856.1188 - sse: 2212.0032 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0852 - val_sse: 483.3176 - learning_rate: 1.0000e-05\n","Epoch 170/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.0015e-16 - r2_keras: -97.0872 - rmse: 0.8619 - sae: 2538.3311 - sse: 3042.5422\n","Epoch 170: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.3814e-16 - r2_keras: -80.0471 - rmse: 0.8540 - sae: 1856.1184 - sse: 2212.0022 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0851 - val_sse: 483.3173 - learning_rate: 1.0000e-05\n","Epoch 171/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.2951e-16 - r2_keras: -97.0872 - rmse: 0.8619 - sae: 2538.3311 - sse: 3042.5425\n","Epoch 171: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.4175e-16 - r2_keras: -80.0471 - rmse: 0.8540 - sae: 1856.1183 - sse: 2212.0022 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0852 - val_sse: 483.3177 - learning_rate: 1.0000e-05\n","Epoch 172/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 6.2276e-16 - r2_keras: -97.0873 - rmse: 0.8619 - sae: 2538.3318 - sse: 3042.5449\n","Epoch 172: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 4.0941e-16 - r2_keras: -80.0471 - rmse: 0.8540 - sae: 1856.1190 - sse: 2212.0042 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.0392e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0849 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 173/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -7.5798e-16 - r2_keras: -97.0873 - rmse: 0.8619 - sae: 2538.3315 - sse: 3042.5449\n","Epoch 173: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.3237e-16 - r2_keras: -80.0471 - rmse: 0.8540 - sae: 1856.1187 - sse: 2212.0039 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0850 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 174/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.7282e-16 - r2_keras: -97.0874 - rmse: 0.8619 - sae: 2538.3328 - sse: 3042.5476\n","Epoch 174: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -3.3921e-16 - r2_keras: -80.0472 - rmse: 0.8540 - sae: 1856.1198 - sse: 2212.0061 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0850 - val_sse: 483.3173 - learning_rate: 1.0000e-05\n","Epoch 175/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.0356e-17 - r2_keras: -97.0874 - rmse: 0.8619 - sae: 2538.3323 - sse: 3042.5471\n","Epoch 175: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 6.5190e-17 - r2_keras: -80.0472 - rmse: 0.8540 - sae: 1856.1193 - sse: 2212.0056 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0851 - val_sse: 483.3176 - learning_rate: 1.0000e-05\n","Epoch 176/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.4530e-16 - r2_keras: -97.0875 - rmse: 0.8619 - sae: 2538.3337 - sse: 3042.5510\n","Epoch 176: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.0306e-16 - r2_keras: -80.0473 - rmse: 0.8540 - sae: 1856.1204 - sse: 2212.0085 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0849 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 177/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.8394e-16 - r2_keras: -97.0875 - rmse: 0.8619 - sae: 2538.3335 - sse: 3042.5515\n","Epoch 177: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -1.2594e-16 - r2_keras: -80.0473 - rmse: 0.8540 - sae: 1856.1202 - sse: 2212.0088 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0849 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 178/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.6527e-16 - r2_keras: -97.0875 - rmse: 0.8619 - sae: 2538.3337 - sse: 3042.5522\n","Epoch 178: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.2362e-16 - r2_keras: -80.0473 - rmse: 0.8540 - sae: 1856.1205 - sse: 2212.0095 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0848 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 179/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.1709e-16 - r2_keras: -97.0875 - rmse: 0.8619 - sae: 2538.3340 - sse: 3042.5527\n","Epoch 179: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.5625e-16 - r2_keras: -80.0473 - rmse: 0.8540 - sae: 1856.1205 - sse: 2212.0095 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0848 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 180/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.3246e-16 - r2_keras: -97.0876 - rmse: 0.8619 - sae: 2538.3347 - sse: 3042.5559\n","Epoch 180: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.0943e-16 - r2_keras: -80.0474 - rmse: 0.8540 - sae: 1856.1212 - sse: 2212.0122 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 3.0294e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0847 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 181/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.2502e-17 - r2_keras: -97.0876 - rmse: 0.8619 - sae: 2538.3345 - sse: 3042.5557\n","Epoch 181: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.5508e-17 - r2_keras: -80.0474 - rmse: 0.8540 - sae: 1856.1210 - sse: 2212.0117 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0848 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 182/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.9363e-16 - r2_keras: -97.0877 - rmse: 0.8619 - sae: 2538.3350 - sse: 3042.5576\n","Epoch 182: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 4.3415e-16 - r2_keras: -80.0475 - rmse: 0.8540 - sae: 1856.1215 - sse: 2212.0134 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0847 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 183/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.9708e-16 - r2_keras: -97.0877 - rmse: 0.8619 - sae: 2538.3354 - sse: 3042.5588\n","Epoch 183: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 2.6856e-16 - r2_keras: -80.0475 - rmse: 0.8540 - sae: 1856.1216 - sse: 2212.0139 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0847 - val_sse: 483.3173 - learning_rate: 1.0000e-05\n","Epoch 184/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.1437e-16 - r2_keras: -97.0878 - rmse: 0.8619 - sae: 2538.3364 - sse: 3042.5620\n","Epoch 184: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 8.0087e-17 - r2_keras: -80.0476 - rmse: 0.8540 - sae: 1856.1224 - sse: 2212.0166 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.5806e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0847 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 185/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.9528e-16 - r2_keras: -97.0878 - rmse: 0.8619 - sae: 2538.3359 - sse: 3042.5610\n","Epoch 185: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.8629e-16 - r2_keras: -80.0475 - rmse: 0.8540 - sae: 1856.1221 - sse: 2212.0156 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0848 - val_sse: 483.3176 - learning_rate: 1.0000e-05\n","Epoch 186/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.5074e-17 - r2_keras: -97.0879 - rmse: 0.8619 - sae: 2538.3372 - sse: 3042.5649\n","Epoch 186: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: -4.7699e-17 - r2_keras: -80.0477 - rmse: 0.8540 - sae: 1856.1229 - sse: 2212.0186 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0846 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 187/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.6147e-16 - r2_keras: -97.0879 - rmse: 0.8619 - sae: 2538.3369 - sse: 3042.5642\n","Epoch 187: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1569 - pearson_correlation: 1.8670e-16 - r2_keras: -80.0476 - rmse: 0.8540 - sae: 1856.1227 - sse: 2212.0178 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0847 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 188/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.2008e-17 - r2_keras: -97.0880 - rmse: 0.8619 - sae: 2538.3379 - sse: 3042.5669\n","Epoch 188: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 9.5195e-17 - r2_keras: -80.0477 - rmse: 0.8540 - sae: 1856.1235 - sse: 2212.0200 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0847 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 189/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 6.6139e-16 - r2_keras: -97.0880 - rmse: 0.8619 - sae: 2538.3379 - sse: 3042.5679\n","Epoch 189: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.1405e-16 - r2_keras: -80.0477 - rmse: 0.8540 - sae: 1856.1234 - sse: 2212.0205 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0846 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 190/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.6312e-16 - r2_keras: -97.0881 - rmse: 0.8619 - sae: 2538.3386 - sse: 3042.5706\n","Epoch 190: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.8842e-16 - r2_keras: -80.0478 - rmse: 0.8540 - sae: 1856.1241 - sse: 2212.0227 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 191/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.1437e-16 - r2_keras: -97.0881 - rmse: 0.8619 - sae: 2538.3386 - sse: 3042.5701\n","Epoch 191: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.1272e-16 - r2_keras: -80.0478 - rmse: 0.8540 - sae: 1856.1240 - sse: 2212.0220 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 192/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.3645e-16 - r2_keras: -97.0882 - rmse: 0.8619 - sae: 2538.3394 - sse: 3042.5732\n","Epoch 192: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 9.5764e-17 - r2_keras: -80.0479 - rmse: 0.8540 - sae: 1856.1246 - sse: 2212.0247 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 193/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.8179e-16 - r2_keras: -97.0882 - rmse: 0.8619 - sae: 2538.3396 - sse: 3042.5740\n","Epoch 193: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.9938e-16 - r2_keras: -80.0479 - rmse: 0.8540 - sae: 1856.1248 - sse: 2212.0249 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3173 - learning_rate: 1.0000e-05\n","Epoch 194/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -7.6901e-16 - r2_keras: -97.0883 - rmse: 0.8619 - sae: 2538.3403 - sse: 3042.5764\n","Epoch 194: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.2995e-16 - r2_keras: -80.0480 - rmse: 0.8540 - sae: 1856.1254 - sse: 2212.0269 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3173 - learning_rate: 1.0000e-05\n","Epoch 195/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.4342e-17 - r2_keras: -97.0883 - rmse: 0.8619 - sae: 2538.3403 - sse: 3042.5764\n","Epoch 195: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0975e-17 - r2_keras: -80.0479 - rmse: 0.8540 - sae: 1856.1252 - sse: 2212.0266 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0844 - val_sse: 483.3173 - learning_rate: 1.0000e-05\n","Epoch 196/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.5993e-17 - r2_keras: -97.0884 - rmse: 0.8619 - sae: 2538.3411 - sse: 3042.5793\n","Epoch 196: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.8743e-17 - r2_keras: -80.0480 - rmse: 0.8540 - sae: 1856.1259 - sse: 2212.0288 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 197/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.0544e-16 - r2_keras: -97.0884 - rmse: 0.8619 - sae: 2538.3413 - sse: 3042.5798\n","Epoch 197: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.4848e-16 - r2_keras: -80.0480 - rmse: 0.8540 - sae: 1856.1260 - sse: 2212.0291 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0846 - val_sse: 483.3177 - learning_rate: 1.0000e-05\n","Epoch 198/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.9558e-16 - r2_keras: -97.0885 - rmse: 0.8619 - sae: 2538.3418 - sse: 3042.5823\n","Epoch 198: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0665e-16 - r2_keras: -80.0481 - rmse: 0.8540 - sae: 1856.1265 - sse: 2212.0310 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0844 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 199/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.5296e-16 - r2_keras: -97.0885 - rmse: 0.8619 - sae: 2538.3418 - sse: 3042.5820\n","Epoch 199: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.2833e-16 - r2_keras: -80.0481 - rmse: 0.8540 - sae: 1856.1263 - sse: 2212.0305 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0845 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 200/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.4381e-16 - r2_keras: -97.0886 - rmse: 0.8619 - sae: 2538.3428 - sse: 3042.5850\n","Epoch 200: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.9151e-17 - r2_keras: -80.0482 - rmse: 0.8540 - sae: 1856.1271 - sse: 2212.0330 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0841 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 201/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.5721e-16 - r2_keras: -97.0886 - rmse: 0.8619 - sae: 2538.3425 - sse: 3042.5850\n","Epoch 201: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.7959e-16 - r2_keras: -80.0482 - rmse: 0.8540 - sae: 1856.1270 - sse: 2212.0327 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0844 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 202/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.4985e-16 - r2_keras: -97.0887 - rmse: 0.8619 - sae: 2538.3433 - sse: 3042.5879\n","Epoch 202: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4109e-16 - r2_keras: -80.0483 - rmse: 0.8540 - sae: 1856.1276 - sse: 2212.0352 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.9270e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0842 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 203/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.5879e-16 - r2_keras: -97.0887 - rmse: 0.8619 - sae: 2538.3433 - sse: 3042.5874\n","Epoch 203: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.2357e-16 - r2_keras: -80.0482 - rmse: 0.8540 - sae: 1856.1276 - sse: 2212.0344 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0843 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 204/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.4806e-16 - r2_keras: -97.0888 - rmse: 0.8619 - sae: 2538.3447 - sse: 3042.5913\n","Epoch 204: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0952e-16 - r2_keras: -80.0483 - rmse: 0.8540 - sae: 1856.1285 - sse: 2212.0376 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0842 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 205/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.0022e-16 - r2_keras: -97.0888 - rmse: 0.8619 - sae: 2538.3445 - sse: 3042.5911\n","Epoch 205: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.4099e-16 - r2_keras: -80.0483 - rmse: 0.8540 - sae: 1856.1283 - sse: 2212.0371 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0843 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 206/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.1420e-16 - r2_keras: -97.0889 - rmse: 0.8619 - sae: 2538.3452 - sse: 3042.5942\n","Epoch 206: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.8312e-16 - r2_keras: -80.0484 - rmse: 0.8540 - sae: 1856.1290 - sse: 2212.0396 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0841 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 207/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.6418e-17 - r2_keras: -97.0888 - rmse: 0.8619 - sae: 2538.3452 - sse: 3042.5933\n","Epoch 207: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.0576e-18 - r2_keras: -80.0484 - rmse: 0.8540 - sae: 1856.1289 - sse: 2212.0388 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.0588e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0843 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 208/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.3763e-16 - r2_keras: -97.0890 - rmse: 0.8619 - sae: 2538.3464 - sse: 3042.5977\n","Epoch 208: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4210e-16 - r2_keras: -80.0485 - rmse: 0.8540 - sae: 1856.1299 - sse: 2212.0420 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.6928e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0842 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 209/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.6116e-16 - r2_keras: -97.0890 - rmse: 0.8619 - sae: 2538.3467 - sse: 3042.5972\n","Epoch 209: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7288e-16 - r2_keras: -80.0485 - rmse: 0.8540 - sae: 1856.1300 - sse: 2212.0415 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.9172e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0843 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 210/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.2007e-16 - r2_keras: -97.0891 - rmse: 0.8619 - sae: 2538.3472 - sse: 3042.6001\n","Epoch 210: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.7813e-16 - r2_keras: -80.0486 - rmse: 0.8540 - sae: 1856.1304 - sse: 2212.0437 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0839 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 211/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.6882e-16 - r2_keras: -97.0890 - rmse: 0.8619 - sae: 2538.3464 - sse: 3042.5991\n","Epoch 211: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.1063e-16 - r2_keras: -80.0485 - rmse: 0.8540 - sae: 1856.1299 - sse: 2212.0430 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0843 - val_sse: 483.3177 - learning_rate: 1.0000e-05\n","Epoch 212/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 7.0829e-17 - r2_keras: -97.0892 - rmse: 0.8619 - sae: 2538.3477 - sse: 3042.6030\n","Epoch 212: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.4917e-18 - r2_keras: -80.0486 - rmse: 0.8540 - sae: 1856.1307 - sse: 2212.0459 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 213/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.2690e-17 - r2_keras: -97.0891 - rmse: 0.8619 - sae: 2538.3479 - sse: 3042.6025\n","Epoch 213: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.9436e-17 - r2_keras: -80.0486 - rmse: 0.8540 - sae: 1856.1309 - sse: 2212.0454 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0842 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 214/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.9396e-16 - r2_keras: -97.0892 - rmse: 0.8619 - sae: 2538.3486 - sse: 3042.6055\n","Epoch 214: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.6290e-16 - r2_keras: -80.0487 - rmse: 0.8540 - sae: 1856.1315 - sse: 2212.0476 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0839 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 215/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.6496e-16 - r2_keras: -97.0892 - rmse: 0.8619 - sae: 2538.3486 - sse: 3042.6055\n","Epoch 215: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -9.9416e-17 - r2_keras: -80.0487 - rmse: 0.8540 - sae: 1856.1315 - sse: 2212.0474 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0842 - val_sse: 483.3176 - learning_rate: 1.0000e-05\n","Epoch 216/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.1463e-16 - r2_keras: -97.0893 - rmse: 0.8619 - sae: 2538.3496 - sse: 3042.6089\n","Epoch 216: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.1106e-16 - r2_keras: -80.0488 - rmse: 0.8540 - sae: 1856.1322 - sse: 2212.0500 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 217/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.0662e-17 - r2_keras: -97.0893 - rmse: 0.8619 - sae: 2538.3496 - sse: 3042.6082\n","Epoch 217: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1547e-16 - r2_keras: -80.0488 - rmse: 0.8540 - sae: 1856.1322 - sse: 2212.0493 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 218/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.9760e-16 - r2_keras: -97.0894 - rmse: 0.8619 - sae: 2538.3506 - sse: 3042.6118\n","Epoch 218: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.4945e-16 - r2_keras: -80.0489 - rmse: 0.8540 - sae: 1856.1329 - sse: 2212.0522 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 219/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.8121e-16 - r2_keras: -97.0894 - rmse: 0.8619 - sae: 2538.3503 - sse: 3042.6116\n","Epoch 219: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.1601e-16 - r2_keras: -80.0488 - rmse: 0.8540 - sae: 1856.1327 - sse: 2212.0518 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 220/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.5261e-17 - r2_keras: -97.0895 - rmse: 0.8619 - sae: 2538.3516 - sse: 3042.6150\n","Epoch 220: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.4222e-17 - r2_keras: -80.0490 - rmse: 0.8540 - sae: 1856.1337 - sse: 2212.0544 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0839 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 221/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.9549e-16 - r2_keras: -97.0895 - rmse: 0.8619 - sae: 2538.3511 - sse: 3042.6150\n","Epoch 221: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.7448e-16 - r2_keras: -80.0489 - rmse: 0.8540 - sae: 1856.1333 - sse: 2212.0542 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 222/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.1297e-16 - r2_keras: -97.0896 - rmse: 0.8619 - sae: 2538.3516 - sse: 3042.6172\n","Epoch 222: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.4006e-16 - r2_keras: -80.0490 - rmse: 0.8540 - sae: 1856.1338 - sse: 2212.0562 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0839 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 223/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.4775e-16 - r2_keras: -97.0896 - rmse: 0.8619 - sae: 2538.3521 - sse: 3042.6172\n","Epoch 223: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4597e-16 - r2_keras: -80.0490 - rmse: 0.8540 - sae: 1856.1339 - sse: 2212.0559 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 224/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 6.9479e-16 - r2_keras: -97.0897 - rmse: 0.8619 - sae: 2538.3530 - sse: 3042.6211\n","Epoch 224: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.2175e-16 - r2_keras: -80.0491 - rmse: 0.8540 - sae: 1856.1348 - sse: 2212.0588 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.1416e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0837 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 225/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.3662e-16 - r2_keras: -97.0897 - rmse: 0.8619 - sae: 2538.3525 - sse: 3042.6196\n","Epoch 225: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.5269e-16 - r2_keras: -80.0490 - rmse: 0.8540 - sae: 1856.1344 - sse: 2212.0576 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0840 - val_sse: 483.3175 - learning_rate: 1.0000e-05\n","Epoch 226/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.2195e-17 - r2_keras: -97.0898 - rmse: 0.8619 - sae: 2538.3540 - sse: 3042.6233\n","Epoch 226: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.2178e-17 - r2_keras: -80.0492 - rmse: 0.8540 - sae: 1856.1355 - sse: 2212.0605 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.2538e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0837 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 227/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.0911e-16 - r2_keras: -97.0898 - rmse: 0.8619 - sae: 2538.3535 - sse: 3042.6228\n","Epoch 227: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.2003e-16 - r2_keras: -80.0491 - rmse: 0.8540 - sae: 1856.1351 - sse: 2212.0598 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0839 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 228/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.6952e-16 - r2_keras: -97.0899 - rmse: 0.8619 - sae: 2538.3550 - sse: 3042.6270\n","Epoch 228: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.9407e-16 - r2_keras: -80.0493 - rmse: 0.8540 - sae: 1856.1362 - sse: 2212.0630 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0837 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 229/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.3837e-16 - r2_keras: -97.0899 - rmse: 0.8619 - sae: 2538.3545 - sse: 3042.6260\n","Epoch 229: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.1214e-16 - r2_keras: -80.0492 - rmse: 0.8540 - sae: 1856.1359 - sse: 2212.0620 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0838 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 230/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.5011e-16 - r2_keras: -97.0900 - rmse: 0.8619 - sae: 2538.3552 - sse: 3042.6284\n","Epoch 230: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7512e-16 - r2_keras: -80.0493 - rmse: 0.8540 - sae: 1856.1365 - sse: 2212.0642 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0836 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 231/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.3233e-17 - r2_keras: -97.0900 - rmse: 0.8619 - sae: 2538.3552 - sse: 3042.6287\n","Epoch 231: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.8929e-18 - r2_keras: -80.0493 - rmse: 0.8540 - sae: 1856.1364 - sse: 2212.0640 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0838 - val_sse: 483.3174 - learning_rate: 1.0000e-05\n","Epoch 232/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.3605e-16 - r2_keras: -97.0901 - rmse: 0.8619 - sae: 2538.3564 - sse: 3042.6323\n","Epoch 232: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.0100e-16 - r2_keras: -80.0494 - rmse: 0.8540 - sae: 1856.1373 - sse: 2212.0669 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0836 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 233/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.4310e-16 - r2_keras: -97.0901 - rmse: 0.8619 - sae: 2538.3564 - sse: 3042.6318\n","Epoch 233: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.8074e-16 - r2_keras: -80.0494 - rmse: 0.8540 - sae: 1856.1372 - sse: 2212.0662 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0835 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 234/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.7525e-16 - r2_keras: -97.0901 - rmse: 0.8619 - sae: 2538.3560 - sse: 3042.6313\n","Epoch 234: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.8132e-16 - r2_keras: -80.0493 - rmse: 0.8540 - sae: 1856.1368 - sse: 2212.0657 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0836 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 235/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.3916e-16 - r2_keras: -97.0902 - rmse: 0.8619 - sae: 2538.3574 - sse: 3042.6355\n","Epoch 235: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.5464e-16 - r2_keras: -80.0495 - rmse: 0.8540 - sae: 1856.1381 - sse: 2212.0688 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0835 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 236/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.1130e-16 - r2_keras: -97.0902 - rmse: 0.8619 - sae: 2538.3569 - sse: 3042.6340\n","Epoch 236: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.2281e-17 - r2_keras: -80.0494 - rmse: 0.8540 - sae: 1856.1376 - sse: 2212.0676 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.4782e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0836 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 237/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 6.3408e-16 - r2_keras: -97.0903 - rmse: 0.8619 - sae: 2538.3579 - sse: 3042.6375\n","Epoch 237: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.6687e-16 - r2_keras: -80.0495 - rmse: 0.8540 - sae: 1856.1383 - sse: 2212.0703 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0833 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 238/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.9523e-16 - r2_keras: -97.0902 - rmse: 0.8619 - sae: 2538.3574 - sse: 3042.6367\n","Epoch 238: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.6924e-16 - r2_keras: -80.0495 - rmse: 0.8540 - sae: 1856.1379 - sse: 2212.0696 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0835 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 239/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.3399e-16 - r2_keras: -97.0904 - rmse: 0.8619 - sae: 2538.3589 - sse: 3042.6406\n","Epoch 239: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4980e-16 - r2_keras: -80.0496 - rmse: 0.8540 - sae: 1856.1390 - sse: 2212.0725 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0834 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 240/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.3000e-16 - r2_keras: -97.0903 - rmse: 0.8619 - sae: 2538.3586 - sse: 3042.6396\n","Epoch 240: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.4138e-16 - r2_keras: -80.0495 - rmse: 0.8540 - sae: 1856.1388 - sse: 2212.0718 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0833 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 241/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.3390e-16 - r2_keras: -97.0904 - rmse: 0.8619 - sae: 2538.3594 - sse: 3042.6426\n","Epoch 241: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.8037e-16 - r2_keras: -80.0496 - rmse: 0.8540 - sae: 1856.1395 - sse: 2212.0740 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0833 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 242/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.0464e-16 - r2_keras: -97.0905 - rmse: 0.8619 - sae: 2538.3599 - sse: 3042.6436\n","Epoch 242: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.9925e-16 - r2_keras: -80.0497 - rmse: 0.8540 - sae: 1856.1398 - sse: 2212.0745 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0834 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 243/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.7411e-16 - r2_keras: -97.0905 - rmse: 0.8619 - sae: 2538.3599 - sse: 3042.6460\n","Epoch 243: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.4819e-16 - r2_keras: -80.0497 - rmse: 0.8540 - sae: 1856.1398 - sse: 2212.0764 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.1416e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0833 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 244/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 7.2974e-17 - r2_keras: -97.0906 - rmse: 0.8619 - sae: 2538.3604 - sse: 3042.6462\n","Epoch 244: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.3292e-17 - r2_keras: -80.0497 - rmse: 0.8540 - sae: 1856.1401 - sse: 2212.0764 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0833 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 245/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 3.3697e-16 - r2_keras: -97.0906 - rmse: 0.8619 - sae: 2538.3613 - sse: 3042.6489\n","Epoch 245: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.4960e-16 - r2_keras: -80.0498 - rmse: 0.8540 - sae: 1856.1409 - sse: 2212.0786 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.0490e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0831 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 246/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.5698e-16 - r2_keras: -97.0906 - rmse: 0.8619 - sae: 2538.3613 - sse: 3042.6492\n","Epoch 246: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.0971e-16 - r2_keras: -80.0498 - rmse: 0.8540 - sae: 1856.1407 - sse: 2212.0786 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.8050e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0834 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 247/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 9.4743e-17 - r2_keras: -97.0907 - rmse: 0.8619 - sae: 2538.3618 - sse: 3042.6516\n","Epoch 247: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.0439e-17 - r2_keras: -80.0499 - rmse: 0.8540 - sae: 1856.1412 - sse: 2212.0806 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0832 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 248/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.2264e-17 - r2_keras: -97.0907 - rmse: 0.8619 - sae: 2538.3618 - sse: 3042.6514\n","Epoch 248: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.3370e-18 - r2_keras: -80.0499 - rmse: 0.8540 - sae: 1856.1412 - sse: 2212.0801 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0832 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 249/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.5392e-16 - r2_keras: -97.0908 - rmse: 0.8619 - sae: 2538.3628 - sse: 3042.6550\n","Epoch 249: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.5252e-16 - r2_keras: -80.0500 - rmse: 0.8540 - sae: 1856.1420 - sse: 2212.0830 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0832 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 250/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.1130e-15 - r2_keras: -97.0908 - rmse: 0.8619 - sae: 2538.3625 - sse: 3042.6543\n","Epoch 250: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.4200e-16 - r2_keras: -80.0499 - rmse: 0.8540 - sae: 1856.1417 - sse: 2212.0823 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0832 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 251/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.7367e-16 - r2_keras: -97.0909 - rmse: 0.8619 - sae: 2538.3635 - sse: 3042.6572\n","Epoch 251: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.4021e-16 - r2_keras: -80.0500 - rmse: 0.8540 - sae: 1856.1426 - sse: 2212.0847 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0830 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 252/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.5527e-16 - r2_keras: -97.0909 - rmse: 0.8619 - sae: 2538.3638 - sse: 3042.6577\n","Epoch 252: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.5657e-16 - r2_keras: -80.0500 - rmse: 0.8540 - sae: 1856.1427 - sse: 2212.0847 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0833 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 253/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.6044e-16 - r2_keras: -97.0910 - rmse: 0.8619 - sae: 2538.3647 - sse: 3042.6606\n","Epoch 253: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.3820e-16 - r2_keras: -80.0501 - rmse: 0.8540 - sae: 1856.1434 - sse: 2212.0872 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0830 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 254/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.9991e-16 - r2_keras: -97.0910 - rmse: 0.8619 - sae: 2538.3647 - sse: 3042.6606\n","Epoch 254: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -8.4322e-17 - r2_keras: -80.0501 - rmse: 0.8540 - sae: 1856.1434 - sse: 2212.0867 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0832 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 255/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.2478e-17 - r2_keras: -97.0911 - rmse: 0.8619 - sae: 2538.3657 - sse: 3042.6636\n","Epoch 255: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.8512e-17 - r2_keras: -80.0502 - rmse: 0.8540 - sae: 1856.1442 - sse: 2212.0891 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 256/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.0932e-16 - r2_keras: -97.0911 - rmse: 0.8619 - sae: 2538.3652 - sse: 3042.6624\n","Epoch 256: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.3065e-16 - r2_keras: -80.0501 - rmse: 0.8540 - sae: 1856.1437 - sse: 2212.0881 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0832 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 257/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.4866e-16 - r2_keras: -97.0912 - rmse: 0.8619 - sae: 2538.3662 - sse: 3042.6660\n","Epoch 257: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.3776e-16 - r2_keras: -80.0503 - rmse: 0.8540 - sae: 1856.1445 - sse: 2212.0908 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0830 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 258/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.0854e-16 - r2_keras: -97.0912 - rmse: 0.8619 - sae: 2538.3662 - sse: 3042.6655\n","Epoch 258: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.1075e-16 - r2_keras: -80.0502 - rmse: 0.8540 - sae: 1856.1444 - sse: 2212.0903 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0831 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 259/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -7.0275e-16 - r2_keras: -97.0913 - rmse: 0.8619 - sae: 2538.3672 - sse: 3042.6699\n","Epoch 259: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.0977e-16 - r2_keras: -80.0503 - rmse: 0.8540 - sae: 1856.1453 - sse: 2212.0938 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.0294e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 260/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.0630e-16 - r2_keras: -97.0913 - rmse: 0.8619 - sae: 2538.3672 - sse: 3042.6689\n","Epoch 260: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2550e-16 - r2_keras: -80.0503 - rmse: 0.8540 - sae: 1856.1451 - sse: 2212.0928 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0830 - val_sse: 483.3171 - learning_rate: 1.0000e-05\n","Epoch 261/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -7.3893e-16 - r2_keras: -97.0914 - rmse: 0.8619 - sae: 2538.3679 - sse: 3042.6719\n","Epoch 261: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.1565e-16 - r2_keras: -80.0504 - rmse: 0.8540 - sae: 1856.1459 - sse: 2212.0950 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 262/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 9.7502e-17 - r2_keras: -97.0914 - rmse: 0.8619 - sae: 2538.3677 - sse: 3042.6711\n","Epoch 262: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -6.9856e-18 - r2_keras: -80.0504 - rmse: 0.8540 - sae: 1856.1456 - sse: 2212.0942 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 263/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.1480e-16 - r2_keras: -97.0915 - rmse: 0.8619 - sae: 2538.3684 - sse: 3042.6743\n","Epoch 263: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.2802e-16 - r2_keras: -80.0505 - rmse: 0.8540 - sae: 1856.1462 - sse: 2212.0969 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 264/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -7.6039e-17 - r2_keras: -97.0915 - rmse: 0.8619 - sae: 2538.3689 - sse: 3042.6753\n","Epoch 264: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.6452e-17 - r2_keras: -80.0505 - rmse: 0.8540 - sae: 1856.1465 - sse: 2212.0972 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 265/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.7477e-17 - r2_keras: -97.0916 - rmse: 0.8619 - sae: 2538.3701 - sse: 3042.6782\n","Epoch 265: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 7.2120e-17 - r2_keras: -80.0506 - rmse: 0.8540 - sae: 1856.1473 - sse: 2212.0996 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0828 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 266/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.5387e-16 - r2_keras: -97.0916 - rmse: 0.8619 - sae: 2538.3696 - sse: 3042.6775\n","Epoch 266: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.4603e-16 - r2_keras: -80.0505 - rmse: 0.8540 - sae: 1856.1471 - sse: 2212.0989 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0830 - val_sse: 483.3172 - learning_rate: 1.0000e-05\n","Epoch 267/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -5.1510e-17 - r2_keras: -97.0917 - rmse: 0.8619 - sae: 2538.3706 - sse: 3042.6807\n","Epoch 267: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.7490e-17 - r2_keras: -80.0506 - rmse: 0.8540 - sae: 1856.1478 - sse: 2212.1013 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 4.7124e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0827 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 268/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.3845e-17 - r2_keras: -97.0916 - rmse: 0.8619 - sae: 2538.3701 - sse: 3042.6797\n","Epoch 268: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.3952e-18 - r2_keras: -80.0506 - rmse: 0.8540 - sae: 1856.1473 - sse: 2212.1003 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0829 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 269/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.4104e-17 - r2_keras: -97.0918 - rmse: 0.8619 - sae: 2538.3716 - sse: 3042.6846\n","Epoch 269: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.9146e-17 - r2_keras: -80.0507 - rmse: 0.8540 - sae: 1856.1486 - sse: 2212.1042 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0827 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 270/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 9.2902e-17 - r2_keras: -97.0917 - rmse: 0.8619 - sae: 2538.3711 - sse: 3042.6826\n","Epoch 270: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.0417e-16 - r2_keras: -80.0507 - rmse: 0.8540 - sae: 1856.1481 - sse: 2212.1025 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0827 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 271/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 5.7029e-17 - r2_keras: -97.0918 - rmse: 0.8619 - sae: 2538.3718 - sse: 3042.6855\n","Epoch 271: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.0251e-17 - r2_keras: -80.0508 - rmse: 0.8540 - sae: 1856.1487 - sse: 2212.1050 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0828 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 272/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.6609e-16 - r2_keras: -97.0919 - rmse: 0.8619 - sae: 2538.3726 - sse: 3042.6870\n","Epoch 272: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.6134e-16 - r2_keras: -80.0508 - rmse: 0.8540 - sae: 1856.1492 - sse: 2212.1057 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0828 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 273/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 2.8790e-16 - r2_keras: -97.0920 - rmse: 0.8619 - sae: 2538.3733 - sse: 3042.6902\n","Epoch 273: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.4569e-16 - r2_keras: -80.0509 - rmse: 0.8540 - sae: 1856.1498 - sse: 2212.1082 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0827 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 274/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.2812e-16 - r2_keras: -97.0919 - rmse: 0.8619 - sae: 2538.3730 - sse: 3042.6890\n","Epoch 274: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0121e-16 - r2_keras: -80.0508 - rmse: 0.8540 - sae: 1856.1495 - sse: 2212.1072 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0827 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 275/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.1462e-16 - r2_keras: -97.0920 - rmse: 0.8619 - sae: 2538.3740 - sse: 3042.6924\n","Epoch 275: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.6420e-16 - r2_keras: -80.0509 - rmse: 0.8540 - sae: 1856.1503 - sse: 2212.1099 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 276/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.8916e-17 - r2_keras: -97.0920 - rmse: 0.8619 - sae: 2538.3735 - sse: 3042.6919\n","Epoch 276: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.5677e-18 - r2_keras: -80.0509 - rmse: 0.8540 - sae: 1856.1499 - sse: 2212.1091 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0827 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 277/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 4.4764e-17 - r2_keras: -97.0922 - rmse: 0.8619 - sae: 2538.3750 - sse: 3042.6960\n","Epoch 277: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.8079e-17 - r2_keras: -80.0510 - rmse: 0.8540 - sae: 1856.1510 - sse: 2212.1123 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 278/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -1.0486e-16 - r2_keras: -97.0921 - rmse: 0.8619 - sae: 2538.3743 - sse: 3042.6941\n","Epoch 278: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4477e-16 - r2_keras: -80.0510 - rmse: 0.8540 - sae: 1856.1505 - sse: 2212.1108 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0826 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 279/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.2929e-16 - r2_keras: -97.0922 - rmse: 0.8619 - sae: 2538.3755 - sse: 3042.6973\n","Epoch 279: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7808e-16 - r2_keras: -80.0511 - rmse: 0.8540 - sae: 1856.1515 - sse: 2212.1133 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 280/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.4899e-16 - r2_keras: -97.0922 - rmse: 0.8619 - sae: 2538.3755 - sse: 3042.6973\n","Epoch 280: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.9191e-16 - r2_keras: -80.0510 - rmse: 0.8540 - sae: 1856.1514 - sse: 2212.1130 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -4.6002e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 281/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 8.9529e-17 - r2_keras: -97.0923 - rmse: 0.8619 - sae: 2538.3760 - sse: 3042.7002\n","Epoch 281: val_loss improved from 0.19327 to 0.19327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.8012e-17 - r2_keras: -80.0511 - rmse: 0.8540 - sae: 1856.1517 - sse: 2212.1155 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0824 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 282/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -6.1597e-16 - r2_keras: -97.0923 - rmse: 0.8619 - sae: 2538.3760 - sse: 3042.7000\n","Epoch 282: val_loss did not improve from 0.19327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.1257e-16 - r2_keras: -80.0511 - rmse: 0.8540 - sae: 1856.1517 - sse: 2212.1150 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0826 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 283/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 6.7146e-17 - r2_keras: -97.0924 - rmse: 0.8619 - sae: 2538.3774 - sse: 3042.7041\n","Epoch 283: val_loss improved from 0.19327 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1387e-16 - r2_keras: -80.0512 - rmse: 0.8540 - sae: 1856.1528 - sse: 2212.1182 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 284/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.6156e-17 - r2_keras: -97.0924 - rmse: 0.8619 - sae: 2538.3774 - sse: 3042.7046\n","Epoch 284: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.0875e-17 - r2_keras: -80.0512 - rmse: 0.8540 - sae: 1856.1528 - sse: 2212.1184 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 285/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -4.3844e-16 - r2_keras: -97.0925 - rmse: 0.8619 - sae: 2538.3777 - sse: 3042.7063\n","Epoch 285: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.5006e-16 - r2_keras: -80.0513 - rmse: 0.8540 - sae: 1856.1531 - sse: 2212.1199 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0823 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 286/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.0118e-17 - r2_keras: -97.0925 - rmse: 0.8619 - sae: 2538.3782 - sse: 3042.7065\n","Epoch 286: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.4334e-17 - r2_keras: -80.0513 - rmse: 0.8540 - sae: 1856.1534 - sse: 2212.1196 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3168 - learning_rate: 1.0000e-05\n","Epoch 287/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -9.6273e-17 - r2_keras: -97.0926 - rmse: 0.8619 - sae: 2538.3792 - sse: 3042.7102\n","Epoch 287: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.2821e-17 - r2_keras: -80.0514 - rmse: 0.8540 - sae: 1856.1542 - sse: 2212.1226 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -8.9760e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0825 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 288/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -3.4217e-16 - r2_keras: -97.0926 - rmse: 0.8619 - sae: 2538.3789 - sse: 3042.7095\n","Epoch 288: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.4539e-16 - r2_keras: -80.0514 - rmse: 0.8540 - sae: 1856.1539 - sse: 2212.1218 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0824 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 289/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: 1.1406e-16 - r2_keras: -97.0927 - rmse: 0.8619 - sae: 2538.3796 - sse: 3042.7119\n","Epoch 289: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1539e-16 - r2_keras: -80.0514 - rmse: 0.8540 - sae: 1856.1545 - sse: 2212.1238 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0822 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 290/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -8.9835e-17 - r2_keras: -97.0927 - rmse: 0.8619 - sae: 2538.3794 - sse: 3042.7119\n","Epoch 290: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.0086e-17 - r2_keras: -80.0514 - rmse: 0.8540 - sae: 1856.1543 - sse: 2212.1235 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0824 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 291/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1698 - pearson_correlation: -2.0052e-16 - r2_keras: -97.0928 - rmse: 0.8619 - sae: 2538.3804 - sse: 3042.7151\n","Epoch 291: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.5671e-16 - r2_keras: -80.0515 - rmse: 0.8540 - sae: 1856.1552 - sse: 2212.1260 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0823 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 292/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.7314e-16 - r2_keras: -97.0928 - rmse: 0.8619 - sae: 2538.3806 - sse: 3042.7153\n","Epoch 292: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.4666e-16 - r2_keras: -80.0515 - rmse: 0.8540 - sae: 1856.1552 - sse: 2212.1260 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0823 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 293/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.4238e-16 - r2_keras: -97.0929 - rmse: 0.8619 - sae: 2538.3813 - sse: 3042.7180\n","Epoch 293: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.6333e-16 - r2_keras: -80.0516 - rmse: 0.8540 - sae: 1856.1558 - sse: 2212.1282 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0822 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 294/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.6061e-16 - r2_keras: -97.0929 - rmse: 0.8619 - sae: 2538.3813 - sse: 3042.7183\n","Epoch 294: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.5359e-16 - r2_keras: -80.0516 - rmse: 0.8540 - sae: 1856.1556 - sse: 2212.1282 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0823 - val_sse: 483.3170 - learning_rate: 1.0000e-05\n","Epoch 295/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.0012e-16 - r2_keras: -97.0929 - rmse: 0.8619 - sae: 2538.3821 - sse: 3042.7205\n","Epoch 295: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7730e-16 - r2_keras: -80.0517 - rmse: 0.8540 - sae: 1856.1564 - sse: 2212.1299 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.9172e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0822 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 296/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.1733e-16 - r2_keras: -97.0930 - rmse: 0.8619 - sae: 2538.3821 - sse: 3042.7207\n","Epoch 296: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.4227e-16 - r2_keras: -80.0516 - rmse: 0.8540 - sae: 1856.1562 - sse: 2212.1299 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0819 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 297/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.6155e-17 - r2_keras: -97.0929 - rmse: 0.8619 - sae: 2538.3816 - sse: 3042.7188\n","Epoch 297: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.2654e-16 - r2_keras: -80.0516 - rmse: 0.8540 - sae: 1856.1559 - sse: 2212.1284 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0822 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 298/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.9981e-16 - r2_keras: -97.0930 - rmse: 0.8619 - sae: 2538.3828 - sse: 3042.7227\n","Epoch 298: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.9455e-16 - r2_keras: -80.0517 - rmse: 0.8540 - sae: 1856.1569 - sse: 2212.1313 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0821 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 299/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 9.6579e-17 - r2_keras: -97.0930 - rmse: 0.8619 - sae: 2538.3831 - sse: 3042.7236\n","Epoch 299: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.2869e-17 - r2_keras: -80.0517 - rmse: 0.8540 - sae: 1856.1570 - sse: 2212.1318 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.8050e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0822 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 300/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.5019e-16 - r2_keras: -97.0932 - rmse: 0.8619 - sae: 2538.3843 - sse: 3042.7271\n","Epoch 300: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.5239e-16 - r2_keras: -80.0518 - rmse: 0.8540 - sae: 1856.1578 - sse: 2212.1345 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 301/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.9368e-16 - r2_keras: -97.0931 - rmse: 0.8619 - sae: 2538.3833 - sse: 3042.7244\n","Epoch 301: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.2580e-16 - r2_keras: -80.0517 - rmse: 0.8540 - sae: 1856.1571 - sse: 2212.1323 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0821 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 302/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.1769e-17 - r2_keras: -97.0932 - rmse: 0.8619 - sae: 2538.3848 - sse: 3042.7295\n","Epoch 302: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0673e-17 - r2_keras: -80.0519 - rmse: 0.8540 - sae: 1856.1583 - sse: 2212.1362 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0819 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 303/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.3226e-16 - r2_keras: -97.0932 - rmse: 0.8619 - sae: 2538.3843 - sse: 3042.7285\n","Epoch 303: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.5274e-16 - r2_keras: -80.0518 - rmse: 0.8540 - sae: 1856.1578 - sse: 2212.1353 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0819 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 304/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.5698e-16 - r2_keras: -97.0933 - rmse: 0.8619 - sae: 2538.3855 - sse: 3042.7324\n","Epoch 304: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2577e-16 - r2_keras: -80.0519 - rmse: 0.8540 - sae: 1856.1588 - sse: 2212.1382 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0819 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 305/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.5433e-16 - r2_keras: -97.0933 - rmse: 0.8619 - sae: 2538.3855 - sse: 3042.7319\n","Epoch 305: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.0219e-16 - r2_keras: -80.0519 - rmse: 0.8540 - sae: 1856.1588 - sse: 2212.1377 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0820 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 306/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.9254e-16 - r2_keras: -97.0934 - rmse: 0.8619 - sae: 2538.3862 - sse: 3042.7346\n","Epoch 306: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.3252e-17 - r2_keras: -80.0520 - rmse: 0.8540 - sae: 1856.1593 - sse: 2212.1399 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 307/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.5514e-16 - r2_keras: -97.0934 - rmse: 0.8619 - sae: 2538.3865 - sse: 3042.7351\n","Epoch 307: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1494e-16 - r2_keras: -80.0520 - rmse: 0.8540 - sae: 1856.1594 - sse: 2212.1399 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4535 - val_rmse: 0.9558 - val_sae: 363.0820 - val_sse: 483.3169 - learning_rate: 1.0000e-05\n","Epoch 308/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.4197e-17 - r2_keras: -97.0935 - rmse: 0.8619 - sae: 2538.3875 - sse: 3042.7383\n","Epoch 308: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.9711e-17 - r2_keras: -80.0521 - rmse: 0.8540 - sae: 1856.1603 - sse: 2212.1426 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 309/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.6342e-16 - r2_keras: -97.0935 - rmse: 0.8619 - sae: 2538.3872 - sse: 3042.7378\n","Epoch 309: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.0553e-17 - r2_keras: -80.0521 - rmse: 0.8540 - sae: 1856.1600 - sse: 2212.1418 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0819 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 310/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.3695e-16 - r2_keras: -97.0936 - rmse: 0.8619 - sae: 2538.3884 - sse: 3042.7412\n","Epoch 310: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.1696e-16 - r2_keras: -80.0522 - rmse: 0.8540 - sae: 1856.1610 - sse: 2212.1445 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2826 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0817 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 311/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 9.2900e-16 - r2_keras: -97.0936 - rmse: 0.8619 - sae: 2538.3879 - sse: 3042.7405\n","Epoch 311: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.5580e-16 - r2_keras: -80.0521 - rmse: 0.8540 - sae: 1856.1605 - sse: 2212.1438 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 312/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.4641e-16 - r2_keras: -97.0937 - rmse: 0.8619 - sae: 2538.3887 - sse: 3042.7432\n","Epoch 312: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.5153e-16 - r2_keras: -80.0522 - rmse: 0.8540 - sae: 1856.1613 - sse: 2212.1460 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.9172e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 313/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.6802e-16 - r2_keras: -97.0937 - rmse: 0.8619 - sae: 2538.3892 - sse: 3042.7441\n","Epoch 313: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.5520e-16 - r2_keras: -80.0522 - rmse: 0.8540 - sae: 1856.1615 - sse: 2212.1465 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 314/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.1651e-16 - r2_keras: -97.0938 - rmse: 0.8619 - sae: 2538.3899 - sse: 3042.7468\n","Epoch 314: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.8037e-16 - r2_keras: -80.0523 - rmse: 0.8540 - sae: 1856.1621 - sse: 2212.1487 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 315/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.2080e-16 - r2_keras: -97.0938 - rmse: 0.8619 - sae: 2538.3896 - sse: 3042.7463\n","Epoch 315: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0741e-16 - r2_keras: -80.0523 - rmse: 0.8540 - sae: 1856.1619 - sse: 2212.1479 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0818 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 316/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.0216e-16 - r2_keras: -97.0939 - rmse: 0.8619 - sae: 2538.3911 - sse: 3042.7495\n","Epoch 316: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.4655e-16 - r2_keras: -80.0524 - rmse: 0.8540 - sae: 1856.1630 - sse: 2212.1504 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.8148e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 317/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.1651e-17 - r2_keras: -97.0939 - rmse: 0.8619 - sae: 2538.3906 - sse: 3042.7490\n","Epoch 317: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.3124e-17 - r2_keras: -80.0524 - rmse: 0.8540 - sae: 1856.1626 - sse: 2212.1499 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0817 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 318/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.1957e-17 - r2_keras: -97.0939 - rmse: 0.8619 - sae: 2538.3914 - sse: 3042.7515\n","Epoch 318: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.3328e-17 - r2_keras: -80.0524 - rmse: 0.8540 - sae: 1856.1632 - sse: 2212.1519 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 319/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.5269e-16 - r2_keras: -97.0939 - rmse: 0.8619 - sae: 2538.3914 - sse: 3042.7515\n","Epoch 319: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.9403e-17 - r2_keras: -80.0524 - rmse: 0.8540 - sae: 1856.1631 - sse: 2212.1516 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0817 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 320/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.2693e-16 - r2_keras: -97.0941 - rmse: 0.8619 - sae: 2538.3923 - sse: 3042.7551\n","Epoch 320: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.5983e-17 - r2_keras: -80.0525 - rmse: 0.8540 - sae: 1856.1639 - sse: 2212.1545 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 321/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.1738e-16 - r2_keras: -97.0941 - rmse: 0.8619 - sae: 2538.3926 - sse: 3042.7556\n","Epoch 321: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -9.8848e-17 - r2_keras: -80.0525 - rmse: 0.8540 - sae: 1856.1639 - sse: 2212.1548 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 322/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.5177e-16 - r2_keras: -97.0941 - rmse: 0.8619 - sae: 2538.3931 - sse: 3042.7573\n","Epoch 322: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.3477e-16 - r2_keras: -80.0526 - rmse: 0.8540 - sae: 1856.1644 - sse: 2212.1562 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0815 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 323/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.8273e-16 - r2_keras: -97.0942 - rmse: 0.8619 - sae: 2538.3933 - sse: 3042.7581\n","Epoch 323: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2758e-16 - r2_keras: -80.0526 - rmse: 0.8540 - sae: 1856.1646 - sse: 2212.1565 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 324/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.9162e-16 - r2_keras: -97.0943 - rmse: 0.8619 - sae: 2538.3940 - sse: 3042.7610\n","Epoch 324: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -6.0563e-17 - r2_keras: -80.0527 - rmse: 0.8540 - sae: 1856.1652 - sse: 2212.1587 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0814 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 325/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.2004e-17 - r2_keras: -97.0942 - rmse: 0.8619 - sae: 2538.3940 - sse: 3042.7607\n","Epoch 325: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.9339e-17 - r2_keras: -80.0527 - rmse: 0.8540 - sae: 1856.1652 - sse: 2212.1584 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0816 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 326/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -9.4125e-17 - r2_keras: -97.0943 - rmse: 0.8619 - sae: 2538.3948 - sse: 3042.7632\n","Epoch 326: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.6680e-17 - r2_keras: -80.0527 - rmse: 0.8540 - sae: 1856.1656 - sse: 2212.1604 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0814 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 327/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.5417e-16 - r2_keras: -97.0943 - rmse: 0.8619 - sae: 2538.3950 - sse: 3042.7632\n","Epoch 327: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.3297e-16 - r2_keras: -80.0527 - rmse: 0.8540 - sae: 1856.1658 - sse: 2212.1602 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0815 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 328/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.3394e-17 - r2_keras: -97.0945 - rmse: 0.8619 - sae: 2538.3962 - sse: 3042.7671\n","Epoch 328: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 7.9591e-17 - r2_keras: -80.0528 - rmse: 0.8540 - sae: 1856.1667 - sse: 2212.1631 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0814 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 329/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.0481e-16 - r2_keras: -97.0944 - rmse: 0.8619 - sae: 2538.3955 - sse: 3042.7661\n","Epoch 329: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.9604e-16 - r2_keras: -80.0528 - rmse: 0.8540 - sae: 1856.1661 - sse: 2212.1621 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0815 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 330/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.8820e-16 - r2_keras: -97.0945 - rmse: 0.8619 - sae: 2538.3965 - sse: 3042.7690\n","Epoch 330: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.4972e-16 - r2_keras: -80.0529 - rmse: 0.8540 - sae: 1856.1670 - sse: 2212.1646 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0814 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 331/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.5544e-16 - r2_keras: -97.0945 - rmse: 0.8619 - sae: 2538.3967 - sse: 3042.7695\n","Epoch 331: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -9.0192e-17 - r2_keras: -80.0529 - rmse: 0.8540 - sae: 1856.1671 - sse: 2212.1648 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0815 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 332/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 6.1993e-16 - r2_keras: -97.0946 - rmse: 0.8619 - sae: 2538.3975 - sse: 3042.7725\n","Epoch 332: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.3536e-16 - r2_keras: -80.0530 - rmse: 0.8540 - sae: 1856.1676 - sse: 2212.1670 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0813 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 333/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.8135e-17 - r2_keras: -97.0946 - rmse: 0.8619 - sae: 2538.3970 - sse: 3042.7715\n","Epoch 333: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -8.0080e-17 - r2_keras: -80.0529 - rmse: 0.8540 - sae: 1856.1674 - sse: 2212.1660 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0814 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 334/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.3051e-16 - r2_keras: -97.0947 - rmse: 0.8619 - sae: 2538.3984 - sse: 3042.7754\n","Epoch 334: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.0672e-16 - r2_keras: -80.0530 - rmse: 0.8540 - sae: 1856.1683 - sse: 2212.1689 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 335/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.0424e-17 - r2_keras: -97.0947 - rmse: 0.8619 - sae: 2538.3984 - sse: 3042.7749\n","Epoch 335: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0884e-17 - r2_keras: -80.0530 - rmse: 0.8540 - sae: 1856.1683 - sse: 2212.1685 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0813 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 336/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.1518e-16 - r2_keras: -97.0948 - rmse: 0.8619 - sae: 2538.3989 - sse: 3042.7778\n","Epoch 336: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.0820e-16 - r2_keras: -80.0531 - rmse: 0.8540 - sae: 1856.1688 - sse: 2212.1707 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 337/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 9.3634e-16 - r2_keras: -97.0948 - rmse: 0.8619 - sae: 2538.3989 - sse: 3042.7778\n","Epoch 337: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.9045e-16 - r2_keras: -80.0531 - rmse: 0.8540 - sae: 1856.1687 - sse: 2212.1707 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 338/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.7767e-16 - r2_keras: -97.0949 - rmse: 0.8619 - sae: 2538.3999 - sse: 3042.7803\n","Epoch 338: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.2517e-16 - r2_keras: -80.0532 - rmse: 0.8540 - sae: 1856.1696 - sse: 2212.1726 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 339/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.7686e-17 - r2_keras: -97.0949 - rmse: 0.8619 - sae: 2538.3994 - sse: 3042.7805\n","Epoch 339: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.3236e-16 - r2_keras: -80.0532 - rmse: 0.8540 - sae: 1856.1691 - sse: 2212.1726 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.6928e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0813 - val_sse: 483.3167 - learning_rate: 1.0000e-05\n","Epoch 340/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.8937e-17 - r2_keras: -97.0950 - rmse: 0.8619 - sae: 2538.4011 - sse: 3042.7842\n","Epoch 340: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.0669e-17 - r2_keras: -80.0533 - rmse: 0.8540 - sae: 1856.1704 - sse: 2212.1753 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.9172e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0811 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 341/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.0603e-16 - r2_keras: -97.0949 - rmse: 0.8619 - sae: 2538.4004 - sse: 3042.7825\n","Epoch 341: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2584e-16 - r2_keras: -80.0532 - rmse: 0.8540 - sae: 1856.1698 - sse: 2212.1738 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 342/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.0353e-16 - r2_keras: -97.0951 - rmse: 0.8619 - sae: 2538.4016 - sse: 3042.7861\n","Epoch 342: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0619e-16 - r2_keras: -80.0533 - rmse: 0.8540 - sae: 1856.1708 - sse: 2212.1768 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 343/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.8237e-16 - r2_keras: -97.0950 - rmse: 0.8619 - sae: 2538.4014 - sse: 3042.7856\n","Epoch 343: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.6215e-16 - r2_keras: -80.0533 - rmse: 0.8540 - sae: 1856.1705 - sse: 2212.1763 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 344/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.7287e-16 - r2_keras: -97.0952 - rmse: 0.8619 - sae: 2538.4028 - sse: 3042.7896\n","Epoch 344: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.2894e-16 - r2_keras: -80.0534 - rmse: 0.8540 - sae: 1856.1716 - sse: 2212.1792 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0810 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 345/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.9826e-16 - r2_keras: -97.0952 - rmse: 0.8619 - sae: 2538.4023 - sse: 3042.7891\n","Epoch 345: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.3000e-16 - r2_keras: -80.0534 - rmse: 0.8540 - sae: 1856.1713 - sse: 2212.1787 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.7222e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 346/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.3735e-16 - r2_keras: -97.0952 - rmse: 0.8619 - sae: 2538.4028 - sse: 3042.7910\n","Epoch 346: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.8560e-17 - r2_keras: -80.0535 - rmse: 0.8540 - sae: 1856.1718 - sse: 2212.1802 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0811 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 347/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.3843e-17 - r2_keras: -97.0952 - rmse: 0.8619 - sae: 2538.4033 - sse: 3042.7917\n","Epoch 347: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4922e-17 - r2_keras: -80.0534 - rmse: 0.8540 - sae: 1856.1720 - sse: 2212.1804 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0812 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 348/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.6397e-16 - r2_keras: -97.0954 - rmse: 0.8619 - sae: 2538.4048 - sse: 3042.7954\n","Epoch 348: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 9.1522e-17 - r2_keras: -80.0536 - rmse: 0.8540 - sae: 1856.1731 - sse: 2212.1833 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 349/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -8.2473e-17 - r2_keras: -97.0953 - rmse: 0.8619 - sae: 2538.4036 - sse: 3042.7935\n","Epoch 349: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0969e-16 - r2_keras: -80.0535 - rmse: 0.8540 - sae: 1856.1722 - sse: 2212.1819 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0811 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 350/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.6275e-16 - r2_keras: -97.0954 - rmse: 0.8619 - sae: 2538.4048 - sse: 3042.7974\n","Epoch 350: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.4925e-16 - r2_keras: -80.0536 - rmse: 0.8540 - sae: 1856.1731 - sse: 2212.1848 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 351/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.4466e-16 - r2_keras: -97.0954 - rmse: 0.8619 - sae: 2538.4048 - sse: 3042.7974\n","Epoch 351: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 9.9761e-17 - r2_keras: -80.0536 - rmse: 0.8540 - sae: 1856.1730 - sse: 2212.1846 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 352/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.2075e-17 - r2_keras: -97.0955 - rmse: 0.8619 - sae: 2538.4060 - sse: 3042.8005\n","Epoch 352: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -9.2459e-17 - r2_keras: -80.0537 - rmse: 0.8540 - sae: 1856.1740 - sse: 2212.1870 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 353/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.3607e-17 - r2_keras: -97.0955 - rmse: 0.8619 - sae: 2538.4058 - sse: 3042.7998\n","Epoch 353: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 7.5245e-17 - r2_keras: -80.0537 - rmse: 0.8540 - sae: 1856.1737 - sse: 2212.1863 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0810 - val_sse: 483.3166 - learning_rate: 1.0000e-05\n","Epoch 354/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.0260e-16 - r2_keras: -97.0956 - rmse: 0.8619 - sae: 2538.4067 - sse: 3042.8037\n","Epoch 354: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.1037e-16 - r2_keras: -80.0538 - rmse: 0.8540 - sae: 1856.1746 - sse: 2212.1892 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0808 - val_sse: 483.3160 - learning_rate: 1.0000e-05\n","Epoch 355/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.5973e-16 - r2_keras: -97.0956 - rmse: 0.8619 - sae: 2538.4065 - sse: 3042.8025\n","Epoch 355: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -7.6314e-18 - r2_keras: -80.0537 - rmse: 0.8540 - sae: 1856.1743 - sse: 2212.1882 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7320e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 356/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 7.1374e-16 - r2_keras: -97.0957 - rmse: 0.8619 - sae: 2538.4075 - sse: 3042.8064\n","Epoch 356: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.5759e-16 - r2_keras: -80.0538 - rmse: 0.8540 - sae: 1856.1752 - sse: 2212.1912 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 357/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.2463e-16 - r2_keras: -97.0957 - rmse: 0.8619 - sae: 2538.4075 - sse: 3042.8052\n","Epoch 357: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.4835e-16 - r2_keras: -80.0538 - rmse: 0.8540 - sae: 1856.1750 - sse: 2212.1902 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0808 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 358/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.4185e-16 - r2_keras: -97.0958 - rmse: 0.8619 - sae: 2538.4082 - sse: 3042.8086\n","Epoch 358: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.4901e-16 - r2_keras: -80.0539 - rmse: 0.8540 - sae: 1856.1757 - sse: 2212.1929 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0808 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 359/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.2851e-17 - r2_keras: -97.0958 - rmse: 0.8619 - sae: 2538.4087 - sse: 3042.8086\n","Epoch 359: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.1196e-16 - r2_keras: -80.0539 - rmse: 0.8540 - sae: 1856.1759 - sse: 2212.1926 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0809 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 360/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -5.3040e-17 - r2_keras: -97.0959 - rmse: 0.8619 - sae: 2538.4092 - sse: 3042.8120\n","Epoch 360: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -6.5666e-18 - r2_keras: -80.0540 - rmse: 0.8540 - sae: 1856.1764 - sse: 2212.1953 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0807 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 361/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.1277e-16 - r2_keras: -97.0959 - rmse: 0.8619 - sae: 2538.4092 - sse: 3042.8110\n","Epoch 361: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -9.7699e-17 - r2_keras: -80.0539 - rmse: 0.8540 - sae: 1856.1763 - sse: 2212.1943 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0808 - val_sse: 483.3165 - learning_rate: 1.0000e-05\n","Epoch 362/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.8911e-17 - r2_keras: -97.0960 - rmse: 0.8619 - sae: 2538.4102 - sse: 3042.8149\n","Epoch 362: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.0480e-17 - r2_keras: -80.0541 - rmse: 0.8540 - sae: 1856.1771 - sse: 2212.1973 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0806 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 363/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.5825e-16 - r2_keras: -97.0960 - rmse: 0.8619 - sae: 2538.4097 - sse: 3042.8140\n","Epoch 363: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.3307e-16 - r2_keras: -80.0540 - rmse: 0.8540 - sae: 1856.1766 - sse: 2212.1965 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0807 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 364/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -5.5063e-16 - r2_keras: -97.0961 - rmse: 0.8619 - sae: 2538.4106 - sse: 3042.8169\n","Epoch 364: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.3829e-16 - r2_keras: -80.0541 - rmse: 0.8540 - sae: 1856.1774 - sse: 2212.1987 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0806 - val_sse: 483.3160 - learning_rate: 1.0000e-05\n","Epoch 365/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.8027e-16 - r2_keras: -97.0961 - rmse: 0.8619 - sae: 2538.4106 - sse: 3042.8169\n","Epoch 365: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.2306e-16 - r2_keras: -80.0541 - rmse: 0.8540 - sae: 1856.1774 - sse: 2212.1985 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0807 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 366/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.4333e-16 - r2_keras: -97.0962 - rmse: 0.8619 - sae: 2538.4116 - sse: 3042.8203\n","Epoch 366: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.0803e-16 - r2_keras: -80.0542 - rmse: 0.8540 - sae: 1856.1782 - sse: 2212.2012 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0806 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 367/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.3612e-16 - r2_keras: -97.0962 - rmse: 0.8619 - sae: 2538.4116 - sse: 3042.8201\n","Epoch 367: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.6177e-16 - r2_keras: -80.0542 - rmse: 0.8540 - sae: 1856.1781 - sse: 2212.2007 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0807 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 368/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -9.2865e-16 - r2_keras: -97.0963 - rmse: 0.8619 - sae: 2538.4126 - sse: 3042.8230\n","Epoch 368: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -6.9012e-16 - r2_keras: -80.0543 - rmse: 0.8540 - sae: 1856.1788 - sse: 2212.2031 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0806 - val_sse: 483.3163 - learning_rate: 1.0000e-05\n","Epoch 369/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.4803e-16 - r2_keras: -97.0963 - rmse: 0.8619 - sae: 2538.4126 - sse: 3042.8235\n","Epoch 369: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2696e-16 - r2_keras: -80.0543 - rmse: 0.8540 - sae: 1856.1788 - sse: 2212.2031 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0806 - val_sse: 483.3164 - learning_rate: 1.0000e-05\n","Epoch 370/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.7567e-16 - r2_keras: -97.0964 - rmse: 0.8619 - sae: 2538.4136 - sse: 3042.8262\n","Epoch 370: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0848e-16 - r2_keras: -80.0544 - rmse: 0.8540 - sae: 1856.1796 - sse: 2212.2053 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0806 - val_sse: 483.3162 - learning_rate: 1.0000e-05\n","Epoch 371/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 9.2313e-16 - r2_keras: -97.0964 - rmse: 0.8619 - sae: 2538.4136 - sse: 3042.8262\n","Epoch 371: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.7146e-16 - r2_keras: -80.0543 - rmse: 0.8540 - sae: 1856.1796 - sse: 2212.2051 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0804 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 372/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.6484e-16 - r2_keras: -97.0963 - rmse: 0.8619 - sae: 2538.4131 - sse: 3042.8252\n","Epoch 372: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.9332e-16 - r2_keras: -80.0543 - rmse: 0.8540 - sae: 1856.1792 - sse: 2212.2043 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0804 - val_sse: 483.3160 - learning_rate: 1.0000e-05\n","Epoch 373/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.3704e-16 - r2_keras: -97.0964 - rmse: 0.8619 - sae: 2538.4141 - sse: 3042.8281\n","Epoch 373: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2208e-16 - r2_keras: -80.0544 - rmse: 0.8540 - sae: 1856.1799 - sse: 2212.2065 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0804 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 374/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.5456e-16 - r2_keras: -97.0964 - rmse: 0.8619 - sae: 2538.4141 - sse: 3042.8279\n","Epoch 374: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.3446e-16 - r2_keras: -80.0544 - rmse: 0.8540 - sae: 1856.1798 - sse: 2212.2061 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.1416e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0803 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 375/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.1788e-16 - r2_keras: -97.0965 - rmse: 0.8619 - sae: 2538.4148 - sse: 3042.8311\n","Epoch 375: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.0084e-16 - r2_keras: -80.0545 - rmse: 0.8540 - sae: 1856.1805 - sse: 2212.2087 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0802 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 376/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.1696e-17 - r2_keras: -97.0965 - rmse: 0.8619 - sae: 2538.4146 - sse: 3042.8308\n","Epoch 376: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.4424e-17 - r2_keras: -80.0544 - rmse: 0.8540 - sae: 1856.1803 - sse: 2212.2083 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0802 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 377/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.1640e-16 - r2_keras: -97.0966 - rmse: 0.8619 - sae: 2538.4153 - sse: 3042.8333\n","Epoch 377: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.4164e-16 - r2_keras: -80.0545 - rmse: 0.8540 - sae: 1856.1809 - sse: 2212.2102 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0802 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 378/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.8451e-16 - r2_keras: -97.0966 - rmse: 0.8619 - sae: 2538.4155 - sse: 3042.8335\n","Epoch 378: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.3497e-16 - r2_keras: -80.0545 - rmse: 0.8540 - sae: 1856.1809 - sse: 2212.2102 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0803 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 379/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.0028e-15 - r2_keras: -97.0967 - rmse: 0.8619 - sae: 2538.4170 - sse: 3042.8379\n","Epoch 379: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -6.8967e-16 - r2_keras: -80.0546 - rmse: 0.8540 - sae: 1856.1820 - sse: 2212.2136 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.0294e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0801 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 380/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.4128e-16 - r2_keras: -97.0967 - rmse: 0.8619 - sae: 2538.4163 - sse: 3042.8364\n","Epoch 380: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0039e-16 - r2_keras: -80.0546 - rmse: 0.8540 - sae: 1856.1815 - sse: 2212.2124 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.2538e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0802 - val_sse: 483.3160 - learning_rate: 1.0000e-05\n","Epoch 381/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.8022e-16 - r2_keras: -97.0968 - rmse: 0.8619 - sae: 2538.4175 - sse: 3042.8396\n","Epoch 381: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.2808e-16 - r2_keras: -80.0547 - rmse: 0.8540 - sae: 1856.1825 - sse: 2212.2146 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0801 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 382/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.4148e-17 - r2_keras: -97.0968 - rmse: 0.8619 - sae: 2538.4172 - sse: 3042.8389\n","Epoch 382: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 9.2769e-18 - r2_keras: -80.0546 - rmse: 0.8540 - sae: 1856.1823 - sse: 2212.2141 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0802 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 383/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.7782e-17 - r2_keras: -97.0969 - rmse: 0.8619 - sae: 2538.4185 - sse: 3042.8420\n","Epoch 383: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.4213e-18 - r2_keras: -80.0547 - rmse: 0.8540 - sae: 1856.1832 - sse: 2212.2166 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0801 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 384/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.9784e-17 - r2_keras: -97.0969 - rmse: 0.8619 - sae: 2538.4182 - sse: 3042.8423\n","Epoch 384: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.2333e-17 - r2_keras: -80.0547 - rmse: 0.8540 - sae: 1856.1830 - sse: 2212.2166 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0801 - val_sse: 483.3158 - learning_rate: 1.0000e-05\n","Epoch 385/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.4368e-16 - r2_keras: -97.0970 - rmse: 0.8619 - sae: 2538.4189 - sse: 3042.8452\n","Epoch 385: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.8287e-16 - r2_keras: -80.0548 - rmse: 0.8540 - sae: 1856.1836 - sse: 2212.2188 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0800 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 386/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.2778e-18 - r2_keras: -97.0970 - rmse: 0.8619 - sae: 2538.4192 - sse: 3042.8457\n","Epoch 386: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.6392e-18 - r2_keras: -80.0548 - rmse: 0.8540 - sae: 1856.1837 - sse: 2212.2190 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.5806e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0800 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 387/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.5686e-16 - r2_keras: -97.0970 - rmse: 0.8619 - sae: 2538.4194 - sse: 3042.8474\n","Epoch 387: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.0605e-16 - r2_keras: -80.0549 - rmse: 0.8540 - sae: 1856.1840 - sse: 2212.2205 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0800 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 388/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.0346e-16 - r2_keras: -97.0971 - rmse: 0.8619 - sae: 2538.4197 - sse: 3042.8479\n","Epoch 388: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.3634e-16 - r2_keras: -80.0549 - rmse: 0.8540 - sae: 1856.1840 - sse: 2212.2205 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0801 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 389/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.4884e-16 - r2_keras: -97.0972 - rmse: 0.8619 - sae: 2538.4214 - sse: 3042.8516\n","Epoch 389: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.3378e-16 - r2_keras: -80.0550 - rmse: 0.8540 - sae: 1856.1853 - sse: 2212.2234 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.6928e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 390/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.2467e-16 - r2_keras: -97.0971 - rmse: 0.8619 - sae: 2538.4202 - sse: 3042.8494\n","Epoch 390: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0301e-16 - r2_keras: -80.0549 - rmse: 0.8540 - sae: 1856.1844 - sse: 2212.2217 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0800 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 391/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.0101e-16 - r2_keras: -97.0972 - rmse: 0.8619 - sae: 2538.4214 - sse: 3042.8535\n","Epoch 391: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.3087e-16 - r2_keras: -80.0550 - rmse: 0.8540 - sae: 1856.1854 - sse: 2212.2249 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0800 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 392/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.5904e-16 - r2_keras: -97.0972 - rmse: 0.8619 - sae: 2538.4216 - sse: 3042.8535\n","Epoch 392: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.5350e-16 - r2_keras: -80.0550 - rmse: 0.8540 - sae: 1856.1854 - sse: 2212.2244 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0799 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 393/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.9125e-17 - r2_keras: -97.0973 - rmse: 0.8619 - sae: 2538.4226 - sse: 3042.8564\n","Epoch 393: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.9727e-17 - r2_keras: -80.0551 - rmse: 0.8540 - sae: 1856.1863 - sse: 2212.2268 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 394/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.5302e-17 - r2_keras: -97.0973 - rmse: 0.8619 - sae: 2538.4219 - sse: 3042.8552\n","Epoch 394: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.6661e-17 - r2_keras: -80.0551 - rmse: 0.8540 - sae: 1856.1857 - sse: 2212.2258 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0800 - val_sse: 483.3161 - learning_rate: 1.0000e-05\n","Epoch 395/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.2308e-17 - r2_keras: -97.0975 - rmse: 0.8619 - sae: 2538.4236 - sse: 3042.8604\n","Epoch 395: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.3562e-17 - r2_keras: -80.0552 - rmse: 0.8540 - sae: 1856.1869 - sse: 2212.2297 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 396/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.8671e-16 - r2_keras: -97.0974 - rmse: 0.8619 - sae: 2538.4233 - sse: 3042.8591\n","Epoch 396: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.7041e-17 - r2_keras: -80.0552 - rmse: 0.8540 - sae: 1856.1866 - sse: 2212.2285 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0799 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 397/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 7.3580e-18 - r2_keras: -97.0975 - rmse: 0.8619 - sae: 2538.4238 - sse: 3042.8616\n","Epoch 397: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.6422e-17 - r2_keras: -80.0552 - rmse: 0.8540 - sae: 1856.1871 - sse: 2212.2305 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.7026e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0796 - val_sse: 483.3153 - learning_rate: 1.0000e-05\n","Epoch 398/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 7.6645e-16 - r2_keras: -97.0975 - rmse: 0.8619 - sae: 2538.4233 - sse: 3042.8601\n","Epoch 398: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.9081e-16 - r2_keras: -80.0552 - rmse: 0.8540 - sae: 1856.1868 - sse: 2212.2292 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 399/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.0209e-16 - r2_keras: -97.0976 - rmse: 0.8619 - sae: 2538.4248 - sse: 3042.8647\n","Epoch 399: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.0741e-16 - r2_keras: -80.0553 - rmse: 0.8540 - sae: 1856.1879 - sse: 2212.2327 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0797 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 400/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 9.1361e-17 - r2_keras: -97.0976 - rmse: 0.8619 - sae: 2538.4250 - sse: 3042.8645\n","Epoch 400: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.2919e-17 - r2_keras: -80.0553 - rmse: 0.8540 - sae: 1856.1880 - sse: 2212.2324 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3160 - learning_rate: 1.0000e-05\n","Epoch 401/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.7375e-17 - r2_keras: -97.0977 - rmse: 0.8619 - sae: 2538.4253 - sse: 3042.8672\n","Epoch 401: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.5371e-17 - r2_keras: -80.0554 - rmse: 0.8540 - sae: 1856.1884 - sse: 2212.2346 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0797 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 402/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.1461e-18 - r2_keras: -97.0977 - rmse: 0.8619 - sae: 2538.4255 - sse: 3042.8677\n","Epoch 402: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.0988e-16 - r2_keras: -80.0554 - rmse: 0.8540 - sae: 1856.1884 - sse: 2212.2346 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 403/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.4490e-16 - r2_keras: -97.0978 - rmse: 0.8619 - sae: 2538.4268 - sse: 3042.8711\n","Epoch 403: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.3185e-16 - r2_keras: -80.0555 - rmse: 0.8540 - sae: 1856.1893 - sse: 2212.2373 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0795 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 404/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.2395e-16 - r2_keras: -97.0977 - rmse: 0.8619 - sae: 2538.4258 - sse: 3042.8691\n","Epoch 404: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.1648e-16 - r2_keras: -80.0554 - rmse: 0.8540 - sae: 1856.1886 - sse: 2212.2356 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0798 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 405/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.6084e-16 - r2_keras: -97.0979 - rmse: 0.8619 - sae: 2538.4272 - sse: 3042.8730\n","Epoch 405: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.6762e-16 - r2_keras: -80.0555 - rmse: 0.8540 - sae: 1856.1897 - sse: 2212.2385 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.9172e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0796 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 406/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.0207e-17 - r2_keras: -97.0978 - rmse: 0.8619 - sae: 2538.4272 - sse: 3042.8726\n","Epoch 406: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.1030e-18 - r2_keras: -80.0555 - rmse: 0.8540 - sae: 1856.1896 - sse: 2212.2383 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0795 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 407/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.4030e-17 - r2_keras: -97.0980 - rmse: 0.8619 - sae: 2538.4282 - sse: 3042.8757\n","Epoch 407: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.6123e-17 - r2_keras: -80.0556 - rmse: 0.8540 - sae: 1856.1904 - sse: 2212.2407 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0794 - val_sse: 483.3153 - learning_rate: 1.0000e-05\n","Epoch 408/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.3765e-16 - r2_keras: -97.0979 - rmse: 0.8619 - sae: 2538.4277 - sse: 3042.8745\n","Epoch 408: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -9.1769e-17 - r2_keras: -80.0556 - rmse: 0.8540 - sae: 1856.1901 - sse: 2212.2395 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0796 - val_sse: 483.3158 - learning_rate: 1.0000e-05\n","Epoch 409/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.8562e-16 - r2_keras: -97.0981 - rmse: 0.8619 - sae: 2538.4287 - sse: 3042.8789\n","Epoch 409: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.7941e-16 - r2_keras: -80.0557 - rmse: 0.8540 - sae: 1856.1908 - sse: 2212.2429 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0795 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 410/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.3919e-16 - r2_keras: -97.0981 - rmse: 0.8619 - sae: 2538.4292 - sse: 3042.8789\n","Epoch 410: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2350e-16 - r2_keras: -80.0557 - rmse: 0.8540 - sae: 1856.1910 - sse: 2212.2427 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0796 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 411/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.6059e-17 - r2_keras: -97.0981 - rmse: 0.8619 - sae: 2538.4294 - sse: 3042.8809\n","Epoch 411: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.6320e-17 - r2_keras: -80.0557 - rmse: 0.8540 - sae: 1856.1913 - sse: 2212.2444 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0794 - val_sse: 483.3153 - learning_rate: 1.0000e-05\n","Epoch 412/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.3534e-16 - r2_keras: -97.0981 - rmse: 0.8619 - sae: 2538.4297 - sse: 3042.8811\n","Epoch 412: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.9119e-16 - r2_keras: -80.0557 - rmse: 0.8540 - sae: 1856.1914 - sse: 2212.2441 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0795 - val_sse: 483.3158 - learning_rate: 1.0000e-05\n","Epoch 413/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.8255e-16 - r2_keras: -97.0982 - rmse: 0.8619 - sae: 2538.4307 - sse: 3042.8838\n","Epoch 413: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.1019e-16 - r2_keras: -80.0558 - rmse: 0.8540 - sae: 1856.1923 - sse: 2212.2463 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0794 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 414/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.3816e-16 - r2_keras: -97.0982 - rmse: 0.8619 - sae: 2538.4307 - sse: 3042.8843\n","Epoch 414: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.5135e-16 - r2_keras: -80.0558 - rmse: 0.8540 - sae: 1856.1923 - sse: 2212.2466 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0794 - val_sse: 483.3158 - learning_rate: 1.0000e-05\n","Epoch 415/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.6717e-17 - r2_keras: -97.0983 - rmse: 0.8619 - sae: 2538.4312 - sse: 3042.8867\n","Epoch 415: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.1848e-17 - r2_keras: -80.0559 - rmse: 0.8540 - sae: 1856.1926 - sse: 2212.2485 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 416/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.0775e-17 - r2_keras: -97.0983 - rmse: 0.8619 - sae: 2538.4314 - sse: 3042.8862\n","Epoch 416: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7183e-17 - r2_keras: -80.0559 - rmse: 0.8540 - sae: 1856.1927 - sse: 2212.2478 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 417/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.3462e-17 - r2_keras: -97.0984 - rmse: 0.8619 - sae: 2538.4321 - sse: 3042.8896\n","Epoch 417: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.4473e-17 - r2_keras: -80.0560 - rmse: 0.8540 - sae: 1856.1934 - sse: 2212.2507 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.4782e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 418/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.7040e-16 - r2_keras: -97.0984 - rmse: 0.8619 - sae: 2538.4321 - sse: 3042.8894\n","Epoch 418: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.9082e-16 - r2_keras: -80.0559 - rmse: 0.8540 - sae: 1856.1932 - sse: 2212.2502 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 419/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.0346e-16 - r2_keras: -97.0985 - rmse: 0.8619 - sae: 2538.4326 - sse: 3042.8918\n","Epoch 419: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.8049e-16 - r2_keras: -80.0560 - rmse: 0.8540 - sae: 1856.1937 - sse: 2212.2522 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 420/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -9.5652e-17 - r2_keras: -97.0985 - rmse: 0.8619 - sae: 2538.4331 - sse: 3042.8926\n","Epoch 420: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2231e-16 - r2_keras: -80.0560 - rmse: 0.8540 - sae: 1856.1940 - sse: 2212.2524 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0794 - val_sse: 483.3159 - learning_rate: 1.0000e-05\n","Epoch 421/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.9604e-16 - r2_keras: -97.0986 - rmse: 0.8619 - sae: 2538.4341 - sse: 3042.8955\n","Epoch 421: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.8252e-16 - r2_keras: -80.0561 - rmse: 0.8540 - sae: 1856.1947 - sse: 2212.2549 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0791 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 422/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.7533e-16 - r2_keras: -97.0986 - rmse: 0.8619 - sae: 2538.4336 - sse: 3042.8945\n","Epoch 422: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -4.7850e-16 - r2_keras: -80.0561 - rmse: 0.8540 - sae: 1856.1943 - sse: 2212.2539 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 423/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.8598e-16 - r2_keras: -97.0987 - rmse: 0.8619 - sae: 2538.4346 - sse: 3042.8982\n","Epoch 423: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7843e-16 - r2_keras: -80.0562 - rmse: 0.8540 - sae: 1856.1952 - sse: 2212.2566 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0792 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 424/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.4643e-17 - r2_keras: -97.0987 - rmse: 0.8619 - sae: 2538.4351 - sse: 3042.8982\n","Epoch 424: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.5604e-17 - r2_keras: -80.0562 - rmse: 0.8540 - sae: 1856.1954 - sse: 2212.2566 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 425/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.1351e-16 - r2_keras: -97.0988 - rmse: 0.8619 - sae: 2538.4355 - sse: 3042.9006\n","Epoch 425: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.5962e-16 - r2_keras: -80.0562 - rmse: 0.8540 - sae: 1856.1958 - sse: 2212.2585 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0790 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 426/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -8.6148e-17 - r2_keras: -97.0987 - rmse: 0.8619 - sae: 2538.4351 - sse: 3042.9001\n","Epoch 426: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -6.8949e-17 - r2_keras: -80.0562 - rmse: 0.8540 - sae: 1856.1954 - sse: 2212.2578 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.1514e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0793 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 427/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.6795e-16 - r2_keras: -97.0989 - rmse: 0.8619 - sae: 2538.4368 - sse: 3042.9043\n","Epoch 427: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.1414e-16 - r2_keras: -80.0563 - rmse: 0.8540 - sae: 1856.1967 - sse: 2212.2610 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0789 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 428/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 6.6527e-17 - r2_keras: -97.0988 - rmse: 0.8619 - sae: 2538.4355 - sse: 3042.9019\n","Epoch 428: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.2274e-17 - r2_keras: -80.0563 - rmse: 0.8540 - sae: 1856.1958 - sse: 2212.2593 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0791 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 429/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.9763e-16 - r2_keras: -97.0989 - rmse: 0.8619 - sae: 2538.4365 - sse: 3042.9060\n","Epoch 429: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0078e-16 - r2_keras: -80.0564 - rmse: 0.8540 - sae: 1856.1967 - sse: 2212.2622 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.3856e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0790 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 430/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.8531e-16 - r2_keras: -97.0989 - rmse: 0.8619 - sae: 2538.4370 - sse: 3042.9062\n","Epoch 430: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.9667e-16 - r2_keras: -80.0564 - rmse: 0.8540 - sae: 1856.1969 - sse: 2212.2622 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.8050e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0790 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 431/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.5841e-18 - r2_keras: -97.0990 - rmse: 0.8619 - sae: 2538.4377 - sse: 3042.9087\n","Epoch 431: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.0583e-17 - r2_keras: -80.0565 - rmse: 0.8540 - sae: 1856.1975 - sse: 2212.2644 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0789 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 432/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.1817e-16 - r2_keras: -97.0990 - rmse: 0.8619 - sae: 2538.4373 - sse: 3042.9082\n","Epoch 432: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.9222e-16 - r2_keras: -80.0564 - rmse: 0.8540 - sae: 1856.1971 - sse: 2212.2637 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0791 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 433/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.2294e-16 - r2_keras: -97.0992 - rmse: 0.8619 - sae: 2538.4395 - sse: 3042.9131\n","Epoch 433: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.7856e-17 - r2_keras: -80.0566 - rmse: 0.8540 - sae: 1856.1987 - sse: 2212.2673 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.1514e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0789 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 434/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.8776e-16 - r2_keras: -97.0991 - rmse: 0.8619 - sae: 2538.4390 - sse: 3042.9124\n","Epoch 434: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.7412e-16 - r2_keras: -80.0565 - rmse: 0.8540 - sae: 1856.1982 - sse: 2212.2666 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0791 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 435/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.4746e-16 - r2_keras: -97.0992 - rmse: 0.8619 - sae: 2538.4399 - sse: 3042.9150\n","Epoch 435: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.5397e-16 - r2_keras: -80.0566 - rmse: 0.8540 - sae: 1856.1991 - sse: 2212.2688 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0788 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 436/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.0178e-16 - r2_keras: -97.0992 - rmse: 0.8619 - sae: 2538.4397 - sse: 3042.9146\n","Epoch 436: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1296e-16 - r2_keras: -80.0566 - rmse: 0.8540 - sae: 1856.1989 - sse: 2212.2681 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0790 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 437/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 7.2351e-17 - r2_keras: -97.0993 - rmse: 0.8619 - sae: 2538.4404 - sse: 3042.9175\n","Epoch 437: val_loss did not improve from 0.19326\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 4.0556e-17 - r2_keras: -80.0567 - rmse: 0.8541 - sae: 1856.1995 - sse: 2212.2705 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0789 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 438/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.7689e-16 - r2_keras: -97.0993 - rmse: 0.8619 - sae: 2538.4404 - sse: 3042.9172\n","Epoch 438: val_loss improved from 0.19326 to 0.19326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.2177e-16 - r2_keras: -80.0567 - rmse: 0.8540 - sae: 1856.1993 - sse: 2212.2700 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0787 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 439/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.5783e-16 - r2_keras: -97.0993 - rmse: 0.8619 - sae: 2538.4404 - sse: 3042.9192\n","Epoch 439: val_loss improved from 0.19326 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.0164e-16 - r2_keras: -80.0567 - rmse: 0.8541 - sae: 1856.1996 - sse: 2212.2717 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9760e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0787 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 440/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.8352e-16 - r2_keras: -97.0994 - rmse: 0.8619 - sae: 2538.4409 - sse: 3042.9202\n","Epoch 440: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.0865e-16 - r2_keras: -80.0567 - rmse: 0.8541 - sae: 1856.1997 - sse: 2212.2722 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0789 - val_sse: 483.3155 - learning_rate: 1.0000e-05\n","Epoch 441/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.0669e-16 - r2_keras: -97.0995 - rmse: 0.8619 - sae: 2538.4419 - sse: 3042.9229\n","Epoch 441: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.9360e-17 - r2_keras: -80.0568 - rmse: 0.8541 - sae: 1856.2006 - sse: 2212.2744 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0786 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 442/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.6678e-16 - r2_keras: -97.0994 - rmse: 0.8619 - sae: 2538.4414 - sse: 3042.9219\n","Epoch 442: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.4190e-16 - r2_keras: -80.0568 - rmse: 0.8541 - sae: 1856.2002 - sse: 2212.2734 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0787 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 443/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.2129e-16 - r2_keras: -97.0996 - rmse: 0.8619 - sae: 2538.4429 - sse: 3042.9260\n","Epoch 443: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1654 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.9596e-16 - r2_keras: -80.0569 - rmse: 0.8541 - sae: 1856.2013 - sse: 2212.2766 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0788 - val_sse: 483.3153 - learning_rate: 1.0000e-05\n","Epoch 444/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 7.8176e-17 - r2_keras: -97.0996 - rmse: 0.8619 - sae: 2538.4431 - sse: 3042.9265\n","Epoch 444: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.6204e-17 - r2_keras: -80.0569 - rmse: 0.8541 - sae: 1856.2014 - sse: 2212.2769 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0787 - val_sse: 483.3154 - learning_rate: 1.0000e-05\n","Epoch 445/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.5482e-16 - r2_keras: -97.0996 - rmse: 0.8619 - sae: 2538.4434 - sse: 3042.9275\n","Epoch 445: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.5120e-16 - r2_keras: -80.0569 - rmse: 0.8541 - sae: 1856.2017 - sse: 2212.2778 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.8050e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0786 - val_sse: 483.3150 - learning_rate: 1.0000e-05\n","Epoch 446/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.6586e-16 - r2_keras: -97.0996 - rmse: 0.8619 - sae: 2538.4434 - sse: 3042.9282\n","Epoch 446: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1057e-16 - r2_keras: -80.0569 - rmse: 0.8541 - sae: 1856.2015 - sse: 2212.2781 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0788 - val_sse: 483.3157 - learning_rate: 1.0000e-05\n","Epoch 447/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.7842e-16 - r2_keras: -97.0998 - rmse: 0.8619 - sae: 2538.4448 - sse: 3042.9324\n","Epoch 447: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 6.9043e-17 - r2_keras: -80.0571 - rmse: 0.8541 - sae: 1856.2028 - sse: 2212.2812 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0785 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 448/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.5507e-16 - r2_keras: -97.0997 - rmse: 0.8619 - sae: 2538.4446 - sse: 3042.9309\n","Epoch 448: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.3915e-16 - r2_keras: -80.0570 - rmse: 0.8541 - sae: 1856.2025 - sse: 2212.2800 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8540e-17 - val_r2_keras: -33.4534 - val_rmse: 0.9558 - val_sae: 363.0787 - val_sse: 483.3156 - learning_rate: 1.0000e-05\n","Epoch 449/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.5562e-17 - r2_keras: -97.0998 - rmse: 0.8619 - sae: 2538.4453 - sse: 3042.9346\n","Epoch 449: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 5.4420e-17 - r2_keras: -80.0571 - rmse: 0.8541 - sae: 1856.2031 - sse: 2212.2827 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0786 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 450/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.4888e-16 - r2_keras: -97.0998 - rmse: 0.8619 - sae: 2538.4453 - sse: 3042.9343\n","Epoch 450: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.4218e-16 - r2_keras: -80.0571 - rmse: 0.8541 - sae: 1856.2030 - sse: 2212.2822 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.9172e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0784 - val_sse: 483.3147 - learning_rate: 1.0000e-05\n","Epoch 451/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.2134e-16 - r2_keras: -97.0998 - rmse: 0.8619 - sae: 2538.4451 - sse: 3042.9336\n","Epoch 451: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.4276e-16 - r2_keras: -80.0571 - rmse: 0.8541 - sae: 1856.2028 - sse: 2212.2817 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0785 - val_sse: 483.3152 - learning_rate: 1.0000e-05\n","Epoch 452/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.9756e-16 - r2_keras: -97.0999 - rmse: 0.8619 - sae: 2538.4458 - sse: 3042.9365\n","Epoch 452: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.2883e-16 - r2_keras: -80.0571 - rmse: 0.8541 - sae: 1856.2035 - sse: 2212.2839 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 453/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.0381e-16 - r2_keras: -97.0999 - rmse: 0.8619 - sae: 2538.4456 - sse: 3042.9358\n","Epoch 453: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.6780e-16 - r2_keras: -80.0571 - rmse: 0.8541 - sae: 1856.2032 - sse: 2212.2832 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0783 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 454/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.7383e-16 - r2_keras: -97.1000 - rmse: 0.8619 - sae: 2538.4468 - sse: 3042.9392\n","Epoch 454: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 2.0994e-16 - r2_keras: -80.0572 - rmse: 0.8541 - sae: 1856.2041 - sse: 2212.2859 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8540e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0783 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 455/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.7279e-16 - r2_keras: -97.1000 - rmse: 0.8619 - sae: 2538.4470 - sse: 3042.9395\n","Epoch 455: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.5639e-16 - r2_keras: -80.0572 - rmse: 0.8541 - sae: 1856.2042 - sse: 2212.2859 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6100e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0784 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 456/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.0755e-16 - r2_keras: -97.1001 - rmse: 0.8619 - sae: 2538.4480 - sse: 3042.9431\n","Epoch 456: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7273e-16 - r2_keras: -80.0573 - rmse: 0.8541 - sae: 1856.2050 - sse: 2212.2886 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.1514e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 457/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.0718e-16 - r2_keras: -97.1001 - rmse: 0.8619 - sae: 2538.4473 - sse: 3042.9414\n","Epoch 457: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.5296e-16 - r2_keras: -80.0573 - rmse: 0.8541 - sae: 1856.2045 - sse: 2212.2874 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6100e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0783 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 458/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.1387e-17 - r2_keras: -97.1002 - rmse: 0.8619 - sae: 2538.4487 - sse: 3042.9453\n","Epoch 458: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.1013e-16 - r2_keras: -80.0574 - rmse: 0.8541 - sae: 1856.2056 - sse: 2212.2903 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9761e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0781 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 459/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.0191e-16 - r2_keras: -97.1002 - rmse: 0.8619 - sae: 2538.4482 - sse: 3042.9446\n","Epoch 459: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.3128e-16 - r2_keras: -80.0573 - rmse: 0.8541 - sae: 1856.2052 - sse: 2212.2896 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3149 - learning_rate: 1.0000e-05\n","Epoch 460/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.6660e-16 - r2_keras: -97.1003 - rmse: 0.8619 - sae: 2538.4495 - sse: 3042.9475\n","Epoch 460: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7939e-16 - r2_keras: -80.0574 - rmse: 0.8541 - sae: 1856.2061 - sse: 2212.2917 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3147 - learning_rate: 1.0000e-05\n","Epoch 461/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.5175e-16 - r2_keras: -97.1002 - rmse: 0.8619 - sae: 2538.4487 - sse: 3042.9468\n","Epoch 461: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.6835e-16 - r2_keras: -80.0574 - rmse: 0.8541 - sae: 1856.2056 - sse: 2212.2913 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 462/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.5255e-17 - r2_keras: -97.1004 - rmse: 0.8619 - sae: 2538.4504 - sse: 3042.9512\n","Epoch 462: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -3.0242e-17 - r2_keras: -80.0575 - rmse: 0.8541 - sae: 1856.2068 - sse: 2212.2944 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4880e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0781 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 463/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.5598e-16 - r2_keras: -97.1003 - rmse: 0.8619 - sae: 2538.4497 - sse: 3042.9492\n","Epoch 463: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.8985e-16 - r2_keras: -80.0575 - rmse: 0.8541 - sae: 1856.2062 - sse: 2212.2930 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 464/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.4838e-16 - r2_keras: -97.1005 - rmse: 0.8619 - sae: 2538.4512 - sse: 3042.9536\n","Epoch 464: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.1236e-16 - r2_keras: -80.0576 - rmse: 0.8541 - sae: 1856.2074 - sse: 2212.2961 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0780 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 465/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.8591e-16 - r2_keras: -97.1004 - rmse: 0.8619 - sae: 2538.4507 - sse: 3042.9526\n","Epoch 465: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.2202e-16 - r2_keras: -80.0575 - rmse: 0.8541 - sae: 1856.2069 - sse: 2212.2952 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7320e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0782 - val_sse: 483.3151 - learning_rate: 1.0000e-05\n","Epoch 466/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.9708e-17 - r2_keras: -97.1005 - rmse: 0.8619 - sae: 2538.4521 - sse: 3042.9558\n","Epoch 466: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 8.2846e-18 - r2_keras: -80.0576 - rmse: 0.8541 - sae: 1856.2081 - sse: 2212.2979 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0780 - val_sse: 483.3147 - learning_rate: 1.0000e-05\n","Epoch 467/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.0136e-16 - r2_keras: -97.1005 - rmse: 0.8619 - sae: 2538.4514 - sse: 3042.9551\n","Epoch 467: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 1.5676e-16 - r2_keras: -80.0576 - rmse: 0.8541 - sae: 1856.2075 - sse: 2212.2971 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0781 - val_sse: 483.3149 - learning_rate: 1.0000e-05\n","Epoch 468/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.7984e-16 - r2_keras: -97.1006 - rmse: 0.8619 - sae: 2538.4529 - sse: 3042.9590\n","Epoch 468: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.8586e-16 - r2_keras: -80.0577 - rmse: 0.8541 - sae: 1856.2086 - sse: 2212.3000 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 469/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.8014e-16 - r2_keras: -97.1006 - rmse: 0.8619 - sae: 2538.4521 - sse: 3042.9570\n","Epoch 469: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -1.9585e-16 - r2_keras: -80.0577 - rmse: 0.8541 - sae: 1856.2081 - sse: 2212.2986 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8540e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0780 - val_sse: 483.3149 - learning_rate: 1.0000e-05\n","Epoch 470/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.4249e-16 - r2_keras: -97.1007 - rmse: 0.8619 - sae: 2538.4536 - sse: 3042.9614\n","Epoch 470: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -2.7011e-16 - r2_keras: -80.0578 - rmse: 0.8541 - sae: 1856.2091 - sse: 2212.3018 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0778 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 471/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 7.1491e-16 - r2_keras: -97.1007 - rmse: 0.8619 - sae: 2538.4531 - sse: 3042.9604\n","Epoch 471: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: 3.9023e-16 - r2_keras: -80.0577 - rmse: 0.8541 - sae: 1856.2087 - sse: 2212.3008 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0780 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 472/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.6887e-16 - r2_keras: -97.1008 - rmse: 0.8619 - sae: 2538.4541 - sse: 3042.9634\n","Epoch 472: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2448 - mse: 0.1568 - pearson_correlation: -5.5097e-16 - r2_keras: -80.0578 - rmse: 0.8541 - sae: 1856.2096 - sse: 2212.3032 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3147 - learning_rate: 1.0000e-05\n","Epoch 473/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.1785e-16 - r2_keras: -97.1008 - rmse: 0.8619 - sae: 2538.4541 - sse: 3042.9641\n","Epoch 473: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.6417e-16 - r2_keras: -80.0578 - rmse: 0.8541 - sae: 1856.2095 - sse: 2212.3035 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.5806e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 474/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -5.1718e-16 - r2_keras: -97.1009 - rmse: 0.8619 - sae: 2538.4546 - sse: 3042.9663\n","Epoch 474: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.6014e-16 - r2_keras: -80.0579 - rmse: 0.8541 - sae: 1856.2100 - sse: 2212.3054 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 475/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 6.8364e-16 - r2_keras: -97.1009 - rmse: 0.8619 - sae: 2538.4551 - sse: 3042.9666\n","Epoch 475: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.3849e-16 - r2_keras: -80.0579 - rmse: 0.8541 - sae: 1856.2102 - sse: 2212.3052 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3149 - learning_rate: 1.0000e-05\n","Epoch 476/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.7861e-16 - r2_keras: -97.1010 - rmse: 0.8619 - sae: 2538.4556 - sse: 3042.9688\n","Epoch 476: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.5624e-16 - r2_keras: -80.0580 - rmse: 0.8541 - sae: 1856.2107 - sse: 2212.3071 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0777 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 477/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.3360e-16 - r2_keras: -97.1010 - rmse: 0.8619 - sae: 2538.4556 - sse: 3042.9688\n","Epoch 477: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.0967e-16 - r2_keras: -80.0580 - rmse: 0.8541 - sae: 1856.2106 - sse: 2212.3069 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3149 - learning_rate: 1.0000e-05\n","Epoch 478/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.3281e-16 - r2_keras: -97.1011 - rmse: 0.8619 - sae: 2538.4565 - sse: 3042.9727\n","Epoch 478: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.1778e-16 - r2_keras: -80.0581 - rmse: 0.8541 - sae: 1856.2113 - sse: 2212.3098 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.0294e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 479/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.0657e-17 - r2_keras: -97.1011 - rmse: 0.8619 - sae: 2538.4570 - sse: 3042.9731\n","Epoch 479: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -5.8260e-17 - r2_keras: -80.0581 - rmse: 0.8541 - sae: 1856.2115 - sse: 2212.3098 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0777 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 480/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 6.9590e-17 - r2_keras: -97.1011 - rmse: 0.8619 - sae: 2538.4565 - sse: 3042.9736\n","Epoch 480: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 8.2863e-17 - r2_keras: -80.0581 - rmse: 0.8541 - sae: 1856.2114 - sse: 2212.3105 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9761e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0777 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 481/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.1306e-16 - r2_keras: -97.1011 - rmse: 0.8619 - sae: 2538.4575 - sse: 3042.9746\n","Epoch 481: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.6795e-16 - r2_keras: -80.0581 - rmse: 0.8541 - sae: 1856.2120 - sse: 2212.3110 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0778 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 482/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.4023e-16 - r2_keras: -97.1012 - rmse: 0.8619 - sae: 2538.4583 - sse: 3042.9775\n","Epoch 482: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.9061e-16 - r2_keras: -80.0582 - rmse: 0.8541 - sae: 1856.2126 - sse: 2212.3135 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.5806e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0776 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 483/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.4145e-17 - r2_keras: -97.1012 - rmse: 0.8619 - sae: 2538.4580 - sse: 3042.9771\n","Epoch 483: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 5.9182e-17 - r2_keras: -80.0582 - rmse: 0.8541 - sae: 1856.2124 - sse: 2212.3127 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0779 - val_sse: 483.3150 - learning_rate: 1.0000e-05\n","Epoch 484/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.0417e-16 - r2_keras: -97.1013 - rmse: 0.8619 - sae: 2538.4595 - sse: 3042.9810\n","Epoch 484: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 6.1256e-17 - r2_keras: -80.0583 - rmse: 0.8541 - sae: 1856.2135 - sse: 2212.3157 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0775 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 485/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.8940e-16 - r2_keras: -97.1013 - rmse: 0.8619 - sae: 2538.4590 - sse: 3042.9800\n","Epoch 485: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.9965e-16 - r2_keras: -80.0583 - rmse: 0.8541 - sae: 1856.2131 - sse: 2212.3149 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.8050e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0777 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 486/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.9707e-18 - r2_keras: -97.1014 - rmse: 0.8619 - sae: 2538.4595 - sse: 3042.9824\n","Epoch 486: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -5.0421e-17 - r2_keras: -80.0583 - rmse: 0.8541 - sae: 1856.2135 - sse: 2212.3169 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0775 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 487/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.4612e-17 - r2_keras: -97.1014 - rmse: 0.8619 - sae: 2538.4600 - sse: 3042.9824\n","Epoch 487: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.1015e-16 - r2_keras: -80.0583 - rmse: 0.8541 - sae: 1856.2139 - sse: 2212.3167 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0776 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 488/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.6788e-16 - r2_keras: -97.1015 - rmse: 0.8619 - sae: 2538.4604 - sse: 3042.9856\n","Epoch 488: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.5485e-16 - r2_keras: -80.0584 - rmse: 0.8541 - sae: 1856.2142 - sse: 2212.3191 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0775 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 489/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -5.6070e-16 - r2_keras: -97.1015 - rmse: 0.8619 - sae: 2538.4604 - sse: 3042.9854\n","Epoch 489: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.4885e-16 - r2_keras: -80.0584 - rmse: 0.8541 - sae: 1856.2142 - sse: 2212.3186 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.6928e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0776 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 490/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.3575e-16 - r2_keras: -97.1016 - rmse: 0.8619 - sae: 2538.4612 - sse: 3042.9878\n","Epoch 490: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 6.6951e-17 - r2_keras: -80.0585 - rmse: 0.8541 - sae: 1856.2148 - sse: 2212.3208 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.2538e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0774 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 491/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.3575e-17 - r2_keras: -97.1016 - rmse: 0.8619 - sae: 2538.4614 - sse: 3042.9883\n","Epoch 491: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.0258e-17 - r2_keras: -80.0585 - rmse: 0.8541 - sae: 1856.2150 - sse: 2212.3208 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0776 - val_sse: 483.3149 - learning_rate: 1.0000e-05\n","Epoch 492/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.3826e-16 - r2_keras: -97.1017 - rmse: 0.8619 - sae: 2538.4624 - sse: 3042.9922\n","Epoch 492: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -5.9543e-17 - r2_keras: -80.0586 - rmse: 0.8541 - sae: 1856.2157 - sse: 2212.3237 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.8148e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0774 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 493/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.1503e-17 - r2_keras: -97.1016 - rmse: 0.8619 - sae: 2538.4619 - sse: 3042.9902\n","Epoch 493: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.7490e-17 - r2_keras: -80.0585 - rmse: 0.8541 - sae: 1856.2152 - sse: 2212.3223 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0775 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 494/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.8130e-17 - r2_keras: -97.1017 - rmse: 0.8619 - sae: 2538.4629 - sse: 3042.9932\n","Epoch 494: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.6329e-17 - r2_keras: -80.0586 - rmse: 0.8541 - sae: 1856.2161 - sse: 2212.3245 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0773 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 495/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.0178e-16 - r2_keras: -97.1017 - rmse: 0.8619 - sae: 2538.4629 - sse: 3042.9932\n","Epoch 495: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -7.4571e-17 - r2_keras: -80.0586 - rmse: 0.8541 - sae: 1856.2159 - sse: 2212.3242 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8541e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0775 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 496/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.6904e-17 - r2_keras: -97.1019 - rmse: 0.8619 - sae: 2538.4639 - sse: 3042.9968\n","Epoch 496: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.1980e-17 - r2_keras: -80.0587 - rmse: 0.8541 - sae: 1856.2168 - sse: 2212.3271 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0773 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 497/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.9914e-16 - r2_keras: -97.1018 - rmse: 0.8619 - sae: 2538.4634 - sse: 3042.9958\n","Epoch 497: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.2752e-16 - r2_keras: -80.0587 - rmse: 0.8541 - sae: 1856.2164 - sse: 2212.3262 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0774 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 498/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -9.7180e-17 - r2_keras: -97.1019 - rmse: 0.8619 - sae: 2538.4644 - sse: 3042.9990\n","Epoch 498: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.6955e-17 - r2_keras: -80.0588 - rmse: 0.8541 - sae: 1856.2172 - sse: 2212.3289 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0773 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 499/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 6.8670e-17 - r2_keras: -97.1019 - rmse: 0.8619 - sae: 2538.4646 - sse: 3042.9995\n","Epoch 499: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.5626e-17 - r2_keras: -80.0588 - rmse: 0.8541 - sae: 1856.2173 - sse: 2212.3289 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.5806e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0774 - val_sse: 483.3148 - learning_rate: 1.0000e-05\n","Epoch 500/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.9405e-16 - r2_keras: -97.1020 - rmse: 0.8619 - sae: 2538.4653 - sse: 3043.0020\n","Epoch 500: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.4185e-16 - r2_keras: -80.0588 - rmse: 0.8541 - sae: 1856.2179 - sse: 2212.3308 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0772 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 501/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.7682e-16 - r2_keras: -97.1020 - rmse: 0.8619 - sae: 2538.4651 - sse: 3043.0010\n","Epoch 501: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.1718e-16 - r2_keras: -80.0588 - rmse: 0.8541 - sae: 1856.2177 - sse: 2212.3298 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0772 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 502/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.6401e-16 - r2_keras: -97.1021 - rmse: 0.8619 - sae: 2538.4661 - sse: 3043.0049\n","Epoch 502: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.3119e-17 - r2_keras: -80.0589 - rmse: 0.8541 - sae: 1856.2184 - sse: 2212.3330 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0771 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 503/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.1692e-16 - r2_keras: -97.1021 - rmse: 0.8619 - sae: 2538.4658 - sse: 3043.0034\n","Epoch 503: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.6835e-16 - r2_keras: -80.0589 - rmse: 0.8541 - sae: 1856.2181 - sse: 2212.3318 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0772 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 504/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.3581e-16 - r2_keras: -97.1022 - rmse: 0.8619 - sae: 2538.4666 - sse: 3043.0068\n","Epoch 504: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.8713e-17 - r2_keras: -80.0590 - rmse: 0.8541 - sae: 1856.2189 - sse: 2212.3342 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.9172e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0770 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 505/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.3231e-16 - r2_keras: -97.1022 - rmse: 0.8619 - sae: 2538.4666 - sse: 3043.0063\n","Epoch 505: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.3018e-16 - r2_keras: -80.0589 - rmse: 0.8541 - sae: 1856.2188 - sse: 2212.3337 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.7026e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0772 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 506/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.9086e-16 - r2_keras: -97.1023 - rmse: 0.8619 - sae: 2538.4678 - sse: 3043.0100\n","Epoch 506: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.9513e-16 - r2_keras: -80.0590 - rmse: 0.8541 - sae: 1856.2197 - sse: 2212.3367 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0771 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 507/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.7676e-17 - r2_keras: -97.1023 - rmse: 0.8619 - sae: 2538.4678 - sse: 3043.0103\n","Epoch 507: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.9813e-17 - r2_keras: -80.0590 - rmse: 0.8541 - sae: 1856.2196 - sse: 2212.3364 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0771 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 508/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.3286e-16 - r2_keras: -97.1024 - rmse: 0.8619 - sae: 2538.4688 - sse: 3043.0132\n","Epoch 508: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.8090e-16 - r2_keras: -80.0591 - rmse: 0.8541 - sae: 1856.2203 - sse: 2212.3389 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9761e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3140 - learning_rate: 1.0000e-05\n","Epoch 509/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.5904e-16 - r2_keras: -97.1023 - rmse: 0.8619 - sae: 2538.4683 - sse: 3043.0120\n","Epoch 509: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.1511e-16 - r2_keras: -80.0591 - rmse: 0.8541 - sae: 1856.2200 - sse: 2212.3376 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0771 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 510/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.6554e-17 - r2_keras: -97.1025 - rmse: 0.8619 - sae: 2538.4695 - sse: 3043.0161\n","Epoch 510: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.1748e-17 - r2_keras: -80.0592 - rmse: 0.8541 - sae: 1856.2209 - sse: 2212.3408 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0770 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 511/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -5.4261e-17 - r2_keras: -97.1025 - rmse: 0.8619 - sae: 2538.4692 - sse: 3043.0154\n","Epoch 511: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.0143e-16 - r2_keras: -80.0592 - rmse: 0.8541 - sae: 1856.2207 - sse: 2212.3401 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0771 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 512/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.4236e-16 - r2_keras: -97.1026 - rmse: 0.8619 - sae: 2538.4707 - sse: 3043.0198\n","Epoch 512: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.8262e-16 - r2_keras: -80.0593 - rmse: 0.8541 - sae: 1856.2218 - sse: 2212.3435 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 513/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.4929e-16 - r2_keras: -97.1026 - rmse: 0.8619 - sae: 2538.4702 - sse: 3043.0186\n","Epoch 513: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.2448e-16 - r2_keras: -80.0592 - rmse: 0.8541 - sae: 1856.2214 - sse: 2212.3425 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.9172e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0770 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 514/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.7400e-17 - r2_keras: -97.1026 - rmse: 0.8619 - sae: 2538.4707 - sse: 3043.0208\n","Epoch 514: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.2208e-17 - r2_keras: -80.0593 - rmse: 0.8541 - sae: 1856.2218 - sse: 2212.3442 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 515/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.7897e-16 - r2_keras: -97.1026 - rmse: 0.8619 - sae: 2538.4712 - sse: 3043.0210\n","Epoch 515: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.7934e-17 - r2_keras: -80.0593 - rmse: 0.8541 - sae: 1856.2220 - sse: 2212.3442 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 516/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.4512e-16 - r2_keras: -97.1027 - rmse: 0.8619 - sae: 2538.4719 - sse: 3043.0244\n","Epoch 516: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.7084e-16 - r2_keras: -80.0594 - rmse: 0.8541 - sae: 1856.2228 - sse: 2212.3469 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.0294e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0768 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 517/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.3329e-16 - r2_keras: -97.1027 - rmse: 0.8619 - sae: 2538.4717 - sse: 3043.0237\n","Epoch 517: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.1138e-16 - r2_keras: -80.0594 - rmse: 0.8541 - sae: 1856.2225 - sse: 2212.3462 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 518/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 6.1925e-16 - r2_keras: -97.1028 - rmse: 0.8619 - sae: 2538.4727 - sse: 3043.0273\n","Epoch 518: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.3413e-16 - r2_keras: -80.0595 - rmse: 0.8541 - sae: 1856.2233 - sse: 2212.3489 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0768 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 519/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -3.3108e-16 - r2_keras: -97.1028 - rmse: 0.8619 - sae: 2538.4727 - sse: 3043.0273\n","Epoch 519: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.3435e-16 - r2_keras: -80.0595 - rmse: 0.8541 - sae: 1856.2233 - sse: 2212.3486 - val_huber_loss: 0.1030 - val_loss: 0.1933 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.5806e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 520/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.1459e-17 - r2_keras: -97.1029 - rmse: 0.8619 - sae: 2538.4736 - sse: 3043.0300\n","Epoch 520: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 5.0775e-17 - r2_keras: -80.0596 - rmse: 0.8541 - sae: 1856.2240 - sse: 2212.3508 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0767 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 521/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.0165e-15 - r2_keras: -97.1029 - rmse: 0.8619 - sae: 2538.4731 - sse: 3043.0288\n","Epoch 521: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.3067e-16 - r2_keras: -80.0595 - rmse: 0.8541 - sae: 1856.2236 - sse: 2212.3499 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0769 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 522/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -8.2770e-16 - r2_keras: -97.1030 - rmse: 0.8619 - sae: 2538.4749 - sse: 3043.0334\n","Epoch 522: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -5.8635e-16 - r2_keras: -80.0596 - rmse: 0.8541 - sae: 1856.2249 - sse: 2212.3533 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0766 - val_sse: 483.3139 - learning_rate: 1.0000e-05\n","Epoch 523/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.8583e-16 - r2_keras: -97.1030 - rmse: 0.8619 - sae: 2538.4741 - sse: 3043.0317\n","Epoch 523: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.2798e-16 - r2_keras: -80.0596 - rmse: 0.8541 - sae: 1856.2242 - sse: 2212.3518 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.6928e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0768 - val_sse: 483.3145 - learning_rate: 1.0000e-05\n","Epoch 524/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.6891e-16 - r2_keras: -97.1031 - rmse: 0.8619 - sae: 2538.4751 - sse: 3043.0347\n","Epoch 524: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.2221e-16 - r2_keras: -80.0597 - rmse: 0.8541 - sae: 1856.2251 - sse: 2212.3542 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0767 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 525/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -6.1740e-16 - r2_keras: -97.1031 - rmse: 0.8619 - sae: 2538.4751 - sse: 3043.0349\n","Epoch 525: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.3943e-16 - r2_keras: -80.0597 - rmse: 0.8541 - sae: 1856.2250 - sse: 2212.3542 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0766 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 526/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.1864e-16 - r2_keras: -97.1032 - rmse: 0.8619 - sae: 2538.4756 - sse: 3043.0371\n","Epoch 526: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 7.7172e-17 - r2_keras: -80.0597 - rmse: 0.8541 - sae: 1856.2255 - sse: 2212.3560 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0766 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 527/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -7.5719e-16 - r2_keras: -97.1032 - rmse: 0.8619 - sae: 2538.4766 - sse: 3043.0383\n","Epoch 527: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -5.5086e-16 - r2_keras: -80.0597 - rmse: 0.8541 - sae: 1856.2261 - sse: 2212.3567 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0768 - val_sse: 483.3146 - learning_rate: 1.0000e-05\n","Epoch 528/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -4.6167e-16 - r2_keras: -97.1033 - rmse: 0.8619 - sae: 2538.4771 - sse: 3043.0410\n","Epoch 528: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.7592e-16 - r2_keras: -80.0598 - rmse: 0.8541 - sae: 1856.2266 - sse: 2212.3586 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9761e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0765 - val_sse: 483.3140 - learning_rate: 1.0000e-05\n","Epoch 529/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 3.8442e-16 - r2_keras: -97.1033 - rmse: 0.8619 - sae: 2538.4768 - sse: 3043.0405\n","Epoch 529: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.8123e-16 - r2_keras: -80.0598 - rmse: 0.8541 - sae: 1856.2263 - sse: 2212.3582 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.8148e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0766 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 530/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.8577e-16 - r2_keras: -97.1034 - rmse: 0.8619 - sae: 2538.4775 - sse: 3043.0442\n","Epoch 530: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -8.9299e-17 - r2_keras: -80.0599 - rmse: 0.8541 - sae: 1856.2269 - sse: 2212.3611 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0765 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 531/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.1078e-17 - r2_keras: -97.1033 - rmse: 0.8619 - sae: 2538.4775 - sse: 3043.0430\n","Epoch 531: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.8834e-17 - r2_keras: -80.0599 - rmse: 0.8541 - sae: 1856.2269 - sse: 2212.3601 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0767 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 532/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.8117e-16 - r2_keras: -97.1035 - rmse: 0.8619 - sae: 2538.4790 - sse: 3043.0474\n","Epoch 532: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.1694e-16 - r2_keras: -80.0600 - rmse: 0.8541 - sae: 1856.2279 - sse: 2212.3633 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.1416e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0764 - val_sse: 483.3139 - learning_rate: 1.0000e-05\n","Epoch 533/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.6198e-16 - r2_keras: -97.1034 - rmse: 0.8619 - sae: 2538.4785 - sse: 3043.0459\n","Epoch 533: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.2814e-16 - r2_keras: -80.0599 - rmse: 0.8541 - sae: 1856.2275 - sse: 2212.3621 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0764 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 534/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -2.4954e-16 - r2_keras: -97.1035 - rmse: 0.8619 - sae: 2538.4785 - sse: 3043.0479\n","Epoch 534: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.0455e-16 - r2_keras: -80.0600 - rmse: 0.8541 - sae: 1856.2277 - sse: 2212.3638 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3139 - learning_rate: 1.0000e-05\n","Epoch 535/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 8.1850e-17 - r2_keras: -97.1035 - rmse: 0.8619 - sae: 2538.4790 - sse: 3043.0493\n","Epoch 535: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.4816e-17 - r2_keras: -80.0600 - rmse: 0.8541 - sae: 1856.2279 - sse: 2212.3645 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0765 - val_sse: 483.3144 - learning_rate: 1.0000e-05\n","Epoch 536/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 4.3408e-16 - r2_keras: -97.1036 - rmse: 0.8619 - sae: 2538.4805 - sse: 3043.0525\n","Epoch 536: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.5465e-16 - r2_keras: -80.0601 - rmse: 0.8541 - sae: 1856.2290 - sse: 2212.3669 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3138 - learning_rate: 1.0000e-05\n","Epoch 537/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 1.4929e-16 - r2_keras: -97.1036 - rmse: 0.8619 - sae: 2538.4800 - sse: 3043.0518\n","Epoch 537: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.5519e-16 - r2_keras: -80.0601 - rmse: 0.8541 - sae: 1856.2286 - sse: 2212.3662 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0764 - val_sse: 483.3143 - learning_rate: 1.0000e-05\n","Epoch 538/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: -1.4684e-16 - r2_keras: -97.1037 - rmse: 0.8619 - sae: 2538.4805 - sse: 3043.0542\n","Epoch 538: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.7275e-16 - r2_keras: -80.0602 - rmse: 0.8541 - sae: 1856.2291 - sse: 2212.3682 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 539/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 5.8276e-16 - r2_keras: -97.1037 - rmse: 0.8619 - sae: 2538.4812 - sse: 3043.0554\n","Epoch 539: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.7795e-16 - r2_keras: -80.0602 - rmse: 0.8541 - sae: 1856.2296 - sse: 2212.3687 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 540/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2547 - mse: 0.1697 - pearson_correlation: 2.6823e-16 - r2_keras: -97.1038 - rmse: 0.8619 - sae: 2538.4819 - sse: 3043.0576\n","Epoch 540: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.8746e-16 - r2_keras: -80.0603 - rmse: 0.8541 - sae: 1856.2301 - sse: 2212.3706 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3140 - learning_rate: 1.0000e-05\n","Epoch 541/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.7564e-16 - r2_keras: -97.1038 - rmse: 0.8619 - sae: 2538.4814 - sse: 3043.0562\n","Epoch 541: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.6578e-16 - r2_keras: -80.0602 - rmse: 0.8541 - sae: 1856.2297 - sse: 2212.3694 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 542/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.0049e-16 - r2_keras: -97.1039 - rmse: 0.8619 - sae: 2538.4824 - sse: 3043.0596\n","Epoch 542: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.8164e-16 - r2_keras: -80.0603 - rmse: 0.8541 - sae: 1856.2306 - sse: 2212.3721 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0761 - val_sse: 483.3138 - learning_rate: 1.0000e-05\n","Epoch 543/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.2188e-17 - r2_keras: -97.1039 - rmse: 0.8619 - sae: 2538.4819 - sse: 3043.0596\n","Epoch 543: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 5.6008e-17 - r2_keras: -80.0603 - rmse: 0.8541 - sae: 1856.2301 - sse: 2212.3718 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0763 - val_sse: 483.3142 - learning_rate: 1.0000e-05\n","Epoch 544/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.4358e-16 - r2_keras: -97.1040 - rmse: 0.8619 - sae: 2538.4834 - sse: 3043.0630\n","Epoch 544: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.5829e-16 - r2_keras: -80.0604 - rmse: 0.8541 - sae: 1856.2312 - sse: 2212.3745 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0762 - val_sse: 483.3139 - learning_rate: 1.0000e-05\n","Epoch 545/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.6786e-16 - r2_keras: -97.1040 - rmse: 0.8619 - sae: 2538.4832 - sse: 3043.0623\n","Epoch 545: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.7883e-16 - r2_keras: -80.0604 - rmse: 0.8541 - sae: 1856.2311 - sse: 2212.3738 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0762 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 546/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.5358e-16 - r2_keras: -97.1041 - rmse: 0.8619 - sae: 2538.4839 - sse: 3043.0659\n","Epoch 546: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.1295e-16 - r2_keras: -80.0605 - rmse: 0.8541 - sae: 1856.2316 - sse: 2212.3765 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0761 - val_sse: 483.3139 - learning_rate: 1.0000e-05\n","Epoch 547/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -4.8343e-16 - r2_keras: -97.1041 - rmse: 0.8619 - sae: 2538.4841 - sse: 3043.0657\n","Epoch 547: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.6759e-16 - r2_keras: -80.0604 - rmse: 0.8541 - sae: 1856.2317 - sse: 2212.3762 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4533 - val_rmse: 0.9558 - val_sae: 363.0762 - val_sse: 483.3141 - learning_rate: 1.0000e-05\n","Epoch 548/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.6909e-16 - r2_keras: -97.1042 - rmse: 0.8619 - sae: 2538.4849 - sse: 3043.0684\n","Epoch 548: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.3454e-16 - r2_keras: -80.0605 - rmse: 0.8541 - sae: 1856.2323 - sse: 2212.3782 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0760 - val_sse: 483.3138 - learning_rate: 1.0000e-05\n","Epoch 549/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.9552e-16 - r2_keras: -97.1041 - rmse: 0.8619 - sae: 2538.4844 - sse: 3043.0674\n","Epoch 549: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.4787e-16 - r2_keras: -80.0605 - rmse: 0.8541 - sae: 1856.2319 - sse: 2212.3774 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3135 - learning_rate: 1.0000e-05\n","Epoch 550/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 9.4724e-17 - r2_keras: -97.1041 - rmse: 0.8619 - sae: 2538.4849 - sse: 3043.0679\n","Epoch 550: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 8.1384e-17 - r2_keras: -80.0605 - rmse: 0.8541 - sae: 1856.2323 - sse: 2212.3777 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3138 - learning_rate: 1.0000e-05\n","Epoch 551/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.4848e-16 - r2_keras: -97.1042 - rmse: 0.8619 - sae: 2538.4854 - sse: 3043.0703\n","Epoch 551: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.4314e-16 - r2_keras: -80.0606 - rmse: 0.8541 - sae: 1856.2327 - sse: 2212.3796 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0758 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 552/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.4928e-16 - r2_keras: -97.1042 - rmse: 0.8619 - sae: 2538.4854 - sse: 3043.0698\n","Epoch 552: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -5.2594e-16 - r2_keras: -80.0605 - rmse: 0.8541 - sae: 1856.2325 - sse: 2212.3789 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3137 - learning_rate: 1.0000e-05\n","Epoch 553/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 9.3130e-16 - r2_keras: -97.1043 - rmse: 0.8619 - sae: 2538.4863 - sse: 3043.0732\n","Epoch 553: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.5580e-16 - r2_keras: -80.0606 - rmse: 0.8541 - sae: 1856.2334 - sse: 2212.3816 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3135 - learning_rate: 1.0000e-05\n","Epoch 554/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.0508e-16 - r2_keras: -97.1043 - rmse: 0.8619 - sae: 2538.4868 - sse: 3043.0737\n","Epoch 554: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.2329e-16 - r2_keras: -80.0606 - rmse: 0.8541 - sae: 1856.2336 - sse: 2212.3818 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3138 - learning_rate: 1.0000e-05\n","Epoch 555/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1710 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.2157e-16 - r2_keras: -97.1044 - rmse: 0.8619 - sae: 2538.4868 - sse: 3043.0759\n","Epoch 555: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.3761e-16 - r2_keras: -80.0607 - rmse: 0.8541 - sae: 1856.2338 - sse: 2212.3835 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0758 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 556/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.6554e-16 - r2_keras: -97.1044 - rmse: 0.8619 - sae: 2538.4871 - sse: 3043.0757\n","Epoch 556: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.0652e-16 - r2_keras: -80.0607 - rmse: 0.8541 - sae: 1856.2338 - sse: 2212.3831 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.8247e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3137 - learning_rate: 1.0000e-05\n","Epoch 557/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 9.1137e-16 - r2_keras: -97.1045 - rmse: 0.8619 - sae: 2538.4883 - sse: 3043.0786\n","Epoch 557: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 6.3925e-16 - r2_keras: -80.0608 - rmse: 0.8541 - sae: 1856.2347 - sse: 2212.3855 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 558/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.5934e-16 - r2_keras: -97.1045 - rmse: 0.8619 - sae: 2538.4873 - sse: 3043.0776\n","Epoch 558: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.2472e-16 - r2_keras: -80.0607 - rmse: 0.8541 - sae: 1856.2340 - sse: 2212.3845 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0759 - val_sse: 483.3138 - learning_rate: 1.0000e-05\n","Epoch 559/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.1194e-16 - r2_keras: -97.1046 - rmse: 0.8619 - sae: 2538.4890 - sse: 3043.0820\n","Epoch 559: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.4897e-16 - r2_keras: -80.0609 - rmse: 0.8541 - sae: 1856.2354 - sse: 2212.3879 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 560/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.0655e-18 - r2_keras: -97.1046 - rmse: 0.8619 - sae: 2538.4888 - sse: 3043.0815\n","Epoch 560: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.8915e-17 - r2_keras: -80.0608 - rmse: 0.8541 - sae: 1856.2351 - sse: 2212.3872 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 561/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.4248e-16 - r2_keras: -97.1047 - rmse: 0.8619 - sae: 2538.4897 - sse: 3043.0842\n","Epoch 561: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.5781e-16 - r2_keras: -80.0609 - rmse: 0.8541 - sae: 1856.2358 - sse: 2212.3894 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 562/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.9306e-16 - r2_keras: -97.1047 - rmse: 0.8619 - sae: 2538.4900 - sse: 3043.0847\n","Epoch 562: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.9537e-16 - r2_keras: -80.0609 - rmse: 0.8541 - sae: 1856.2360 - sse: 2212.3896 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3137 - learning_rate: 1.0000e-05\n","Epoch 563/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.9116e-16 - r2_keras: -97.1048 - rmse: 0.8619 - sae: 2538.4902 - sse: 3043.0874\n","Epoch 563: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.5501e-16 - r2_keras: -80.0610 - rmse: 0.8541 - sae: 1856.2362 - sse: 2212.3916 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0756 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 564/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.3819e-16 - r2_keras: -97.1048 - rmse: 0.8619 - sae: 2538.4907 - sse: 3043.0869\n","Epoch 564: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.4133e-16 - r2_keras: -80.0610 - rmse: 0.8541 - sae: 1856.2366 - sse: 2212.3911 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3139 - learning_rate: 1.0000e-05\n","Epoch 565/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.2770e-16 - r2_keras: -97.1049 - rmse: 0.8619 - sae: 2538.4915 - sse: 3043.0898\n","Epoch 565: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.2422e-16 - r2_keras: -80.0611 - rmse: 0.8541 - sae: 1856.2372 - sse: 2212.3933 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0755 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 566/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.7662e-16 - r2_keras: -97.1048 - rmse: 0.8619 - sae: 2538.4912 - sse: 3043.0896\n","Epoch 566: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.0764e-16 - r2_keras: -80.0610 - rmse: 0.8541 - sae: 1856.2369 - sse: 2212.3931 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.6928e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0757 - val_sse: 483.3137 - learning_rate: 1.0000e-05\n","Epoch 567/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.3720e-17 - r2_keras: -97.1049 - rmse: 0.8619 - sae: 2538.4922 - sse: 3043.0928\n","Epoch 567: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.3843e-17 - r2_keras: -80.0611 - rmse: 0.8541 - sae: 1856.2377 - sse: 2212.3955 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0755 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 568/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -4.5860e-16 - r2_keras: -97.1049 - rmse: 0.8619 - sae: 2538.4927 - sse: 3043.0928\n","Epoch 568: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.4047e-16 - r2_keras: -80.0611 - rmse: 0.8541 - sae: 1856.2379 - sse: 2212.3953 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0755 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 569/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.0055e-16 - r2_keras: -97.1050 - rmse: 0.8619 - sae: 2538.4927 - sse: 3043.0952\n","Epoch 569: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 7.8548e-17 - r2_keras: -80.0612 - rmse: 0.8541 - sae: 1856.2380 - sse: 2212.3972 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0755 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 570/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.8172e-16 - r2_keras: -97.1050 - rmse: 0.8619 - sae: 2538.4932 - sse: 3043.0957\n","Epoch 570: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.6075e-16 - r2_keras: -80.0612 - rmse: 0.8541 - sae: 1856.2383 - sse: 2212.3975 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0756 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 571/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.6639e-16 - r2_keras: -97.1052 - rmse: 0.8619 - sae: 2538.4944 - sse: 3043.0991\n","Epoch 571: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.8431e-16 - r2_keras: -80.0613 - rmse: 0.8541 - sae: 1856.2393 - sse: 2212.4001 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 572/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.2684e-16 - r2_keras: -97.1051 - rmse: 0.8619 - sae: 2538.4937 - sse: 3043.0977\n","Epoch 572: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.0612e-16 - r2_keras: -80.0612 - rmse: 0.8541 - sae: 1856.2386 - sse: 2212.3989 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0755 - val_sse: 483.3137 - learning_rate: 1.0000e-05\n","Epoch 573/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.2028e-16 - r2_keras: -97.1052 - rmse: 0.8619 - sae: 2538.4949 - sse: 3043.1016\n","Epoch 573: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0715 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.7922e-16 - r2_keras: -80.0614 - rmse: 0.8541 - sae: 1856.2396 - sse: 2212.4019 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.2735e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0754 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 574/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -8.2768e-18 - r2_keras: -97.1052 - rmse: 0.8619 - sae: 2538.4949 - sse: 3043.1011\n","Epoch 574: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.5978e-17 - r2_keras: -80.0613 - rmse: 0.8541 - sae: 1856.2396 - sse: 2212.4011 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9761e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0754 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 575/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.7858e-16 - r2_keras: -97.1053 - rmse: 0.8619 - sae: 2538.4954 - sse: 3043.1040\n","Epoch 575: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.5143e-16 - r2_keras: -80.0614 - rmse: 0.8541 - sae: 1856.2401 - sse: 2212.4036 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6101e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 576/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.1922e-17 - r2_keras: -97.1053 - rmse: 0.8619 - sae: 2538.4956 - sse: 3043.1038\n","Epoch 576: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -8.5427e-17 - r2_keras: -80.0614 - rmse: 0.8541 - sae: 1856.2401 - sse: 2212.4033 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0755 - val_sse: 483.3137 - learning_rate: 1.0000e-05\n","Epoch 577/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.0576e-16 - r2_keras: -97.1054 - rmse: 0.8619 - sae: 2538.4963 - sse: 3043.1064\n","Epoch 577: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.5957e-17 - r2_keras: -80.0615 - rmse: 0.8541 - sae: 1856.2407 - sse: 2212.4053 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 578/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.0893e-16 - r2_keras: -97.1054 - rmse: 0.8619 - sae: 2538.4966 - sse: 3043.1064\n","Epoch 578: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.6475e-16 - r2_keras: -80.0615 - rmse: 0.8541 - sae: 1856.2408 - sse: 2212.4050 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.0294e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 579/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.8025e-16 - r2_keras: -97.1055 - rmse: 0.8619 - sae: 2538.4971 - sse: 3043.1089\n","Epoch 579: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 6.9302e-17 - r2_keras: -80.0616 - rmse: 0.8541 - sae: 1856.2413 - sse: 2212.4070 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 580/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.4408e-17 - r2_keras: -97.1055 - rmse: 0.8619 - sae: 2538.4971 - sse: 3043.1091\n","Epoch 580: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.8306e-18 - r2_keras: -80.0615 - rmse: 0.8541 - sae: 1856.2412 - sse: 2212.4070 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0754 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 581/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.8635e-16 - r2_keras: -97.1056 - rmse: 0.8619 - sae: 2538.4980 - sse: 3043.1123\n","Epoch 581: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.2993e-16 - r2_keras: -80.0616 - rmse: 0.8541 - sae: 1856.2421 - sse: 2212.4094 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0752 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 582/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.3672e-16 - r2_keras: -97.1056 - rmse: 0.8619 - sae: 2538.4980 - sse: 3043.1116\n","Epoch 582: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -8.8267e-17 - r2_keras: -80.0616 - rmse: 0.8541 - sae: 1856.2419 - sse: 2212.4087 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0752 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 583/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 9.5642e-17 - r2_keras: -97.1057 - rmse: 0.8619 - sae: 2538.4985 - sse: 3043.1145\n","Epoch 583: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.0407e-16 - r2_keras: -80.0617 - rmse: 0.8541 - sae: 1856.2423 - sse: 2212.4111 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3135 - learning_rate: 1.0000e-05\n","Epoch 584/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.6853e-16 - r2_keras: -97.1057 - rmse: 0.8619 - sae: 2538.4988 - sse: 3043.1145\n","Epoch 584: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.4428e-16 - r2_keras: -80.0617 - rmse: 0.8541 - sae: 1856.2426 - sse: 2212.4109 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4880e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 585/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.9588e-16 - r2_keras: -97.1058 - rmse: 0.8619 - sae: 2538.4995 - sse: 3043.1177\n","Epoch 585: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.7185e-16 - r2_keras: -80.0618 - rmse: 0.8541 - sae: 1856.2432 - sse: 2212.4133 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0752 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 586/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.1373e-16 - r2_keras: -97.1057 - rmse: 0.8619 - sae: 2538.4993 - sse: 3043.1165\n","Epoch 586: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 8.6375e-17 - r2_keras: -80.0617 - rmse: 0.8541 - sae: 1856.2428 - sse: 2212.4124 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0753 - val_sse: 483.3136 - learning_rate: 1.0000e-05\n","Epoch 587/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 6.1002e-17 - r2_keras: -97.1058 - rmse: 0.8619 - sae: 2538.5005 - sse: 3043.1206\n","Epoch 587: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.2991e-17 - r2_keras: -80.0619 - rmse: 0.8541 - sae: 1856.2438 - sse: 2212.4155 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0752 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 588/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.0293e-16 - r2_keras: -97.1058 - rmse: 0.8619 - sae: 2538.5005 - sse: 3043.1201\n","Epoch 588: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.1206e-16 - r2_keras: -80.0618 - rmse: 0.8541 - sae: 1856.2438 - sse: 2212.4148 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0752 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 589/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.8147e-16 - r2_keras: -97.1059 - rmse: 0.8619 - sae: 2538.5015 - sse: 3043.1226\n","Epoch 589: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.8048e-16 - r2_keras: -80.0619 - rmse: 0.8541 - sae: 1856.2445 - sse: 2212.4167 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0751 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 590/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.8856e-17 - r2_keras: -97.1059 - rmse: 0.8619 - sae: 2538.5012 - sse: 3043.1226\n","Epoch 590: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.5618e-17 - r2_keras: -80.0619 - rmse: 0.8541 - sae: 1856.2443 - sse: 2212.4165 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0752 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 591/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.3996e-16 - r2_keras: -97.1060 - rmse: 0.8619 - sae: 2538.5024 - sse: 3043.1265\n","Epoch 591: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.7961e-16 - r2_keras: -80.0620 - rmse: 0.8541 - sae: 1856.2452 - sse: 2212.4197 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.3759e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0750 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 592/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -9.5795e-16 - r2_keras: -97.1060 - rmse: 0.8619 - sae: 2538.5020 - sse: 3043.1260\n","Epoch 592: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.6262e-16 - r2_keras: -80.0620 - rmse: 0.8541 - sae: 1856.2449 - sse: 2212.4189 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0750 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 593/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.0654e-17 - r2_keras: -97.1061 - rmse: 0.8619 - sae: 2538.5027 - sse: 3043.1279\n","Epoch 593: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -8.5695e-17 - r2_keras: -80.0620 - rmse: 0.8541 - sae: 1856.2455 - sse: 2212.4207 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0750 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 594/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.7895e-17 - r2_keras: -97.1061 - rmse: 0.8619 - sae: 2538.5032 - sse: 3043.1289\n","Epoch 594: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.1307e-17 - r2_keras: -80.0620 - rmse: 0.8541 - sae: 1856.2457 - sse: 2212.4211 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.9172e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0750 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 595/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.8665e-17 - r2_keras: -97.1062 - rmse: 0.8619 - sae: 2538.5037 - sse: 3043.1311\n","Epoch 595: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.7543e-17 - r2_keras: -80.0621 - rmse: 0.8541 - sae: 1856.2462 - sse: 2212.4229 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0749 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 596/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.4929e-16 - r2_keras: -97.1062 - rmse: 0.8619 - sae: 2538.5039 - sse: 3043.1311\n","Epoch 596: val_loss did not improve from 0.19325\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.2096e-17 - r2_keras: -80.0621 - rmse: 0.8541 - sae: 1856.2462 - sse: 2212.4229 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0750 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 597/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.3277e-16 - r2_keras: -97.1063 - rmse: 0.8619 - sae: 2538.5046 - sse: 3043.1343\n","Epoch 597: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.2447e-16 - r2_keras: -80.0622 - rmse: 0.8541 - sae: 1856.2468 - sse: 2212.4250 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.9270e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0749 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 598/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.2507e-16 - r2_keras: -97.1063 - rmse: 0.8619 - sae: 2538.5046 - sse: 3043.1343\n","Epoch 598: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.7315e-17 - r2_keras: -80.0622 - rmse: 0.8541 - sae: 1856.2468 - sse: 2212.4250 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0750 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 599/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 8.3686e-17 - r2_keras: -97.1064 - rmse: 0.8619 - sae: 2538.5059 - sse: 3043.1377\n","Epoch 599: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 7.4984e-17 - r2_keras: -80.0623 - rmse: 0.8541 - sae: 1856.2477 - sse: 2212.4275 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0749 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 600/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -7.3570e-16 - r2_keras: -97.1064 - rmse: 0.8619 - sae: 2538.5054 - sse: 3043.1365\n","Epoch 600: val_loss improved from 0.19325 to 0.19325, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.5208e-16 - r2_keras: -80.0622 - rmse: 0.8541 - sae: 1856.2474 - sse: 2212.4265 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0749 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 601/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -7.6635e-18 - r2_keras: -97.1065 - rmse: 0.8619 - sae: 2538.5063 - sse: 3043.1401\n","Epoch 601: val_loss improved from 0.19325 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.3746e-17 - r2_keras: -80.0624 - rmse: 0.8541 - sae: 1856.2482 - sse: 2212.4294 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0748 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 602/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.8086e-17 - r2_keras: -97.1065 - rmse: 0.8619 - sae: 2538.5063 - sse: 3043.1401\n","Epoch 602: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 5.4161e-17 - r2_keras: -80.0623 - rmse: 0.8541 - sae: 1856.2480 - sse: 2212.4292 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0749 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 603/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.1727e-16 - r2_keras: -97.1066 - rmse: 0.8619 - sae: 2538.5071 - sse: 3043.1426\n","Epoch 603: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.2207e-16 - r2_keras: -80.0624 - rmse: 0.8541 - sae: 1856.2487 - sse: 2212.4312 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0748 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 604/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.4469e-16 - r2_keras: -97.1065 - rmse: 0.8619 - sae: 2538.5071 - sse: 3043.1423\n","Epoch 604: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.0893e-16 - r2_keras: -80.0624 - rmse: 0.8541 - sae: 1856.2487 - sse: 2212.4307 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0749 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 605/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.1281e-16 - r2_keras: -97.1067 - rmse: 0.8619 - sae: 2538.5083 - sse: 3043.1460\n","Epoch 605: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -7.3285e-17 - r2_keras: -80.0625 - rmse: 0.8541 - sae: 1856.2495 - sse: 2212.4336 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0746 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 606/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.9837e-16 - r2_keras: -97.1066 - rmse: 0.8619 - sae: 2538.5078 - sse: 3043.1445\n","Epoch 606: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.4977e-16 - r2_keras: -80.0624 - rmse: 0.8541 - sae: 1856.2491 - sse: 2212.4324 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0748 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 607/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.8386e-16 - r2_keras: -97.1067 - rmse: 0.8619 - sae: 2538.5088 - sse: 3043.1477\n","Epoch 607: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.7004e-16 - r2_keras: -80.0625 - rmse: 0.8541 - sae: 1856.2499 - sse: 2212.4348 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0746 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 608/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.5480e-16 - r2_keras: -97.1067 - rmse: 0.8619 - sae: 2538.5085 - sse: 3043.1475\n","Epoch 608: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.4815e-17 - r2_keras: -80.0625 - rmse: 0.8541 - sae: 1856.2496 - sse: 2212.4343 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0748 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 609/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.5075e-16 - r2_keras: -97.1068 - rmse: 0.8619 - sae: 2538.5100 - sse: 3043.1519\n","Epoch 609: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.3358e-16 - r2_keras: -80.0626 - rmse: 0.8541 - sae: 1856.2509 - sse: 2212.4377 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0746 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 610/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.7589e-18 - r2_keras: -97.1068 - rmse: 0.8619 - sae: 2538.5095 - sse: 3043.1504\n","Epoch 610: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 7.5734e-17 - r2_keras: -80.0626 - rmse: 0.8541 - sae: 1856.2504 - sse: 2212.4365 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.8050e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0747 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 611/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.2915e-16 - r2_keras: -97.1069 - rmse: 0.8619 - sae: 2538.5103 - sse: 3043.1533\n","Epoch 611: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 3.7919e-16 - r2_keras: -80.0627 - rmse: 0.8541 - sae: 1856.2510 - sse: 2212.4387 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0744 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 612/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.6669e-16 - r2_keras: -97.1069 - rmse: 0.8619 - sae: 2538.5098 - sse: 3043.1521\n","Epoch 612: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.2770e-16 - r2_keras: -80.0626 - rmse: 0.8541 - sae: 1856.2506 - sse: 2212.4377 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0746 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 613/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.7289e-16 - r2_keras: -97.1070 - rmse: 0.8620 - sae: 2538.5107 - sse: 3043.1560\n","Epoch 613: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.4981e-16 - r2_keras: -80.0628 - rmse: 0.8541 - sae: 1856.2515 - sse: 2212.4407 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 614/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.6955e-16 - r2_keras: -97.1070 - rmse: 0.8620 - sae: 2538.5110 - sse: 3043.1555\n","Epoch 614: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 4.3152e-16 - r2_keras: -80.0627 - rmse: 0.8541 - sae: 1856.2516 - sse: 2212.4402 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.0393e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 615/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.1481e-16 - r2_keras: -97.1071 - rmse: 0.8620 - sae: 2538.5120 - sse: 3043.1589\n","Epoch 615: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.0028e-16 - r2_keras: -80.0628 - rmse: 0.8541 - sae: 1856.2523 - sse: 2212.4429 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 616/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.6478e-16 - r2_keras: -97.1071 - rmse: 0.8620 - sae: 2538.5120 - sse: 3043.1589\n","Epoch 616: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.1440e-16 - r2_keras: -80.0628 - rmse: 0.8541 - sae: 1856.2522 - sse: 2212.4426 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0746 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 617/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.3028e-16 - r2_keras: -97.1072 - rmse: 0.8620 - sae: 2538.5129 - sse: 3043.1621\n","Epoch 617: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.7353e-17 - r2_keras: -80.0629 - rmse: 0.8541 - sae: 1856.2531 - sse: 2212.4451 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0743 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 618/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 8.4298e-16 - r2_keras: -97.1071 - rmse: 0.8620 - sae: 2538.5122 - sse: 3043.1604\n","Epoch 618: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 5.6007e-16 - r2_keras: -80.0629 - rmse: 0.8541 - sae: 1856.2524 - sse: 2212.4436 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 619/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.6195e-16 - r2_keras: -97.1073 - rmse: 0.8620 - sae: 2538.5139 - sse: 3043.1653\n","Epoch 619: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.8494e-16 - r2_keras: -80.0630 - rmse: 0.8541 - sae: 1856.2538 - sse: 2212.4473 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 620/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.4945e-17 - r2_keras: -97.1073 - rmse: 0.8620 - sae: 2538.5137 - sse: 3043.1646\n","Epoch 620: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -6.9824e-18 - r2_keras: -80.0630 - rmse: 0.8541 - sae: 1856.2535 - sse: 2212.4465 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 621/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -8.4911e-17 - r2_keras: -97.1074 - rmse: 0.8620 - sae: 2538.5146 - sse: 3043.1680\n","Epoch 621: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.6121e-16 - r2_keras: -80.0631 - rmse: 0.8541 - sae: 1856.2543 - sse: 2212.4492 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0743 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 622/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.1955e-16 - r2_keras: -97.1073 - rmse: 0.8620 - sae: 2538.5146 - sse: 3043.1672\n","Epoch 622: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.4016e-16 - r2_keras: -80.0630 - rmse: 0.8541 - sae: 1856.2543 - sse: 2212.4485 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0745 - val_sse: 483.3134 - learning_rate: 1.0000e-05\n","Epoch 623/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.1123e-16 - r2_keras: -97.1074 - rmse: 0.8620 - sae: 2538.5151 - sse: 3043.1697\n","Epoch 623: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.0269e-16 - r2_keras: -80.0631 - rmse: 0.8541 - sae: 1856.2546 - sse: 2212.4504 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0744 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 624/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.3910e-17 - r2_keras: -97.1075 - rmse: 0.8620 - sae: 2538.5159 - sse: 3043.1709\n","Epoch 624: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 2.1698e-17 - r2_keras: -80.0631 - rmse: 0.8541 - sae: 1856.2550 - sse: 2212.4512 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0743 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 625/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 7.1055e-16 - r2_keras: -97.1075 - rmse: 0.8620 - sae: 2538.5161 - sse: 3043.1729\n","Epoch 625: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 5.0057e-16 - r2_keras: -80.0632 - rmse: 0.8541 - sae: 1856.2554 - sse: 2212.4526 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.0294e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0742 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 626/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.0388e-16 - r2_keras: -97.1075 - rmse: 0.8620 - sae: 2538.5159 - sse: 3043.1724\n","Epoch 626: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -3.7092e-16 - r2_keras: -80.0632 - rmse: 0.8541 - sae: 1856.2551 - sse: 2212.4521 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.4782e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0744 - val_sse: 483.3133 - learning_rate: 1.0000e-05\n","Epoch 627/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.2101e-16 - r2_keras: -97.1076 - rmse: 0.8620 - sae: 2538.5166 - sse: 3043.1753\n","Epoch 627: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.1068e-16 - r2_keras: -80.0632 - rmse: 0.8541 - sae: 1856.2557 - sse: 2212.4543 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0742 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 628/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.2813e-16 - r2_keras: -97.1076 - rmse: 0.8620 - sae: 2538.5166 - sse: 3043.1748\n","Epoch 628: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -7.6784e-17 - r2_keras: -80.0632 - rmse: 0.8541 - sae: 1856.2557 - sse: 2212.4539 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0742 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 629/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.7652e-16 - r2_keras: -97.1077 - rmse: 0.8620 - sae: 2538.5176 - sse: 3043.1782\n","Epoch 629: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -4.2798e-16 - r2_keras: -80.0633 - rmse: 0.8541 - sae: 1856.2565 - sse: 2212.4565 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0741 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 630/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.3113e-16 - r2_keras: -97.1077 - rmse: 0.8620 - sae: 2538.5173 - sse: 3043.1775\n","Epoch 630: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: 1.8000e-16 - r2_keras: -80.0633 - rmse: 0.8541 - sae: 1856.2562 - sse: 2212.4558 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.0294e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0743 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 631/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.1764e-16 - r2_keras: -97.1078 - rmse: 0.8620 - sae: 2538.5186 - sse: 3043.1812\n","Epoch 631: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -1.3838e-16 - r2_keras: -80.0634 - rmse: 0.8541 - sae: 1856.2572 - sse: 2212.4587 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0740 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 632/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -4.1474e-16 - r2_keras: -97.1078 - rmse: 0.8620 - sae: 2538.5181 - sse: 3043.1804\n","Epoch 632: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1568 - pearson_correlation: -2.4483e-16 - r2_keras: -80.0634 - rmse: 0.8541 - sae: 1856.2567 - sse: 2212.4580 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0742 - val_sse: 483.3131 - learning_rate: 1.0000e-05\n","Epoch 633/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.7666e-16 - r2_keras: -97.1079 - rmse: 0.8620 - sae: 2538.5198 - sse: 3043.1843\n","Epoch 633: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.5616e-16 - r2_keras: -80.0635 - rmse: 0.8541 - sae: 1856.2581 - sse: 2212.4609 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0740 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 634/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.1175e-16 - r2_keras: -97.1079 - rmse: 0.8620 - sae: 2538.5190 - sse: 3043.1831\n","Epoch 634: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.9248e-16 - r2_keras: -80.0634 - rmse: 0.8541 - sae: 1856.2574 - sse: 2212.4600 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0741 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 635/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.2844e-16 - r2_keras: -97.1080 - rmse: 0.8620 - sae: 2538.5205 - sse: 3043.1875\n","Epoch 635: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3937e-16 - r2_keras: -80.0636 - rmse: 0.8541 - sae: 1856.2585 - sse: 2212.4631 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0740 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 636/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.6393e-16 - r2_keras: -97.1080 - rmse: 0.8620 - sae: 2538.5203 - sse: 3043.1865\n","Epoch 636: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.8727e-16 - r2_keras: -80.0635 - rmse: 0.8541 - sae: 1856.2584 - sse: 2212.4624 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0740 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 637/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 6.4066e-17 - r2_keras: -97.1081 - rmse: 0.8620 - sae: 2538.5208 - sse: 3043.1895\n","Epoch 637: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9678e-17 - r2_keras: -80.0636 - rmse: 0.8541 - sae: 1856.2588 - sse: 2212.4646 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 638/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.0844e-17 - r2_keras: -97.1080 - rmse: 0.8620 - sae: 2538.5208 - sse: 3043.1890\n","Epoch 638: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.0363e-17 - r2_keras: -80.0636 - rmse: 0.8541 - sae: 1856.2587 - sse: 2212.4641 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.0294e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0742 - val_sse: 483.3132 - learning_rate: 1.0000e-05\n","Epoch 639/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.6822e-16 - r2_keras: -97.1082 - rmse: 0.8620 - sae: 2538.5222 - sse: 3043.1934\n","Epoch 639: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.4906e-16 - r2_keras: -80.0637 - rmse: 0.8541 - sae: 1856.2599 - sse: 2212.4673 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 640/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -7.2955e-17 - r2_keras: -97.1081 - rmse: 0.8620 - sae: 2538.5217 - sse: 3043.1917\n","Epoch 640: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3082e-16 - r2_keras: -80.0637 - rmse: 0.8541 - sae: 1856.2594 - sse: 2212.4661 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0740 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 641/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 7.6633e-18 - r2_keras: -97.1082 - rmse: 0.8620 - sae: 2538.5225 - sse: 3043.1948\n","Epoch 641: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.4052e-17 - r2_keras: -80.0638 - rmse: 0.8541 - sae: 1856.2601 - sse: 2212.4685 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9761e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 642/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.8930e-16 - r2_keras: -97.1082 - rmse: 0.8620 - sae: 2538.5222 - sse: 3043.1938\n","Epoch 642: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.0963e-16 - r2_keras: -80.0637 - rmse: 0.8541 - sae: 1856.2599 - sse: 2212.4675 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0740 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 643/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.7288e-16 - r2_keras: -97.1083 - rmse: 0.8620 - sae: 2538.5239 - sse: 3043.1982\n","Epoch 643: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.0950e-16 - r2_keras: -80.0638 - rmse: 0.8541 - sae: 1856.2611 - sse: 2212.4709 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 644/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.6829e-16 - r2_keras: -97.1083 - rmse: 0.8620 - sae: 2538.5234 - sse: 3043.1973\n","Epoch 644: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 7.8603e-17 - r2_keras: -80.0638 - rmse: 0.8541 - sae: 1856.2607 - sse: 2212.4700 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 645/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.4699e-16 - r2_keras: -97.1084 - rmse: 0.8620 - sae: 2538.5244 - sse: 3043.2002\n","Epoch 645: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8910e-16 - r2_keras: -80.0639 - rmse: 0.8541 - sae: 1856.2615 - sse: 2212.4724 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 646/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.5749e-17 - r2_keras: -97.1085 - rmse: 0.8620 - sae: 2538.5249 - sse: 3043.2021\n","Epoch 646: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3293e-17 - r2_keras: -80.0639 - rmse: 0.8541 - sae: 1856.2617 - sse: 2212.4734 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 647/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.7512e-16 - r2_keras: -97.1085 - rmse: 0.8620 - sae: 2538.5251 - sse: 3043.2026\n","Epoch 647: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.0312e-16 - r2_keras: -80.0640 - rmse: 0.8541 - sae: 1856.2621 - sse: 2212.4741 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.9172e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0739 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 648/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -4.4171e-16 - r2_keras: -97.1085 - rmse: 0.8620 - sae: 2538.5251 - sse: 3043.2031\n","Epoch 648: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.2326e-16 - r2_keras: -80.0639 - rmse: 0.8541 - sae: 1856.2620 - sse: 2212.4741 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0738 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 649/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.1955e-17 - r2_keras: -97.1086 - rmse: 0.8620 - sae: 2538.5259 - sse: 3043.2061\n","Epoch 649: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.6760e-17 - r2_keras: -80.0640 - rmse: 0.8541 - sae: 1856.2626 - sse: 2212.4766 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6101e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 650/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.1082e-16 - r2_keras: -97.1086 - rmse: 0.8620 - sae: 2538.5259 - sse: 3043.2058\n","Epoch 650: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.3792e-16 - r2_keras: -80.0640 - rmse: 0.8541 - sae: 1856.2626 - sse: 2212.4761 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 651/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.5980e-17 - r2_keras: -97.1087 - rmse: 0.8620 - sae: 2538.5264 - sse: 3043.2083\n","Epoch 651: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.5967e-17 - r2_keras: -80.0641 - rmse: 0.8541 - sae: 1856.2629 - sse: 2212.4780 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 652/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.3303e-16 - r2_keras: -97.1087 - rmse: 0.8620 - sae: 2538.5264 - sse: 3043.2080\n","Epoch 652: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3379e-16 - r2_keras: -80.0641 - rmse: 0.8541 - sae: 1856.2628 - sse: 2212.4778 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.4782e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 653/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.9710e-16 - r2_keras: -97.1088 - rmse: 0.8620 - sae: 2538.5278 - sse: 3043.2117\n","Epoch 653: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.9982e-17 - r2_keras: -80.0642 - rmse: 0.8541 - sae: 1856.2640 - sse: 2212.4805 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.6928e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3129 - learning_rate: 1.0000e-05\n","Epoch 654/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 7.0502e-18 - r2_keras: -97.1088 - rmse: 0.8620 - sae: 2538.5273 - sse: 3043.2114\n","Epoch 654: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.3436e-17 - r2_keras: -80.0642 - rmse: 0.8541 - sae: 1856.2635 - sse: 2212.4802 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 655/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -7.6326e-17 - r2_keras: -97.1088 - rmse: 0.8620 - sae: 2538.5283 - sse: 3043.2139\n","Epoch 655: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -9.8867e-17 - r2_keras: -80.0642 - rmse: 0.8541 - sae: 1856.2644 - sse: 2212.4822 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0736 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 656/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -8.5399e-16 - r2_keras: -97.1088 - rmse: 0.8620 - sae: 2538.5283 - sse: 3043.2139\n","Epoch 656: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.3382e-16 - r2_keras: -80.0642 - rmse: 0.8541 - sae: 1856.2643 - sse: 2212.4817 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9761e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0737 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 657/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.1014e-15 - r2_keras: -97.1090 - rmse: 0.8620 - sae: 2538.5298 - sse: 3043.2180\n","Epoch 657: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 8.0526e-16 - r2_keras: -80.0643 - rmse: 0.8541 - sae: 1856.2655 - sse: 2212.4851 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.5806e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0735 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 658/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 9.0426e-17 - r2_keras: -97.1089 - rmse: 0.8620 - sae: 2538.5288 - sse: 3043.2156\n","Epoch 658: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.6042e-17 - r2_keras: -80.0643 - rmse: 0.8541 - sae: 1856.2648 - sse: 2212.4832 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -5.6101e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0736 - val_sse: 483.3128 - learning_rate: 1.0000e-05\n","Epoch 659/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.0540e-16 - r2_keras: -97.1090 - rmse: 0.8620 - sae: 2538.5300 - sse: 3043.2197\n","Epoch 659: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.6521e-16 - r2_keras: -80.0644 - rmse: 0.8541 - sae: 1856.2656 - sse: 2212.4863 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0735 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 660/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.8356e-17 - r2_keras: -97.1090 - rmse: 0.8620 - sae: 2538.5303 - sse: 3043.2197\n","Epoch 660: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.4764e-17 - r2_keras: -80.0644 - rmse: 0.8541 - sae: 1856.2657 - sse: 2212.4861 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3660e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0736 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 661/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -4.6163e-16 - r2_keras: -97.1091 - rmse: 0.8620 - sae: 2538.5305 - sse: 3043.2217\n","Epoch 661: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.6342e-16 - r2_keras: -80.0644 - rmse: 0.8541 - sae: 1856.2660 - sse: 2212.4875 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0735 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 662/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.4371e-18 - r2_keras: -97.1091 - rmse: 0.8620 - sae: 2538.5308 - sse: 3043.2217\n","Epoch 662: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.6418e-17 - r2_keras: -80.0644 - rmse: 0.8541 - sae: 1856.2661 - sse: 2212.4875 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0734 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 663/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.6338e-16 - r2_keras: -97.1092 - rmse: 0.8620 - sae: 2538.5312 - sse: 3043.2246\n","Epoch 663: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.2044e-16 - r2_keras: -80.0645 - rmse: 0.8541 - sae: 1856.2666 - sse: 2212.4897 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8541e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0734 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 664/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.6024e-16 - r2_keras: -97.1092 - rmse: 0.8620 - sae: 2538.5317 - sse: 3043.2251\n","Epoch 664: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1592e-16 - r2_keras: -80.0645 - rmse: 0.8541 - sae: 1856.2668 - sse: 2212.4900 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0736 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 665/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.4982e-16 - r2_keras: -97.1093 - rmse: 0.8620 - sae: 2538.5327 - sse: 3043.2280\n","Epoch 665: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.7710e-16 - r2_keras: -80.0646 - rmse: 0.8541 - sae: 1856.2676 - sse: 2212.4922 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0734 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 666/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.0224e-16 - r2_keras: -97.1093 - rmse: 0.8620 - sae: 2538.5327 - sse: 3043.2275\n","Epoch 666: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8038e-16 - r2_keras: -80.0646 - rmse: 0.8541 - sae: 1856.2676 - sse: 2212.4917 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0734 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 667/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.9412e-16 - r2_keras: -97.1093 - rmse: 0.8620 - sae: 2538.5327 - sse: 3043.2292\n","Epoch 667: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.8719e-16 - r2_keras: -80.0646 - rmse: 0.8541 - sae: 1856.2677 - sse: 2212.4932 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3660e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0733 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 668/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.8821e-16 - r2_keras: -97.1094 - rmse: 0.8620 - sae: 2538.5334 - sse: 3043.2302\n","Epoch 668: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.7921e-16 - r2_keras: -80.0646 - rmse: 0.8541 - sae: 1856.2682 - sse: 2212.4937 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0735 - val_sse: 483.3130 - learning_rate: 1.0000e-05\n","Epoch 669/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.7196e-16 - r2_keras: -97.1095 - rmse: 0.8620 - sae: 2538.5344 - sse: 3043.2334\n","Epoch 669: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9333e-16 - r2_keras: -80.0647 - rmse: 0.8541 - sae: 1856.2689 - sse: 2212.4961 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0732 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 670/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -6.4984e-17 - r2_keras: -97.1095 - rmse: 0.8620 - sae: 2538.5342 - sse: 3043.2329\n","Epoch 670: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.6176e-17 - r2_keras: -80.0647 - rmse: 0.8541 - sae: 1856.2687 - sse: 2212.4954 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0731 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 671/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.7243e-16 - r2_keras: -97.1094 - rmse: 0.8620 - sae: 2538.5337 - sse: 3043.2319\n","Epoch 671: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.9723e-16 - r2_keras: -80.0647 - rmse: 0.8541 - sae: 1856.2682 - sse: 2212.4946 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9761e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0732 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 672/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.5656e-16 - r2_keras: -97.1096 - rmse: 0.8620 - sae: 2538.5352 - sse: 3043.2358\n","Epoch 672: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.1327e-16 - r2_keras: -80.0648 - rmse: 0.8541 - sae: 1856.2694 - sse: 2212.4976 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0731 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 673/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.6316e-16 - r2_keras: -97.1095 - rmse: 0.8620 - sae: 2538.5347 - sse: 3043.2354\n","Epoch 673: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.3469e-16 - r2_keras: -80.0648 - rmse: 0.8541 - sae: 1856.2689 - sse: 2212.4971 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0732 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 674/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.2676e-16 - r2_keras: -97.1096 - rmse: 0.8620 - sae: 2538.5356 - sse: 3043.2378\n","Epoch 674: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.7657e-16 - r2_keras: -80.0648 - rmse: 0.8541 - sae: 1856.2698 - sse: 2212.4990 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.3562e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0732 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 675/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -8.6441e-17 - r2_keras: -97.1097 - rmse: 0.8620 - sae: 2538.5361 - sse: 3043.2388\n","Epoch 675: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.1062e-17 - r2_keras: -80.0648 - rmse: 0.8541 - sae: 1856.2700 - sse: 2212.4995 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0731 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 676/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -7.6632e-18 - r2_keras: -97.1097 - rmse: 0.8620 - sae: 2538.5364 - sse: 3043.2402\n","Epoch 676: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -9.0517e-17 - r2_keras: -80.0649 - rmse: 0.8541 - sae: 1856.2703 - sse: 2212.5007 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0730 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 677/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.8844e-16 - r2_keras: -97.1097 - rmse: 0.8620 - sae: 2538.5366 - sse: 3043.2412\n","Epoch 677: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.0957e-16 - r2_keras: -80.0649 - rmse: 0.8541 - sae: 1856.2704 - sse: 2212.5012 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0732 - val_sse: 483.3127 - learning_rate: 1.0000e-05\n","Epoch 678/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -5.5818e-16 - r2_keras: -97.1098 - rmse: 0.8620 - sae: 2538.5376 - sse: 3043.2439\n","Epoch 678: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.4813e-16 - r2_keras: -80.0650 - rmse: 0.8541 - sae: 1856.2711 - sse: 2212.5034 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 679/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.9289e-16 - r2_keras: -97.1098 - rmse: 0.8620 - sae: 2538.5371 - sse: 3043.2432\n","Epoch 679: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.7178e-16 - r2_keras: -80.0649 - rmse: 0.8541 - sae: 1856.2708 - sse: 2212.5027 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0731 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 680/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.7703e-17 - r2_keras: -97.1099 - rmse: 0.8620 - sae: 2538.5383 - sse: 3043.2466\n","Epoch 680: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.9682e-17 - r2_keras: -80.0651 - rmse: 0.8541 - sae: 1856.2717 - sse: 2212.5054 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0727 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 681/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.9978e-16 - r2_keras: -97.1098 - rmse: 0.8620 - sae: 2538.5376 - sse: 3043.2449\n","Epoch 681: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.9602e-16 - r2_keras: -80.0650 - rmse: 0.8541 - sae: 1856.2711 - sse: 2212.5039 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 682/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -1.3610e-16 - r2_keras: -97.1100 - rmse: 0.8620 - sae: 2538.5388 - sse: 3043.2485\n","Epoch 682: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -9.8409e-17 - r2_keras: -80.0651 - rmse: 0.8541 - sae: 1856.2721 - sse: 2212.5066 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 683/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.1763e-16 - r2_keras: -97.1100 - rmse: 0.8620 - sae: 2538.5391 - sse: 3043.2500\n","Epoch 683: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5564e-16 - r2_keras: -80.0651 - rmse: 0.8541 - sae: 1856.2722 - sse: 2212.5076 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 684/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -4.4109e-16 - r2_keras: -97.1101 - rmse: 0.8620 - sae: 2538.5396 - sse: 3043.2520\n","Epoch 684: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.2688e-16 - r2_keras: -80.0652 - rmse: 0.8541 - sae: 1856.2726 - sse: 2212.5090 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -8.9761e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 685/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.1365e-16 - r2_keras: -97.1101 - rmse: 0.8620 - sae: 2538.5398 - sse: 3043.2520\n","Epoch 685: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4339e-16 - r2_keras: -80.0652 - rmse: 0.8541 - sae: 1856.2727 - sse: 2212.5088 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.8050e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0730 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 686/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -2.7495e-16 - r2_keras: -97.1102 - rmse: 0.8620 - sae: 2538.5410 - sse: 3043.2556\n","Epoch 686: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.0441e-16 - r2_keras: -80.0653 - rmse: 0.8541 - sae: 1856.2737 - sse: 2212.5117 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0727 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 687/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 4.0921e-16 - r2_keras: -97.1102 - rmse: 0.8620 - sae: 2538.5405 - sse: 3043.2542\n","Epoch 687: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.0563e-16 - r2_keras: -80.0652 - rmse: 0.8541 - sae: 1856.2733 - sse: 2212.5105 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0728 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 688/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.4345e-16 - r2_keras: -97.1102 - rmse: 0.8620 - sae: 2538.5413 - sse: 3043.2568\n","Epoch 688: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3690e-16 - r2_keras: -80.0653 - rmse: 0.8541 - sae: 1856.2739 - sse: 2212.5127 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0728 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 689/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.8200e-17 - r2_keras: -97.1102 - rmse: 0.8620 - sae: 2538.5413 - sse: 3043.2568\n","Epoch 689: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 8.2441e-18 - r2_keras: -80.0653 - rmse: 0.8541 - sae: 1856.2738 - sse: 2212.5125 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.0294e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0729 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 690/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -3.0959e-17 - r2_keras: -97.1104 - rmse: 0.8620 - sae: 2538.5425 - sse: 3043.2610\n","Epoch 690: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1989e-17 - r2_keras: -80.0654 - rmse: 0.8541 - sae: 1856.2748 - sse: 2212.5156 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0727 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 691/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.3442e-16 - r2_keras: -97.1103 - rmse: 0.8620 - sae: 2538.5420 - sse: 3043.2595\n","Epoch 691: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.5749e-16 - r2_keras: -80.0654 - rmse: 0.8541 - sae: 1856.2744 - sse: 2212.5144 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0728 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 692/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 1.5142e-16 - r2_keras: -97.1104 - rmse: 0.8620 - sae: 2538.5432 - sse: 3043.2627\n","Epoch 692: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.8572e-17 - r2_keras: -80.0655 - rmse: 0.8541 - sae: 1856.2753 - sse: 2212.5168 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0726 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 693/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.7894e-17 - r2_keras: -97.1104 - rmse: 0.8620 - sae: 2538.5430 - sse: 3043.2627\n","Epoch 693: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.0328e-16 - r2_keras: -80.0655 - rmse: 0.8541 - sae: 1856.2750 - sse: 2212.5166 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0728 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 694/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: -7.9022e-16 - r2_keras: -97.1105 - rmse: 0.8620 - sae: 2538.5444 - sse: 3043.2666\n","Epoch 694: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3564e-16 - r2_keras: -80.0656 - rmse: 0.8541 - sae: 1856.2762 - sse: 2212.5195 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0726 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 695/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 3.9419e-16 - r2_keras: -97.1105 - rmse: 0.8620 - sae: 2538.5435 - sse: 3043.2649\n","Epoch 695: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.4148e-16 - r2_keras: -80.0655 - rmse: 0.8541 - sae: 1856.2755 - sse: 2212.5183 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0727 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 696/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 5.6737e-16 - r2_keras: -97.1106 - rmse: 0.8620 - sae: 2538.5449 - sse: 3043.2686\n","Epoch 696: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.3411e-16 - r2_keras: -80.0656 - rmse: 0.8541 - sae: 1856.2765 - sse: 2212.5210 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0726 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 697/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.5012e-16 - r2_keras: -97.1106 - rmse: 0.8620 - sae: 2538.5449 - sse: 3043.2690\n","Epoch 697: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.7654e-17 - r2_keras: -80.0656 - rmse: 0.8541 - sae: 1856.2765 - sse: 2212.5212 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4532 - val_rmse: 0.9558 - val_sae: 363.0728 - val_sse: 483.3126 - learning_rate: 1.0000e-05\n","Epoch 698/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.4828e-17 - r2_keras: -97.1107 - rmse: 0.8620 - sae: 2538.5459 - sse: 3043.2720\n","Epoch 698: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.6202e-17 - r2_keras: -80.0657 - rmse: 0.8541 - sae: 1856.2773 - sse: 2212.5234 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.0295e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0725 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 699/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 2.4706e-16 - r2_keras: -97.1107 - rmse: 0.8620 - sae: 2538.5454 - sse: 3043.2715\n","Epoch 699: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8966e-16 - r2_keras: -80.0657 - rmse: 0.8541 - sae: 1856.2770 - sse: 2212.5229 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0726 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 700/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1697 - pearson_correlation: 8.2761e-17 - r2_keras: -97.1108 - rmse: 0.8620 - sae: 2538.5464 - sse: 3043.2737\n","Epoch 700: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 7.6286e-17 - r2_keras: -80.0658 - rmse: 0.8541 - sae: 1856.2777 - sse: 2212.5247 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0725 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 701/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.1472e-16 - r2_keras: -97.1108 - rmse: 0.8620 - sae: 2538.5466 - sse: 3043.2747\n","Epoch 701: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.4481e-16 - r2_keras: -80.0658 - rmse: 0.8541 - sae: 1856.2778 - sse: 2212.5251 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0726 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 702/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.0385e-16 - r2_keras: -97.1109 - rmse: 0.8620 - sae: 2538.5474 - sse: 3043.2769\n","Epoch 702: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3711e-16 - r2_keras: -80.0658 - rmse: 0.8541 - sae: 1856.2784 - sse: 2212.5269 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.9074e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0725 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 703/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.3939e-16 - r2_keras: -97.1109 - rmse: 0.8620 - sae: 2538.5471 - sse: 3043.2764\n","Epoch 703: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.2581e-16 - r2_keras: -80.0658 - rmse: 0.8541 - sae: 1856.2782 - sse: 2212.5264 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.5806e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0724 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 704/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.2345e-16 - r2_keras: -97.1109 - rmse: 0.8620 - sae: 2538.5479 - sse: 3043.2788\n","Epoch 704: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4225e-16 - r2_keras: -80.0659 - rmse: 0.8541 - sae: 1856.2788 - sse: 2212.5283 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0724 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 705/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -9.3795e-17 - r2_keras: -97.1109 - rmse: 0.8620 - sae: 2538.5474 - sse: 3043.2783\n","Epoch 705: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5082e-16 - r2_keras: -80.0659 - rmse: 0.8541 - sae: 1856.2784 - sse: 2212.5278 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0725 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 706/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.2261e-18 - r2_keras: -97.1111 - rmse: 0.8620 - sae: 2538.5486 - sse: 3043.2822\n","Epoch 706: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.8091e-17 - r2_keras: -80.0660 - rmse: 0.8541 - sae: 1856.2794 - sse: 2212.5308 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0724 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 707/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 9.2569e-17 - r2_keras: -97.1111 - rmse: 0.8620 - sae: 2538.5488 - sse: 3043.2822\n","Epoch 707: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5058e-17 - r2_keras: -80.0660 - rmse: 0.8541 - sae: 1856.2794 - sse: 2212.5305 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0725 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 708/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.7763e-16 - r2_keras: -97.1112 - rmse: 0.8620 - sae: 2538.5496 - sse: 3043.2852\n","Epoch 708: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.5080e-16 - r2_keras: -80.0661 - rmse: 0.8541 - sae: 1856.2800 - sse: 2212.5330 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0723 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 709/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.4621e-16 - r2_keras: -97.1111 - rmse: 0.8620 - sae: 2538.5493 - sse: 3043.2847\n","Epoch 709: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4546e-16 - r2_keras: -80.0660 - rmse: 0.8541 - sae: 1856.2799 - sse: 2212.5325 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0724 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 710/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.0193e-16 - r2_keras: -97.1112 - rmse: 0.8620 - sae: 2538.5503 - sse: 3043.2876\n","Epoch 710: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.6603e-16 - r2_keras: -80.0661 - rmse: 0.8541 - sae: 1856.2806 - sse: 2212.5347 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0723 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 711/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.5357e-16 - r2_keras: -97.1112 - rmse: 0.8620 - sae: 2538.5503 - sse: 3043.2871\n","Epoch 711: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.0718e-16 - r2_keras: -80.0661 - rmse: 0.8541 - sae: 1856.2805 - sse: 2212.5342 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0725 - val_sse: 483.3125 - learning_rate: 1.0000e-05\n","Epoch 712/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.5081e-16 - r2_keras: -97.1113 - rmse: 0.8620 - sae: 2538.5513 - sse: 3043.2910\n","Epoch 712: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.0630e-16 - r2_keras: -80.0662 - rmse: 0.8541 - sae: 1856.2814 - sse: 2212.5371 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 713/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.9389e-17 - r2_keras: -97.1113 - rmse: 0.8620 - sae: 2538.5508 - sse: 3043.2891\n","Epoch 713: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.6361e-17 - r2_keras: -80.0661 - rmse: 0.8541 - sae: 1856.2809 - sse: 2212.5354 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.5806e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0723 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 714/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.2169e-16 - r2_keras: -97.1114 - rmse: 0.8620 - sae: 2538.5520 - sse: 3043.2930\n","Epoch 714: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.3222e-18 - r2_keras: -80.0663 - rmse: 0.8541 - sae: 1856.2819 - sse: 2212.5386 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0723 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 715/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.1419e-17 - r2_keras: -97.1114 - rmse: 0.8620 - sae: 2538.5520 - sse: 3043.2932\n","Epoch 715: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.8016e-17 - r2_keras: -80.0662 - rmse: 0.8541 - sae: 1856.2819 - sse: 2212.5386 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0722 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 716/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.3641e-17 - r2_keras: -97.1115 - rmse: 0.8620 - sae: 2538.5527 - sse: 3043.2959\n","Epoch 716: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.6920e-17 - r2_keras: -80.0663 - rmse: 0.8541 - sae: 1856.2823 - sse: 2212.5405 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.6003e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0722 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 717/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.4668e-16 - r2_keras: -97.1115 - rmse: 0.8620 - sae: 2538.5527 - sse: 3043.2961\n","Epoch 717: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.8243e-16 - r2_keras: -80.0663 - rmse: 0.8541 - sae: 1856.2823 - sse: 2212.5405 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.5905e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0723 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 718/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -9.8086e-18 - r2_keras: -97.1116 - rmse: 0.8620 - sae: 2538.5540 - sse: 3043.2988\n","Epoch 718: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.0331e-17 - r2_keras: -80.0664 - rmse: 0.8541 - sae: 1856.2833 - sse: 2212.5427 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 719/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.3219e-17 - r2_keras: -97.1115 - rmse: 0.8620 - sae: 2538.5532 - sse: 3043.2976\n","Epoch 719: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.5682e-17 - r2_keras: -80.0664 - rmse: 0.8541 - sae: 1856.2827 - sse: 2212.5417 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0723 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 720/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.3456e-16 - r2_keras: -97.1117 - rmse: 0.8620 - sae: 2538.5544 - sse: 3043.3015\n","Epoch 720: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.2425e-16 - r2_keras: -80.0665 - rmse: 0.8541 - sae: 1856.2837 - sse: 2212.5447 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 721/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.3449e-17 - r2_keras: -97.1117 - rmse: 0.8620 - sae: 2538.5540 - sse: 3043.3008\n","Epoch 721: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.4622e-17 - r2_keras: -80.0664 - rmse: 0.8541 - sae: 1856.2833 - sse: 2212.5439 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0722 - val_sse: 483.3124 - learning_rate: 1.0000e-05\n","Epoch 722/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.9610e-16 - r2_keras: -97.1117 - rmse: 0.8620 - sae: 2538.5552 - sse: 3043.3037\n","Epoch 722: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6189e-16 - r2_keras: -80.0665 - rmse: 0.8541 - sae: 1856.2843 - sse: 2212.5461 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 723/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.7855e-17 - r2_keras: -97.1118 - rmse: 0.8620 - sae: 2538.5552 - sse: 3043.3042\n","Epoch 723: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.9221e-18 - r2_keras: -80.0665 - rmse: 0.8541 - sae: 1856.2842 - sse: 2212.5464 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 724/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.7778e-16 - r2_keras: -97.1118 - rmse: 0.8620 - sae: 2538.5557 - sse: 3043.3059\n","Epoch 724: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3004e-16 - r2_keras: -80.0666 - rmse: 0.8541 - sae: 1856.2845 - sse: 2212.5479 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0720 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 725/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.8162e-17 - r2_keras: -97.1118 - rmse: 0.8620 - sae: 2538.5562 - sse: 3043.3066\n","Epoch 725: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 7.2260e-17 - r2_keras: -80.0666 - rmse: 0.8541 - sae: 1856.2848 - sse: 2212.5481 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 726/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.5272e-16 - r2_keras: -97.1120 - rmse: 0.8620 - sae: 2538.5569 - sse: 3043.3103\n","Epoch 726: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.0470e-16 - r2_keras: -80.0667 - rmse: 0.8541 - sae: 1856.2855 - sse: 2212.5508 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0719 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 727/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.8890e-18 - r2_keras: -97.1119 - rmse: 0.8620 - sae: 2538.5562 - sse: 3043.3083\n","Epoch 727: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.5088e-18 - r2_keras: -80.0666 - rmse: 0.8541 - sae: 1856.2849 - sse: 2212.5493 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0721 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 728/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.6284e-16 - r2_keras: -97.1120 - rmse: 0.8620 - sae: 2538.5576 - sse: 3043.3123\n","Epoch 728: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.4694e-16 - r2_keras: -80.0668 - rmse: 0.8541 - sae: 1856.2860 - sse: 2212.5525 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0719 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 729/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.6184e-16 - r2_keras: -97.1120 - rmse: 0.8620 - sae: 2538.5571 - sse: 3043.3108\n","Epoch 729: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1749e-16 - r2_keras: -80.0667 - rmse: 0.8541 - sae: 1856.2856 - sse: 2212.5513 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0719 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 730/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.2835e-16 - r2_keras: -97.1121 - rmse: 0.8620 - sae: 2538.5581 - sse: 3043.3149\n","Epoch 730: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4552e-16 - r2_keras: -80.0668 - rmse: 0.8541 - sae: 1856.2864 - sse: 2212.5542 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0719 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 731/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.2031e-17 - r2_keras: -97.1121 - rmse: 0.8620 - sae: 2538.5581 - sse: 3043.3145\n","Epoch 731: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.8797e-18 - r2_keras: -80.0668 - rmse: 0.8541 - sae: 1856.2864 - sse: 2212.5537 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9761e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0719 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 732/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.8667e-16 - r2_keras: -97.1122 - rmse: 0.8620 - sae: 2538.5586 - sse: 3043.3164\n","Epoch 732: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.9998e-17 - r2_keras: -80.0669 - rmse: 0.8541 - sae: 1856.2867 - sse: 2212.5554 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0717 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 733/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.5211e-16 - r2_keras: -97.1122 - rmse: 0.8620 - sae: 2538.5583 - sse: 3043.3164\n","Epoch 733: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.7166e-16 - r2_keras: -80.0668 - rmse: 0.8541 - sae: 1856.2865 - sse: 2212.5552 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0720 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 734/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.2314e-16 - r2_keras: -97.1123 - rmse: 0.8620 - sae: 2538.5596 - sse: 3043.3203\n","Epoch 734: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.2886e-16 - r2_keras: -80.0670 - rmse: 0.8541 - sae: 1856.2875 - sse: 2212.5581 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0718 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 735/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.2782e-16 - r2_keras: -97.1123 - rmse: 0.8620 - sae: 2538.5596 - sse: 3043.3201\n","Epoch 735: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5622e-16 - r2_keras: -80.0669 - rmse: 0.8541 - sae: 1856.2875 - sse: 2212.5579 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.3562e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0717 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 736/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.0866e-16 - r2_keras: -97.1123 - rmse: 0.8620 - sae: 2538.5601 - sse: 3043.3210\n","Epoch 736: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1557e-16 - r2_keras: -80.0670 - rmse: 0.8541 - sae: 1856.2878 - sse: 2212.5586 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0717 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 737/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.0782e-16 - r2_keras: -97.1123 - rmse: 0.8620 - sae: 2538.5601 - sse: 3043.3220\n","Epoch 737: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4814e-16 - r2_keras: -80.0670 - rmse: 0.8541 - sae: 1856.2878 - sse: 2212.5591 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0719 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 738/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.7586e-17 - r2_keras: -97.1125 - rmse: 0.8620 - sae: 2538.5613 - sse: 3043.3257\n","Epoch 738: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.2317e-17 - r2_keras: -80.0671 - rmse: 0.8541 - sae: 1856.2887 - sse: 2212.5620 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.6928e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0717 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 739/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.9625e-16 - r2_keras: -97.1124 - rmse: 0.8620 - sae: 2538.5613 - sse: 3043.3252\n","Epoch 739: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.5412e-16 - r2_keras: -80.0671 - rmse: 0.8541 - sae: 1856.2887 - sse: 2212.5613 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0717 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 740/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.8054e-16 - r2_keras: -97.1125 - rmse: 0.8620 - sae: 2538.5620 - sse: 3043.3276\n","Epoch 740: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.5036e-16 - r2_keras: -80.0671 - rmse: 0.8541 - sae: 1856.2893 - sse: 2212.5635 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0716 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 741/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.7770e-16 - r2_keras: -97.1125 - rmse: 0.8620 - sae: 2538.5620 - sse: 3043.3281\n","Epoch 741: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.2352e-16 - r2_keras: -80.0671 - rmse: 0.8541 - sae: 1856.2892 - sse: 2212.5635 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 7.8541e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0718 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 742/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.5410e-16 - r2_keras: -97.1126 - rmse: 0.8620 - sae: 2538.5625 - sse: 3043.3301\n","Epoch 742: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.3177e-16 - r2_keras: -80.0672 - rmse: 0.8541 - sae: 1856.2897 - sse: 2212.5652 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0715 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 743/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.4498e-16 - r2_keras: -97.1126 - rmse: 0.8620 - sae: 2538.5620 - sse: 3043.3298\n","Epoch 743: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1393e-16 - r2_keras: -80.0672 - rmse: 0.8541 - sae: 1856.2892 - sse: 2212.5647 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0716 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 744/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.4368e-16 - r2_keras: -97.1127 - rmse: 0.8620 - sae: 2538.5635 - sse: 3043.3330\n","Epoch 744: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.2695e-16 - r2_keras: -80.0673 - rmse: 0.8541 - sae: 1856.2904 - sse: 2212.5671 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0715 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 745/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.1103e-16 - r2_keras: -97.1127 - rmse: 0.8620 - sae: 2538.5635 - sse: 3043.3330\n","Epoch 745: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6655e-16 - r2_keras: -80.0673 - rmse: 0.8541 - sae: 1856.2904 - sse: 2212.5671 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0716 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 746/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.4866e-17 - r2_keras: -97.1128 - rmse: 0.8620 - sae: 2538.5640 - sse: 3043.3354\n","Epoch 746: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.1719e-16 - r2_keras: -80.0674 - rmse: 0.8541 - sae: 1856.2908 - sse: 2212.5691 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -7.8541e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0714 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 747/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.5004e-16 - r2_keras: -97.1128 - rmse: 0.8620 - sae: 2538.5640 - sse: 3043.3359\n","Epoch 747: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8826e-16 - r2_keras: -80.0673 - rmse: 0.8541 - sae: 1856.2906 - sse: 2212.5691 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0716 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 748/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.5716e-16 - r2_keras: -97.1129 - rmse: 0.8620 - sae: 2538.5649 - sse: 3043.3384\n","Epoch 748: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.7240e-16 - r2_keras: -80.0674 - rmse: 0.8541 - sae: 1856.2915 - sse: 2212.5710 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0715 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 749/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.9004e-17 - r2_keras: -97.1129 - rmse: 0.8620 - sae: 2538.5647 - sse: 3043.3384\n","Epoch 749: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6508e-17 - r2_keras: -80.0674 - rmse: 0.8541 - sae: 1856.2913 - sse: 2212.5708 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0714 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 750/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.2552e-16 - r2_keras: -97.1130 - rmse: 0.8620 - sae: 2538.5659 - sse: 3043.3411\n","Epoch 750: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9878e-16 - r2_keras: -80.0675 - rmse: 0.8541 - sae: 1856.2921 - sse: 2212.5730 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0714 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 751/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.3816e-16 - r2_keras: -97.1129 - rmse: 0.8620 - sae: 2538.5654 - sse: 3043.3403\n","Epoch 751: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.6346e-17 - r2_keras: -80.0675 - rmse: 0.8541 - sae: 1856.2919 - sse: 2212.5723 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0716 - val_sse: 483.3123 - learning_rate: 1.0000e-05\n","Epoch 752/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.7011e-16 - r2_keras: -97.1131 - rmse: 0.8620 - sae: 2538.5669 - sse: 3043.3447\n","Epoch 752: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6427e-16 - r2_keras: -80.0676 - rmse: 0.8541 - sae: 1856.2930 - sse: 2212.5757 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0713 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 753/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.1954e-16 - r2_keras: -97.1130 - rmse: 0.8620 - sae: 2538.5659 - sse: 3043.3425\n","Epoch 753: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.6606e-16 - r2_keras: -80.0675 - rmse: 0.8541 - sae: 1856.2921 - sse: 2212.5740 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0715 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 754/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.6666e-17 - r2_keras: -97.1131 - rmse: 0.8620 - sae: 2538.5674 - sse: 3043.3467\n","Epoch 754: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.8485e-17 - r2_keras: -80.0676 - rmse: 0.8541 - sae: 1856.2933 - sse: 2212.5769 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0714 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 755/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.3800e-16 - r2_keras: -97.1131 - rmse: 0.8620 - sae: 2538.5674 - sse: 3043.3467\n","Epoch 755: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.2771e-16 - r2_keras: -80.0676 - rmse: 0.8541 - sae: 1856.2932 - sse: 2212.5769 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0713 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 756/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.2153e-16 - r2_keras: -97.1132 - rmse: 0.8620 - sae: 2538.5674 - sse: 3043.3481\n","Epoch 756: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.2011e-16 - r2_keras: -80.0677 - rmse: 0.8541 - sae: 1856.2933 - sse: 2212.5784 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0712 - val_sse: 483.3115 - learning_rate: 1.0000e-05\n","Epoch 757/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.9617e-16 - r2_keras: -97.1132 - rmse: 0.8620 - sae: 2538.5679 - sse: 3043.3491\n","Epoch 757: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.9027e-16 - r2_keras: -80.0677 - rmse: 0.8541 - sae: 1856.2936 - sse: 2212.5786 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0714 - val_sse: 483.3119 - learning_rate: 1.0000e-05\n","Epoch 758/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.7502e-16 - r2_keras: -97.1133 - rmse: 0.8620 - sae: 2538.5688 - sse: 3043.3521\n","Epoch 758: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.0804e-16 - r2_keras: -80.0678 - rmse: 0.8541 - sae: 1856.2944 - sse: 2212.5811 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0712 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 759/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.2329e-16 - r2_keras: -97.1133 - rmse: 0.8620 - sae: 2538.5688 - sse: 3043.3516\n","Epoch 759: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.0331e-16 - r2_keras: -80.0677 - rmse: 0.8541 - sae: 1856.2943 - sse: 2212.5803 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0714 - val_sse: 483.3121 - learning_rate: 1.0000e-05\n","Epoch 760/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.5478e-16 - r2_keras: -97.1134 - rmse: 0.8620 - sae: 2538.5698 - sse: 3043.3555\n","Epoch 760: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.9097e-16 - r2_keras: -80.0679 - rmse: 0.8541 - sae: 1856.2950 - sse: 2212.5833 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0710 - val_sse: 483.3114 - learning_rate: 1.0000e-05\n","Epoch 761/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.0230e-16 - r2_keras: -97.1134 - rmse: 0.8620 - sae: 2538.5691 - sse: 3043.3538\n","Epoch 761: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.3853e-17 - r2_keras: -80.0678 - rmse: 0.8541 - sae: 1856.2946 - sse: 2212.5820 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.7125e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0713 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 762/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.4184e-16 - r2_keras: -97.1135 - rmse: 0.8620 - sae: 2538.5703 - sse: 3043.3574\n","Epoch 762: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.1688e-16 - r2_keras: -80.0679 - rmse: 0.8541 - sae: 1856.2955 - sse: 2212.5847 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0713 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 763/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.6505e-16 - r2_keras: -97.1135 - rmse: 0.8620 - sae: 2538.5706 - sse: 3043.3577\n","Epoch 763: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.3377e-16 - r2_keras: -80.0679 - rmse: 0.8541 - sae: 1856.2955 - sse: 2212.5847 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0711 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 764/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.1310e-16 - r2_keras: -97.1135 - rmse: 0.8620 - sae: 2538.5708 - sse: 3043.3594\n","Epoch 764: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.4710e-18 - r2_keras: -80.0680 - rmse: 0.8541 - sae: 1856.2959 - sse: 2212.5862 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.8051e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0711 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 765/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.6390e-16 - r2_keras: -97.1135 - rmse: 0.8620 - sae: 2538.5708 - sse: 3043.3594\n","Epoch 765: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.9826e-16 - r2_keras: -80.0680 - rmse: 0.8541 - sae: 1856.2958 - sse: 2212.5859 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0713 - val_sse: 483.3122 - learning_rate: 1.0000e-05\n","Epoch 766/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.2949e-17 - r2_keras: -97.1137 - rmse: 0.8620 - sae: 2538.5723 - sse: 3043.3633\n","Epoch 766: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -8.0300e-17 - r2_keras: -80.0681 - rmse: 0.8541 - sae: 1856.2970 - sse: 2212.5891 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.0295e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0710 - val_sse: 483.3115 - learning_rate: 1.0000e-05\n","Epoch 767/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.7532e-16 - r2_keras: -97.1137 - rmse: 0.8620 - sae: 2538.5718 - sse: 3043.3628\n","Epoch 767: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.7386e-17 - r2_keras: -80.0680 - rmse: 0.8541 - sae: 1856.2965 - sse: 2212.5884 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0711 - val_sse: 483.3118 - learning_rate: 1.0000e-05\n","Epoch 768/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.8390e-16 - r2_keras: -97.1137 - rmse: 0.8620 - sae: 2538.5730 - sse: 3043.3657\n","Epoch 768: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -8.8057e-17 - r2_keras: -80.0681 - rmse: 0.8541 - sae: 1856.2975 - sse: 2212.5908 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0710 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 769/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.1378e-15 - r2_keras: -97.1137 - rmse: 0.8620 - sae: 2538.5725 - sse: 3043.3652\n","Epoch 769: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.6043e-16 - r2_keras: -80.0681 - rmse: 0.8541 - sae: 1856.2971 - sse: 2212.5903 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0710 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 770/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.0443e-16 - r2_keras: -97.1138 - rmse: 0.8620 - sae: 2538.5732 - sse: 3043.3682\n","Epoch 770: val_loss did not improve from 0.19324\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.2215e-16 - r2_keras: -80.0682 - rmse: 0.8541 - sae: 1856.2977 - sse: 2212.5925 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0710 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 771/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.1609e-16 - r2_keras: -97.1138 - rmse: 0.8620 - sae: 2538.5732 - sse: 3043.3677\n","Epoch 771: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6901e-16 - r2_keras: -80.0682 - rmse: 0.8541 - sae: 1856.2976 - sse: 2212.5920 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0711 - val_sse: 483.3120 - learning_rate: 1.0000e-05\n","Epoch 772/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.2144e-17 - r2_keras: -97.1139 - rmse: 0.8620 - sae: 2538.5745 - sse: 3043.3713\n","Epoch 772: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.9813e-17 - r2_keras: -80.0683 - rmse: 0.8541 - sae: 1856.2986 - sse: 2212.5947 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0709 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 773/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.4222e-16 - r2_keras: -97.1139 - rmse: 0.8620 - sae: 2538.5735 - sse: 3043.3691\n","Epoch 773: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.9863e-17 - r2_keras: -80.0682 - rmse: 0.8541 - sae: 1856.2979 - sse: 2212.5930 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0709 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 774/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.2083e-16 - r2_keras: -97.1140 - rmse: 0.8620 - sae: 2538.5750 - sse: 3043.3733\n","Epoch 774: val_loss improved from 0.19324 to 0.19324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.5489e-16 - r2_keras: -80.0683 - rmse: 0.8541 - sae: 1856.2990 - sse: 2212.5962 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.4783e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0709 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 775/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.5019e-16 - r2_keras: -97.1140 - rmse: 0.8620 - sae: 2538.5747 - sse: 3043.3730\n","Epoch 775: val_loss improved from 0.19324 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9519e-17 - r2_keras: -80.0683 - rmse: 0.8541 - sae: 1856.2987 - sse: 2212.5959 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0707 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 776/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.7394e-17 - r2_keras: -97.1140 - rmse: 0.8620 - sae: 2538.5747 - sse: 3043.3728\n","Epoch 776: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -9.7859e-17 - r2_keras: -80.0683 - rmse: 0.8541 - sae: 1856.2987 - sse: 2212.5955 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0709 - val_sse: 483.3117 - learning_rate: 1.0000e-05\n","Epoch 777/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.9586e-16 - r2_keras: -97.1141 - rmse: 0.8620 - sae: 2538.5759 - sse: 3043.3760\n","Epoch 777: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.4107e-17 - r2_keras: -80.0684 - rmse: 0.8541 - sae: 1856.2996 - sse: 2212.5979 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0706 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 778/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.3478e-16 - r2_keras: -97.1141 - rmse: 0.8620 - sae: 2538.5757 - sse: 3043.3755\n","Epoch 778: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5460e-16 - r2_keras: -80.0684 - rmse: 0.8541 - sae: 1856.2993 - sse: 2212.5974 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0707 - val_sse: 483.3114 - learning_rate: 1.0000e-05\n","Epoch 779/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.5287e-16 - r2_keras: -97.1141 - rmse: 0.8620 - sae: 2538.5762 - sse: 3043.3779\n","Epoch 779: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.9833e-16 - r2_keras: -80.0685 - rmse: 0.8541 - sae: 1856.2999 - sse: 2212.5994 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.1417e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0706 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 780/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.5784e-17 - r2_keras: -97.1141 - rmse: 0.8620 - sae: 2538.5762 - sse: 3043.3779\n","Epoch 780: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.6382e-17 - r2_keras: -80.0684 - rmse: 0.8541 - sae: 1856.2998 - sse: 2212.5991 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0706 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 781/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.7838e-16 - r2_keras: -97.1142 - rmse: 0.8620 - sae: 2538.5771 - sse: 3043.3811\n","Epoch 781: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.0114e-16 - r2_keras: -80.0685 - rmse: 0.8541 - sae: 1856.3004 - sse: 2212.6016 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0706 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 782/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -9.2871e-17 - r2_keras: -97.1142 - rmse: 0.8620 - sae: 2538.5769 - sse: 3043.3804\n","Epoch 782: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.0096e-17 - r2_keras: -80.0685 - rmse: 0.8541 - sae: 1856.3003 - sse: 2212.6008 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0706 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 783/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.8589e-16 - r2_keras: -97.1143 - rmse: 0.8620 - sae: 2538.5776 - sse: 3043.3828\n","Epoch 783: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.0544e-16 - r2_keras: -80.0686 - rmse: 0.8541 - sae: 1856.3009 - sse: 2212.6030 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.0295e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0705 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 784/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.3371e-16 - r2_keras: -97.1143 - rmse: 0.8620 - sae: 2538.5774 - sse: 3043.3831\n","Epoch 784: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.0949e-16 - r2_keras: -80.0686 - rmse: 0.8541 - sae: 1856.3007 - sse: 2212.6028 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.3759e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0705 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 785/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.5616e-16 - r2_keras: -97.1144 - rmse: 0.8620 - sae: 2538.5786 - sse: 3043.3862\n","Epoch 785: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.2976e-16 - r2_keras: -80.0687 - rmse: 0.8541 - sae: 1856.3016 - sse: 2212.6052 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.4684e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0705 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 786/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.4864e-16 - r2_keras: -97.1144 - rmse: 0.8620 - sae: 2538.5789 - sse: 3043.3867\n","Epoch 786: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.5405e-16 - r2_keras: -80.0687 - rmse: 0.8541 - sae: 1856.3018 - sse: 2212.6055 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0705 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 787/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.3823e-16 - r2_keras: -97.1145 - rmse: 0.8620 - sae: 2538.5791 - sse: 3043.3887\n","Epoch 787: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9158e-17 - r2_keras: -80.0687 - rmse: 0.8541 - sae: 1856.3020 - sse: 2212.6072 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0704 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 788/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.9547e-16 - r2_keras: -97.1145 - rmse: 0.8620 - sae: 2538.5793 - sse: 3043.3892\n","Epoch 788: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.9486e-16 - r2_keras: -80.0687 - rmse: 0.8541 - sae: 1856.3021 - sse: 2212.6072 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0705 - val_sse: 483.3115 - learning_rate: 1.0000e-05\n","Epoch 789/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0807 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.3946e-16 - r2_keras: -97.1146 - rmse: 0.8620 - sae: 2538.5806 - sse: 3043.3921\n","Epoch 789: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.8253e-18 - r2_keras: -80.0688 - rmse: 0.8541 - sae: 1856.3031 - sse: 2212.6096 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0703 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 790/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.2665e-16 - r2_keras: -97.1145 - rmse: 0.8620 - sae: 2538.5796 - sse: 3043.3904\n","Epoch 790: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.1994e-16 - r2_keras: -80.0687 - rmse: 0.8541 - sae: 1856.3024 - sse: 2212.6082 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0705 - val_sse: 483.3116 - learning_rate: 1.0000e-05\n","Epoch 791/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.0099e-16 - r2_keras: -97.1147 - rmse: 0.8620 - sae: 2538.5811 - sse: 3043.3950\n","Epoch 791: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.0258e-16 - r2_keras: -80.0689 - rmse: 0.8541 - sae: 1856.3035 - sse: 2212.6116 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0703 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 792/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.0160e-16 - r2_keras: -97.1147 - rmse: 0.8620 - sae: 2538.5808 - sse: 3043.3943\n","Epoch 792: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5884e-16 - r2_keras: -80.0688 - rmse: 0.8541 - sae: 1856.3032 - sse: 2212.6108 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0704 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 793/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.3056e-16 - r2_keras: -97.1148 - rmse: 0.8620 - sae: 2538.5820 - sse: 3043.3975\n","Epoch 793: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.5946e-16 - r2_keras: -80.0689 - rmse: 0.8541 - sae: 1856.3042 - sse: 2212.6135 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0703 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 794/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.2819e-16 - r2_keras: -97.1148 - rmse: 0.8620 - sae: 2538.5815 - sse: 3043.3970\n","Epoch 794: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.3172e-16 - r2_keras: -80.0689 - rmse: 0.8541 - sae: 1856.3038 - sse: 2212.6128 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.8149e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0704 - val_sse: 483.3114 - learning_rate: 1.0000e-05\n","Epoch 795/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.7945e-16 - r2_keras: -97.1149 - rmse: 0.8620 - sae: 2538.5828 - sse: 3043.3999\n","Epoch 795: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.6468e-16 - r2_keras: -80.0690 - rmse: 0.8541 - sae: 1856.3048 - sse: 2212.6152 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 796/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -8.8273e-17 - r2_keras: -97.1148 - rmse: 0.8620 - sae: 2538.5823 - sse: 3043.3992\n","Epoch 796: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.8445e-17 - r2_keras: -80.0690 - rmse: 0.8541 - sae: 1856.3043 - sse: 2212.6145 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0704 - val_sse: 483.3115 - learning_rate: 1.0000e-05\n","Epoch 797/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.1454e-16 - r2_keras: -97.1149 - rmse: 0.8620 - sae: 2538.5835 - sse: 3043.4023\n","Epoch 797: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.6939e-16 - r2_keras: -80.0691 - rmse: 0.8541 - sae: 1856.3053 - sse: 2212.6169 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 798/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.2933e-16 - r2_keras: -97.1149 - rmse: 0.8620 - sae: 2538.5828 - sse: 3043.4019\n","Epoch 798: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.6248e-16 - r2_keras: -80.0690 - rmse: 0.8541 - sae: 1856.3047 - sse: 2212.6165 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.6929e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0703 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 799/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.4680e-16 - r2_keras: -97.1150 - rmse: 0.8620 - sae: 2538.5840 - sse: 3043.4053\n","Epoch 799: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.3287e-16 - r2_keras: -80.0692 - rmse: 0.8541 - sae: 1856.3057 - sse: 2212.6191 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 800/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.4590e-16 - r2_keras: -97.1150 - rmse: 0.8620 - sae: 2538.5835 - sse: 3043.4041\n","Epoch 800: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.0590e-16 - r2_keras: -80.0691 - rmse: 0.8541 - sae: 1856.3053 - sse: 2212.6182 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: 3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 801/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.7361e-16 - r2_keras: -97.1151 - rmse: 0.8620 - sae: 2538.5847 - sse: 3043.4080\n","Epoch 801: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.8675e-16 - r2_keras: -80.0692 - rmse: 0.8541 - sae: 1856.3063 - sse: 2212.6211 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.8051e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 802/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.8106e-16 - r2_keras: -97.1151 - rmse: 0.8620 - sae: 2538.5850 - sse: 3043.4080\n","Epoch 802: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.8354e-16 - r2_keras: -80.0692 - rmse: 0.8541 - sae: 1856.3063 - sse: 2212.6208 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -2.2440e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 803/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.2412e-17 - r2_keras: -97.1152 - rmse: 0.8620 - sae: 2538.5854 - sse: 3043.4104\n","Epoch 803: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5233e-18 - r2_keras: -80.0693 - rmse: 0.8541 - sae: 1856.3068 - sse: 2212.6228 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0700 - val_sse: 483.3109 - learning_rate: 1.0000e-05\n","Epoch 804/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.8427e-17 - r2_keras: -97.1152 - rmse: 0.8620 - sae: 2538.5854 - sse: 3043.4106\n","Epoch 804: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.4134e-19 - r2_keras: -80.0693 - rmse: 0.8541 - sae: 1856.3068 - sse: 2212.6228 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0702 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 805/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.1608e-16 - r2_keras: -97.1153 - rmse: 0.8620 - sae: 2538.5867 - sse: 3043.4138\n","Epoch 805: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6421e-16 - r2_keras: -80.0694 - rmse: 0.8541 - sae: 1856.3076 - sse: 2212.6252 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2825 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0700 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 806/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.3263e-16 - r2_keras: -97.1153 - rmse: 0.8620 - sae: 2538.5859 - sse: 3043.4126\n","Epoch 806: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5893e-16 - r2_keras: -80.0693 - rmse: 0.8541 - sae: 1856.3071 - sse: 2212.6243 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0701 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 807/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.0803e-16 - r2_keras: -97.1154 - rmse: 0.8620 - sae: 2538.5872 - sse: 3043.4158\n","Epoch 807: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5738e-16 - r2_keras: -80.0694 - rmse: 0.8541 - sae: 1856.3080 - sse: 2212.6265 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -6.7321e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0699 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 808/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.9193e-16 - r2_keras: -97.1154 - rmse: 0.8620 - sae: 2538.5869 - sse: 3043.4155\n","Epoch 808: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.0493e-16 - r2_keras: -80.0694 - rmse: 0.8541 - sae: 1856.3077 - sse: 2212.6262 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.5807e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0701 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 809/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.3531e-16 - r2_keras: -97.1155 - rmse: 0.8620 - sae: 2538.5879 - sse: 3043.4187\n","Epoch 809: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.8495e-16 - r2_keras: -80.0695 - rmse: 0.8541 - sae: 1856.3086 - sse: 2212.6287 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.8051e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0700 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 810/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.3088e-16 - r2_keras: -97.1154 - rmse: 0.8620 - sae: 2538.5879 - sse: 3043.4185\n","Epoch 810: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.9574e-17 - r2_keras: -80.0695 - rmse: 0.8541 - sae: 1856.3085 - sse: 2212.6282 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0700 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 811/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.2289e-16 - r2_keras: -97.1155 - rmse: 0.8620 - sae: 2538.5884 - sse: 3043.4209\n","Epoch 811: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.0637e-16 - r2_keras: -80.0696 - rmse: 0.8541 - sae: 1856.3090 - sse: 2212.6304 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0698 - val_sse: 483.3108 - learning_rate: 1.0000e-05\n","Epoch 812/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.5164e-16 - r2_keras: -97.1155 - rmse: 0.8620 - sae: 2538.5879 - sse: 3043.4204\n","Epoch 812: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4377e-16 - r2_keras: -80.0695 - rmse: 0.8541 - sae: 1856.3085 - sse: 2212.6296 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0699 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 813/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.8206e-16 - r2_keras: -97.1156 - rmse: 0.8620 - sae: 2538.5894 - sse: 3043.4243\n","Epoch 813: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3193e-16 - r2_keras: -80.0696 - rmse: 0.8541 - sae: 1856.3097 - sse: 2212.6328 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0697 - val_sse: 483.3108 - learning_rate: 1.0000e-05\n","Epoch 814/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.5523e-16 - r2_keras: -97.1156 - rmse: 0.8620 - sae: 2538.5889 - sse: 3043.4231\n","Epoch 814: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.7329e-16 - r2_keras: -80.0696 - rmse: 0.8541 - sae: 1856.3092 - sse: 2212.6316 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.2539e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0699 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 815/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -9.4463e-16 - r2_keras: -97.1157 - rmse: 0.8620 - sae: 2538.5906 - sse: 3043.4272\n","Epoch 815: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.7218e-16 - r2_keras: -80.0697 - rmse: 0.8541 - sae: 1856.3105 - sse: 2212.6348 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0698 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 816/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.0636e-16 - r2_keras: -97.1157 - rmse: 0.8620 - sae: 2538.5898 - sse: 3043.4255\n","Epoch 816: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.7873e-17 - r2_keras: -80.0697 - rmse: 0.8541 - sae: 1856.3099 - sse: 2212.6335 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.1318e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0698 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 817/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.0137e-16 - r2_keras: -97.1158 - rmse: 0.8620 - sae: 2538.5908 - sse: 3043.4292\n","Epoch 817: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5728e-16 - r2_keras: -80.0698 - rmse: 0.8541 - sae: 1856.3107 - sse: 2212.6362 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.4685e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0697 - val_sse: 483.3109 - learning_rate: 1.0000e-05\n","Epoch 818/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.0842e-16 - r2_keras: -97.1158 - rmse: 0.8620 - sae: 2538.5911 - sse: 3043.4297\n","Epoch 818: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.6573e-17 - r2_keras: -80.0698 - rmse: 0.8541 - sae: 1856.3109 - sse: 2212.6365 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0698 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 819/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.4559e-16 - r2_keras: -97.1159 - rmse: 0.8620 - sae: 2538.5920 - sse: 3043.4326\n","Epoch 819: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.9230e-17 - r2_keras: -80.0699 - rmse: 0.8541 - sae: 1856.3116 - sse: 2212.6387 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0697 - val_sse: 483.3109 - learning_rate: 1.0000e-05\n","Epoch 820/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.1263e-17 - r2_keras: -97.1158 - rmse: 0.8620 - sae: 2538.5913 - sse: 3043.4307\n","Epoch 820: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.1935e-17 - r2_keras: -80.0698 - rmse: 0.8541 - sae: 1856.3110 - sse: 2212.6372 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0696 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 821/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.0672e-16 - r2_keras: -97.1160 - rmse: 0.8620 - sae: 2538.5920 - sse: 3043.4341\n","Epoch 821: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.5847e-16 - r2_keras: -80.0699 - rmse: 0.8541 - sae: 1856.3116 - sse: 2212.6396 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0696 - val_sse: 483.3108 - learning_rate: 1.0000e-05\n","Epoch 822/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.8036e-16 - r2_keras: -97.1160 - rmse: 0.8620 - sae: 2538.5923 - sse: 3043.4346\n","Epoch 822: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.6029e-16 - r2_keras: -80.0699 - rmse: 0.8541 - sae: 1856.3118 - sse: 2212.6399 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.1417e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0697 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 823/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.3868e-16 - r2_keras: -97.1160 - rmse: 0.8620 - sae: 2538.5930 - sse: 3043.4368\n","Epoch 823: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.0851e-16 - r2_keras: -80.0700 - rmse: 0.8541 - sae: 1856.3124 - sse: 2212.6416 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.6929e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0696 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 824/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.5723e-16 - r2_keras: -97.1160 - rmse: 0.8620 - sae: 2538.5928 - sse: 3043.4365\n","Epoch 824: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5472e-16 - r2_keras: -80.0699 - rmse: 0.8541 - sae: 1856.3121 - sse: 2212.6414 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.2440e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0697 - val_sse: 483.3111 - learning_rate: 1.0000e-05\n","Epoch 825/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -9.4708e-17 - r2_keras: -97.1161 - rmse: 0.8620 - sae: 2538.5938 - sse: 3043.4402\n","Epoch 825: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.8189e-17 - r2_keras: -80.0701 - rmse: 0.8541 - sae: 1856.3129 - sse: 2212.6440 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0695 - val_sse: 483.3108 - learning_rate: 1.0000e-05\n","Epoch 826/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.5476e-17 - r2_keras: -97.1161 - rmse: 0.8620 - sae: 2538.5935 - sse: 3043.4390\n","Epoch 826: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.0267e-17 - r2_keras: -80.0700 - rmse: 0.8541 - sae: 1856.3127 - sse: 2212.6431 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.0196e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0697 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 827/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.7814e-17 - r2_keras: -97.1162 - rmse: 0.8620 - sae: 2538.5950 - sse: 3043.4434\n","Epoch 827: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.0663e-17 - r2_keras: -80.0701 - rmse: 0.8541 - sae: 1856.3138 - sse: 2212.6465 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0694 - val_sse: 483.3106 - learning_rate: 1.0000e-05\n","Epoch 828/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.0758e-16 - r2_keras: -97.1162 - rmse: 0.8620 - sae: 2538.5942 - sse: 3043.4419\n","Epoch 828: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.5495e-18 - r2_keras: -80.0701 - rmse: 0.8541 - sae: 1856.3132 - sse: 2212.6453 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7321e-17 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0696 - val_sse: 483.3112 - learning_rate: 1.0000e-05\n","Epoch 829/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.5938e-16 - r2_keras: -97.1163 - rmse: 0.8620 - sae: 2538.5957 - sse: 3043.4460\n","Epoch 829: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6767e-16 - r2_keras: -80.0702 - rmse: 0.8541 - sae: 1856.3143 - sse: 2212.6484 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0694 - val_sse: 483.3108 - learning_rate: 1.0000e-05\n","Epoch 830/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.7292e-16 - r2_keras: -97.1163 - rmse: 0.8620 - sae: 2538.5952 - sse: 3043.4448\n","Epoch 830: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.0569e-16 - r2_keras: -80.0702 - rmse: 0.8541 - sae: 1856.3140 - sse: 2212.6472 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0695 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 831/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.0727e-17 - r2_keras: -97.1164 - rmse: 0.8620 - sae: 2538.5959 - sse: 3043.4473\n","Epoch 831: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.1383e-17 - r2_keras: -80.0702 - rmse: 0.8541 - sae: 1856.3146 - sse: 2212.6492 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0693 - val_sse: 483.3107 - learning_rate: 1.0000e-05\n","Epoch 832/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.4589e-16 - r2_keras: -97.1164 - rmse: 0.8620 - sae: 2538.5959 - sse: 3043.4478\n","Epoch 832: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4524e-16 - r2_keras: -80.0702 - rmse: 0.8541 - sae: 1856.3146 - sse: 2212.6494 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.4684e-16 - val_r2_keras: -33.4531 - val_rmse: 0.9558 - val_sae: 363.0695 - val_sse: 483.3113 - learning_rate: 1.0000e-05\n","Epoch 833/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.3567e-16 - r2_keras: -97.1165 - rmse: 0.8620 - sae: 2538.5967 - sse: 3043.4504\n","Epoch 833: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.5545e-16 - r2_keras: -80.0703 - rmse: 0.8541 - sae: 1856.3151 - sse: 2212.6516 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0692 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 834/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.8410e-16 - r2_keras: -97.1164 - rmse: 0.8620 - sae: 2538.5964 - sse: 3043.4492\n","Epoch 834: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3687e-16 - r2_keras: -80.0703 - rmse: 0.8541 - sae: 1856.3148 - sse: 2212.6504 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0694 - val_sse: 483.3110 - learning_rate: 1.0000e-05\n","Epoch 835/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.4336e-16 - r2_keras: -97.1166 - rmse: 0.8620 - sae: 2538.5977 - sse: 3043.4531\n","Epoch 835: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4113e-16 - r2_keras: -80.0704 - rmse: 0.8541 - sae: 1856.3158 - sse: 2212.6536 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.5905e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0692 - val_sse: 483.3107 - learning_rate: 1.0000e-05\n","Epoch 836/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.1430e-16 - r2_keras: -97.1165 - rmse: 0.8620 - sae: 2538.5972 - sse: 3043.4521\n","Epoch 836: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.5822e-16 - r2_keras: -80.0704 - rmse: 0.8541 - sae: 1856.3154 - sse: 2212.6526 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0691 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 837/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.2229e-16 - r2_keras: -97.1165 - rmse: 0.8620 - sae: 2538.5969 - sse: 3043.4517\n","Epoch 837: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.4486e-16 - r2_keras: -80.0703 - rmse: 0.8541 - sae: 1856.3152 - sse: 2212.6521 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0692 - val_sse: 483.3107 - learning_rate: 1.0000e-05\n","Epoch 838/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.8696e-17 - r2_keras: -97.1166 - rmse: 0.8620 - sae: 2538.5981 - sse: 3043.4546\n","Epoch 838: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.0696e-17 - r2_keras: -80.0704 - rmse: 0.8541 - sae: 1856.3162 - sse: 2212.6543 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0693 - val_sse: 483.3109 - learning_rate: 1.0000e-05\n","Epoch 839/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.0915e-17 - r2_keras: -97.1167 - rmse: 0.8620 - sae: 2538.5991 - sse: 3043.4585\n","Epoch 839: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.7124e-17 - r2_keras: -80.0705 - rmse: 0.8541 - sae: 1856.3169 - sse: 2212.6572 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0692 - val_sse: 483.3107 - learning_rate: 1.0000e-05\n","Epoch 840/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.1185e-17 - r2_keras: -97.1167 - rmse: 0.8620 - sae: 2538.5991 - sse: 3043.4580\n","Epoch 840: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.4425e-17 - r2_keras: -80.0705 - rmse: 0.8541 - sae: 1856.3169 - sse: 2212.6567 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 841/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.2450e-16 - r2_keras: -97.1167 - rmse: 0.8620 - sae: 2538.5989 - sse: 3043.4580\n","Epoch 841: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.6093e-16 - r2_keras: -80.0705 - rmse: 0.8541 - sae: 1856.3167 - sse: 2212.6565 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0690 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 842/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.9003e-16 - r2_keras: -97.1168 - rmse: 0.8620 - sae: 2538.5996 - sse: 3043.4604\n","Epoch 842: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3628e-16 - r2_keras: -80.0706 - rmse: 0.8541 - sae: 1856.3173 - sse: 2212.6584 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 843/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.4013e-16 - r2_keras: -97.1168 - rmse: 0.8620 - sae: 2538.5996 - sse: 3043.4600\n","Epoch 843: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.3564e-16 - r2_keras: -80.0705 - rmse: 0.8541 - sae: 1856.3173 - sse: 2212.6580 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0690 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 844/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.6587e-17 - r2_keras: -97.1169 - rmse: 0.8620 - sae: 2538.6006 - sse: 3043.4634\n","Epoch 844: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.3937e-17 - r2_keras: -80.0706 - rmse: 0.8541 - sae: 1856.3180 - sse: 2212.6606 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 845/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.9438e-16 - r2_keras: -97.1169 - rmse: 0.8620 - sae: 2538.6001 - sse: 3043.4626\n","Epoch 845: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.8695e-16 - r2_keras: -80.0706 - rmse: 0.8541 - sae: 1856.3175 - sse: 2212.6599 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.7027e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0690 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 846/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.7261e-16 - r2_keras: -97.1170 - rmse: 0.8620 - sae: 2538.6016 - sse: 3043.4668\n","Epoch 846: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.5846e-16 - r2_keras: -80.0707 - rmse: 0.8541 - sae: 1856.3187 - sse: 2212.6631 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0688 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 847/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.0443e-16 - r2_keras: -97.1170 - rmse: 0.8620 - sae: 2538.6011 - sse: 3043.4658\n","Epoch 847: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -9.7905e-17 - r2_keras: -80.0707 - rmse: 0.8541 - sae: 1856.3182 - sse: 2212.6621 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 848/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.9162e-16 - r2_keras: -97.1171 - rmse: 0.8620 - sae: 2538.6023 - sse: 3043.4695\n","Epoch 848: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.0759e-16 - r2_keras: -80.0708 - rmse: 0.8541 - sae: 1856.3192 - sse: 2212.6650 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 849/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.2970e-16 - r2_keras: -97.1171 - rmse: 0.8620 - sae: 2538.6021 - sse: 3043.4690\n","Epoch 849: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.1258e-16 - r2_keras: -80.0708 - rmse: 0.8541 - sae: 1856.3190 - sse: 2212.6646 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 850/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 9.1948e-18 - r2_keras: -97.1171 - rmse: 0.8620 - sae: 2538.6030 - sse: 3043.4712\n","Epoch 850: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.4577e-17 - r2_keras: -80.0708 - rmse: 0.8541 - sae: 1856.3198 - sse: 2212.6663 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0686 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 851/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -8.3673e-16 - r2_keras: -97.1171 - rmse: 0.8620 - sae: 2538.6025 - sse: 3043.4709\n","Epoch 851: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.9332e-16 - r2_keras: -80.0708 - rmse: 0.8541 - sae: 1856.3193 - sse: 2212.6658 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.9074e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0689 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 852/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.2218e-16 - r2_keras: -97.1173 - rmse: 0.8620 - sae: 2538.6040 - sse: 3043.4751\n","Epoch 852: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.9751e-16 - r2_keras: -80.0709 - rmse: 0.8541 - sae: 1856.3204 - sse: 2212.6689 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0687 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 853/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.2987e-16 - r2_keras: -97.1172 - rmse: 0.8620 - sae: 2538.6035 - sse: 3043.4741\n","Epoch 853: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5037e-16 - r2_keras: -80.0709 - rmse: 0.8541 - sae: 1856.3202 - sse: 2212.6682 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.3661e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0688 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 854/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.8635e-16 - r2_keras: -97.1174 - rmse: 0.8620 - sae: 2538.6050 - sse: 3043.4775\n","Epoch 854: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3383e-16 - r2_keras: -80.0710 - rmse: 0.8541 - sae: 1856.3212 - sse: 2212.6707 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.3563e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0685 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 855/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.0811e-16 - r2_keras: -97.1173 - rmse: 0.8620 - sae: 2538.6042 - sse: 3043.4763\n","Epoch 855: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3586e-16 - r2_keras: -80.0710 - rmse: 0.8541 - sae: 1856.3207 - sse: 2212.6697 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0688 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 856/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.6860e-16 - r2_keras: -97.1174 - rmse: 0.8620 - sae: 2538.6055 - sse: 3043.4797\n","Epoch 856: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.5103e-16 - r2_keras: -80.0711 - rmse: 0.8541 - sae: 1856.3217 - sse: 2212.6724 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0686 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 857/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.9083e-16 - r2_keras: -97.1174 - rmse: 0.8620 - sae: 2538.6055 - sse: 3043.4800\n","Epoch 857: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.0565e-16 - r2_keras: -80.0711 - rmse: 0.8541 - sae: 1856.3215 - sse: 2212.6724 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.1417e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0687 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 858/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.1454e-17 - r2_keras: -97.1175 - rmse: 0.8620 - sae: 2538.6062 - sse: 3043.4827\n","Epoch 858: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -8.8190e-17 - r2_keras: -80.0711 - rmse: 0.8541 - sae: 1856.3221 - sse: 2212.6746 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0686 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 859/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.6052e-16 - r2_keras: -97.1175 - rmse: 0.8620 - sae: 2538.6055 - sse: 3043.4814\n","Epoch 859: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.8903e-16 - r2_keras: -80.0711 - rmse: 0.8541 - sae: 1856.3217 - sse: 2212.6733 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0687 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 860/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.3215e-17 - r2_keras: -97.1176 - rmse: 0.8620 - sae: 2538.6069 - sse: 3043.4856\n","Epoch 860: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8209e-17 - r2_keras: -80.0712 - rmse: 0.8541 - sae: 1856.3228 - sse: 2212.6765 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0685 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 861/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.9546e-16 - r2_keras: -97.1176 - rmse: 0.8620 - sae: 2538.6069 - sse: 3043.4851\n","Epoch 861: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.3823e-16 - r2_keras: -80.0712 - rmse: 0.8541 - sae: 1856.3226 - sse: 2212.6760 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0686 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 862/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -8.8269e-17 - r2_keras: -97.1177 - rmse: 0.8620 - sae: 2538.6074 - sse: 3043.4878\n","Epoch 862: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.8140e-17 - r2_keras: -80.0713 - rmse: 0.8541 - sae: 1856.3231 - sse: 2212.6782 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0685 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 863/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.0699e-16 - r2_keras: -97.1177 - rmse: 0.8620 - sae: 2538.6074 - sse: 3043.4878\n","Epoch 863: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.3032e-16 - r2_keras: -80.0713 - rmse: 0.8541 - sae: 1856.3231 - sse: 2212.6780 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0686 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 864/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.4656e-16 - r2_keras: -97.1178 - rmse: 0.8620 - sae: 2538.6084 - sse: 3043.4907\n","Epoch 864: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.9387e-16 - r2_keras: -80.0713 - rmse: 0.8541 - sae: 1856.3237 - sse: 2212.6802 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0685 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 865/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.7236e-17 - r2_keras: -97.1178 - rmse: 0.8620 - sae: 2538.6082 - sse: 3043.4902\n","Epoch 865: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -8.4116e-17 - r2_keras: -80.0713 - rmse: 0.8541 - sae: 1856.3236 - sse: 2212.6797 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -5.7223e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0686 - val_sse: 483.3106 - learning_rate: 1.0000e-05\n","Epoch 866/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.1240e-16 - r2_keras: -97.1179 - rmse: 0.8620 - sae: 2538.6091 - sse: 3043.4932\n","Epoch 866: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3968e-16 - r2_keras: -80.0714 - rmse: 0.8541 - sae: 1856.3243 - sse: 2212.6821 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0684 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 867/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -8.0607e-17 - r2_keras: -97.1178 - rmse: 0.8620 - sae: 2538.6084 - sse: 3043.4917\n","Epoch 867: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.8000e-18 - r2_keras: -80.0714 - rmse: 0.8541 - sae: 1856.3239 - sse: 2212.6809 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0685 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 868/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.4296e-16 - r2_keras: -97.1179 - rmse: 0.8620 - sae: 2538.6094 - sse: 3043.4956\n","Epoch 868: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6339e-16 - r2_keras: -80.0715 - rmse: 0.8541 - sae: 1856.3246 - sse: 2212.6838 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0684 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 869/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.6091e-16 - r2_keras: -97.1179 - rmse: 0.8620 - sae: 2538.6099 - sse: 3043.4951\n","Epoch 869: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 7.8767e-18 - r2_keras: -80.0714 - rmse: 0.8541 - sae: 1856.3248 - sse: 2212.6833 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0684 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 870/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.3945e-16 - r2_keras: -97.1180 - rmse: 0.8620 - sae: 2538.6106 - sse: 3043.4985\n","Epoch 870: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.2943e-16 - r2_keras: -80.0716 - rmse: 0.8541 - sae: 1856.3254 - sse: 2212.6858 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0684 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 871/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.9810e-16 - r2_keras: -97.1180 - rmse: 0.8620 - sae: 2538.6108 - sse: 3043.4990\n","Epoch 871: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.2631e-16 - r2_keras: -80.0715 - rmse: 0.8541 - sae: 1856.3256 - sse: 2212.6860 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0683 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 872/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.6380e-16 - r2_keras: -97.1181 - rmse: 0.8620 - sae: 2538.6113 - sse: 3043.5010\n","Epoch 872: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.2814e-16 - r2_keras: -80.0716 - rmse: 0.8541 - sae: 1856.3260 - sse: 2212.6877 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0683 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 873/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.0886e-16 - r2_keras: -97.1181 - rmse: 0.8620 - sae: 2538.6113 - sse: 3043.5007\n","Epoch 873: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.0520e-16 - r2_keras: -80.0716 - rmse: 0.8541 - sae: 1856.3259 - sse: 2212.6873 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0684 - val_sse: 483.3106 - learning_rate: 1.0000e-05\n","Epoch 874/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.7063e-16 - r2_keras: -97.1182 - rmse: 0.8620 - sae: 2538.6121 - sse: 3043.5042\n","Epoch 874: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3244e-16 - r2_keras: -80.0717 - rmse: 0.8541 - sae: 1856.3265 - sse: 2212.6899 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0682 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 875/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.1652e-16 - r2_keras: -97.1182 - rmse: 0.8620 - sae: 2538.6116 - sse: 3043.5029\n","Epoch 875: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.8727e-16 - r2_keras: -80.0717 - rmse: 0.8541 - sae: 1856.3262 - sse: 2212.6890 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.0295e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0683 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 876/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 9.7157e-17 - r2_keras: -97.1183 - rmse: 0.8620 - sae: 2538.6128 - sse: 3043.5066\n","Epoch 876: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.5984e-17 - r2_keras: -80.0718 - rmse: 0.8541 - sae: 1856.3270 - sse: 2212.6917 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0682 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 877/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.1463e-16 - r2_keras: -97.1183 - rmse: 0.8620 - sae: 2538.6128 - sse: 3043.5068\n","Epoch 877: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.4752e-17 - r2_keras: -80.0717 - rmse: 0.8541 - sae: 1856.3270 - sse: 2212.6917 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -7.8542e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0683 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 878/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.9239e-16 - r2_keras: -97.1184 - rmse: 0.8620 - sae: 2538.6138 - sse: 3043.5093\n","Epoch 878: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.6230e-16 - r2_keras: -80.0718 - rmse: 0.8541 - sae: 1856.3278 - sse: 2212.6936 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0682 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 879/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.3390e-16 - r2_keras: -97.1184 - rmse: 0.8620 - sae: 2538.6138 - sse: 3043.5100\n","Epoch 879: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.7608e-16 - r2_keras: -80.0718 - rmse: 0.8541 - sae: 1856.3278 - sse: 2212.6938 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0684 - val_sse: 483.3107 - learning_rate: 1.0000e-05\n","Epoch 880/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.9130e-16 - r2_keras: -97.1185 - rmse: 0.8620 - sae: 2538.6147 - sse: 3043.5120\n","Epoch 880: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.9854e-16 - r2_keras: -80.0719 - rmse: 0.8541 - sae: 1856.3285 - sse: 2212.6956 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.2441e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0680 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 881/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.4349e-16 - r2_keras: -97.1184 - rmse: 0.8620 - sae: 2538.6143 - sse: 3043.5112\n","Epoch 881: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.9086e-16 - r2_keras: -80.0719 - rmse: 0.8541 - sae: 1856.3281 - sse: 2212.6948 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0682 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 882/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.1183e-17 - r2_keras: -97.1186 - rmse: 0.8620 - sae: 2538.6155 - sse: 3043.5149\n","Epoch 882: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.8365e-17 - r2_keras: -80.0720 - rmse: 0.8541 - sae: 1856.3291 - sse: 2212.6978 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 883/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.6686e-16 - r2_keras: -97.1185 - rmse: 0.8620 - sae: 2538.6152 - sse: 3043.5144\n","Epoch 883: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.4841e-16 - r2_keras: -80.0720 - rmse: 0.8541 - sae: 1856.3289 - sse: 2212.6973 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 884/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.5115e-16 - r2_keras: -97.1187 - rmse: 0.8620 - sae: 2538.6162 - sse: 3043.5181\n","Epoch 884: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.9117e-16 - r2_keras: -80.0721 - rmse: 0.8541 - sae: 1856.3296 - sse: 2212.7000 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 885/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.6121e-16 - r2_keras: -97.1187 - rmse: 0.8620 - sae: 2538.6162 - sse: 3043.5178\n","Epoch 885: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.4970e-16 - r2_keras: -80.0720 - rmse: 0.8541 - sae: 1856.3296 - sse: 2212.6997 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 886/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.5605e-16 - r2_keras: -97.1187 - rmse: 0.8620 - sae: 2538.6165 - sse: 3043.5193\n","Epoch 886: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.8848e-16 - r2_keras: -80.0721 - rmse: 0.8541 - sae: 1856.3298 - sse: 2212.7009 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.1319e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 887/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.3976e-16 - r2_keras: -97.1187 - rmse: 0.8620 - sae: 2538.6167 - sse: 3043.5198\n","Epoch 887: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.2772e-16 - r2_keras: -80.0721 - rmse: 0.8541 - sae: 1856.3300 - sse: 2212.7012 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 888/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.4059e-16 - r2_keras: -97.1188 - rmse: 0.8620 - sae: 2538.6177 - sse: 3043.5225\n","Epoch 888: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.1701e-16 - r2_keras: -80.0722 - rmse: 0.8541 - sae: 1856.3307 - sse: 2212.7031 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 889/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.9874e-16 - r2_keras: -97.1188 - rmse: 0.8620 - sae: 2538.6172 - sse: 3043.5215\n","Epoch 889: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.7350e-16 - r2_keras: -80.0721 - rmse: 0.8541 - sae: 1856.3303 - sse: 2212.7024 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0681 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 890/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.5937e-17 - r2_keras: -97.1189 - rmse: 0.8620 - sae: 2538.6184 - sse: 3043.5256\n","Epoch 890: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.5434e-17 - r2_keras: -80.0723 - rmse: 0.8541 - sae: 1856.3313 - sse: 2212.7056 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.1319e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0678 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 891/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.6612e-16 - r2_keras: -97.1189 - rmse: 0.8620 - sae: 2538.6182 - sse: 3043.5244\n","Epoch 891: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.3357e-16 - r2_keras: -80.0722 - rmse: 0.8541 - sae: 1856.3311 - sse: 2212.7043 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0680 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 892/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.4650e-16 - r2_keras: -97.1190 - rmse: 0.8620 - sae: 2538.6194 - sse: 3043.5278\n","Epoch 892: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.1203e-17 - r2_keras: -80.0723 - rmse: 0.8541 - sae: 1856.3319 - sse: 2212.7070 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 893/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.7768e-16 - r2_keras: -97.1190 - rmse: 0.8620 - sae: 2538.6187 - sse: 3043.5273\n","Epoch 893: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9855e-16 - r2_keras: -80.0723 - rmse: 0.8541 - sae: 1856.3314 - sse: 2212.7065 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 7.8542e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 894/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.4909e-16 - r2_keras: -97.1191 - rmse: 0.8620 - sae: 2538.6201 - sse: 3043.5310\n","Epoch 894: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.4616e-16 - r2_keras: -80.0724 - rmse: 0.8541 - sae: 1856.3325 - sse: 2212.7092 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 895/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.3914e-16 - r2_keras: -97.1191 - rmse: 0.8620 - sae: 2538.6201 - sse: 3043.5308\n","Epoch 895: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -9.6601e-17 - r2_keras: -80.0724 - rmse: 0.8541 - sae: 1856.3325 - sse: 2212.7090 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.0196e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3106 - learning_rate: 1.0000e-05\n","Epoch 896/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.3556e-18 - r2_keras: -97.1191 - rmse: 0.8620 - sae: 2538.6206 - sse: 3043.5330\n","Epoch 896: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.4993e-17 - r2_keras: -80.0725 - rmse: 0.8541 - sae: 1856.3329 - sse: 2212.7107 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.2539e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0678 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 897/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.0534e-16 - r2_keras: -97.1191 - rmse: 0.8620 - sae: 2538.6204 - sse: 3043.5322\n","Epoch 897: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.2757e-17 - r2_keras: -80.0724 - rmse: 0.8541 - sae: 1856.3326 - sse: 2212.7100 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 898/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.4694e-16 - r2_keras: -97.1193 - rmse: 0.8620 - sae: 2538.6221 - sse: 3043.5371\n","Epoch 898: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.4473e-16 - r2_keras: -80.0726 - rmse: 0.8541 - sae: 1856.3340 - sse: 2212.7136 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 899/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.1297e-18 - r2_keras: -97.1192 - rmse: 0.8620 - sae: 2538.6213 - sse: 3043.5354\n","Epoch 899: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.4237e-17 - r2_keras: -80.0725 - rmse: 0.8541 - sae: 1856.3334 - sse: 2212.7124 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0679 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 900/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.6305e-16 - r2_keras: -97.1194 - rmse: 0.8620 - sae: 2538.6226 - sse: 3043.5396\n","Epoch 900: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.4516e-16 - r2_keras: -80.0726 - rmse: 0.8541 - sae: 1856.3344 - sse: 2212.7153 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 901/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.2382e-16 - r2_keras: -97.1193 - rmse: 0.8620 - sae: 2538.6221 - sse: 3043.5386\n","Epoch 901: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.4973e-17 - r2_keras: -80.0726 - rmse: 0.8541 - sae: 1856.3340 - sse: 2212.7146 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 902/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.2413e-16 - r2_keras: -97.1194 - rmse: 0.8620 - sae: 2538.6226 - sse: 3043.5410\n","Epoch 902: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.4923e-17 - r2_keras: -80.0727 - rmse: 0.8541 - sae: 1856.3345 - sse: 2212.7166 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 903/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.1147e-17 - r2_keras: -97.1194 - rmse: 0.8620 - sae: 2538.6228 - sse: 3043.5410\n","Epoch 903: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3475e-17 - r2_keras: -80.0726 - rmse: 0.8541 - sae: 1856.3345 - sse: 2212.7163 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0678 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 904/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.0868e-15 - r2_keras: -97.1195 - rmse: 0.8620 - sae: 2538.6240 - sse: 3043.5444\n","Epoch 904: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.5352e-16 - r2_keras: -80.0728 - rmse: 0.8541 - sae: 1856.3354 - sse: 2212.7190 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0675 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 905/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.4834e-16 - r2_keras: -97.1195 - rmse: 0.8620 - sae: 2538.6230 - sse: 3043.5430\n","Epoch 905: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3919e-16 - r2_keras: -80.0727 - rmse: 0.8541 - sae: 1856.3348 - sse: 2212.7178 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 906/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.5254e-16 - r2_keras: -97.1196 - rmse: 0.8620 - sae: 2538.6243 - sse: 3043.5464\n","Epoch 906: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5877e-16 - r2_keras: -80.0728 - rmse: 0.8541 - sae: 1856.3357 - sse: 2212.7205 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 907/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 9.3171e-17 - r2_keras: -97.1196 - rmse: 0.8620 - sae: 2538.6250 - sse: 3043.5471\n","Epoch 907: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1393e-16 - r2_keras: -80.0728 - rmse: 0.8541 - sae: 1856.3361 - sse: 2212.7207 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0676 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 908/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.2535e-16 - r2_keras: -97.1197 - rmse: 0.8620 - sae: 2538.6250 - sse: 3043.5496\n","Epoch 908: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.8528e-16 - r2_keras: -80.0729 - rmse: 0.8541 - sae: 1856.3363 - sse: 2212.7227 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -7.8542e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 909/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.8446e-16 - r2_keras: -97.1197 - rmse: 0.8620 - sae: 2538.6255 - sse: 3043.5493\n","Epoch 909: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.4817e-16 - r2_keras: -80.0729 - rmse: 0.8541 - sae: 1856.3365 - sse: 2212.7224 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0677 - val_sse: 483.3106 - learning_rate: 1.0000e-05\n","Epoch 910/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.5959e-16 - r2_keras: -97.1198 - rmse: 0.8620 - sae: 2538.6265 - sse: 3043.5532\n","Epoch 910: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8553e-16 - r2_keras: -80.0730 - rmse: 0.8541 - sae: 1856.3373 - sse: 2212.7253 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0674 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 911/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.7509e-16 - r2_keras: -97.1197 - rmse: 0.8620 - sae: 2538.6260 - sse: 3043.5515\n","Epoch 911: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.4359e-16 - r2_keras: -80.0729 - rmse: 0.8541 - sae: 1856.3369 - sse: 2212.7239 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0676 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 912/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.8976e-16 - r2_keras: -97.1198 - rmse: 0.8620 - sae: 2538.6270 - sse: 3043.5547\n","Epoch 912: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.0039e-16 - r2_keras: -80.0730 - rmse: 0.8541 - sae: 1856.3376 - sse: 2212.7263 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 7.8542e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0676 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 913/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.9974e-16 - r2_keras: -97.1198 - rmse: 0.8620 - sae: 2538.6267 - sse: 3043.5542\n","Epoch 913: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.9002e-16 - r2_keras: -80.0730 - rmse: 0.8541 - sae: 1856.3375 - sse: 2212.7258 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0675 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 914/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.3997e-16 - r2_keras: -97.1199 - rmse: 0.8620 - sae: 2538.6274 - sse: 3043.5579\n","Epoch 914: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 8.3219e-17 - r2_keras: -80.0731 - rmse: 0.8541 - sae: 1856.3380 - sse: 2212.7288 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.8051e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0674 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 915/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.2645e-16 - r2_keras: -97.1199 - rmse: 0.8620 - sae: 2538.6277 - sse: 3043.5579\n","Epoch 915: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.5121e-16 - r2_keras: -80.0731 - rmse: 0.8541 - sae: 1856.3381 - sse: 2212.7285 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.6929e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0675 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 916/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.3879e-16 - r2_keras: -97.1200 - rmse: 0.8620 - sae: 2538.6284 - sse: 3043.5605\n","Epoch 916: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.8435e-16 - r2_keras: -80.0732 - rmse: 0.8541 - sae: 1856.3387 - sse: 2212.7307 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.3759e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0675 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 917/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.4146e-16 - r2_keras: -97.1200 - rmse: 0.8620 - sae: 2538.6284 - sse: 3043.5603\n","Epoch 917: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.1997e-16 - r2_keras: -80.0732 - rmse: 0.8541 - sae: 1856.3387 - sse: 2212.7302 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0675 - val_sse: 483.3105 - learning_rate: 1.0000e-05\n","Epoch 918/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.4146e-16 - r2_keras: -97.1201 - rmse: 0.8620 - sae: 2538.6299 - sse: 3043.5640\n","Epoch 918: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.3415e-16 - r2_keras: -80.0733 - rmse: 0.8541 - sae: 1856.3398 - sse: 2212.7332 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0673 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 919/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.2649e-16 - r2_keras: -97.1201 - rmse: 0.8620 - sae: 2538.6292 - sse: 3043.5627\n","Epoch 919: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1741e-16 - r2_keras: -80.0732 - rmse: 0.8541 - sae: 1856.3392 - sse: 2212.7319 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0675 - val_sse: 483.3106 - learning_rate: 1.0000e-05\n","Epoch 920/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.5232e-16 - r2_keras: -97.1202 - rmse: 0.8620 - sae: 2538.6301 - sse: 3043.5659\n","Epoch 920: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5432e-16 - r2_keras: -80.0733 - rmse: 0.8541 - sae: 1856.3401 - sse: 2212.7346 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0673 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 921/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.3866e-16 - r2_keras: -97.1202 - rmse: 0.8620 - sae: 2538.6299 - sse: 3043.5662\n","Epoch 921: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.8910e-16 - r2_keras: -80.0733 - rmse: 0.8541 - sae: 1856.3398 - sse: 2212.7344 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0674 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 922/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.1103e-17 - r2_keras: -97.1203 - rmse: 0.8620 - sae: 2538.6309 - sse: 3043.5688\n","Epoch 922: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.5483e-17 - r2_keras: -80.0734 - rmse: 0.8541 - sae: 1856.3406 - sse: 2212.7366 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.4586e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0674 - val_sse: 483.3104 - learning_rate: 1.0000e-05\n","Epoch 923/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.8923e-17 - r2_keras: -97.1203 - rmse: 0.8620 - sae: 2538.6313 - sse: 3043.5688\n","Epoch 923: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.5545e-18 - r2_keras: -80.0734 - rmse: 0.8541 - sae: 1856.3409 - sse: 2212.7363 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0672 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 924/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.7881e-16 - r2_keras: -97.1203 - rmse: 0.8620 - sae: 2538.6309 - sse: 3043.5684\n","Epoch 924: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.1320e-16 - r2_keras: -80.0733 - rmse: 0.8541 - sae: 1856.3405 - sse: 2212.7358 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.2342e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0673 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 925/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.3170e-16 - r2_keras: -97.1204 - rmse: 0.8620 - sae: 2538.6318 - sse: 3043.5713\n","Epoch 925: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1033e-16 - r2_keras: -80.0734 - rmse: 0.8541 - sae: 1856.3412 - sse: 2212.7383 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0671 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 926/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.0420e-16 - r2_keras: -97.1203 - rmse: 0.8620 - sae: 2538.6313 - sse: 3043.5698\n","Epoch 926: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.1388e-17 - r2_keras: -80.0734 - rmse: 0.8541 - sae: 1856.3409 - sse: 2212.7371 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.9173e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0671 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 927/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.3078e-16 - r2_keras: -97.1205 - rmse: 0.8620 - sae: 2538.6326 - sse: 3043.5742\n","Epoch 927: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.3274e-16 - r2_keras: -80.0735 - rmse: 0.8541 - sae: 1856.3418 - sse: 2212.7402 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0671 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 928/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.9417e-16 - r2_keras: -97.1205 - rmse: 0.8620 - sae: 2538.6328 - sse: 3043.5742\n","Epoch 928: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.0905e-16 - r2_keras: -80.0735 - rmse: 0.8541 - sae: 1856.3419 - sse: 2212.7400 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0670 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 929/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.8231e-18 - r2_keras: -97.1205 - rmse: 0.8620 - sae: 2538.6328 - sse: 3043.5762\n","Epoch 929: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.7943e-18 - r2_keras: -80.0736 - rmse: 0.8541 - sae: 1856.3420 - sse: 2212.7417 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0670 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 930/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.9829e-16 - r2_keras: -97.1205 - rmse: 0.8620 - sae: 2538.6331 - sse: 3043.5759\n","Epoch 930: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.4755e-16 - r2_keras: -80.0735 - rmse: 0.8541 - sae: 1856.3422 - sse: 2212.7412 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0670 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 931/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.8651e-17 - r2_keras: -97.1206 - rmse: 0.8620 - sae: 2538.6338 - sse: 3043.5786\n","Epoch 931: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3848e-17 - r2_keras: -80.0736 - rmse: 0.8541 - sae: 1856.3428 - sse: 2212.7434 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.0197e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0670 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 932/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.7031e-16 - r2_keras: -97.1206 - rmse: 0.8620 - sae: 2538.6343 - sse: 3043.5791\n","Epoch 932: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.6102e-16 - r2_keras: -80.0736 - rmse: 0.8541 - sae: 1856.3430 - sse: 2212.7437 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0671 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 933/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.1681e-16 - r2_keras: -97.1207 - rmse: 0.8620 - sae: 2538.6350 - sse: 3043.5828\n","Epoch 933: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.3373e-16 - r2_keras: -80.0737 - rmse: 0.8541 - sae: 1856.3436 - sse: 2212.7463 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.2539e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 934/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.8423e-16 - r2_keras: -97.1207 - rmse: 0.8620 - sae: 2538.6348 - sse: 3043.5818\n","Epoch 934: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.6813e-16 - r2_keras: -80.0737 - rmse: 0.8541 - sae: 1856.3434 - sse: 2212.7456 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0671 - val_sse: 483.3103 - learning_rate: 1.0000e-05\n","Epoch 935/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.7228e-16 - r2_keras: -97.1208 - rmse: 0.8620 - sae: 2538.6360 - sse: 3043.5852\n","Epoch 935: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.4481e-16 - r2_keras: -80.0738 - rmse: 0.8541 - sae: 1856.3444 - sse: 2212.7483 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 936/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.5875e-16 - r2_keras: -97.1208 - rmse: 0.8620 - sae: 2538.6353 - sse: 3043.5835\n","Epoch 936: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5093e-16 - r2_keras: -80.0737 - rmse: 0.8541 - sae: 1856.3438 - sse: 2212.7468 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.8149e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0670 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 937/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.1295e-17 - r2_keras: -97.1209 - rmse: 0.8620 - sae: 2538.6365 - sse: 3043.5872\n","Epoch 937: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.9229e-17 - r2_keras: -80.0739 - rmse: 0.8541 - sae: 1856.3447 - sse: 2212.7495 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 938/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.0650e-15 - r2_keras: -97.1209 - rmse: 0.8620 - sae: 2538.6362 - sse: 3043.5869\n","Epoch 938: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.3708e-16 - r2_keras: -80.0738 - rmse: 0.8541 - sae: 1856.3445 - sse: 2212.7493 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 7.8542e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0669 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 939/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.1751e-16 - r2_keras: -97.1210 - rmse: 0.8620 - sae: 2538.6377 - sse: 3043.5908\n","Epoch 939: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.8289e-16 - r2_keras: -80.0739 - rmse: 0.8541 - sae: 1856.3456 - sse: 2212.7522 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 940/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 7.4228e-16 - r2_keras: -97.1210 - rmse: 0.8620 - sae: 2538.6375 - sse: 3043.5908\n","Epoch 940: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.3708e-16 - r2_keras: -80.0739 - rmse: 0.8541 - sae: 1856.3453 - sse: 2212.7520 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 941/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.5416e-16 - r2_keras: -97.1211 - rmse: 0.8620 - sae: 2538.6377 - sse: 3043.5928\n","Epoch 941: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.4499e-16 - r2_keras: -80.0740 - rmse: 0.8541 - sae: 1856.3456 - sse: 2212.7537 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 942/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.8021e-16 - r2_keras: -97.1211 - rmse: 0.8620 - sae: 2538.6382 - sse: 3043.5928\n","Epoch 942: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.7867e-16 - r2_keras: -80.0740 - rmse: 0.8541 - sae: 1856.3459 - sse: 2212.7534 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 943/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.4369e-16 - r2_keras: -97.1211 - rmse: 0.8620 - sae: 2538.6387 - sse: 3043.5952\n","Epoch 943: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.6054e-16 - r2_keras: -80.0741 - rmse: 0.8541 - sae: 1856.3463 - sse: 2212.7554 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.2441e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 944/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.0114e-16 - r2_keras: -97.1212 - rmse: 0.8620 - sae: 2538.6387 - sse: 3043.5955\n","Epoch 944: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.1636e-16 - r2_keras: -80.0741 - rmse: 0.8541 - sae: 1856.3463 - sse: 2212.7554 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 945/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.0399e-15 - r2_keras: -97.1213 - rmse: 0.8620 - sae: 2538.6401 - sse: 3043.5991\n","Epoch 945: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 6.4527e-16 - r2_keras: -80.0742 - rmse: 0.8541 - sae: 1856.3474 - sse: 2212.7581 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.3464e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 946/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.8708e-16 - r2_keras: -97.1212 - rmse: 0.8620 - sae: 2538.6396 - sse: 3043.5981\n","Epoch 946: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9376e-16 - r2_keras: -80.0741 - rmse: 0.8541 - sae: 1856.3470 - sse: 2212.7573 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0668 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 947/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.8664e-16 - r2_keras: -97.1213 - rmse: 0.8620 - sae: 2538.6404 - sse: 3043.6008\n","Epoch 947: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3115e-16 - r2_keras: -80.0742 - rmse: 0.8541 - sae: 1856.3477 - sse: 2212.7595 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.0197e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 948/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.0350e-16 - r2_keras: -97.1213 - rmse: 0.8620 - sae: 2538.6401 - sse: 3043.6003\n","Epoch 948: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.3551e-17 - r2_keras: -80.0742 - rmse: 0.8541 - sae: 1856.3474 - sse: 2212.7590 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 949/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.3813e-16 - r2_keras: -97.1214 - rmse: 0.8620 - sae: 2538.6411 - sse: 3043.6028\n","Epoch 949: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.9522e-16 - r2_keras: -80.0743 - rmse: 0.8541 - sae: 1856.3483 - sse: 2212.7610 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 7.8542e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 950/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.9982e-16 - r2_keras: -97.1214 - rmse: 0.8620 - sae: 2538.6411 - sse: 3043.6033\n","Epoch 950: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.7711e-17 - r2_keras: -80.0743 - rmse: 0.8541 - sae: 1856.3481 - sse: 2212.7610 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 5.6101e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 951/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.1637e-16 - r2_keras: -97.1215 - rmse: 0.8620 - sae: 2538.6418 - sse: 3043.6052\n","Epoch 951: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1738e-16 - r2_keras: -80.0743 - rmse: 0.8541 - sae: 1856.3488 - sse: 2212.7627 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.8051e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3096 - learning_rate: 1.0000e-05\n","Epoch 952/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.5576e-16 - r2_keras: -97.1215 - rmse: 0.8620 - sae: 2538.6416 - sse: 3043.6060\n","Epoch 952: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.0864e-16 - r2_keras: -80.0743 - rmse: 0.8541 - sae: 1856.3485 - sse: 2212.7629 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0667 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 953/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.0503e-16 - r2_keras: -97.1216 - rmse: 0.8620 - sae: 2538.6431 - sse: 3043.6094\n","Epoch 953: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 5.8006e-17 - r2_keras: -80.0744 - rmse: 0.8541 - sae: 1856.3496 - sse: 2212.7656 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.7027e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0666 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 954/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.4531e-16 - r2_keras: -97.1216 - rmse: 0.8620 - sae: 2538.6428 - sse: 3043.6091\n","Epoch 954: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.5753e-16 - r2_keras: -80.0744 - rmse: 0.8541 - sae: 1856.3494 - sse: 2212.7651 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 955/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.5086e-17 - r2_keras: -97.1217 - rmse: 0.8620 - sae: 2538.6436 - sse: 3043.6113\n","Epoch 955: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5191e-17 - r2_keras: -80.0745 - rmse: 0.8541 - sae: 1856.3500 - sse: 2212.7671 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.1319e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 956/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.0923e-16 - r2_keras: -97.1217 - rmse: 0.8620 - sae: 2538.6431 - sse: 3043.6108\n","Epoch 956: val_loss improved from 0.19323 to 0.19323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.9656e-16 - r2_keras: -80.0745 - rmse: 0.8541 - sae: 1856.3496 - sse: 2212.7666 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 957/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.2389e-16 - r2_keras: -97.1218 - rmse: 0.8620 - sae: 2538.6445 - sse: 3043.6147\n","Epoch 957: val_loss did not improve from 0.19323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -5.3441e-16 - r2_keras: -80.0746 - rmse: 0.8541 - sae: 1856.3507 - sse: 2212.7695 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 958/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.2499e-16 - r2_keras: -97.1218 - rmse: 0.8620 - sae: 2538.6445 - sse: 3043.6143\n","Epoch 958: val_loss improved from 0.19323 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.1065e-16 - r2_keras: -80.0745 - rmse: 0.8541 - sae: 1856.3507 - sse: 2212.7690 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.8051e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0664 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 959/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.0476e-16 - r2_keras: -97.1218 - rmse: 0.8620 - sae: 2538.6445 - sse: 3043.6157\n","Epoch 959: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.0025e-16 - r2_keras: -80.0746 - rmse: 0.8541 - sae: 1856.3507 - sse: 2212.7703 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.3464e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 960/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.9535e-17 - r2_keras: -97.1218 - rmse: 0.8620 - sae: 2538.6450 - sse: 3043.6167\n","Epoch 960: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.2615e-16 - r2_keras: -80.0746 - rmse: 0.8541 - sae: 1856.3511 - sse: 2212.7708 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0663 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 961/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.8094e-16 - r2_keras: -97.1219 - rmse: 0.8620 - sae: 2538.6455 - sse: 3043.6194\n","Epoch 961: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.2902e-16 - r2_keras: -80.0747 - rmse: 0.8541 - sae: 1856.3514 - sse: 2212.7729 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.2539e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0664 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 962/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -7.2327e-16 - r2_keras: -97.1219 - rmse: 0.8620 - sae: 2538.6460 - sse: 3043.6196\n","Epoch 962: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -4.4860e-16 - r2_keras: -80.0747 - rmse: 0.8541 - sae: 1856.3518 - sse: 2212.7729 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.2342e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0665 - val_sse: 483.3102 - learning_rate: 1.0000e-05\n","Epoch 963/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.6106e-16 - r2_keras: -97.1220 - rmse: 0.8620 - sae: 2538.6465 - sse: 3043.6221\n","Epoch 963: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 4.2631e-16 - r2_keras: -80.0748 - rmse: 0.8541 - sae: 1856.3522 - sse: 2212.7747 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.1319e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0663 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 964/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.5468e-16 - r2_keras: -97.1220 - rmse: 0.8620 - sae: 2538.6462 - sse: 3043.6213\n","Epoch 964: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.2640e-16 - r2_keras: -80.0747 - rmse: 0.8541 - sae: 1856.3519 - sse: 2212.7739 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0664 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 965/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.5388e-16 - r2_keras: -97.1221 - rmse: 0.8620 - sae: 2538.6475 - sse: 3043.6250\n","Epoch 965: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.6037e-16 - r2_keras: -80.0748 - rmse: 0.8541 - sae: 1856.3529 - sse: 2212.7769 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.6929e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0662 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 966/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.0187e-16 - r2_keras: -97.1221 - rmse: 0.8620 - sae: 2538.6470 - sse: 3043.6238\n","Epoch 966: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.7438e-16 - r2_keras: -80.0748 - rmse: 0.8541 - sae: 1856.3525 - sse: 2212.7759 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.3563e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0663 - val_sse: 483.3101 - learning_rate: 1.0000e-05\n","Epoch 967/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.4929e-16 - r2_keras: -97.1222 - rmse: 0.8620 - sae: 2538.6482 - sse: 3043.6274\n","Epoch 967: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.3524e-16 - r2_keras: -80.0749 - rmse: 0.8541 - sae: 1856.3534 - sse: 2212.7786 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0663 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 968/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.6023e-16 - r2_keras: -97.1222 - rmse: 0.8620 - sae: 2538.6479 - sse: 3043.6270\n","Epoch 968: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.0536e-16 - r2_keras: -80.0749 - rmse: 0.8541 - sae: 1856.3533 - sse: 2212.7781 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0662 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 969/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.5585e-17 - r2_keras: -97.1223 - rmse: 0.8620 - sae: 2538.6489 - sse: 3043.6296\n","Epoch 969: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.0897e-16 - r2_keras: -80.0750 - rmse: 0.8541 - sae: 1856.3540 - sse: 2212.7803 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0662 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 970/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.2504e-16 - r2_keras: -97.1222 - rmse: 0.8620 - sae: 2538.6489 - sse: 3043.6294\n","Epoch 970: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.0447e-16 - r2_keras: -80.0749 - rmse: 0.8541 - sae: 1856.3540 - sse: 2212.7798 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0662 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 971/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.6868e-16 - r2_keras: -97.1224 - rmse: 0.8620 - sae: 2538.6499 - sse: 3043.6331\n","Epoch 971: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.3619e-16 - r2_keras: -80.0750 - rmse: 0.8541 - sae: 1856.3547 - sse: 2212.7827 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0661 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 972/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -2.4518e-16 - r2_keras: -97.1223 - rmse: 0.8620 - sae: 2538.6494 - sse: 3043.6318\n","Epoch 972: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -1.5577e-16 - r2_keras: -80.0750 - rmse: 0.8541 - sae: 1856.3544 - sse: 2212.7817 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0662 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 973/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.1799e-16 - r2_keras: -97.1224 - rmse: 0.8620 - sae: 2538.6501 - sse: 3043.6348\n","Epoch 973: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.3719e-16 - r2_keras: -80.0751 - rmse: 0.8541 - sae: 1856.3550 - sse: 2212.7839 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3095 - learning_rate: 1.0000e-05\n","Epoch 974/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.1085e-16 - r2_keras: -97.1224 - rmse: 0.8620 - sae: 2538.6499 - sse: 3043.6348\n","Epoch 974: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.1082e-16 - r2_keras: -80.0751 - rmse: 0.8541 - sae: 1856.3547 - sse: 2212.7837 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0662 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 975/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.6764e-16 - r2_keras: -97.1225 - rmse: 0.8620 - sae: 2538.6514 - sse: 3043.6382\n","Epoch 975: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 9.7366e-17 - r2_keras: -80.0752 - rmse: 0.8541 - sae: 1856.3558 - sse: 2212.7864 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 6.7322e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 976/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.2136e-16 - r2_keras: -97.1225 - rmse: 0.8620 - sae: 2538.6514 - sse: 3043.6384\n","Epoch 976: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -3.0826e-19 - r2_keras: -80.0752 - rmse: 0.8541 - sae: 1856.3558 - sse: 2212.7864 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 977/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.1873e-17 - r2_keras: -97.1226 - rmse: 0.8620 - sae: 2538.6516 - sse: 3043.6406\n","Epoch 977: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 7.5941e-17 - r2_keras: -80.0752 - rmse: 0.8541 - sae: 1856.3561 - sse: 2212.7881 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 978/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 8.6118e-17 - r2_keras: -97.1226 - rmse: 0.8620 - sae: 2538.6516 - sse: 3043.6399\n","Epoch 978: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 3.7262e-17 - r2_keras: -80.0752 - rmse: 0.8541 - sae: 1856.3561 - sse: 2212.7876 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 979/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.0812e-16 - r2_keras: -97.1227 - rmse: 0.8620 - sae: 2538.6526 - sse: 3043.6431\n","Epoch 979: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.5815e-16 - r2_keras: -80.0753 - rmse: 0.8541 - sae: 1856.3568 - sse: 2212.7900 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.5708e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 980/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.8082e-17 - r2_keras: -97.1227 - rmse: 0.8620 - sae: 2538.6523 - sse: 3043.6421\n","Epoch 980: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -6.9625e-17 - r2_keras: -80.0753 - rmse: 0.8541 - sae: 1856.3566 - sse: 2212.7891 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.4685e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 981/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.0227e-17 - r2_keras: -97.1228 - rmse: 0.8620 - sae: 2538.6533 - sse: 3043.6455\n","Epoch 981: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 2.7877e-17 - r2_keras: -80.0754 - rmse: 0.8541 - sae: 1856.3573 - sse: 2212.7917 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.9271e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0659 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 982/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.2617e-16 - r2_keras: -97.1228 - rmse: 0.8620 - sae: 2538.6533 - sse: 3043.6455\n","Epoch 982: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: 1.5654e-16 - r2_keras: -80.0754 - rmse: 0.8541 - sae: 1856.3573 - sse: 2212.7915 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.3563e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0659 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 983/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -4.7656e-16 - r2_keras: -97.1228 - rmse: 0.8620 - sae: 2538.6543 - sse: 3043.6479\n","Epoch 983: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -2.7932e-16 - r2_keras: -80.0754 - rmse: 0.8541 - sae: 1856.3580 - sse: 2212.7935 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 2.9173e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0658 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 984/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.0233e-15 - r2_keras: -97.1228 - rmse: 0.8620 - sae: 2538.6538 - sse: 3043.6472\n","Epoch 984: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2447 - mse: 0.1567 - pearson_correlation: -7.2825e-16 - r2_keras: -80.0754 - rmse: 0.8541 - sae: 1856.3577 - sse: 2212.7927 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.2441e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0660 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 985/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 4.6583e-16 - r2_keras: -97.1230 - rmse: 0.8620 - sae: 2538.6553 - sse: 3043.6514\n","Epoch 985: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 3.5085e-16 - r2_keras: -80.0755 - rmse: 0.8541 - sae: 1856.3588 - sse: 2212.7959 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 4.4881e-17 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0658 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 986/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -5.5471e-17 - r2_keras: -97.1229 - rmse: 0.8620 - sae: 2538.6543 - sse: 3043.6504\n","Epoch 986: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: -5.3164e-18 - r2_keras: -80.0755 - rmse: 0.8541 - sae: 1856.3580 - sse: 2212.7949 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 8.9762e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0659 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 987/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.8124e-16 - r2_keras: -97.1230 - rmse: 0.8620 - sae: 2538.6558 - sse: 3043.6538\n","Epoch 987: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 2.7143e-16 - r2_keras: -80.0756 - rmse: 0.8541 - sae: 1856.3591 - sse: 2212.7976 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.4586e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0657 - val_sse: 483.3095 - learning_rate: 1.0000e-05\n","Epoch 988/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 6.8311e-16 - r2_keras: -97.1230 - rmse: 0.8620 - sae: 2538.6555 - sse: 3043.6531\n","Epoch 988: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 4.0264e-16 - r2_keras: -80.0756 - rmse: 0.8541 - sae: 1856.3589 - sse: 2212.7969 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0658 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 989/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.7705e-16 - r2_keras: -97.1231 - rmse: 0.8620 - sae: 2538.6565 - sse: 3043.6560\n","Epoch 989: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 2.1732e-16 - r2_keras: -80.0757 - rmse: 0.8541 - sae: 1856.3597 - sse: 2212.7993 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 1.7952e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0658 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 990/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 5.8535e-17 - r2_keras: -97.1231 - rmse: 0.8620 - sae: 2538.6565 - sse: 3043.6558\n","Epoch 990: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 2.5619e-18 - r2_keras: -80.0756 - rmse: 0.8541 - sae: 1856.3596 - sse: 2212.7988 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.2539e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0657 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 991/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.5308e-16 - r2_keras: -97.1232 - rmse: 0.8620 - sae: 2538.6572 - sse: 3043.6587\n","Epoch 991: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: -4.0276e-16 - r2_keras: -80.0757 - rmse: 0.8541 - sae: 1856.3602 - sse: 2212.8013 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0657 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 992/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.3178e-16 - r2_keras: -97.1232 - rmse: 0.8620 - sae: 2538.6567 - sse: 3043.6582\n","Epoch 992: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 1.2240e-16 - r2_keras: -80.0757 - rmse: 0.8541 - sae: 1856.3599 - sse: 2212.8005 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.1220e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0658 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 993/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.6442e-16 - r2_keras: -97.1233 - rmse: 0.8620 - sae: 2538.6582 - sse: 3043.6624\n","Epoch 993: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: -4.8516e-16 - r2_keras: -80.0758 - rmse: 0.8541 - sae: 1856.3610 - sse: 2212.8037 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.0295e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0656 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 994/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 3.4018e-16 - r2_keras: -97.1233 - rmse: 0.8620 - sae: 2538.6577 - sse: 3043.6606\n","Epoch 994: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 1.3947e-16 - r2_keras: -80.0758 - rmse: 0.8541 - sae: 1856.3605 - sse: 2212.8025 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -2.0197e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0657 - val_sse: 483.3098 - learning_rate: 1.0000e-05\n","Epoch 995/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -1.2657e-16 - r2_keras: -97.1234 - rmse: 0.8620 - sae: 2538.6587 - sse: 3043.6641\n","Epoch 995: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: -1.0165e-16 - r2_keras: -80.0759 - rmse: 0.8541 - sae: 1856.3613 - sse: 2212.8049 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0656 - val_sse: 483.3096 - learning_rate: 1.0000e-05\n","Epoch 996/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 2.7245e-16 - r2_keras: -97.1234 - rmse: 0.8620 - sae: 2538.6589 - sse: 3043.6641\n","Epoch 996: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 2.0178e-16 - r2_keras: -80.0759 - rmse: 0.8541 - sae: 1856.3615 - sse: 2212.8049 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.6830e-16 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0656 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","Epoch 997/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -3.9840e-18 - r2_keras: -97.1234 - rmse: 0.8620 - sae: 2538.6597 - sse: 3043.6665\n","Epoch 997: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: -5.5429e-17 - r2_keras: -80.0759 - rmse: 0.8541 - sae: 1856.3621 - sse: 2212.8069 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -1.0098e-16 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0655 - val_sse: 483.3095 - learning_rate: 1.0000e-05\n","Epoch 998/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -8.1734e-16 - r2_keras: -97.1235 - rmse: 0.8620 - sae: 2538.6597 - sse: 3043.6667\n","Epoch 998: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: -6.2645e-16 - r2_keras: -80.0759 - rmse: 0.8541 - sae: 1856.3619 - sse: 2212.8069 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: 3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0657 - val_sse: 483.3100 - learning_rate: 1.0000e-05\n","Epoch 999/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: 1.2442e-16 - r2_keras: -97.1235 - rmse: 0.8620 - sae: 2538.6606 - sse: 3043.6697\n","Epoch 999: val_loss improved from 0.19322 to 0.19322, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 1.2613e-16 - r2_keras: -80.0760 - rmse: 0.8541 - sae: 1856.3628 - sse: 2212.8091 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -4.4881e-17 - val_r2_keras: -33.4529 - val_rmse: 0.9558 - val_sae: 363.0656 - val_sse: 483.3097 - learning_rate: 1.0000e-05\n","Epoch 1000/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.1709 - mae: 0.2546 - mse: 0.1696 - pearson_correlation: -6.1293e-19 - r2_keras: -97.1235 - rmse: 0.8620 - sae: 2538.6604 - sse: 3043.6697\n","Epoch 1000: val_loss did not improve from 0.19322\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0714 - loss: 0.1653 - mae: 0.2446 - mse: 0.1567 - pearson_correlation: 3.2215e-17 - r2_keras: -80.0760 - rmse: 0.8541 - sae: 1856.3625 - sse: 2212.8088 - val_huber_loss: 0.1030 - val_loss: 0.1932 - val_mae: 0.2824 - val_mse: 0.2279 - val_pearson_correlation: -3.3661e-17 - val_r2_keras: -33.4530 - val_rmse: 0.9558 - val_sae: 363.0656 - val_sse: 483.3099 - learning_rate: 1.0000e-05\n","| \u001b[39m19       \u001b[39m | \u001b[39m-0.1932  \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m94.97    \u001b[39m | \u001b[39m77.48    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.5179 - loss: 0.6113 - mae: 0.9111 - mse: 1.3314 - pearson_correlation: 1.2799e-16 - r2_keras: -137.6773 - rmse: 1.0248 - sae: 3342.7634 - sse: 4301.5952\n","Epoch 1: val_loss improved from inf to 0.79762, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step - huber_loss: 1.5372 - loss: 1.2322 - mae: 1.5476 - mse: 6.1422 - pearson_correlation: 2.1116e-16 - r2_keras: -732.1557 - rmse: 2.4707 - sae: 3368.9651 - sse: 10383.2119 - val_huber_loss: 0.6998 - val_loss: 0.7976 - val_mae: 1.1661 - val_mse: 1.8345 - val_pearson_correlation: 2.0248e-16 - val_r2_keras: -54.4967 - val_rmse: 1.2131 - val_sae: 528.5937 - val_sse: 778.5137 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 1.4343 - loss: 1.5321 - mae: 1.9106 - mse: 5.7095 - pearson_correlation: 1.9454e-16 - r2_keras: -694.7980 - rmse: 2.2955 - sae: 7329.4453 - sse: 21582.7852\n","Epoch 2: val_loss improved from 0.79762 to 0.54577, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 1.2330 - loss: 1.4097 - mae: 1.7712 - mse: 5.0698 - pearson_correlation: 7.5924e-17 - r2_keras: -544.7601 - rmse: 2.1694 - sae: 5266.8926 - sse: 15349.1514 - val_huber_loss: 0.4476 - val_loss: 0.5458 - val_mae: 0.8809 - val_mse: 1.1067 - val_pearson_correlation: 7.6135e-17 - val_r2_keras: -32.2565 - val_rmse: 0.9391 - val_sae: 390.3919 - val_sse: 466.5265 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.7339 - loss: 0.8320 - mae: 1.1608 - mse: 2.0691 - pearson_correlation: 5.5135e-17 - r2_keras: -239.3305 - rmse: 1.3491 - sae: 4168.6729 - sse: 7454.7515\n","Epoch 3: val_loss improved from 0.54577 to 0.35421, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.6514 - loss: 0.7818 - mae: 1.0974 - mse: 1.9023 - pearson_correlation: -5.8066e-18 - r2_keras: -206.7270 - rmse: 1.3861 - sae: 3066.7344 - sse: 5527.0889 - val_huber_loss: 0.2561 - val_loss: 0.3542 - val_mae: 0.5788 - val_mse: 0.6289 - val_pearson_correlation: 2.4931e-16 - val_r2_keras: -23.3106 - val_rmse: 0.8029 - val_sae: 307.8752 - val_sse: 341.0311 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.2359 - loss: 0.3340 - mae: 0.5137 - mse: 0.5438 - pearson_correlation: -7.0278e-17 - r2_keras: -85.9389 - rmse: 0.8114 - sae: 2307.8691 - sse: 2696.7363\n","Epoch 4: val_loss did not improve from 0.35421\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2641 - loss: 0.3512 - mae: 0.5396 - mse: 0.5697 - pearson_correlation: 1.9781e-16 - r2_keras: -82.9262 - rmse: 0.9008 - sae: 1758.3947 - sse: 2102.4175 - val_huber_loss: 0.3717 - val_loss: 0.4697 - val_mae: 0.7696 - val_mse: 0.9216 - val_pearson_correlation: 6.9322e-17 - val_r2_keras: -32.2217 - val_rmse: 0.9386 - val_sae: 373.0343 - val_sse: 466.0371 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4473 - loss: 0.5452 - mae: 0.7848 - mse: 1.1163 - pearson_correlation: 1.7769e-16 - r2_keras: -192.0117 - rmse: 1.2090 - sae: 3677.8843 - sse: 5986.9814\n","Epoch 5: val_loss improved from 0.35421 to 0.35189, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.3540 - loss: 0.4884 - mae: 0.7188 - mse: 0.9595 - pearson_correlation: 8.5623e-17 - r2_keras: -144.2249 - rmse: 1.0933 - sae: 2625.1917 - sse: 4185.4580 - val_huber_loss: 0.2541 - val_loss: 0.3519 - val_mae: 0.6004 - val_mse: 0.6145 - val_pearson_correlation: 1.8812e-16 - val_r2_keras: -26.5379 - val_rmse: 0.8545 - val_sae: 330.9470 - val_sse: 386.3045 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1969 - loss: 0.2947 - mae: 0.4920 - mse: 0.4209 - pearson_correlation: 1.1512e-16 - r2_keras: -104.1572 - rmse: 0.8924 - sae: 2651.1406 - sse: 3261.8438\n","Epoch 6: val_loss did not improve from 0.35189\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1882 - loss: 0.2893 - mae: 0.4837 - mse: 0.4075 - pearson_correlation: -6.9528e-17 - r2_keras: -86.2807 - rmse: 0.8876 - sae: 1944.5919 - sse: 2376.0366 - val_huber_loss: 0.2594 - val_loss: 0.3570 - val_mae: 0.6189 - val_mse: 0.6227 - val_pearson_correlation: -1.7010e-16 - val_r2_keras: -27.6248 - val_rmse: 0.8713 - val_sae: 347.2886 - val_sse: 401.5522 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2096 - loss: 0.3071 - mae: 0.5276 - mse: 0.4400 - pearson_correlation: 6.5273e-16 - r2_keras: -100.8350 - rmse: 0.8782 - sae: 2707.6826 - sse: 3158.7942\n","Epoch 7: val_loss improved from 0.35189 to 0.28438, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.1995 - loss: 0.3010 - mae: 0.5085 - mse: 0.4303 - pearson_correlation: 4.4956e-16 - r2_keras: -83.4968 - rmse: 0.8732 - sae: 1977.2327 - sse: 2300.6616 - val_huber_loss: 0.1870 - val_loss: 0.2844 - val_mae: 0.4687 - val_mse: 0.4298 - val_pearson_correlation: -3.0895e-17 - val_r2_keras: -28.0424 - val_rmse: 0.8776 - val_sae: 344.0304 - val_sse: 407.4101 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2011 - loss: 0.2985 - mae: 0.5128 - mse: 0.4405 - pearson_correlation: 8.7077e-17 - r2_keras: -110.1937 - rmse: 0.9176 - sae: 2949.5515 - sse: 3449.0908\n","Epoch 8: val_loss improved from 0.28438 to 0.24930, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.1924 - loss: 0.2932 - mae: 0.4974 - mse: 0.4307 - pearson_correlation: 4.5394e-17 - r2_keras: -87.7890 - rmse: 0.8822 - sae: 2125.6082 - sse: 2471.3547 - val_huber_loss: 0.1521 - val_loss: 0.2493 - val_mae: 0.4369 - val_mse: 0.3240 - val_pearson_correlation: 1.7487e-16 - val_r2_keras: -35.6892 - val_rmse: 0.9864 - val_sae: 407.8752 - val_sse: 514.6804 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.2178 - loss: 0.3150 - mae: 0.5730 - mse: 0.4713 - pearson_correlation: -4.2379e-17 - r2_keras: -138.7230 - rmse: 1.0286 - sae: 3400.2651 - sse: 4334.0322\n","Epoch 9: val_loss improved from 0.24930 to 0.24247, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.2259 - loss: 0.3199 - mae: 0.5690 - mse: 0.4826 - pearson_correlation: -5.1993e-17 - r2_keras: -108.5426 - rmse: 0.9717 - sae: 2438.4966 - sse: 3081.6567 - val_huber_loss: 0.1455 - val_loss: 0.2425 - val_mae: 0.4379 - val_mse: 0.2984 - val_pearson_correlation: 9.3802e-17 - val_r2_keras: -38.8820 - val_rmse: 1.0284 - val_sae: 427.0453 - val_sse: 559.4690 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1916 - loss: 0.2886 - mae: 0.5291 - mse: 0.4259 - pearson_correlation: -1.9521e-16 - r2_keras: -132.2982 - rmse: 1.0047 - sae: 3212.0815 - sse: 4134.7451\n","Epoch 10: val_loss improved from 0.24247 to 0.21032, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1754 - loss: 0.2787 - mae: 0.5067 - mse: 0.4024 - pearson_correlation: -1.1729e-16 - r2_keras: -103.0015 - rmse: 0.9446 - sae: 2307.4685 - sse: 2934.0427 - val_huber_loss: 0.1135 - val_loss: 0.2103 - val_mae: 0.3535 - val_mse: 0.2368 - val_pearson_correlation: -3.2382e-16 - val_r2_keras: -32.3674 - val_rmse: 0.9407 - val_sae: 373.3232 - val_sse: 468.0818 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1171 - loss: 0.2139 - mae: 0.3389 - mse: 0.2626 - pearson_correlation: -1.7052e-16 - r2_keras: -96.5617 - rmse: 0.8596 - sae: 2552.3105 - sse: 3026.2422\n","Epoch 11: val_loss improved from 0.21032 to 0.20757, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.1109 - loss: 0.2101 - mae: 0.3374 - mse: 0.2515 - pearson_correlation: -1.9735e-16 - r2_keras: -80.9437 - rmse: 0.8634 - sae: 1872.0258 - sse: 2215.7620 - val_huber_loss: 0.1110 - val_loss: 0.2076 - val_mae: 0.3672 - val_mse: 0.2408 - val_pearson_correlation: 4.9158e-17 - val_r2_keras: -27.5464 - val_rmse: 0.8701 - val_sae: 344.9844 - val_sse: 400.4516 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1163 - loss: 0.2129 - mae: 0.3391 - mse: 0.2503 - pearson_correlation: -2.2405e-16 - r2_keras: -83.1779 - rmse: 0.7984 - sae: 2384.3855 - sse: 2611.0947\n","Epoch 12: val_loss did not improve from 0.20757\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1174 - loss: 0.2136 - mae: 0.3495 - mse: 0.2490 - pearson_correlation: -2.3370e-16 - r2_keras: -75.1310 - rmse: 0.8482 - sae: 1778.3209 - sse: 1975.4761 - val_huber_loss: 0.1279 - val_loss: 0.2243 - val_mae: 0.3983 - val_mse: 0.2820 - val_pearson_correlation: -7.7639e-17 - val_r2_keras: -26.8835 - val_rmse: 0.8599 - val_sae: 337.9926 - val_sse: 391.1521 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1300 - loss: 0.2264 - mae: 0.3581 - mse: 0.2739 - pearson_correlation: 1.9193e-16 - r2_keras: -85.2795 - rmse: 0.8083 - sae: 2441.5493 - sse: 2676.2837\n","Epoch 13: val_loss did not improve from 0.20757\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1244 - loss: 0.2229 - mae: 0.3620 - mse: 0.2645 - pearson_correlation: 1.3261e-16 - r2_keras: -75.5369 - rmse: 0.8469 - sae: 1814.2881 - sse: 2007.2618 - val_huber_loss: 0.1403 - val_loss: 0.2364 - val_mae: 0.4171 - val_mse: 0.3105 - val_pearson_correlation: -6.8892e-16 - val_r2_keras: -28.5633 - val_rmse: 0.8854 - val_sae: 342.4680 - val_sse: 414.7173 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1184 - loss: 0.2146 - mae: 0.3580 - mse: 0.2490 - pearson_correlation: -6.5469e-17 - r2_keras: -89.7026 - rmse: 0.8288 - sae: 2486.4565 - sse: 2813.4824\n","Epoch 14: val_loss did not improve from 0.20757\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1111 - loss: 0.2101 - mae: 0.3562 - mse: 0.2378 - pearson_correlation: -9.6318e-17 - r2_keras: -75.7650 - rmse: 0.8376 - sae: 1830.9100 - sse: 2066.8147 - val_huber_loss: 0.1431 - val_loss: 0.2391 - val_mae: 0.4045 - val_mse: 0.3167 - val_pearson_correlation: -8.7540e-17 - val_r2_keras: -31.3030 - val_rmse: 0.9255 - val_sae: 351.5420 - val_sse: 453.1501 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1062 - loss: 0.2021 - mae: 0.3288 - mse: 0.2236 - pearson_correlation: -4.2259e-17 - r2_keras: -95.2222 - rmse: 0.8536 - sae: 2521.5132 - sse: 2984.6912\n","Epoch 15: val_loss did not improve from 0.20757\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1001 - loss: 0.1984 - mae: 0.3269 - mse: 0.2141 - pearson_correlation: 2.6016e-17 - r2_keras: -77.7645 - rmse: 0.8391 - sae: 1843.4747 - sse: 2161.2449 - val_huber_loss: 0.1395 - val_loss: 0.2352 - val_mae: 0.3975 - val_mse: 0.3082 - val_pearson_correlation: 3.6748e-16 - val_r2_keras: -33.1526 - val_rmse: 0.9517 - val_sae: 358.9714 - val_sse: 479.0962 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0995 - loss: 0.1952 - mae: 0.3137 - mse: 0.2112 - pearson_correlation: -4.3927e-16 - r2_keras: -98.1117 - rmse: 0.8664 - sae: 2533.7310 - sse: 3074.3201\n","Epoch 16: val_loss did not improve from 0.20757\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0926 - loss: 0.1910 - mae: 0.3088 - mse: 0.2007 - pearson_correlation: -3.3760e-16 - r2_keras: -79.4395 - rmse: 0.8452 - sae: 1848.6143 - sse: 2218.0488 - val_huber_loss: 0.1236 - val_loss: 0.2191 - val_mae: 0.3594 - val_mse: 0.2725 - val_pearson_correlation: -2.0027e-16 - val_r2_keras: -32.5762 - val_rmse: 0.9436 - val_sae: 356.1291 - val_sse: 471.0104 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0893 - loss: 0.1848 - mae: 0.2787 - mse: 0.1908 - pearson_correlation: 2.8783e-16 - r2_keras: -94.6142 - rmse: 0.8509 - sae: 2502.9153 - sse: 2965.8337\n","Epoch 17: val_loss improved from 0.20757 to 0.20367, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0834 - loss: 0.1812 - mae: 0.2783 - mse: 0.1816 - pearson_correlation: 1.9565e-16 - r2_keras: -78.6777 - rmse: 0.8492 - sae: 1833.4573 - sse: 2164.1394 - val_huber_loss: 0.1082 - val_loss: 0.2037 - val_mae: 0.3156 - val_mse: 0.2374 - val_pearson_correlation: -1.2070e-16 - val_r2_keras: -32.0087 - val_rmse: 0.9356 - val_sae: 351.8827 - val_sse: 463.0500 - learning_rate: 0.0200\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0860 - loss: 0.1815 - mae: 0.2638 - mse: 0.1847 - pearson_correlation: 3.1793e-17 - r2_keras: -92.2217 - rmse: 0.8402 - sae: 2478.1602 - sse: 2891.6201\n","Epoch 18: val_loss improved from 0.20367 to 0.19845, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0804 - loss: 0.1781 - mae: 0.2632 - mse: 0.1757 - pearson_correlation: 4.2576e-17 - r2_keras: -76.6541 - rmse: 0.8382 - sae: 1814.9806 - sse: 2109.6362 - val_huber_loss: 0.1030 - val_loss: 0.1984 - val_mae: 0.2988 - val_mse: 0.2251 - val_pearson_correlation: -1.2029e-16 - val_r2_keras: -32.0568 - val_rmse: 0.9363 - val_sae: 352.8199 - val_sse: 463.7250 - learning_rate: 0.0200\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0851 - loss: 0.1805 - mae: 0.2606 - mse: 0.1826 - pearson_correlation: -1.9251e-16 - r2_keras: -91.9908 - rmse: 0.8392 - sae: 2477.0054 - sse: 2884.4590\n","Epoch 19: val_loss improved from 0.19845 to 0.19610, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0795 - loss: 0.1771 - mae: 0.2592 - mse: 0.1737 - pearson_correlation: -1.2981e-16 - r2_keras: -76.3541 - rmse: 0.8362 - sae: 1813.6504 - sse: 2103.1489 - val_huber_loss: 0.1007 - val_loss: 0.1961 - val_mae: 0.2914 - val_mse: 0.2195 - val_pearson_correlation: 5.9966e-17 - val_r2_keras: -32.1050 - val_rmse: 0.9370 - val_sae: 353.6241 - val_sse: 464.4001 - learning_rate: 0.0200\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0846 - loss: 0.1799 - mae: 0.2595 - mse: 0.1812 - pearson_correlation: -4.6698e-16 - r2_keras: -92.1737 - rmse: 0.8400 - sae: 2479.9868 - sse: 2890.1323\n","Epoch 20: val_loss improved from 0.19610 to 0.19509, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0791 - loss: 0.1766 - mae: 0.2579 - mse: 0.1725 - pearson_correlation: -2.4550e-16 - r2_keras: -76.4030 - rmse: 0.8361 - sae: 1815.3732 - sse: 2106.0745 - val_huber_loss: 0.0998 - val_loss: 0.1951 - val_mae: 0.2885 - val_mse: 0.2170 - val_pearson_correlation: -4.0480e-16 - val_r2_keras: -32.2575 - val_rmse: 0.9391 - val_sae: 354.8758 - val_sse: 466.5403 - learning_rate: 0.0200\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0841 - loss: 0.1794 - mae: 0.2581 - mse: 0.1799 - pearson_correlation: -1.8256e-16 - r2_keras: -92.4027 - rmse: 0.8410 - sae: 2482.9336 - sse: 2897.2358\n","Epoch 21: val_loss improved from 0.19509 to 0.19436, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.0786 - loss: 0.1761 - mae: 0.2564 - mse: 0.1713 - pearson_correlation: -2.0818e-16 - r2_keras: -76.5074 - rmse: 0.8364 - sae: 1817.2371 - sse: 2110.2429 - val_huber_loss: 0.0991 - val_loss: 0.1944 - val_mae: 0.2873 - val_mse: 0.2152 - val_pearson_correlation: -2.2570e-16 - val_r2_keras: -32.2987 - val_rmse: 0.9397 - val_sae: 355.3193 - val_sse: 467.1175 - learning_rate: 0.0200\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0836 - loss: 0.1789 - mae: 0.2569 - mse: 0.1787 - pearson_correlation: 2.1477e-16 - r2_keras: -92.7119 - rmse: 0.8424 - sae: 2486.7307 - sse: 2906.8257\n","Epoch 22: val_loss improved from 0.19436 to 0.19397, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0782 - loss: 0.1756 - mae: 0.2553 - mse: 0.1702 - pearson_correlation: 1.0737e-16 - r2_keras: -76.7057 - rmse: 0.8372 - sae: 1819.8074 - sse: 2116.5457 - val_huber_loss: 0.0988 - val_loss: 0.1940 - val_mae: 0.2864 - val_mse: 0.2143 - val_pearson_correlation: 1.3034e-16 - val_r2_keras: -32.3472 - val_rmse: 0.9404 - val_sae: 355.7333 - val_sse: 467.7985 - learning_rate: 0.0200\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0832 - loss: 0.1784 - mae: 0.2558 - mse: 0.1776 - pearson_correlation: -3.7606e-16 - r2_keras: -92.9633 - rmse: 0.8436 - sae: 2489.5518 - sse: 2914.6235\n","Epoch 23: val_loss improved from 0.19397 to 0.19347, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0779 - loss: 0.1752 - mae: 0.2543 - mse: 0.1692 - pearson_correlation: -2.1292e-16 - r2_keras: -76.8759 - rmse: 0.8380 - sae: 1821.7559 - sse: 2121.7737 - val_huber_loss: 0.0983 - val_loss: 0.1935 - val_mae: 0.2852 - val_mse: 0.2131 - val_pearson_correlation: 2.3633e-17 - val_r2_keras: -32.4040 - val_rmse: 0.9412 - val_sae: 356.0396 - val_sse: 468.5949 - learning_rate: 0.0200\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0829 - loss: 0.1780 - mae: 0.2550 - mse: 0.1768 - pearson_correlation: 1.8964e-16 - r2_keras: -93.1775 - rmse: 0.8445 - sae: 2491.8027 - sse: 2921.2686\n","Epoch 24: val_loss improved from 0.19347 to 0.19346, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0776 - loss: 0.1748 - mae: 0.2535 - mse: 0.1684 - pearson_correlation: 1.1050e-16 - r2_keras: -77.0094 - rmse: 0.8386 - sae: 1823.2062 - sse: 2126.0950 - val_huber_loss: 0.0983 - val_loss: 0.1935 - val_mae: 0.2851 - val_mse: 0.2130 - val_pearson_correlation: -3.0474e-16 - val_r2_keras: -32.5812 - val_rmse: 0.9437 - val_sae: 357.2234 - val_sse: 471.0804 - learning_rate: 0.0200\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0826 - loss: 0.1777 - mae: 0.2541 - mse: 0.1760 - pearson_correlation: 2.0614e-16 - r2_keras: -93.4025 - rmse: 0.8455 - sae: 2494.2542 - sse: 2928.2485\n","Epoch 25: val_loss improved from 0.19346 to 0.19317, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0773 - loss: 0.1745 - mae: 0.2526 - mse: 0.1676 - pearson_correlation: 2.2887e-16 - r2_keras: -77.1748 - rmse: 0.8394 - sae: 1824.9498 - sse: 2130.9285 - val_huber_loss: 0.0981 - val_loss: 0.1932 - val_mae: 0.2849 - val_mse: 0.2124 - val_pearson_correlation: 7.0339e-17 - val_r2_keras: -32.5680 - val_rmse: 0.9435 - val_sae: 357.2238 - val_sse: 470.8958 - learning_rate: 0.0200\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0822 - loss: 0.1773 - mae: 0.2535 - mse: 0.1751 - pearson_correlation: 6.3846e-16 - r2_keras: -93.5657 - rmse: 0.8463 - sae: 2495.8120 - sse: 2933.3110\n","Epoch 26: val_loss improved from 0.19317 to 0.19285, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0770 - loss: 0.1741 - mae: 0.2520 - mse: 0.1669 - pearson_correlation: 4.9711e-16 - r2_keras: -77.2988 - rmse: 0.8400 - sae: 1826.0978 - sse: 2134.4814 - val_huber_loss: 0.0978 - val_loss: 0.1928 - val_mae: 0.2839 - val_mse: 0.2118 - val_pearson_correlation: -4.6854e-17 - val_r2_keras: -32.5877 - val_rmse: 0.9438 - val_sae: 357.1548 - val_sse: 471.1724 - learning_rate: 0.0200\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0819 - loss: 0.1770 - mae: 0.2530 - mse: 0.1745 - pearson_correlation: 5.6083e-16 - r2_keras: -93.7335 - rmse: 0.8470 - sae: 2497.6265 - sse: 2938.5151\n","Epoch 27: val_loss improved from 0.19285 to 0.19281, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.0767 - loss: 0.1738 - mae: 0.2514 - mse: 0.1662 - pearson_correlation: 4.0958e-16 - r2_keras: -77.4260 - rmse: 0.8406 - sae: 1827.4098 - sse: 2138.1321 - val_huber_loss: 0.0978 - val_loss: 0.1928 - val_mae: 0.2841 - val_mse: 0.2117 - val_pearson_correlation: -3.5078e-17 - val_r2_keras: -32.6197 - val_rmse: 0.9442 - val_sae: 357.4398 - val_sse: 471.6215 - learning_rate: 0.0200\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0817 - loss: 0.1767 - mae: 0.2525 - mse: 0.1739 - pearson_correlation: 3.2404e-16 - r2_keras: -93.8800 - rmse: 0.8477 - sae: 2499.1882 - sse: 2943.0586\n","Epoch 28: val_loss did not improve from 0.19281\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0764 - loss: 0.1735 - mae: 0.2509 - mse: 0.1656 - pearson_correlation: 2.9335e-16 - r2_keras: -77.5246 - rmse: 0.8411 - sae: 1828.4384 - sse: 2141.1716 - val_huber_loss: 0.0981 - val_loss: 0.1930 - val_mae: 0.2845 - val_mse: 0.2121 - val_pearson_correlation: 2.2085e-16 - val_r2_keras: -32.7546 - val_rmse: 0.9461 - val_sae: 358.3506 - val_sse: 473.5130 - learning_rate: 0.0200\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0815 - loss: 0.1765 - mae: 0.2519 - mse: 0.1734 - pearson_correlation: 9.8092e-17 - r2_keras: -93.9746 - rmse: 0.8481 - sae: 2500.0337 - sse: 2945.9949\n","Epoch 29: val_loss improved from 0.19281 to 0.19273, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0762 - loss: 0.1732 - mae: 0.2503 - mse: 0.1651 - pearson_correlation: 7.1332e-17 - r2_keras: -77.6090 - rmse: 0.8416 - sae: 1829.1522 - sse: 2143.3784 - val_huber_loss: 0.0978 - val_loss: 0.1927 - val_mae: 0.2843 - val_mse: 0.2115 - val_pearson_correlation: 3.6058e-16 - val_r2_keras: -32.7357 - val_rmse: 0.9458 - val_sae: 358.1457 - val_sse: 473.2476 - learning_rate: 0.0200\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0812 - loss: 0.1761 - mae: 0.2513 - mse: 0.1727 - pearson_correlation: -3.2068e-18 - r2_keras: -94.1564 - rmse: 0.8489 - sae: 2501.9680 - sse: 2951.6311\n","Epoch 30: val_loss improved from 0.19273 to 0.19233, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0759 - loss: 0.1729 - mae: 0.2497 - mse: 0.1644 - pearson_correlation: 1.0702e-17 - r2_keras: -77.7526 - rmse: 0.8423 - sae: 1830.5677 - sse: 2147.3997 - val_huber_loss: 0.0975 - val_loss: 0.1923 - val_mae: 0.2830 - val_mse: 0.2107 - val_pearson_correlation: -1.5108e-16 - val_r2_keras: -32.7529 - val_rmse: 0.9461 - val_sae: 358.1064 - val_sse: 473.4893 - learning_rate: 0.0200\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0811 - loss: 0.1759 - mae: 0.2510 - mse: 0.1723 - pearson_correlation: -8.9620e-17 - r2_keras: -94.2740 - rmse: 0.8494 - sae: 2502.8896 - sse: 2955.2795\n","Epoch 31: val_loss did not improve from 0.19233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0757 - loss: 0.1726 - mae: 0.2494 - mse: 0.1639 - pearson_correlation: -1.5310e-17 - r2_keras: -77.8330 - rmse: 0.8427 - sae: 1831.1613 - sse: 2149.8557 - val_huber_loss: 0.0979 - val_loss: 0.1927 - val_mae: 0.2835 - val_mse: 0.2116 - val_pearson_correlation: 1.1555e-17 - val_r2_keras: -32.8858 - val_rmse: 0.9479 - val_sae: 358.9879 - val_sse: 475.3533 - learning_rate: 0.0200\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0809 - loss: 0.1757 - mae: 0.2507 - mse: 0.1718 - pearson_correlation: -9.1413e-17 - r2_keras: -94.3613 - rmse: 0.8498 - sae: 2503.8447 - sse: 2957.9895\n","Epoch 32: val_loss did not improve from 0.19233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0755 - loss: 0.1724 - mae: 0.2490 - mse: 0.1634 - pearson_correlation: -8.8533e-17 - r2_keras: -77.9167 - rmse: 0.8432 - sae: 1831.9576 - sse: 2151.9604 - val_huber_loss: 0.0978 - val_loss: 0.1925 - val_mae: 0.2835 - val_mse: 0.2112 - val_pearson_correlation: -2.3140e-16 - val_r2_keras: -32.8485 - val_rmse: 0.9474 - val_sae: 358.7848 - val_sse: 474.8301 - learning_rate: 0.0200\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0806 - loss: 0.1754 - mae: 0.2502 - mse: 0.1712 - pearson_correlation: -2.3971e-16 - r2_keras: -94.4481 - rmse: 0.8502 - sae: 2504.6895 - sse: 2960.6797\n","Epoch 33: val_loss did not improve from 0.19233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0752 - loss: 0.1721 - mae: 0.2485 - mse: 0.1628 - pearson_correlation: -2.0309e-16 - r2_keras: -77.9939 - rmse: 0.8436 - sae: 1832.6469 - sse: 2153.9814 - val_huber_loss: 0.0977 - val_loss: 0.1924 - val_mae: 0.2831 - val_mse: 0.2110 - val_pearson_correlation: 1.0440e-16 - val_r2_keras: -32.7861 - val_rmse: 0.9465 - val_sae: 358.3300 - val_sse: 473.9554 - learning_rate: 0.0200\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0804 - loss: 0.1751 - mae: 0.2499 - mse: 0.1707 - pearson_correlation: -2.5954e-16 - r2_keras: -94.5146 - rmse: 0.8505 - sae: 2505.1250 - sse: 2962.7446\n","Epoch 34: val_loss did not improve from 0.19233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0749 - loss: 0.1718 - mae: 0.2481 - mse: 0.1623 - pearson_correlation: -1.3171e-16 - r2_keras: -78.0390 - rmse: 0.8438 - sae: 1832.9152 - sse: 2155.3665 - val_huber_loss: 0.0978 - val_loss: 0.1925 - val_mae: 0.2830 - val_mse: 0.2113 - val_pearson_correlation: 2.3062e-17 - val_r2_keras: -32.9271 - val_rmse: 0.9485 - val_sae: 359.1539 - val_sse: 475.9331 - learning_rate: 0.0200\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0803 - loss: 0.1749 - mae: 0.2495 - mse: 0.1702 - pearson_correlation: -2.4991e-16 - r2_keras: -94.6122 - rmse: 0.8509 - sae: 2506.1479 - sse: 2965.7710\n","Epoch 35: val_loss improved from 0.19233 to 0.19231, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0747 - loss: 0.1716 - mae: 0.2477 - mse: 0.1617 - pearson_correlation: -1.9018e-16 - r2_keras: -78.1248 - rmse: 0.8443 - sae: 1833.7366 - sse: 2157.6282 - val_huber_loss: 0.0977 - val_loss: 0.1923 - val_mae: 0.2830 - val_mse: 0.2110 - val_pearson_correlation: -5.7814e-17 - val_r2_keras: -32.8561 - val_rmse: 0.9475 - val_sae: 358.7545 - val_sse: 474.9364 - learning_rate: 0.0200\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0800 - loss: 0.1746 - mae: 0.2491 - mse: 0.1696 - pearson_correlation: -3.4409e-16 - r2_keras: -94.6804 - rmse: 0.8512 - sae: 2506.8225 - sse: 2967.8848\n","Epoch 36: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0743 - loss: 0.1711 - mae: 0.2473 - mse: 0.1609 - pearson_correlation: -2.4125e-16 - r2_keras: -78.0973 - rmse: 0.8438 - sae: 1833.9969 - sse: 2158.1809 - val_huber_loss: 0.0977 - val_loss: 0.1923 - val_mae: 0.2828 - val_mse: 0.2110 - val_pearson_correlation: -1.1528e-17 - val_r2_keras: -32.9212 - val_rmse: 0.9484 - val_sae: 359.2226 - val_sse: 475.8508 - learning_rate: 0.0040\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0799 - loss: 0.1745 - mae: 0.2489 - mse: 0.1695 - pearson_correlation: 2.3191e-17 - r2_keras: -94.7468 - rmse: 0.8515 - sae: 2507.5732 - sse: 2969.9473\n","Epoch 37: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0742 - loss: 0.1711 - mae: 0.2471 - mse: 0.1607 - pearson_correlation: 1.0528e-17 - r2_keras: -78.1560 - rmse: 0.8441 - sae: 1834.5594 - sse: 2159.7244 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2828 - val_mse: 0.2111 - val_pearson_correlation: -2.9918e-16 - val_r2_keras: -32.9613 - val_rmse: 0.9490 - val_sae: 359.5071 - val_sse: 476.4132 - learning_rate: 0.0040\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0798 - loss: 0.1744 - mae: 0.2487 - mse: 0.1693 - pearson_correlation: -1.4697e-16 - r2_keras: -94.7963 - rmse: 0.8517 - sae: 2508.1309 - sse: 2971.4829\n","Epoch 38: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0742 - loss: 0.1710 - mae: 0.2469 - mse: 0.1606 - pearson_correlation: -1.2164e-16 - r2_keras: -78.2005 - rmse: 0.8444 - sae: 1834.9834 - sse: 2160.8833 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2827 - val_mse: 0.2111 - val_pearson_correlation: 2.4127e-16 - val_r2_keras: -32.9955 - val_rmse: 0.9495 - val_sae: 359.7333 - val_sse: 476.8928 - learning_rate: 0.0040\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0798 - loss: 0.1744 - mae: 0.2486 - mse: 0.1692 - pearson_correlation: 3.6637e-16 - r2_keras: -94.8436 - rmse: 0.8519 - sae: 2508.6675 - sse: 2972.9475\n","Epoch 39: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0741 - loss: 0.1709 - mae: 0.2468 - mse: 0.1605 - pearson_correlation: 1.9303e-16 - r2_keras: -78.2398 - rmse: 0.8446 - sae: 1835.3658 - sse: 2161.9521 - val_huber_loss: 0.0979 - val_loss: 0.1925 - val_mae: 0.2827 - val_mse: 0.2113 - val_pearson_correlation: -1.3758e-16 - val_r2_keras: -33.0441 - val_rmse: 0.9502 - val_sae: 360.0502 - val_sse: 477.5741 - learning_rate: 0.0040\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0797 - loss: 0.1743 - mae: 0.2484 - mse: 0.1690 - pearson_correlation: -4.0990e-16 - r2_keras: -94.8805 - rmse: 0.8521 - sae: 2509.0408 - sse: 2974.0935\n","Epoch 40: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0741 - loss: 0.1709 - mae: 0.2466 - mse: 0.1603 - pearson_correlation: -2.2603e-16 - r2_keras: -78.2737 - rmse: 0.8448 - sae: 1835.6594 - sse: 2162.8245 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2825 - val_mse: 0.2111 - val_pearson_correlation: 9.1728e-17 - val_r2_keras: -33.0416 - val_rmse: 0.9501 - val_sae: 360.0118 - val_sse: 477.5396 - learning_rate: 0.0040\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0797 - loss: 0.1743 - mae: 0.2483 - mse: 0.1689 - pearson_correlation: -1.8123e-16 - r2_keras: -94.9168 - rmse: 0.8523 - sae: 2509.4075 - sse: 2975.2205\n","Epoch 41: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0740 - loss: 0.1708 - mae: 0.2465 - mse: 0.1602 - pearson_correlation: -1.5431e-16 - r2_keras: -78.2886 - rmse: 0.8448 - sae: 1835.8823 - sse: 2163.4663 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2824 - val_mse: 0.2111 - val_pearson_correlation: 5.7285e-17 - val_r2_keras: -33.0592 - val_rmse: 0.9504 - val_sae: 360.1354 - val_sse: 477.7855 - learning_rate: 8.0000e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0797 - loss: 0.1742 - mae: 0.2483 - mse: 0.1689 - pearson_correlation: 1.4699e-16 - r2_keras: -94.9265 - rmse: 0.8523 - sae: 2509.5146 - sse: 2975.5195\n","Epoch 42: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0740 - loss: 0.1708 - mae: 0.2465 - mse: 0.1601 - pearson_correlation: 2.0632e-16 - r2_keras: -78.2963 - rmse: 0.8449 - sae: 1835.9578 - sse: 2163.6814 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2823 - val_mse: 0.2110 - val_pearson_correlation: -1.8318e-16 - val_r2_keras: -33.0759 - val_rmse: 0.9506 - val_sae: 360.2518 - val_sse: 478.0209 - learning_rate: 8.0000e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0797 - loss: 0.1742 - mae: 0.2482 - mse: 0.1688 - pearson_correlation: 3.3925e-16 - r2_keras: -94.9331 - rmse: 0.8523 - sae: 2509.5796 - sse: 2975.7261\n","Epoch 43: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1708 - mae: 0.2464 - mse: 0.1601 - pearson_correlation: 9.3236e-17 - r2_keras: -78.3028 - rmse: 0.8449 - sae: 1836.0107 - sse: 2163.8423 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2823 - val_mse: 0.2110 - val_pearson_correlation: -1.3735e-16 - val_r2_keras: -33.0819 - val_rmse: 0.9507 - val_sae: 360.2934 - val_sse: 478.1046 - learning_rate: 8.0000e-04\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2482 - mse: 0.1688 - pearson_correlation: -4.7981e-16 - r2_keras: -94.9425 - rmse: 0.8524 - sae: 2509.6855 - sse: 2976.0156\n","Epoch 44: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2464 - mse: 0.1601 - pearson_correlation: -2.5490e-16 - r2_keras: -78.3110 - rmse: 0.8449 - sae: 1836.0907 - sse: 2164.0586 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2823 - val_mse: 0.2110 - val_pearson_correlation: -3.3185e-16 - val_r2_keras: -33.0867 - val_rmse: 0.9507 - val_sae: 360.3265 - val_sse: 478.1721 - learning_rate: 8.0000e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2482 - mse: 0.1688 - pearson_correlation: 2.0172e-16 - r2_keras: -94.9502 - rmse: 0.8524 - sae: 2509.7666 - sse: 2976.2561\n","Epoch 45: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2464 - mse: 0.1600 - pearson_correlation: 9.5104e-17 - r2_keras: -78.3172 - rmse: 0.8450 - sae: 1836.1478 - sse: 2164.2317 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2823 - val_mse: 0.2110 - val_pearson_correlation: 1.0296e-16 - val_r2_keras: -33.0933 - val_rmse: 0.9508 - val_sae: 360.3690 - val_sse: 478.2648 - learning_rate: 8.0000e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1688 - pearson_correlation: -4.8794e-16 - r2_keras: -94.9562 - rmse: 0.8524 - sae: 2509.8254 - sse: 2976.4421\n","Epoch 46: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -3.6468e-16 - r2_keras: -78.3196 - rmse: 0.8450 - sae: 1836.1835 - sse: 2164.3367 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: -5.7193e-17 - val_r2_keras: -33.0958 - val_rmse: 0.9509 - val_sae: 360.3850 - val_sse: 478.2998 - learning_rate: 1.6000e-04\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -5.5316e-16 - r2_keras: -94.9579 - rmse: 0.8525 - sae: 2509.8435 - sse: 2976.4951\n","Epoch 47: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -3.3136e-16 - r2_keras: -78.3211 - rmse: 0.8450 - sae: 1836.1974 - sse: 2164.3765 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: -2.1732e-16 - val_r2_keras: -33.0976 - val_rmse: 0.9509 - val_sae: 360.3963 - val_sse: 478.3248 - learning_rate: 1.6000e-04\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -6.6174e-17 - r2_keras: -94.9597 - rmse: 0.8525 - sae: 2509.8616 - sse: 2976.5486\n","Epoch 48: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -6.1837e-17 - r2_keras: -78.3227 - rmse: 0.8450 - sae: 1836.2113 - sse: 2164.4167 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: 5.7185e-17 - val_r2_keras: -33.0989 - val_rmse: 0.9509 - val_sae: 360.4047 - val_sse: 478.3435 - learning_rate: 1.6000e-04\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 4.6859e-17 - r2_keras: -94.9614 - rmse: 0.8525 - sae: 2509.8796 - sse: 2976.6016\n","Epoch 49: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -8.1377e-18 - r2_keras: -78.3242 - rmse: 0.8450 - sae: 1836.2252 - sse: 2164.4565 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: -2.4017e-16 - val_r2_keras: -33.0999 - val_rmse: 0.9509 - val_sae: 360.4108 - val_sse: 478.3578 - learning_rate: 1.6000e-04\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 3.2009e-16 - r2_keras: -94.9631 - rmse: 0.8525 - sae: 2509.8979 - sse: 2976.6545\n","Epoch 50: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 2.4391e-16 - r2_keras: -78.3257 - rmse: 0.8450 - sae: 1836.2394 - sse: 2164.4963 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: -8.0054e-17 - val_r2_keras: -33.1004 - val_rmse: 0.9509 - val_sae: 360.4130 - val_sse: 478.3638 - learning_rate: 1.6000e-04\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 4.9548e-16 - r2_keras: -94.9646 - rmse: 0.8525 - sae: 2509.9133 - sse: 2976.7017\n","Epoch 51: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 3.1063e-16 - r2_keras: -78.3264 - rmse: 0.8450 - sae: 1836.2489 - sse: 2164.5239 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: 1.4867e-16 - val_r2_keras: -33.1013 - val_rmse: 0.9509 - val_sae: 360.4187 - val_sse: 478.3773 - learning_rate: 3.2000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -2.8462e-16 - r2_keras: -94.9649 - rmse: 0.8525 - sae: 2509.9165 - sse: 2976.7109\n","Epoch 52: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -1.8679e-16 - r2_keras: -78.3267 - rmse: 0.8450 - sae: 1836.2513 - sse: 2164.5310 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: 1.8297e-16 - val_r2_keras: -33.1020 - val_rmse: 0.9510 - val_sae: 360.4225 - val_sse: 478.3865 - learning_rate: 3.2000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 4.6540e-17 - r2_keras: -94.9652 - rmse: 0.8525 - sae: 2509.9197 - sse: 2976.7207\n","Epoch 53: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 1.6260e-17 - r2_keras: -78.3270 - rmse: 0.8450 - sae: 1836.2538 - sse: 2164.5383 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2110 - val_pearson_correlation: -1.7153e-16 - val_r2_keras: -33.1024 - val_rmse: 0.9510 - val_sae: 360.4251 - val_sse: 478.3927 - learning_rate: 3.2000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 3.5490e-16 - r2_keras: -94.9655 - rmse: 0.8525 - sae: 2509.9229 - sse: 2976.7300\n","Epoch 54: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 2.5531e-16 - r2_keras: -78.3272 - rmse: 0.8450 - sae: 1836.2563 - sse: 2164.5454 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2109 - val_pearson_correlation: 5.7176e-17 - val_r2_keras: -33.1027 - val_rmse: 0.9510 - val_sae: 360.4264 - val_sse: 478.3960 - learning_rate: 3.2000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 5.3029e-16 - r2_keras: -94.9658 - rmse: 0.8525 - sae: 2509.9255 - sse: 2976.7380\n","Epoch 55: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 3.6830e-16 - r2_keras: -78.3275 - rmse: 0.8450 - sae: 1836.2584 - sse: 2164.5515 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2109 - val_pearson_correlation: 1.6009e-16 - val_r2_keras: -33.1029 - val_rmse: 0.9510 - val_sae: 360.4279 - val_sse: 478.3997 - learning_rate: 3.2000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 7.7027e-16 - r2_keras: -94.9661 - rmse: 0.8525 - sae: 2509.9290 - sse: 2976.7476\n","Epoch 56: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 5.5584e-16 - r2_keras: -78.3277 - rmse: 0.8450 - sae: 1836.2606 - sse: 2164.5576 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2822 - val_mse: 0.2109 - val_pearson_correlation: 5.7175e-17 - val_r2_keras: -33.1031 - val_rmse: 0.9510 - val_sae: 360.4290 - val_sse: 478.4025 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 1.6146e-17 - r2_keras: -94.9662 - rmse: 0.8525 - sae: 2509.9297 - sse: 2976.7505\n","Epoch 57: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 3.1436e-17 - r2_keras: -78.3277 - rmse: 0.8450 - sae: 1836.2612 - sse: 2164.5598 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 1.4865e-16 - val_r2_keras: -33.1033 - val_rmse: 0.9510 - val_sae: 360.4299 - val_sse: 478.4045 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -2.2003e-16 - r2_keras: -94.9662 - rmse: 0.8525 - sae: 2509.9307 - sse: 2976.7529\n","Epoch 58: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -2.6974e-16 - r2_keras: -78.3278 - rmse: 0.8450 - sae: 1836.2621 - sse: 2164.5615 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -1.3722e-16 - val_r2_keras: -33.1034 - val_rmse: 0.9510 - val_sae: 360.4304 - val_sse: 478.4059 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 3.4572e-16 - r2_keras: -94.9663 - rmse: 0.8525 - sae: 2509.9312 - sse: 2976.7556\n","Epoch 59: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 2.1965e-16 - r2_keras: -78.3279 - rmse: 0.8450 - sae: 1836.2623 - sse: 2164.5635 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -4.4596e-16 - val_r2_keras: -33.1034 - val_rmse: 0.9510 - val_sae: 360.4308 - val_sse: 478.4068 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -1.6969e-16 - r2_keras: -94.9664 - rmse: 0.8525 - sae: 2509.9321 - sse: 2976.7583\n","Epoch 60: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -8.4581e-17 - r2_keras: -78.3280 - rmse: 0.8450 - sae: 1836.2632 - sse: 2164.5657 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.6300e-16 - val_r2_keras: -33.1035 - val_rmse: 0.9510 - val_sae: 360.4313 - val_sse: 478.4079 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -1.1049e-16 - r2_keras: -94.9665 - rmse: 0.8525 - sae: 2509.9331 - sse: 2976.7612\n","Epoch 61: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -4.3144e-17 - r2_keras: -78.3280 - rmse: 0.8450 - sae: 1836.2639 - sse: 2164.5679 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -3.4304e-17 - val_r2_keras: -33.1036 - val_rmse: 0.9510 - val_sae: 360.4315 - val_sse: 478.4085 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -5.8063e-16 - r2_keras: -94.9666 - rmse: 0.8525 - sae: 2509.9338 - sse: 2976.7637\n","Epoch 62: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -4.5993e-16 - r2_keras: -78.3281 - rmse: 0.8450 - sae: 1836.2645 - sse: 2164.5696 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -1.6009e-16 - val_r2_keras: -33.1036 - val_rmse: 0.9510 - val_sae: 360.4318 - val_sse: 478.4091 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 4.1030e-16 - r2_keras: -94.9667 - rmse: 0.8525 - sae: 2509.9351 - sse: 2976.7666\n","Epoch 63: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 2.4203e-16 - r2_keras: -78.3282 - rmse: 0.8450 - sae: 1836.2655 - sse: 2164.5718 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.1036 - val_rmse: 0.9510 - val_sae: 360.4319 - val_sse: 478.4095 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 6.4268e-17 - r2_keras: -94.9668 - rmse: 0.8525 - sae: 2509.9360 - sse: 2976.7693\n","Epoch 64: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 1.1667e-16 - r2_keras: -78.3283 - rmse: 0.8450 - sae: 1836.2662 - sse: 2164.5740 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 1.3722e-16 - val_r2_keras: -33.1037 - val_rmse: 0.9510 - val_sae: 360.4321 - val_sse: 478.4101 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 8.0129e-16 - r2_keras: -94.9669 - rmse: 0.8525 - sae: 2509.9370 - sse: 2976.7725\n","Epoch 65: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 5.1647e-16 - r2_keras: -78.3284 - rmse: 0.8450 - sae: 1836.2670 - sse: 2164.5762 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -1.0291e-16 - val_r2_keras: -33.1037 - val_rmse: 0.9510 - val_sae: 360.4322 - val_sse: 478.4103 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 1.2189e-16 - r2_keras: -94.9670 - rmse: 0.8525 - sae: 2509.9380 - sse: 2976.7754\n","Epoch 66: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 2.9085e-17 - r2_keras: -78.3285 - rmse: 0.8450 - sae: 1836.2677 - sse: 2164.5784 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -8.0043e-17 - val_r2_keras: -33.1037 - val_rmse: 0.9510 - val_sae: 360.4324 - val_sse: 478.4109 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 4.4765e-16 - r2_keras: -94.9670 - rmse: 0.8525 - sae: 2509.9390 - sse: 2976.7778\n","Epoch 67: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 4.1361e-16 - r2_keras: -78.3285 - rmse: 0.8450 - sae: 1836.2684 - sse: 2164.5803 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.4013e-16 - val_r2_keras: -33.1037 - val_rmse: 0.9510 - val_sae: 360.4325 - val_sse: 478.4110 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 5.1952e-16 - r2_keras: -94.9671 - rmse: 0.8525 - sae: 2509.9399 - sse: 2976.7805\n","Epoch 68: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 3.2469e-16 - r2_keras: -78.3286 - rmse: 0.8450 - sae: 1836.2692 - sse: 2164.5823 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 4.5739e-17 - val_r2_keras: -33.1038 - val_rmse: 0.9510 - val_sae: 360.4327 - val_sse: 478.4116 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -3.3432e-16 - r2_keras: -94.9672 - rmse: 0.8525 - sae: 2509.9407 - sse: 2976.7837\n","Epoch 69: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -2.0221e-16 - r2_keras: -78.3287 - rmse: 0.8450 - sae: 1836.2698 - sse: 2164.5847 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.1726e-16 - val_r2_keras: -33.1038 - val_rmse: 0.9510 - val_sae: 360.4328 - val_sse: 478.4118 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 6.7464e-16 - r2_keras: -94.9673 - rmse: 0.8525 - sae: 2509.9414 - sse: 2976.7861\n","Epoch 70: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 3.9070e-16 - r2_keras: -78.3288 - rmse: 0.8450 - sae: 1836.2704 - sse: 2164.5867 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.2869e-17 - val_r2_keras: -33.1038 - val_rmse: 0.9510 - val_sae: 360.4330 - val_sse: 478.4123 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -3.5901e-16 - r2_keras: -94.9674 - rmse: 0.8525 - sae: 2509.9424 - sse: 2976.7893\n","Epoch 71: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -2.7182e-16 - r2_keras: -78.3289 - rmse: 0.8450 - sae: 1836.2711 - sse: 2164.5891 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 1.3722e-16 - val_r2_keras: -33.1038 - val_rmse: 0.9510 - val_sae: 360.4330 - val_sse: 478.4124 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -5.6510e-16 - r2_keras: -94.9675 - rmse: 0.8525 - sae: 2509.9434 - sse: 2976.7922\n","Epoch 72: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -3.4917e-16 - r2_keras: -78.3289 - rmse: 0.8450 - sae: 1836.2719 - sse: 2164.5913 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.4013e-16 - val_r2_keras: -33.1039 - val_rmse: 0.9510 - val_sae: 360.4332 - val_sse: 478.4130 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 8.6428e-17 - r2_keras: -94.9676 - rmse: 0.8525 - sae: 2509.9443 - sse: 2976.7949\n","Epoch 73: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 1.1766e-16 - r2_keras: -78.3290 - rmse: 0.8450 - sae: 1836.2726 - sse: 2164.5933 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: -1.1435e-16 - val_r2_keras: -33.1039 - val_rmse: 0.9510 - val_sae: 360.4333 - val_sse: 478.4132 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -1.8457e-16 - r2_keras: -94.9677 - rmse: 0.8525 - sae: 2509.9453 - sse: 2976.7974\n","Epoch 74: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -9.8437e-17 - r2_keras: -78.3291 - rmse: 0.8450 - sae: 1836.2734 - sse: 2164.5950 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 3.5447e-16 - val_r2_keras: -33.1039 - val_rmse: 0.9510 - val_sae: 360.4335 - val_sse: 478.4136 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 2.0135e-16 - r2_keras: -94.9678 - rmse: 0.8525 - sae: 2509.9463 - sse: 2976.8005\n","Epoch 75: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 1.4900e-16 - r2_keras: -78.3292 - rmse: 0.8450 - sae: 1836.2742 - sse: 2164.5974 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.0582e-16 - val_r2_keras: -33.1039 - val_rmse: 0.9510 - val_sae: 360.4335 - val_sse: 478.4139 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 1.3135e-15 - r2_keras: -94.9679 - rmse: 0.8525 - sae: 2509.9473 - sse: 2976.8032\n","Epoch 76: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 9.0520e-16 - r2_keras: -78.3293 - rmse: 0.8450 - sae: 1836.2749 - sse: 2164.5994 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 2.5156e-16 - val_r2_keras: -33.1040 - val_rmse: 0.9510 - val_sae: 360.4338 - val_sse: 478.4144 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -1.3613e-17 - r2_keras: -94.9680 - rmse: 0.8525 - sae: 2509.9482 - sse: 2976.8062\n","Epoch 77: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -2.5810e-17 - r2_keras: -78.3293 - rmse: 0.8450 - sae: 1836.2758 - sse: 2164.6018 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2109 - val_pearson_correlation: 1.9439e-16 - val_r2_keras: -33.1040 - val_rmse: 0.9510 - val_sae: 360.4338 - val_sse: 478.4145 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 8.5572e-16 - r2_keras: -94.9680 - rmse: 0.8525 - sae: 2509.9492 - sse: 2976.8088\n","Epoch 78: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 5.5572e-16 - r2_keras: -78.3294 - rmse: 0.8450 - sae: 1836.2765 - sse: 2164.6038 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: 3.0873e-16 - val_r2_keras: -33.1040 - val_rmse: 0.9510 - val_sae: 360.4340 - val_sse: 478.4151 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 1.7729e-17 - r2_keras: -94.9681 - rmse: 0.8525 - sae: 2509.9500 - sse: 2976.8115\n","Epoch 79: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 6.6943e-17 - r2_keras: -78.3295 - rmse: 0.8450 - sae: 1836.2770 - sse: 2164.6057 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: -1.8295e-16 - val_r2_keras: -33.1040 - val_rmse: 0.9510 - val_sae: 360.4341 - val_sse: 478.4152 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 2.1559e-16 - r2_keras: -94.9682 - rmse: 0.8525 - sae: 2509.9509 - sse: 2976.8142\n","Epoch 80: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 1.6342e-16 - r2_keras: -78.3296 - rmse: 0.8450 - sae: 1836.2777 - sse: 2164.6079 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: -1.1434e-17 - val_r2_keras: -33.1041 - val_rmse: 0.9510 - val_sae: 360.4343 - val_sse: 478.4157 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 5.8251e-17 - r2_keras: -94.9683 - rmse: 0.8525 - sae: 2509.9517 - sse: 2976.8169\n","Epoch 81: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -4.2868e-17 - r2_keras: -78.3297 - rmse: 0.8450 - sae: 1836.2784 - sse: 2164.6099 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: 3.7734e-16 - val_r2_keras: -33.1041 - val_rmse: 0.9510 - val_sae: 360.4343 - val_sse: 478.4159 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -5.2837e-16 - r2_keras: -94.9684 - rmse: 0.8525 - sae: 2509.9531 - sse: 2976.8201\n","Epoch 82: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -3.3551e-16 - r2_keras: -78.3298 - rmse: 0.8450 - sae: 1836.2794 - sse: 2164.6123 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: 9.1476e-17 - val_r2_keras: -33.1041 - val_rmse: 0.9510 - val_sae: 360.4346 - val_sse: 478.4164 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: -1.0669e-16 - r2_keras: -94.9685 - rmse: 0.8525 - sae: 2509.9541 - sse: 2976.8232\n","Epoch 83: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: -1.6001e-17 - r2_keras: -78.3298 - rmse: 0.8450 - sae: 1836.2803 - sse: 2164.6145 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: -1.4865e-16 - val_r2_keras: -33.1041 - val_rmse: 0.9510 - val_sae: 360.4346 - val_sse: 478.4166 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 4.4068e-16 - r2_keras: -94.9686 - rmse: 0.8525 - sae: 2509.9546 - sse: 2976.8257\n","Epoch 84: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 2.5638e-16 - r2_keras: -78.3299 - rmse: 0.8450 - sae: 1836.2806 - sse: 2164.6165 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: 9.1475e-17 - val_r2_keras: -33.1042 - val_rmse: 0.9510 - val_sae: 360.4351 - val_sse: 478.4176 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.1742 - mae: 0.2481 - mse: 0.1687 - pearson_correlation: 9.2093e-16 - r2_keras: -94.9687 - rmse: 0.8525 - sae: 2509.9553 - sse: 2976.8276\n","Epoch 85: val_loss did not improve from 0.19231\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0739 - loss: 0.1707 - mae: 0.2463 - mse: 0.1600 - pearson_correlation: 6.1887e-16 - r2_keras: -78.3300 - rmse: 0.8450 - sae: 1836.2811 - sse: 2164.6179 - val_huber_loss: 0.0978 - val_loss: 0.1924 - val_mae: 0.2821 - val_mse: 0.2110 - val_pearson_correlation: -1.3721e-16 - val_r2_keras: -33.1042 - val_rmse: 0.9510 - val_sae: 360.4352 - val_sse: 478.4179 - learning_rate: 1.0000e-05\n","| \u001b[39m20       \u001b[39m | \u001b[39m-0.1924  \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m95.96    \u001b[39m | \u001b[39m78.41    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.2948 - loss: 0.3866 - mae: 0.6522 - mse: 0.6417 - pearson_correlation: -1.7495e-16 - r2_keras: -115.6207 - rmse: 0.9398 - sae: 3081.3701 - sse: 3617.4297\n","Epoch 1: val_loss improved from inf to 0.38993, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 494ms/step - huber_loss: 0.2943 - loss: 0.3864 - mae: 0.6441 - mse: 0.6503 - pearson_correlation: -6.8887e-17 - r2_keras: -97.9911 - rmse: 0.9520 - sae: 2246.5483 - sse: 2660.8123 - val_huber_loss: 0.2980 - val_loss: 0.3899 - val_mae: 0.6789 - val_mse: 0.7167 - val_pearson_correlation: 3.4505e-16 - val_r2_keras: -24.1349 - val_rmse: 0.8164 - val_sae: 350.6774 - val_sse: 352.5949 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2874 - loss: 0.3793 - mae: 0.6417 - mse: 0.6247 - pearson_correlation: -2.1129e-16 - r2_keras: -114.1054 - rmse: 0.9336 - sae: 3058.3149 - sse: 3570.4241\n","Epoch 2: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.2871 - loss: 0.3791 - mae: 0.6338 - mse: 0.6331 - pearson_correlation: -1.1810e-16 - r2_keras: -96.6751 - rmse: 0.9456 - sae: 2229.8369 - sse: 2625.8884 - val_huber_loss: 0.3442 - val_loss: 0.4361 - val_mae: 0.7452 - val_mse: 0.7852 - val_pearson_correlation: -7.1766e-17 - val_r2_keras: -27.5062 - val_rmse: 0.8694 - val_sae: 396.3228 - val_sse: 399.8882 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2814 - loss: 0.3732 - mae: 0.6329 - mse: 0.6108 - pearson_correlation: 1.3334e-16 - r2_keras: -112.8759 - rmse: 0.9286 - sae: 3039.3608 - sse: 3532.2886\n","Epoch 3: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.2811 - loss: 0.3731 - mae: 0.6250 - mse: 0.6189 - pearson_correlation: 8.8896e-17 - r2_keras: -95.6045 - rmse: 0.9403 - sae: 2216.1072 - sse: 2597.5212 - val_huber_loss: 0.3739 - val_loss: 0.4658 - val_mae: 0.7837 - val_mse: 0.8332 - val_pearson_correlation: -4.4767e-16 - val_r2_keras: -30.2912 - val_rmse: 0.9109 - val_sae: 423.1120 - val_sse: 438.9564 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2761 - loss: 0.3680 - mae: 0.6251 - mse: 0.5988 - pearson_correlation: -9.9295e-17 - r2_keras: -111.8168 - rmse: 0.9243 - sae: 3022.9268 - sse: 3499.4370\n","Epoch 4: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2759 - loss: 0.3678 - mae: 0.6172 - mse: 0.6067 - pearson_correlation: 1.0522e-16 - r2_keras: -94.6814 - rmse: 0.9357 - sae: 2204.1865 - sse: 2573.0742 - val_huber_loss: 0.3804 - val_loss: 0.4722 - val_mae: 0.7909 - val_mse: 0.8407 - val_pearson_correlation: -3.4560e-16 - val_r2_keras: -31.6115 - val_rmse: 0.9299 - val_sae: 434.2181 - val_sse: 457.4783 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2714 - loss: 0.3633 - mae: 0.6181 - mse: 0.5881 - pearson_correlation: -1.7736e-16 - r2_keras: -110.8837 - rmse: 0.9205 - sae: 3008.2871 - sse: 3470.4922\n","Epoch 5: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2711 - loss: 0.3631 - mae: 0.6102 - mse: 0.5956 - pearson_correlation: -2.0617e-16 - r2_keras: -93.8662 - rmse: 0.9317 - sae: 2193.5706 - sse: 2551.5127 - val_huber_loss: 0.3695 - val_loss: 0.4614 - val_mae: 0.7763 - val_mse: 0.8165 - val_pearson_correlation: 1.6822e-16 - val_r2_keras: -31.7882 - val_rmse: 0.9325 - val_sae: 435.0531 - val_sse: 459.9567 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2671 - loss: 0.3589 - mae: 0.6118 - mse: 0.5782 - pearson_correlation: 3.5265e-16 - r2_keras: -110.0424 - rmse: 0.9170 - sae: 2994.8364 - sse: 3444.3960\n","Epoch 6: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.2668 - loss: 0.3588 - mae: 0.6038 - mse: 0.5855 - pearson_correlation: 2.1737e-16 - r2_keras: -93.1301 - rmse: 0.9280 - sae: 2183.8298 - sse: 2532.0591 - val_huber_loss: 0.3489 - val_loss: 0.4408 - val_mae: 0.7490 - val_mse: 0.7743 - val_pearson_correlation: 4.0498e-17 - val_r2_keras: -31.3170 - val_rmse: 0.9257 - val_sae: 429.2383 - val_sse: 453.3468 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2630 - loss: 0.3549 - mae: 0.6059 - mse: 0.5691 - pearson_correlation: -9.4555e-17 - r2_keras: -109.2772 - rmse: 0.9139 - sae: 2982.3550 - sse: 3420.6606\n","Epoch 7: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2629 - loss: 0.3548 - mae: 0.5981 - mse: 0.5764 - pearson_correlation: -2.3600e-16 - r2_keras: -92.4266 - rmse: 0.9243 - sae: 2174.7021 - sse: 2513.9670 - val_huber_loss: 0.3254 - val_loss: 0.4173 - val_mae: 0.7123 - val_mse: 0.7273 - val_pearson_correlation: 1.6333e-16 - val_r2_keras: -30.6447 - val_rmse: 0.9161 - val_sae: 419.9836 - val_sse: 443.9159 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2622 - loss: 0.3541 - mae: 0.6047 - mse: 0.5674 - pearson_correlation: 0.0000e+00 - r2_keras: -109.1345 - rmse: 0.9133 - sae: 2980.0073 - sse: 3416.2351\n","Epoch 8: val_loss did not improve from 0.38993\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.2621 - loss: 0.3540 - mae: 0.5970 - mse: 0.5746 - pearson_correlation: 1.4933e-16 - r2_keras: -92.3011 - rmse: 0.9237 - sae: 2173.0034 - sse: 2510.6606 - val_huber_loss: 0.3058 - val_loss: 0.3976 - val_mae: 0.6748 - val_mse: 0.6883 - val_pearson_correlation: 1.1756e-16 - val_r2_keras: -30.0835 - val_rmse: 0.9079 - val_sae: 409.9277 - val_sse: 436.0429 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.2615 - loss: 0.3534 - mae: 0.6036 - mse: 0.5658 - pearson_correlation: 2.7917e-16 - r2_keras: -108.9975 - rmse: 0.9127 - sae: 2977.7581 - sse: 3411.9849\n","Epoch 9: val_loss improved from 0.38993 to 0.38459, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.2614 - loss: 0.3533 - mae: 0.5959 - mse: 0.5729 - pearson_correlation: 6.3490e-17 - r2_keras: -92.1800 - rmse: 0.9231 - sae: 2171.3755 - sse: 2507.4778 - val_huber_loss: 0.2927 - val_loss: 0.3846 - val_mae: 0.6502 - val_mse: 0.6643 - val_pearson_correlation: 2.2584e-16 - val_r2_keras: -29.7990 - val_rmse: 0.9037 - val_sae: 401.0508 - val_sse: 432.0511 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.2608 - loss: 0.3527 - mae: 0.6026 - mse: 0.5642 - pearson_correlation: 4.9439e-16 - r2_keras: -108.8661 - rmse: 0.9121 - sae: 2975.5913 - sse: 3407.9087\n","Epoch 10: val_loss improved from 0.38459 to 0.37782, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.2607 - loss: 0.3526 - mae: 0.5948 - mse: 0.5713 - pearson_correlation: 3.5954e-16 - r2_keras: -92.0638 - rmse: 0.9225 - sae: 2169.8066 - sse: 2504.4255 - val_huber_loss: 0.2859 - val_loss: 0.3778 - val_mae: 0.6312 - val_mse: 0.6539 - val_pearson_correlation: -6.0193e-17 - val_r2_keras: -29.8556 - val_rmse: 0.9046 - val_sae: 391.8932 - val_sse: 432.8457 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2601 - loss: 0.3520 - mae: 0.6015 - mse: 0.5626 - pearson_correlation: 9.7290e-18 - r2_keras: -108.7397 - rmse: 0.9116 - sae: 2973.5000 - sse: 3403.9878\n","Epoch 11: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.2600 - loss: 0.3519 - mae: 0.5938 - mse: 0.5697 - pearson_correlation: -1.6145e-16 - r2_keras: -91.9521 - rmse: 0.9219 - sae: 2168.2935 - sse: 2501.4900 - val_huber_loss: 0.2861 - val_loss: 0.3779 - val_mae: 0.6263 - val_mse: 0.6583 - val_pearson_correlation: -1.5989e-16 - val_r2_keras: -30.2256 - val_rmse: 0.9100 - val_sae: 383.7171 - val_sse: 438.0357 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2595 - loss: 0.3513 - mae: 0.6006 - mse: 0.5612 - pearson_correlation: 5.4125e-18 - r2_keras: -108.6178 - rmse: 0.9111 - sae: 2971.4758 - sse: 3400.2085\n","Epoch 12: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2593 - loss: 0.3513 - mae: 0.5928 - mse: 0.5682 - pearson_correlation: -3.2424e-17 - r2_keras: -91.8445 - rmse: 0.9214 - sae: 2166.8291 - sse: 2498.6602 - val_huber_loss: 0.2924 - val_loss: 0.3843 - val_mae: 0.6259 - val_mse: 0.6756 - val_pearson_correlation: 1.2729e-16 - val_r2_keras: -30.8196 - val_rmse: 0.9186 - val_sae: 378.3890 - val_sse: 446.3681 - learning_rate: 2.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2588 - loss: 0.3507 - mae: 0.5996 - mse: 0.5597 - pearson_correlation: 1.7343e-16 - r2_keras: -108.5001 - rmse: 0.9106 - sae: 2969.5103 - sse: 3396.5566\n","Epoch 13: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2587 - loss: 0.3506 - mae: 0.5918 - mse: 0.5667 - pearson_correlation: 3.0502e-16 - r2_keras: -91.7403 - rmse: 0.9209 - sae: 2165.4072 - sse: 2495.9248 - val_huber_loss: 0.3029 - val_loss: 0.3947 - val_mae: 0.6283 - val_mse: 0.7014 - val_pearson_correlation: 1.9086e-16 - val_r2_keras: -31.5659 - val_rmse: 0.9293 - val_sae: 376.0089 - val_sse: 456.8379 - learning_rate: 2.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2582 - loss: 0.3501 - mae: 0.5986 - mse: 0.5583 - pearson_correlation: 1.8885e-16 - r2_keras: -108.3861 - rmse: 0.9102 - sae: 2967.5952 - sse: 3393.0200\n","Epoch 14: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2581 - loss: 0.3500 - mae: 0.5909 - mse: 0.5653 - pearson_correlation: 1.9814e-16 - r2_keras: -91.6394 - rmse: 0.9203 - sae: 2164.0220 - sse: 2493.2751 - val_huber_loss: 0.3143 - val_loss: 0.4062 - val_mae: 0.6376 - val_mse: 0.7298 - val_pearson_correlation: -2.4461e-17 - val_r2_keras: -32.3147 - val_rmse: 0.9399 - val_sae: 375.8608 - val_sse: 467.3419 - learning_rate: 2.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2576 - loss: 0.3495 - mae: 0.5977 - mse: 0.5570 - pearson_correlation: 2.3799e-16 - r2_keras: -108.2755 - rmse: 0.9097 - sae: 2965.7295 - sse: 3389.5879\n","Epoch 15: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.2574 - loss: 0.3494 - mae: 0.5900 - mse: 0.5639 - pearson_correlation: 2.5208e-16 - r2_keras: -91.5415 - rmse: 0.9198 - sae: 2162.6721 - sse: 2490.7039 - val_huber_loss: 0.3247 - val_loss: 0.4165 - val_mae: 0.6494 - val_mse: 0.7556 - val_pearson_correlation: -2.2321e-16 - val_r2_keras: -32.9545 - val_rmse: 0.9489 - val_sae: 376.7149 - val_sse: 476.3172 - learning_rate: 2.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2570 - loss: 0.3489 - mae: 0.5968 - mse: 0.5557 - pearson_correlation: -1.0010e-16 - r2_keras: -108.1678 - rmse: 0.9092 - sae: 2963.9116 - sse: 3386.2480\n","Epoch 16: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.2569 - loss: 0.3488 - mae: 0.5891 - mse: 0.5626 - pearson_correlation: 2.5300e-17 - r2_keras: -91.4429 - rmse: 0.9193 - sae: 2161.3462 - sse: 2488.1621 - val_huber_loss: 0.3327 - val_loss: 0.4246 - val_mae: 0.6606 - val_mse: 0.7758 - val_pearson_correlation: 1.7127e-16 - val_r2_keras: -33.4572 - val_rmse: 0.9559 - val_sae: 378.0907 - val_sse: 483.3688 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.2567 - loss: 0.3486 - mae: 0.5964 - mse: 0.5551 - pearson_correlation: 1.5024e-16 - r2_keras: -108.1153 - rmse: 0.9090 - sae: 2963.0239 - sse: 3384.6196\n","Epoch 17: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2566 - loss: 0.3485 - mae: 0.5887 - mse: 0.5619 - pearson_correlation: 4.2797e-17 - r2_keras: -91.3964 - rmse: 0.9191 - sae: 2160.7043 - sse: 2486.9421 - val_huber_loss: 0.3388 - val_loss: 0.4307 - val_mae: 0.6687 - val_mse: 0.7910 - val_pearson_correlation: -4.3667e-16 - val_r2_keras: -33.8340 - val_rmse: 0.9611 - val_sae: 379.3250 - val_sse: 488.6547 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2565 - loss: 0.3483 - mae: 0.5960 - mse: 0.5545 - pearson_correlation: -5.0001e-16 - r2_keras: -108.0639 - rmse: 0.9088 - sae: 2962.1548 - sse: 3383.0273\n","Epoch 18: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2563 - loss: 0.3482 - mae: 0.5883 - mse: 0.5613 - pearson_correlation: -2.6688e-16 - r2_keras: -91.3510 - rmse: 0.9189 - sae: 2160.0762 - sse: 2485.7493 - val_huber_loss: 0.3431 - val_loss: 0.4350 - val_mae: 0.6745 - val_mse: 0.8019 - val_pearson_correlation: 1.8233e-16 - val_r2_keras: -34.1039 - val_rmse: 0.9648 - val_sae: 380.3357 - val_sse: 492.4412 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.2562 - loss: 0.3481 - mae: 0.5956 - mse: 0.5539 - pearson_correlation: -4.3599e-17 - r2_keras: -108.0137 - rmse: 0.9086 - sae: 2961.3027 - sse: 3381.4683\n","Epoch 19: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2560 - loss: 0.3480 - mae: 0.5878 - mse: 0.5606 - pearson_correlation: -1.8640e-18 - r2_keras: -91.3065 - rmse: 0.9186 - sae: 2159.4604 - sse: 2484.5815 - val_huber_loss: 0.3461 - val_loss: 0.4379 - val_mae: 0.6783 - val_mse: 0.8092 - val_pearson_correlation: 1.2597e-16 - val_r2_keras: -34.2906 - val_rmse: 0.9674 - val_sae: 381.1610 - val_sse: 495.0608 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2559 - loss: 0.3478 - mae: 0.5952 - mse: 0.5533 - pearson_correlation: 2.0067e-16 - r2_keras: -107.9645 - rmse: 0.9084 - sae: 2960.4666 - sse: 3379.9419\n","Epoch 20: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2558 - loss: 0.3477 - mae: 0.5874 - mse: 0.5600 - pearson_correlation: 4.3058e-17 - r2_keras: -91.2630 - rmse: 0.9184 - sae: 2158.8562 - sse: 2483.4382 - val_huber_loss: 0.3479 - val_loss: 0.4398 - val_mae: 0.6807 - val_mse: 0.8139 - val_pearson_correlation: -1.0891e-17 - val_r2_keras: -34.4153 - val_rmse: 0.9691 - val_sae: 381.7652 - val_sse: 496.8101 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2557 - loss: 0.3476 - mae: 0.5948 - mse: 0.5527 - pearson_correlation: 6.1325e-16 - r2_keras: -107.9163 - rmse: 0.9082 - sae: 2959.6460 - sse: 3378.4460\n","Epoch 21: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2555 - loss: 0.3474 - mae: 0.5870 - mse: 0.5594 - pearson_correlation: 3.1807e-16 - r2_keras: -91.2204 - rmse: 0.9182 - sae: 2158.2632 - sse: 2482.3179 - val_huber_loss: 0.3491 - val_loss: 0.4410 - val_mae: 0.6821 - val_mse: 0.8167 - val_pearson_correlation: 1.0309e-16 - val_r2_keras: -34.4961 - val_rmse: 0.9702 - val_sae: 382.1522 - val_sse: 497.9425 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2554 - loss: 0.3473 - mae: 0.5944 - mse: 0.5521 - pearson_correlation: -3.8868e-16 - r2_keras: -107.8689 - rmse: 0.9080 - sae: 2958.8391 - sse: 3376.9771\n","Epoch 22: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2552 - loss: 0.3472 - mae: 0.5866 - mse: 0.5588 - pearson_correlation: -2.3793e-16 - r2_keras: -91.1785 - rmse: 0.9180 - sae: 2157.6799 - sse: 2481.2173 - val_huber_loss: 0.3497 - val_loss: 0.4416 - val_mae: 0.6829 - val_mse: 0.8182 - val_pearson_correlation: 1.0827e-16 - val_r2_keras: -34.5464 - val_rmse: 0.9709 - val_sae: 382.3784 - val_sse: 498.6481 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.2552 - loss: 0.3470 - mae: 0.5940 - mse: 0.5516 - pearson_correlation: 8.7390e-17 - r2_keras: -107.8224 - rmse: 0.9078 - sae: 2958.0449 - sse: 3375.5352\n","Epoch 23: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2550 - loss: 0.3469 - mae: 0.5862 - mse: 0.5582 - pearson_correlation: 1.9152e-16 - r2_keras: -91.1373 - rmse: 0.9178 - sae: 2157.1057 - sse: 2480.1372 - val_huber_loss: 0.3500 - val_loss: 0.4419 - val_mae: 0.6832 - val_mse: 0.8189 - val_pearson_correlation: 2.6489e-16 - val_r2_keras: -34.5769 - val_rmse: 0.9713 - val_sae: 382.5113 - val_sse: 499.0772 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2549 - loss: 0.3468 - mae: 0.5936 - mse: 0.5510 - pearson_correlation: 8.8529e-17 - r2_keras: -107.7768 - rmse: 0.9076 - sae: 2957.2634 - sse: 3374.1191\n","Epoch 24: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2547 - loss: 0.3467 - mae: 0.5858 - mse: 0.5577 - pearson_correlation: 1.5901e-16 - r2_keras: -91.0970 - rmse: 0.9176 - sae: 2156.5410 - sse: 2479.0764 - val_huber_loss: 0.3501 - val_loss: 0.4420 - val_mae: 0.6833 - val_mse: 0.8191 - val_pearson_correlation: 2.1606e-16 - val_r2_keras: -34.5947 - val_rmse: 0.9715 - val_sae: 382.5837 - val_sse: 499.3260 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2547 - loss: 0.3466 - mae: 0.5932 - mse: 0.5505 - pearson_correlation: -1.0935e-16 - r2_keras: -107.7319 - rmse: 0.9074 - sae: 2956.4932 - sse: 3372.7275\n","Epoch 25: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2545 - loss: 0.3464 - mae: 0.5855 - mse: 0.5571 - pearson_correlation: -6.2065e-18 - r2_keras: -91.0573 - rmse: 0.9174 - sae: 2155.9841 - sse: 2478.0339 - val_huber_loss: 0.3500 - val_loss: 0.4419 - val_mae: 0.6832 - val_mse: 0.8189 - val_pearson_correlation: -4.3194e-16 - val_r2_keras: -34.6041 - val_rmse: 0.9717 - val_sae: 382.6156 - val_sse: 499.4575 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2544 - loss: 0.3463 - mae: 0.5928 - mse: 0.5499 - pearson_correlation: -1.4223e-17 - r2_keras: -107.6878 - rmse: 0.9072 - sae: 2955.7349 - sse: 3371.3589\n","Epoch 26: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2542 - loss: 0.3462 - mae: 0.5851 - mse: 0.5566 - pearson_correlation: 4.9662e-17 - r2_keras: -91.0182 - rmse: 0.9172 - sae: 2155.4360 - sse: 2477.0085 - val_huber_loss: 0.3499 - val_loss: 0.4418 - val_mae: 0.6830 - val_mse: 0.8186 - val_pearson_correlation: -2.4292e-16 - val_r2_keras: -34.6080 - val_rmse: 0.9717 - val_sae: 382.6199 - val_sse: 499.5134 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2542 - loss: 0.3461 - mae: 0.5925 - mse: 0.5494 - pearson_correlation: 9.4138e-17 - r2_keras: -107.6444 - rmse: 0.9071 - sae: 2954.9871 - sse: 3370.0122\n","Epoch 27: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.2540 - loss: 0.3460 - mae: 0.5847 - mse: 0.5560 - pearson_correlation: -4.9515e-17 - r2_keras: -90.9798 - rmse: 0.9170 - sae: 2154.8960 - sse: 2475.9998 - val_huber_loss: 0.3497 - val_loss: 0.4416 - val_mae: 0.6827 - val_mse: 0.8180 - val_pearson_correlation: -2.7530e-16 - val_r2_keras: -34.6086 - val_rmse: 0.9717 - val_sae: 382.6066 - val_sse: 499.5209 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2540 - loss: 0.3458 - mae: 0.5921 - mse: 0.5489 - pearson_correlation: -1.9823e-16 - r2_keras: -107.6016 - rmse: 0.9069 - sae: 2954.2493 - sse: 3368.6860\n","Epoch 28: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2538 - loss: 0.3457 - mae: 0.5844 - mse: 0.5555 - pearson_correlation: -1.1545e-16 - r2_keras: -90.9420 - rmse: 0.9168 - sae: 2154.3630 - sse: 2475.0061 - val_huber_loss: 0.3495 - val_loss: 0.4414 - val_mae: 0.6824 - val_mse: 0.8175 - val_pearson_correlation: 3.3470e-16 - val_r2_keras: -34.6069 - val_rmse: 0.9717 - val_sae: 382.5822 - val_sse: 499.4980 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2537 - loss: 0.3456 - mae: 0.5918 - mse: 0.5484 - pearson_correlation: 1.8408e-16 - r2_keras: -107.5595 - rmse: 0.9067 - sae: 2953.5220 - sse: 3367.3804\n","Epoch 29: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2535 - loss: 0.3455 - mae: 0.5840 - mse: 0.5550 - pearson_correlation: 6.1974e-17 - r2_keras: -90.9047 - rmse: 0.9166 - sae: 2153.8376 - sse: 2474.0281 - val_huber_loss: 0.3492 - val_loss: 0.4411 - val_mae: 0.6821 - val_mse: 0.8168 - val_pearson_correlation: -5.9390e-17 - val_r2_keras: -34.6039 - val_rmse: 0.9717 - val_sae: 382.5506 - val_sse: 499.4556 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2535 - loss: 0.3454 - mae: 0.5914 - mse: 0.5479 - pearson_correlation: -6.6870e-17 - r2_keras: -107.5180 - rmse: 0.9065 - sae: 2952.8040 - sse: 3366.0938\n","Epoch 30: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2533 - loss: 0.3453 - mae: 0.5837 - mse: 0.5544 - pearson_correlation: -2.5120e-16 - r2_keras: -90.8680 - rmse: 0.9164 - sae: 2153.3193 - sse: 2473.0640 - val_huber_loss: 0.3490 - val_loss: 0.4409 - val_mae: 0.6817 - val_mse: 0.8162 - val_pearson_correlation: 3.2399e-17 - val_r2_keras: -34.6001 - val_rmse: 0.9716 - val_sae: 382.5147 - val_sse: 499.4016 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2533 - loss: 0.3452 - mae: 0.5911 - mse: 0.5474 - pearson_correlation: 3.4767e-16 - r2_keras: -107.4772 - rmse: 0.9064 - sae: 2952.0969 - sse: 3364.8281\n","Epoch 31: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2531 - loss: 0.3450 - mae: 0.5833 - mse: 0.5539 - pearson_correlation: 1.9226e-16 - r2_keras: -90.8319 - rmse: 0.9162 - sae: 2152.8091 - sse: 2472.1155 - val_huber_loss: 0.3487 - val_loss: 0.4406 - val_mae: 0.6813 - val_mse: 0.8155 - val_pearson_correlation: 3.2945e-16 - val_r2_keras: -34.5957 - val_rmse: 0.9716 - val_sae: 382.4763 - val_sse: 499.3403 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2531 - loss: 0.3450 - mae: 0.5907 - mse: 0.5469 - pearson_correlation: 1.7556e-16 - r2_keras: -107.4369 - rmse: 0.9062 - sae: 2951.3982 - sse: 3363.5784\n","Epoch 32: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2529 - loss: 0.3448 - mae: 0.5830 - mse: 0.5534 - pearson_correlation: 1.1704e-16 - r2_keras: -90.7962 - rmse: 0.9160 - sae: 2152.3047 - sse: 2471.1790 - val_huber_loss: 0.3485 - val_loss: 0.4404 - val_mae: 0.6810 - val_mse: 0.8148 - val_pearson_correlation: -5.4019e-17 - val_r2_keras: -34.5910 - val_rmse: 0.9715 - val_sae: 382.4362 - val_sse: 499.2747 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2529 - loss: 0.3447 - mae: 0.5904 - mse: 0.5464 - pearson_correlation: 1.3832e-16 - r2_keras: -107.3972 - rmse: 0.9060 - sae: 2950.7070 - sse: 3362.3457\n","Epoch 33: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2527 - loss: 0.3446 - mae: 0.5826 - mse: 0.5529 - pearson_correlation: 2.5277e-17 - r2_keras: -90.7610 - rmse: 0.9158 - sae: 2151.8062 - sse: 2470.2554 - val_huber_loss: 0.3482 - val_loss: 0.4401 - val_mae: 0.6806 - val_mse: 0.8141 - val_pearson_correlation: 3.2958e-16 - val_r2_keras: -34.5862 - val_rmse: 0.9714 - val_sae: 382.3953 - val_sse: 499.2067 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2526 - loss: 0.3445 - mae: 0.5900 - mse: 0.5459 - pearson_correlation: -8.7861e-18 - r2_keras: -107.3580 - rmse: 0.9059 - sae: 2950.0239 - sse: 3361.1294\n","Epoch 34: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2524 - loss: 0.3444 - mae: 0.5823 - mse: 0.5524 - pearson_correlation: 1.3927e-17 - r2_keras: -90.7263 - rmse: 0.9157 - sae: 2151.3132 - sse: 2469.3440 - val_huber_loss: 0.3480 - val_loss: 0.4398 - val_mae: 0.6802 - val_mse: 0.8134 - val_pearson_correlation: 1.7293e-16 - val_r2_keras: -34.5813 - val_rmse: 0.9714 - val_sae: 382.3541 - val_sse: 499.1377 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2524 - loss: 0.3443 - mae: 0.5897 - mse: 0.5455 - pearson_correlation: -2.9007e-16 - r2_keras: -107.3193 - rmse: 0.9057 - sae: 2949.3489 - sse: 3359.9297\n","Epoch 35: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2522 - loss: 0.3442 - mae: 0.5820 - mse: 0.5519 - pearson_correlation: -3.2128e-16 - r2_keras: -90.6921 - rmse: 0.9155 - sae: 2150.8259 - sse: 2468.4448 - val_huber_loss: 0.3477 - val_loss: 0.4396 - val_mae: 0.6798 - val_mse: 0.8127 - val_pearson_correlation: 2.5945e-16 - val_r2_keras: -34.5763 - val_rmse: 0.9713 - val_sae: 382.3131 - val_sse: 499.0684 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2522 - loss: 0.3441 - mae: 0.5894 - mse: 0.5450 - pearson_correlation: 4.6169e-17 - r2_keras: -107.2811 - rmse: 0.9055 - sae: 2948.6819 - sse: 3358.7449\n","Epoch 36: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2520 - loss: 0.3440 - mae: 0.5816 - mse: 0.5515 - pearson_correlation: 1.0998e-16 - r2_keras: -90.6582 - rmse: 0.9153 - sae: 2150.3445 - sse: 2467.5569 - val_huber_loss: 0.3474 - val_loss: 0.4393 - val_mae: 0.6795 - val_mse: 0.8120 - val_pearson_correlation: -2.6491e-16 - val_r2_keras: -34.5714 - val_rmse: 0.9712 - val_sae: 382.2722 - val_sse: 498.9991 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2520 - loss: 0.3439 - mae: 0.5891 - mse: 0.5446 - pearson_correlation: -3.3322e-16 - r2_keras: -107.2434 - rmse: 0.9054 - sae: 2948.0220 - sse: 3357.5752\n","Epoch 37: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2518 - loss: 0.3438 - mae: 0.5813 - mse: 0.5510 - pearson_correlation: -2.0081e-16 - r2_keras: -90.6249 - rmse: 0.9151 - sae: 2149.8682 - sse: 2466.6802 - val_huber_loss: 0.3472 - val_loss: 0.4391 - val_mae: 0.6791 - val_mse: 0.8114 - val_pearson_correlation: 2.9741e-16 - val_r2_keras: -34.5665 - val_rmse: 0.9712 - val_sae: 382.2315 - val_sse: 498.9304 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2518 - loss: 0.3437 - mae: 0.5887 - mse: 0.5441 - pearson_correlation: -2.0574e-16 - r2_keras: -107.2062 - rmse: 0.9052 - sae: 2947.3716 - sse: 3356.4221\n","Epoch 38: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.2516 - loss: 0.3436 - mae: 0.5810 - mse: 0.5505 - pearson_correlation: 5.7967e-17 - r2_keras: -90.5919 - rmse: 0.9150 - sae: 2149.3987 - sse: 2465.8162 - val_huber_loss: 0.3469 - val_loss: 0.4388 - val_mae: 0.6788 - val_mse: 0.8107 - val_pearson_correlation: 8.6537e-17 - val_r2_keras: -34.5616 - val_rmse: 0.9711 - val_sae: 382.1911 - val_sse: 498.8622 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2516 - loss: 0.3435 - mae: 0.5884 - mse: 0.5437 - pearson_correlation: 1.8712e-17 - r2_keras: -107.1695 - rmse: 0.9051 - sae: 2946.7275 - sse: 3355.2822\n","Epoch 39: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2514 - loss: 0.3434 - mae: 0.5807 - mse: 0.5501 - pearson_correlation: 2.7409e-19 - r2_keras: -90.5594 - rmse: 0.9148 - sae: 2148.9338 - sse: 2464.9617 - val_huber_loss: 0.3467 - val_loss: 0.4386 - val_mae: 0.6784 - val_mse: 0.8101 - val_pearson_correlation: 2.4343e-16 - val_r2_keras: -34.5568 - val_rmse: 0.9710 - val_sae: 382.1509 - val_sse: 498.7946 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2514 - loss: 0.3433 - mae: 0.5881 - mse: 0.5432 - pearson_correlation: -3.8540e-17 - r2_keras: -107.1332 - rmse: 0.9049 - sae: 2946.0933 - sse: 3354.1570\n","Epoch 40: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.2512 - loss: 0.3432 - mae: 0.5803 - mse: 0.5496 - pearson_correlation: 7.8707e-18 - r2_keras: -90.5272 - rmse: 0.9146 - sae: 2148.4758 - sse: 2464.1182 - val_huber_loss: 0.3464 - val_loss: 0.4383 - val_mae: 0.6781 - val_mse: 0.8094 - val_pearson_correlation: 1.1904e-16 - val_r2_keras: -34.5520 - val_rmse: 0.9710 - val_sae: 382.1113 - val_sse: 498.7278 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2512 - loss: 0.3431 - mae: 0.5878 - mse: 0.5428 - pearson_correlation: 1.3880e-16 - r2_keras: -107.0973 - rmse: 0.9048 - sae: 2945.4644 - sse: 3353.0432\n","Epoch 41: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2510 - loss: 0.3430 - mae: 0.5800 - mse: 0.5492 - pearson_correlation: 5.2853e-17 - r2_keras: -90.4955 - rmse: 0.9145 - sae: 2148.0222 - sse: 2463.2844 - val_huber_loss: 0.3462 - val_loss: 0.4381 - val_mae: 0.6777 - val_mse: 0.8088 - val_pearson_correlation: -4.3294e-16 - val_r2_keras: -34.5474 - val_rmse: 0.9709 - val_sae: 382.0722 - val_sse: 498.6621 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.2510 - loss: 0.3429 - mae: 0.5875 - mse: 0.5424 - pearson_correlation: 1.3225e-17 - r2_keras: -107.0615 - rmse: 0.9046 - sae: 2944.8381 - sse: 3351.9316\n","Epoch 42: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.2508 - loss: 0.3428 - mae: 0.5797 - mse: 0.5487 - pearson_correlation: -4.3095e-17 - r2_keras: -90.4639 - rmse: 0.9143 - sae: 2147.5706 - sse: 2462.4529 - val_huber_loss: 0.3459 - val_loss: 0.4378 - val_mae: 0.6774 - val_mse: 0.8081 - val_pearson_correlation: -2.0028e-16 - val_r2_keras: -34.5427 - val_rmse: 0.9708 - val_sae: 382.0333 - val_sse: 498.5970 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2508 - loss: 0.3427 - mae: 0.5872 - mse: 0.5419 - pearson_correlation: -9.2613e-17 - r2_keras: -107.0261 - rmse: 0.9045 - sae: 2944.2183 - sse: 3350.8330\n","Epoch 43: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.2506 - loss: 0.3426 - mae: 0.5794 - mse: 0.5483 - pearson_correlation: -1.7171e-16 - r2_keras: -90.4327 - rmse: 0.9142 - sae: 2147.1240 - sse: 2461.6311 - val_huber_loss: 0.3457 - val_loss: 0.4376 - val_mae: 0.6770 - val_mse: 0.8075 - val_pearson_correlation: -5.4139e-17 - val_r2_keras: -34.5381 - val_rmse: 0.9708 - val_sae: 381.9945 - val_sse: 498.5324 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2506 - loss: 0.3425 - mae: 0.5869 - mse: 0.5415 - pearson_correlation: -1.3787e-16 - r2_keras: -106.9910 - rmse: 0.9043 - sae: 2943.6040 - sse: 3349.7471\n","Epoch 44: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2504 - loss: 0.3424 - mae: 0.5791 - mse: 0.5478 - pearson_correlation: -1.4998e-16 - r2_keras: -90.4018 - rmse: 0.9140 - sae: 2146.6819 - sse: 2460.8188 - val_huber_loss: 0.3455 - val_loss: 0.4373 - val_mae: 0.6767 - val_mse: 0.8069 - val_pearson_correlation: -3.8446e-16 - val_r2_keras: -34.5336 - val_rmse: 0.9707 - val_sae: 381.9562 - val_sse: 498.4687 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.2504 - loss: 0.3423 - mae: 0.5866 - mse: 0.5411 - pearson_correlation: -2.0524e-16 - r2_keras: -106.9564 - rmse: 0.9042 - sae: 2942.9956 - sse: 3348.6726\n","Epoch 45: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2502 - loss: 0.3422 - mae: 0.5788 - mse: 0.5474 - pearson_correlation: -1.3988e-16 - r2_keras: -90.3713 - rmse: 0.9138 - sae: 2146.2439 - sse: 2460.0146 - val_huber_loss: 0.3452 - val_loss: 0.4371 - val_mae: 0.6763 - val_mse: 0.8062 - val_pearson_correlation: -7.5823e-17 - val_r2_keras: -34.5291 - val_rmse: 0.9707 - val_sae: 381.9181 - val_sse: 498.4055 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.2503 - loss: 0.3421 - mae: 0.5863 - mse: 0.5407 - pearson_correlation: -1.2363e-16 - r2_keras: -106.9221 - rmse: 0.9040 - sae: 2942.3938 - sse: 3347.6099\n","Epoch 46: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2500 - loss: 0.3420 - mae: 0.5785 - mse: 0.5470 - pearson_correlation: -9.7714e-17 - r2_keras: -90.3410 - rmse: 0.9137 - sae: 2145.8105 - sse: 2459.2195 - val_huber_loss: 0.3450 - val_loss: 0.4369 - val_mae: 0.6760 - val_mse: 0.8056 - val_pearson_correlation: 2.8168e-16 - val_r2_keras: -34.5246 - val_rmse: 0.9706 - val_sae: 381.8803 - val_sse: 498.3433 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2501 - loss: 0.3420 - mae: 0.5860 - mse: 0.5403 - pearson_correlation: -5.4112e-16 - r2_keras: -106.8882 - rmse: 0.9039 - sae: 2941.7974 - sse: 3346.5579\n","Epoch 47: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2498 - loss: 0.3418 - mae: 0.5782 - mse: 0.5465 - pearson_correlation: -2.9038e-16 - r2_keras: -90.3111 - rmse: 0.9135 - sae: 2145.3811 - sse: 2458.4324 - val_huber_loss: 0.3448 - val_loss: 0.4366 - val_mae: 0.6757 - val_mse: 0.8050 - val_pearson_correlation: -2.1672e-17 - val_r2_keras: -34.5202 - val_rmse: 0.9705 - val_sae: 381.8427 - val_sse: 498.2813 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2499 - loss: 0.3418 - mae: 0.5857 - mse: 0.5399 - pearson_correlation: -1.8781e-17 - r2_keras: -106.8546 - rmse: 0.9038 - sae: 2941.2061 - sse: 3345.5149\n","Epoch 48: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2496 - loss: 0.3416 - mae: 0.5779 - mse: 0.5461 - pearson_correlation: -1.6248e-16 - r2_keras: -90.2814 - rmse: 0.9134 - sae: 2144.9553 - sse: 2457.6519 - val_huber_loss: 0.3445 - val_loss: 0.4364 - val_mae: 0.6753 - val_mse: 0.8044 - val_pearson_correlation: -5.4190e-18 - val_r2_keras: -34.5159 - val_rmse: 0.9705 - val_sae: 381.8054 - val_sse: 498.2203 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2497 - loss: 0.3416 - mae: 0.5854 - mse: 0.5395 - pearson_correlation: -4.3102e-16 - r2_keras: -106.8214 - rmse: 0.9036 - sae: 2940.6226 - sse: 3344.4846\n","Epoch 49: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2495 - loss: 0.3414 - mae: 0.5776 - mse: 0.5457 - pearson_correlation: -2.4449e-16 - r2_keras: -90.2521 - rmse: 0.9132 - sae: 2144.5349 - sse: 2456.8809 - val_huber_loss: 0.3443 - val_loss: 0.4362 - val_mae: 0.6750 - val_mse: 0.8038 - val_pearson_correlation: -1.1382e-16 - val_r2_keras: -34.5116 - val_rmse: 0.9704 - val_sae: 381.7685 - val_sse: 498.1602 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2495 - loss: 0.3414 - mae: 0.5851 - mse: 0.5391 - pearson_correlation: 1.4373e-16 - r2_keras: -106.7884 - rmse: 0.9035 - sae: 2940.0439 - sse: 3343.4624\n","Epoch 50: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2493 - loss: 0.3413 - mae: 0.5773 - mse: 0.5453 - pearson_correlation: 2.1526e-16 - r2_keras: -90.2230 - rmse: 0.9131 - sae: 2144.1179 - sse: 2456.1160 - val_huber_loss: 0.3441 - val_loss: 0.4360 - val_mae: 0.6747 - val_mse: 0.8032 - val_pearson_correlation: -1.1926e-16 - val_r2_keras: -34.5073 - val_rmse: 0.9704 - val_sae: 381.7319 - val_sse: 498.1005 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2493 - loss: 0.3412 - mae: 0.5848 - mse: 0.5387 - pearson_correlation: 2.4333e-17 - r2_keras: -106.7559 - rmse: 0.9033 - sae: 2939.4712 - sse: 3342.4526\n","Epoch 51: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2491 - loss: 0.3411 - mae: 0.5771 - mse: 0.5449 - pearson_correlation: 1.6941e-16 - r2_keras: -90.1943 - rmse: 0.9129 - sae: 2143.7053 - sse: 2455.3601 - val_huber_loss: 0.3439 - val_loss: 0.4357 - val_mae: 0.6744 - val_mse: 0.8026 - val_pearson_correlation: -1.0844e-17 - val_r2_keras: -34.5031 - val_rmse: 0.9703 - val_sae: 381.6954 - val_sse: 498.0415 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2492 - loss: 0.3411 - mae: 0.5846 - mse: 0.5383 - pearson_correlation: 1.3720e-16 - r2_keras: -106.7236 - rmse: 0.9032 - sae: 2938.9028 - sse: 3341.4521\n","Epoch 52: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2489 - loss: 0.3409 - mae: 0.5768 - mse: 0.5445 - pearson_correlation: -8.6292e-17 - r2_keras: -90.1658 - rmse: 0.9128 - sae: 2143.2959 - sse: 2454.6113 - val_huber_loss: 0.3436 - val_loss: 0.4355 - val_mae: 0.6740 - val_mse: 0.8020 - val_pearson_correlation: -1.3015e-16 - val_r2_keras: -34.4990 - val_rmse: 0.9702 - val_sae: 381.6593 - val_sse: 497.9831 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2490 - loss: 0.3409 - mae: 0.5843 - mse: 0.5379 - pearson_correlation: -1.9702e-16 - r2_keras: -106.6917 - rmse: 0.9031 - sae: 2938.3398 - sse: 3340.4609\n","Epoch 53: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2487 - loss: 0.3407 - mae: 0.5765 - mse: 0.5440 - pearson_correlation: -2.5577e-17 - r2_keras: -90.1376 - rmse: 0.9126 - sae: 2142.8901 - sse: 2453.8694 - val_huber_loss: 0.3434 - val_loss: 0.4353 - val_mae: 0.6737 - val_mse: 0.8015 - val_pearson_correlation: 2.4949e-16 - val_r2_keras: -34.4948 - val_rmse: 0.9702 - val_sae: 381.6233 - val_sse: 497.9254 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2488 - loss: 0.3407 - mae: 0.5840 - mse: 0.5375 - pearson_correlation: 3.1004e-17 - r2_keras: -106.6600 - rmse: 0.9029 - sae: 2937.7812 - sse: 3339.4792\n","Epoch 54: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2486 - loss: 0.3405 - mae: 0.5762 - mse: 0.5437 - pearson_correlation: -7.1339e-17 - r2_keras: -90.1096 - rmse: 0.9125 - sae: 2142.4878 - sse: 2453.1345 - val_huber_loss: 0.3432 - val_loss: 0.4351 - val_mae: 0.6734 - val_mse: 0.8009 - val_pearson_correlation: 9.2220e-17 - val_r2_keras: -34.4908 - val_rmse: 0.9701 - val_sae: 381.5877 - val_sse: 497.8683 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2487 - loss: 0.3405 - mae: 0.5837 - mse: 0.5371 - pearson_correlation: -2.7803e-16 - r2_keras: -106.6287 - rmse: 0.9028 - sae: 2937.2261 - sse: 3338.5066\n","Epoch 55: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.2484 - loss: 0.3404 - mae: 0.5759 - mse: 0.5433 - pearson_correlation: -2.8200e-16 - r2_keras: -90.0819 - rmse: 0.9124 - sae: 2142.0876 - sse: 2452.4065 - val_huber_loss: 0.3430 - val_loss: 0.4349 - val_mae: 0.6731 - val_mse: 0.8003 - val_pearson_correlation: 2.5500e-16 - val_r2_keras: -34.4867 - val_rmse: 0.9701 - val_sae: 381.5524 - val_sse: 497.8118 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2485 - loss: 0.3404 - mae: 0.5834 - mse: 0.5367 - pearson_correlation: -3.6457e-16 - r2_keras: -106.5976 - rmse: 0.9027 - sae: 2936.6763 - sse: 3337.5435\n","Epoch 56: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.2482 - loss: 0.3402 - mae: 0.5757 - mse: 0.5429 - pearson_correlation: -2.9368e-16 - r2_keras: -90.0545 - rmse: 0.9122 - sae: 2141.6914 - sse: 2451.6853 - val_huber_loss: 0.3428 - val_loss: 0.4346 - val_mae: 0.6728 - val_mse: 0.7998 - val_pearson_correlation: 5.4265e-17 - val_r2_keras: -34.4828 - val_rmse: 0.9700 - val_sae: 381.5172 - val_sse: 497.7560 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2483 - loss: 0.3402 - mae: 0.5832 - mse: 0.5364 - pearson_correlation: -1.9732e-16 - r2_keras: -106.5668 - rmse: 0.9026 - sae: 2936.1299 - sse: 3336.5889\n","Epoch 57: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2480 - loss: 0.3400 - mae: 0.5754 - mse: 0.5425 - pearson_correlation: -3.6487e-16 - r2_keras: -90.0273 - rmse: 0.9121 - sae: 2141.2976 - sse: 2450.9705 - val_huber_loss: 0.3426 - val_loss: 0.4344 - val_mae: 0.6725 - val_mse: 0.7992 - val_pearson_correlation: 1.6282e-17 - val_r2_keras: -34.4788 - val_rmse: 0.9700 - val_sae: 381.4823 - val_sse: 497.7006 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.2481 - loss: 0.3400 - mae: 0.5829 - mse: 0.5360 - pearson_correlation: -2.0848e-16 - r2_keras: -106.5363 - rmse: 0.9024 - sae: 2935.5876 - sse: 3335.6426\n","Epoch 58: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2479 - loss: 0.3399 - mae: 0.5751 - mse: 0.5421 - pearson_correlation: -2.1115e-16 - r2_keras: -90.0003 - rmse: 0.9119 - sae: 2140.9070 - sse: 2450.2620 - val_huber_loss: 0.3423 - val_loss: 0.4342 - val_mae: 0.6722 - val_mse: 0.7987 - val_pearson_correlation: 6.5140e-17 - val_r2_keras: -34.4749 - val_rmse: 0.9699 - val_sae: 381.4477 - val_sse: 497.6459 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.2480 - loss: 0.3399 - mae: 0.5826 - mse: 0.5356 - pearson_correlation: 1.8747e-16 - r2_keras: -106.5061 - rmse: 0.9023 - sae: 2935.0493 - sse: 3334.7051\n","Epoch 59: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2477 - loss: 0.3397 - mae: 0.5749 - mse: 0.5417 - pearson_correlation: 8.8117e-17 - r2_keras: -89.9736 - rmse: 0.9118 - sae: 2140.5188 - sse: 2449.5598 - val_huber_loss: 0.3421 - val_loss: 0.4340 - val_mae: 0.6719 - val_mse: 0.7981 - val_pearson_correlation: 2.2260e-16 - val_r2_keras: -34.4710 - val_rmse: 0.9699 - val_sae: 381.4131 - val_sse: 497.5916 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2478 - loss: 0.3397 - mae: 0.5824 - mse: 0.5353 - pearson_correlation: -3.1738e-16 - r2_keras: -106.4761 - rmse: 0.9022 - sae: 2934.5146 - sse: 3333.7756\n","Epoch 60: val_loss did not improve from 0.37782\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.2475 - loss: 0.3395 - mae: 0.5746 - mse: 0.5413 - pearson_correlation: -2.6075e-16 - r2_keras: -89.9471 - rmse: 0.9117 - sae: 2140.1335 - sse: 2448.8638 - val_huber_loss: 0.3419 - val_loss: 0.4338 - val_mae: 0.6716 - val_mse: 0.7976 - val_pearson_correlation: 5.2129e-16 - val_r2_keras: -34.4672 - val_rmse: 0.9698 - val_sae: 381.3789 - val_sse: 497.5379 - learning_rate: 1.0000e-05\n","| \u001b[39m21       \u001b[39m | \u001b[39m-0.4338  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m94.67    \u001b[39m | \u001b[39m79.01    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - huber_loss: 1.1367 - loss: 1.2283 - mae: 1.6027 - mse: 3.3633 - pearson_correlation: -4.6182e-17 - r2_keras: -320.4436 - rmse: 1.5602 - sae: 5401.1152 - sse: 9970.7793\n","Epoch 1: val_loss improved from inf to 0.54228, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 471ms/step - huber_loss: 2.0911 - loss: 1.8100 - mae: 2.1901 - mse: 8.1092 - pearson_correlation: 7.3120e-17 - r2_keras: -859.5211 - rmse: 2.8354 - sae: 4836.2236 - sse: 14227.4307 - val_huber_loss: 0.4448 - val_loss: 0.5423 - val_mae: 0.8651 - val_mse: 1.0860 - val_pearson_correlation: 2.6813e-16 - val_r2_keras: -29.7624 - val_rmse: 0.9032 - val_sae: 369.4499 - val_sse: 431.5388 - learning_rate: 0.1000\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.6109 - loss: 0.7084 - mae: 1.0352 - mse: 1.4507 - pearson_correlation: -1.5297e-16 - r2_keras: -174.8278 - rmse: 1.1539 - sae: 3905.1919 - sse: 5453.9570\n","Epoch 2: val_loss improved from 0.54228 to 0.34948, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - huber_loss: 0.9460 - loss: 0.9125 - mae: 1.2388 - mse: 2.4947 - pearson_correlation: -1.9355e-16 - r2_keras: -290.4463 - rmse: 1.7014 - sae: 3207.0093 - sse: 5679.6694 - val_huber_loss: 0.2515 - val_loss: 0.3495 - val_mae: 0.5714 - val_mse: 0.5991 - val_pearson_correlation: 1.3751e-16 - val_r2_keras: -22.7376 - val_rmse: 0.7934 - val_sae: 308.8368 - val_sse: 332.9933 - learning_rate: 0.1000\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2753 - loss: 0.3733 - mae: 0.6553 - mse: 0.5811 - pearson_correlation: 1.5230e-16 - r2_keras: -94.5593 - rmse: 0.8507 - sae: 2754.9453 - sse: 2964.1309\n","Epoch 3: val_loss did not improve from 0.34948\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3825 - loss: 0.4385 - mae: 0.7209 - mse: 0.7557 - pearson_correlation: 3.2989e-16 - r2_keras: -110.6189 - rmse: 1.0560 - sae: 2144.6018 - sse: 2538.1042 - val_huber_loss: 0.2962 - val_loss: 0.3942 - val_mae: 0.6498 - val_mse: 0.7125 - val_pearson_correlation: 3.0173e-16 - val_r2_keras: -26.1154 - val_rmse: 0.8480 - val_sae: 322.0565 - val_sse: 380.3781 - learning_rate: 0.1000\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.3489 - loss: 0.4469 - mae: 0.7100 - mse: 0.7158 - pearson_correlation: -1.0007e-15 - r2_keras: -120.7106 - rmse: 0.9601 - sae: 3076.5867 - sse: 3775.3101\n","Epoch 4: val_loss did not improve from 0.34948\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.3939 - loss: 0.4743 - mae: 0.7427 - mse: 0.7904 - pearson_correlation: -8.3689e-16 - r2_keras: -113.9322 - rmse: 1.0506 - sae: 2308.5811 - sse: 2913.2522 - val_huber_loss: 0.2889 - val_loss: 0.3868 - val_mae: 0.5967 - val_mse: 0.6902 - val_pearson_correlation: -2.9758e-17 - val_r2_keras: -33.7261 - val_rmse: 0.9596 - val_sae: 349.1220 - val_sse: 487.1416 - learning_rate: 0.1000\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3982 - loss: 0.4961 - mae: 0.7083 - mse: 1.0191 - pearson_correlation: -1.8298e-16 - r2_keras: -244.2306 - rmse: 1.3628 - sae: 3948.1284 - sse: 7606.7451\n","Epoch 5: val_loss improved from 0.34948 to 0.30807, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.3497 - loss: 0.4665 - mae: 0.6776 - mse: 0.9208 - pearson_correlation: -6.4397e-17 - r2_keras: -177.3239 - rmse: 1.1805 - sae: 2794.7783 - sse: 5245.2002 - val_huber_loss: 0.2103 - val_loss: 0.3081 - val_mae: 0.4973 - val_mse: 0.4839 - val_pearson_correlation: 2.4518e-16 - val_r2_keras: -30.2680 - val_rmse: 0.9106 - val_sae: 338.7069 - val_sse: 438.6316 - learning_rate: 0.1000\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.2315 - loss: 0.3293 - mae: 0.5071 - mse: 0.5155 - pearson_correlation: 2.2923e-16 - r2_keras: -164.2577 - rmse: 1.1187 - sae: 3267.5889 - sse: 5126.0884\n","Epoch 6: val_loss improved from 0.30807 to 0.25056, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.2081 - loss: 0.3150 - mae: 0.4996 - mse: 0.4785 - pearson_correlation: 2.3893e-16 - r2_keras: -121.9192 - rmse: 0.9979 - sae: 2330.4031 - sse: 3566.9192 - val_huber_loss: 0.1529 - val_loss: 0.2506 - val_mae: 0.4087 - val_mse: 0.3487 - val_pearson_correlation: -6.9979e-17 - val_r2_keras: -28.3793 - val_rmse: 0.8827 - val_sae: 324.1679 - val_sse: 412.1357 - learning_rate: 0.1000\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1359 - loss: 0.2335 - mae: 0.3520 - mse: 0.3005 - pearson_correlation: 2.4874e-16 - r2_keras: -126.6222 - rmse: 0.9831 - sae: 2834.2371 - sse: 3958.6816\n","Epoch 7: val_loss improved from 0.25056 to 0.21965, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.1319 - loss: 0.2311 - mae: 0.3635 - mse: 0.2918 - pearson_correlation: 1.7684e-16 - r2_keras: -97.3322 - rmse: 0.9125 - sae: 2046.4037 - sse: 2794.5522 - val_huber_loss: 0.1222 - val_loss: 0.2196 - val_mae: 0.3786 - val_mse: 0.2578 - val_pearson_correlation: -1.5435e-16 - val_r2_keras: -32.2591 - val_rmse: 0.9391 - val_sae: 366.4893 - val_sse: 466.5627 - learning_rate: 0.1000\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2082 - loss: 0.3056 - mae: 0.4974 - mse: 0.4616 - pearson_correlation: -1.2437e-16 - r2_keras: -141.0917 - rmse: 1.0373 - sae: 3110.3716 - sse: 4407.5054\n","Epoch 8: val_loss did not improve from 0.21965\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2451 - loss: 0.3281 - mae: 0.5417 - mse: 0.5036 - pearson_correlation: -1.5613e-16 - r2_keras: -117.6982 - rmse: 1.0373 - sae: 2287.2893 - sse: 3219.5115 - val_huber_loss: 0.1760 - val_loss: 0.2733 - val_mae: 0.4684 - val_mse: 0.3546 - val_pearson_correlation: -1.3573e-16 - val_r2_keras: -44.7883 - val_rmse: 1.1019 - val_sae: 454.7695 - val_sse: 642.3234 - learning_rate: 0.1000\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2813 - loss: 0.3786 - mae: 0.5914 - mse: 0.6299 - pearson_correlation: -3.0678e-16 - r2_keras: -169.1647 - rmse: 1.1352 - sae: 3482.7844 - sse: 5278.2969\n","Epoch 9: val_loss did not improve from 0.21965\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.2445 - loss: 0.3562 - mae: 0.5768 - mse: 0.5721 - pearson_correlation: -1.6644e-16 - r2_keras: -128.3974 - rmse: 1.0389 - sae: 2500.8992 - sse: 3706.0085 - val_huber_loss: 0.1406 - val_loss: 0.2377 - val_mae: 0.4139 - val_mse: 0.2856 - val_pearson_correlation: 2.1853e-16 - val_r2_keras: -40.9367 - val_rmse: 1.0546 - val_sae: 435.6202 - val_sse: 588.2928 - learning_rate: 0.1000\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1697 - loss: 0.2668 - mae: 0.4332 - mse: 0.3666 - pearson_correlation: 1.0129e-16 - r2_keras: -136.7779 - rmse: 1.0215 - sae: 3175.1040 - sse: 4273.6982\n","Epoch 10: val_loss improved from 0.21965 to 0.21417, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1533 - loss: 0.2568 - mae: 0.4336 - mse: 0.3411 - pearson_correlation: 2.9586e-17 - r2_keras: -105.1865 - rmse: 0.9484 - sae: 2284.5110 - sse: 3017.2766 - val_huber_loss: 0.1173 - val_loss: 0.2142 - val_mae: 0.3627 - val_mse: 0.2427 - val_pearson_correlation: 3.4511e-16 - val_r2_keras: -37.6882 - val_rmse: 1.0129 - val_sae: 405.9089 - val_sse: 542.7225 - learning_rate: 0.1000\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1132 - loss: 0.2101 - mae: 0.3240 - mse: 0.2455 - pearson_correlation: 4.8443e-17 - r2_keras: -114.4104 - rmse: 0.9349 - sae: 2806.9409 - sse: 3579.8862\n","Epoch 11: val_loss improved from 0.21417 to 0.21356, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - huber_loss: 0.1005 - loss: 0.2023 - mae: 0.3197 - mse: 0.2261 - pearson_correlation: 3.4408e-17 - r2_keras: -90.5301 - rmse: 0.8930 - sae: 2029.7316 - sse: 2557.7297 - val_huber_loss: 0.1169 - val_loss: 0.2136 - val_mae: 0.3204 - val_mse: 0.2579 - val_pearson_correlation: 1.4880e-16 - val_r2_keras: -31.3709 - val_rmse: 0.9265 - val_sae: 352.7502 - val_sse: 454.1021 - learning_rate: 0.1000\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0925 - loss: 0.1892 - mae: 0.2928 - mse: 0.1952 - pearson_correlation: -5.2308e-16 - r2_keras: -88.6193 - rmse: 0.8238 - sae: 2452.1663 - sse: 2779.8779\n","Epoch 12: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0926 - loss: 0.1892 - mae: 0.2941 - mse: 0.1933 - pearson_correlation: -3.1408e-16 - r2_keras: -77.4915 - rmse: 0.8550 - sae: 1814.9921 - sse: 2073.1355 - val_huber_loss: 0.1724 - val_loss: 0.2688 - val_mae: 0.4740 - val_mse: 0.3993 - val_pearson_correlation: -2.3042e-16 - val_r2_keras: -28.1071 - val_rmse: 0.8786 - val_sae: 344.9447 - val_sse: 408.3179 - learning_rate: 0.1000\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1405 - loss: 0.2370 - mae: 0.4435 - mse: 0.2899 - pearson_correlation: 5.6792e-16 - r2_keras: -80.5295 - rmse: 0.7858 - sae: 2459.0310 - sse: 2528.9443\n","Epoch 13: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1407 - loss: 0.2371 - mae: 0.4385 - mse: 0.2890 - pearson_correlation: 1.7095e-16 - r2_keras: -76.0042 - rmse: 0.8599 - sae: 1843.3948 - sse: 1951.6617 - val_huber_loss: 0.2052 - val_loss: 0.3014 - val_mae: 0.5440 - val_mse: 0.4757 - val_pearson_correlation: 1.8308e-16 - val_r2_keras: -28.1909 - val_rmse: 0.8798 - val_sae: 354.1223 - val_sse: 409.4934 - learning_rate: 0.1000\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1572 - loss: 0.2535 - mae: 0.4776 - mse: 0.3238 - pearson_correlation: -4.5778e-16 - r2_keras: -83.2080 - rmse: 0.7986 - sae: 2511.5537 - sse: 2612.0264\n","Epoch 14: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.1463 - loss: 0.2468 - mae: 0.4602 - mse: 0.3091 - pearson_correlation: -3.2494e-16 - r2_keras: -76.1797 - rmse: 0.8563 - sae: 1871.0703 - sse: 1988.1637 - val_huber_loss: 0.1724 - val_loss: 0.2685 - val_mae: 0.4867 - val_mse: 0.3959 - val_pearson_correlation: 2.9985e-17 - val_r2_keras: -28.4134 - val_rmse: 0.8832 - val_sae: 352.4069 - val_sse: 412.6141 - learning_rate: 0.1000\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1163 - loss: 0.2123 - mae: 0.3856 - mse: 0.2395 - pearson_correlation: 3.1853e-16 - r2_keras: -87.5849 - rmse: 0.8191 - sae: 2511.2434 - sse: 2747.7920\n","Epoch 15: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1061 - loss: 0.2061 - mae: 0.3694 - mse: 0.2258 - pearson_correlation: 1.5388e-16 - r2_keras: -75.8715 - rmse: 0.8441 - sae: 1852.9430 - sse: 2040.8307 - val_huber_loss: 0.1355 - val_loss: 0.2313 - val_mae: 0.3845 - val_mse: 0.3072 - val_pearson_correlation: 8.2827e-17 - val_r2_keras: -29.5729 - val_rmse: 0.9004 - val_sae: 349.0503 - val_sse: 428.8804 - learning_rate: 0.1000\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0892 - loss: 0.1850 - mae: 0.2895 - mse: 0.1874 - pearson_correlation: -1.0480e-15 - r2_keras: -93.2089 - rmse: 0.8447 - sae: 2511.9177 - sse: 2922.2422\n","Epoch 16: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0821 - loss: 0.1807 - mae: 0.2867 - mse: 0.1770 - pearson_correlation: -6.6201e-16 - r2_keras: -77.4084 - rmse: 0.8421 - sae: 1841.3568 - sse: 2131.1785 - val_huber_loss: 0.1184 - val_loss: 0.2140 - val_mae: 0.3165 - val_mse: 0.2616 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.3011 - val_rmse: 0.9397 - val_sae: 357.6654 - val_sse: 467.1519 - learning_rate: 0.1000\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0832 - loss: 0.1788 - mae: 0.2542 - mse: 0.1774 - pearson_correlation: 2.5251e-16 - r2_keras: -100.5625 - rmse: 0.8770 - sae: 2570.6099 - sse: 3150.3420\n","Epoch 17: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0757 - loss: 0.1742 - mae: 0.2522 - mse: 0.1660 - pearson_correlation: 1.2840e-16 - r2_keras: -82.0238 - rmse: 0.8610 - sae: 1876.2181 - sse: 2279.8787 - val_huber_loss: 0.1189 - val_loss: 0.2144 - val_mae: 0.3163 - val_mse: 0.2614 - val_pearson_correlation: 3.4391e-17 - val_r2_keras: -32.9705 - val_rmse: 0.9491 - val_sae: 361.5468 - val_sse: 476.5425 - learning_rate: 0.0200\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0816 - loss: 0.1772 - mae: 0.2526 - mse: 0.1737 - pearson_correlation: 1.2659e-16 - r2_keras: -98.9867 - rmse: 0.8702 - sae: 2554.2305 - sse: 3101.4636\n","Epoch 18: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0744 - loss: 0.1728 - mae: 0.2509 - mse: 0.1628 - pearson_correlation: 5.7506e-17 - r2_keras: -80.8617 - rmse: 0.8555 - sae: 1865.0273 - sse: 2245.9839 - val_huber_loss: 0.1192 - val_loss: 0.2147 - val_mae: 0.3162 - val_mse: 0.2613 - val_pearson_correlation: 6.7688e-17 - val_r2_keras: -33.3279 - val_rmse: 0.9541 - val_sae: 363.9109 - val_sse: 481.5553 - learning_rate: 0.0200\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0810 - loss: 0.1765 - mae: 0.2511 - mse: 0.1722 - pearson_correlation: -1.9680e-16 - r2_keras: -98.6370 - rmse: 0.8686 - sae: 2551.2070 - sse: 3090.6157\n","Epoch 19: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0739 - loss: 0.1722 - mae: 0.2500 - mse: 0.1615 - pearson_correlation: -1.2771e-16 - r2_keras: -80.6194 - rmse: 0.8544 - sae: 1863.1179 - sse: 2238.6453 - val_huber_loss: 0.1195 - val_loss: 0.2150 - val_mae: 0.3159 - val_mse: 0.2616 - val_pearson_correlation: -7.8136e-17 - val_r2_keras: -33.5696 - val_rmse: 0.9575 - val_sae: 365.5172 - val_sse: 484.9459 - learning_rate: 0.0200\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0805 - loss: 0.1760 - mae: 0.2502 - mse: 0.1710 - pearson_correlation: 1.9821e-16 - r2_keras: -98.5546 - rmse: 0.8683 - sae: 2550.9580 - sse: 3088.0603\n","Epoch 20: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0735 - loss: 0.1717 - mae: 0.2494 - mse: 0.1604 - pearson_correlation: 1.0776e-16 - r2_keras: -80.5844 - rmse: 0.8543 - sae: 1863.1376 - sse: 2237.1748 - val_huber_loss: 0.1198 - val_loss: 0.2153 - val_mae: 0.3161 - val_mse: 0.2621 - val_pearson_correlation: -1.8871e-16 - val_r2_keras: -33.6973 - val_rmse: 0.9592 - val_sae: 366.3085 - val_sse: 486.7374 - learning_rate: 0.0200\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0801 - loss: 0.1755 - mae: 0.2494 - mse: 0.1700 - pearson_correlation: -3.5893e-16 - r2_keras: -98.4816 - rmse: 0.8680 - sae: 2550.2427 - sse: 3085.7952\n","Epoch 21: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0731 - loss: 0.1713 - mae: 0.2487 - mse: 0.1595 - pearson_correlation: -2.1644e-16 - r2_keras: -80.5578 - rmse: 0.8543 - sae: 1862.8307 - sse: 2235.9241 - val_huber_loss: 0.1200 - val_loss: 0.2153 - val_mae: 0.3159 - val_mse: 0.2623 - val_pearson_correlation: -4.4228e-17 - val_r2_keras: -33.7886 - val_rmse: 0.9605 - val_sae: 366.8905 - val_sse: 488.0182 - learning_rate: 0.0200\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0797 - loss: 0.1751 - mae: 0.2486 - mse: 0.1691 - pearson_correlation: 7.4610e-16 - r2_keras: -98.4807 - rmse: 0.8680 - sae: 2550.4412 - sse: 3085.7656\n","Epoch 22: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0726 - loss: 0.1707 - mae: 0.2469 - mse: 0.1584 - pearson_correlation: 5.1962e-16 - r2_keras: -80.6263 - rmse: 0.8549 - sae: 1863.2318 - sse: 2236.7151 - val_huber_loss: 0.1201 - val_loss: 0.2155 - val_mae: 0.3162 - val_mse: 0.2624 - val_pearson_correlation: 1.9807e-16 - val_r2_keras: -33.9017 - val_rmse: 0.9620 - val_sae: 367.5975 - val_sse: 489.6053 - learning_rate: 0.0040\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0796 - loss: 0.1750 - mae: 0.2485 - mse: 0.1688 - pearson_correlation: -6.7168e-16 - r2_keras: -98.4030 - rmse: 0.8676 - sae: 2549.5491 - sse: 3083.3579\n","Epoch 23: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0725 - loss: 0.1706 - mae: 0.2469 - mse: 0.1582 - pearson_correlation: -5.1049e-16 - r2_keras: -80.5743 - rmse: 0.8547 - sae: 1862.6576 - sse: 2235.1072 - val_huber_loss: 0.1201 - val_loss: 0.2155 - val_mae: 0.3163 - val_mse: 0.2623 - val_pearson_correlation: 2.7452e-16 - val_r2_keras: -33.9511 - val_rmse: 0.9627 - val_sae: 367.8976 - val_sse: 490.2979 - learning_rate: 0.0040\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0795 - loss: 0.1749 - mae: 0.2482 - mse: 0.1686 - pearson_correlation: -3.9377e-16 - r2_keras: -98.3750 - rmse: 0.8675 - sae: 2549.1689 - sse: 3082.4895\n","Epoch 24: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0724 - loss: 0.1705 - mae: 0.2467 - mse: 0.1581 - pearson_correlation: -1.9045e-16 - r2_keras: -80.5586 - rmse: 0.8546 - sae: 1862.4261 - sse: 2234.5627 - val_huber_loss: 0.1202 - val_loss: 0.2156 - val_mae: 0.3166 - val_mse: 0.2626 - val_pearson_correlation: 9.8584e-17 - val_r2_keras: -34.0097 - val_rmse: 0.9635 - val_sae: 368.2563 - val_sse: 491.1197 - learning_rate: 0.0040\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0794 - loss: 0.1748 - mae: 0.2481 - mse: 0.1684 - pearson_correlation: 2.1813e-16 - r2_keras: -98.3183 - rmse: 0.8673 - sae: 2548.5295 - sse: 3080.7280\n","Epoch 25: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0724 - loss: 0.1705 - mae: 0.2466 - mse: 0.1579 - pearson_correlation: 1.1087e-16 - r2_keras: -80.5216 - rmse: 0.8545 - sae: 1862.0226 - sse: 2233.3992 - val_huber_loss: 0.1202 - val_loss: 0.2156 - val_mae: 0.3167 - val_mse: 0.2626 - val_pearson_correlation: 1.0949e-16 - val_r2_keras: -34.0194 - val_rmse: 0.9637 - val_sae: 368.3063 - val_sse: 491.2554 - learning_rate: 0.0040\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0793 - loss: 0.1747 - mae: 0.2479 - mse: 0.1682 - pearson_correlation: 3.9357e-16 - r2_keras: -98.3023 - rmse: 0.8672 - sae: 2548.2881 - sse: 3080.2332\n","Epoch 26: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0723 - loss: 0.1704 - mae: 0.2465 - mse: 0.1577 - pearson_correlation: 2.8655e-16 - r2_keras: -80.5149 - rmse: 0.8545 - sae: 1861.8882 - sse: 2233.1147 - val_huber_loss: 0.1203 - val_loss: 0.2156 - val_mae: 0.3168 - val_mse: 0.2626 - val_pearson_correlation: 4.3772e-16 - val_r2_keras: -34.0332 - val_rmse: 0.9639 - val_sae: 368.3836 - val_sse: 491.4497 - learning_rate: 0.0040\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0792 - loss: 0.1746 - mae: 0.2477 - mse: 0.1681 - pearson_correlation: 2.0678e-16 - r2_keras: -98.2837 - rmse: 0.8671 - sae: 2548.0176 - sse: 3079.6548\n","Epoch 27: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0722 - loss: 0.1703 - mae: 0.2461 - mse: 0.1575 - pearson_correlation: 1.5511e-16 - r2_keras: -80.5132 - rmse: 0.8545 - sae: 1861.7468 - sse: 2232.8555 - val_huber_loss: 0.1202 - val_loss: 0.2156 - val_mae: 0.3167 - val_mse: 0.2625 - val_pearson_correlation: 3.2810e-16 - val_r2_keras: -34.0469 - val_rmse: 0.9640 - val_sae: 368.4723 - val_sse: 491.6412 - learning_rate: 8.0000e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0792 - loss: 0.1746 - mae: 0.2476 - mse: 0.1680 - pearson_correlation: 2.3392e-16 - r2_keras: -98.2804 - rmse: 0.8671 - sae: 2547.9717 - sse: 3079.5537\n","Epoch 28: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0722 - loss: 0.1703 - mae: 0.2461 - mse: 0.1575 - pearson_correlation: 2.1559e-16 - r2_keras: -80.5117 - rmse: 0.8545 - sae: 1861.7203 - sse: 2232.7959 - val_huber_loss: 0.1202 - val_loss: 0.2156 - val_mae: 0.3167 - val_mse: 0.2625 - val_pearson_correlation: -1.9679e-16 - val_r2_keras: -34.0553 - val_rmse: 0.9642 - val_sae: 368.5266 - val_sse: 491.7601 - learning_rate: 8.0000e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2476 - mse: 0.1680 - pearson_correlation: -2.4117e-16 - r2_keras: -98.2772 - rmse: 0.8671 - sae: 2547.9272 - sse: 3079.4556\n","Epoch 29: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2461 - mse: 0.1574 - pearson_correlation: -1.4648e-16 - r2_keras: -80.5104 - rmse: 0.8545 - sae: 1861.6956 - sse: 2232.7402 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2625 - val_pearson_correlation: -3.1698e-16 - val_r2_keras: -34.0608 - val_rmse: 0.9642 - val_sae: 368.5606 - val_sse: 491.8364 - learning_rate: 8.0000e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2476 - mse: 0.1679 - pearson_correlation: -4.3653e-16 - r2_keras: -98.2746 - rmse: 0.8671 - sae: 2547.8872 - sse: 3079.3740\n","Epoch 30: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2460 - mse: 0.1574 - pearson_correlation: -2.6785e-16 - r2_keras: -80.5095 - rmse: 0.8545 - sae: 1861.6737 - sse: 2232.6953 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2625 - val_pearson_correlation: 1.7486e-16 - val_r2_keras: -34.0642 - val_rmse: 0.9643 - val_sae: 368.5813 - val_sse: 491.8840 - learning_rate: 8.0000e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2475 - mse: 0.1679 - pearson_correlation: -3.8469e-16 - r2_keras: -98.2707 - rmse: 0.8670 - sae: 2547.8289 - sse: 3079.2517\n","Epoch 31: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2460 - mse: 0.1574 - pearson_correlation: -2.4217e-16 - r2_keras: -80.5074 - rmse: 0.8545 - sae: 1861.6381 - sse: 2232.6201 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2625 - val_pearson_correlation: 3.7154e-16 - val_r2_keras: -34.0663 - val_rmse: 0.9643 - val_sae: 368.5940 - val_sse: 491.9145 - learning_rate: 8.0000e-04\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2475 - mse: 0.1679 - pearson_correlation: 4.7033e-16 - r2_keras: -98.2681 - rmse: 0.8670 - sae: 2547.7917 - sse: 3079.1719\n","Epoch 32: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 2.2240e-16 - r2_keras: -80.5077 - rmse: 0.8545 - sae: 1861.6210 - sse: 2232.5903 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2625 - val_pearson_correlation: 1.2018e-16 - val_r2_keras: -34.0713 - val_rmse: 0.9644 - val_sae: 368.6269 - val_sse: 491.9840 - learning_rate: 1.6000e-04\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2475 - mse: 0.1679 - pearson_correlation: 6.5004e-16 - r2_keras: -98.2661 - rmse: 0.8670 - sae: 2547.7690 - sse: 3079.1099\n","Epoch 33: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 3.8360e-16 - r2_keras: -80.5064 - rmse: 0.8545 - sae: 1861.6067 - sse: 2232.5496 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2625 - val_pearson_correlation: 4.3696e-17 - val_r2_keras: -34.0747 - val_rmse: 0.9644 - val_sae: 368.6497 - val_sse: 492.0313 - learning_rate: 1.6000e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2475 - mse: 0.1679 - pearson_correlation: 2.9427e-16 - r2_keras: -98.2644 - rmse: 0.8670 - sae: 2547.7510 - sse: 3079.0581\n","Epoch 34: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 1.6268e-16 - r2_keras: -80.5053 - rmse: 0.8545 - sae: 1861.5956 - sse: 2232.5154 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 4.3694e-17 - val_r2_keras: -34.0756 - val_rmse: 0.9644 - val_sae: 368.6560 - val_sse: 492.0449 - learning_rate: 1.6000e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -1.6041e-16 - r2_keras: -98.2636 - rmse: 0.8670 - sae: 2547.7395 - sse: 3079.0342\n","Epoch 35: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -9.9053e-17 - r2_keras: -80.5049 - rmse: 0.8545 - sae: 1861.5887 - sse: 2232.5010 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -1.4200e-16 - val_r2_keras: -34.0764 - val_rmse: 0.9644 - val_sae: 368.6610 - val_sse: 492.0555 - learning_rate: 1.6000e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0792 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -8.5027e-17 - r2_keras: -98.2632 - rmse: 0.8670 - sae: 2547.7329 - sse: 3079.0200\n","Epoch 36: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 6.8957e-17 - r2_keras: -80.5048 - rmse: 0.8545 - sae: 1861.5853 - sse: 2232.4932 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 3.0585e-16 - val_r2_keras: -34.0766 - val_rmse: 0.9645 - val_sae: 368.6622 - val_sse: 492.0585 - learning_rate: 1.6000e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 5.7228e-16 - r2_keras: -98.2624 - rmse: 0.8670 - sae: 2547.7209 - sse: 3078.9954\n","Epoch 37: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 4.3079e-16 - r2_keras: -80.5046 - rmse: 0.8545 - sae: 1861.5785 - sse: 2232.4810 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -2.6214e-16 - val_r2_keras: -34.0776 - val_rmse: 0.9645 - val_sae: 368.6691 - val_sse: 492.0728 - learning_rate: 3.2000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -8.9853e-17 - r2_keras: -98.2621 - rmse: 0.8670 - sae: 2547.7173 - sse: 3078.9854\n","Epoch 38: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -5.3990e-17 - r2_keras: -80.5044 - rmse: 0.8545 - sae: 1861.5763 - sse: 2232.4744 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 3.1675e-16 - val_r2_keras: -34.0781 - val_rmse: 0.9645 - val_sae: 368.6722 - val_sse: 492.0793 - learning_rate: 3.2000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -6.4586e-16 - r2_keras: -98.2619 - rmse: 0.8670 - sae: 2547.7158 - sse: 3078.9814\n","Epoch 39: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -4.3944e-16 - r2_keras: -80.5043 - rmse: 0.8545 - sae: 1861.5756 - sse: 2232.4722 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -1.7476e-16 - val_r2_keras: -34.0784 - val_rmse: 0.9645 - val_sae: 368.6740 - val_sse: 492.0832 - learning_rate: 3.2000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 1.0071e-16 - r2_keras: -98.2619 - rmse: 0.8670 - sae: 2547.7144 - sse: 3078.9785\n","Epoch 40: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 4.2997e-17 - r2_keras: -80.5043 - rmse: 0.8545 - sae: 1861.5748 - sse: 2232.4705 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -6.5532e-17 - val_r2_keras: -34.0787 - val_rmse: 0.9645 - val_sae: 368.6765 - val_sse: 492.0881 - learning_rate: 3.2000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -1.4051e-16 - r2_keras: -98.2615 - rmse: 0.8670 - sae: 2547.7104 - sse: 3078.9673\n","Epoch 41: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -1.4836e-16 - r2_keras: -80.5041 - rmse: 0.8545 - sae: 1861.5724 - sse: 2232.4631 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -2.6213e-16 - val_r2_keras: -34.0788 - val_rmse: 0.9645 - val_sae: 368.6768 - val_sse: 492.0888 - learning_rate: 3.2000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 2.3579e-16 - r2_keras: -98.2614 - rmse: 0.8670 - sae: 2547.7085 - sse: 3078.9629\n","Epoch 42: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 1.6015e-16 - r2_keras: -80.5040 - rmse: 0.8545 - sae: 1861.5713 - sse: 2232.4609 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 4.3688e-17 - val_r2_keras: -34.0789 - val_rmse: 0.9645 - val_sae: 368.6774 - val_sse: 492.0901 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -3.0032e-16 - r2_keras: -98.2613 - rmse: 0.8670 - sae: 2547.7075 - sse: 3078.9619\n","Epoch 43: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -2.9629e-16 - r2_keras: -80.5040 - rmse: 0.8545 - sae: 1861.5707 - sse: 2232.4604 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.7475e-16 - val_r2_keras: -34.0789 - val_rmse: 0.9645 - val_sae: 368.6779 - val_sse: 492.0911 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 1.6885e-17 - r2_keras: -98.2613 - rmse: 0.8670 - sae: 2547.7073 - sse: 3078.9604\n","Epoch 44: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 3.0965e-17 - r2_keras: -80.5040 - rmse: 0.8545 - sae: 1861.5707 - sse: 2232.4595 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -2.1844e-17 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6782 - val_sse: 492.0917 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -3.6665e-16 - r2_keras: -98.2612 - rmse: 0.8670 - sae: 2547.7065 - sse: 3078.9592\n","Epoch 45: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -2.2522e-16 - r2_keras: -80.5040 - rmse: 0.8545 - sae: 1861.5702 - sse: 2232.4590 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.4199e-16 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6783 - val_sse: 492.0920 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -2.5328e-17 - r2_keras: -98.2612 - rmse: 0.8670 - sae: 2547.7061 - sse: 3078.9580\n","Epoch 46: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 2.3023e-17 - r2_keras: -80.5040 - rmse: 0.8545 - sae: 1861.5699 - sse: 2232.4580 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -1.8567e-16 - val_r2_keras: -34.0791 - val_rmse: 0.9645 - val_sae: 368.6788 - val_sse: 492.0930 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -4.7822e-16 - r2_keras: -98.2611 - rmse: 0.8670 - sae: 2547.7048 - sse: 3078.9543\n","Epoch 47: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -4.2622e-16 - r2_keras: -80.5039 - rmse: 0.8545 - sae: 1861.5692 - sse: 2232.4558 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -1.8567e-16 - val_r2_keras: -34.0791 - val_rmse: 0.9645 - val_sae: 368.6787 - val_sse: 492.0928 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -1.8695e-17 - r2_keras: -98.2610 - rmse: 0.8670 - sae: 2547.7041 - sse: 3078.9526\n","Epoch 48: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -2.2317e-17 - r2_keras: -80.5039 - rmse: 0.8545 - sae: 1861.5687 - sse: 2232.4546 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.3106e-16 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6786 - val_sse: 492.0927 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -4.4626e-17 - r2_keras: -98.2610 - rmse: 0.8670 - sae: 2547.7036 - sse: 3078.9517\n","Epoch 49: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -2.5316e-17 - r2_keras: -80.5038 - rmse: 0.8545 - sae: 1861.5685 - sse: 2232.4541 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -9.8297e-17 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6785 - val_sse: 492.0924 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 3.6484e-16 - r2_keras: -98.2610 - rmse: 0.8670 - sae: 2547.7031 - sse: 3078.9507\n","Epoch 50: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 2.6343e-16 - r2_keras: -80.5038 - rmse: 0.8545 - sae: 1861.5682 - sse: 2232.4536 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 2.1844e-16 - val_r2_keras: -34.0791 - val_rmse: 0.9645 - val_sae: 368.6788 - val_sse: 492.0932 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 1.8092e-18 - r2_keras: -98.2608 - rmse: 0.8670 - sae: 2547.7019 - sse: 3078.9468\n","Epoch 51: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 1.3523e-17 - r2_keras: -80.5037 - rmse: 0.8545 - sae: 1861.5675 - sse: 2232.4509 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6786 - val_sse: 492.0927 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 2.4725e-16 - r2_keras: -98.2608 - rmse: 0.8670 - sae: 2547.7012 - sse: 3078.9453\n","Epoch 52: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 1.3182e-16 - r2_keras: -80.5037 - rmse: 0.8545 - sae: 1861.5670 - sse: 2232.4500 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.0922e-17 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6786 - val_sse: 492.0926 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 6.9954e-17 - r2_keras: -98.2607 - rmse: 0.8670 - sae: 2547.7002 - sse: 3078.9438\n","Epoch 53: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -4.2048e-17 - r2_keras: -80.5037 - rmse: 0.8545 - sae: 1861.5664 - sse: 2232.4492 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.0922e-17 - val_r2_keras: -34.0791 - val_rmse: 0.9645 - val_sae: 368.6788 - val_sse: 492.0931 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 2.5449e-16 - r2_keras: -98.2606 - rmse: 0.8670 - sae: 2547.6992 - sse: 3078.9399\n","Epoch 54: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 1.8493e-16 - r2_keras: -80.5036 - rmse: 0.8545 - sae: 1861.5658 - sse: 2232.4465 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 5.4610e-17 - val_r2_keras: -34.0791 - val_rmse: 0.9645 - val_sae: 368.6786 - val_sse: 492.0927 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -1.1458e-16 - r2_keras: -98.2606 - rmse: 0.8670 - sae: 2547.6985 - sse: 3078.9385\n","Epoch 55: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -1.4339e-16 - r2_keras: -80.5036 - rmse: 0.8545 - sae: 1861.5653 - sse: 2232.4456 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 3.9319e-16 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6784 - val_sse: 492.0923 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 4.9511e-16 - r2_keras: -98.2605 - rmse: 0.8670 - sae: 2547.6980 - sse: 3078.9380\n","Epoch 56: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 2.8425e-16 - r2_keras: -80.5036 - rmse: 0.8545 - sae: 1861.5651 - sse: 2232.4456 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -2.7305e-16 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6783 - val_sse: 492.0921 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 2.6836e-16 - r2_keras: -98.2605 - rmse: 0.8670 - sae: 2547.6975 - sse: 3078.9360\n","Epoch 57: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 2.3212e-16 - r2_keras: -80.5036 - rmse: 0.8545 - sae: 1861.5648 - sse: 2232.4443 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.0922e-16 - val_r2_keras: -34.0791 - val_rmse: 0.9645 - val_sae: 368.6786 - val_sse: 492.0927 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 3.7389e-16 - r2_keras: -98.2604 - rmse: 0.8670 - sae: 2547.6963 - sse: 3078.9326\n","Epoch 58: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 3.0247e-16 - r2_keras: -80.5035 - rmse: 0.8545 - sae: 1861.5641 - sse: 2232.4419 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.3106e-16 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6784 - val_sse: 492.0923 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 4.0224e-16 - r2_keras: -98.2603 - rmse: 0.8670 - sae: 2547.6958 - sse: 3078.9314\n","Epoch 59: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 2.7900e-16 - r2_keras: -80.5035 - rmse: 0.8545 - sae: 1861.5638 - sse: 2232.4412 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 6.5532e-17 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6783 - val_sse: 492.0920 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: 3.9259e-16 - r2_keras: -98.2603 - rmse: 0.8670 - sae: 2547.6948 - sse: 3078.9297\n","Epoch 60: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: 3.2922e-16 - r2_keras: -80.5034 - rmse: 0.8545 - sae: 1861.5632 - sse: 2232.4402 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: -6.5532e-17 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6781 - val_sse: 492.0916 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0791 - loss: 0.1745 - mae: 0.2474 - mse: 0.1678 - pearson_correlation: -8.5754e-16 - r2_keras: -98.2603 - rmse: 0.8670 - sae: 2547.6943 - sse: 3078.9290\n","Epoch 61: val_loss did not improve from 0.21356\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0721 - loss: 0.1702 - mae: 0.2459 - mse: 0.1573 - pearson_correlation: -6.0668e-16 - r2_keras: -80.5034 - rmse: 0.8545 - sae: 1861.5630 - sse: 2232.4397 - val_huber_loss: 0.1202 - val_loss: 0.2155 - val_mae: 0.3166 - val_mse: 0.2624 - val_pearson_correlation: 1.7475e-16 - val_r2_keras: -34.0790 - val_rmse: 0.9645 - val_sae: 368.6784 - val_sse: 492.0923 - learning_rate: 1.0000e-05\n","| \u001b[39m22       \u001b[39m | \u001b[39m-0.2155  \u001b[39m | \u001b[39m0.1      \u001b[39m | \u001b[39m96.93    \u001b[39m | \u001b[39m79.52    \u001b[39m |\n","=============================================================\n","Mejores parámetros encontrados:\n","  learning_rate: 0.02866896712745276\n","  units_1: 19\n","  units_2: 19\n","Epoch 1/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - huber_loss: 0.4536 - loss: 0.4766 - mae: 0.8267 - mse: 1.1832 - pearson_correlation: -2.4424e-17 - r2_keras: -132.2792 - rmse: 1.0046 - sae: 3204.6440 - sse: 4134.1533\n","Epoch 1: val_loss improved from inf to 0.27793, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 482ms/step - huber_loss: 0.3835 - loss: 0.4340 - mae: 0.7740 - mse: 1.0494 - pearson_correlation: -2.7462e-17 - r2_keras: -109.0874 - rmse: 0.9952 - sae: 2330.4456 - sse: 3005.1848 - val_huber_loss: 0.2549 - val_loss: 0.2779 - val_mae: 0.5702 - val_mse: 0.6625 - val_pearson_correlation: 2.5885e-16 - val_r2_keras: -22.6124 - val_rmse: 0.7913 - val_sae: 299.9742 - val_sse: 331.2372 - learning_rate: 0.0287\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2745 - loss: 0.2976 - mae: 0.6118 - mse: 0.6638 - pearson_correlation: 2.1368e-16 - r2_keras: -106.1044 - rmse: 0.9006 - sae: 2839.5225 - sse: 3322.2446\n","Epoch 2: val_loss did not improve from 0.27793\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2415 - loss: 0.2775 - mae: 0.5860 - mse: 0.6017 - pearson_correlation: 1.4901e-16 - r2_keras: -88.3816 - rmse: 0.8998 - sae: 2075.8237 - sse: 2425.7205 - val_huber_loss: 0.2600 - val_loss: 0.2831 - val_mae: 0.5418 - val_mse: 0.7009 - val_pearson_correlation: -3.4350e-16 - val_r2_keras: -24.3889 - val_rmse: 0.8205 - val_sae: 282.6613 - val_sse: 356.1581 - learning_rate: 0.0287\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.2141 - loss: 0.2372 - mae: 0.5019 - mse: 0.5163 - pearson_correlation: -9.7205e-17 - r2_keras: -113.8168 - rmse: 0.9325 - sae: 2864.6147 - sse: 3561.4739\n","Epoch 3: val_loss did not improve from 0.27793\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.1750 - loss: 0.2133 - mae: 0.4767 - mse: 0.4508 - pearson_correlation: 3.2226e-17 - r2_keras: -90.4813 - rmse: 0.8946 - sae: 2075.6345 - sse: 2549.5249 - val_huber_loss: 0.2744 - val_loss: 0.2975 - val_mae: 0.5549 - val_mse: 0.7604 - val_pearson_correlation: -7.4174e-17 - val_r2_keras: -26.0601 - val_rmse: 0.8471 - val_sae: 284.7008 - val_sse: 379.6024 - learning_rate: 0.0287\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1362 - loss: 0.1593 - mae: 0.3440 - mse: 0.3291 - pearson_correlation: 1.8991e-16 - r2_keras: -96.0616 - rmse: 0.8573 - sae: 2539.3413 - sse: 3010.7288\n","Epoch 4: val_loss did not improve from 0.27793\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1197 - loss: 0.1492 - mae: 0.3394 - mse: 0.2978 - pearson_correlation: 6.5306e-17 - r2_keras: -77.6764 - rmse: 0.8355 - sae: 1853.2577 - sse: 2171.0054 - val_huber_loss: 0.2924 - val_loss: 0.3155 - val_mae: 0.5758 - val_mse: 0.8159 - val_pearson_correlation: -2.8188e-16 - val_r2_keras: -27.6015 - val_rmse: 0.8709 - val_sae: 294.7538 - val_sse: 401.2248 - learning_rate: 0.0287\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1525 - loss: 0.1756 - mae: 0.3954 - mse: 0.3530 - pearson_correlation: 1.1226e-16 - r2_keras: -96.3090 - rmse: 0.8584 - sae: 2576.4692 - sse: 3018.4036\n","Epoch 5: val_loss did not improve from 0.27793\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1331 - loss: 0.1638 - mae: 0.3818 - mse: 0.3204 - pearson_correlation: 1.8559e-16 - r2_keras: -78.7778 - rmse: 0.8449 - sae: 1885.2039 - sse: 2187.1069 - val_huber_loss: 0.2953 - val_loss: 0.3184 - val_mae: 0.5798 - val_mse: 0.8146 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -28.6393 - val_rmse: 0.8866 - val_sae: 302.9797 - val_sse: 415.7839 - learning_rate: 0.0287\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1317 - loss: 0.1547 - mae: 0.3513 - mse: 0.3059 - pearson_correlation: 2.5232e-16 - r2_keras: -94.3967 - rmse: 0.8500 - sae: 2536.2861 - sse: 2959.0874\n","Epoch 6: val_loss did not improve from 0.27793\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1113 - loss: 0.1423 - mae: 0.3331 - mse: 0.2726 - pearson_correlation: 1.7457e-16 - r2_keras: -77.1549 - rmse: 0.8361 - sae: 1851.2188 - sse: 2143.4797 - val_huber_loss: 0.2852 - val_loss: 0.3082 - val_mae: 0.5718 - val_mse: 0.7693 - val_pearson_correlation: 1.2398e-16 - val_r2_keras: -29.0557 - val_rmse: 0.8928 - val_sae: 306.8689 - val_sse: 421.6242 - learning_rate: 0.0287\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1169 - loss: 0.1400 - mae: 0.3212 - mse: 0.2705 - pearson_correlation: -2.7498e-16 - r2_keras: -92.6031 - rmse: 0.8419 - sae: 2507.5034 - sse: 2903.4507\n","Epoch 7: val_loss did not improve from 0.27793\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0970 - loss: 0.1278 - mae: 0.3060 - mse: 0.2387 - pearson_correlation: -1.5190e-16 - r2_keras: -76.9847 - rmse: 0.8401 - sae: 1835.3273 - sse: 2118.4182 - val_huber_loss: 0.2686 - val_loss: 0.2916 - val_mae: 0.5575 - val_mse: 0.7065 - val_pearson_correlation: 1.7492e-16 - val_r2_keras: -29.5004 - val_rmse: 0.8993 - val_sae: 312.6926 - val_sse: 427.8625 - learning_rate: 0.0057\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1116 - loss: 0.1346 - mae: 0.3112 - mse: 0.2585 - pearson_correlation: -8.3188e-17 - r2_keras: -91.9269 - rmse: 0.8389 - sae: 2492.9749 - sse: 2882.4751\n","Epoch 8: val_loss improved from 0.27793 to 0.26609, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0930 - loss: 0.1233 - mae: 0.2957 - mse: 0.2287 - pearson_correlation: 9.5917e-19 - r2_keras: -76.2500 - rmse: 0.8355 - sae: 1823.7194 - sse: 2101.1050 - val_huber_loss: 0.2430 - val_loss: 0.2661 - val_mae: 0.5269 - val_mse: 0.6241 - val_pearson_correlation: -1.1231e-16 - val_r2_keras: -29.6205 - val_rmse: 0.9011 - val_sae: 318.3321 - val_sse: 429.5478 - learning_rate: 0.0057\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1091 - loss: 0.1322 - mae: 0.3067 - mse: 0.2525 - pearson_correlation: -1.1935e-15 - r2_keras: -91.7399 - rmse: 0.8380 - sae: 2489.1895 - sse: 2876.6743\n","Epoch 9: val_loss improved from 0.26609 to 0.23513, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - huber_loss: 0.0912 - loss: 0.1213 - mae: 0.2911 - mse: 0.2237 - pearson_correlation: -7.4001e-16 - r2_keras: -76.0839 - rmse: 0.8345 - sae: 1820.8075 - sse: 2096.7520 - val_huber_loss: 0.2121 - val_loss: 0.2351 - val_mae: 0.4839 - val_mse: 0.5338 - val_pearson_correlation: 7.9812e-17 - val_r2_keras: -29.6212 - val_rmse: 0.9011 - val_sae: 323.0839 - val_sse: 429.5573 - learning_rate: 0.0057\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1078 - loss: 0.1309 - mae: 0.3038 - mse: 0.2490 - pearson_correlation: -2.6263e-16 - r2_keras: -91.9066 - rmse: 0.8388 - sae: 2490.4792 - sse: 2881.8462\n","Epoch 10: val_loss improved from 0.23513 to 0.20435, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - huber_loss: 0.0902 - loss: 0.1201 - mae: 0.2882 - mse: 0.2207 - pearson_correlation: -2.1677e-16 - r2_keras: -76.2042 - rmse: 0.8351 - sae: 1821.6796 - sse: 2100.3071 - val_huber_loss: 0.1813 - val_loss: 0.2043 - val_mae: 0.4431 - val_mse: 0.4494 - val_pearson_correlation: 6.4623e-16 - val_r2_keras: -29.7564 - val_rmse: 0.9031 - val_sae: 327.2892 - val_sse: 431.4545 - learning_rate: 0.0057\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1070 - loss: 0.1300 - mae: 0.3020 - mse: 0.2466 - pearson_correlation: -1.7763e-16 - r2_keras: -92.0550 - rmse: 0.8395 - sae: 2491.4998 - sse: 2886.4490\n","Epoch 11: val_loss improved from 0.20435 to 0.17842, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0895 - loss: 0.1194 - mae: 0.2864 - mse: 0.2187 - pearson_correlation: -7.2849e-17 - r2_keras: -76.3247 - rmse: 0.8358 - sae: 1822.4615 - sse: 2103.6284 - val_huber_loss: 0.1554 - val_loss: 0.1784 - val_mae: 0.4072 - val_mse: 0.3776 - val_pearson_correlation: 5.6218e-17 - val_r2_keras: -30.1757 - val_rmse: 0.9092 - val_sae: 332.6188 - val_sse: 437.3364 - learning_rate: 0.0057\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1061 - loss: 0.1291 - mae: 0.3005 - mse: 0.2440 - pearson_correlation: -3.3351e-16 - r2_keras: -92.1422 - rmse: 0.8399 - sae: 2492.0679 - sse: 2889.1545\n","Epoch 12: val_loss improved from 0.17842 to 0.15962, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - huber_loss: 0.0888 - loss: 0.1186 - mae: 0.2850 - mse: 0.2165 - pearson_correlation: -2.8062e-16 - r2_keras: -76.4163 - rmse: 0.8363 - sae: 1823.0475 - sse: 2105.8242 - val_huber_loss: 0.1366 - val_loss: 0.1596 - val_mae: 0.3779 - val_mse: 0.3254 - val_pearson_correlation: -3.0297e-16 - val_r2_keras: -30.8387 - val_rmse: 0.9189 - val_sae: 339.4504 - val_sse: 446.6363 - learning_rate: 0.0057\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.1055 - loss: 0.1285 - mae: 0.2995 - mse: 0.2423 - pearson_correlation: 4.3163e-16 - r2_keras: -92.2333 - rmse: 0.8403 - sae: 2492.5281 - sse: 2891.9795\n","Epoch 13: val_loss improved from 0.15962 to 0.14817, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0883 - loss: 0.1180 - mae: 0.2839 - mse: 0.2150 - pearson_correlation: 2.5818e-16 - r2_keras: -76.5023 - rmse: 0.8368 - sae: 1823.4874 - sse: 2108.0042 - val_huber_loss: 0.1251 - val_loss: 0.1482 - val_mae: 0.3593 - val_mse: 0.2941 - val_pearson_correlation: -2.2474e-16 - val_r2_keras: -31.5604 - val_rmse: 0.9292 - val_sae: 346.2433 - val_sse: 456.7608 - learning_rate: 0.0057\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1048 - loss: 0.1278 - mae: 0.2984 - mse: 0.2401 - pearson_correlation: 1.7674e-16 - r2_keras: -92.3470 - rmse: 0.8408 - sae: 2493.7568 - sse: 2895.5078\n","Epoch 14: val_loss improved from 0.14817 to 0.14079, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0877 - loss: 0.1174 - mae: 0.2828 - mse: 0.2131 - pearson_correlation: 1.0210e-16 - r2_keras: -76.6123 - rmse: 0.8375 - sae: 1824.5055 - sse: 2110.7581 - val_huber_loss: 0.1178 - val_loss: 0.1408 - val_mae: 0.3421 - val_mse: 0.2733 - val_pearson_correlation: 1.5573e-16 - val_r2_keras: -32.2242 - val_rmse: 0.9386 - val_sae: 352.3566 - val_sse: 466.0727 - learning_rate: 0.0057\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.1043 - loss: 0.1273 - mae: 0.2976 - mse: 0.2387 - pearson_correlation: -8.1137e-17 - r2_keras: -92.4428 - rmse: 0.8412 - sae: 2494.5056 - sse: 2898.4795\n","Epoch 15: val_loss improved from 0.14079 to 0.13675, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - huber_loss: 0.0872 - loss: 0.1169 - mae: 0.2820 - mse: 0.2119 - pearson_correlation: -1.2474e-16 - r2_keras: -76.6965 - rmse: 0.8380 - sae: 1825.0847 - sse: 2112.9778 - val_huber_loss: 0.1137 - val_loss: 0.1368 - val_mae: 0.3295 - val_mse: 0.2610 - val_pearson_correlation: 4.1713e-16 - val_r2_keras: -32.8400 - val_rmse: 0.9473 - val_sae: 357.7846 - val_sse: 474.7115 - learning_rate: 0.0057\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1037 - loss: 0.1267 - mae: 0.2966 - mse: 0.2369 - pearson_correlation: 6.8887e-16 - r2_keras: -92.5671 - rmse: 0.8418 - sae: 2496.1460 - sse: 2902.3347\n","Epoch 16: val_loss improved from 0.13675 to 0.13426, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0867 - loss: 0.1164 - mae: 0.2809 - mse: 0.2103 - pearson_correlation: 4.5044e-16 - r2_keras: -76.8098 - rmse: 0.8386 - sae: 1826.3527 - sse: 2115.9041 - val_huber_loss: 0.1112 - val_loss: 0.1343 - val_mae: 0.3199 - val_mse: 0.2531 - val_pearson_correlation: -2.8332e-16 - val_r2_keras: -33.2933 - val_rmse: 0.9536 - val_sae: 361.3546 - val_sse: 481.0696 - learning_rate: 0.0057\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1030 - loss: 0.1260 - mae: 0.2955 - mse: 0.2349 - pearson_correlation: -1.7629e-16 - r2_keras: -92.6089 - rmse: 0.8420 - sae: 2496.2092 - sse: 2903.6323\n","Epoch 17: val_loss improved from 0.13426 to 0.13252, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0863 - loss: 0.1158 - mae: 0.2799 - mse: 0.2087 - pearson_correlation: -1.6446e-16 - r2_keras: -76.8510 - rmse: 0.8388 - sae: 1826.4811 - sse: 2116.9255 - val_huber_loss: 0.1095 - val_loss: 0.1325 - val_mae: 0.3139 - val_mse: 0.2476 - val_pearson_correlation: -4.0158e-16 - val_r2_keras: -33.6393 - val_rmse: 0.9584 - val_sae: 363.8817 - val_sse: 485.9240 - learning_rate: 0.0057\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1026 - loss: 0.1256 - mae: 0.2947 - mse: 0.2337 - pearson_correlation: 2.0598e-16 - r2_keras: -92.6773 - rmse: 0.8423 - sae: 2497.1809 - sse: 2905.7539\n","Epoch 18: val_loss improved from 0.13252 to 0.13164, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0859 - loss: 0.1154 - mae: 0.2790 - mse: 0.2076 - pearson_correlation: 1.4025e-16 - r2_keras: -76.8978 - rmse: 0.8391 - sae: 1827.1233 - sse: 2118.3545 - val_huber_loss: 0.1086 - val_loss: 0.1316 - val_mae: 0.3100 - val_mse: 0.2445 - val_pearson_correlation: 4.4172e-17 - val_r2_keras: -33.8612 - val_rmse: 0.9615 - val_sae: 365.7370 - val_sse: 489.0361 - learning_rate: 0.0057\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1020 - loss: 0.1250 - mae: 0.2938 - mse: 0.2320 - pearson_correlation: 1.2156e-17 - r2_keras: -92.6760 - rmse: 0.8423 - sae: 2496.4883 - sse: 2905.7119\n","Epoch 19: val_loss improved from 0.13164 to 0.13093, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0855 - loss: 0.1150 - mae: 0.2781 - mse: 0.2062 - pearson_correlation: -4.6579e-17 - r2_keras: -76.9108 - rmse: 0.8392 - sae: 1826.7383 - sse: 2118.4885 - val_huber_loss: 0.1079 - val_loss: 0.1309 - val_mae: 0.3067 - val_mse: 0.2421 - val_pearson_correlation: 1.2029e-16 - val_r2_keras: -34.0853 - val_rmse: 0.9646 - val_sae: 367.4003 - val_sse: 492.1808 - learning_rate: 0.0057\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1017 - loss: 0.1247 - mae: 0.2931 - mse: 0.2311 - pearson_correlation: 4.4200e-16 - r2_keras: -92.7912 - rmse: 0.8428 - sae: 2498.1313 - sse: 2909.2847\n","Epoch 20: val_loss improved from 0.13093 to 0.13052, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - huber_loss: 0.0851 - loss: 0.1146 - mae: 0.2775 - mse: 0.2053 - pearson_correlation: 3.1125e-16 - r2_keras: -76.9988 - rmse: 0.8396 - sae: 1827.8661 - sse: 2121.0022 - val_huber_loss: 0.1075 - val_loss: 0.1305 - val_mae: 0.3047 - val_mse: 0.2406 - val_pearson_correlation: -1.0898e-16 - val_r2_keras: -34.1622 - val_rmse: 0.9656 - val_sae: 368.0787 - val_sse: 493.2588 - learning_rate: 0.0057\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1010 - loss: 0.1240 - mae: 0.2918 - mse: 0.2291 - pearson_correlation: -1.8969e-16 - r2_keras: -92.7394 - rmse: 0.8425 - sae: 2496.6536 - sse: 2907.6802\n","Epoch 21: val_loss improved from 0.13052 to 0.12986, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - huber_loss: 0.0846 - loss: 0.1141 - mae: 0.2762 - mse: 0.2036 - pearson_correlation: -3.8813e-17 - r2_keras: -76.9858 - rmse: 0.8397 - sae: 1827.0023 - sse: 2120.1846 - val_huber_loss: 0.1069 - val_loss: 0.1299 - val_mae: 0.3029 - val_mse: 0.2388 - val_pearson_correlation: -1.6287e-16 - val_r2_keras: -34.2537 - val_rmse: 0.9669 - val_sae: 368.4672 - val_sse: 494.5427 - learning_rate: 0.0057\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.1007 - loss: 0.1237 - mae: 0.2912 - mse: 0.2281 - pearson_correlation: -2.6560e-17 - r2_keras: -92.7907 - rmse: 0.8428 - sae: 2497.2490 - sse: 2909.2712\n","Epoch 22: val_loss improved from 0.12986 to 0.12972, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0843 - loss: 0.1137 - mae: 0.2755 - mse: 0.2028 - pearson_correlation: -3.0924e-18 - r2_keras: -77.0144 - rmse: 0.8398 - sae: 1827.3319 - sse: 2121.1802 - val_huber_loss: 0.1067 - val_loss: 0.1297 - val_mae: 0.3020 - val_mse: 0.2381 - val_pearson_correlation: -2.1655e-16 - val_r2_keras: -34.3209 - val_rmse: 0.9678 - val_sae: 368.9621 - val_sse: 495.4859 - learning_rate: 0.0057\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1002 - loss: 0.1232 - mae: 0.2901 - mse: 0.2266 - pearson_correlation: -3.1768e-16 - r2_keras: -92.8629 - rmse: 0.8431 - sae: 2497.9404 - sse: 2911.5083\n","Epoch 23: val_loss improved from 0.12972 to 0.12952, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0839 - loss: 0.1133 - mae: 0.2745 - mse: 0.2015 - pearson_correlation: -3.0220e-16 - r2_keras: -77.0874 - rmse: 0.8402 - sae: 1827.9408 - sse: 2122.9639 - val_huber_loss: 0.1065 - val_loss: 0.1295 - val_mae: 0.3012 - val_mse: 0.2374 - val_pearson_correlation: 3.6785e-16 - val_r2_keras: -34.3373 - val_rmse: 0.9680 - val_sae: 369.0919 - val_sse: 495.7149 - learning_rate: 0.0057\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0997 - loss: 0.1227 - mae: 0.2892 - mse: 0.2251 - pearson_correlation: -1.6443e-16 - r2_keras: -92.8530 - rmse: 0.8431 - sae: 2497.3123 - sse: 2911.2036\n","Epoch 24: val_loss improved from 0.12952 to 0.12904, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0835 - loss: 0.1128 - mae: 0.2736 - mse: 0.2002 - pearson_correlation: -9.5069e-17 - r2_keras: -77.1073 - rmse: 0.8404 - sae: 1827.6700 - sse: 2123.0710 - val_huber_loss: 0.1060 - val_loss: 0.1290 - val_mae: 0.3002 - val_mse: 0.2362 - val_pearson_correlation: -1.9442e-16 - val_r2_keras: -34.3830 - val_rmse: 0.9687 - val_sae: 369.1287 - val_sse: 496.3568 - learning_rate: 0.0057\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0994 - loss: 0.1224 - mae: 0.2886 - mse: 0.2243 - pearson_correlation: -1.7602e-16 - r2_keras: -92.9209 - rmse: 0.8434 - sae: 2498.2378 - sse: 2913.3096\n","Epoch 25: val_loss did not improve from 0.12904\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0833 - loss: 0.1126 - mae: 0.2730 - mse: 0.1995 - pearson_correlation: -2.2899e-16 - r2_keras: -77.1449 - rmse: 0.8406 - sae: 1828.2261 - sse: 2124.3850 - val_huber_loss: 0.1062 - val_loss: 0.1292 - val_mae: 0.3002 - val_mse: 0.2362 - val_pearson_correlation: 2.6999e-16 - val_r2_keras: -34.3815 - val_rmse: 0.9686 - val_sae: 369.2288 - val_sse: 496.3356 - learning_rate: 0.0057\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0989 - loss: 0.1219 - mae: 0.2877 - mse: 0.2229 - pearson_correlation: 2.3790e-16 - r2_keras: -92.9935 - rmse: 0.8437 - sae: 2499.0073 - sse: 2915.5603\n","Epoch 26: val_loss improved from 0.12904 to 0.12859, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - huber_loss: 0.0829 - loss: 0.1122 - mae: 0.2720 - mse: 0.1983 - pearson_correlation: 1.6732e-16 - r2_keras: -77.2208 - rmse: 0.8410 - sae: 1828.9200 - sse: 2126.2085 - val_huber_loss: 0.1056 - val_loss: 0.1286 - val_mae: 0.2990 - val_mse: 0.2350 - val_pearson_correlation: -1.0795e-17 - val_r2_keras: -34.3960 - val_rmse: 0.9688 - val_sae: 369.0401 - val_sse: 496.5391 - learning_rate: 0.0057\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0986 - loss: 0.1216 - mae: 0.2872 - mse: 0.2221 - pearson_correlation: 4.9395e-16 - r2_keras: -93.0126 - rmse: 0.8438 - sae: 2499.1851 - sse: 2916.1533\n","Epoch 27: val_loss did not improve from 0.12859\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0826 - loss: 0.1119 - mae: 0.2714 - mse: 0.1976 - pearson_correlation: 3.3511e-16 - r2_keras: -77.2287 - rmse: 0.8410 - sae: 1829.0072 - sse: 2126.5464 - val_huber_loss: 0.1058 - val_loss: 0.1287 - val_mae: 0.2991 - val_mse: 0.2351 - val_pearson_correlation: -1.6196e-16 - val_r2_keras: -34.3875 - val_rmse: 0.9687 - val_sae: 369.0970 - val_sse: 496.4200 - learning_rate: 0.0057\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0982 - loss: 0.1212 - mae: 0.2863 - mse: 0.2208 - pearson_correlation: 1.6508e-16 - r2_keras: -93.0921 - rmse: 0.8441 - sae: 2500.0425 - sse: 2918.6201\n","Epoch 28: val_loss improved from 0.12859 to 0.12858, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0823 - loss: 0.1115 - mae: 0.2706 - mse: 0.1965 - pearson_correlation: 6.2675e-17 - r2_keras: -77.3069 - rmse: 0.8415 - sae: 1829.7501 - sse: 2128.4868 - val_huber_loss: 0.1056 - val_loss: 0.1286 - val_mae: 0.2977 - val_mse: 0.2347 - val_pearson_correlation: -2.1545e-17 - val_r2_keras: -34.4408 - val_rmse: 0.9694 - val_sae: 369.3772 - val_sse: 497.1679 - learning_rate: 0.0057\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0981 - loss: 0.1210 - mae: 0.2862 - mse: 0.2202 - pearson_correlation: -4.5912e-16 - r2_keras: -93.1249 - rmse: 0.8443 - sae: 2500.6101 - sse: 2919.6355\n","Epoch 29: val_loss improved from 0.12858 to 0.12806, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - huber_loss: 0.0821 - loss: 0.1114 - mae: 0.2704 - mse: 0.1960 - pearson_correlation: -3.8177e-16 - r2_keras: -77.2846 - rmse: 0.8412 - sae: 1829.9828 - sse: 2128.6462 - val_huber_loss: 0.1051 - val_loss: 0.1281 - val_mae: 0.2966 - val_mse: 0.2336 - val_pearson_correlation: 2.0610e-16 - val_r2_keras: -34.2715 - val_rmse: 0.9671 - val_sae: 368.2106 - val_sse: 494.7924 - learning_rate: 0.0057\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0976 - loss: 0.1205 - mae: 0.2852 - mse: 0.2188 - pearson_correlation: -2.7241e-16 - r2_keras: -93.0236 - rmse: 0.8438 - sae: 2498.8809 - sse: 2916.4946\n","Epoch 30: val_loss did not improve from 0.12806\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0818 - loss: 0.1109 - mae: 0.2694 - mse: 0.1948 - pearson_correlation: -1.3422e-16 - r2_keras: -77.2593 - rmse: 0.8413 - sae: 1829.0306 - sse: 2127.0479 - val_huber_loss: 0.1053 - val_loss: 0.1282 - val_mae: 0.2969 - val_mse: 0.2338 - val_pearson_correlation: 8.6436e-17 - val_r2_keras: -34.3699 - val_rmse: 0.9685 - val_sae: 368.8355 - val_sse: 496.1735 - learning_rate: 0.0057\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0972 - loss: 0.1202 - mae: 0.2845 - mse: 0.2179 - pearson_correlation: 5.6702e-16 - r2_keras: -93.2320 - rmse: 0.8448 - sae: 2501.4136 - sse: 2922.9602\n","Epoch 31: val_loss improved from 0.12806 to 0.12790, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0815 - loss: 0.1106 - mae: 0.2686 - mse: 0.1940 - pearson_correlation: 3.4810e-16 - r2_keras: -77.4273 - rmse: 0.8422 - sae: 1830.8624 - sse: 2131.6985 - val_huber_loss: 0.1049 - val_loss: 0.1279 - val_mae: 0.2962 - val_mse: 0.2330 - val_pearson_correlation: 4.3138e-17 - val_r2_keras: -34.4199 - val_rmse: 0.9692 - val_sae: 368.8912 - val_sse: 496.8745 - learning_rate: 0.0057\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0970 - loss: 0.1200 - mae: 0.2842 - mse: 0.2173 - pearson_correlation: 7.0469e-16 - r2_keras: -93.3174 - rmse: 0.8451 - sae: 2502.6711 - sse: 2925.6091\n","Epoch 32: val_loss did not improve from 0.12790\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0813 - loss: 0.1104 - mae: 0.2683 - mse: 0.1934 - pearson_correlation: 4.6690e-16 - r2_keras: -77.4866 - rmse: 0.8424 - sae: 1831.7120 - sse: 2133.4919 - val_huber_loss: 0.1050 - val_loss: 0.1280 - val_mae: 0.2963 - val_mse: 0.2332 - val_pearson_correlation: -1.0784e-16 - val_r2_keras: -34.4169 - val_rmse: 0.9691 - val_sae: 368.9163 - val_sse: 496.8315 - learning_rate: 0.0057\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0967 - loss: 0.1197 - mae: 0.2836 - mse: 0.2162 - pearson_correlation: 3.8181e-16 - r2_keras: -93.3869 - rmse: 0.8455 - sae: 2503.2207 - sse: 2927.7651\n","Epoch 33: val_loss improved from 0.12790 to 0.12750, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - huber_loss: 0.0810 - loss: 0.1101 - mae: 0.2677 - mse: 0.1925 - pearson_correlation: 3.5608e-16 - r2_keras: -77.5015 - rmse: 0.8424 - sae: 1832.0092 - sse: 2134.5605 - val_huber_loss: 0.1045 - val_loss: 0.1275 - val_mae: 0.2952 - val_mse: 0.2321 - val_pearson_correlation: -4.5521e-16 - val_r2_keras: -34.2956 - val_rmse: 0.9675 - val_sae: 368.0347 - val_sse: 495.1302 - learning_rate: 0.0057\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0964 - loss: 0.1193 - mae: 0.2831 - mse: 0.2152 - pearson_correlation: 6.0408e-16 - r2_keras: -93.3027 - rmse: 0.8451 - sae: 2502.1218 - sse: 2925.1528\n","Epoch 34: val_loss improved from 0.12750 to 0.12746, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - huber_loss: 0.0807 - loss: 0.1098 - mae: 0.2671 - mse: 0.1917 - pearson_correlation: 3.8633e-16 - r2_keras: -77.4858 - rmse: 0.8425 - sae: 1831.4543 - sse: 2133.2930 - val_huber_loss: 0.1045 - val_loss: 0.1275 - val_mae: 0.2950 - val_mse: 0.2319 - val_pearson_correlation: -7.5481e-17 - val_r2_keras: -34.4248 - val_rmse: 0.9692 - val_sae: 368.7085 - val_sse: 496.9433 - learning_rate: 0.0057\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0962 - loss: 0.1192 - mae: 0.2828 - mse: 0.2147 - pearson_correlation: 3.3557e-16 - r2_keras: -93.5310 - rmse: 0.8461 - sae: 2505.4448 - sse: 2932.2346\n","Epoch 35: val_loss did not improve from 0.12746\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0806 - loss: 0.1096 - mae: 0.2668 - mse: 0.1912 - pearson_correlation: 1.9674e-16 - r2_keras: -77.6477 - rmse: 0.8432 - sae: 1833.7079 - sse: 2138.1279 - val_huber_loss: 0.1047 - val_loss: 0.1276 - val_mae: 0.2952 - val_mse: 0.2322 - val_pearson_correlation: 6.4693e-16 - val_r2_keras: -34.4220 - val_rmse: 0.9692 - val_sae: 368.7146 - val_sse: 496.9038 - learning_rate: 0.0057\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0958 - loss: 0.1188 - mae: 0.2821 - mse: 0.2137 - pearson_correlation: 1.5209e-16 - r2_keras: -93.5887 - rmse: 0.8464 - sae: 2505.7236 - sse: 2934.0247\n","Epoch 36: val_loss did not improve from 0.12746\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0803 - loss: 0.1093 - mae: 0.2661 - mse: 0.1903 - pearson_correlation: 7.1584e-17 - r2_keras: -77.7057 - rmse: 0.8436 - sae: 1834.0112 - sse: 2139.5505 - val_huber_loss: 0.1050 - val_loss: 0.1279 - val_mae: 0.2944 - val_mse: 0.2330 - val_pearson_correlation: 2.0411e-16 - val_r2_keras: -34.5067 - val_rmse: 0.9703 - val_sae: 369.3907 - val_sse: 498.0924 - learning_rate: 0.0057\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0957 - loss: 0.1187 - mae: 0.2820 - mse: 0.2132 - pearson_correlation: -1.9453e-16 - r2_keras: -93.6753 - rmse: 0.8467 - sae: 2506.8213 - sse: 2936.7080\n","Epoch 37: val_loss improved from 0.12746 to 0.12743, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0802 - loss: 0.1092 - mae: 0.2660 - mse: 0.1898 - pearson_correlation: -6.2204e-17 - r2_keras: -77.7314 - rmse: 0.8436 - sae: 1834.6356 - sse: 2140.9646 - val_huber_loss: 0.1045 - val_loss: 0.1274 - val_mae: 0.2935 - val_mse: 0.2319 - val_pearson_correlation: 5.3948e-17 - val_r2_keras: -34.4045 - val_rmse: 0.9689 - val_sae: 368.5828 - val_sse: 496.6577 - learning_rate: 0.0057\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0953 - loss: 0.1183 - mae: 0.2812 - mse: 0.2121 - pearson_correlation: 2.4554e-16 - r2_keras: -93.6878 - rmse: 0.8468 - sae: 2507.0312 - sse: 2937.0959\n","Epoch 38: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0799 - loss: 0.1089 - mae: 0.2652 - mse: 0.1889 - pearson_correlation: 2.7032e-16 - r2_keras: -77.7844 - rmse: 0.8440 - sae: 1834.9799 - sse: 2141.7471 - val_huber_loss: 0.1049 - val_loss: 0.1278 - val_mae: 0.2935 - val_mse: 0.2327 - val_pearson_correlation: -1.6077e-16 - val_r2_keras: -34.5739 - val_rmse: 0.9713 - val_sae: 369.5614 - val_sse: 499.0343 - learning_rate: 0.0057\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0952 - loss: 0.1181 - mae: 0.2809 - mse: 0.2116 - pearson_correlation: 8.0368e-17 - r2_keras: -93.9955 - rmse: 0.8482 - sae: 2511.2092 - sse: 2946.6406\n","Epoch 39: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0795 - loss: 0.1086 - mae: 0.2649 - mse: 0.1882 - pearson_correlation: 5.4532e-17 - r2_keras: -78.0871 - rmse: 0.8458 - sae: 1838.2411 - sse: 2149.2551 - val_huber_loss: 0.1048 - val_loss: 0.1277 - val_mae: 0.2938 - val_mse: 0.2325 - val_pearson_correlation: 3.2239e-17 - val_r2_keras: -34.5065 - val_rmse: 0.9703 - val_sae: 369.0831 - val_sse: 498.0888 - learning_rate: 0.0011\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0951 - loss: 0.1180 - mae: 0.2807 - mse: 0.2113 - pearson_correlation: -8.6198e-17 - r2_keras: -93.9640 - rmse: 0.8480 - sae: 2510.7104 - sse: 2945.6636\n","Epoch 40: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0794 - loss: 0.1085 - mae: 0.2647 - mse: 0.1879 - pearson_correlation: -2.2228e-17 - r2_keras: -78.0758 - rmse: 0.8458 - sae: 1837.9421 - sse: 2148.7170 - val_huber_loss: 0.1048 - val_loss: 0.1277 - val_mae: 0.2939 - val_mse: 0.2325 - val_pearson_correlation: 2.2583e-16 - val_r2_keras: -34.4877 - val_rmse: 0.9701 - val_sae: 368.9437 - val_sse: 497.8250 - learning_rate: 0.0011\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0950 - loss: 0.1179 - mae: 0.2806 - mse: 0.2110 - pearson_correlation: 1.6143e-16 - r2_keras: -93.9744 - rmse: 0.8481 - sae: 2510.7100 - sse: 2945.9868\n","Epoch 41: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0793 - loss: 0.1084 - mae: 0.2645 - mse: 0.1877 - pearson_correlation: 1.0953e-16 - r2_keras: -78.0917 - rmse: 0.8459 - sae: 1837.9764 - sse: 2149.0381 - val_huber_loss: 0.1047 - val_loss: 0.1277 - val_mae: 0.2940 - val_mse: 0.2325 - val_pearson_correlation: -1.9367e-16 - val_r2_keras: -34.4742 - val_rmse: 0.9699 - val_sae: 368.8451 - val_sse: 497.6355 - learning_rate: 0.0011\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0949 - loss: 0.1178 - mae: 0.2804 - mse: 0.2108 - pearson_correlation: 3.5562e-16 - r2_keras: -93.9833 - rmse: 0.8481 - sae: 2510.7124 - sse: 2946.2646\n","Epoch 42: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0792 - loss: 0.1083 - mae: 0.2644 - mse: 0.1874 - pearson_correlation: 2.4374e-16 - r2_keras: -78.1059 - rmse: 0.8460 - sae: 1838.0116 - sse: 2149.3196 - val_huber_loss: 0.1047 - val_loss: 0.1277 - val_mae: 0.2939 - val_mse: 0.2325 - val_pearson_correlation: 2.5835e-16 - val_r2_keras: -34.4630 - val_rmse: 0.9697 - val_sae: 368.7639 - val_sse: 497.4783 - learning_rate: 0.0011\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0948 - loss: 0.1178 - mae: 0.2803 - mse: 0.2105 - pearson_correlation: -7.2468e-16 - r2_keras: -93.9885 - rmse: 0.8481 - sae: 2510.6799 - sse: 2946.4258\n","Epoch 43: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0792 - loss: 0.1082 - mae: 0.2642 - mse: 0.1872 - pearson_correlation: -5.8672e-16 - r2_keras: -78.1175 - rmse: 0.8461 - sae: 1838.0245 - sse: 2149.5222 - val_huber_loss: 0.1047 - val_loss: 0.1277 - val_mae: 0.2938 - val_mse: 0.2324 - val_pearson_correlation: -8.6141e-17 - val_r2_keras: -34.4553 - val_rmse: 0.9696 - val_sae: 368.7083 - val_sse: 497.3713 - learning_rate: 0.0011\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0947 - loss: 0.1177 - mae: 0.2802 - mse: 0.2103 - pearson_correlation: 2.2182e-16 - r2_keras: -93.9946 - rmse: 0.8482 - sae: 2510.6704 - sse: 2946.6130\n","Epoch 44: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0791 - loss: 0.1081 - mae: 0.2641 - mse: 0.1870 - pearson_correlation: 1.1275e-16 - r2_keras: -78.1355 - rmse: 0.8462 - sae: 1838.0835 - sse: 2149.8108 - val_huber_loss: 0.1047 - val_loss: 0.1276 - val_mae: 0.2938 - val_mse: 0.2324 - val_pearson_correlation: 1.8308e-16 - val_r2_keras: -34.4516 - val_rmse: 0.9696 - val_sae: 368.6684 - val_sse: 497.3182 - learning_rate: 2.2935e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0947 - loss: 0.1177 - mae: 0.2801 - mse: 0.2102 - pearson_correlation: 5.3429e-16 - r2_keras: -93.9947 - rmse: 0.8482 - sae: 2510.6545 - sse: 2946.6167\n","Epoch 45: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2641 - mse: 0.1870 - pearson_correlation: 3.4575e-16 - r2_keras: -78.1368 - rmse: 0.8462 - sae: 1838.0784 - sse: 2149.8281 - val_huber_loss: 0.1047 - val_loss: 0.1276 - val_mae: 0.2938 - val_mse: 0.2323 - val_pearson_correlation: 1.6156e-16 - val_r2_keras: -34.4489 - val_rmse: 0.9696 - val_sae: 368.6418 - val_sse: 497.2812 - learning_rate: 2.2935e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0947 - loss: 0.1176 - mae: 0.2801 - mse: 0.2102 - pearson_correlation: -5.9280e-16 - r2_keras: -93.9952 - rmse: 0.8482 - sae: 2510.6436 - sse: 2946.6318\n","Epoch 46: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2640 - mse: 0.1869 - pearson_correlation: -3.9805e-16 - r2_keras: -78.1384 - rmse: 0.8462 - sae: 1838.0765 - sse: 2149.8530 - val_huber_loss: 0.1046 - val_loss: 0.1276 - val_mae: 0.2938 - val_mse: 0.2323 - val_pearson_correlation: -6.4630e-17 - val_r2_keras: -34.4468 - val_rmse: 0.9695 - val_sae: 368.6217 - val_sse: 497.2516 - learning_rate: 2.2935e-04\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0947 - loss: 0.1176 - mae: 0.2801 - mse: 0.2101 - pearson_correlation: 1.2087e-16 - r2_keras: -93.9957 - rmse: 0.8482 - sae: 2510.6328 - sse: 2946.6465\n","Epoch 47: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2640 - mse: 0.1869 - pearson_correlation: 1.0716e-16 - r2_keras: -78.1399 - rmse: 0.8462 - sae: 1838.0747 - sse: 2149.8770 - val_huber_loss: 0.1046 - val_loss: 0.1276 - val_mae: 0.2938 - val_mse: 0.2323 - val_pearson_correlation: 2.2621e-16 - val_r2_keras: -34.4460 - val_rmse: 0.9695 - val_sae: 368.6095 - val_sse: 497.2402 - learning_rate: 2.2935e-04\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0947 - loss: 0.1176 - mae: 0.2801 - mse: 0.2101 - pearson_correlation: -2.1088e-16 - r2_keras: -93.9968 - rmse: 0.8482 - sae: 2510.6299 - sse: 2946.6812\n","Epoch 48: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2640 - mse: 0.1868 - pearson_correlation: -5.5171e-17 - r2_keras: -78.1417 - rmse: 0.8463 - sae: 1838.0768 - sse: 2149.9114 - val_huber_loss: 0.1046 - val_loss: 0.1276 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -1.0772e-17 - val_r2_keras: -34.4454 - val_rmse: 0.9695 - val_sae: 368.6007 - val_sse: 497.2322 - learning_rate: 2.2935e-04\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2101 - pearson_correlation: 2.6424e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6316 - sse: 2946.7283\n","Epoch 49: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2639 - mse: 0.1868 - pearson_correlation: 1.2587e-16 - r2_keras: -78.1449 - rmse: 0.8463 - sae: 1838.0886 - sse: 2149.9688 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -1.5082e-16 - val_r2_keras: -34.4447 - val_rmse: 0.9695 - val_sae: 368.5925 - val_sse: 497.2217 - learning_rate: 4.5870e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2101 - pearson_correlation: 7.5864e-17 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6282 - sse: 2946.7283\n","Epoch 50: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2639 - mse: 0.1868 - pearson_correlation: 7.6196e-17 - r2_keras: -78.1451 - rmse: 0.8463 - sae: 1838.0874 - sse: 2149.9717 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: 1.1850e-16 - val_r2_keras: -34.4441 - val_rmse: 0.9695 - val_sae: 368.5865 - val_sse: 497.2136 - learning_rate: 4.5870e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 3.7032e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6255 - sse: 2946.7285\n","Epoch 51: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2639 - mse: 0.1868 - pearson_correlation: 2.7440e-16 - r2_keras: -78.1454 - rmse: 0.8463 - sae: 1838.0867 - sse: 2149.9746 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -2.1546e-17 - val_r2_keras: -34.4436 - val_rmse: 0.9695 - val_sae: 368.5819 - val_sse: 497.2071 - learning_rate: 4.5870e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 1.2858e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6221 - sse: 2946.7285\n","Epoch 52: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2639 - mse: 0.1868 - pearson_correlation: 9.8057e-17 - r2_keras: -78.1456 - rmse: 0.8463 - sae: 1838.0854 - sse: 2149.9775 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: 1.0773e-16 - val_r2_keras: -34.4432 - val_rmse: 0.9695 - val_sae: 368.5785 - val_sse: 497.2017 - learning_rate: 4.5870e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 4.9504e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6196 - sse: 2946.7297\n","Epoch 53: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0790 - loss: 0.1081 - mae: 0.2639 - mse: 0.1868 - pearson_correlation: 2.9018e-16 - r2_keras: -78.1459 - rmse: 0.8463 - sae: 1838.0848 - sse: 2149.9810 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -4.5249e-16 - val_r2_keras: -34.4429 - val_rmse: 0.9695 - val_sae: 368.5755 - val_sse: 497.1970 - learning_rate: 4.5870e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 4.5518e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6165 - sse: 2946.7295\n","Epoch 54: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 3.1294e-16 - r2_keras: -78.1463 - rmse: 0.8463 - sae: 1838.0850 - sse: 2149.9863 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: 8.6189e-17 - val_r2_keras: -34.4428 - val_rmse: 0.9695 - val_sae: 368.5741 - val_sse: 497.1956 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 6.5642e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6157 - sse: 2946.7295\n","Epoch 55: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 4.7841e-16 - r2_keras: -78.1464 - rmse: 0.8463 - sae: 1838.0847 - sse: 2149.9868 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -2.5857e-16 - val_r2_keras: -34.4427 - val_rmse: 0.9695 - val_sae: 368.5729 - val_sse: 497.1944 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 2.6810e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6152 - sse: 2946.7297\n","Epoch 56: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 1.4552e-16 - r2_keras: -78.1464 - rmse: 0.8463 - sae: 1838.0846 - sse: 2149.9875 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -2.3702e-16 - val_r2_keras: -34.4426 - val_rmse: 0.9695 - val_sae: 368.5721 - val_sse: 497.1933 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 5.8827e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6143 - sse: 2946.7290\n","Epoch 57: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 3.6846e-16 - r2_keras: -78.1465 - rmse: 0.8463 - sae: 1838.0841 - sse: 2149.9878 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -8.6189e-17 - val_r2_keras: -34.4426 - val_rmse: 0.9695 - val_sae: 368.5714 - val_sse: 497.1924 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -2.8674e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6138 - sse: 2946.7295\n","Epoch 58: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -1.5416e-16 - r2_keras: -78.1465 - rmse: 0.8463 - sae: 1838.0841 - sse: 2149.9888 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: -1.9393e-16 - val_r2_keras: -34.4425 - val_rmse: 0.9695 - val_sae: 368.5708 - val_sse: 497.1915 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -7.8500e-16 - r2_keras: -93.9983 - rmse: 0.8482 - sae: 2510.6130 - sse: 2946.7292\n","Epoch 59: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -5.6223e-16 - r2_keras: -78.1466 - rmse: 0.8463 - sae: 1838.0837 - sse: 2149.9890 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: 1.1851e-16 - val_r2_keras: -34.4425 - val_rmse: 0.9695 - val_sae: 368.5705 - val_sse: 497.1907 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 4.4233e-16 - r2_keras: -93.9984 - rmse: 0.8482 - sae: 2510.6133 - sse: 2946.7314\n","Epoch 60: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 2.4460e-16 - r2_keras: -78.1467 - rmse: 0.8463 - sae: 1838.0841 - sse: 2149.9910 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2938 - val_mse: 0.2322 - val_pearson_correlation: 4.6327e-16 - val_r2_keras: -34.4424 - val_rmse: 0.9695 - val_sae: 368.5699 - val_sse: 497.1898 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -6.2363e-17 - r2_keras: -93.9984 - rmse: 0.8482 - sae: 2510.6133 - sse: 2946.7317\n","Epoch 61: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -3.5882e-17 - r2_keras: -78.1467 - rmse: 0.8463 - sae: 1838.0844 - sse: 2149.9917 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.0774e-17 - val_r2_keras: -34.4424 - val_rmse: 0.9695 - val_sae: 368.5698 - val_sse: 497.1898 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 7.0721e-17 - r2_keras: -93.9984 - rmse: 0.8482 - sae: 2510.6128 - sse: 2946.7329\n","Epoch 62: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 6.3498e-18 - r2_keras: -78.1468 - rmse: 0.8463 - sae: 1838.0841 - sse: 2149.9929 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.4424 - val_rmse: 0.9695 - val_sae: 368.5696 - val_sse: 497.1896 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -6.9885e-16 - r2_keras: -93.9985 - rmse: 0.8482 - sae: 2510.6138 - sse: 2946.7358\n","Epoch 63: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -5.6552e-16 - r2_keras: -78.1469 - rmse: 0.8463 - sae: 1838.0848 - sse: 2149.9954 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -8.6190e-17 - val_r2_keras: -34.4423 - val_rmse: 0.9695 - val_sae: 368.5690 - val_sse: 497.1884 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -4.0504e-17 - r2_keras: -93.9986 - rmse: 0.8482 - sae: 2510.6135 - sse: 2946.7366\n","Epoch 64: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 1.2101e-16 - r2_keras: -78.1469 - rmse: 0.8463 - sae: 1838.0850 - sse: 2149.9963 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -1.9393e-16 - val_r2_keras: -34.4423 - val_rmse: 0.9695 - val_sae: 368.5688 - val_sse: 497.1882 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -5.0211e-16 - r2_keras: -93.9986 - rmse: 0.8482 - sae: 2510.6128 - sse: 2946.7363\n","Epoch 65: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -3.4044e-16 - r2_keras: -78.1469 - rmse: 0.8463 - sae: 1838.0846 - sse: 2149.9963 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.8316e-16 - val_r2_keras: -34.4423 - val_rmse: 0.9695 - val_sae: 368.5686 - val_sse: 497.1879 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -3.5232e-16 - r2_keras: -93.9987 - rmse: 0.8482 - sae: 2510.6143 - sse: 2946.7402\n","Epoch 66: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -2.1495e-16 - r2_keras: -78.1471 - rmse: 0.8463 - sae: 1838.0857 - sse: 2149.9995 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -3.2322e-16 - val_r2_keras: -34.4422 - val_rmse: 0.9695 - val_sae: 368.5680 - val_sse: 497.1866 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -2.6874e-16 - r2_keras: -93.9987 - rmse: 0.8482 - sae: 2510.6135 - sse: 2946.7407\n","Epoch 67: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -1.0610e-16 - r2_keras: -78.1471 - rmse: 0.8463 - sae: 1838.0854 - sse: 2150.0002 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -1.8316e-16 - val_r2_keras: -34.4422 - val_rmse: 0.9695 - val_sae: 368.5677 - val_sse: 497.1864 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 9.3736e-16 - r2_keras: -93.9987 - rmse: 0.8482 - sae: 2510.6128 - sse: 2946.7412\n","Epoch 68: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 5.7842e-16 - r2_keras: -78.1472 - rmse: 0.8463 - sae: 1838.0851 - sse: 2150.0010 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.0774e-17 - val_r2_keras: -34.4421 - val_rmse: 0.9695 - val_sae: 368.5676 - val_sse: 497.1861 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 4.9247e-16 - r2_keras: -93.9989 - rmse: 0.8482 - sae: 2510.6147 - sse: 2946.7456\n","Epoch 69: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 3.6531e-16 - r2_keras: -78.1473 - rmse: 0.8463 - sae: 1838.0865 - sse: 2150.0042 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.9393e-16 - val_r2_keras: -34.4421 - val_rmse: 0.9695 - val_sae: 368.5671 - val_sse: 497.1855 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -5.0147e-17 - r2_keras: -93.9988 - rmse: 0.8482 - sae: 2510.6138 - sse: 2946.7446\n","Epoch 70: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 6.9034e-17 - r2_keras: -78.1473 - rmse: 0.8463 - sae: 1838.0859 - sse: 2150.0039 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -2.1548e-17 - val_r2_keras: -34.4420 - val_rmse: 0.9695 - val_sae: 368.5668 - val_sse: 497.1849 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -1.8644e-17 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6152 - sse: 2946.7490\n","Epoch 71: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 2.5520e-17 - r2_keras: -78.1474 - rmse: 0.8463 - sae: 1838.0870 - sse: 2150.0073 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.4420 - val_rmse: 0.9695 - val_sae: 368.5663 - val_sse: 497.1837 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 3.8124e-16 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6143 - sse: 2946.7490\n","Epoch 72: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 3.2532e-16 - r2_keras: -78.1475 - rmse: 0.8463 - sae: 1838.0865 - sse: 2150.0078 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 4.3096e-17 - val_r2_keras: -34.4419 - val_rmse: 0.9695 - val_sae: 368.5661 - val_sse: 497.1835 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 2.1473e-16 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6143 - sse: 2946.7507\n","Epoch 73: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 2.0008e-16 - r2_keras: -78.1475 - rmse: 0.8463 - sae: 1838.0868 - sse: 2150.0093 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 3.2322e-17 - val_r2_keras: -34.4419 - val_rmse: 0.9695 - val_sae: 368.5659 - val_sse: 497.1832 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -2.3530e-16 - r2_keras: -93.9991 - rmse: 0.8482 - sae: 2510.6152 - sse: 2946.7532\n","Epoch 74: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -1.6636e-16 - r2_keras: -78.1475 - rmse: 0.8463 - sae: 1838.0870 - sse: 2150.0100 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -4.3096e-17 - val_r2_keras: -34.4416 - val_rmse: 0.9695 - val_sae: 368.5637 - val_sse: 497.1788 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -5.2140e-16 - r2_keras: -93.9988 - rmse: 0.8482 - sae: 2510.6108 - sse: 2946.7441\n","Epoch 75: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -3.5234e-16 - r2_keras: -78.1474 - rmse: 0.8463 - sae: 1838.0844 - sse: 2150.0044 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 2.6935e-16 - val_r2_keras: -34.4416 - val_rmse: 0.9695 - val_sae: 368.5633 - val_sse: 497.1779 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 5.6576e-16 - r2_keras: -93.9988 - rmse: 0.8482 - sae: 2510.6104 - sse: 2946.7439\n","Epoch 76: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 4.3125e-16 - r2_keras: -78.1474 - rmse: 0.8463 - sae: 1838.0841 - sse: 2150.0046 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 2.1548e-17 - val_r2_keras: -34.4415 - val_rmse: 0.9695 - val_sae: 368.5632 - val_sse: 497.1777 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -1.3630e-16 - r2_keras: -93.9989 - rmse: 0.8482 - sae: 2510.6113 - sse: 2946.7471\n","Epoch 77: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -2.0282e-16 - r2_keras: -78.1475 - rmse: 0.8463 - sae: 1838.0850 - sse: 2150.0071 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.5084e-16 - val_r2_keras: -34.4415 - val_rmse: 0.9695 - val_sae: 368.5629 - val_sse: 497.1774 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 2.4109e-16 - r2_keras: -93.9989 - rmse: 0.8482 - sae: 2510.6108 - sse: 2946.7478\n","Epoch 78: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 1.9583e-16 - r2_keras: -78.1475 - rmse: 0.8463 - sae: 1838.0847 - sse: 2150.0078 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 3.1245e-16 - val_r2_keras: -34.4415 - val_rmse: 0.9695 - val_sae: 368.5627 - val_sse: 497.1770 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -6.7762e-16 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6121 - sse: 2946.7517\n","Epoch 79: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -5.4662e-16 - r2_keras: -78.1476 - rmse: 0.8463 - sae: 1838.0857 - sse: 2150.0110 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -4.3097e-16 - val_r2_keras: -34.4414 - val_rmse: 0.9695 - val_sae: 368.5621 - val_sse: 497.1757 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -5.1497e-16 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6108 - sse: 2946.7505\n","Epoch 80: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -3.5660e-16 - r2_keras: -78.1477 - rmse: 0.8463 - sae: 1838.0851 - sse: 2150.0107 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.1852e-16 - val_r2_keras: -34.4414 - val_rmse: 0.9695 - val_sae: 368.5618 - val_sse: 497.1754 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 2.2952e-16 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6113 - sse: 2946.7517\n","Epoch 81: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 2.6876e-16 - r2_keras: -78.1477 - rmse: 0.8463 - sae: 1838.0856 - sse: 2150.0117 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.9394e-16 - val_r2_keras: -34.4413 - val_rmse: 0.9695 - val_sae: 368.5616 - val_sse: 497.1750 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 1.6394e-16 - r2_keras: -93.9992 - rmse: 0.8482 - sae: 2510.6118 - sse: 2946.7549\n","Epoch 82: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 1.2827e-16 - r2_keras: -78.1478 - rmse: 0.8463 - sae: 1838.0859 - sse: 2150.0144 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 2.2626e-16 - val_r2_keras: -34.4413 - val_rmse: 0.9695 - val_sae: 368.5613 - val_sse: 497.1746 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 4.6932e-17 - r2_keras: -93.9992 - rmse: 0.8482 - sae: 2510.6116 - sse: 2946.7559\n","Epoch 83: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 5.8801e-17 - r2_keras: -78.1479 - rmse: 0.8463 - sae: 1838.0861 - sse: 2150.0154 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 1.0774e-16 - val_r2_keras: -34.4412 - val_rmse: 0.9695 - val_sae: 368.5608 - val_sse: 497.1735 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 1.6587e-16 - r2_keras: -93.9992 - rmse: 0.8482 - sae: 2510.6108 - sse: 2946.7559\n","Epoch 84: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 5.6502e-17 - r2_keras: -78.1478 - rmse: 0.8463 - sae: 1838.0853 - sse: 2150.0144 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -1.0774e-17 - val_r2_keras: -34.4409 - val_rmse: 0.9694 - val_sae: 368.5587 - val_sse: 497.1693 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -3.8767e-16 - r2_keras: -93.9989 - rmse: 0.8482 - sae: 2510.6079 - sse: 2946.7483\n","Epoch 85: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -2.4422e-16 - r2_keras: -78.1477 - rmse: 0.8463 - sae: 1838.0834 - sse: 2150.0098 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: -2.8014e-16 - val_r2_keras: -34.4409 - val_rmse: 0.9694 - val_sae: 368.5585 - val_sse: 497.1690 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: -5.4133e-16 - r2_keras: -93.9990 - rmse: 0.8482 - sae: 2510.6074 - sse: 2946.7493\n","Epoch 86: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: -3.1535e-16 - r2_keras: -78.1477 - rmse: 0.8463 - sae: 1838.0831 - sse: 2150.0107 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 2.0471e-16 - val_r2_keras: -34.4409 - val_rmse: 0.9694 - val_sae: 368.5584 - val_sse: 497.1688 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0946 - loss: 0.1176 - mae: 0.2800 - mse: 0.2100 - pearson_correlation: 1.0801e-16 - r2_keras: -93.9991 - rmse: 0.8482 - sae: 2510.6082 - sse: 2946.7524\n","Epoch 87: val_loss did not improve from 0.12743\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0790 - loss: 0.1080 - mae: 0.2639 - mse: 0.1867 - pearson_correlation: 2.7416e-17 - r2_keras: -78.1478 - rmse: 0.8463 - sae: 1838.0839 - sse: 2150.0134 - val_huber_loss: 0.1046 - val_loss: 0.1275 - val_mae: 0.2937 - val_mse: 0.2322 - val_pearson_correlation: 4.3098e-17 - val_r2_keras: -34.4409 - val_rmse: 0.9694 - val_sae: 368.5581 - val_sse: 497.1684 - learning_rate: 1.0000e-05\n"]}],"source":["# Función que entrena el modelo y devuelve la pérdida final, el historial y el modelo\n","def train_model_with_params(units_1, units_2, learning_rate):\n","    model = Sequential([\n","        Dense(int(units_1), input_dim=X_train.shape[1], kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        Activation('relu'),  # Cambiar LeakyReLU por relu\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(units_2), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        Activation('relu'),  # Cambiar LeakyReLU por relu\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(1, activation='linear')\n","    ])\n","\n","    # Usar Huber como pérdida y agregar Huber Loss como métrica\n","    model.compile(optimizer=Adagrad(learning_rate),\n","                  loss=tf.keras.losses.Huber(), #----------------------------\n","                  metrics=['mae', 'mse', rmse, sse, sae, r2_keras, pearson_correlation, tf.keras.losses.Huber(name='huber_loss')])\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True) #----------------50\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n","    checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n","\n","    history = model.fit(X_train, y_train,\n","                        validation_data=(X_val, y_val),\n","                        epochs=1000,   #---------------1000\n","                        batch_size=64,\n","                        callbacks=[early_stopping, reduce_lr, checkpoint],\n","                        verbose=1)\n","\n","    return -history.history['val_loss'][-1], history, model\n","\n","# Función solo para la optimización bayesiana (retorna solo la pérdida)\n","def train_model_for_optimization(units_1, units_2, learning_rate):\n","\n","    val_loss, _, _ = train_model_with_params(units_1, units_2, learning_rate)\n","    return val_loss\n","\n","# Definir los límites para la optimización\n","pbounds = {\n","    'units_1': (5, 100),\n","    'units_2': (5, 100),\n","    'learning_rate': (0.0001, 0.1)\n","}\n","\n","# Crear una instancia de BayesianOptimization con semilla\n","optimizer = BayesianOptimization(\n","    f=train_model_for_optimization,\n","    pbounds=pbounds,\n","    random_state=42,  # Fijar la semilla para la optimización bayesiana\n","    verbose=2\n",")\n","\n","# Ejecutar la optimización\n","optimizer.maximize(init_points=2, n_iter=20) #---------------20\n","\n","# Recuperar los mejores hiperparámetros\n","best_params = optimizer.max['params']\n","\n","# Redondear los valores de las unidades a enteros para las capas\n","best_params['units_1'] = int(round(best_params['units_1']))\n","best_params['units_2'] = int(round(best_params['units_2']))\n","\n","# Imprimir los mejores hiperparámetros encontrados\n","print(\"Mejores parámetros encontrados:\")\n","for param, value in best_params.items():\n","    print(f\"  {param}: {value}\")\n","\n","# Entrenar el modelo con los mejores hiperparámetros encontrados y obtener el historial y el modelo\n","val_loss, history, model = train_model_with_params(\n","    best_params['units_1'],\n","    best_params['units_2'],\n","    best_params['learning_rate']\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"LFLJLT-xqlOu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1726457124376,"user_tz":300,"elapsed":3,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}},"outputId":"9635d218-a5cc-4ba8-fc1f-ea97d85380ce"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 4 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Métricas de entrenamiento:\n","MSE: 0.1937456658429946\n","RMSE: 0.4401654982424163\n","MAE: 0.25587258746379\n","R^2: 0.5833988275134265\n","Correlación de Pearson: -5.325510724851005e-16\n","Correlación de Spearman: 0.7636353828820924\n","SSE: 6125.120895662251\n","SAE: 5219.971268167099\n","Media del error: 0.012022126337275871\n","Desviación estándar del error: 0.8506014760655716\n","Huber Loss (Entrenamiento): 0.07113391160964966\n","\n","Métricas de validación:\n","MSE: 0.23189784172164982\n","RMSE: 0.4815577241843908\n","MAE: 0.2935070658695597\n","R^2: 0.6197883000318056\n","Correlación de Pearson: -1.0789535527280803e-16\n","Correlación de Spearman: 0.7460474308300395\n","SSE: 496.657710711944\n","SAE: 368.5827803811733\n","Media del error: 0.02796332882857696\n","Desviación estándar del error: 0.9685450475652716\n","Huber Loss (Validación): 0.10456636548042297\n","El punto de convergencia (mejor epoch): 37\n"]}],"source":["# Graficar las curvas de aprendizaje (entrenamiento y validación)\n","plt.figure(figsize=(12, 8))\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(history.history['loss'], label='Entrenamiento')\n","plt.plot(history.history['val_loss'], label='Validación')\n","plt.title('Pérdida (Loss - Huber) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Pérdida (Loss)')\n","plt.legend()\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(history.history['huber_loss'], label='Huber Loss Entrenamiento')\n","plt.plot(history.history['val_huber_loss'], label='Huber Loss Validación')\n","plt.title('Huber Loss durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Huber Loss')\n","plt.legend()\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(history.history['mae'], label='Entrenamiento')\n","plt.plot(history.history['val_mae'], label='Validación')\n","plt.title('Error Absoluto Medio (MAE) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MAE')\n","plt.legend()\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(history.history['mse'], label='Entrenamiento')\n","plt.plot(history.history['val_mse'], label='Validación')\n","plt.title('Error Cuadrático Medio (MSE) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MSE')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Graficar los datos entrenados vs reales y validados vs reales\n","y_train_pred = model.predict(X_train)\n","y_val_pred = model.predict(X_val)\n","\n","plt.figure(figsize=(12, 6))\n","\n","# Gráfico de datos de entrenamiento\n","plt.subplot(1, 2, 1)\n","plt.scatter(y_train, y_train_pred, alpha=0.3)\n","plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Datos de Entrenamiento')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","# Gráfico de datos de validación\n","plt.subplot(1, 2, 2)\n","plt.scatter(y_val, y_val_pred, alpha=0.3)\n","plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Datos de Validación')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Función para calcular la media y desviación estándar\n","def calcular_media_desviacion(y_true, y_pred):\n","    diferencia = y_true - y_pred\n","    media = np.mean(diferencia)\n","    desviacion = np.std(diferencia)\n","    return media, desviacion\n","\n","# Evaluar el modelo final en el conjunto de entrenamiento\n","mse_train = mean_squared_error(y_train, y_train_pred)\n","mae_train = mean_absolute_error(y_train, y_train_pred)\n","rmse_train = np.sqrt(mse_train)\n","r2_train = r2_score(y_train, y_train_pred)\n","pearson_train = pearson_correlation(y_train, y_train_pred).numpy()\n","spearman_train, _ = spearmanr(y_train, y_train_pred)  # Correlación de Spearman\n","sse_train = np.sum((y_train - y_train_pred) ** 2)\n","sae_train = np.sum(np.abs(y_train - y_train_pred))\n","media_train, desviacion_train = calcular_media_desviacion(y_train, y_train_pred)\n","huber_loss_train = history.history['huber_loss'][-1]\n","\n","print(\"\\nMétricas de entrenamiento:\")\n","print(f\"MSE: {mse_train}\")\n","print(f\"RMSE: {rmse_train}\")\n","print(f\"MAE: {mae_train}\")\n","print(f\"R^2: {r2_train}\")\n","print(f\"Correlación de Pearson: {pearson_train}\")\n","print(f\"Correlación de Spearman: {spearman_train}\")\n","print(f\"SSE: {sse_train}\")\n","print(f\"SAE: {sae_train}\")\n","print(f\"Media del error: {media_train}\")\n","print(f\"Desviación estándar del error: {desviacion_train}\")\n","print(f\"Huber Loss (Entrenamiento): {huber_loss_train}\")\n","\n","# Evaluar el modelo final en el conjunto de validación\n","mse_val = mean_squared_error(y_val, y_val_pred)\n","mae_val = mean_absolute_error(y_val, y_val_pred)\n","rmse_val = np.sqrt(mse_val)\n","r2_val = r2_score(y_val, y_val_pred)\n","pearson_val = pearson_correlation(y_val, y_val_pred).numpy()\n","spearman_val, _ = spearmanr(y_val, y_val_pred)  # Correlación de Spearman\n","sse_val = np.sum((y_val - y_val_pred) ** 2)\n","sae_val = np.sum(np.abs(y_val - y_val_pred))\n","media_val, desviacion_val = calcular_media_desviacion(y_val, y_val_pred)\n","huber_loss_val = history.history['val_huber_loss'][-1]\n","\n","print(\"\\nMétricas de validación:\")\n","print(f\"MSE: {mse_val}\")\n","print(f\"RMSE: {rmse_val}\")\n","print(f\"MAE: {mae_val}\")\n","print(f\"R^2: {r2_val}\")\n","print(f\"Correlación de Pearson: {pearson_val}\")\n","print(f\"Correlación de Spearman: {spearman_val}\")\n","print(f\"SSE: {sse_val}\")\n","print(f\"SAE: {sae_val}\")\n","print(f\"Media del error: {media_val}\")\n","print(f\"Desviación estándar del error: {desviacion_val}\")\n","print(f\"Huber Loss (Validación): {huber_loss_val}\")\n","\n","# Imprimir la época en la que se alcanzó la mejor validación\n","best_epoch = np.argmin(history.history['val_loss']) + 1\n","print(f\"El punto de convergencia (mejor epoch): {best_epoch}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"K71LbvUpoBQT","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1726457124418,"user_tz":300,"elapsed":1,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}},"outputId":"7cc9cc0d-ea1a-4e94-d54b-3bd1d3f67aae"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ee0eafa7880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ee120270ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 4 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Simulación de cross_val_score (MSE): 0.26940061348149574 ± 0.13823978773133297\n","Simulación de cross_val_score (RMSE): 0.5026125271111992 ± 0.12954250681683532\n","Simulación de cross_val_score (MAE): 0.3297431383364673 ± 0.0820655213269347\n","SSE promedio: 398.12682963988357\n","SAE promedio: 325.25219695139333\n","R^2 promedio: 0.4376541672590828, Desviación estándar: 0.21550805280359162\n","Correlación de Pearson promedio: -1.5165879526110226e-16, Desviación estándar: 2.377823474686494e-16\n","Correlación de Spearman promedio: 0.6551869839213611, Desviación estándar: 0.16835803949493736\n","Huber Loss promedio: 0.07143292650580406, Desviación estándar: 0.02024615209542662\n","El punto de convergencia (mejor epoch): 40\n"]}],"source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from scipy.stats import spearmanr\n","import numpy as np\n","\n","# Definir el número de pliegues (k) para la validación cruzada\n","k = 5\n","\n","# Crear un objeto KFold\n","kf = KFold(n_splits=k, shuffle=True, random_state=42)\n","\n","# Inicializar listas para almacenar las métricas en cada pliegue\n","mse_scores = []\n","mae_scores = []\n","sse_scores = []\n","sae_scores = []\n","r2_scores = []\n","pearson_scores = []\n","rmse_scores = []\n","spearman_scores = []\n","huber_loss_scores = []\n","\n","# Iterar sobre los pliegues\n","for train_index, val_index in kf.split(X):\n","    X_train, X_val = X[train_index], X[val_index]\n","    y_train, y_val = y[train_index], y[val_index]\n","\n","    # Crear y entrenar el modelo con los datos del pliegue actual\n","    model = Sequential([\n","        Dense(int(best_params['units_1']), input_dim=X_train.shape[1], kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        Activation('relu'),  # Cambiar LeakyReLU por relu\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(best_params['units_2']), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        Activation('relu'),  # Cambiar LeakyReLU por relu\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(1, activation='linear')\n","    ])\n","\n","    # Función personalizada para calcular SSE\n","    def sse(y_true, y_pred):\n","        return tf.reduce_sum(tf.square(y_true - y_pred))\n","\n","    # Función personalizada para calcular SAE\n","    def sae(y_true, y_pred):\n","        return tf.reduce_sum(tf.abs(y_true - y_pred))\n","\n","    # Función personalizada para calcular el coeficiente de determinación R^2\n","    def r2_keras(y_true, y_pred):\n","        ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n","        ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n","        return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n","\n","    # Función personalizada para calcular el coeficiente de correlación de Pearson\n","    def pearson_correlation(y_true, y_pred):\n","        y_true = tf.cast(y_true, tf.float64)  # Cast y_true to float64\n","        y_pred = tf.cast(y_pred, tf.float64)  # Cast y_pred to float64\n","        x = y_true - tf.reduce_mean(y_true)\n","        y = y_pred - tf.reduce_mean(y_pred)\n","        r_num = tf.reduce_sum(x * y)\n","        r_den = tf.sqrt(tf.reduce_sum(tf.square(x)) * tf.reduce_sum(tf.square(y)))\n","        return r_num / (r_den + tf.keras.backend.epsilon())\n","\n","    model.compile(optimizer=Adagrad(best_params['learning_rate']),#------------------------------------\n","                  loss=tf.keras.losses.Huber(),                      #---------------------\n","                  metrics=['mae', 'mse', sse, sae, r2_keras, pearson_correlation, tf.keras.losses.Huber(name='huber_loss')])\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True) #-----------------------50\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n","\n","    history = model.fit(X_train, y_train,\n","                        validation_data=(X_val, y_val),\n","                        epochs=1000, #--------------------------1000\n","                        batch_size=64,\n","                        callbacks=[early_stopping, reduce_lr],\n","                        verbose=0)\n","\n","    # Predecir con el modelo en el conjunto de validación\n","    y_pred = model.predict(X_val)\n","\n","    # Calcular las métricas de error\n","    mse = mean_squared_error(y_val, y_pred)\n","    rmse = np.sqrt(mse)\n","    mae = mean_absolute_error(y_val, y_pred)\n","    sse = np.sum((y_val - y_pred) ** 2)\n","    sae = np.sum(np.abs(y_val - y_pred))\n","    r2 = r2_score(y_val, y_pred)\n","    pearson = pearson_correlation(y_val, y_pred).numpy()\n","    spearman, _ = spearmanr(y_val, y_pred)\n","    huber_loss = history.history['huber_loss'][-1]\n","\n","    # Almacenar las métricas en las listas\n","    mse_scores.append(mse)\n","    rmse_scores.append(rmse)\n","    mae_scores.append(mae)\n","    sse_scores.append(sse)\n","    sae_scores.append(sae)\n","    r2_scores.append(r2)\n","    pearson_scores.append(pearson)\n","    spearman_scores.append(spearman)\n","    huber_loss_scores.append(huber_loss)\n","\n","import matplotlib.pyplot as plt\n","\n","# Graficar las curvas de aprendizaje (pérdida, huber_loss, mse, mae)\n","plt.figure(figsize=(12, 8))\n","\n","# Pérdida (Loss)\n","plt.subplot(2, 2, 1)\n","plt.plot(history.history['loss'], label='Entrenamiento')\n","plt.plot(history.history['val_loss'], label='Prueba')\n","plt.title('Pérdida (Loss) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Pérdida (Loss)')\n","plt.legend()\n","\n","# Huber Loss\n","plt.subplot(2, 2, 2)\n","plt.plot(history.history['huber_loss'], label='Huber Loss Entrenamiento')\n","plt.plot(history.history['val_huber_loss'], label='Huber Loss Prueba')\n","plt.title('Huber Loss durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Huber Loss')\n","plt.legend()\n","\n","# MSE\n","plt.subplot(2, 2, 3)\n","plt.plot(history.history['mse'], label='Entrenamiento')\n","plt.plot(history.history['val_mse'], label='Prueba')\n","plt.title('MSE durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MSE')\n","plt.legend()\n","\n","# MAE\n","plt.subplot(2, 2, 4)\n","plt.plot(history.history['mae'], label='Entrenamiento')\n","plt.plot(history.history['val_mae'], label='Prueba')\n","plt.title('MAE durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MAE')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Gráfico de predicciones en los datos de entrenamiento\n","y_train_pred = model.predict(X_train)\n","y_val_pred = model.predict(X_val)\n","\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.scatter(y_train, y_train_pred, alpha=0.3)\n","plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Entrenamiento')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","plt.subplot(1, 2, 2)\n","plt.scatter(y_val, y_val_pred, alpha=0.3)\n","plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Prueba')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Calcular estadísticas de las métricas\n","mse_mean = np.mean(mse_scores)\n","mse_std = np.std(mse_scores)\n","rmse_mean = np.mean(rmse_scores)\n","rmse_std = np.std(rmse_scores)\n","mae_mean = np.mean(mae_scores)\n","mae_std = np.std(mae_scores)\n","sse_mean = np.mean(sse_scores)\n","sae_mean = np.mean(sae_scores)\n","r2_mean = np.mean(r2_scores)\n","r2_std = np.std(r2_scores)\n","pearson_mean = np.mean(pearson_scores)\n","pearson_std = np.std(pearson_scores)\n","spearman_mean = np.mean(spearman_scores)\n","spearman_std = np.std(spearman_scores)\n","huber_loss_mean = np.mean(huber_loss_scores)\n","huber_loss_std = np.std(huber_loss_scores)\n","\n","# Simular cross_val_score al imprimir el promedio de las métricas\n","print(f\"Simulación de cross_val_score (MSE): {mse_mean} ± {mse_std}\")\n","print(f\"Simulación de cross_val_score (RMSE): {rmse_mean} ± {rmse_std}\")\n","print(f\"Simulación de cross_val_score (MAE): {mae_mean} ± {mae_std}\")\n","print(f\"SSE promedio: {sse_mean}\")\n","print(f\"SAE promedio: {sae_mean}\")\n","print(f\"R^2 promedio: {r2_mean}, Desviación estándar: {r2_std}\")\n","print(f\"Correlación de Pearson promedio: {pearson_mean}, Desviación estándar: {pearson_std}\")\n","print(f\"Correlación de Spearman promedio: {spearman_mean}, Desviación estándar: {spearman_std}\")\n","print(f\"Huber Loss promedio: {huber_loss_mean}, Desviación estándar: {huber_loss_std}\")\n","\n","# Imprimir la época en la que se alcanzó la mejor validación\n","best_epoch = np.argmin(history.history['val_loss']) + 1\n","print(f\"El punto de convergencia (mejor epoch): {best_epoch}\")"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1uuz-in9_iet5aTcVbBxDcGWjojPI91-5","timestamp":1726071776729},{"file_id":"1BnNK3Cu3WYpBskHb-k_8C58VCXRLRAuY","timestamp":1726013212523},{"file_id":"1OsI0BYdUccRJYaRJTVEnfZ9FC1fPloSq","timestamp":1725916121177},{"file_id":"1EATYBn5pRBQR-y6UtnACmeBPxL8IJfMZ","timestamp":1725907861504},{"file_id":"1r_JM6X0nvIs1tPxWdSL2ks_3znzQkbU3","timestamp":1725900803257},{"file_id":"1q_AARXwxesxS8p5h5DHxPu87f4W90Piu","timestamp":1725671031145},{"file_id":"1Iu7gaS-rMsag8yv6B7u5GyAGYgzlNMQo","timestamp":1725668219370},{"file_id":"1lc3MJOj5LnHhLKbPODnyWxrF2Qy18W40","timestamp":1725653291124},{"file_id":"1T8NuI3Vdm1GKDP6FHv5YfZpFRzCB8yJ0","timestamp":1725647067341},{"file_id":"1YEO6Z9OG6wghZ9hpgw22ZlghESt248yh","timestamp":1725642363686},{"file_id":"1Nftb0ZvXUIvmIoKXWo8gsG9ZgxkRB4Pj","timestamp":1725416240579},{"file_id":"148WaN3mx63rXNhUjGCfDYS00LlaCs-lN","timestamp":1725371486778},{"file_id":"1zqXXtvghnQzJCVVcEU9S4N-28Q_GdjyF","timestamp":1725306949217},{"file_id":"1zDXIbxi0v_uZmIa1CWqiBcBHDxLnKk63","timestamp":1725036289643}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}