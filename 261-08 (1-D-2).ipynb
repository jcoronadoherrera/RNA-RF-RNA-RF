{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3421,"status":"ok","timestamp":1726377924517,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"m0hxbkmFQqQ3","outputId":"225e81bf-14a4-488e-d12f-159a74704fae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"]}],"source":["!pip install xlrd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7726,"status":"ok","timestamp":1726377932241,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"-dVSaH6MdwMU","outputId":"e60331fa-55b0-4229-b4cb-75481f35a2a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"]}],"source":["!pip install openpyxl\n","\n","import pathlib\n","\n","import pandas as pd\n","import numpy as np\n","import xlrd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import PercentFormatter\n","import scipy.stats as stats\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1335,"status":"ok","timestamp":1726377933574,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"SWB0I35adDWT","outputId":"a63a4f8a-f555-41f9-a570-64d11f554e53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3102,"status":"ok","timestamp":1726377936674,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"XrclvH4fQA_I","outputId":"883d3e82-b28b-4092-e68d-393b7299773f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (0.4.6)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.26.4)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.3.2)\n","Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n"]}],"source":["!pip install bayesian-optimization"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1726377936992,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"6b7epD9JV04o","outputId":"313e5c99-df29-454f-dbf2-9c98a222f1fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         Días      Área  PY_VC_PCA  Valor_Proyecto\n","#                                                 \n","1    0.199969 -0.224328  -0.670771       -0.563421\n","2    0.199969 -0.224328  -0.670771       -0.545120\n","3    0.199969 -0.222966  -0.670771       -0.544601\n","4    0.199969 -0.222966  -0.670771       -0.532932\n","5    1.478731 -0.182279  -0.670771       -0.532623\n","..        ...       ...        ...             ...\n","121 -0.699160 -0.219754  -1.883419       -0.617652\n","122 -0.659199 -0.223679  -1.883419       -0.604545\n","123 -0.579276 -0.224410  -1.883419       -0.584883\n","124 -0.898967 -0.074911  -1.932311       -0.488695\n","125  0.080085 -0.203695  -0.670771        1.333930\n","\n","[115 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-02fe11fc-bc6b-41d7-8491-b1bf8424345f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Días</th>\n","      <th>Área</th>\n","      <th>PY_VC_PCA</th>\n","      <th>Valor_Proyecto</th>\n","    </tr>\n","    <tr>\n","      <th>#</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.199969</td>\n","      <td>-0.224328</td>\n","      <td>-0.670771</td>\n","      <td>-0.563421</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.199969</td>\n","      <td>-0.224328</td>\n","      <td>-0.670771</td>\n","      <td>-0.545120</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.199969</td>\n","      <td>-0.222966</td>\n","      <td>-0.670771</td>\n","      <td>-0.544601</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.199969</td>\n","      <td>-0.222966</td>\n","      <td>-0.670771</td>\n","      <td>-0.532932</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.478731</td>\n","      <td>-0.182279</td>\n","      <td>-0.670771</td>\n","      <td>-0.532623</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>-0.699160</td>\n","      <td>-0.219754</td>\n","      <td>-1.883419</td>\n","      <td>-0.617652</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>-0.659199</td>\n","      <td>-0.223679</td>\n","      <td>-1.883419</td>\n","      <td>-0.604545</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>-0.579276</td>\n","      <td>-0.224410</td>\n","      <td>-1.883419</td>\n","      <td>-0.584883</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>-0.898967</td>\n","      <td>-0.074911</td>\n","      <td>-1.932311</td>\n","      <td>-0.488695</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>0.080085</td>\n","      <td>-0.203695</td>\n","      <td>-0.670771</td>\n","      <td>1.333930</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>115 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02fe11fc-bc6b-41d7-8491-b1bf8424345f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-02fe11fc-bc6b-41d7-8491-b1bf8424345f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-02fe11fc-bc6b-41d7-8491-b1bf8424345f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-93f488d1-cee4-4b68-a7dc-d267daf1a2dd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93f488d1-cee4-4b68-a7dc-d267daf1a2dd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-93f488d1-cee4-4b68-a7dc-d267daf1a2dd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_b64c12d1-02c7-41a3-ab88-6842d8103931\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('PY_DATOS_REALES_EST_SA')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b64c12d1-02c7-41a3-ab88-6842d8103931 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('PY_DATOS_REALES_EST_SA');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"PY_DATOS_REALES_EST_SA","summary":"{\n  \"name\": \"PY_DATOS_REALES_EST_SA\",\n  \"rows\": 115,\n  \"fields\": [\n    {\n      \"column\": \"#\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 1,\n        \"max\": 125,\n        \"num_unique_values\": 115,\n        \"samples\": [\n          88,\n          5,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D\\u00edas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803867251482979,\n        \"min\": -0.9189475169275999,\n        \"max\": 3.576699032651917,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          1.099098267550317,\n          0.3198528656232003,\n          0.1999689576344132\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u00c1rea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6059869599176284,\n        \"min\": -0.2244174118541763,\n        \"max\": 4.300395967794374,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          -0.2215413972005786,\n          -0.221120588490909,\n          -0.2197543115106207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PY_VC_PCA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.861373017906514,\n        \"min\": -1.932310996606438,\n        \"max\": 3.52411703404423,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          2.311469443226625,\n          -0.4732605429692015,\n          -0.6707711165617886\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valor_Proyecto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7062492114343796,\n        \"min\": -0.6821759220149384,\n        \"max\": 2.571424409907773,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.1168984995526829,\n          -0.5326233376160263,\n          -0.4347466604685049\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}],"source":["PY_DATOS_REALES_EST_SA=pd.read_excel(\"/content/drive/MyDrive/Datos/Copia de 4 Variables. Datos reales estandarizados sin atípicos (z-score).xlsx\", sheet_name='Datos sin atipicos', header=0, index_col=0, usecols='A, B, C, D, E')\n","PY_DATOS_REALES_EST_SA"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1726377937332,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"},"user_tz":300},"id":"V79YMsGZZZF5","outputId":"555224ee-2d4f-4743-f0d4-c90b19765db3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             Días        Área   PY_VC_PCA  Valor_Proyecto\n","count  115.000000  115.000000  115.000000      115.000000\n","mean    -0.082193   -0.098454   -0.089025       -0.097465\n","std      0.780387    0.605987    1.861373        0.706249\n","min     -0.918948   -0.224417   -1.932311       -0.682176\n","25%     -0.669189   -0.224096   -1.883419       -0.587202\n","50%     -0.359489   -0.222363   -0.670771       -0.410561\n","75%      0.219950   -0.203633    0.739387        0.150954\n","max      3.576699    4.300396    3.524117        2.571424"],"text/html":["\n","  <div id=\"df-61bd558c-63f1-4d67-8771-ef505bc40c57\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Días</th>\n","      <th>Área</th>\n","      <th>PY_VC_PCA</th>\n","      <th>Valor_Proyecto</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>115.000000</td>\n","      <td>115.000000</td>\n","      <td>115.000000</td>\n","      <td>115.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-0.082193</td>\n","      <td>-0.098454</td>\n","      <td>-0.089025</td>\n","      <td>-0.097465</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.780387</td>\n","      <td>0.605987</td>\n","      <td>1.861373</td>\n","      <td>0.706249</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-0.918948</td>\n","      <td>-0.224417</td>\n","      <td>-1.932311</td>\n","      <td>-0.682176</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-0.669189</td>\n","      <td>-0.224096</td>\n","      <td>-1.883419</td>\n","      <td>-0.587202</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-0.359489</td>\n","      <td>-0.222363</td>\n","      <td>-0.670771</td>\n","      <td>-0.410561</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.219950</td>\n","      <td>-0.203633</td>\n","      <td>0.739387</td>\n","      <td>0.150954</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.576699</td>\n","      <td>4.300396</td>\n","      <td>3.524117</td>\n","      <td>2.571424</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61bd558c-63f1-4d67-8771-ef505bc40c57')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-61bd558c-63f1-4d67-8771-ef505bc40c57 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-61bd558c-63f1-4d67-8771-ef505bc40c57');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c1ba4215-288a-40af-a610-834a04fde8ef\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1ba4215-288a-40af-a610-834a04fde8ef')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c1ba4215-288a-40af-a610-834a04fde8ef button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"PY_DATOS_REALES_EST_SA\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"D\\u00edas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.5545662531427,\n        \"min\": -0.9189475169275999,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.08219258812470316,\n          -0.3594892796465934,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u00c1rea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.48971129133538,\n        \"min\": -0.2244174118541763,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.09845418591053573,\n          -0.2223626584729893,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PY_VC_PCA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.62230361790927,\n        \"min\": -1.932310996606438,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.08902548734541608,\n          -0.6707711165617886,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valor_Proyecto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.58885053966308,\n        \"min\": -0.6821759220149384,\n        \"max\": 115.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.09746450807400997,\n          -0.4105610840414156,\n          115.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["PY_DATOS_REALES_EST_SA.describe()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gUevuBrFumOK","executionInfo":{"status":"ok","timestamp":1726377937332,"user_tz":300,"elapsed":5,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, ReLU, ELU\n","from keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adagrad\n","from keras.regularizers import l2\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import tensorflow as tf\n","from bayes_opt import BayesianOptimization\n","from scipy.stats import spearmanr\n","import random\n","\n","# Fijar la semilla para reproducibilidad\n","random.seed(42)\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# Función personalizada para calcular SSE\n","def sse(y_true, y_pred):\n","    return tf.reduce_sum(tf.square(y_true - y_pred))\n","\n","# Función personalizada para calcular SAE\n","def sae(y_true, y_pred):\n","    return tf.reduce_sum(tf.abs(y_true - y_pred))\n","\n","# Función personalizada para calcular el coeficiente de determinación R^2\n","def r2_keras(y_true, y_pred):\n","    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n","    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n","    return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n","\n","# Función personalizada para calcular el coeficiente de correlación de Pearson\n","def pearson_correlation(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float64)\n","    y_pred = tf.cast(y_pred, tf.float64)\n","    x = y_true - tf.reduce_mean(y_true)\n","    y = y_pred - tf.reduce_mean(y_pred)\n","    r_num = tf.reduce_sum(x * y)\n","    r_den = tf.sqrt(tf.reduce_sum(tf.square(x)) * tf.reduce_sum(tf.square(y)))\n","    return r_num / (r_den + tf.keras.backend.epsilon())\n","\n","# Función para calcular RMSE\n","def rmse(y_true, y_pred):\n","    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n","\n","# Seleccionar las columnas relevantes para la predicción de 'Valor_Proyecto'\n","data = PY_DATOS_REALES_EST_SA[['Días', 'Área', 'PY_VC_PCA', 'Valor_Proyecto']]\n","X = data.drop('Valor_Proyecto', axis=1).values\n","y = data['Valor_Proyecto'].values\n","\n","# Dividir los datos en entrenamiento y validación con una semilla fija\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqOzCp8HvXOs","outputId":"ba76e75e-1e3e-4b53-98fa-ae02a2ba1c36","executionInfo":{"status":"ok","timestamp":1726378233086,"user_tz":300,"elapsed":295758,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | learni... |  units_1  |  units_2  |  units_3  |  units_4  |  units_5  |\n","-------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/step - huber_loss: 0.8397 - loss: 1.0412 - mae: 1.2113 - mse: 2.9292 - pearson_correlation: -1.6957e-16 - r2_keras: -448.6150 - rmse: 1.8452 - sae: 5384.2646 - sse: 13946.4951\n","Epoch 1: val_loss improved from inf to 0.40327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689ms/step - huber_loss: 0.7523 - loss: 0.9882 - mae: 1.1679 - mse: 2.6134 - pearson_correlation: -8.1453e-17 - r2_keras: -324.3587 - rmse: 1.5876 - sae: 3816.0579 - sse: 9598.1318 - val_huber_loss: 0.1996 - val_loss: 0.4033 - val_mae: 0.5059 - val_mse: 0.5001 - val_pearson_correlation: -8.8223e-17 - val_r2_keras: -23.6741 - val_rmse: 0.8089 - val_sae: 320.4227 - val_sse: 346.1309 - learning_rate: 0.0038\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.3760 - loss: 0.5796 - mae: 0.7180 - mse: 0.8870 - pearson_correlation: 3.3775e-16 - r2_keras: -187.0732 - rmse: 1.1934 - sae: 3833.1853 - sse: 5833.7969\n","Epoch 2: val_loss did not improve from 0.40327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - huber_loss: 0.4298 - loss: 0.6125 - mae: 0.7566 - mse: 0.9640 - pearson_correlation: 1.9979e-16 - r2_keras: -162.0223 - rmse: 1.2289 - sae: 2832.6592 - sse: 4330.7183 - val_huber_loss: 0.2158 - val_loss: 0.4197 - val_mae: 0.5360 - val_mse: 0.5069 - val_pearson_correlation: 3.8226e-16 - val_r2_keras: -26.4497 - val_rmse: 0.8532 - val_sae: 357.3107 - val_sse: 385.0671 - learning_rate: 0.0038\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.1988 - loss: 0.4027 - mae: 0.4374 - mse: 0.4509 - pearson_correlation: 7.5069e-17 - r2_keras: -103.0700 - rmse: 0.8878 - sae: 2682.8862 - sse: 3228.1201\n","Epoch 3: val_loss did not improve from 0.40327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1751 - loss: 0.3883 - mae: 0.4265 - mse: 0.4134 - pearson_correlation: 1.0360e-16 - r2_keras: -90.0347 - rmse: 0.9205 - sae: 1985.0660 - sse: 2406.0906 - val_huber_loss: 0.2278 - val_loss: 0.4315 - val_mae: 0.5551 - val_mse: 0.5140 - val_pearson_correlation: -1.8624e-17 - val_r2_keras: -28.3231 - val_rmse: 0.8818 - val_sae: 379.6195 - val_sse: 411.3480 - learning_rate: 0.0038\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.1174 - loss: 0.3211 - mae: 0.3739 - mse: 0.2393 - pearson_correlation: 8.3380e-16 - r2_keras: -91.7857 - rmse: 0.8382 - sae: 2631.1301 - sse: 2878.0977\n","Epoch 4: val_loss did not improve from 0.40327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.1221 - loss: 0.3239 - mae: 0.3801 - mse: 0.2443 - pearson_correlation: 6.4806e-16 - r2_keras: -82.8274 - rmse: 0.8898 - sae: 1945.1980 - sse: 2176.4434 - val_huber_loss: 0.2598 - val_loss: 0.4632 - val_mae: 0.6075 - val_mse: 0.5787 - val_pearson_correlation: -2.0962e-16 - val_r2_keras: -33.4027 - val_rmse: 0.9551 - val_sae: 409.3278 - val_sse: 482.6050 - learning_rate: 0.0038\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1437 - loss: 0.3470 - mae: 0.4124 - mse: 0.3014 - pearson_correlation: -2.2089e-16 - r2_keras: -98.0223 - rmse: 0.8660 - sae: 2665.0574 - sse: 3071.5464\n","Epoch 5: val_loss did not improve from 0.40327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.1305 - loss: 0.3389 - mae: 0.4011 - mse: 0.2835 - pearson_correlation: -1.8216e-16 - r2_keras: -88.2566 - rmse: 0.9178 - sae: 1984.8810 - sse: 2320.3242 - val_huber_loss: 0.2451 - val_loss: 0.4480 - val_mae: 0.5324 - val_mse: 0.5792 - val_pearson_correlation: -4.0632e-16 - val_r2_keras: -31.0917 - val_rmse: 0.9225 - val_sae: 375.0859 - val_sse: 450.1854 - learning_rate: 0.0038\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1231 - loss: 0.3260 - mae: 0.3501 - mse: 0.2551 - pearson_correlation: 7.3265e-17 - r2_keras: -109.5863 - rmse: 0.9151 - sae: 2613.5874 - sse: 3430.2488\n","Epoch 6: val_loss did not improve from 0.40327\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1025 - loss: 0.3134 - mae: 0.3309 - mse: 0.2282 - pearson_correlation: 1.0078e-16 - r2_keras: -88.5802 - rmse: 0.8913 - sae: 1909.6045 - sse: 2472.8240 - val_huber_loss: 0.2034 - val_loss: 0.4058 - val_mae: 0.4686 - val_mse: 0.4681 - val_pearson_correlation: -2.9962e-16 - val_r2_keras: -34.9746 - val_rmse: 0.9767 - val_sae: 379.0011 - val_sse: 504.6562 - learning_rate: 0.0038\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0836 - loss: 0.2860 - mae: 0.2597 - mse: 0.1684 - pearson_correlation: -2.2924e-16 - r2_keras: -103.4987 - rmse: 0.8896 - sae: 2678.0498 - sse: 3241.4199\n","Epoch 7: val_loss improved from 0.40327 to 0.39185, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - huber_loss: 0.0712 - loss: 0.2784 - mae: 0.2496 - mse: 0.1530 - pearson_correlation: -1.2944e-16 - r2_keras: -86.0322 - rmse: 0.8874 - sae: 1956.7909 - sse: 2364.6545 - val_huber_loss: 0.1896 - val_loss: 0.3919 - val_mae: 0.4312 - val_mse: 0.4332 - val_pearson_correlation: -1.8705e-16 - val_r2_keras: -35.4675 - val_rmse: 0.9834 - val_sae: 374.0866 - val_sse: 511.5695 - learning_rate: 7.6159e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0745 - loss: 0.2768 - mae: 0.2431 - mse: 0.1499 - pearson_correlation: 2.7862e-16 - r2_keras: -103.8321 - rmse: 0.8910 - sae: 2666.1702 - sse: 3251.7605\n","Epoch 8: val_loss improved from 0.39185 to 0.37384, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - huber_loss: 0.0646 - loss: 0.2707 - mae: 0.2344 - mse: 0.1377 - pearson_correlation: 1.9189e-16 - r2_keras: -85.7646 - rmse: 0.8841 - sae: 1946.5149 - sse: 2365.8027 - val_huber_loss: 0.1717 - val_loss: 0.3738 - val_mae: 0.4031 - val_mse: 0.3863 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.7635 - val_rmse: 0.9738 - val_sae: 368.3936 - val_sse: 501.6947 - learning_rate: 7.6159e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - huber_loss: 0.0700 - loss: 0.2721 - mae: 0.2348 - mse: 0.1409 - pearson_correlation: 2.3482e-16 - r2_keras: -103.9889 - rmse: 0.8917 - sae: 2657.9189 - sse: 3256.6230\n","Epoch 9: val_loss improved from 0.37384 to 0.35985, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - huber_loss: 0.0613 - loss: 0.2668 - mae: 0.2267 - mse: 0.1301 - pearson_correlation: 1.8058e-16 - r2_keras: -85.6617 - rmse: 0.8828 - sae: 1940.0985 - sse: 2366.6116 - val_huber_loss: 0.1579 - val_loss: 0.3599 - val_mae: 0.3842 - val_mse: 0.3510 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.0573 - val_rmse: 0.9642 - val_sae: 364.0224 - val_sse: 491.7875 - learning_rate: 7.6159e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0670 - loss: 0.2689 - mae: 0.2298 - mse: 0.1348 - pearson_correlation: 1.5228e-16 - r2_keras: -104.0421 - rmse: 0.8919 - sae: 2652.8413 - sse: 3258.2749\n","Epoch 10: val_loss improved from 0.35985 to 0.34733, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - huber_loss: 0.0590 - loss: 0.2641 - mae: 0.2221 - mse: 0.1249 - pearson_correlation: 8.3695e-17 - r2_keras: -85.6794 - rmse: 0.8828 - sae: 1936.6233 - sse: 2367.5039 - val_huber_loss: 0.1455 - val_loss: 0.3473 - val_mae: 0.3704 - val_mse: 0.3198 - val_pearson_correlation: 2.9414e-16 - val_r2_keras: -33.2596 - val_rmse: 0.9532 - val_sae: 359.1384 - val_sse: 480.5970 - learning_rate: 7.6159e-04\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0650 - loss: 0.2668 - mae: 0.2257 - mse: 0.1310 - pearson_correlation: -1.6753e-16 - r2_keras: -104.4433 - rmse: 0.8936 - sae: 2654.5352 - sse: 3270.7178\n","Epoch 11: val_loss improved from 0.34733 to 0.33882, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - huber_loss: 0.0574 - loss: 0.2622 - mae: 0.2180 - mse: 0.1215 - pearson_correlation: -1.2342e-16 - r2_keras: -85.7626 - rmse: 0.8823 - sae: 1936.8325 - sse: 2373.6377 - val_huber_loss: 0.1372 - val_loss: 0.3388 - val_mae: 0.3601 - val_mse: 0.2967 - val_pearson_correlation: -2.7332e-16 - val_r2_keras: -33.1177 - val_rmse: 0.9512 - val_sae: 358.0259 - val_sse: 478.6068 - learning_rate: 7.6159e-04\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0631 - loss: 0.2647 - mae: 0.2217 - mse: 0.1270 - pearson_correlation: -1.1956e-16 - r2_keras: -104.5128 - rmse: 0.8939 - sae: 2650.8943 - sse: 3272.8762\n","Epoch 12: val_loss improved from 0.33882 to 0.33227, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - huber_loss: 0.0557 - loss: 0.2602 - mae: 0.2137 - mse: 0.1178 - pearson_correlation: -1.0224e-16 - r2_keras: -85.8291 - rmse: 0.8827 - sae: 1934.8358 - sse: 2375.3135 - val_huber_loss: 0.1309 - val_loss: 0.3323 - val_mae: 0.3520 - val_mse: 0.2806 - val_pearson_correlation: -7.0435e-17 - val_r2_keras: -32.4959 - val_rmse: 0.9425 - val_sae: 353.4414 - val_sse: 469.8836 - learning_rate: 7.6159e-04\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0618 - loss: 0.2632 - mae: 0.2208 - mse: 0.1243 - pearson_correlation: 1.5770e-16 - r2_keras: -104.4854 - rmse: 0.8938 - sae: 2648.2441 - sse: 3272.0239\n","Epoch 13: val_loss improved from 0.33227 to 0.32963, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - huber_loss: 0.0544 - loss: 0.2587 - mae: 0.2129 - mse: 0.1152 - pearson_correlation: 1.4380e-16 - r2_keras: -85.8459 - rmse: 0.8829 - sae: 1933.1444 - sse: 2375.1565 - val_huber_loss: 0.1284 - val_loss: 0.3296 - val_mae: 0.3494 - val_mse: 0.2727 - val_pearson_correlation: -2.2058e-16 - val_r2_keras: -32.7383 - val_rmse: 0.9459 - val_sae: 354.9328 - val_sse: 473.2840 - learning_rate: 7.6159e-04\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0608 - loss: 0.2620 - mae: 0.2183 - mse: 0.1226 - pearson_correlation: -5.4177e-16 - r2_keras: -104.4846 - rmse: 0.8938 - sae: 2648.0706 - sse: 3272.0007\n","Epoch 14: val_loss improved from 0.32963 to 0.32666, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0532 - loss: 0.2574 - mae: 0.2099 - mse: 0.1132 - pearson_correlation: -3.7112e-16 - r2_keras: -85.7839 - rmse: 0.8824 - sae: 1933.1418 - sse: 2374.4204 - val_huber_loss: 0.1257 - val_loss: 0.3267 - val_mae: 0.3461 - val_mse: 0.2655 - val_pearson_correlation: 2.8167e-16 - val_r2_keras: -32.5278 - val_rmse: 0.9429 - val_sae: 353.5021 - val_sse: 470.3322 - learning_rate: 7.6159e-04\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0596 - loss: 0.2606 - mae: 0.2173 - mse: 0.1201 - pearson_correlation: -4.7840e-16 - r2_keras: -104.8141 - rmse: 0.8952 - sae: 2647.5598 - sse: 3282.2212\n","Epoch 15: val_loss improved from 0.32666 to 0.32373, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - huber_loss: 0.0519 - loss: 0.2559 - mae: 0.2089 - mse: 0.1105 - pearson_correlation: -3.5725e-16 - r2_keras: -86.1992 - rmse: 0.8850 - sae: 1933.7828 - sse: 2383.5283 - val_huber_loss: 0.1230 - val_loss: 0.3237 - val_mae: 0.3424 - val_mse: 0.2611 - val_pearson_correlation: -7.4087e-17 - val_r2_keras: -31.5679 - val_rmse: 0.9293 - val_sae: 347.9079 - val_sse: 456.8661 - learning_rate: 7.6159e-04\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0584 - loss: 0.2591 - mae: 0.2155 - mse: 0.1181 - pearson_correlation: -4.8065e-16 - r2_keras: -103.7065 - rmse: 0.8905 - sae: 2627.4487 - sse: 3247.8645\n","Epoch 16: val_loss improved from 0.32373 to 0.32099, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - huber_loss: 0.0505 - loss: 0.2543 - mae: 0.2067 - mse: 0.1082 - pearson_correlation: -3.3465e-16 - r2_keras: -85.5050 - rmse: 0.8822 - sae: 1920.5526 - sse: 2361.1421 - val_huber_loss: 0.1206 - val_loss: 0.3210 - val_mae: 0.3365 - val_mse: 0.2527 - val_pearson_correlation: -5.8187e-17 - val_r2_keras: -32.7207 - val_rmse: 0.9456 - val_sae: 355.1646 - val_sse: 473.0374 - learning_rate: 7.6159e-04\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0564 - loss: 0.2568 - mae: 0.2099 - mse: 0.1137 - pearson_correlation: -1.3588e-17 - r2_keras: -104.7203 - rmse: 0.8948 - sae: 2636.3596 - sse: 3279.3110\n","Epoch 17: val_loss did not improve from 0.32099\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0485 - loss: 0.2520 - mae: 0.2014 - mse: 0.1039 - pearson_correlation: -2.0610e-18 - r2_keras: -86.4148 - rmse: 0.8871 - sae: 1927.6058 - sse: 2384.8506 - val_huber_loss: 0.1231 - val_loss: 0.3232 - val_mae: 0.3426 - val_mse: 0.2612 - val_pearson_correlation: -3.0048e-16 - val_r2_keras: -31.3405 - val_rmse: 0.9261 - val_sae: 346.7529 - val_sse: 453.6759 - learning_rate: 7.6159e-04\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0544 - loss: 0.2545 - mae: 0.2074 - mse: 0.1099 - pearson_correlation: 2.4830e-17 - r2_keras: -104.2199 - rmse: 0.8926 - sae: 2622.6423 - sse: 3263.7886\n","Epoch 18: val_loss improved from 0.32099 to 0.32086, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - huber_loss: 0.0470 - loss: 0.2500 - mae: 0.1990 - mse: 0.1006 - pearson_correlation: 8.5749e-17 - r2_keras: -86.2541 - rmse: 0.8872 - sae: 1919.2588 - sse: 2376.5308 - val_huber_loss: 0.1211 - val_loss: 0.3209 - val_mae: 0.3368 - val_mse: 0.2559 - val_pearson_correlation: -1.1582e-16 - val_r2_keras: -32.7978 - val_rmse: 0.9467 - val_sae: 356.2739 - val_sse: 474.1187 - learning_rate: 7.6159e-04\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0540 - loss: 0.2537 - mae: 0.2034 - mse: 0.1088 - pearson_correlation: -8.3615e-16 - r2_keras: -105.0456 - rmse: 0.8961 - sae: 2631.1592 - sse: 3289.4009\n","Epoch 19: val_loss improved from 0.32086 to 0.31969, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - huber_loss: 0.0460 - loss: 0.2488 - mae: 0.1948 - mse: 0.0989 - pearson_correlation: -5.7697e-16 - r2_keras: -86.4048 - rmse: 0.8861 - sae: 1922.3385 - sse: 2388.9167 - val_huber_loss: 0.1203 - val_loss: 0.3197 - val_mae: 0.3390 - val_mse: 0.2561 - val_pearson_correlation: 2.5384e-17 - val_r2_keras: -31.1975 - val_rmse: 0.9240 - val_sae: 346.7422 - val_sse: 451.6700 - learning_rate: 7.6159e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0527 - loss: 0.2521 - mae: 0.2035 - mse: 0.1058 - pearson_correlation: 3.7771e-16 - r2_keras: -107.1974 - rmse: 0.9052 - sae: 2660.3145 - sse: 3356.1470\n","Epoch 20: val_loss did not improve from 0.31969\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0445 - loss: 0.2471 - mae: 0.1928 - mse: 0.0957 - pearson_correlation: 2.6623e-16 - r2_keras: -87.6237 - rmse: 0.8903 - sae: 1940.8052 - sse: 2430.8850 - val_huber_loss: 0.1236 - val_loss: 0.3226 - val_mae: 0.3425 - val_mse: 0.2640 - val_pearson_correlation: 4.0921e-16 - val_r2_keras: -32.0327 - val_rmse: 0.9359 - val_sae: 352.5880 - val_sse: 463.3864 - learning_rate: 7.6159e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0526 - loss: 0.2516 - mae: 0.2018 - mse: 0.1061 - pearson_correlation: 1.3662e-17 - r2_keras: -104.2689 - rmse: 0.8929 - sae: 2621.8828 - sse: 3265.3110\n","Epoch 21: val_loss improved from 0.31969 to 0.31363, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - huber_loss: 0.0436 - loss: 0.2461 - mae: 0.1915 - mse: 0.0949 - pearson_correlation: -3.6518e-18 - r2_keras: -86.5498 - rmse: 0.8896 - sae: 1919.6019 - sse: 2380.6306 - val_huber_loss: 0.1150 - val_loss: 0.3136 - val_mae: 0.3279 - val_mse: 0.2430 - val_pearson_correlation: 2.1194e-16 - val_r2_keras: -31.4632 - val_rmse: 0.9278 - val_sae: 347.4146 - val_sse: 455.3975 - learning_rate: 7.6159e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0521 - loss: 0.2508 - mae: 0.2050 - mse: 0.1046 - pearson_correlation: 1.2227e-17 - r2_keras: -108.4005 - rmse: 0.9102 - sae: 2657.8184 - sse: 3393.4658\n","Epoch 22: val_loss did not improve from 0.31363\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0424 - loss: 0.2448 - mae: 0.1932 - mse: 0.0927 - pearson_correlation: -5.2087e-17 - r2_keras: -88.8988 - rmse: 0.8977 - sae: 1941.5204 - sse: 2461.3127 - val_huber_loss: 0.1163 - val_loss: 0.3145 - val_mae: 0.3341 - val_mse: 0.2490 - val_pearson_correlation: 1.2809e-17 - val_r2_keras: -30.9057 - val_rmse: 0.9198 - val_sae: 345.4563 - val_sse: 447.5769 - learning_rate: 7.6159e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0510 - loss: 0.2492 - mae: 0.2004 - mse: 0.1031 - pearson_correlation: 7.0605e-16 - r2_keras: -106.5349 - rmse: 0.9024 - sae: 2640.4280 - sse: 3335.5984\n","Epoch 23: val_loss improved from 0.31363 to 0.30949, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - huber_loss: 0.0415 - loss: 0.2434 - mae: 0.1886 - mse: 0.0913 - pearson_correlation: 5.1509e-16 - r2_keras: -88.0049 - rmse: 0.8955 - sae: 1931.8069 - sse: 2426.8379 - val_huber_loss: 0.1117 - val_loss: 0.3095 - val_mae: 0.3403 - val_mse: 0.2336 - val_pearson_correlation: -2.0995e-16 - val_r2_keras: -31.7518 - val_rmse: 0.9319 - val_sae: 353.3360 - val_sse: 459.4454 - learning_rate: 7.6159e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0511 - loss: 0.2489 - mae: 0.1981 - mse: 0.1024 - pearson_correlation: 2.7009e-16 - r2_keras: -111.3851 - rmse: 0.9225 - sae: 2710.0969 - sse: 3486.0461\n","Epoch 24: val_loss improved from 0.30949 to 0.30811, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - huber_loss: 0.0405 - loss: 0.2424 - mae: 0.1842 - mse: 0.0894 - pearson_correlation: 1.9503e-16 - r2_keras: -90.7532 - rmse: 0.9047 - sae: 1975.4448 - sse: 2521.4451 - val_huber_loss: 0.1108 - val_loss: 0.3081 - val_mae: 0.3299 - val_mse: 0.2367 - val_pearson_correlation: 3.4846e-16 - val_r2_keras: -30.7118 - val_rmse: 0.9170 - val_sae: 344.6009 - val_sse: 444.8571 - learning_rate: 7.6159e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0487 - loss: 0.2460 - mae: 0.2046 - mse: 0.0978 - pearson_correlation: -3.5805e-16 - r2_keras: -106.6006 - rmse: 0.9027 - sae: 2638.1040 - sse: 3337.6348\n","Epoch 25: val_loss did not improve from 0.30811\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0389 - loss: 0.2400 - mae: 0.1907 - mse: 0.0859 - pearson_correlation: -2.8947e-16 - r2_keras: -89.0211 - rmse: 0.9038 - sae: 1933.5593 - sse: 2439.6023 - val_huber_loss: 0.1222 - val_loss: 0.3190 - val_mae: 0.3446 - val_mse: 0.2586 - val_pearson_correlation: -2.3126e-16 - val_r2_keras: -29.9427 - val_rmse: 0.9058 - val_sae: 337.7254 - val_sse: 434.0674 - learning_rate: 7.6159e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0478 - loss: 0.2446 - mae: 0.2038 - mse: 0.0956 - pearson_correlation: 3.9572e-16 - r2_keras: -104.3416 - rmse: 0.8932 - sae: 2606.1865 - sse: 3267.5654\n","Epoch 26: val_loss did not improve from 0.30811\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0387 - loss: 0.2390 - mae: 0.1911 - mse: 0.0845 - pearson_correlation: 1.8780e-16 - r2_keras: -87.4535 - rmse: 0.8969 - sae: 1911.9025 - sse: 2392.1653 - val_huber_loss: 0.1345 - val_loss: 0.3309 - val_mae: 0.3678 - val_mse: 0.2883 - val_pearson_correlation: -8.7313e-17 - val_r2_keras: -29.6969 - val_rmse: 0.9022 - val_sae: 329.9446 - val_sse: 430.6199 - learning_rate: 7.6159e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0457 - loss: 0.2421 - mae: 0.1854 - mse: 0.0929 - pearson_correlation: 4.5232e-16 - r2_keras: -115.7264 - rmse: 0.9402 - sae: 2745.0391 - sse: 3620.7056\n","Epoch 27: val_loss improved from 0.30811 to 0.30256, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - huber_loss: 0.0398 - loss: 0.2384 - mae: 0.1816 - mse: 0.0854 - pearson_correlation: 2.9971e-16 - r2_keras: -93.0553 - rmse: 0.9114 - sae: 1997.8141 - sse: 2604.2732 - val_huber_loss: 0.1066 - val_loss: 0.3026 - val_mae: 0.3322 - val_mse: 0.2230 - val_pearson_correlation: 2.1996e-17 - val_r2_keras: -33.9946 - val_rmse: 0.9633 - val_sae: 365.1312 - val_sse: 490.9086 - learning_rate: 7.6159e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0547 - loss: 0.2506 - mae: 0.2279 - mse: 0.1094 - pearson_correlation: 1.4904e-16 - r2_keras: -112.9318 - rmse: 0.9289 - sae: 2751.6631 - sse: 3534.0225\n","Epoch 28: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0450 - loss: 0.2447 - mae: 0.2126 - mse: 0.0977 - pearson_correlation: 1.0741e-16 - r2_keras: -93.2589 - rmse: 0.9214 - sae: 2006.4443 - sse: 2570.7258 - val_huber_loss: 0.1316 - val_loss: 0.3271 - val_mae: 0.3457 - val_mse: 0.2794 - val_pearson_correlation: -7.4614e-17 - val_r2_keras: -29.2093 - val_rmse: 0.8950 - val_sae: 323.1572 - val_sse: 423.7792 - learning_rate: 7.6159e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0445 - loss: 0.2399 - mae: 0.1993 - mse: 0.0891 - pearson_correlation: -5.2011e-17 - r2_keras: -108.0965 - rmse: 0.9089 - sae: 2666.7537 - sse: 3384.0374\n","Epoch 29: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0371 - loss: 0.2354 - mae: 0.1888 - mse: 0.0802 - pearson_correlation: -1.1624e-16 - r2_keras: -90.5180 - rmse: 0.9121 - sae: 1954.7921 - sse: 2476.3965 - val_huber_loss: 0.1099 - val_loss: 0.3050 - val_mae: 0.3407 - val_mse: 0.2275 - val_pearson_correlation: -3.6305e-17 - val_r2_keras: -31.8370 - val_rmse: 0.9332 - val_sae: 355.2127 - val_sse: 460.6410 - learning_rate: 7.6159e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0489 - loss: 0.2440 - mae: 0.2070 - mse: 0.0996 - pearson_correlation: -2.7887e-16 - r2_keras: -110.6658 - rmse: 0.9196 - sae: 2677.1816 - sse: 3463.7334\n","Epoch 30: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0395 - loss: 0.2382 - mae: 0.1914 - mse: 0.0878 - pearson_correlation: -5.7955e-17 - r2_keras: -90.9827 - rmse: 0.9088 - sae: 1956.2013 - sse: 2514.8862 - val_huber_loss: 0.1384 - val_loss: 0.3330 - val_mae: 0.3580 - val_mse: 0.2995 - val_pearson_correlation: 1.3317e-17 - val_r2_keras: -28.8841 - val_rmse: 0.8902 - val_sae: 323.3586 - val_sse: 419.2169 - learning_rate: 7.6159e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0416 - loss: 0.2362 - mae: 0.1830 - mse: 0.0834 - pearson_correlation: 4.5176e-16 - r2_keras: -114.6030 - rmse: 0.9357 - sae: 2711.3394 - sse: 3585.8589\n","Epoch 31: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0348 - loss: 0.2321 - mae: 0.1753 - mse: 0.0751 - pearson_correlation: 2.5573e-16 - r2_keras: -93.3114 - rmse: 0.9170 - sae: 1975.9180 - sse: 2592.8311 - val_huber_loss: 0.1193 - val_loss: 0.3135 - val_mae: 0.3380 - val_mse: 0.2484 - val_pearson_correlation: 1.1180e-16 - val_r2_keras: -31.3895 - val_rmse: 0.9268 - val_sae: 348.2750 - val_sse: 454.3631 - learning_rate: 7.6159e-04\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0388 - loss: 0.2330 - mae: 0.1816 - mse: 0.0778 - pearson_correlation: -2.6639e-17 - r2_keras: -108.6604 - rmse: 0.9113 - sae: 2653.9092 - sse: 3401.5283\n","Epoch 32: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0327 - loss: 0.2292 - mae: 0.1739 - mse: 0.0702 - pearson_correlation: -2.7068e-17 - r2_keras: -91.1018 - rmse: 0.9153 - sae: 1950.3102 - sse: 2490.4963 - val_huber_loss: 0.1324 - val_loss: 0.3261 - val_mae: 0.3652 - val_mse: 0.2807 - val_pearson_correlation: 3.8123e-16 - val_r2_keras: -29.4077 - val_rmse: 0.8980 - val_sae: 331.7506 - val_sse: 426.5620 - learning_rate: 7.6159e-04\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0371 - loss: 0.2308 - mae: 0.1787 - mse: 0.0746 - pearson_correlation: 1.4872e-16 - r2_keras: -116.6045 - rmse: 0.9437 - sae: 2745.0234 - sse: 3647.9434\n","Epoch 33: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0310 - loss: 0.2271 - mae: 0.1693 - mse: 0.0671 - pearson_correlation: 7.2273e-17 - r2_keras: -94.9766 - rmse: 0.9252 - sae: 1998.9185 - sse: 2638.1008 - val_huber_loss: 0.1306 - val_loss: 0.3242 - val_mae: 0.3529 - val_mse: 0.2761 - val_pearson_correlation: 1.8227e-16 - val_r2_keras: -29.4486 - val_rmse: 0.8986 - val_sae: 329.5486 - val_sse: 427.1364 - learning_rate: 1.5232e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0319 - loss: 0.2255 - mae: 0.1576 - mse: 0.0639 - pearson_correlation: -3.2344e-17 - r2_keras: -113.2355 - rmse: 0.9301 - sae: 2700.6401 - sse: 3543.4431\n","Epoch 34: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0257 - loss: 0.2217 - mae: 0.1458 - mse: 0.0563 - pearson_correlation: 9.1918e-17 - r2_keras: -92.4748 - rmse: 0.9140 - sae: 1969.0143 - sse: 2565.4341 - val_huber_loss: 0.1296 - val_loss: 0.3231 - val_mae: 0.3470 - val_mse: 0.2740 - val_pearson_correlation: -2.1381e-17 - val_r2_keras: -29.5331 - val_rmse: 0.8998 - val_sae: 328.7588 - val_sse: 428.3210 - learning_rate: 1.5232e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0301 - loss: 0.2236 - mae: 0.1503 - mse: 0.0603 - pearson_correlation: 6.7934e-16 - r2_keras: -112.7353 - rmse: 0.9281 - sae: 2691.2351 - sse: 3527.9253\n","Epoch 35: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0241 - loss: 0.2199 - mae: 0.1374 - mse: 0.0529 - pearson_correlation: 5.1655e-16 - r2_keras: -92.2261 - rmse: 0.9133 - sae: 1963.4962 - sse: 2556.0835 - val_huber_loss: 0.1287 - val_loss: 0.3221 - val_mae: 0.3442 - val_mse: 0.2723 - val_pearson_correlation: 8.8946e-17 - val_r2_keras: -29.5792 - val_rmse: 0.9005 - val_sae: 328.6267 - val_sse: 428.9680 - learning_rate: 1.5232e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0290 - loss: 0.2224 - mae: 0.1460 - mse: 0.0580 - pearson_correlation: -3.4380e-16 - r2_keras: -112.6788 - rmse: 0.9278 - sae: 2689.0010 - sse: 3526.1733\n","Epoch 36: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0232 - loss: 0.2188 - mae: 0.1329 - mse: 0.0509 - pearson_correlation: -2.1490e-16 - r2_keras: -92.3325 - rmse: 0.9144 - sae: 1962.9314 - sse: 2556.6050 - val_huber_loss: 0.1276 - val_loss: 0.3209 - val_mae: 0.3407 - val_mse: 0.2702 - val_pearson_correlation: -1.0716e-16 - val_r2_keras: -29.5347 - val_rmse: 0.8998 - val_sae: 328.1444 - val_sse: 428.3440 - learning_rate: 1.5232e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0276 - loss: 0.2209 - mae: 0.1433 - mse: 0.0553 - pearson_correlation: 6.8159e-16 - r2_keras: -112.2952 - rmse: 0.9263 - sae: 2681.4902 - sse: 3514.2739\n","Epoch 37: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0222 - loss: 0.2176 - mae: 0.1302 - mse: 0.0486 - pearson_correlation: 4.2680e-16 - r2_keras: -92.1762 - rmse: 0.9142 - sae: 1958.4122 - sse: 2549.8381 - val_huber_loss: 0.1269 - val_loss: 0.3200 - val_mae: 0.3381 - val_mse: 0.2691 - val_pearson_correlation: -7.1657e-18 - val_r2_keras: -29.4999 - val_rmse: 0.8993 - val_sae: 327.9689 - val_sse: 427.8563 - learning_rate: 1.5232e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0268 - loss: 0.2200 - mae: 0.1415 - mse: 0.0537 - pearson_correlation: -6.1777e-17 - r2_keras: -112.2207 - rmse: 0.9260 - sae: 2679.5127 - sse: 3511.9639\n","Epoch 38: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0215 - loss: 0.2168 - mae: 0.1277 - mse: 0.0472 - pearson_correlation: -9.1911e-17 - r2_keras: -92.2189 - rmse: 0.9147 - sae: 1957.5072 - sse: 2549.3818 - val_huber_loss: 0.1265 - val_loss: 0.3196 - val_mae: 0.3374 - val_mse: 0.2683 - val_pearson_correlation: 6.4278e-17 - val_r2_keras: -29.5325 - val_rmse: 0.8998 - val_sae: 328.4840 - val_sse: 428.3127 - learning_rate: 3.0464e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0266 - loss: 0.2197 - mae: 0.1408 - mse: 0.0532 - pearson_correlation: 2.5725e-16 - r2_keras: -112.4436 - rmse: 0.9269 - sae: 2681.6040 - sse: 3518.8789\n","Epoch 39: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0214 - loss: 0.2165 - mae: 0.1271 - mse: 0.0469 - pearson_correlation: 1.3826e-16 - r2_keras: -92.3794 - rmse: 0.9155 - sae: 1958.9344 - sse: 2554.1313 - val_huber_loss: 0.1263 - val_loss: 0.3194 - val_mae: 0.3370 - val_mse: 0.2679 - val_pearson_correlation: -2.8489e-17 - val_r2_keras: -29.5649 - val_rmse: 0.9003 - val_sae: 328.8645 - val_sse: 428.7681 - learning_rate: 3.0464e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0264 - loss: 0.2195 - mae: 0.1402 - mse: 0.0528 - pearson_correlation: -5.3637e-16 - r2_keras: -112.6362 - rmse: 0.9277 - sae: 2683.3306 - sse: 3524.8513\n","Epoch 40: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0213 - loss: 0.2164 - mae: 0.1266 - mse: 0.0466 - pearson_correlation: -3.5509e-16 - r2_keras: -92.5147 - rmse: 0.9160 - sae: 1960.0995 - sse: 2558.1938 - val_huber_loss: 0.1262 - val_loss: 0.3193 - val_mae: 0.3368 - val_mse: 0.2678 - val_pearson_correlation: -7.8297e-17 - val_r2_keras: -29.5643 - val_rmse: 0.9003 - val_sae: 329.0186 - val_sse: 428.7598 - learning_rate: 3.0464e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0262 - loss: 0.2193 - mae: 0.1396 - mse: 0.0524 - pearson_correlation: 3.1729e-16 - r2_keras: -112.7812 - rmse: 0.9283 - sae: 2684.6362 - sse: 3529.3503\n","Epoch 41: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0211 - loss: 0.2162 - mae: 0.1261 - mse: 0.0462 - pearson_correlation: 2.3477e-16 - r2_keras: -92.6198 - rmse: 0.9165 - sae: 1960.9935 - sse: 2561.2920 - val_huber_loss: 0.1262 - val_loss: 0.3192 - val_mae: 0.3365 - val_mse: 0.2678 - val_pearson_correlation: 1.8141e-16 - val_r2_keras: -29.5674 - val_rmse: 0.9003 - val_sae: 329.1131 - val_sse: 428.8029 - learning_rate: 3.0464e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0260 - loss: 0.2190 - mae: 0.1390 - mse: 0.0521 - pearson_correlation: 1.6426e-16 - r2_keras: -112.9151 - rmse: 0.9288 - sae: 2685.9458 - sse: 3533.5024\n","Epoch 42: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0210 - loss: 0.2160 - mae: 0.1257 - mse: 0.0459 - pearson_correlation: 9.2918e-17 - r2_keras: -92.7240 - rmse: 0.9170 - sae: 1961.9141 - sse: 2564.2358 - val_huber_loss: 0.1262 - val_loss: 0.3191 - val_mae: 0.3364 - val_mse: 0.2676 - val_pearson_correlation: -7.8209e-17 - val_r2_keras: -29.5758 - val_rmse: 0.9005 - val_sae: 329.1881 - val_sse: 428.9204 - learning_rate: 3.0464e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0259 - loss: 0.2188 - mae: 0.1385 - mse: 0.0517 - pearson_correlation: 1.0247e-15 - r2_keras: -113.0334 - rmse: 0.9293 - sae: 2686.6987 - sse: 3537.1746\n","Epoch 43: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0209 - loss: 0.2158 - mae: 0.1251 - mse: 0.0456 - pearson_correlation: 5.8863e-16 - r2_keras: -92.8183 - rmse: 0.9174 - sae: 1962.4811 - sse: 2566.8643 - val_huber_loss: 0.1261 - val_loss: 0.3191 - val_mae: 0.3362 - val_mse: 0.2675 - val_pearson_correlation: -1.0654e-17 - val_r2_keras: -29.5869 - val_rmse: 0.9006 - val_sae: 329.3267 - val_sse: 429.0761 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0258 - loss: 0.2187 - mae: 0.1383 - mse: 0.0515 - pearson_correlation: 1.8149e-16 - r2_keras: -113.0620 - rmse: 0.9294 - sae: 2686.9805 - sse: 3538.0618\n","Epoch 44: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0208 - loss: 0.2157 - mae: 0.1249 - mse: 0.0455 - pearson_correlation: 6.7962e-17 - r2_keras: -92.8408 - rmse: 0.9175 - sae: 1962.6772 - sse: 2567.4958 - val_huber_loss: 0.1261 - val_loss: 0.3190 - val_mae: 0.3361 - val_mse: 0.2675 - val_pearson_correlation: -2.0942e-16 - val_r2_keras: -29.5913 - val_rmse: 0.9007 - val_sae: 329.4100 - val_sse: 429.1381 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0257 - loss: 0.2186 - mae: 0.1381 - mse: 0.0514 - pearson_correlation: -6.0267e-16 - r2_keras: -113.1040 - rmse: 0.9296 - sae: 2687.4258 - sse: 3539.3643\n","Epoch 45: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0207 - loss: 0.2156 - mae: 0.1247 - mse: 0.0454 - pearson_correlation: -4.6971e-16 - r2_keras: -92.8741 - rmse: 0.9177 - sae: 1962.9884 - sse: 2568.4270 - val_huber_loss: 0.1261 - val_loss: 0.3190 - val_mae: 0.3360 - val_mse: 0.2674 - val_pearson_correlation: -2.1285e-17 - val_r2_keras: -29.5982 - val_rmse: 0.9008 - val_sae: 329.4745 - val_sse: 429.2353 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0256 - loss: 0.2186 - mae: 0.1379 - mse: 0.0513 - pearson_correlation: 2.6427e-16 - r2_keras: -113.1514 - rmse: 0.9298 - sae: 2687.7852 - sse: 3540.8335\n","Epoch 46: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0207 - loss: 0.2156 - mae: 0.1245 - mse: 0.0453 - pearson_correlation: 1.2650e-16 - r2_keras: -92.9117 - rmse: 0.9179 - sae: 1963.2518 - sse: 2569.4763 - val_huber_loss: 0.1260 - val_loss: 0.3189 - val_mae: 0.3358 - val_mse: 0.2673 - val_pearson_correlation: 3.6893e-16 - val_r2_keras: -29.5989 - val_rmse: 0.9008 - val_sae: 329.4671 - val_sse: 429.2442 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0256 - loss: 0.2185 - mae: 0.1377 - mse: 0.0511 - pearson_correlation: 3.5700e-16 - r2_keras: -113.1757 - rmse: 0.9299 - sae: 2687.9905 - sse: 3541.5864\n","Epoch 47: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0206 - loss: 0.2155 - mae: 0.1244 - mse: 0.0451 - pearson_correlation: 2.3138e-16 - r2_keras: -92.9365 - rmse: 0.9180 - sae: 1963.4153 - sse: 2570.0793 - val_huber_loss: 0.1260 - val_loss: 0.3189 - val_mae: 0.3358 - val_mse: 0.2674 - val_pearson_correlation: -2.3061e-16 - val_r2_keras: -29.5970 - val_rmse: 0.9008 - val_sae: 329.4704 - val_sse: 429.2175 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0255 - loss: 0.2184 - mae: 0.1374 - mse: 0.0510 - pearson_correlation: -1.6759e-16 - r2_keras: -113.1997 - rmse: 0.9300 - sae: 2688.1663 - sse: 3542.3315\n","Epoch 48: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0206 - loss: 0.2154 - mae: 0.1241 - mse: 0.0450 - pearson_correlation: -1.5310e-16 - r2_keras: -92.9536 - rmse: 0.9181 - sae: 1963.5344 - sse: 2570.5896 - val_huber_loss: 0.1260 - val_loss: 0.3189 - val_mae: 0.3357 - val_mse: 0.2674 - val_pearson_correlation: 4.1867e-16 - val_r2_keras: -29.5968 - val_rmse: 0.9008 - val_sae: 329.4566 - val_sse: 429.2150 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0254 - loss: 0.2183 - mae: 0.1372 - mse: 0.0508 - pearson_correlation: 3.6226e-16 - r2_keras: -113.2597 - rmse: 0.9302 - sae: 2688.7117 - sse: 3544.1934\n","Epoch 49: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0205 - loss: 0.2153 - mae: 0.1239 - mse: 0.0449 - pearson_correlation: 2.7458e-16 - r2_keras: -93.0049 - rmse: 0.9184 - sae: 1963.9386 - sse: 2571.9631 - val_huber_loss: 0.1260 - val_loss: 0.3189 - val_mae: 0.3357 - val_mse: 0.2674 - val_pearson_correlation: -7.8068e-17 - val_r2_keras: -29.5948 - val_rmse: 0.9007 - val_sae: 329.4362 - val_sse: 429.1870 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0253 - loss: 0.2182 - mae: 0.1370 - mse: 0.0507 - pearson_correlation: -9.4098e-16 - r2_keras: -113.2896 - rmse: 0.9303 - sae: 2688.9146 - sse: 3545.1201\n","Epoch 50: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0205 - loss: 0.2153 - mae: 0.1237 - mse: 0.0448 - pearson_correlation: -7.1165e-16 - r2_keras: -93.0293 - rmse: 0.9185 - sae: 1964.0958 - sse: 2572.6331 - val_huber_loss: 0.1260 - val_loss: 0.3189 - val_mae: 0.3355 - val_mse: 0.2673 - val_pearson_correlation: -1.2072e-16 - val_r2_keras: -29.5877 - val_rmse: 0.9006 - val_sae: 329.3541 - val_sse: 429.0879 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0253 - loss: 0.2181 - mae: 0.1368 - mse: 0.0505 - pearson_correlation: -2.2097e-16 - r2_keras: -113.2937 - rmse: 0.9303 - sae: 2688.7915 - sse: 3545.2476\n","Epoch 51: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0204 - loss: 0.2152 - mae: 0.1236 - mse: 0.0446 - pearson_correlation: -1.4235e-16 - r2_keras: -93.0404 - rmse: 0.9186 - sae: 1964.0399 - sse: 2572.8162 - val_huber_loss: 0.1260 - val_loss: 0.3189 - val_mae: 0.3355 - val_mse: 0.2673 - val_pearson_correlation: 2.2368e-16 - val_r2_keras: -29.5910 - val_rmse: 0.9007 - val_sae: 329.3470 - val_sse: 429.1342 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0252 - loss: 0.2180 - mae: 0.1365 - mse: 0.0504 - pearson_correlation: -5.5521e-17 - r2_keras: -113.3598 - rmse: 0.9306 - sae: 2689.3696 - sse: 3547.2993\n","Epoch 52: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0204 - loss: 0.2151 - mae: 0.1233 - mse: 0.0445 - pearson_correlation: -1.2459e-16 - r2_keras: -93.0880 - rmse: 0.9188 - sae: 1964.4369 - sse: 2574.2251 - val_huber_loss: 0.1260 - val_loss: 0.3188 - val_mae: 0.3355 - val_mse: 0.2673 - val_pearson_correlation: 2.5218e-16 - val_r2_keras: -29.5825 - val_rmse: 0.9006 - val_sae: 329.3155 - val_sse: 429.0151 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - huber_loss: 0.0251 - loss: 0.2179 - mae: 0.1363 - mse: 0.0502 - pearson_correlation: 2.9265e-17 - r2_keras: -113.3937 - rmse: 0.9308 - sae: 2689.6580 - sse: 3548.3491\n","Epoch 53: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0203 - loss: 0.2150 - mae: 0.1231 - mse: 0.0444 - pearson_correlation: -3.6120e-18 - r2_keras: -93.1194 - rmse: 0.9189 - sae: 1964.6600 - sse: 2575.0291 - val_huber_loss: 0.1260 - val_loss: 0.3188 - val_mae: 0.3355 - val_mse: 0.2674 - val_pearson_correlation: 2.2377e-16 - val_r2_keras: -29.5861 - val_rmse: 0.9006 - val_sae: 329.3027 - val_sse: 429.0658 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0250 - loss: 0.2178 - mae: 0.1360 - mse: 0.0500 - pearson_correlation: 5.4030e-16 - r2_keras: -113.4567 - rmse: 0.9310 - sae: 2690.1792 - sse: 3550.3022\n","Epoch 54: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - huber_loss: 0.0203 - loss: 0.2149 - mae: 0.1228 - mse: 0.0442 - pearson_correlation: 3.7671e-16 - r2_keras: -93.1680 - rmse: 0.9192 - sae: 1965.0371 - sse: 2576.4080 - val_huber_loss: 0.1260 - val_loss: 0.3188 - val_mae: 0.3353 - val_mse: 0.2673 - val_pearson_correlation: -2.1324e-16 - val_r2_keras: -29.5787 - val_rmse: 0.9005 - val_sae: 329.2065 - val_sse: 428.9615 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0249 - loss: 0.2177 - mae: 0.1358 - mse: 0.0499 - pearson_correlation: -8.7232e-17 - r2_keras: -113.4602 - rmse: 0.9310 - sae: 2690.0554 - sse: 3550.4124\n","Epoch 55: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0202 - loss: 0.2148 - mae: 0.1227 - mse: 0.0441 - pearson_correlation: -1.8552e-17 - r2_keras: -93.1787 - rmse: 0.9192 - sae: 1964.9822 - sse: 2576.5798 - val_huber_loss: 0.1260 - val_loss: 0.3188 - val_mae: 0.3353 - val_mse: 0.2674 - val_pearson_correlation: 3.5538e-17 - val_r2_keras: -29.5811 - val_rmse: 0.9005 - val_sae: 329.2222 - val_sse: 428.9949 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0249 - loss: 0.2176 - mae: 0.1355 - mse: 0.0497 - pearson_correlation: -1.3002e-16 - r2_keras: -113.5134 - rmse: 0.9312 - sae: 2690.5454 - sse: 3552.0637\n","Epoch 56: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0201 - loss: 0.2148 - mae: 0.1224 - mse: 0.0440 - pearson_correlation: -1.6093e-16 - r2_keras: -93.2160 - rmse: 0.9194 - sae: 1965.3169 - sse: 2577.7012 - val_huber_loss: 0.1261 - val_loss: 0.3188 - val_mae: 0.3353 - val_mse: 0.2674 - val_pearson_correlation: -2.4535e-16 - val_r2_keras: -29.5722 - val_rmse: 0.9004 - val_sae: 329.1610 - val_sse: 428.8705 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0248 - loss: 0.2175 - mae: 0.1353 - mse: 0.0495 - pearson_correlation: 1.5062e-16 - r2_keras: -113.5535 - rmse: 0.9314 - sae: 2690.8577 - sse: 3553.3071\n","Epoch 57: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0201 - loss: 0.2147 - mae: 0.1222 - mse: 0.0438 - pearson_correlation: 6.7438e-17 - r2_keras: -93.2531 - rmse: 0.9196 - sae: 1965.5631 - sse: 2578.6519 - val_huber_loss: 0.1261 - val_loss: 0.3188 - val_mae: 0.3354 - val_mse: 0.2675 - val_pearson_correlation: 9.2452e-17 - val_r2_keras: -29.5762 - val_rmse: 0.9005 - val_sae: 329.1599 - val_sse: 428.9257 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0247 - loss: 0.2174 - mae: 0.1350 - mse: 0.0494 - pearson_correlation: -2.8193e-16 - r2_keras: -113.6173 - rmse: 0.9317 - sae: 2691.4089 - sse: 3555.2847\n","Epoch 58: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0200 - loss: 0.2146 - mae: 0.1219 - mse: 0.0437 - pearson_correlation: -1.7806e-16 - r2_keras: -93.3010 - rmse: 0.9198 - sae: 1965.9564 - sse: 2580.0337 - val_huber_loss: 0.1261 - val_loss: 0.3188 - val_mae: 0.3352 - val_mse: 0.2674 - val_pearson_correlation: -1.2099e-16 - val_r2_keras: -29.5648 - val_rmse: 0.9003 - val_sae: 329.0613 - val_sse: 428.7662 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0246 - loss: 0.2173 - mae: 0.1349 - mse: 0.0492 - pearson_correlation: -1.8630e-17 - r2_keras: -113.6021 - rmse: 0.9316 - sae: 2691.0859 - sse: 3554.8145\n","Epoch 59: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0200 - loss: 0.2145 - mae: 0.1218 - mse: 0.0436 - pearson_correlation: -1.9012e-17 - r2_keras: -93.2966 - rmse: 0.9198 - sae: 1965.7540 - sse: 2579.7871 - val_huber_loss: 0.1260 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2674 - val_pearson_correlation: 1.1741e-16 - val_r2_keras: -29.5734 - val_rmse: 0.9004 - val_sae: 329.0761 - val_sse: 428.8869 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0245 - loss: 0.2172 - mae: 0.1346 - mse: 0.0491 - pearson_correlation: 2.9229e-16 - r2_keras: -113.6915 - rmse: 0.9320 - sae: 2691.8335 - sse: 3557.5879\n","Epoch 60: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0199 - loss: 0.2144 - mae: 0.1215 - mse: 0.0434 - pearson_correlation: 1.8333e-16 - r2_keras: -93.3624 - rmse: 0.9201 - sae: 1966.2731 - sse: 2581.7087 - val_huber_loss: 0.1261 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2675 - val_pearson_correlation: -1.2106e-16 - val_r2_keras: -29.5598 - val_rmse: 0.9002 - val_sae: 329.0004 - val_sse: 428.6958 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0244 - loss: 0.2171 - mae: 0.1343 - mse: 0.0489 - pearson_correlation: -4.7735e-16 - r2_keras: -113.7049 - rmse: 0.9320 - sae: 2691.8525 - sse: 3558.0034\n","Epoch 61: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0198 - loss: 0.2143 - mae: 0.1213 - mse: 0.0433 - pearson_correlation: -3.0341e-16 - r2_keras: -93.3736 - rmse: 0.9202 - sae: 1966.2959 - sse: 2582.0134 - val_huber_loss: 0.1261 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2675 - val_pearson_correlation: -2.4230e-16 - val_r2_keras: -29.5525 - val_rmse: 0.9001 - val_sae: 328.8981 - val_sse: 428.5932 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0244 - loss: 0.2170 - mae: 0.1341 - mse: 0.0487 - pearson_correlation: -2.7351e-16 - r2_keras: -113.7499 - rmse: 0.9322 - sae: 2692.2007 - sse: 3559.3984\n","Epoch 62: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0198 - loss: 0.2142 - mae: 0.1211 - mse: 0.0432 - pearson_correlation: -1.8070e-16 - r2_keras: -93.4123 - rmse: 0.9204 - sae: 1966.5543 - sse: 2583.0452 - val_huber_loss: 0.1261 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2675 - val_pearson_correlation: 2.6724e-16 - val_r2_keras: -29.5546 - val_rmse: 0.9001 - val_sae: 328.9035 - val_sse: 428.6232 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0243 - loss: 0.2169 - mae: 0.1338 - mse: 0.0486 - pearson_correlation: -3.5436e-17 - r2_keras: -113.7780 - rmse: 0.9323 - sae: 2692.2644 - sse: 3560.2705\n","Epoch 63: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0197 - loss: 0.2141 - mae: 0.1209 - mse: 0.0430 - pearson_correlation: -2.1978e-17 - r2_keras: -93.4289 - rmse: 0.9204 - sae: 1966.5868 - sse: 2583.6013 - val_huber_loss: 0.1261 - val_loss: 0.3188 - val_mae: 0.3353 - val_mse: 0.2676 - val_pearson_correlation: 3.2093e-17 - val_r2_keras: -29.5446 - val_rmse: 0.9000 - val_sae: 328.8272 - val_sse: 428.4830 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0242 - loss: 0.2168 - mae: 0.1336 - mse: 0.0484 - pearson_correlation: 6.8820e-17 - r2_keras: -113.8407 - rmse: 0.9326 - sae: 2692.8088 - sse: 3562.2148\n","Epoch 64: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0197 - loss: 0.2141 - mae: 0.1207 - mse: 0.0429 - pearson_correlation: 1.4131e-16 - r2_keras: -93.4810 - rmse: 0.9207 - sae: 1966.9894 - sse: 2585.0188 - val_huber_loss: 0.1262 - val_loss: 0.3187 - val_mae: 0.3353 - val_mse: 0.2677 - val_pearson_correlation: -3.2092e-17 - val_r2_keras: -29.5477 - val_rmse: 0.9000 - val_sae: 328.8174 - val_sse: 428.5269 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0241 - loss: 0.2167 - mae: 0.1333 - mse: 0.0483 - pearson_correlation: 5.3279e-16 - r2_keras: -113.8752 - rmse: 0.9327 - sae: 2692.9482 - sse: 3563.2837\n","Epoch 65: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - huber_loss: 0.0196 - loss: 0.2140 - mae: 0.1204 - mse: 0.0428 - pearson_correlation: 3.6342e-16 - r2_keras: -93.5075 - rmse: 0.9208 - sae: 1967.0958 - sse: 2585.7727 - val_huber_loss: 0.1262 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2677 - val_pearson_correlation: -1.5699e-16 - val_r2_keras: -29.5399 - val_rmse: 0.8999 - val_sae: 328.7390 - val_sse: 428.4169 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0241 - loss: 0.2166 - mae: 0.1331 - mse: 0.0481 - pearson_correlation: -1.6315e-16 - r2_keras: -113.9064 - rmse: 0.9328 - sae: 2693.2246 - sse: 3564.2532\n","Epoch 66: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0196 - loss: 0.2139 - mae: 0.1202 - mse: 0.0426 - pearson_correlation: -2.3247e-17 - r2_keras: -93.5332 - rmse: 0.9209 - sae: 1967.2977 - sse: 2586.4761 - val_huber_loss: 0.1261 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2677 - val_pearson_correlation: -7.1417e-17 - val_r2_keras: -29.5293 - val_rmse: 0.8998 - val_sae: 328.6578 - val_sse: 428.2690 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0240 - loss: 0.2165 - mae: 0.1328 - mse: 0.0479 - pearson_correlation: 3.5125e-18 - r2_keras: -113.9520 - rmse: 0.9330 - sae: 2693.5295 - sse: 3565.6687\n","Epoch 67: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0195 - loss: 0.2138 - mae: 0.1200 - mse: 0.0425 - pearson_correlation: -1.7383e-17 - r2_keras: -93.5730 - rmse: 0.9211 - sae: 1967.5325 - sse: 2587.5288 - val_huber_loss: 0.1262 - val_loss: 0.3187 - val_mae: 0.3352 - val_mse: 0.2677 - val_pearson_correlation: 1.8209e-16 - val_r2_keras: -29.5339 - val_rmse: 0.8998 - val_sae: 328.6613 - val_sse: 428.3330 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0239 - loss: 0.2164 - mae: 0.1325 - mse: 0.0478 - pearson_correlation: -1.6050e-16 - r2_keras: -113.9937 - rmse: 0.9332 - sae: 2693.6841 - sse: 3566.9604\n","Epoch 68: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0194 - loss: 0.2137 - mae: 0.1197 - mse: 0.0424 - pearson_correlation: -9.5497e-17 - r2_keras: -93.6004 - rmse: 0.9212 - sae: 1967.6278 - sse: 2588.3865 - val_huber_loss: 0.1261 - val_loss: 0.3187 - val_mae: 0.3351 - val_mse: 0.2676 - val_pearson_correlation: -3.2163e-17 - val_r2_keras: -29.5229 - val_rmse: 0.8997 - val_sae: 328.5479 - val_sse: 428.1782 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0238 - loss: 0.2163 - mae: 0.1323 - mse: 0.0476 - pearson_correlation: 3.9235e-16 - r2_keras: -114.0274 - rmse: 0.9333 - sae: 2693.7529 - sse: 3568.0051\n","Epoch 69: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0194 - loss: 0.2136 - mae: 0.1195 - mse: 0.0422 - pearson_correlation: 2.1885e-16 - r2_keras: -93.6307 - rmse: 0.9214 - sae: 1967.7118 - sse: 2589.1743 - val_huber_loss: 0.1261 - val_loss: 0.3186 - val_mae: 0.3350 - val_mse: 0.2676 - val_pearson_correlation: 7.5077e-17 - val_r2_keras: -29.5155 - val_rmse: 0.8996 - val_sae: 328.5218 - val_sse: 428.0750 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0237 - loss: 0.2162 - mae: 0.1321 - mse: 0.0475 - pearson_correlation: -3.2538e-16 - r2_keras: -114.0395 - rmse: 0.9334 - sae: 2693.9158 - sse: 3568.3828\n","Epoch 70: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0193 - loss: 0.2136 - mae: 0.1193 - mse: 0.0421 - pearson_correlation: -1.7914e-16 - r2_keras: -93.6452 - rmse: 0.9215 - sae: 1967.8419 - sse: 2589.5012 - val_huber_loss: 0.1261 - val_loss: 0.3186 - val_mae: 0.3351 - val_mse: 0.2677 - val_pearson_correlation: -3.2183e-16 - val_r2_keras: -29.5150 - val_rmse: 0.8996 - val_sae: 328.5025 - val_sse: 428.0671 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0237 - loss: 0.2161 - mae: 0.1318 - mse: 0.0473 - pearson_correlation: 7.2906e-17 - r2_keras: -114.0963 - rmse: 0.9336 - sae: 2694.2290 - sse: 3570.1418\n","Epoch 71: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0193 - loss: 0.2135 - mae: 0.1191 - mse: 0.0420 - pearson_correlation: 5.8455e-17 - r2_keras: -93.6898 - rmse: 0.9217 - sae: 1968.0812 - sse: 2590.7539 - val_huber_loss: 0.1261 - val_loss: 0.3186 - val_mae: 0.3351 - val_mse: 0.2676 - val_pearson_correlation: -2.7551e-16 - val_r2_keras: -29.5041 - val_rmse: 0.8994 - val_sae: 328.4436 - val_sse: 427.9147 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0236 - loss: 0.2160 - mae: 0.1315 - mse: 0.0472 - pearson_correlation: 1.8789e-17 - r2_keras: -114.1015 - rmse: 0.9336 - sae: 2694.2878 - sse: 3570.3047\n","Epoch 72: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0192 - loss: 0.2134 - mae: 0.1188 - mse: 0.0419 - pearson_correlation: -7.1228e-17 - r2_keras: -93.6885 - rmse: 0.9217 - sae: 1968.1111 - sse: 2590.8057 - val_huber_loss: 0.1262 - val_loss: 0.3186 - val_mae: 0.3351 - val_mse: 0.2677 - val_pearson_correlation: 2.0039e-16 - val_r2_keras: -29.5043 - val_rmse: 0.8994 - val_sae: 328.4322 - val_sse: 427.9177 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0235 - loss: 0.2160 - mae: 0.1312 - mse: 0.0470 - pearson_correlation: 3.1541e-16 - r2_keras: -114.1809 - rmse: 0.9339 - sae: 2695.0750 - sse: 3572.7688\n","Epoch 73: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0192 - loss: 0.2133 - mae: 0.1186 - mse: 0.0417 - pearson_correlation: 2.0043e-16 - r2_keras: -93.7487 - rmse: 0.9219 - sae: 1968.6702 - sse: 2592.5337 - val_huber_loss: 0.1261 - val_loss: 0.3185 - val_mae: 0.3350 - val_mse: 0.2676 - val_pearson_correlation: -2.6857e-16 - val_r2_keras: -29.4952 - val_rmse: 0.8993 - val_sae: 328.3393 - val_sse: 427.7896 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0234 - loss: 0.2159 - mae: 0.1310 - mse: 0.0469 - pearson_correlation: 1.9048e-16 - r2_keras: -114.1925 - rmse: 0.9340 - sae: 2694.8789 - sse: 3573.1270\n","Epoch 74: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0191 - loss: 0.2132 - mae: 0.1184 - mse: 0.0416 - pearson_correlation: 1.2699e-16 - r2_keras: -93.7654 - rmse: 0.9220 - sae: 1968.5728 - sse: 2592.8777 - val_huber_loss: 0.1261 - val_loss: 0.3185 - val_mae: 0.3351 - val_mse: 0.2676 - val_pearson_correlation: 7.1609e-18 - val_r2_keras: -29.5011 - val_rmse: 0.8994 - val_sae: 328.3583 - val_sse: 427.8722 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0234 - loss: 0.2158 - mae: 0.1307 - mse: 0.0468 - pearson_correlation: 2.6514e-17 - r2_keras: -114.2620 - rmse: 0.9343 - sae: 2695.3650 - sse: 3575.2842\n","Epoch 75: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0191 - loss: 0.2132 - mae: 0.1181 - mse: 0.0415 - pearson_correlation: 6.6896e-17 - r2_keras: -93.8117 - rmse: 0.9222 - sae: 1968.8939 - sse: 2594.3157 - val_huber_loss: 0.1261 - val_loss: 0.3185 - val_mae: 0.3351 - val_mse: 0.2676 - val_pearson_correlation: 1.0747e-17 - val_r2_keras: -29.4953 - val_rmse: 0.8993 - val_sae: 328.2851 - val_sse: 427.7913 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0233 - loss: 0.2157 - mae: 0.1305 - mse: 0.0466 - pearson_correlation: -4.0184e-16 - r2_keras: -114.2923 - rmse: 0.9344 - sae: 2695.5479 - sse: 3576.2236\n","Epoch 76: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0190 - loss: 0.2131 - mae: 0.1179 - mse: 0.0414 - pearson_correlation: -1.9574e-16 - r2_keras: -93.8400 - rmse: 0.9224 - sae: 1969.0483 - sse: 2595.0364 - val_huber_loss: 0.1261 - val_loss: 0.3185 - val_mae: 0.3350 - val_mse: 0.2676 - val_pearson_correlation: 5.4116e-16 - val_r2_keras: -29.4880 - val_rmse: 0.8992 - val_sae: 328.2429 - val_sse: 427.6888 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0232 - loss: 0.2156 - mae: 0.1302 - mse: 0.0465 - pearson_correlation: 3.3850e-16 - r2_keras: -114.3141 - rmse: 0.9345 - sae: 2695.7275 - sse: 3576.8984\n","Epoch 77: val_loss did not improve from 0.30256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0190 - loss: 0.2130 - mae: 0.1177 - mse: 0.0413 - pearson_correlation: 1.8959e-16 - r2_keras: -93.8558 - rmse: 0.9224 - sae: 1969.1654 - sse: 2595.5017 - val_huber_loss: 0.1261 - val_loss: 0.3184 - val_mae: 0.3348 - val_mse: 0.2674 - val_pearson_correlation: -5.0190e-17 - val_r2_keras: -29.4896 - val_rmse: 0.8992 - val_sae: 328.1826 - val_sse: 427.7117 - learning_rate: 1.0000e-05\n","| \u001b[39m1        \u001b[39m | \u001b[39m-0.3184  \u001b[39m | \u001b[39m0.003808 \u001b[39m | \u001b[39m95.32    \u001b[39m | \u001b[39m74.54    \u001b[39m | \u001b[39m61.87    \u001b[39m | \u001b[39m19.82    \u001b[39m | \u001b[39m19.82    \u001b[39m |\n","Epoch 1/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 0.8152 - loss: 0.9790 - mae: 1.2135 - mse: 2.5792 - pearson_correlation: -2.6646e-16 - r2_keras: -321.7242 - rmse: 1.5633 - sae: 4963.4434 - sse: 10010.5000\n","Epoch 1: val_loss improved from inf to 0.41779, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 660ms/step - huber_loss: 0.7500 - loss: 0.9393 - mae: 1.1797 - mse: 2.3923 - pearson_correlation: -2.5146e-18 - r2_keras: -257.5713 - rmse: 1.5076 - sae: 3604.3613 - sse: 7183.0068 - val_huber_loss: 0.2539 - val_loss: 0.4178 - val_mae: 0.6241 - val_mse: 0.6090 - val_pearson_correlation: -3.2339e-16 - val_r2_keras: -22.3951 - val_rmse: 0.7877 - val_sae: 331.1005 - val_sse: 328.1884 - learning_rate: 6.7503e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.5728 - loss: 0.7367 - mae: 0.9755 - mse: 1.3097 - pearson_correlation: 2.7053e-17 - r2_keras: -188.0296 - rmse: 1.1965 - sae: 4053.5718 - sse: 5863.4629\n","Epoch 2: val_loss did not improve from 0.41779\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.4495 - loss: 0.6616 - mae: 0.8809 - mse: 1.1292 - pearson_correlation: 2.8258e-17 - r2_keras: -156.5892 - rmse: 1.1944 - sae: 2954.4329 - sse: 4279.2861 - val_huber_loss: 0.2587 - val_loss: 0.4225 - val_mae: 0.6409 - val_mse: 0.5998 - val_pearson_correlation: -2.5861e-16 - val_r2_keras: -23.3871 - val_rmse: 0.8042 - val_sae: 351.2607 - val_sse: 342.1047 - learning_rate: 6.7503e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2371 - loss: 0.4010 - mae: 0.5598 - mse: 0.5111 - pearson_correlation: 1.7824e-17 - r2_keras: -131.3741 - rmse: 1.0012 - sae: 3279.9065 - sse: 4106.0801\n","Epoch 3: val_loss did not improve from 0.41779\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1966 - loss: 0.3763 - mae: 0.5248 - mse: 0.4545 - pearson_correlation: 2.9881e-17 - r2_keras: -106.9112 - rmse: 0.9806 - sae: 2378.7808 - sse: 2968.0198 - val_huber_loss: 0.2654 - val_loss: 0.4292 - val_mae: 0.6618 - val_mse: 0.5980 - val_pearson_correlation: -2.1638e-16 - val_r2_keras: -24.8358 - val_rmse: 0.8277 - val_sae: 371.0861 - val_sse: 362.4276 - learning_rate: 6.7503e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1592 - loss: 0.3230 - mae: 0.4540 - mse: 0.3402 - pearson_correlation: 7.2972e-17 - r2_keras: -105.3052 - rmse: 0.8972 - sae: 2857.8091 - sse: 3297.4534\n","Epoch 4: val_loss did not improve from 0.41779\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1370 - loss: 0.3095 - mae: 0.4232 - mse: 0.3088 - pearson_correlation: 1.3348e-16 - r2_keras: -90.0608 - rmse: 0.9155 - sae: 2099.7209 - sse: 2435.1396 - val_huber_loss: 0.2756 - val_loss: 0.4394 - val_mae: 0.6800 - val_mse: 0.6095 - val_pearson_correlation: -2.9961e-16 - val_r2_keras: -25.6177 - val_rmse: 0.8402 - val_sae: 380.3444 - val_sse: 373.3958 - learning_rate: 6.7503e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1142 - loss: 0.2779 - mae: 0.3647 - mse: 0.2331 - pearson_correlation: 1.0646e-16 - r2_keras: -99.9785 - rmse: 0.8745 - sae: 2745.4697 - sse: 3132.2278\n","Epoch 5: val_loss did not improve from 0.41779\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0966 - loss: 0.2672 - mae: 0.3440 - mse: 0.2107 - pearson_correlation: 2.8033e-17 - r2_keras: -83.5250 - rmse: 0.8759 - sae: 2003.1891 - sse: 2289.9783 - val_huber_loss: 0.2603 - val_loss: 0.4240 - val_mae: 0.6602 - val_mse: 0.5677 - val_pearson_correlation: -8.2010e-18 - val_r2_keras: -26.5900 - val_rmse: 0.8554 - val_sae: 385.4125 - val_sse: 387.0362 - learning_rate: 6.7503e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0997 - loss: 0.2634 - mae: 0.3162 - mse: 0.2125 - pearson_correlation: -5.2857e-16 - r2_keras: -97.4959 - rmse: 0.8637 - sae: 2650.8359 - sse: 3055.2195\n","Epoch 6: val_loss did not improve from 0.41779\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0815 - loss: 0.2523 - mae: 0.2980 - mse: 0.1877 - pearson_correlation: -3.4838e-16 - r2_keras: -83.0545 - rmse: 0.8786 - sae: 1946.7227 - sse: 2252.5347 - val_huber_loss: 0.2644 - val_loss: 0.4281 - val_mae: 0.6566 - val_mse: 0.5690 - val_pearson_correlation: -4.6746e-17 - val_r2_keras: -26.8153 - val_rmse: 0.8588 - val_sae: 382.6740 - val_sse: 390.1966 - learning_rate: 6.7503e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0811 - loss: 0.2447 - mae: 0.2848 - mse: 0.1647 - pearson_correlation: 2.4415e-17 - r2_keras: -102.8680 - rmse: 0.8869 - sae: 2704.5369 - sse: 3221.8555\n","Epoch 7: val_loss did not improve from 0.41779\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0700 - loss: 0.2380 - mae: 0.2675 - mse: 0.1506 - pearson_correlation: 1.0539e-16 - r2_keras: -85.0413 - rmse: 0.8807 - sae: 1971.4022 - sse: 2344.9214 - val_huber_loss: 0.2563 - val_loss: 0.4200 - val_mae: 0.6356 - val_mse: 0.5479 - val_pearson_correlation: -4.7807e-17 - val_r2_keras: -27.7504 - val_rmse: 0.8732 - val_sae: 386.9467 - val_sse: 403.3141 - learning_rate: 1.3501e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0770 - loss: 0.2406 - mae: 0.2700 - mse: 0.1573 - pearson_correlation: 1.0402e-16 - r2_keras: -100.2176 - rmse: 0.8755 - sae: 2661.5132 - sse: 3139.6426\n","Epoch 8: val_loss improved from 0.41779 to 0.39920, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0609 - loss: 0.2308 - mae: 0.2482 - mse: 0.1369 - pearson_correlation: 4.4336e-17 - r2_keras: -83.8935 - rmse: 0.8784 - sae: 1947.3793 - sse: 2297.3750 - val_huber_loss: 0.2356 - val_loss: 0.3992 - val_mae: 0.5973 - val_mse: 0.4995 - val_pearson_correlation: 3.2085e-16 - val_r2_keras: -27.7495 - val_rmse: 0.8731 - val_sae: 382.6957 - val_sse: 403.3006 - learning_rate: 1.3501e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0741 - loss: 0.2377 - mae: 0.2619 - mse: 0.1513 - pearson_correlation: -1.3770e-16 - r2_keras: -99.7992 - rmse: 0.8737 - sae: 2652.3843 - sse: 3126.6665\n","Epoch 9: val_loss improved from 0.39920 to 0.36610, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0583 - loss: 0.2281 - mae: 0.2414 - mse: 0.1315 - pearson_correlation: -2.1811e-16 - r2_keras: -83.6720 - rmse: 0.8777 - sae: 1941.7432 - sse: 2289.3977 - val_huber_loss: 0.2025 - val_loss: 0.3661 - val_mae: 0.5382 - val_mse: 0.4279 - val_pearson_correlation: 1.4342e-16 - val_r2_keras: -27.4879 - val_rmse: 0.8692 - val_sae: 371.4095 - val_sse: 399.6313 - learning_rate: 1.3501e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0719 - loss: 0.2355 - mae: 0.2554 - mse: 0.1466 - pearson_correlation: 9.8568e-17 - r2_keras: -99.6661 - rmse: 0.8731 - sae: 2647.1548 - sse: 3122.5356\n","Epoch 10: val_loss improved from 0.36610 to 0.33140, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0564 - loss: 0.2261 - mae: 0.2351 - mse: 0.1273 - pearson_correlation: 9.1982e-17 - r2_keras: -83.5350 - rmse: 0.8769 - sae: 1938.0787 - sse: 2286.0779 - val_huber_loss: 0.1678 - val_loss: 0.3314 - val_mae: 0.4688 - val_mse: 0.3546 - val_pearson_correlation: -1.3344e-16 - val_r2_keras: -28.0110 - val_rmse: 0.8771 - val_sae: 363.3148 - val_sse: 406.9699 - learning_rate: 1.3501e-04\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0703 - loss: 0.2339 - mae: 0.2500 - mse: 0.1431 - pearson_correlation: 2.2509e-16 - r2_keras: -99.8100 - rmse: 0.8737 - sae: 2645.7783 - sse: 3127.0007\n","Epoch 11: val_loss improved from 0.33140 to 0.30812, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - huber_loss: 0.0551 - loss: 0.2246 - mae: 0.2304 - mse: 0.1241 - pearson_correlation: 2.2144e-16 - r2_keras: -83.5869 - rmse: 0.8769 - sae: 1937.0669 - sse: 2288.5371 - val_huber_loss: 0.1446 - val_loss: 0.3081 - val_mae: 0.4097 - val_mse: 0.3076 - val_pearson_correlation: -6.9694e-17 - val_r2_keras: -29.0880 - val_rmse: 0.8932 - val_sae: 358.4037 - val_sse: 422.0784 - learning_rate: 1.3501e-04\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0684 - loss: 0.2320 - mae: 0.2432 - mse: 0.1396 - pearson_correlation: -4.3414e-16 - r2_keras: -99.6700 - rmse: 0.8731 - sae: 2638.8875 - sse: 3122.6584\n","Epoch 12: val_loss improved from 0.30812 to 0.29714, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0535 - loss: 0.2229 - mae: 0.2243 - mse: 0.1208 - pearson_correlation: -2.5455e-16 - r2_keras: -83.4782 - rmse: 0.8764 - sae: 1932.2836 - sse: 2285.4622 - val_huber_loss: 0.1336 - val_loss: 0.2971 - val_mae: 0.3710 - val_mse: 0.2858 - val_pearson_correlation: -2.9577e-17 - val_r2_keras: -30.5485 - val_rmse: 0.9147 - val_sae: 359.2286 - val_sse: 442.5659 - learning_rate: 1.3501e-04\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0667 - loss: 0.2302 - mae: 0.2375 - mse: 0.1356 - pearson_correlation: 9.5477e-16 - r2_keras: -100.1589 - rmse: 0.8753 - sae: 2641.0894 - sse: 3137.8220\n","Epoch 13: val_loss improved from 0.29714 to 0.29128, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0521 - loss: 0.2214 - mae: 0.2183 - mse: 0.1174 - pearson_correlation: 6.9098e-16 - r2_keras: -83.7975 - rmse: 0.8777 - sae: 1933.6849 - sse: 2295.4937 - val_huber_loss: 0.1278 - val_loss: 0.2913 - val_mae: 0.3505 - val_mse: 0.2747 - val_pearson_correlation: 9.6063e-17 - val_r2_keras: -32.1024 - val_rmse: 0.9369 - val_sae: 364.5454 - val_sse: 464.3643 - learning_rate: 1.3501e-04\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0656 - loss: 0.2291 - mae: 0.2317 - mse: 0.1337 - pearson_correlation: -4.7913e-16 - r2_keras: -100.0201 - rmse: 0.8747 - sae: 2634.2212 - sse: 3133.5166\n","Epoch 14: val_loss improved from 0.29128 to 0.29079, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0511 - loss: 0.2203 - mae: 0.2136 - mse: 0.1156 - pearson_correlation: -3.8523e-16 - r2_keras: -83.6363 - rmse: 0.8767 - sae: 1928.6420 - sse: 2291.8186 - val_huber_loss: 0.1273 - val_loss: 0.2908 - val_mae: 0.3480 - val_mse: 0.2742 - val_pearson_correlation: 4.0119e-17 - val_r2_keras: -33.0379 - val_rmse: 0.9501 - val_sae: 368.9734 - val_sse: 477.4880 - learning_rate: 1.3501e-04\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0642 - loss: 0.2277 - mae: 0.2270 - mse: 0.1305 - pearson_correlation: 3.9604e-16 - r2_keras: -100.6311 - rmse: 0.8773 - sae: 2640.3123 - sse: 3152.4688\n","Epoch 15: val_loss did not improve from 0.29079\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0500 - loss: 0.2190 - mae: 0.2085 - mse: 0.1128 - pearson_correlation: 3.0504e-16 - r2_keras: -84.0503 - rmse: 0.8786 - sae: 1932.6136 - sse: 2304.5317 - val_huber_loss: 0.1282 - val_loss: 0.2917 - val_mae: 0.3500 - val_mse: 0.2768 - val_pearson_correlation: 2.2106e-16 - val_r2_keras: -33.8375 - val_rmse: 0.9612 - val_sae: 373.5249 - val_sse: 488.7047 - learning_rate: 1.3501e-04\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0629 - loss: 0.2263 - mae: 0.2223 - mse: 0.1284 - pearson_correlation: -1.3419e-16 - r2_keras: -100.2281 - rmse: 0.8756 - sae: 2630.8374 - sse: 3139.9705\n","Epoch 16: val_loss improved from 0.29079 to 0.28974, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0489 - loss: 0.2178 - mae: 0.2049 - mse: 0.1108 - pearson_correlation: -8.5198e-17 - r2_keras: -83.8212 - rmse: 0.8777 - sae: 1926.4882 - sse: 2296.6631 - val_huber_loss: 0.1263 - val_loss: 0.2897 - val_mae: 0.3487 - val_mse: 0.2734 - val_pearson_correlation: -1.8790e-16 - val_r2_keras: -33.8038 - val_rmse: 0.9607 - val_sae: 373.8436 - val_sse: 488.2311 - learning_rate: 1.3501e-04\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0613 - loss: 0.2248 - mae: 0.2165 - mse: 0.1246 - pearson_correlation: 5.9328e-17 - r2_keras: -100.9448 - rmse: 0.8786 - sae: 2636.4541 - sse: 3162.2000\n","Epoch 17: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0478 - loss: 0.2165 - mae: 0.1996 - mse: 0.1077 - pearson_correlation: 8.2194e-17 - r2_keras: -84.2891 - rmse: 0.8797 - sae: 1930.0669 - sse: 2311.3667 - val_huber_loss: 0.1316 - val_loss: 0.2950 - val_mae: 0.3569 - val_mse: 0.2844 - val_pearson_correlation: 1.6951e-16 - val_r2_keras: -34.8496 - val_rmse: 0.9750 - val_sae: 380.8775 - val_sse: 502.9023 - learning_rate: 1.3501e-04\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0604 - loss: 0.2238 - mae: 0.2136 - mse: 0.1235 - pearson_correlation: -3.8654e-16 - r2_keras: -100.5371 - rmse: 0.8769 - sae: 2627.5701 - sse: 3149.5532\n","Epoch 18: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - huber_loss: 0.0469 - loss: 0.2156 - mae: 0.1974 - mse: 0.1065 - pearson_correlation: -2.9926e-16 - r2_keras: -84.1052 - rmse: 0.8793 - sae: 1924.3634 - sse: 2303.9666 - val_huber_loss: 0.1266 - val_loss: 0.2900 - val_mae: 0.3515 - val_mse: 0.2750 - val_pearson_correlation: 1.8489e-16 - val_r2_keras: -34.1808 - val_rmse: 0.9659 - val_sae: 376.9108 - val_sse: 493.5208 - learning_rate: 1.3501e-04\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0591 - loss: 0.2225 - mae: 0.2107 - mse: 0.1197 - pearson_correlation: -6.9299e-18 - r2_keras: -101.4857 - rmse: 0.8810 - sae: 2635.9568 - sse: 3178.9783\n","Epoch 19: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0458 - loss: 0.2144 - mae: 0.1954 - mse: 0.1032 - pearson_correlation: -5.7266e-17 - r2_keras: -84.7205 - rmse: 0.8819 - sae: 1930.4777 - sse: 2323.3828 - val_huber_loss: 0.1288 - val_loss: 0.2922 - val_mae: 0.3581 - val_mse: 0.2796 - val_pearson_correlation: -1.0762e-17 - val_r2_keras: -34.4381 - val_rmse: 0.9694 - val_sae: 378.3073 - val_sse: 497.1294 - learning_rate: 1.3501e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0578 - loss: 0.2212 - mae: 0.2056 - mse: 0.1177 - pearson_correlation: -1.1733e-16 - r2_keras: -101.4176 - rmse: 0.8807 - sae: 2632.3745 - sse: 3176.8667\n","Epoch 20: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0448 - loss: 0.2132 - mae: 0.1898 - mse: 0.1015 - pearson_correlation: -9.0156e-17 - r2_keras: -84.6122 - rmse: 0.8811 - sae: 1926.4952 - sse: 2321.2368 - val_huber_loss: 0.1366 - val_loss: 0.2999 - val_mae: 0.3690 - val_mse: 0.2956 - val_pearson_correlation: 1.8658e-16 - val_r2_keras: -35.4083 - val_rmse: 0.9826 - val_sae: 386.9896 - val_sse: 510.7391 - learning_rate: 1.3501e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0564 - loss: 0.2197 - mae: 0.2034 - mse: 0.1146 - pearson_correlation: 3.1865e-18 - r2_keras: -101.2340 - rmse: 0.8799 - sae: 2630.3008 - sse: 3171.1699\n","Epoch 21: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0436 - loss: 0.2119 - mae: 0.1895 - mse: 0.0987 - pearson_correlation: -6.7887e-17 - r2_keras: -84.8591 - rmse: 0.8837 - sae: 1928.0469 - sse: 2321.7715 - val_huber_loss: 0.1279 - val_loss: 0.2911 - val_mae: 0.3538 - val_mse: 0.2784 - val_pearson_correlation: -1.6469e-16 - val_r2_keras: -33.9520 - val_rmse: 0.9627 - val_sae: 375.1351 - val_sse: 490.3104 - learning_rate: 1.3501e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0558 - loss: 0.2190 - mae: 0.2032 - mse: 0.1127 - pearson_correlation: 4.2058e-16 - r2_keras: -103.1004 - rmse: 0.8879 - sae: 2650.4246 - sse: 3229.0630\n","Epoch 22: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0431 - loss: 0.2113 - mae: 0.1873 - mse: 0.0970 - pearson_correlation: 3.0417e-16 - r2_keras: -85.7897 - rmse: 0.8864 - sae: 1938.7098 - sse: 2356.6873 - val_huber_loss: 0.1312 - val_loss: 0.2944 - val_mae: 0.3596 - val_mse: 0.2852 - val_pearson_correlation: -1.2825e-16 - val_r2_keras: -34.6117 - val_rmse: 0.9718 - val_sae: 380.4039 - val_sse: 499.5644 - learning_rate: 2.7001e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0546 - loss: 0.2179 - mae: 0.1995 - mse: 0.1106 - pearson_correlation: -3.6751e-16 - r2_keras: -102.2805 - rmse: 0.8844 - sae: 2638.1902 - sse: 3203.6309\n","Epoch 23: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0419 - loss: 0.2102 - mae: 0.1835 - mse: 0.0949 - pearson_correlation: -1.7904e-16 - r2_keras: -85.3144 - rmse: 0.8847 - sae: 1931.2435 - sse: 2340.5696 - val_huber_loss: 0.1326 - val_loss: 0.2958 - val_mae: 0.3630 - val_mse: 0.2882 - val_pearson_correlation: 2.5434e-16 - val_r2_keras: -34.8276 - val_rmse: 0.9747 - val_sae: 382.2865 - val_sse: 502.5935 - learning_rate: 2.7001e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0542 - loss: 0.2174 - mae: 0.1985 - mse: 0.1098 - pearson_correlation: -1.6470e-16 - r2_keras: -101.9647 - rmse: 0.8830 - sae: 2633.1729 - sse: 3193.8369\n","Epoch 24: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0415 - loss: 0.2097 - mae: 0.1826 - mse: 0.0941 - pearson_correlation: -1.5529e-16 - r2_keras: -85.1673 - rmse: 0.8843 - sae: 1928.3258 - sse: 2334.7839 - val_huber_loss: 0.1326 - val_loss: 0.2959 - val_mae: 0.3634 - val_mse: 0.2885 - val_pearson_correlation: 1.0599e-17 - val_r2_keras: -34.8231 - val_rmse: 0.9747 - val_sae: 382.4801 - val_sse: 502.5305 - learning_rate: 2.7001e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0539 - loss: 0.2171 - mae: 0.1975 - mse: 0.1092 - pearson_correlation: 2.6206e-16 - r2_keras: -102.0230 - rmse: 0.8833 - sae: 2633.3538 - sse: 3195.6440\n","Epoch 25: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0413 - loss: 0.2095 - mae: 0.1820 - mse: 0.0935 - pearson_correlation: 2.0832e-16 - r2_keras: -85.2501 - rmse: 0.8849 - sae: 1928.7660 - sse: 2336.5044 - val_huber_loss: 0.1329 - val_loss: 0.2962 - val_mae: 0.3634 - val_mse: 0.2892 - val_pearson_correlation: -1.9087e-16 - val_r2_keras: -34.8117 - val_rmse: 0.9745 - val_sae: 382.3169 - val_sse: 502.3701 - learning_rate: 2.7001e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0535 - loss: 0.2168 - mae: 0.1971 - mse: 0.1086 - pearson_correlation: -1.8440e-16 - r2_keras: -102.0044 - rmse: 0.8832 - sae: 2632.9321 - sse: 3195.0691\n","Epoch 26: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0410 - loss: 0.2091 - mae: 0.1814 - mse: 0.0929 - pearson_correlation: -6.5791e-17 - r2_keras: -85.2354 - rmse: 0.8848 - sae: 1928.3691 - sse: 2336.0938 - val_huber_loss: 0.1336 - val_loss: 0.2968 - val_mae: 0.3647 - val_mse: 0.2907 - val_pearson_correlation: 1.3736e-16 - val_r2_keras: -34.9044 - val_rmse: 0.9758 - val_sae: 383.2092 - val_sse: 503.6715 - learning_rate: 2.7001e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0533 - loss: 0.2165 - mae: 0.1962 - mse: 0.1080 - pearson_correlation: -9.7715e-17 - r2_keras: -102.0669 - rmse: 0.8835 - sae: 2633.2725 - sse: 3197.0056\n","Epoch 27: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0407 - loss: 0.2089 - mae: 0.1808 - mse: 0.0924 - pearson_correlation: -6.0111e-17 - r2_keras: -85.3089 - rmse: 0.8852 - sae: 1928.8656 - sse: 2337.7585 - val_huber_loss: 0.1335 - val_loss: 0.2967 - val_mae: 0.3643 - val_mse: 0.2906 - val_pearson_correlation: -3.3888e-16 - val_r2_keras: -34.8458 - val_rmse: 0.9750 - val_sae: 382.7537 - val_sse: 502.8493 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0531 - loss: 0.2163 - mae: 0.1959 - mse: 0.1076 - pearson_correlation: 6.5347e-17 - r2_keras: -102.0513 - rmse: 0.8834 - sae: 2632.6370 - sse: 3196.5239\n","Epoch 28: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0406 - loss: 0.2087 - mae: 0.1804 - mse: 0.0920 - pearson_correlation: -2.6833e-17 - r2_keras: -85.3115 - rmse: 0.8853 - sae: 1928.4458 - sse: 2337.5886 - val_huber_loss: 0.1336 - val_loss: 0.2968 - val_mae: 0.3645 - val_mse: 0.2909 - val_pearson_correlation: 2.1201e-17 - val_r2_keras: -34.8206 - val_rmse: 0.9746 - val_sae: 382.6323 - val_sse: 502.4959 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0530 - loss: 0.2162 - mae: 0.1957 - mse: 0.1073 - pearson_correlation: 1.5274e-16 - r2_keras: -102.0609 - rmse: 0.8834 - sae: 2632.8169 - sse: 3196.8193\n","Epoch 29: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0404 - loss: 0.2085 - mae: 0.1801 - mse: 0.0918 - pearson_correlation: 2.8110e-17 - r2_keras: -85.3246 - rmse: 0.8854 - sae: 1928.5547 - sse: 2337.8647 - val_huber_loss: 0.1335 - val_loss: 0.2967 - val_mae: 0.3644 - val_mse: 0.2908 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.7912 - val_rmse: 0.9742 - val_sae: 382.4911 - val_sse: 502.0824 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0529 - loss: 0.2161 - mae: 0.1953 - mse: 0.1072 - pearson_correlation: 5.8725e-17 - r2_keras: -102.0913 - rmse: 0.8836 - sae: 2633.0405 - sse: 3197.7622\n","Epoch 30: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0404 - loss: 0.2085 - mae: 0.1797 - mse: 0.0916 - pearson_correlation: 7.7710e-17 - r2_keras: -85.3342 - rmse: 0.8854 - sae: 1928.6494 - sse: 2338.3689 - val_huber_loss: 0.1339 - val_loss: 0.2971 - val_mae: 0.3649 - val_mse: 0.2916 - val_pearson_correlation: 1.5898e-16 - val_r2_keras: -34.8250 - val_rmse: 0.9747 - val_sae: 382.7299 - val_sse: 502.5567 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0527 - loss: 0.2159 - mae: 0.1949 - mse: 0.1069 - pearson_correlation: -1.8008e-16 - r2_keras: -102.0127 - rmse: 0.8832 - sae: 2631.6580 - sse: 3195.3267\n","Epoch 31: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0402 - loss: 0.2083 - mae: 0.1793 - mse: 0.0914 - pearson_correlation: -1.1838e-16 - r2_keras: -85.2912 - rmse: 0.8852 - sae: 1927.7244 - sse: 2336.8540 - val_huber_loss: 0.1337 - val_loss: 0.2968 - val_mae: 0.3648 - val_mse: 0.2911 - val_pearson_correlation: -4.2487e-17 - val_r2_keras: -34.7691 - val_rmse: 0.9739 - val_sae: 382.3964 - val_sse: 501.7721 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0526 - loss: 0.2158 - mae: 0.1945 - mse: 0.1066 - pearson_correlation: -1.8371e-16 - r2_keras: -102.0526 - rmse: 0.8834 - sae: 2632.0469 - sse: 3196.5630\n","Epoch 32: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0401 - loss: 0.2082 - mae: 0.1789 - mse: 0.0911 - pearson_correlation: -1.2917e-16 - r2_keras: -85.3279 - rmse: 0.8854 - sae: 1928.0197 - sse: 2337.7971 - val_huber_loss: 0.1340 - val_loss: 0.2972 - val_mae: 0.3651 - val_mse: 0.2919 - val_pearson_correlation: 1.3787e-16 - val_r2_keras: -34.8079 - val_rmse: 0.9745 - val_sae: 382.6009 - val_sse: 502.3176 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0525 - loss: 0.2157 - mae: 0.1941 - mse: 0.1064 - pearson_correlation: 2.4057e-16 - r2_keras: -102.0157 - rmse: 0.8833 - sae: 2630.8481 - sse: 3195.4170\n","Epoch 33: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0400 - loss: 0.2081 - mae: 0.1785 - mse: 0.0910 - pearson_correlation: 4.6458e-17 - r2_keras: -85.2955 - rmse: 0.8853 - sae: 1927.1075 - sse: 2336.9421 - val_huber_loss: 0.1341 - val_loss: 0.2973 - val_mae: 0.3656 - val_mse: 0.2921 - val_pearson_correlation: -3.1837e-17 - val_r2_keras: -34.7919 - val_rmse: 0.9742 - val_sae: 382.6425 - val_sse: 502.0923 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0523 - loss: 0.2155 - mae: 0.1938 - mse: 0.1060 - pearson_correlation: 8.6548e-17 - r2_keras: -102.0582 - rmse: 0.8834 - sae: 2631.6006 - sse: 3196.7354\n","Epoch 34: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0399 - loss: 0.2079 - mae: 0.1781 - mse: 0.0906 - pearson_correlation: 4.7652e-17 - r2_keras: -85.3329 - rmse: 0.8855 - sae: 1927.6863 - sse: 2337.9280 - val_huber_loss: 0.1344 - val_loss: 0.2976 - val_mae: 0.3661 - val_mse: 0.2927 - val_pearson_correlation: 1.8021e-16 - val_r2_keras: -34.8198 - val_rmse: 0.9746 - val_sae: 382.8588 - val_sse: 502.4838 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0522 - loss: 0.2154 - mae: 0.1933 - mse: 0.1059 - pearson_correlation: -3.4550e-16 - r2_keras: -101.9550 - rmse: 0.8830 - sae: 2630.0645 - sse: 3193.5349\n","Epoch 35: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0398 - loss: 0.2078 - mae: 0.1778 - mse: 0.0905 - pearson_correlation: -2.0525e-16 - r2_keras: -85.2853 - rmse: 0.8853 - sae: 1926.7643 - sse: 2336.0430 - val_huber_loss: 0.1342 - val_loss: 0.2974 - val_mae: 0.3657 - val_mse: 0.2924 - val_pearson_correlation: 3.3952e-16 - val_r2_keras: -34.7976 - val_rmse: 0.9743 - val_sae: 382.5941 - val_sse: 502.1722 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0520 - loss: 0.2152 - mae: 0.1930 - mse: 0.1054 - pearson_correlation: 3.6640e-16 - r2_keras: -102.0869 - rmse: 0.8836 - sae: 2631.1750 - sse: 3197.6257\n","Epoch 36: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0396 - loss: 0.2077 - mae: 0.1774 - mse: 0.0901 - pearson_correlation: 2.6768e-16 - r2_keras: -85.3772 - rmse: 0.8857 - sae: 1927.4818 - sse: 2338.8159 - val_huber_loss: 0.1349 - val_loss: 0.2981 - val_mae: 0.3674 - val_mse: 0.2938 - val_pearson_correlation: -3.1768e-17 - val_r2_keras: -34.8477 - val_rmse: 0.9750 - val_sae: 383.2207 - val_sse: 502.8748 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0519 - loss: 0.2151 - mae: 0.1924 - mse: 0.1052 - pearson_correlation: 2.0531e-16 - r2_keras: -102.0129 - rmse: 0.8832 - sae: 2630.3645 - sse: 3195.3328\n","Epoch 37: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0395 - loss: 0.2075 - mae: 0.1769 - mse: 0.0899 - pearson_correlation: 1.8197e-16 - r2_keras: -85.3451 - rmse: 0.8857 - sae: 1927.0532 - sse: 2337.4897 - val_huber_loss: 0.1345 - val_loss: 0.2976 - val_mae: 0.3666 - val_mse: 0.2929 - val_pearson_correlation: 6.3652e-17 - val_r2_keras: -34.8006 - val_rmse: 0.9744 - val_sae: 382.7471 - val_sse: 502.2151 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0518 - loss: 0.2150 - mae: 0.1922 - mse: 0.1050 - pearson_correlation: 1.0109e-16 - r2_keras: -102.1119 - rmse: 0.8837 - sae: 2630.5171 - sse: 3198.4019\n","Epoch 38: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0394 - loss: 0.2074 - mae: 0.1766 - mse: 0.0896 - pearson_correlation: 5.4025e-17 - r2_keras: -85.4003 - rmse: 0.8859 - sae: 1927.0266 - sse: 2339.4087 - val_huber_loss: 0.1353 - val_loss: 0.2984 - val_mae: 0.3682 - val_mse: 0.2946 - val_pearson_correlation: 2.6451e-16 - val_r2_keras: -34.8690 - val_rmse: 0.9753 - val_sae: 383.4657 - val_sse: 503.1740 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0516 - loss: 0.2148 - mae: 0.1916 - mse: 0.1047 - pearson_correlation: 1.2850e-16 - r2_keras: -101.9924 - rmse: 0.8832 - sae: 2629.2827 - sse: 3194.6943\n","Epoch 39: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0393 - loss: 0.2073 - mae: 0.1762 - mse: 0.0894 - pearson_correlation: 1.1736e-16 - r2_keras: -85.3513 - rmse: 0.8858 - sae: 1926.4142 - sse: 2337.2969 - val_huber_loss: 0.1353 - val_loss: 0.2984 - val_mae: 0.3684 - val_mse: 0.2946 - val_pearson_correlation: -8.4797e-17 - val_r2_keras: -34.8225 - val_rmse: 0.9747 - val_sae: 383.1791 - val_sse: 502.5212 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0515 - loss: 0.2146 - mae: 0.1912 - mse: 0.1043 - pearson_correlation: 2.7778e-17 - r2_keras: -102.1148 - rmse: 0.8837 - sae: 2630.9844 - sse: 3198.4932\n","Epoch 40: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0392 - loss: 0.2071 - mae: 0.1758 - mse: 0.0890 - pearson_correlation: 2.5184e-17 - r2_keras: -85.4530 - rmse: 0.8863 - sae: 1927.6279 - sse: 2340.0647 - val_huber_loss: 0.1357 - val_loss: 0.2988 - val_mae: 0.3686 - val_mse: 0.2955 - val_pearson_correlation: 4.7587e-16 - val_r2_keras: -34.8825 - val_rmse: 0.9755 - val_sae: 383.4052 - val_sse: 503.3636 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0513 - loss: 0.2145 - mae: 0.1911 - mse: 0.1041 - pearson_correlation: 2.1590e-16 - r2_keras: -102.1221 - rmse: 0.8837 - sae: 2630.0742 - sse: 3198.7183\n","Epoch 41: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0391 - loss: 0.2070 - mae: 0.1754 - mse: 0.0888 - pearson_correlation: 1.1724e-16 - r2_keras: -85.4355 - rmse: 0.8861 - sae: 1926.7760 - sse: 2339.9531 - val_huber_loss: 0.1357 - val_loss: 0.2988 - val_mae: 0.3692 - val_mse: 0.2955 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.8911 - val_rmse: 0.9756 - val_sae: 383.7132 - val_sse: 503.4842 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0512 - loss: 0.2143 - mae: 0.1905 - mse: 0.1037 - pearson_correlation: 3.0406e-16 - r2_keras: -102.1313 - rmse: 0.8837 - sae: 2630.0039 - sse: 3199.0044\n","Epoch 42: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0389 - loss: 0.2068 - mae: 0.1751 - mse: 0.0885 - pearson_correlation: 1.6939e-16 - r2_keras: -85.4649 - rmse: 0.8864 - sae: 1926.9818 - sse: 2340.4165 - val_huber_loss: 0.1357 - val_loss: 0.2989 - val_mae: 0.3694 - val_mse: 0.2956 - val_pearson_correlation: -2.2229e-16 - val_r2_keras: -34.8579 - val_rmse: 0.9751 - val_sae: 383.4450 - val_sse: 503.0191 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0510 - loss: 0.2141 - mae: 0.1902 - mse: 0.1034 - pearson_correlation: -1.2343e-16 - r2_keras: -102.1094 - rmse: 0.8837 - sae: 2629.4087 - sse: 3198.3237\n","Epoch 43: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0388 - loss: 0.2067 - mae: 0.1747 - mse: 0.0883 - pearson_correlation: -9.0616e-17 - r2_keras: -85.4587 - rmse: 0.8864 - sae: 1926.5209 - sse: 2340.0615 - val_huber_loss: 0.1361 - val_loss: 0.2992 - val_mae: 0.3696 - val_mse: 0.2963 - val_pearson_correlation: -1.0568e-17 - val_r2_keras: -34.8992 - val_rmse: 0.9757 - val_sae: 383.6475 - val_sse: 503.5985 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0509 - loss: 0.2140 - mae: 0.1899 - mse: 0.1031 - pearson_correlation: -3.0233e-16 - r2_keras: -102.2095 - rmse: 0.8841 - sae: 2630.3425 - sse: 3201.4302\n","Epoch 44: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0387 - loss: 0.2066 - mae: 0.1743 - mse: 0.0880 - pearson_correlation: -2.0988e-16 - r2_keras: -85.5250 - rmse: 0.8867 - sae: 1927.1136 - sse: 2342.1277 - val_huber_loss: 0.1358 - val_loss: 0.2989 - val_mae: 0.3695 - val_mse: 0.2957 - val_pearson_correlation: -1.2708e-16 - val_r2_keras: -34.8468 - val_rmse: 0.9750 - val_sae: 383.2694 - val_sse: 502.8631 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0508 - loss: 0.2139 - mae: 0.1896 - mse: 0.1029 - pearson_correlation: -7.9601e-17 - r2_keras: -102.1249 - rmse: 0.8837 - sae: 2628.8030 - sse: 3198.8062\n","Epoch 45: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0386 - loss: 0.2065 - mae: 0.1741 - mse: 0.0878 - pearson_correlation: -5.9719e-17 - r2_keras: -85.4927 - rmse: 0.8866 - sae: 1926.1381 - sse: 2340.6609 - val_huber_loss: 0.1355 - val_loss: 0.2986 - val_mae: 0.3690 - val_mse: 0.2953 - val_pearson_correlation: -2.3306e-16 - val_r2_keras: -34.8366 - val_rmse: 0.9748 - val_sae: 383.2063 - val_sse: 502.7197 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0506 - loss: 0.2137 - mae: 0.1891 - mse: 0.1024 - pearson_correlation: 2.9465e-17 - r2_keras: -102.1966 - rmse: 0.8840 - sae: 2629.6360 - sse: 3201.0308\n","Epoch 46: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0384 - loss: 0.2063 - mae: 0.1737 - mse: 0.0874 - pearson_correlation: 5.2907e-17 - r2_keras: -85.5383 - rmse: 0.8868 - sae: 1926.7562 - sse: 2342.1179 - val_huber_loss: 0.1364 - val_loss: 0.2995 - val_mae: 0.3702 - val_mse: 0.2971 - val_pearson_correlation: -5.2854e-17 - val_r2_keras: -34.8926 - val_rmse: 0.9756 - val_sae: 383.6064 - val_sse: 503.5058 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0504 - loss: 0.2135 - mae: 0.1889 - mse: 0.1023 - pearson_correlation: 3.3336e-16 - r2_keras: -102.1749 - rmse: 0.8839 - sae: 2629.0769 - sse: 3200.3547\n","Epoch 47: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0383 - loss: 0.2062 - mae: 0.1734 - mse: 0.0872 - pearson_correlation: 2.6050e-16 - r2_keras: -85.5205 - rmse: 0.8867 - sae: 1926.2133 - sse: 2341.6282 - val_huber_loss: 0.1367 - val_loss: 0.2998 - val_mae: 0.3718 - val_mse: 0.2977 - val_pearson_correlation: 3.4836e-16 - val_r2_keras: -34.9280 - val_rmse: 0.9761 - val_sae: 384.0771 - val_sse: 504.0019 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0503 - loss: 0.2134 - mae: 0.1883 - mse: 0.1019 - pearson_correlation: 6.1818e-17 - r2_keras: -102.1622 - rmse: 0.8839 - sae: 2628.6938 - sse: 3199.9609\n","Epoch 48: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0382 - loss: 0.2060 - mae: 0.1728 - mse: 0.0869 - pearson_correlation: 4.7851e-17 - r2_keras: -85.5489 - rmse: 0.8870 - sae: 1926.2365 - sse: 2341.7981 - val_huber_loss: 0.1368 - val_loss: 0.2999 - val_mae: 0.3711 - val_mse: 0.2979 - val_pearson_correlation: 4.1153e-16 - val_r2_keras: -34.9389 - val_rmse: 0.9762 - val_sae: 383.9706 - val_sse: 504.1554 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0502 - loss: 0.2133 - mae: 0.1880 - mse: 0.1017 - pearson_correlation: -1.9322e-16 - r2_keras: -102.1452 - rmse: 0.8838 - sae: 2628.3442 - sse: 3199.4348\n","Epoch 49: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0381 - loss: 0.2059 - mae: 0.1726 - mse: 0.0867 - pearson_correlation: -1.2882e-16 - r2_keras: -85.5443 - rmse: 0.8870 - sae: 1925.9694 - sse: 2341.5261 - val_huber_loss: 0.1359 - val_loss: 0.2990 - val_mae: 0.3698 - val_mse: 0.2963 - val_pearson_correlation: -1.4831e-16 - val_r2_keras: -34.8372 - val_rmse: 0.9749 - val_sae: 383.1588 - val_sse: 502.7276 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0500 - loss: 0.2131 - mae: 0.1877 - mse: 0.1013 - pearson_correlation: 6.1176e-17 - r2_keras: -102.2516 - rmse: 0.8843 - sae: 2629.4409 - sse: 3202.7363\n","Epoch 50: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0380 - loss: 0.2058 - mae: 0.1723 - mse: 0.0864 - pearson_correlation: 1.9192e-17 - r2_keras: -85.5976 - rmse: 0.8871 - sae: 1926.5775 - sse: 2343.5203 - val_huber_loss: 0.1371 - val_loss: 0.3002 - val_mae: 0.3716 - val_mse: 0.2986 - val_pearson_correlation: -1.6858e-16 - val_r2_keras: -34.9782 - val_rmse: 0.9768 - val_sae: 384.1362 - val_sse: 504.7058 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0499 - loss: 0.2130 - mae: 0.1874 - mse: 0.1011 - pearson_correlation: 6.0109e-17 - r2_keras: -102.1515 - rmse: 0.8838 - sae: 2627.7305 - sse: 3199.6318\n","Epoch 51: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0378 - loss: 0.2056 - mae: 0.1719 - mse: 0.0862 - pearson_correlation: 5.3341e-17 - r2_keras: -85.5545 - rmse: 0.8871 - sae: 1925.4873 - sse: 2341.7278 - val_huber_loss: 0.1369 - val_loss: 0.3000 - val_mae: 0.3722 - val_mse: 0.2982 - val_pearson_correlation: 2.3207e-16 - val_r2_keras: -34.9470 - val_rmse: 0.9763 - val_sae: 384.1487 - val_sse: 504.2679 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0497 - loss: 0.2127 - mae: 0.1867 - mse: 0.1006 - pearson_correlation: -3.3737e-17 - r2_keras: -102.2410 - rmse: 0.8842 - sae: 2628.5068 - sse: 3202.4067\n","Epoch 52: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0377 - loss: 0.2054 - mae: 0.1714 - mse: 0.0857 - pearson_correlation: 1.2266e-17 - r2_keras: -85.6501 - rmse: 0.8876 - sae: 1926.2393 - sse: 2343.9998 - val_huber_loss: 0.1375 - val_loss: 0.3006 - val_mae: 0.3727 - val_mse: 0.2996 - val_pearson_correlation: 5.2602e-17 - val_r2_keras: -35.0169 - val_rmse: 0.9773 - val_sae: 384.5483 - val_sse: 505.2495 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0495 - loss: 0.2126 - mae: 0.1867 - mse: 0.1003 - pearson_correlation: -1.1236e-16 - r2_keras: -102.2445 - rmse: 0.8842 - sae: 2628.4761 - sse: 3202.5161\n","Epoch 53: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0375 - loss: 0.2053 - mae: 0.1713 - mse: 0.0855 - pearson_correlation: 9.6158e-18 - r2_keras: -85.6304 - rmse: 0.8874 - sae: 1925.9917 - sse: 2343.8142 - val_huber_loss: 0.1375 - val_loss: 0.3006 - val_mae: 0.3726 - val_mse: 0.2995 - val_pearson_correlation: -3.1539e-17 - val_r2_keras: -35.0354 - val_rmse: 0.9775 - val_sae: 384.6381 - val_sse: 505.5091 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0494 - loss: 0.2125 - mae: 0.1862 - mse: 0.1000 - pearson_correlation: 4.7558e-16 - r2_keras: -102.3629 - rmse: 0.8847 - sae: 2629.9541 - sse: 3206.1887\n","Epoch 54: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0374 - loss: 0.2052 - mae: 0.1707 - mse: 0.0852 - pearson_correlation: 3.3031e-16 - r2_keras: -85.7145 - rmse: 0.8878 - sae: 1927.0762 - sse: 2346.3232 - val_huber_loss: 0.1377 - val_loss: 0.3007 - val_mae: 0.3727 - val_mse: 0.2999 - val_pearson_correlation: 8.4131e-17 - val_r2_keras: -35.0270 - val_rmse: 0.9774 - val_sae: 384.4536 - val_sse: 505.3908 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0492 - loss: 0.2123 - mae: 0.1860 - mse: 0.0997 - pearson_correlation: 3.7140e-17 - r2_keras: -102.2982 - rmse: 0.8845 - sae: 2628.0000 - sse: 3204.1824\n","Epoch 55: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0373 - loss: 0.2050 - mae: 0.1705 - mse: 0.0849 - pearson_correlation: -2.4909e-17 - r2_keras: -85.6825 - rmse: 0.8877 - sae: 1925.6493 - sse: 2345.1157 - val_huber_loss: 0.1378 - val_loss: 0.3008 - val_mae: 0.3734 - val_mse: 0.3002 - val_pearson_correlation: 1.9939e-16 - val_r2_keras: -35.0820 - val_rmse: 0.9782 - val_sae: 385.0420 - val_sse: 506.1628 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0490 - loss: 0.2121 - mae: 0.1853 - mse: 0.0993 - pearson_correlation: 2.7700e-16 - r2_keras: -102.3325 - rmse: 0.8846 - sae: 2628.6624 - sse: 3205.2437\n","Epoch 56: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0371 - loss: 0.2048 - mae: 0.1700 - mse: 0.0846 - pearson_correlation: 1.5985e-16 - r2_keras: -85.7176 - rmse: 0.8879 - sae: 1926.2639 - sse: 2345.9673 - val_huber_loss: 0.1385 - val_loss: 0.3015 - val_mae: 0.3741 - val_mse: 0.3016 - val_pearson_correlation: 3.7738e-16 - val_r2_keras: -35.1106 - val_rmse: 0.9786 - val_sae: 385.1075 - val_sse: 506.5632 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0489 - loss: 0.2120 - mae: 0.1856 - mse: 0.0991 - pearson_correlation: 1.5673e-16 - r2_keras: -102.3553 - rmse: 0.8847 - sae: 2628.6909 - sse: 3205.9536\n","Epoch 57: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0370 - loss: 0.2047 - mae: 0.1701 - mse: 0.0844 - pearson_correlation: 7.4718e-17 - r2_keras: -85.7385 - rmse: 0.8880 - sae: 1926.1562 - sse: 2346.5073 - val_huber_loss: 0.1383 - val_loss: 0.3013 - val_mae: 0.3745 - val_mse: 0.3012 - val_pearson_correlation: -3.2491e-16 - val_r2_keras: -35.1155 - val_rmse: 0.9786 - val_sae: 385.3255 - val_sse: 506.6323 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0487 - loss: 0.2118 - mae: 0.1849 - mse: 0.0987 - pearson_correlation: -1.1153e-16 - r2_keras: -102.4249 - rmse: 0.8850 - sae: 2629.2883 - sse: 3208.1113\n","Epoch 58: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0369 - loss: 0.2046 - mae: 0.1695 - mse: 0.0840 - pearson_correlation: -6.6085e-17 - r2_keras: -85.7911 - rmse: 0.8883 - sae: 1926.7284 - sse: 2348.0186 - val_huber_loss: 0.1384 - val_loss: 0.3015 - val_mae: 0.3744 - val_mse: 0.3015 - val_pearson_correlation: 3.1450e-17 - val_r2_keras: -35.1095 - val_rmse: 0.9785 - val_sae: 385.1391 - val_sse: 506.5486 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0486 - loss: 0.2117 - mae: 0.1848 - mse: 0.0985 - pearson_correlation: 2.5350e-16 - r2_keras: -102.3604 - rmse: 0.8847 - sae: 2627.8857 - sse: 3206.1094\n","Epoch 59: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0368 - loss: 0.2045 - mae: 0.1693 - mse: 0.0838 - pearson_correlation: 1.4752e-16 - r2_keras: -85.7581 - rmse: 0.8882 - sae: 1925.7009 - sse: 2346.8015 - val_huber_loss: 0.1389 - val_loss: 0.3019 - val_mae: 0.3754 - val_mse: 0.3025 - val_pearson_correlation: -7.3223e-17 - val_r2_keras: -35.1674 - val_rmse: 0.9793 - val_sae: 385.5530 - val_sse: 507.3600 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0484 - loss: 0.2114 - mae: 0.1845 - mse: 0.0980 - pearson_correlation: 4.7573e-16 - r2_keras: -102.4785 - rmse: 0.8852 - sae: 2630.0981 - sse: 3209.7739\n","Epoch 60: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0366 - loss: 0.2043 - mae: 0.1691 - mse: 0.0834 - pearson_correlation: 2.8331e-16 - r2_keras: -85.8498 - rmse: 0.8886 - sae: 1927.2482 - sse: 2349.3958 - val_huber_loss: 0.1389 - val_loss: 0.3019 - val_mae: 0.3757 - val_mse: 0.3024 - val_pearson_correlation: -1.7782e-16 - val_r2_keras: -35.1690 - val_rmse: 0.9794 - val_sae: 385.5825 - val_sse: 507.3827 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0484 - loss: 0.2114 - mae: 0.1842 - mse: 0.0979 - pearson_correlation: -1.9595e-16 - r2_keras: -102.5424 - rmse: 0.8855 - sae: 2630.4524 - sse: 3211.7554\n","Epoch 61: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0366 - loss: 0.2042 - mae: 0.1688 - mse: 0.0833 - pearson_correlation: -8.0253e-17 - r2_keras: -85.8851 - rmse: 0.8888 - sae: 1927.4952 - sse: 2350.6316 - val_huber_loss: 0.1391 - val_loss: 0.3022 - val_mae: 0.3750 - val_mse: 0.3031 - val_pearson_correlation: 9.4019e-17 - val_r2_keras: -35.2021 - val_rmse: 0.9798 - val_sae: 385.5688 - val_sse: 507.8477 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0482 - loss: 0.2112 - mae: 0.1841 - mse: 0.0976 - pearson_correlation: 5.4105e-18 - r2_keras: -102.5549 - rmse: 0.8856 - sae: 2630.0000 - sse: 3212.1421\n","Epoch 62: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0364 - loss: 0.2040 - mae: 0.1686 - mse: 0.0830 - pearson_correlation: -4.6819e-17 - r2_keras: -85.8778 - rmse: 0.8887 - sae: 1926.9640 - sse: 2350.7068 - val_huber_loss: 0.1400 - val_loss: 0.3030 - val_mae: 0.3780 - val_mse: 0.3048 - val_pearson_correlation: 6.2431e-17 - val_r2_keras: -35.3077 - val_rmse: 0.9812 - val_sae: 386.6747 - val_sse: 509.3283 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0480 - loss: 0.2110 - mae: 0.1836 - mse: 0.0971 - pearson_correlation: -1.3868e-16 - r2_keras: -102.5521 - rmse: 0.8855 - sae: 2630.0303 - sse: 3212.0579\n","Epoch 63: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0363 - loss: 0.2039 - mae: 0.1682 - mse: 0.0826 - pearson_correlation: -6.9371e-17 - r2_keras: -85.9208 - rmse: 0.8890 - sae: 1927.3707 - sse: 2351.1758 - val_huber_loss: 0.1400 - val_loss: 0.3030 - val_mae: 0.3761 - val_mse: 0.3048 - val_pearson_correlation: 3.1212e-17 - val_r2_keras: -35.3108 - val_rmse: 0.9813 - val_sae: 386.3245 - val_sse: 509.3713 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0479 - loss: 0.2109 - mae: 0.1836 - mse: 0.0970 - pearson_correlation: -8.3925e-17 - r2_keras: -102.6300 - rmse: 0.8859 - sae: 2630.5464 - sse: 3214.4727\n","Epoch 64: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0362 - loss: 0.2038 - mae: 0.1680 - mse: 0.0825 - pearson_correlation: -5.9253e-17 - r2_keras: -85.9480 - rmse: 0.8890 - sae: 1927.4240 - sse: 2352.4956 - val_huber_loss: 0.1400 - val_loss: 0.3030 - val_mae: 0.3782 - val_mse: 0.3049 - val_pearson_correlation: -3.1258e-17 - val_r2_keras: -35.2717 - val_rmse: 0.9807 - val_sae: 386.4923 - val_sse: 508.8233 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0477 - loss: 0.2107 - mae: 0.1831 - mse: 0.0965 - pearson_correlation: 2.1933e-16 - r2_keras: -102.6355 - rmse: 0.8859 - sae: 2630.3359 - sse: 3214.6438\n","Epoch 65: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0360 - loss: 0.2036 - mae: 0.1676 - mse: 0.0821 - pearson_correlation: 1.1732e-16 - r2_keras: -85.9517 - rmse: 0.8891 - sae: 1927.3452 - sse: 2352.6101 - val_huber_loss: 0.1400 - val_loss: 0.3029 - val_mae: 0.3771 - val_mse: 0.3048 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.2881 - val_rmse: 0.9810 - val_sae: 386.3410 - val_sse: 509.0535 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0476 - loss: 0.2106 - mae: 0.1828 - mse: 0.0964 - pearson_correlation: 3.6646e-16 - r2_keras: -102.6222 - rmse: 0.8858 - sae: 2629.8335 - sse: 3214.2297\n","Epoch 66: val_loss did not improve from 0.28974\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0359 - loss: 0.2035 - mae: 0.1673 - mse: 0.0820 - pearson_correlation: 2.3935e-16 - r2_keras: -85.9463 - rmse: 0.8891 - sae: 1926.9448 - sse: 2352.3750 - val_huber_loss: 0.1406 - val_loss: 0.3036 - val_mae: 0.3783 - val_mse: 0.3061 - val_pearson_correlation: 1.8689e-16 - val_r2_keras: -35.3656 - val_rmse: 0.9820 - val_sae: 386.9286 - val_sse: 510.1411 - learning_rate: 1.0000e-05\n","| \u001b[35m2        \u001b[39m | \u001b[35m-0.3036  \u001b[39m | \u001b[35m0.000675 \u001b[39m | \u001b[35m87.29    \u001b[39m | \u001b[35m62.11    \u001b[39m | \u001b[35m72.27    \u001b[39m | \u001b[35m6.956    \u001b[39m | \u001b[35m97.14    \u001b[39m |\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 1.3536 - loss: 1.5407 - mae: 1.8180 - mse: 4.6377 - pearson_correlation: 6.5242e-17 - r2_keras: -616.2565 - rmse: 2.1620 - sae: 7580.5361 - sse: 19146.5254\n","Epoch 1: val_loss improved from inf to 0.42455, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 635ms/step - huber_loss: 1.3172 - loss: 1.5192 - mae: 1.7912 - mse: 4.5418 - pearson_correlation: 3.6264e-17 - r2_keras: -484.0648 - rmse: 2.0471 - sae: 5443.8589 - sse: 13627.2178 - val_huber_loss: 0.2339 - val_loss: 0.4245 - val_mae: 0.5371 - val_mse: 0.5963 - val_pearson_correlation: 2.6889e-16 - val_r2_keras: -22.8719 - val_rmse: 0.7956 - val_sae: 289.9404 - val_sse: 334.8775 - learning_rate: 0.0047\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3357 - loss: 0.5263 - mae: 0.6810 - mse: 0.8518 - pearson_correlation: -4.1718e-17 - r2_keras: -149.6291 - rmse: 1.0680 - sae: 3297.5710 - sse: 4672.3271\n","Epoch 2: val_loss improved from 0.42455 to 0.40323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.3525 - loss: 0.5365 - mae: 0.7020 - mse: 0.8633 - pearson_correlation: -2.2090e-16 - r2_keras: -122.1969 - rmse: 1.0491 - sae: 2402.3672 - sse: 3382.0654 - val_huber_loss: 0.2126 - val_loss: 0.4032 - val_mae: 0.5095 - val_mse: 0.5197 - val_pearson_correlation: -6.4303e-17 - val_r2_keras: -23.0571 - val_rmse: 0.7987 - val_sae: 303.2682 - val_sse: 337.4758 - learning_rate: 0.0047\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2933 - loss: 0.4840 - mae: 0.6432 - mse: 0.7119 - pearson_correlation: -2.2533e-16 - r2_keras: -146.4890 - rmse: 1.0568 - sae: 3252.5713 - sse: 4574.9258\n","Epoch 3: val_loss improved from 0.40323 to 0.40045, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.3319 - loss: 0.5074 - mae: 0.6651 - mse: 0.7605 - pearson_correlation: -1.3370e-16 - r2_keras: -123.5269 - rmse: 1.0660 - sae: 2394.8262 - sse: 3357.2876 - val_huber_loss: 0.2100 - val_loss: 0.4005 - val_mae: 0.5306 - val_mse: 0.4937 - val_pearson_correlation: 5.9044e-17 - val_r2_keras: -22.9386 - val_rmse: 0.7967 - val_sae: 317.7454 - val_sse: 335.8129 - learning_rate: 0.0047\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2584 - loss: 0.4488 - mae: 0.6177 - mse: 0.5813 - pearson_correlation: -5.6170e-17 - r2_keras: -79.2141 - rmse: 0.7794 - sae: 2571.4478 - sse: 2488.1416\n","Epoch 4: val_loss did not improve from 0.40045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2525 - loss: 0.4453 - mae: 0.6160 - mse: 0.5633 - pearson_correlation: -7.8222e-18 - r2_keras: -82.6518 - rmse: 0.9075 - sae: 1957.6490 - sse: 2012.7238 - val_huber_loss: 0.2875 - val_loss: 0.4777 - val_mae: 0.6473 - val_mse: 0.6643 - val_pearson_correlation: -2.4765e-16 - val_r2_keras: -25.6420 - val_rmse: 0.8405 - val_sae: 349.5469 - val_sse: 373.7370 - learning_rate: 0.0047\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.3720 - loss: 0.5623 - mae: 0.7892 - mse: 0.8829 - pearson_correlation: -2.8082e-17 - r2_keras: -116.7280 - rmse: 0.9442 - sae: 3061.1216 - sse: 3651.7742\n","Epoch 5: val_loss improved from 0.40045 to 0.38958, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.3099 - loss: 0.5244 - mae: 0.7267 - mse: 0.7816 - pearson_correlation: -2.2033e-16 - r2_keras: -97.6282 - rmse: 0.9464 - sae: 2235.0901 - sse: 2670.7922 - val_huber_loss: 0.1998 - val_loss: 0.3896 - val_mae: 0.4856 - val_mse: 0.4681 - val_pearson_correlation: -9.0961e-17 - val_r2_keras: -25.3863 - val_rmse: 0.8365 - val_sae: 318.8963 - val_sse: 370.1494 - learning_rate: 0.0047\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1384 - loss: 0.3282 - mae: 0.4212 - mse: 0.2873 - pearson_correlation: -5.9795e-16 - r2_keras: -97.8052 - rmse: 0.8650 - sae: 2692.8735 - sse: 3064.8149\n","Epoch 6: val_loss improved from 0.38958 to 0.37226, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1378 - loss: 0.3278 - mae: 0.4198 - mse: 0.2852 - pearson_correlation: -3.2366e-16 - r2_keras: -83.8042 - rmse: 0.8840 - sae: 1984.3038 - sse: 2265.3069 - val_huber_loss: 0.1829 - val_loss: 0.3723 - val_mae: 0.4714 - val_mse: 0.4166 - val_pearson_correlation: -5.6106e-17 - val_r2_keras: -26.5593 - val_rmse: 0.8549 - val_sae: 338.6783 - val_sse: 386.6047 - learning_rate: 0.0047\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1250 - loss: 0.3143 - mae: 0.3596 - mse: 0.2759 - pearson_correlation: -2.6012e-16 - r2_keras: -93.9083 - rmse: 0.8478 - sae: 2583.3330 - sse: 2943.9370\n","Epoch 7: val_loss did not improve from 0.37226\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1065 - loss: 0.3030 - mae: 0.3432 - mse: 0.2482 - pearson_correlation: -4.1738e-17 - r2_keras: -79.0241 - rmse: 0.8542 - sae: 1896.8525 - sse: 2159.1252 - val_huber_loss: 0.1860 - val_loss: 0.3748 - val_mae: 0.5034 - val_mse: 0.4146 - val_pearson_correlation: 5.2182e-16 - val_r2_keras: -28.1211 - val_rmse: 0.8788 - val_sae: 360.8763 - val_sse: 408.5145 - learning_rate: 0.0047\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1009 - loss: 0.2897 - mae: 0.3054 - mse: 0.2043 - pearson_correlation: -2.0675e-16 - r2_keras: -107.5015 - rmse: 0.9065 - sae: 2737.4395 - sse: 3365.5813\n","Epoch 8: val_loss improved from 0.37226 to 0.35934, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1008 - loss: 0.2896 - mae: 0.3141 - mse: 0.2039 - pearson_correlation: -2.0868e-16 - r2_keras: -87.2156 - rmse: 0.8857 - sae: 1994.7733 - sse: 2430.0090 - val_huber_loss: 0.1711 - val_loss: 0.3593 - val_mae: 0.4745 - val_mse: 0.3740 - val_pearson_correlation: 8.3451e-17 - val_r2_keras: -31.0995 - val_rmse: 0.9226 - val_sae: 380.4901 - val_sse: 450.2954 - learning_rate: 0.0047\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1403 - loss: 0.3285 - mae: 0.4256 - mse: 0.3083 - pearson_correlation: -5.6174e-16 - r2_keras: -129.0675 - rmse: 0.9925 - sae: 3151.3213 - sse: 4034.5312\n","Epoch 9: val_loss improved from 0.35934 to 0.32448, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1194 - loss: 0.3157 - mae: 0.3989 - mse: 0.2776 - pearson_correlation: -3.3291e-16 - r2_keras: -99.4654 - rmse: 0.9235 - sae: 2256.7798 - sse: 2851.0188 - val_huber_loss: 0.1369 - val_loss: 0.3245 - val_mae: 0.3839 - val_mse: 0.3020 - val_pearson_correlation: -1.3255e-16 - val_r2_keras: -32.3068 - val_rmse: 0.9398 - val_sae: 365.7034 - val_sse: 467.2308 - learning_rate: 0.0047\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0855 - loss: 0.2730 - mae: 0.2785 - mse: 0.1730 - pearson_correlation: 4.6151e-16 - r2_keras: -108.3084 - rmse: 0.9098 - sae: 2678.3467 - sse: 3390.6091\n","Epoch 10: val_loss did not improve from 0.32448\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0812 - loss: 0.2704 - mae: 0.2797 - mse: 0.1674 - pearson_correlation: 3.0767e-16 - r2_keras: -89.8464 - rmse: 0.9060 - sae: 1965.3613 - sse: 2471.2432 - val_huber_loss: 0.1683 - val_loss: 0.3551 - val_mae: 0.4704 - val_mse: 0.3761 - val_pearson_correlation: -3.6695e-16 - val_r2_keras: -29.3903 - val_rmse: 0.8977 - val_sae: 366.1582 - val_sse: 426.3181 - learning_rate: 0.0047\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1180 - loss: 0.3049 - mae: 0.3464 - mse: 0.2592 - pearson_correlation: -3.2907e-17 - r2_keras: -99.6296 - rmse: 0.8730 - sae: 2621.5320 - sse: 3121.4036\n","Epoch 11: val_loss did not improve from 0.32448\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1095 - loss: 0.2996 - mae: 0.3441 - mse: 0.2442 - pearson_correlation: -3.2677e-17 - r2_keras: -88.3694 - rmse: 0.9153 - sae: 1952.1741 - sse: 2342.3164 - val_huber_loss: 0.2032 - val_loss: 0.3893 - val_mae: 0.5262 - val_mse: 0.4825 - val_pearson_correlation: 1.1441e-16 - val_r2_keras: -28.1987 - val_rmse: 0.8799 - val_sae: 347.3579 - val_sse: 409.6028 - learning_rate: 0.0047\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1310 - loss: 0.3171 - mae: 0.3898 - mse: 0.2695 - pearson_correlation: 2.7232e-16 - r2_keras: -93.5029 - rmse: 0.8460 - sae: 2587.0100 - sse: 2931.3623\n","Epoch 12: val_loss did not improve from 0.32448\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1203 - loss: 0.3105 - mae: 0.3865 - mse: 0.2550 - pearson_correlation: 2.0662e-16 - r2_keras: -83.3699 - rmse: 0.8904 - sae: 1922.7568 - sse: 2204.8887 - val_huber_loss: 0.2119 - val_loss: 0.3973 - val_mae: 0.5164 - val_mse: 0.4866 - val_pearson_correlation: 2.0586e-17 - val_r2_keras: -28.4977 - val_rmse: 0.8844 - val_sae: 344.9330 - val_sse: 413.7963 - learning_rate: 0.0047\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1222 - loss: 0.3076 - mae: 0.3976 - mse: 0.2516 - pearson_correlation: -3.1953e-16 - r2_keras: -114.1176 - rmse: 0.9337 - sae: 2913.9888 - sse: 3570.8054\n","Epoch 13: val_loss improved from 0.32448 to 0.32250, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1206 - loss: 0.3065 - mae: 0.4013 - mse: 0.2481 - pearson_correlation: -1.7869e-16 - r2_keras: -91.5229 - rmse: 0.9030 - sae: 2118.1743 - sse: 2565.6104 - val_huber_loss: 0.1379 - val_loss: 0.3225 - val_mae: 0.3731 - val_mse: 0.2854 - val_pearson_correlation: -8.1085e-17 - val_r2_keras: -43.9363 - val_rmse: 1.0916 - val_sae: 430.1640 - val_sse: 630.3716 - learning_rate: 0.0047\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1146 - loss: 0.2993 - mae: 0.3358 - mse: 0.2353 - pearson_correlation: -3.2610e-16 - r2_keras: -138.9710 - rmse: 1.0296 - sae: 3045.7192 - sse: 4341.7246\n","Epoch 14: val_loss did not improve from 0.32250\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1299 - loss: 0.3085 - mae: 0.3694 - mse: 0.2538 - pearson_correlation: -2.7605e-16 - r2_keras: -108.6268 - rmse: 0.9716 - sae: 2208.3147 - sse: 3085.8330 - val_huber_loss: 0.2762 - val_loss: 0.4602 - val_mae: 0.6336 - val_mse: 0.6455 - val_pearson_correlation: 4.6071e-17 - val_r2_keras: -43.5971 - val_rmse: 1.0875 - val_sae: 450.2248 - val_sse: 625.6129 - learning_rate: 0.0047\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2221 - loss: 0.4061 - mae: 0.5271 - mse: 0.5018 - pearson_correlation: -5.3382e-16 - r2_keras: -178.1903 - rmse: 1.1649 - sae: 3675.9585 - sse: 5558.2598\n","Epoch 15: val_loss did not improve from 0.32250\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1772 - loss: 0.3787 - mae: 0.4828 - mse: 0.4357 - pearson_correlation: -4.8168e-16 - r2_keras: -134.0076 - rmse: 1.0551 - sae: 2614.6274 - sse: 3887.8784 - val_huber_loss: 0.2542 - val_loss: 0.4375 - val_mae: 0.5456 - val_mse: 0.5749 - val_pearson_correlation: 2.5608e-16 - val_r2_keras: -45.6151 - val_rmse: 1.1118 - val_sae: 442.3100 - val_sse: 653.9216 - learning_rate: 0.0047\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1837 - loss: 0.3670 - mae: 0.4898 - mse: 0.3941 - pearson_correlation: 3.9289e-16 - r2_keras: -118.1981 - rmse: 0.9501 - sae: 2957.3398 - sse: 3697.3757\n","Epoch 16: val_loss did not improve from 0.32250\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1628 - loss: 0.3542 - mae: 0.4762 - mse: 0.3632 - pearson_correlation: 3.2684e-16 - r2_keras: -98.5506 - rmse: 0.9499 - sae: 2168.3147 - sse: 2700.5168 - val_huber_loss: 0.2155 - val_loss: 0.3980 - val_mae: 0.5092 - val_mse: 0.4768 - val_pearson_correlation: 1.8368e-16 - val_r2_keras: -43.3377 - val_rmse: 1.0843 - val_sae: 436.8080 - val_sse: 621.9745 - learning_rate: 0.0047\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1341 - loss: 0.3166 - mae: 0.3933 - mse: 0.2843 - pearson_correlation: 1.5658e-16 - r2_keras: -104.3615 - rmse: 0.8933 - sae: 2723.9380 - sse: 3268.1816\n","Epoch 17: val_loss did not improve from 0.32250\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1148 - loss: 0.3048 - mae: 0.3716 - mse: 0.2575 - pearson_correlation: 1.2694e-16 - r2_keras: -90.3398 - rmse: 0.9199 - sae: 2005.9788 - sse: 2426.2773 - val_huber_loss: 0.1884 - val_loss: 0.3699 - val_mae: 0.4879 - val_mse: 0.4292 - val_pearson_correlation: -3.8176e-17 - val_r2_keras: -31.4583 - val_rmse: 0.9278 - val_sae: 371.1726 - val_sse: 455.3290 - learning_rate: 0.0047\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1213 - loss: 0.3028 - mae: 0.3910 - mse: 0.2455 - pearson_correlation: 5.0601e-18 - r2_keras: -93.2385 - rmse: 0.8448 - sae: 2623.1753 - sse: 2923.1606\n","Epoch 18: val_loss did not improve from 0.32250\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1265 - loss: 0.3058 - mae: 0.3945 - mse: 0.2513 - pearson_correlation: -1.7859e-17 - r2_keras: -86.0980 - rmse: 0.9111 - sae: 1960.9969 - sse: 2233.4890 - val_huber_loss: 0.3389 - val_loss: 0.5195 - val_mae: 0.7266 - val_mse: 0.7590 - val_pearson_correlation: -3.2271e-16 - val_r2_keras: -35.8476 - val_rmse: 0.9885 - val_sae: 429.2660 - val_sse: 516.9021 - learning_rate: 0.0047\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1873 - loss: 0.3679 - mae: 0.5290 - mse: 0.3806 - pearson_correlation: 6.0321e-16 - r2_keras: -117.1866 - rmse: 0.9461 - sae: 3120.8052 - sse: 3665.9993\n","Epoch 19: val_loss did not improve from 0.32250\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1635 - loss: 0.3533 - mae: 0.5052 - mse: 0.3505 - pearson_correlation: 4.0025e-16 - r2_keras: -93.5718 - rmse: 0.9112 - sae: 2258.0500 - sse: 2629.1084 - val_huber_loss: 0.1577 - val_loss: 0.3381 - val_mae: 0.4105 - val_mse: 0.3654 - val_pearson_correlation: -1.9209e-16 - val_r2_keras: -32.0266 - val_rmse: 0.9358 - val_sae: 362.8350 - val_sse: 463.3009 - learning_rate: 9.3483e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0786 - loss: 0.2589 - mae: 0.2687 - mse: 0.1612 - pearson_correlation: 1.7788e-16 - r2_keras: -102.8523 - rmse: 0.8868 - sae: 2635.9797 - sse: 3221.3682\n","Epoch 20: val_loss improved from 0.32250 to 0.32214, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.0694 - loss: 0.2533 - mae: 0.2636 - mse: 0.1492 - pearson_correlation: 1.1659e-16 - r2_keras: -83.3972 - rmse: 0.8662 - sae: 1922.4718 - sse: 2325.4331 - val_huber_loss: 0.1421 - val_loss: 0.3221 - val_mae: 0.3635 - val_mse: 0.3216 - val_pearson_correlation: 2.1578e-17 - val_r2_keras: -34.4078 - val_rmse: 0.9690 - val_sae: 371.5849 - val_sse: 496.7045 - learning_rate: 9.3483e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0670 - loss: 0.2471 - mae: 0.2257 - mse: 0.1364 - pearson_correlation: -2.6616e-16 - r2_keras: -106.9038 - rmse: 0.9040 - sae: 2646.4065 - sse: 3347.0417\n","Epoch 21: val_loss improved from 0.32214 to 0.31771, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.0581 - loss: 0.2416 - mae: 0.2228 - mse: 0.1251 - pearson_correlation: -1.6681e-16 - r2_keras: -86.4950 - rmse: 0.8812 - sae: 1929.8763 - sse: 2413.8706 - val_huber_loss: 0.1379 - val_loss: 0.3177 - val_mae: 0.3504 - val_mse: 0.3087 - val_pearson_correlation: 1.6672e-16 - val_r2_keras: -35.2954 - val_rmse: 0.9811 - val_sae: 376.9038 - val_sse: 509.1553 - learning_rate: 9.3483e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0609 - loss: 0.2407 - mae: 0.2118 - mse: 0.1237 - pearson_correlation: 4.7606e-16 - r2_keras: -108.0772 - rmse: 0.9089 - sae: 2652.8914 - sse: 3383.4395\n","Epoch 22: val_loss improved from 0.31771 to 0.31491, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0527 - loss: 0.2357 - mae: 0.2079 - mse: 0.1133 - pearson_correlation: 3.6934e-16 - r2_keras: -87.5678 - rmse: 0.8871 - sae: 1934.9500 - sse: 2441.5427 - val_huber_loss: 0.1354 - val_loss: 0.3149 - val_mae: 0.3461 - val_mse: 0.3013 - val_pearson_correlation: -2.4702e-16 - val_r2_keras: -35.6276 - val_rmse: 0.9855 - val_sae: 379.5520 - val_sse: 513.8162 - learning_rate: 9.3483e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0577 - loss: 0.2372 - mae: 0.2033 - mse: 0.1174 - pearson_correlation: -4.7317e-18 - r2_keras: -109.4349 - rmse: 0.9145 - sae: 2660.3909 - sse: 3425.5513\n","Epoch 23: val_loss did not improve from 0.31491\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0499 - loss: 0.2324 - mae: 0.1992 - mse: 0.1075 - pearson_correlation: -6.8548e-18 - r2_keras: -88.7550 - rmse: 0.8933 - sae: 1940.8500 - sse: 2472.9275 - val_huber_loss: 0.1360 - val_loss: 0.3151 - val_mae: 0.3474 - val_mse: 0.3011 - val_pearson_correlation: 4.0302e-17 - val_r2_keras: -36.2301 - val_rmse: 0.9936 - val_sae: 382.8841 - val_sse: 522.2676 - learning_rate: 9.3483e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0546 - loss: 0.2337 - mae: 0.1968 - mse: 0.1109 - pearson_correlation: 9.5305e-17 - r2_keras: -109.2920 - rmse: 0.9139 - sae: 2655.0945 - sse: 3421.1191\n","Epoch 24: val_loss improved from 0.31491 to 0.31378, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0472 - loss: 0.2292 - mae: 0.1923 - mse: 0.1015 - pearson_correlation: 7.2670e-17 - r2_keras: -88.8360 - rmse: 0.8945 - sae: 1937.7347 - sse: 2472.0403 - val_huber_loss: 0.1350 - val_loss: 0.3138 - val_mae: 0.3499 - val_mse: 0.2993 - val_pearson_correlation: 1.0216e-16 - val_r2_keras: -35.8358 - val_rmse: 0.9883 - val_sae: 381.3326 - val_sse: 516.7370 - learning_rate: 9.3483e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0519 - loss: 0.2307 - mae: 0.1906 - mse: 0.1066 - pearson_correlation: 1.1429e-16 - r2_keras: -109.6916 - rmse: 0.9156 - sae: 2651.7334 - sse: 3433.5164\n","Epoch 25: val_loss improved from 0.31378 to 0.31366, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0448 - loss: 0.2263 - mae: 0.1858 - mse: 0.0974 - pearson_correlation: 6.0846e-17 - r2_keras: -89.2641 - rmse: 0.8970 - sae: 1936.1305 - sse: 2482.2004 - val_huber_loss: 0.1353 - val_loss: 0.3137 - val_mae: 0.3536 - val_mse: 0.2997 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.5662 - val_rmse: 0.9847 - val_sae: 379.7194 - val_sse: 512.9549 - learning_rate: 9.3483e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0500 - loss: 0.2284 - mae: 0.1881 - mse: 0.1025 - pearson_correlation: 2.7931e-16 - r2_keras: -109.2175 - rmse: 0.9136 - sae: 2645.6533 - sse: 3418.8093\n","Epoch 26: val_loss improved from 0.31366 to 0.31180, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0430 - loss: 0.2241 - mae: 0.1828 - mse: 0.0935 - pearson_correlation: 2.0763e-16 - r2_keras: -89.1112 - rmse: 0.8971 - sae: 1932.6461 - sse: 2474.3108 - val_huber_loss: 0.1339 - val_loss: 0.3118 - val_mae: 0.3548 - val_mse: 0.2944 - val_pearson_correlation: -6.0646e-17 - val_r2_keras: -36.1511 - val_rmse: 0.9926 - val_sae: 383.6429 - val_sse: 521.1594 - learning_rate: 9.3483e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0487 - loss: 0.2266 - mae: 0.1810 - mse: 0.1005 - pearson_correlation: -7.6748e-17 - r2_keras: -111.3769 - rmse: 0.9225 - sae: 2658.0005 - sse: 3485.7913\n","Epoch 27: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0415 - loss: 0.2222 - mae: 0.1754 - mse: 0.0912 - pearson_correlation: -9.9930e-17 - r2_keras: -90.6515 - rmse: 0.9039 - sae: 1941.1670 - sse: 2520.1458 - val_huber_loss: 0.1396 - val_loss: 0.3170 - val_mae: 0.3640 - val_mse: 0.3102 - val_pearson_correlation: 1.4333e-16 - val_r2_keras: -35.7943 - val_rmse: 0.9878 - val_sae: 381.3646 - val_sse: 516.1544 - learning_rate: 9.3483e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0475 - loss: 0.2249 - mae: 0.1843 - mse: 0.0971 - pearson_correlation: 1.6008e-16 - r2_keras: -108.9901 - rmse: 0.9127 - sae: 2640.4414 - sse: 3411.7559\n","Epoch 28: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0400 - loss: 0.2203 - mae: 0.1765 - mse: 0.0875 - pearson_correlation: 2.2376e-16 - r2_keras: -89.2850 - rmse: 0.8993 - sae: 1929.7804 - sse: 2473.4246 - val_huber_loss: 0.1360 - val_loss: 0.3129 - val_mae: 0.3615 - val_mse: 0.3085 - val_pearson_correlation: 1.3123e-16 - val_r2_keras: -34.0632 - val_rmse: 0.9643 - val_sae: 372.2658 - val_sse: 491.8703 - learning_rate: 9.3483e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0463 - loss: 0.2232 - mae: 0.1752 - mse: 0.0960 - pearson_correlation: -1.5078e-16 - r2_keras: -110.1629 - rmse: 0.9175 - sae: 2641.8511 - sse: 3448.1353\n","Epoch 29: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0389 - loss: 0.2186 - mae: 0.1686 - mse: 0.0863 - pearson_correlation: -7.7919e-17 - r2_keras: -90.1414 - rmse: 0.9031 - sae: 1931.2853 - sse: 2498.5515 - val_huber_loss: 0.1385 - val_loss: 0.3149 - val_mae: 0.3660 - val_mse: 0.3094 - val_pearson_correlation: -4.1297e-17 - val_r2_keras: -35.5696 - val_rmse: 0.9848 - val_sae: 380.5021 - val_sse: 513.0024 - learning_rate: 9.3483e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0453 - loss: 0.2217 - mae: 0.1751 - mse: 0.0923 - pearson_correlation: 7.5654e-16 - r2_keras: -111.1067 - rmse: 0.9214 - sae: 2658.7778 - sse: 3477.4084\n","Epoch 30: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0373 - loss: 0.2167 - mae: 0.1662 - mse: 0.0821 - pearson_correlation: 4.9907e-16 - r2_keras: -90.5714 - rmse: 0.9040 - sae: 1941.0508 - sse: 2515.7310 - val_huber_loss: 0.1429 - val_loss: 0.3186 - val_mae: 0.3689 - val_mse: 0.3173 - val_pearson_correlation: -8.9453e-17 - val_r2_keras: -36.7136 - val_rmse: 1.0000 - val_sae: 386.7951 - val_sse: 529.0506 - learning_rate: 9.3483e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0448 - loss: 0.2206 - mae: 0.1683 - mse: 0.0929 - pearson_correlation: 4.7038e-16 - r2_keras: -114.4777 - rmse: 0.9352 - sae: 2672.9907 - sse: 3581.9751\n","Epoch 31: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0375 - loss: 0.2160 - mae: 0.1625 - mse: 0.0833 - pearson_correlation: 3.7211e-16 - r2_keras: -93.4035 - rmse: 0.9182 - sae: 1953.7251 - sse: 2592.3010 - val_huber_loss: 0.1448 - val_loss: 0.3199 - val_mae: 0.3781 - val_mse: 0.3327 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.9923 - val_rmse: 0.9494 - val_sae: 366.6182 - val_sse: 476.8478 - learning_rate: 9.3483e-04\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0440 - loss: 0.2191 - mae: 0.1736 - mse: 0.0908 - pearson_correlation: 2.2261e-16 - r2_keras: -109.3586 - rmse: 0.9142 - sae: 2639.5854 - sse: 3423.1868\n","Epoch 32: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0365 - loss: 0.2145 - mae: 0.1677 - mse: 0.0812 - pearson_correlation: 1.9180e-16 - r2_keras: -89.6224 - rmse: 0.9011 - sae: 1930.0878 - sse: 2482.1208 - val_huber_loss: 0.1405 - val_loss: 0.3155 - val_mae: 0.3719 - val_mse: 0.3143 - val_pearson_correlation: -4.2810e-17 - val_r2_keras: -34.6208 - val_rmse: 0.9719 - val_sae: 375.1381 - val_sse: 499.6924 - learning_rate: 1.8697e-04\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0424 - loss: 0.2174 - mae: 0.1681 - mse: 0.0865 - pearson_correlation: 2.7225e-17 - r2_keras: -110.7385 - rmse: 0.9199 - sae: 2651.2627 - sse: 3465.9871\n","Epoch 33: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0343 - loss: 0.2124 - mae: 0.1590 - mse: 0.0762 - pearson_correlation: 1.2992e-17 - r2_keras: -90.6890 - rmse: 0.9061 - sae: 1937.6223 - sse: 2512.3762 - val_huber_loss: 0.1419 - val_loss: 0.3167 - val_mae: 0.3728 - val_mse: 0.3171 - val_pearson_correlation: 7.3496e-17 - val_r2_keras: -35.1262 - val_rmse: 0.9788 - val_sae: 377.5486 - val_sse: 506.7819 - learning_rate: 1.8697e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0417 - loss: 0.2166 - mae: 0.1653 - mse: 0.0852 - pearson_correlation: -4.4115e-17 - r2_keras: -111.2188 - rmse: 0.9219 - sae: 2651.8052 - sse: 3480.8875\n","Epoch 34: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0334 - loss: 0.2115 - mae: 0.1554 - mse: 0.0747 - pearson_correlation: -5.6723e-17 - r2_keras: -91.1232 - rmse: 0.9084 - sae: 1938.2604 - sse: 2523.6467 - val_huber_loss: 0.1441 - val_loss: 0.3188 - val_mae: 0.3750 - val_mse: 0.3227 - val_pearson_correlation: 1.4526e-16 - val_r2_keras: -35.4496 - val_rmse: 0.9831 - val_sae: 379.0778 - val_sse: 511.3192 - learning_rate: 1.8697e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0412 - loss: 0.2159 - mae: 0.1644 - mse: 0.0842 - pearson_correlation: -4.0998e-16 - r2_keras: -111.2052 - rmse: 0.9218 - sae: 2649.6865 - sse: 3480.4644\n","Epoch 35: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0328 - loss: 0.2108 - mae: 0.1538 - mse: 0.0736 - pearson_correlation: -2.5809e-16 - r2_keras: -91.2552 - rmse: 0.9096 - sae: 1937.4263 - sse: 2525.0190 - val_huber_loss: 0.1464 - val_loss: 0.3209 - val_mae: 0.3773 - val_mse: 0.3283 - val_pearson_correlation: 4.6173e-16 - val_r2_keras: -35.7666 - val_rmse: 0.9874 - val_sae: 380.7426 - val_sse: 515.7656 - learning_rate: 1.8697e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0408 - loss: 0.2153 - mae: 0.1621 - mse: 0.0833 - pearson_correlation: -3.2352e-16 - r2_keras: -111.5958 - rmse: 0.9234 - sae: 2653.4568 - sse: 3492.5801\n","Epoch 36: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0324 - loss: 0.2102 - mae: 0.1514 - mse: 0.0727 - pearson_correlation: -2.6202e-16 - r2_keras: -91.5825 - rmse: 0.9112 - sae: 1940.1621 - sse: 2533.8811 - val_huber_loss: 0.1484 - val_loss: 0.3227 - val_mae: 0.3796 - val_mse: 0.3339 - val_pearson_correlation: -9.1952e-17 - val_r2_keras: -35.8879 - val_rmse: 0.9890 - val_sae: 381.3160 - val_sse: 517.4670 - learning_rate: 1.8697e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0404 - loss: 0.2147 - mae: 0.1596 - mse: 0.0826 - pearson_correlation: -7.5060e-17 - r2_keras: -112.2253 - rmse: 0.9260 - sae: 2658.9824 - sse: 3512.1060\n","Epoch 37: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0320 - loss: 0.2096 - mae: 0.1489 - mse: 0.0720 - pearson_correlation: -1.1235e-16 - r2_keras: -92.0141 - rmse: 0.9130 - sae: 1943.9042 - sse: 2547.0383 - val_huber_loss: 0.1495 - val_loss: 0.3238 - val_mae: 0.3804 - val_mse: 0.3363 - val_pearson_correlation: 1.4191e-16 - val_r2_keras: -36.1139 - val_rmse: 0.9921 - val_sae: 382.4361 - val_sse: 520.6384 - learning_rate: 3.7393e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0403 - loss: 0.2146 - mae: 0.1594 - mse: 0.0824 - pearson_correlation: 2.3798e-16 - r2_keras: -112.2098 - rmse: 0.9259 - sae: 2658.7061 - sse: 3511.6279\n","Epoch 38: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0319 - loss: 0.2095 - mae: 0.1486 - mse: 0.0718 - pearson_correlation: 1.4518e-16 - r2_keras: -92.0058 - rmse: 0.9130 - sae: 1943.7250 - sse: 2546.7432 - val_huber_loss: 0.1504 - val_loss: 0.3246 - val_mae: 0.3811 - val_mse: 0.3383 - val_pearson_correlation: 1.3107e-16 - val_r2_keras: -36.2702 - val_rmse: 0.9942 - val_sae: 383.1960 - val_sse: 522.8307 - learning_rate: 3.7393e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0402 - loss: 0.2144 - mae: 0.1591 - mse: 0.0821 - pearson_correlation: 2.8441e-16 - r2_keras: -112.2240 - rmse: 0.9260 - sae: 2658.6384 - sse: 3512.0669\n","Epoch 39: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0318 - loss: 0.2093 - mae: 0.1482 - mse: 0.0716 - pearson_correlation: 1.8456e-16 - r2_keras: -92.0190 - rmse: 0.9131 - sae: 1943.6873 - sse: 2547.0791 - val_huber_loss: 0.1513 - val_loss: 0.3255 - val_mae: 0.3819 - val_mse: 0.3405 - val_pearson_correlation: -4.3082e-16 - val_r2_keras: -36.4554 - val_rmse: 0.9966 - val_sae: 384.1188 - val_sse: 525.4278 - learning_rate: 3.7393e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0400 - loss: 0.2142 - mae: 0.1587 - mse: 0.0818 - pearson_correlation: -6.4981e-16 - r2_keras: -112.2920 - rmse: 0.9263 - sae: 2659.0615 - sse: 3514.1763\n","Epoch 40: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0317 - loss: 0.2091 - mae: 0.1478 - mse: 0.0713 - pearson_correlation: -3.8192e-16 - r2_keras: -92.0820 - rmse: 0.9134 - sae: 1944.0304 - sse: 2548.6931 - val_huber_loss: 0.1519 - val_loss: 0.3261 - val_mae: 0.3826 - val_mse: 0.3422 - val_pearson_correlation: 9.0042e-17 - val_r2_keras: -36.4966 - val_rmse: 0.9972 - val_sae: 384.2761 - val_sse: 526.0059 - learning_rate: 3.7393e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0399 - loss: 0.2141 - mae: 0.1583 - mse: 0.0815 - pearson_correlation: -4.3574e-16 - r2_keras: -112.2970 - rmse: 0.9263 - sae: 2658.7654 - sse: 3514.3320\n","Epoch 41: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0316 - loss: 0.2090 - mae: 0.1474 - mse: 0.0710 - pearson_correlation: -2.5267e-16 - r2_keras: -92.0894 - rmse: 0.9134 - sae: 1943.8409 - sse: 2548.8450 - val_huber_loss: 0.1528 - val_loss: 0.3269 - val_mae: 0.3834 - val_mse: 0.3443 - val_pearson_correlation: -2.3882e-16 - val_r2_keras: -36.6595 - val_rmse: 0.9993 - val_sae: 385.0950 - val_sse: 528.2913 - learning_rate: 3.7393e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0398 - loss: 0.2139 - mae: 0.1578 - mse: 0.0812 - pearson_correlation: -7.1592e-16 - r2_keras: -112.3926 - rmse: 0.9267 - sae: 2659.5459 - sse: 3517.2976\n","Epoch 42: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0314 - loss: 0.2088 - mae: 0.1469 - mse: 0.0708 - pearson_correlation: -4.9240e-16 - r2_keras: -92.1625 - rmse: 0.9138 - sae: 1944.3843 - sse: 2550.9316 - val_huber_loss: 0.1531 - val_loss: 0.3273 - val_mae: 0.3838 - val_mse: 0.3452 - val_pearson_correlation: 1.4906e-16 - val_r2_keras: -36.6989 - val_rmse: 0.9999 - val_sae: 385.2411 - val_sse: 528.8445 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0397 - loss: 0.2138 - mae: 0.1578 - mse: 0.0812 - pearson_correlation: 3.6581e-16 - r2_keras: -112.3731 - rmse: 0.9266 - sae: 2659.1787 - sse: 3516.6904\n","Epoch 43: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0314 - loss: 0.2088 - mae: 0.1469 - mse: 0.0707 - pearson_correlation: 2.2875e-16 - r2_keras: -92.1519 - rmse: 0.9137 - sae: 1944.1466 - sse: 2550.5552 - val_huber_loss: 0.1535 - val_loss: 0.3276 - val_mae: 0.3840 - val_mse: 0.3460 - val_pearson_correlation: 2.9729e-16 - val_r2_keras: -36.7831 - val_rmse: 1.0010 - val_sae: 385.6473 - val_sse: 530.0252 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0397 - loss: 0.2138 - mae: 0.1576 - mse: 0.0811 - pearson_correlation: 1.1465e-17 - r2_keras: -112.4230 - rmse: 0.9268 - sae: 2659.6704 - sse: 3518.2412\n","Epoch 44: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0314 - loss: 0.2087 - mae: 0.1467 - mse: 0.0706 - pearson_correlation: 5.3819e-17 - r2_keras: -92.1936 - rmse: 0.9139 - sae: 1944.5050 - sse: 2551.6873 - val_huber_loss: 0.1537 - val_loss: 0.3277 - val_mae: 0.3842 - val_mse: 0.3466 - val_pearson_correlation: -2.0799e-16 - val_r2_keras: -36.7987 - val_rmse: 1.0012 - val_sae: 385.6852 - val_sse: 530.2441 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0396 - loss: 0.2137 - mae: 0.1575 - mse: 0.0811 - pearson_correlation: 3.7191e-17 - r2_keras: -112.4434 - rmse: 0.9269 - sae: 2659.7954 - sse: 3518.8726\n","Epoch 45: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0313 - loss: 0.2087 - mae: 0.1466 - mse: 0.0706 - pearson_correlation: -5.4945e-17 - r2_keras: -92.2109 - rmse: 0.9140 - sae: 1944.6034 - sse: 2552.1516 - val_huber_loss: 0.1540 - val_loss: 0.3280 - val_mae: 0.3844 - val_mse: 0.3472 - val_pearson_correlation: -7.9016e-17 - val_r2_keras: -36.8831 - val_rmse: 1.0023 - val_sae: 386.1013 - val_sse: 531.4288 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0396 - loss: 0.2137 - mae: 0.1574 - mse: 0.0810 - pearson_correlation: -5.8054e-16 - r2_keras: -112.4866 - rmse: 0.9271 - sae: 2660.2861 - sse: 3520.2139\n","Epoch 46: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0313 - loss: 0.2086 - mae: 0.1464 - mse: 0.0705 - pearson_correlation: -4.0967e-16 - r2_keras: -92.2516 - rmse: 0.9143 - sae: 1944.9780 - sse: 2553.1851 - val_huber_loss: 0.1541 - val_loss: 0.3281 - val_mae: 0.3846 - val_mse: 0.3476 - val_pearson_correlation: 3.9515e-17 - val_r2_keras: -36.8768 - val_rmse: 1.0022 - val_sae: 386.0406 - val_sse: 531.3395 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0396 - loss: 0.2136 - mae: 0.1572 - mse: 0.0809 - pearson_correlation: -1.6087e-16 - r2_keras: -112.5186 - rmse: 0.9272 - sae: 2660.5020 - sse: 3521.2046\n","Epoch 47: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0313 - loss: 0.2086 - mae: 0.1463 - mse: 0.0705 - pearson_correlation: -1.4247e-16 - r2_keras: -92.2742 - rmse: 0.9144 - sae: 1945.1250 - sse: 2553.8611 - val_huber_loss: 0.1544 - val_loss: 0.3284 - val_mae: 0.3849 - val_mse: 0.3484 - val_pearson_correlation: -1.8735e-16 - val_r2_keras: -36.9334 - val_rmse: 1.0030 - val_sae: 386.3109 - val_sse: 532.1335 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0395 - loss: 0.2136 - mae: 0.1572 - mse: 0.0808 - pearson_correlation: -5.8882e-16 - r2_keras: -112.5076 - rmse: 0.9271 - sae: 2660.4719 - sse: 3520.8650\n","Epoch 48: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0312 - loss: 0.2085 - mae: 0.1462 - mse: 0.0704 - pearson_correlation: -4.4367e-16 - r2_keras: -92.2781 - rmse: 0.9144 - sae: 1945.1493 - sse: 2553.7664 - val_huber_loss: 0.1545 - val_loss: 0.3285 - val_mae: 0.3850 - val_mse: 0.3487 - val_pearson_correlation: -1.4798e-16 - val_r2_keras: -36.9180 - val_rmse: 1.0028 - val_sae: 386.2118 - val_sse: 531.9175 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0395 - loss: 0.2135 - mae: 0.1570 - mse: 0.0808 - pearson_correlation: 5.6494e-17 - r2_keras: -112.5434 - rmse: 0.9273 - sae: 2660.7363 - sse: 3521.9746\n","Epoch 49: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0312 - loss: 0.2085 - mae: 0.1461 - mse: 0.0703 - pearson_correlation: 6.6153e-17 - r2_keras: -92.3049 - rmse: 0.9145 - sae: 1945.3359 - sse: 2554.5405 - val_huber_loss: 0.1547 - val_loss: 0.3287 - val_mae: 0.3852 - val_mse: 0.3491 - val_pearson_correlation: 2.1674e-16 - val_r2_keras: -36.9594 - val_rmse: 1.0033 - val_sae: 386.4041 - val_sse: 532.4986 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0394 - loss: 0.2134 - mae: 0.1569 - mse: 0.0807 - pearson_correlation: 1.3661e-16 - r2_keras: -112.5745 - rmse: 0.9274 - sae: 2661.0479 - sse: 3522.9375\n","Epoch 50: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0312 - loss: 0.2084 - mae: 0.1459 - mse: 0.0702 - pearson_correlation: 1.2290e-16 - r2_keras: -92.3320 - rmse: 0.9147 - sae: 1945.5656 - sse: 2555.2576 - val_huber_loss: 0.1548 - val_loss: 0.3288 - val_mae: 0.3854 - val_mse: 0.3497 - val_pearson_correlation: 1.2799e-16 - val_r2_keras: -36.9790 - val_rmse: 1.0036 - val_sae: 386.4944 - val_sse: 532.7729 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0394 - loss: 0.2134 - mae: 0.1567 - mse: 0.0806 - pearson_correlation: -2.5860e-16 - r2_keras: -112.6218 - rmse: 0.9276 - sae: 2661.4705 - sse: 3524.4072\n","Epoch 51: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0311 - loss: 0.2084 - mae: 0.1457 - mse: 0.0702 - pearson_correlation: -1.3723e-16 - r2_keras: -92.3713 - rmse: 0.9149 - sae: 1945.8801 - sse: 2556.3276 - val_huber_loss: 0.1550 - val_loss: 0.3289 - val_mae: 0.3856 - val_mse: 0.3501 - val_pearson_correlation: 3.8423e-16 - val_r2_keras: -36.9572 - val_rmse: 1.0033 - val_sae: 386.3556 - val_sse: 532.4675 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0394 - loss: 0.2133 - mae: 0.1566 - mse: 0.0805 - pearson_correlation: -7.7819e-17 - r2_keras: -112.6077 - rmse: 0.9275 - sae: 2661.3286 - sse: 3523.9678\n","Epoch 52: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0311 - loss: 0.2083 - mae: 0.1456 - mse: 0.0701 - pearson_correlation: -5.8578e-17 - r2_keras: -92.3609 - rmse: 0.9148 - sae: 1945.7770 - sse: 2556.0237 - val_huber_loss: 0.1553 - val_loss: 0.3292 - val_mae: 0.3859 - val_mse: 0.3509 - val_pearson_correlation: -2.0662e-16 - val_r2_keras: -36.9974 - val_rmse: 1.0038 - val_sae: 386.5502 - val_sse: 533.0323 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0393 - loss: 0.2133 - mae: 0.1565 - mse: 0.0804 - pearson_correlation: 3.2237e-16 - r2_keras: -112.6360 - rmse: 0.9277 - sae: 2661.5615 - sse: 3524.8457\n","Epoch 53: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0311 - loss: 0.2082 - mae: 0.1455 - mse: 0.0700 - pearson_correlation: 2.0906e-16 - r2_keras: -92.3919 - rmse: 0.9150 - sae: 1945.9803 - sse: 2556.7510 - val_huber_loss: 0.1554 - val_loss: 0.3293 - val_mae: 0.3860 - val_mse: 0.3512 - val_pearson_correlation: -2.7530e-16 - val_r2_keras: -37.0187 - val_rmse: 1.0041 - val_sae: 386.6377 - val_sse: 533.3311 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0393 - loss: 0.2132 - mae: 0.1564 - mse: 0.0803 - pearson_correlation: -3.3653e-16 - r2_keras: -112.6584 - rmse: 0.9278 - sae: 2661.7502 - sse: 3525.5413\n","Epoch 54: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0310 - loss: 0.2082 - mae: 0.1454 - mse: 0.0699 - pearson_correlation: -2.3606e-16 - r2_keras: -92.4128 - rmse: 0.9151 - sae: 1946.1266 - sse: 2557.2844 - val_huber_loss: 0.1555 - val_loss: 0.3294 - val_mae: 0.3862 - val_mse: 0.3515 - val_pearson_correlation: -2.4581e-16 - val_r2_keras: -37.0173 - val_rmse: 1.0041 - val_sae: 386.6138 - val_sse: 533.3105 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0392 - loss: 0.2131 - mae: 0.1561 - mse: 0.0803 - pearson_correlation: 1.3110e-16 - r2_keras: -112.7028 - rmse: 0.9279 - sae: 2662.0640 - sse: 3526.9192\n","Epoch 55: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0310 - loss: 0.2081 - mae: 0.1451 - mse: 0.0699 - pearson_correlation: 1.0245e-16 - r2_keras: -92.4448 - rmse: 0.9153 - sae: 1946.3400 - sse: 2558.2314 - val_huber_loss: 0.1557 - val_loss: 0.3296 - val_mae: 0.3865 - val_mse: 0.3522 - val_pearson_correlation: 1.0800e-16 - val_r2_keras: -37.0625 - val_rmse: 1.0047 - val_sae: 386.8252 - val_sse: 533.9443 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0392 - loss: 0.2131 - mae: 0.1560 - mse: 0.0802 - pearson_correlation: -6.4777e-17 - r2_keras: -112.7167 - rmse: 0.9280 - sae: 2662.2241 - sse: 3527.3503\n","Epoch 56: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0310 - loss: 0.2081 - mae: 0.1450 - mse: 0.0698 - pearson_correlation: -3.5661e-17 - r2_keras: -92.4607 - rmse: 0.9153 - sae: 1946.4694 - sse: 2558.5972 - val_huber_loss: 0.1559 - val_loss: 0.3298 - val_mae: 0.3866 - val_mse: 0.3527 - val_pearson_correlation: -1.1786e-16 - val_r2_keras: -37.0500 - val_rmse: 1.0045 - val_sae: 386.7391 - val_sse: 533.7696 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0392 - loss: 0.2130 - mae: 0.1559 - mse: 0.0801 - pearson_correlation: -5.7403e-17 - r2_keras: -112.7288 - rmse: 0.9280 - sae: 2662.2026 - sse: 3527.7244\n","Epoch 57: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0309 - loss: 0.2080 - mae: 0.1449 - mse: 0.0697 - pearson_correlation: -9.8426e-17 - r2_keras: -92.4773 - rmse: 0.9155 - sae: 1946.4911 - sse: 2558.9463 - val_huber_loss: 0.1561 - val_loss: 0.3299 - val_mae: 0.3869 - val_mse: 0.3532 - val_pearson_correlation: -1.7683e-16 - val_r2_keras: -37.0427 - val_rmse: 1.0044 - val_sae: 386.6905 - val_sse: 533.6670 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0391 - loss: 0.2130 - mae: 0.1558 - mse: 0.0800 - pearson_correlation: -1.1633e-16 - r2_keras: -112.7287 - rmse: 0.9280 - sae: 2662.2729 - sse: 3527.7222\n","Epoch 58: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0309 - loss: 0.2080 - mae: 0.1448 - mse: 0.0696 - pearson_correlation: -1.2434e-16 - r2_keras: -92.4776 - rmse: 0.9155 - sae: 1946.5361 - sse: 2558.9495 - val_huber_loss: 0.1563 - val_loss: 0.3301 - val_mae: 0.3871 - val_mse: 0.3537 - val_pearson_correlation: -2.4505e-16 - val_r2_keras: -37.1123 - val_rmse: 1.0053 - val_sae: 387.0413 - val_sse: 534.6437 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0391 - loss: 0.2129 - mae: 0.1555 - mse: 0.0799 - pearson_correlation: 1.4212e-16 - r2_keras: -112.8087 - rmse: 0.9284 - sae: 2662.9529 - sse: 3530.2051\n","Epoch 59: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0309 - loss: 0.2079 - mae: 0.1445 - mse: 0.0696 - pearson_correlation: 1.2147e-16 - r2_keras: -92.5402 - rmse: 0.9158 - sae: 1947.0189 - sse: 2560.7131 - val_huber_loss: 0.1564 - val_loss: 0.3302 - val_mae: 0.3873 - val_mse: 0.3545 - val_pearson_correlation: 3.3399e-16 - val_r2_keras: -37.0426 - val_rmse: 1.0044 - val_sae: 386.6375 - val_sse: 533.6657 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0390 - loss: 0.2128 - mae: 0.1556 - mse: 0.0799 - pearson_correlation: -6.0354e-16 - r2_keras: -112.7630 - rmse: 0.9282 - sae: 2662.4004 - sse: 3528.7852\n","Epoch 60: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0308 - loss: 0.2078 - mae: 0.1445 - mse: 0.0695 - pearson_correlation: -4.2240e-16 - r2_keras: -92.5107 - rmse: 0.9156 - sae: 1946.6573 - sse: 2559.7783 - val_huber_loss: 0.1567 - val_loss: 0.3305 - val_mae: 0.3876 - val_mse: 0.3551 - val_pearson_correlation: -2.3517e-16 - val_r2_keras: -37.1207 - val_rmse: 1.0054 - val_sae: 387.0392 - val_sse: 534.7610 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0390 - loss: 0.2128 - mae: 0.1554 - mse: 0.0798 - pearson_correlation: 1.9795e-16 - r2_keras: -112.8107 - rmse: 0.9284 - sae: 2662.9695 - sse: 3530.2646\n","Epoch 61: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0308 - loss: 0.2078 - mae: 0.1443 - mse: 0.0694 - pearson_correlation: 1.2863e-16 - r2_keras: -92.5535 - rmse: 0.9159 - sae: 1947.0787 - sse: 2560.8931 - val_huber_loss: 0.1567 - val_loss: 0.3305 - val_mae: 0.3877 - val_mse: 0.3554 - val_pearson_correlation: 9.8136e-17 - val_r2_keras: -37.0719 - val_rmse: 1.0048 - val_sae: 386.7591 - val_sse: 534.0774 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0390 - loss: 0.2127 - mae: 0.1553 - mse: 0.0797 - pearson_correlation: 3.3797e-16 - r2_keras: -112.8315 - rmse: 0.9285 - sae: 2663.0571 - sse: 3530.9116\n","Epoch 62: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0308 - loss: 0.2077 - mae: 0.1442 - mse: 0.0694 - pearson_correlation: 2.6537e-16 - r2_keras: -92.5655 - rmse: 0.9159 - sae: 1947.1328 - sse: 2561.3025 - val_huber_loss: 0.1570 - val_loss: 0.3308 - val_mae: 0.3880 - val_mse: 0.3559 - val_pearson_correlation: -2.2519e-16 - val_r2_keras: -37.1438 - val_rmse: 1.0057 - val_sae: 387.1228 - val_sse: 535.0857 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0389 - loss: 0.2127 - mae: 0.1550 - mse: 0.0796 - pearson_correlation: 4.3274e-16 - r2_keras: -112.8619 - rmse: 0.9286 - sae: 2663.2744 - sse: 3531.8545\n","Epoch 63: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0307 - loss: 0.2077 - mae: 0.1440 - mse: 0.0693 - pearson_correlation: 3.1268e-16 - r2_keras: -92.5952 - rmse: 0.9161 - sae: 1947.3085 - sse: 2562.0417 - val_huber_loss: 0.1571 - val_loss: 0.3309 - val_mae: 0.3881 - val_mse: 0.3565 - val_pearson_correlation: 2.1553e-16 - val_r2_keras: -37.1236 - val_rmse: 1.0055 - val_sae: 386.9908 - val_sse: 534.8023 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0389 - loss: 0.2126 - mae: 0.1550 - mse: 0.0795 - pearson_correlation: 2.6837e-16 - r2_keras: -112.8597 - rmse: 0.9286 - sae: 2663.1895 - sse: 3531.7861\n","Epoch 64: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0307 - loss: 0.2076 - mae: 0.1440 - mse: 0.0692 - pearson_correlation: 1.8058e-16 - r2_keras: -92.5989 - rmse: 0.9161 - sae: 1947.2704 - sse: 2562.0566 - val_huber_loss: 0.1574 - val_loss: 0.3311 - val_mae: 0.3884 - val_mse: 0.3571 - val_pearson_correlation: 2.3463e-16 - val_r2_keras: -37.1903 - val_rmse: 1.0063 - val_sae: 387.3289 - val_sse: 535.7382 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0388 - loss: 0.2125 - mae: 0.1548 - mse: 0.0794 - pearson_correlation: 2.5609e-17 - r2_keras: -112.9019 - rmse: 0.9287 - sae: 2663.6841 - sse: 3533.0947\n","Epoch 65: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0306 - loss: 0.2076 - mae: 0.1438 - mse: 0.0691 - pearson_correlation: 4.6240e-17 - r2_keras: -92.6361 - rmse: 0.9163 - sae: 1947.6350 - sse: 2563.0354 - val_huber_loss: 0.1575 - val_loss: 0.3312 - val_mae: 0.3886 - val_mse: 0.3575 - val_pearson_correlation: 6.8555e-17 - val_r2_keras: -37.1333 - val_rmse: 1.0056 - val_sae: 387.0121 - val_sse: 534.9374 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0388 - loss: 0.2125 - mae: 0.1547 - mse: 0.0793 - pearson_correlation: 5.8718e-16 - r2_keras: -112.9106 - rmse: 0.9288 - sae: 2663.6248 - sse: 3533.3640\n","Epoch 66: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0306 - loss: 0.2075 - mae: 0.1437 - mse: 0.0690 - pearson_correlation: 3.9062e-16 - r2_keras: -92.6445 - rmse: 0.9163 - sae: 1947.6121 - sse: 2563.2461 - val_huber_loss: 0.1576 - val_loss: 0.3313 - val_mae: 0.3886 - val_mse: 0.3576 - val_pearson_correlation: -6.8382e-17 - val_r2_keras: -37.2125 - val_rmse: 1.0066 - val_sae: 387.4120 - val_sse: 536.0490 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0388 - loss: 0.2124 - mae: 0.1544 - mse: 0.0793 - pearson_correlation: -2.8560e-16 - r2_keras: -112.9547 - rmse: 0.9290 - sae: 2664.1819 - sse: 3534.7319\n","Epoch 67: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0306 - loss: 0.2074 - mae: 0.1434 - mse: 0.0690 - pearson_correlation: -1.9373e-16 - r2_keras: -92.6761 - rmse: 0.9165 - sae: 1947.9816 - sse: 2564.1836 - val_huber_loss: 0.1579 - val_loss: 0.3315 - val_mae: 0.3890 - val_mse: 0.3586 - val_pearson_correlation: 4.8863e-17 - val_r2_keras: -37.2002 - val_rmse: 1.0065 - val_sae: 387.3227 - val_sse: 535.8760 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0387 - loss: 0.2124 - mae: 0.1544 - mse: 0.0792 - pearson_correlation: 1.7134e-16 - r2_keras: -112.9381 - rmse: 0.9289 - sae: 2663.9023 - sse: 3534.2161\n","Epoch 68: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0305 - loss: 0.2074 - mae: 0.1434 - mse: 0.0689 - pearson_correlation: 7.7586e-17 - r2_keras: -92.6725 - rmse: 0.9165 - sae: 1947.8236 - sse: 2563.9275 - val_huber_loss: 0.1579 - val_loss: 0.3315 - val_mae: 0.3890 - val_mse: 0.3586 - val_pearson_correlation: 2.8362e-16 - val_r2_keras: -37.1752 - val_rmse: 1.0061 - val_sae: 387.1758 - val_sse: 535.5257 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0387 - loss: 0.2123 - mae: 0.1542 - mse: 0.0791 - pearson_correlation: -3.9144e-16 - r2_keras: -112.9768 - rmse: 0.9291 - sae: 2664.0857 - sse: 3535.4167\n","Epoch 69: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0305 - loss: 0.2073 - mae: 0.1432 - mse: 0.0688 - pearson_correlation: -2.4598e-16 - r2_keras: -92.7006 - rmse: 0.9166 - sae: 1947.9498 - sse: 2564.7544 - val_huber_loss: 0.1582 - val_loss: 0.3318 - val_mae: 0.3893 - val_mse: 0.3594 - val_pearson_correlation: 2.2453e-16 - val_r2_keras: -37.2321 - val_rmse: 1.0069 - val_sae: 387.4554 - val_sse: 536.3239 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0386 - loss: 0.2122 - mae: 0.1542 - mse: 0.0790 - pearson_correlation: -1.2566e-16 - r2_keras: -112.9859 - rmse: 0.9291 - sae: 2664.4580 - sse: 3535.6997\n","Epoch 70: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0305 - loss: 0.2073 - mae: 0.1431 - mse: 0.0687 - pearson_correlation: -1.1207e-16 - r2_keras: -92.7130 - rmse: 0.9167 - sae: 1948.2238 - sse: 2565.0176 - val_huber_loss: 0.1583 - val_loss: 0.3319 - val_mae: 0.3894 - val_mse: 0.3595 - val_pearson_correlation: -2.0491e-16 - val_r2_keras: -37.2469 - val_rmse: 1.0071 - val_sae: 387.5332 - val_sse: 536.5314 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0386 - loss: 0.2122 - mae: 0.1539 - mse: 0.0789 - pearson_correlation: 1.1138e-17 - r2_keras: -113.0636 - rmse: 0.9294 - sae: 2664.9976 - sse: 3538.1086\n","Epoch 71: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0304 - loss: 0.2072 - mae: 0.1429 - mse: 0.0687 - pearson_correlation: 2.9888e-17 - r2_keras: -92.7721 - rmse: 0.9170 - sae: 1948.6178 - sse: 2566.7100 - val_huber_loss: 0.1584 - val_loss: 0.3320 - val_mae: 0.3896 - val_mse: 0.3601 - val_pearson_correlation: -1.5630e-16 - val_r2_keras: -37.2094 - val_rmse: 1.0066 - val_sae: 387.3094 - val_sse: 536.0050 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0385 - loss: 0.2121 - mae: 0.1540 - mse: 0.0788 - pearson_correlation: 6.5341e-16 - r2_keras: -112.9784 - rmse: 0.9291 - sae: 2664.3186 - sse: 3535.4688\n","Epoch 72: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0304 - loss: 0.2072 - mae: 0.1430 - mse: 0.0686 - pearson_correlation: 3.6904e-16 - r2_keras: -92.7130 - rmse: 0.9167 - sae: 1948.1497 - sse: 2564.9214 - val_huber_loss: 0.1585 - val_loss: 0.3321 - val_mae: 0.3897 - val_mse: 0.3604 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -37.2580 - val_rmse: 1.0072 - val_sae: 387.5511 - val_sse: 536.6870 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0385 - loss: 0.2121 - mae: 0.1537 - mse: 0.0788 - pearson_correlation: 2.0254e-18 - r2_keras: -113.0492 - rmse: 0.9293 - sae: 2664.7979 - sse: 3537.6621\n","Epoch 73: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0304 - loss: 0.2071 - mae: 0.1427 - mse: 0.0685 - pearson_correlation: -2.0272e-17 - r2_keras: -92.7689 - rmse: 0.9170 - sae: 1948.4976 - sse: 2566.4873 - val_huber_loss: 0.1588 - val_loss: 0.3323 - val_mae: 0.3900 - val_mse: 0.3610 - val_pearson_correlation: 1.3643e-16 - val_r2_keras: -37.2871 - val_rmse: 1.0076 - val_sae: 387.6908 - val_sse: 537.0951 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0385 - loss: 0.2120 - mae: 0.1537 - mse: 0.0787 - pearson_correlation: 6.1517e-17 - r2_keras: -113.0578 - rmse: 0.9294 - sae: 2664.9292 - sse: 3537.9312\n","Epoch 74: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0304 - loss: 0.2071 - mae: 0.1426 - mse: 0.0684 - pearson_correlation: 5.2648e-17 - r2_keras: -92.7827 - rmse: 0.9171 - sae: 1948.6215 - sse: 2566.7607 - val_huber_loss: 0.1589 - val_loss: 0.3324 - val_mae: 0.3901 - val_mse: 0.3613 - val_pearson_correlation: 9.7495e-18 - val_r2_keras: -37.2705 - val_rmse: 1.0074 - val_sae: 387.5991 - val_sse: 536.8622 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0384 - loss: 0.2119 - mae: 0.1535 - mse: 0.0786 - pearson_correlation: -4.0747e-16 - r2_keras: -113.0850 - rmse: 0.9295 - sae: 2665.2698 - sse: 3538.7727\n","Epoch 75: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0303 - loss: 0.2070 - mae: 0.1425 - mse: 0.0684 - pearson_correlation: -2.4670e-16 - r2_keras: -92.7970 - rmse: 0.9171 - sae: 1948.8322 - sse: 2567.2771 - val_huber_loss: 0.1590 - val_loss: 0.3325 - val_mae: 0.3903 - val_mse: 0.3617 - val_pearson_correlation: 7.0169e-16 - val_r2_keras: -37.2820 - val_rmse: 1.0076 - val_sae: 387.6356 - val_sse: 537.0247 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0384 - loss: 0.2119 - mae: 0.1535 - mse: 0.0785 - pearson_correlation: -6.8414e-16 - r2_keras: -113.0414 - rmse: 0.9293 - sae: 2664.6665 - sse: 3537.4204\n","Epoch 76: val_loss did not improve from 0.31180\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0303 - loss: 0.2069 - mae: 0.1424 - mse: 0.0683 - pearson_correlation: -4.5277e-16 - r2_keras: -92.7745 - rmse: 0.9170 - sae: 1948.4437 - sse: 2566.4521 - val_huber_loss: 0.1592 - val_loss: 0.3327 - val_mae: 0.3905 - val_mse: 0.3623 - val_pearson_correlation: -2.9211e-16 - val_r2_keras: -37.3111 - val_rmse: 1.0079 - val_sae: 387.7821 - val_sse: 537.4324 - learning_rate: 1.0000e-05\n","| \u001b[39m3        \u001b[39m | \u001b[39m-0.3327  \u001b[39m | \u001b[39m0.004674 \u001b[39m | \u001b[39m95.59    \u001b[39m | \u001b[39m59.05    \u001b[39m | \u001b[39m71.13    \u001b[39m | \u001b[39m13.41    \u001b[39m | \u001b[39m88.35    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 1.0141 - loss: 1.1326 - mae: 1.4734 - mse: 3.1700 - pearson_correlation: 1.9596e-16 - r2_keras: -284.9043 - rmse: 1.4714 - sae: 4933.6260 - sse: 8868.3926\n","Epoch 1: val_loss improved from inf to 0.36085, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620ms/step - huber_loss: 0.8191 - loss: 1.0139 - mae: 1.3305 - mse: 2.7434 - pearson_correlation: 7.6905e-17 - r2_keras: -213.2246 - rmse: 1.3242 - sae: 3503.5842 - sse: 6189.3462 - val_huber_loss: 0.2423 - val_loss: 0.3609 - val_mae: 0.5937 - val_mse: 0.5885 - val_pearson_correlation: -4.6844e-17 - val_r2_keras: -22.2623 - val_rmse: 0.7854 - val_sae: 321.6080 - val_sse: 326.3254 - learning_rate: 4.2145e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.5563 - loss: 0.6748 - mae: 0.9283 - mse: 1.4814 - pearson_correlation: 3.2946e-16 - r2_keras: -172.5651 - rmse: 1.1465 - sae: 3904.7751 - sse: 5383.7715\n","Epoch 2: val_loss improved from 0.36085 to 0.34683, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.4356 - loss: 0.6013 - mae: 0.8382 - mse: 1.2640 - pearson_correlation: 3.1055e-16 - r2_keras: -131.7129 - rmse: 1.0555 - sae: 2778.6858 - sse: 3788.6252 - val_huber_loss: 0.2284 - val_loss: 0.3468 - val_mae: 0.5749 - val_mse: 0.5412 - val_pearson_correlation: -2.6490e-17 - val_r2_keras: -22.4352 - val_rmse: 0.7883 - val_sae: 325.4660 - val_sse: 328.7509 - learning_rate: 4.2145e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3326 - loss: 0.4511 - mae: 0.6705 - mse: 0.8669 - pearson_correlation: -1.8750e-16 - r2_keras: -118.3243 - rmse: 0.9506 - sae: 3126.8530 - sse: 3701.2910\n","Epoch 3: val_loss improved from 0.34683 to 0.33787, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.2635 - loss: 0.4090 - mae: 0.6095 - mse: 0.7423 - pearson_correlation: 1.6588e-17 - r2_keras: -94.9821 - rmse: 0.9200 - sae: 2254.4226 - sse: 2660.2815 - val_huber_loss: 0.2195 - val_loss: 0.3379 - val_mae: 0.5602 - val_mse: 0.5085 - val_pearson_correlation: -4.1270e-17 - val_r2_keras: -22.8750 - val_rmse: 0.7957 - val_sae: 329.0823 - val_sse: 334.9216 - learning_rate: 4.2145e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2459 - loss: 0.3643 - mae: 0.5584 - mse: 0.6142 - pearson_correlation: 5.6334e-17 - r2_keras: -104.8399 - rmse: 0.8953 - sae: 2831.7000 - sse: 3283.0205\n","Epoch 4: val_loss improved from 0.33787 to 0.33513, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1960 - loss: 0.3339 - mae: 0.5081 - mse: 0.5288 - pearson_correlation: -1.0959e-17 - r2_keras: -85.8609 - rmse: 0.8820 - sae: 2055.9561 - sse: 2379.8911 - val_huber_loss: 0.2168 - val_loss: 0.3351 - val_mae: 0.5542 - val_mse: 0.4910 - val_pearson_correlation: -2.5134e-17 - val_r2_keras: -23.5696 - val_rmse: 0.8072 - val_sae: 333.6498 - val_sse: 344.6648 - learning_rate: 4.2145e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1957 - loss: 0.3141 - mae: 0.4857 - mse: 0.4792 - pearson_correlation: -2.6549e-16 - r2_keras: -96.9049 - rmse: 0.8611 - sae: 2667.8008 - sse: 3036.8867\n","Epoch 5: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1586 - loss: 0.2915 - mae: 0.4461 - mse: 0.4164 - pearson_correlation: -1.6215e-16 - r2_keras: -80.3730 - rmse: 0.8574 - sae: 1945.6404 - sse: 2213.4810 - val_huber_loss: 0.2224 - val_loss: 0.3407 - val_mae: 0.5646 - val_mse: 0.4936 - val_pearson_correlation: 2.5643e-16 - val_r2_keras: -24.6604 - val_rmse: 0.8249 - val_sae: 344.3334 - val_sse: 359.9662 - learning_rate: 4.2145e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1656 - loss: 0.2838 - mae: 0.4318 - mse: 0.3957 - pearson_correlation: 4.8794e-16 - r2_keras: -94.7537 - rmse: 0.8515 - sae: 2617.8982 - sse: 2970.1611\n","Epoch 6: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1354 - loss: 0.2655 - mae: 0.3994 - mse: 0.3461 - pearson_correlation: 3.5534e-16 - r2_keras: -78.7752 - rmse: 0.8496 - sae: 1912.0066 - sse: 2167.0771 - val_huber_loss: 0.2383 - val_loss: 0.3566 - val_mae: 0.5934 - val_mse: 0.5171 - val_pearson_correlation: -8.8690e-17 - val_r2_keras: -26.3743 - val_rmse: 0.8520 - val_sae: 359.0641 - val_sse: 384.0103 - learning_rate: 4.2145e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1445 - loss: 0.2627 - mae: 0.3956 - mse: 0.3418 - pearson_correlation: -4.6772e-16 - r2_keras: -92.5485 - rmse: 0.8417 - sae: 2587.2866 - sse: 2901.7573\n","Epoch 7: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1201 - loss: 0.2479 - mae: 0.3677 - mse: 0.3015 - pearson_correlation: -3.9603e-16 - r2_keras: -77.6430 - rmse: 0.8460 - sae: 1892.9290 - sse: 2125.4387 - val_huber_loss: 0.2449 - val_loss: 0.3630 - val_mae: 0.5986 - val_mse: 0.5239 - val_pearson_correlation: 1.1480e-16 - val_r2_keras: -28.1374 - val_rmse: 0.8790 - val_sae: 369.0917 - val_sse: 408.7430 - learning_rate: 4.2145e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1290 - loss: 0.2471 - mae: 0.3672 - mse: 0.2993 - pearson_correlation: 7.2090e-16 - r2_keras: -92.8054 - rmse: 0.8428 - sae: 2580.2666 - sse: 2909.7268\n","Epoch 8: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1079 - loss: 0.2343 - mae: 0.3440 - mse: 0.2654 - pearson_correlation: 4.1107e-16 - r2_keras: -76.9334 - rmse: 0.8390 - sae: 1884.4240 - sse: 2120.4194 - val_huber_loss: 0.2328 - val_loss: 0.3509 - val_mae: 0.5755 - val_mse: 0.4920 - val_pearson_correlation: -1.2434e-16 - val_r2_keras: -30.3625 - val_rmse: 0.9120 - val_sae: 377.3764 - val_sse: 439.9571 - learning_rate: 4.2145e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1169 - loss: 0.2350 - mae: 0.3440 - mse: 0.2695 - pearson_correlation: -1.1550e-16 - r2_keras: -94.9786 - rmse: 0.8525 - sae: 2592.6167 - sse: 2977.1372\n","Epoch 9: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0986 - loss: 0.2238 - mae: 0.3217 - mse: 0.2400 - pearson_correlation: -1.0756e-16 - r2_keras: -78.6926 - rmse: 0.8482 - sae: 1894.1274 - sse: 2169.0005 - val_huber_loss: 0.2323 - val_loss: 0.3503 - val_mae: 0.5791 - val_mse: 0.4864 - val_pearson_correlation: -2.9359e-17 - val_r2_keras: -31.9530 - val_rmse: 0.9348 - val_sae: 386.7792 - val_sse: 462.2685 - learning_rate: 4.2145e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1077 - loss: 0.2257 - mae: 0.3289 - mse: 0.2442 - pearson_correlation: 2.2167e-16 - r2_keras: -93.7643 - rmse: 0.8471 - sae: 2572.2253 - sse: 2939.4688\n","Epoch 10: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0900 - loss: 0.2149 - mae: 0.3063 - mse: 0.2169 - pearson_correlation: 1.0167e-16 - r2_keras: -77.8070 - rmse: 0.8440 - sae: 1880.5729 - sse: 2142.9958 - val_huber_loss: 0.2278 - val_loss: 0.3458 - val_mae: 0.5741 - val_mse: 0.4727 - val_pearson_correlation: 1.7512e-16 - val_r2_keras: -34.2085 - val_rmse: 0.9663 - val_sae: 401.7188 - val_sse: 493.9093 - learning_rate: 8.4291e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1055 - loss: 0.2234 - mae: 0.3235 - mse: 0.2386 - pearson_correlation: -3.6085e-16 - r2_keras: -94.3994 - rmse: 0.8500 - sae: 2576.8308 - sse: 2959.1709\n","Epoch 11: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0882 - loss: 0.2129 - mae: 0.3014 - mse: 0.2119 - pearson_correlation: -1.7772e-16 - r2_keras: -78.3401 - rmse: 0.8468 - sae: 1884.0443 - sse: 2157.4167 - val_huber_loss: 0.2300 - val_loss: 0.3480 - val_mae: 0.5637 - val_mse: 0.4752 - val_pearson_correlation: -2.4352e-16 - val_r2_keras: -36.3022 - val_rmse: 0.9946 - val_sae: 412.2462 - val_sse: 523.2791 - learning_rate: 8.4291e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1035 - loss: 0.2215 - mae: 0.3193 - mse: 0.2337 - pearson_correlation: 7.6092e-17 - r2_keras: -94.7560 - rmse: 0.8516 - sae: 2578.9072 - sse: 2970.2327\n","Epoch 12: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0866 - loss: 0.2112 - mae: 0.2975 - mse: 0.2076 - pearson_correlation: 1.2777e-17 - r2_keras: -78.6243 - rmse: 0.8483 - sae: 1885.5865 - sse: 2165.3364 - val_huber_loss: 0.2268 - val_loss: 0.3447 - val_mae: 0.5583 - val_mse: 0.4676 - val_pearson_correlation: -1.5417e-16 - val_r2_keras: -37.8171 - val_rmse: 1.0146 - val_sae: 418.7637 - val_sse: 544.5305 - learning_rate: 8.4291e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1017 - loss: 0.2196 - mae: 0.3156 - mse: 0.2287 - pearson_correlation: -1.3162e-16 - r2_keras: -95.0962 - rmse: 0.8531 - sae: 2581.8140 - sse: 2980.7847\n","Epoch 13: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0851 - loss: 0.2095 - mae: 0.2941 - mse: 0.2033 - pearson_correlation: -6.1251e-17 - r2_keras: -78.8837 - rmse: 0.8496 - sae: 1887.5912 - sse: 2172.7532 - val_huber_loss: 0.2252 - val_loss: 0.3432 - val_mae: 0.5558 - val_mse: 0.4639 - val_pearson_correlation: 1.7129e-16 - val_r2_keras: -38.9947 - val_rmse: 1.0298 - val_sae: 423.9069 - val_sse: 561.0494 - learning_rate: 8.4291e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0998 - loss: 0.2177 - mae: 0.3119 - mse: 0.2239 - pearson_correlation: -3.7167e-16 - r2_keras: -95.1365 - rmse: 0.8533 - sae: 2580.7500 - sse: 2982.0352\n","Epoch 14: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0835 - loss: 0.2078 - mae: 0.2906 - mse: 0.1991 - pearson_correlation: -2.1944e-16 - r2_keras: -78.9328 - rmse: 0.8499 - sae: 1886.9404 - sse: 2173.8484 - val_huber_loss: 0.2246 - val_loss: 0.3425 - val_mae: 0.5556 - val_mse: 0.4624 - val_pearson_correlation: 1.9355e-16 - val_r2_keras: -39.9334 - val_rmse: 1.0419 - val_sae: 427.8022 - val_sse: 574.2179 - learning_rate: 8.4291e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0979 - loss: 0.2159 - mae: 0.3085 - mse: 0.2190 - pearson_correlation: 2.5985e-17 - r2_keras: -95.2798 - rmse: 0.8539 - sae: 2581.5796 - sse: 2986.4790\n","Epoch 15: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0817 - loss: 0.2060 - mae: 0.2870 - mse: 0.1946 - pearson_correlation: 2.2384e-18 - r2_keras: -79.0544 - rmse: 0.8506 - sae: 1887.5887 - sse: 2177.1167 - val_huber_loss: 0.2239 - val_loss: 0.3418 - val_mae: 0.5540 - val_mse: 0.4611 - val_pearson_correlation: 6.3262e-17 - val_r2_keras: -40.5633 - val_rmse: 1.0498 - val_sae: 430.3853 - val_sse: 583.0540 - learning_rate: 1.6858e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0975 - loss: 0.2155 - mae: 0.3077 - mse: 0.2180 - pearson_correlation: -4.6813e-16 - r2_keras: -95.3087 - rmse: 0.8540 - sae: 2581.7991 - sse: 2987.3755\n","Epoch 16: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0814 - loss: 0.2056 - mae: 0.2863 - mse: 0.1937 - pearson_correlation: -2.7816e-16 - r2_keras: -79.0800 - rmse: 0.8507 - sae: 1887.7677 - sse: 2177.7886 - val_huber_loss: 0.2231 - val_loss: 0.3410 - val_mae: 0.5522 - val_mse: 0.4598 - val_pearson_correlation: 4.0098e-17 - val_r2_keras: -41.0242 - val_rmse: 1.0557 - val_sae: 432.1662 - val_sse: 589.5201 - learning_rate: 1.6858e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0971 - loss: 0.2150 - mae: 0.3068 - mse: 0.2169 - pearson_correlation: -2.6122e-16 - r2_keras: -95.4029 - rmse: 0.8544 - sae: 2582.5286 - sse: 2990.2964\n","Epoch 17: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0811 - loss: 0.2053 - mae: 0.2855 - mse: 0.1928 - pearson_correlation: -1.4210e-16 - r2_keras: -79.1369 - rmse: 0.8509 - sae: 1888.2316 - sse: 2179.6672 - val_huber_loss: 0.2225 - val_loss: 0.3404 - val_mae: 0.5511 - val_mse: 0.4589 - val_pearson_correlation: -1.4570e-16 - val_r2_keras: -41.3283 - val_rmse: 1.0595 - val_sae: 433.2814 - val_sse: 593.7864 - learning_rate: 1.6858e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0967 - loss: 0.2146 - mae: 0.3059 - mse: 0.2158 - pearson_correlation: 1.2768e-16 - r2_keras: -95.4418 - rmse: 0.8546 - sae: 2582.6914 - sse: 2991.5039\n","Epoch 18: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0807 - loss: 0.2049 - mae: 0.2848 - mse: 0.1918 - pearson_correlation: 7.5698e-17 - r2_keras: -79.1680 - rmse: 0.8511 - sae: 1888.3881 - sse: 2180.5317 - val_huber_loss: 0.2221 - val_loss: 0.3400 - val_mae: 0.5503 - val_mse: 0.4582 - val_pearson_correlation: 2.1055e-16 - val_r2_keras: -41.5501 - val_rmse: 1.0622 - val_sae: 434.0993 - val_sse: 596.8978 - learning_rate: 1.6858e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0963 - loss: 0.2142 - mae: 0.3049 - mse: 0.2147 - pearson_correlation: -3.7866e-18 - r2_keras: -95.5401 - rmse: 0.8550 - sae: 2583.3677 - sse: 2994.5547\n","Epoch 19: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0804 - loss: 0.2045 - mae: 0.2838 - mse: 0.1909 - pearson_correlation: 1.0671e-17 - r2_keras: -79.2315 - rmse: 0.8514 - sae: 1888.8143 - sse: 2182.5415 - val_huber_loss: 0.2218 - val_loss: 0.3397 - val_mae: 0.5500 - val_mse: 0.4578 - val_pearson_correlation: 8.7362e-17 - val_r2_keras: -41.6955 - val_rmse: 1.0641 - val_sae: 434.6211 - val_sse: 598.9371 - learning_rate: 1.6858e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0958 - loss: 0.2137 - mae: 0.3040 - mse: 0.2135 - pearson_correlation: 8.6401e-16 - r2_keras: -95.5823 - rmse: 0.8552 - sae: 2583.5981 - sse: 2995.8630\n","Epoch 20: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0800 - loss: 0.2041 - mae: 0.2830 - mse: 0.1898 - pearson_correlation: 6.0427e-16 - r2_keras: -79.2659 - rmse: 0.8516 - sae: 1889.0177 - sse: 2183.4875 - val_huber_loss: 0.2216 - val_loss: 0.3395 - val_mae: 0.5499 - val_mse: 0.4574 - val_pearson_correlation: -3.3531e-16 - val_r2_keras: -41.8040 - val_rmse: 1.0654 - val_sae: 435.0659 - val_sse: 600.4597 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0955 - loss: 0.2134 - mae: 0.3033 - mse: 0.2128 - pearson_correlation: -3.1624e-16 - r2_keras: -95.6528 - rmse: 0.8555 - sae: 2584.1455 - sse: 2998.0493\n","Epoch 21: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0798 - loss: 0.2038 - mae: 0.2824 - mse: 0.1892 - pearson_correlation: -2.5415e-16 - r2_keras: -79.3158 - rmse: 0.8518 - sae: 1889.3925 - sse: 2184.9800 - val_huber_loss: 0.2215 - val_loss: 0.3394 - val_mae: 0.5499 - val_mse: 0.4573 - val_pearson_correlation: 1.6948e-16 - val_r2_keras: -41.8792 - val_rmse: 1.0663 - val_sae: 435.3770 - val_sse: 601.5135 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0952 - loss: 0.2131 - mae: 0.3028 - mse: 0.2120 - pearson_correlation: -9.7588e-17 - r2_keras: -95.6877 - rmse: 0.8557 - sae: 2584.4082 - sse: 2999.1326\n","Epoch 22: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0795 - loss: 0.2036 - mae: 0.2819 - mse: 0.1885 - pearson_correlation: -5.7525e-17 - r2_keras: -79.3406 - rmse: 0.8519 - sae: 1889.5851 - sse: 2185.7190 - val_huber_loss: 0.2214 - val_loss: 0.3393 - val_mae: 0.5498 - val_mse: 0.4570 - val_pearson_correlation: -2.3438e-16 - val_r2_keras: -41.9231 - val_rmse: 1.0669 - val_sae: 435.5434 - val_sse: 602.1296 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0949 - loss: 0.2128 - mae: 0.3022 - mse: 0.2113 - pearson_correlation: -1.5415e-16 - r2_keras: -95.7287 - rmse: 0.8559 - sae: 2584.6467 - sse: 3000.4033\n","Epoch 23: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0793 - loss: 0.2033 - mae: 0.2814 - mse: 0.1879 - pearson_correlation: -1.4231e-16 - r2_keras: -79.3699 - rmse: 0.8520 - sae: 1889.7433 - sse: 2186.5896 - val_huber_loss: 0.2213 - val_loss: 0.3392 - val_mae: 0.5498 - val_mse: 0.4569 - val_pearson_correlation: 2.6012e-17 - val_r2_keras: -41.9645 - val_rmse: 1.0674 - val_sae: 435.7094 - val_sse: 602.7112 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0947 - loss: 0.2125 - mae: 0.3016 - mse: 0.2105 - pearson_correlation: 9.7464e-17 - r2_keras: -95.7665 - rmse: 0.8560 - sae: 2584.9124 - sse: 3001.5750\n","Epoch 24: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0791 - loss: 0.2030 - mae: 0.2809 - mse: 0.1872 - pearson_correlation: 8.7581e-17 - r2_keras: -79.3913 - rmse: 0.8521 - sae: 1889.9016 - sse: 2187.3262 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5496 - val_mse: 0.4566 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -41.9874 - val_rmse: 1.0677 - val_sae: 435.7549 - val_sse: 603.0319 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0944 - loss: 0.2122 - mae: 0.3010 - mse: 0.2097 - pearson_correlation: 2.0169e-16 - r2_keras: -95.8133 - rmse: 0.8562 - sae: 2585.1873 - sse: 3003.0269\n","Epoch 25: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0788 - loss: 0.2028 - mae: 0.2803 - mse: 0.1866 - pearson_correlation: 1.1751e-16 - r2_keras: -79.4237 - rmse: 0.8523 - sae: 1890.0750 - sse: 2188.3083 - val_huber_loss: 0.2211 - val_loss: 0.3390 - val_mae: 0.5496 - val_mse: 0.4566 - val_pearson_correlation: -1.4292e-16 - val_r2_keras: -42.0001 - val_rmse: 1.0678 - val_sae: 435.7796 - val_sse: 603.2095 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0941 - loss: 0.2119 - mae: 0.3005 - mse: 0.2089 - pearson_correlation: -2.2495e-16 - r2_keras: -95.8088 - rmse: 0.8562 - sae: 2585.0452 - sse: 3002.8867\n","Epoch 26: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0786 - loss: 0.2025 - mae: 0.2799 - mse: 0.1859 - pearson_correlation: -1.3679e-16 - r2_keras: -79.4251 - rmse: 0.8523 - sae: 1890.0116 - sse: 2188.2666 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5498 - val_mse: 0.4567 - val_pearson_correlation: 1.9037e-16 - val_r2_keras: -42.0359 - val_rmse: 1.0683 - val_sae: 435.9252 - val_sse: 603.7116 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0937 - loss: 0.2116 - mae: 0.2998 - mse: 0.2081 - pearson_correlation: -4.6881e-16 - r2_keras: -95.8865 - rmse: 0.8566 - sae: 2585.6968 - sse: 3005.2971\n","Epoch 27: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0783 - loss: 0.2022 - mae: 0.2793 - mse: 0.1852 - pearson_correlation: -3.0313e-16 - r2_keras: -79.4787 - rmse: 0.8525 - sae: 1890.4479 - sse: 2189.8953 - val_huber_loss: 0.2212 - val_loss: 0.3391 - val_mae: 0.5499 - val_mse: 0.4568 - val_pearson_correlation: 2.3350e-16 - val_r2_keras: -42.0551 - val_rmse: 1.0685 - val_sae: 435.9908 - val_sse: 603.9815 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0934 - loss: 0.2113 - mae: 0.2993 - mse: 0.2073 - pearson_correlation: -1.1481e-16 - r2_keras: -95.9049 - rmse: 0.8567 - sae: 2585.7817 - sse: 3005.8687\n","Epoch 28: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0781 - loss: 0.2020 - mae: 0.2788 - mse: 0.1845 - pearson_correlation: -5.7711e-17 - r2_keras: -79.4870 - rmse: 0.8526 - sae: 1890.4811 - sse: 2190.2292 - val_huber_loss: 0.2210 - val_loss: 0.3389 - val_mae: 0.5496 - val_mse: 0.4565 - val_pearson_correlation: -5.1450e-16 - val_r2_keras: -42.0583 - val_rmse: 1.0686 - val_sae: 435.9622 - val_sse: 604.0272 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0931 - loss: 0.2110 - mae: 0.2987 - mse: 0.2065 - pearson_correlation: -3.4733e-16 - r2_keras: -95.9502 - rmse: 0.8569 - sae: 2586.0010 - sse: 3007.2747\n","Epoch 29: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0778 - loss: 0.2017 - mae: 0.2783 - mse: 0.1838 - pearson_correlation: -2.7484e-16 - r2_keras: -79.5246 - rmse: 0.8528 - sae: 1890.6483 - sse: 2191.2527 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5499 - val_mse: 0.4568 - val_pearson_correlation: -2.7653e-16 - val_r2_keras: -42.0807 - val_rmse: 1.0688 - val_sae: 436.0302 - val_sse: 604.3404 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0928 - loss: 0.2107 - mae: 0.2981 - mse: 0.2057 - pearson_correlation: -2.5380e-16 - r2_keras: -95.9788 - rmse: 0.8570 - sae: 2586.2222 - sse: 3008.1611\n","Epoch 30: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0776 - loss: 0.2014 - mae: 0.2777 - mse: 0.1831 - pearson_correlation: -1.1648e-16 - r2_keras: -79.5402 - rmse: 0.8528 - sae: 1890.7887 - sse: 2191.8035 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5498 - val_mse: 0.4568 - val_pearson_correlation: -3.2833e-16 - val_r2_keras: -42.0845 - val_rmse: 1.0689 - val_sae: 436.0040 - val_sse: 604.3945 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0925 - loss: 0.2104 - mae: 0.2975 - mse: 0.2049 - pearson_correlation: 1.0835e-16 - r2_keras: -96.0120 - rmse: 0.8571 - sae: 2586.3953 - sse: 3009.1921\n","Epoch 31: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0773 - loss: 0.2011 - mae: 0.2771 - mse: 0.1824 - pearson_correlation: 1.1929e-16 - r2_keras: -79.5654 - rmse: 0.8529 - sae: 1890.9069 - sse: 2192.5269 - val_huber_loss: 0.2211 - val_loss: 0.3390 - val_mae: 0.5498 - val_mse: 0.4567 - val_pearson_correlation: -3.0222e-17 - val_r2_keras: -42.1068 - val_rmse: 1.0692 - val_sae: 436.0843 - val_sse: 604.7067 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - huber_loss: 0.0922 - loss: 0.2100 - mae: 0.2969 - mse: 0.2041 - pearson_correlation: 1.3332e-16 - r2_keras: -96.0547 - rmse: 0.8573 - sae: 2586.6553 - sse: 3010.5154\n","Epoch 32: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - huber_loss: 0.0771 - loss: 0.2008 - mae: 0.2766 - mse: 0.1817 - pearson_correlation: 5.8781e-17 - r2_keras: -79.6020 - rmse: 0.8531 - sae: 1891.1046 - sse: 2193.5039 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5499 - val_mse: 0.4568 - val_pearson_correlation: 1.7262e-17 - val_r2_keras: -42.1195 - val_rmse: 1.0693 - val_sae: 436.1001 - val_sse: 604.8852 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - huber_loss: 0.0919 - loss: 0.2097 - mae: 0.2962 - mse: 0.2033 - pearson_correlation: -7.7883e-16 - r2_keras: -96.0872 - rmse: 0.8575 - sae: 2586.8186 - sse: 3011.5242\n","Epoch 33: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0768 - loss: 0.2006 - mae: 0.2760 - mse: 0.1810 - pearson_correlation: -5.0793e-16 - r2_keras: -79.6168 - rmse: 0.8532 - sae: 1891.1750 - sse: 2194.0962 - val_huber_loss: 0.2211 - val_loss: 0.3390 - val_mae: 0.5499 - val_mse: 0.4568 - val_pearson_correlation: 1.0788e-16 - val_r2_keras: -42.1261 - val_rmse: 1.0694 - val_sae: 436.1192 - val_sse: 604.9774 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0916 - loss: 0.2094 - mae: 0.2957 - mse: 0.2025 - pearson_correlation: -2.2322e-16 - r2_keras: -96.1182 - rmse: 0.8576 - sae: 2587.0273 - sse: 3012.4839\n","Epoch 34: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0766 - loss: 0.2003 - mae: 0.2755 - mse: 0.1803 - pearson_correlation: -1.4128e-16 - r2_keras: -79.6392 - rmse: 0.8533 - sae: 1891.2997 - sse: 2194.7573 - val_huber_loss: 0.2213 - val_loss: 0.3391 - val_mae: 0.5500 - val_mse: 0.4571 - val_pearson_correlation: 3.7104e-16 - val_r2_keras: -42.1304 - val_rmse: 1.0695 - val_sae: 436.0778 - val_sse: 605.0377 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0913 - loss: 0.2091 - mae: 0.2951 - mse: 0.2017 - pearson_correlation: -5.0335e-16 - r2_keras: -96.1134 - rmse: 0.8576 - sae: 2586.8462 - sse: 3012.3350\n","Epoch 35: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0763 - loss: 0.2000 - mae: 0.2750 - mse: 0.1796 - pearson_correlation: -3.1676e-16 - r2_keras: -79.6397 - rmse: 0.8533 - sae: 1891.1910 - sse: 2194.7012 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5499 - val_mse: 0.4570 - val_pearson_correlation: -6.4707e-17 - val_r2_keras: -42.1315 - val_rmse: 1.0695 - val_sae: 436.0217 - val_sse: 605.0527 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0910 - loss: 0.2088 - mae: 0.2944 - mse: 0.2009 - pearson_correlation: -3.7496e-18 - r2_keras: -96.1493 - rmse: 0.8577 - sae: 2586.9390 - sse: 3013.4500\n","Epoch 36: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0761 - loss: 0.1997 - mae: 0.2744 - mse: 0.1790 - pearson_correlation: 1.0674e-17 - r2_keras: -79.6581 - rmse: 0.8533 - sae: 1891.2349 - sse: 2195.3794 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5500 - val_mse: 0.4569 - val_pearson_correlation: -5.6882e-16 - val_r2_keras: -42.1720 - val_rmse: 1.0700 - val_sae: 436.2258 - val_sse: 605.6218 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0906 - loss: 0.2085 - mae: 0.2939 - mse: 0.2000 - pearson_correlation: 4.7446e-17 - r2_keras: -96.2143 - rmse: 0.8580 - sae: 2587.5452 - sse: 3015.4653\n","Epoch 37: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0758 - loss: 0.1995 - mae: 0.2739 - mse: 0.1782 - pearson_correlation: 1.6594e-17 - r2_keras: -79.7179 - rmse: 0.8537 - sae: 1891.7142 - sse: 2196.9163 - val_huber_loss: 0.2213 - val_loss: 0.3391 - val_mae: 0.5503 - val_mse: 0.4572 - val_pearson_correlation: -6.4618e-17 - val_r2_keras: -42.1809 - val_rmse: 1.0701 - val_sae: 436.2187 - val_sse: 605.7457 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.0903 - loss: 0.2082 - mae: 0.2932 - mse: 0.1993 - pearson_correlation: 3.1762e-16 - r2_keras: -96.2436 - rmse: 0.8581 - sae: 2587.6060 - sse: 3016.3733\n","Epoch 38: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - huber_loss: 0.0756 - loss: 0.1992 - mae: 0.2732 - mse: 0.1775 - pearson_correlation: 2.2869e-16 - r2_keras: -79.7176 - rmse: 0.8536 - sae: 1891.6530 - sse: 2197.2886 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5501 - val_mse: 0.4570 - val_pearson_correlation: 1.5508e-16 - val_r2_keras: -42.1841 - val_rmse: 1.0701 - val_sae: 436.2116 - val_sse: 605.7914 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0900 - loss: 0.2079 - mae: 0.2927 - mse: 0.1985 - pearson_correlation: -2.5384e-16 - r2_keras: -96.2755 - rmse: 0.8583 - sae: 2587.7881 - sse: 3017.3630\n","Epoch 39: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0753 - loss: 0.1989 - mae: 0.2728 - mse: 0.1768 - pearson_correlation: -1.3914e-16 - r2_keras: -79.7514 - rmse: 0.8538 - sae: 1891.8120 - sse: 2198.0962 - val_huber_loss: 0.2213 - val_loss: 0.3391 - val_mae: 0.5503 - val_mse: 0.4572 - val_pearson_correlation: 1.1623e-16 - val_r2_keras: -42.2075 - val_rmse: 1.0704 - val_sae: 436.2975 - val_sse: 606.1192 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0897 - loss: 0.2076 - mae: 0.2920 - mse: 0.1977 - pearson_correlation: 6.2320e-17 - r2_keras: -96.3246 - rmse: 0.8585 - sae: 2588.1611 - sse: 3018.8884\n","Epoch 40: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - huber_loss: 0.0751 - loss: 0.1986 - mae: 0.2722 - mse: 0.1761 - pearson_correlation: -3.5973e-18 - r2_keras: -79.7817 - rmse: 0.8539 - sae: 1892.0439 - sse: 2199.0830 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5500 - val_mse: 0.4570 - val_pearson_correlation: 5.5968e-17 - val_r2_keras: -42.2019 - val_rmse: 1.0703 - val_sae: 436.1636 - val_sse: 606.0409 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0894 - loss: 0.2073 - mae: 0.2912 - mse: 0.1970 - pearson_correlation: -2.8153e-16 - r2_keras: -96.3600 - rmse: 0.8587 - sae: 2588.2075 - sse: 3019.9854\n","Epoch 41: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0748 - loss: 0.1984 - mae: 0.2715 - mse: 0.1755 - pearson_correlation: -1.8769e-16 - r2_keras: -79.8032 - rmse: 0.8540 - sae: 1892.0497 - sse: 2199.7900 - val_huber_loss: 0.2213 - val_loss: 0.3391 - val_mae: 0.5504 - val_mse: 0.4573 - val_pearson_correlation: 2.1505e-16 - val_r2_keras: -42.2396 - val_rmse: 1.0708 - val_sae: 436.3868 - val_sse: 606.5699 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0891 - loss: 0.2070 - mae: 0.2909 - mse: 0.1961 - pearson_correlation: -3.9717e-16 - r2_keras: -96.3934 - rmse: 0.8588 - sae: 2588.5989 - sse: 3021.0225\n","Epoch 42: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0746 - loss: 0.1981 - mae: 0.2711 - mse: 0.1748 - pearson_correlation: -2.9861e-16 - r2_keras: -79.8374 - rmse: 0.8542 - sae: 1892.3796 - sse: 2200.6218 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5504 - val_mse: 0.4572 - val_pearson_correlation: -3.2674e-16 - val_r2_keras: -42.2505 - val_rmse: 1.0709 - val_sae: 436.3819 - val_sse: 606.7230 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0888 - loss: 0.2066 - mae: 0.2901 - mse: 0.1954 - pearson_correlation: 5.2868e-17 - r2_keras: -96.4495 - rmse: 0.8591 - sae: 2588.8667 - sse: 3022.7622\n","Epoch 43: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0743 - loss: 0.1978 - mae: 0.2704 - mse: 0.1741 - pearson_correlation: 7.2846e-17 - r2_keras: -79.8716 - rmse: 0.8543 - sae: 1892.5343 - sse: 2201.7439 - val_huber_loss: 0.2211 - val_loss: 0.3389 - val_mae: 0.5501 - val_mse: 0.4570 - val_pearson_correlation: 5.5895e-17 - val_r2_keras: -42.2471 - val_rmse: 1.0709 - val_sae: 436.2811 - val_sse: 606.6747 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0885 - loss: 0.2064 - mae: 0.2894 - mse: 0.1947 - pearson_correlation: 1.9330e-16 - r2_keras: -96.4933 - rmse: 0.8593 - sae: 2588.9819 - sse: 3024.1201\n","Epoch 44: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0741 - loss: 0.1975 - mae: 0.2698 - mse: 0.1735 - pearson_correlation: 6.8733e-17 - r2_keras: -79.9062 - rmse: 0.8545 - sae: 1892.6329 - sse: 2202.7134 - val_huber_loss: 0.2213 - val_loss: 0.3391 - val_mae: 0.5507 - val_mse: 0.4574 - val_pearson_correlation: -3.1771e-16 - val_r2_keras: -42.3007 - val_rmse: 1.0716 - val_sae: 436.5651 - val_sse: 607.4265 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0882 - loss: 0.2060 - mae: 0.2888 - mse: 0.1939 - pearson_correlation: -1.3413e-16 - r2_keras: -96.5540 - rmse: 0.8595 - sae: 2589.6470 - sse: 3026.0029\n","Epoch 45: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0738 - loss: 0.1973 - mae: 0.2693 - mse: 0.1728 - pearson_correlation: -8.3781e-17 - r2_keras: -79.9458 - rmse: 0.8547 - sae: 1893.0684 - sse: 2203.9580 - val_huber_loss: 0.2211 - val_loss: 0.3389 - val_mae: 0.5503 - val_mse: 0.4571 - val_pearson_correlation: 1.5889e-16 - val_r2_keras: -42.2921 - val_rmse: 1.0715 - val_sae: 436.4442 - val_sse: 607.3065 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0879 - loss: 0.2058 - mae: 0.2881 - mse: 0.1931 - pearson_correlation: 2.9971e-16 - r2_keras: -96.6015 - rmse: 0.8597 - sae: 2589.7939 - sse: 3027.4766\n","Epoch 46: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - huber_loss: 0.0736 - loss: 0.1970 - mae: 0.2687 - mse: 0.1721 - pearson_correlation: 2.4867e-16 - r2_keras: -79.9764 - rmse: 0.8548 - sae: 1893.1508 - sse: 2204.9280 - val_huber_loss: 0.2211 - val_loss: 0.3389 - val_mae: 0.5504 - val_mse: 0.4571 - val_pearson_correlation: 9.8657e-17 - val_r2_keras: -42.3355 - val_rmse: 1.0720 - val_sae: 436.6488 - val_sse: 607.9150 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0876 - loss: 0.2055 - mae: 0.2876 - mse: 0.1923 - pearson_correlation: 2.4795e-16 - r2_keras: -96.6672 - rmse: 0.8600 - sae: 2590.3745 - sse: 3029.5139\n","Epoch 47: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - huber_loss: 0.0733 - loss: 0.1967 - mae: 0.2682 - mse: 0.1714 - pearson_correlation: 1.3524e-16 - r2_keras: -80.0267 - rmse: 0.8551 - sae: 1893.5454 - sse: 2206.3621 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5504 - val_mse: 0.4573 - val_pearson_correlation: -8.1529e-17 - val_r2_keras: -42.3200 - val_rmse: 1.0718 - val_sae: 436.4688 - val_sse: 607.6974 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0874 - loss: 0.2052 - mae: 0.2870 - mse: 0.1916 - pearson_correlation: 1.0355e-16 - r2_keras: -96.6465 - rmse: 0.8599 - sae: 2589.9023 - sse: 3028.8716\n","Epoch 48: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0731 - loss: 0.1965 - mae: 0.2677 - mse: 0.1708 - pearson_correlation: 7.0475e-18 - r2_keras: -80.0144 - rmse: 0.8550 - sae: 1893.2323 - sse: 2205.9519 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5507 - val_mse: 0.4574 - val_pearson_correlation: -1.0291e-16 - val_r2_keras: -42.3424 - val_rmse: 1.0721 - val_sae: 436.5484 - val_sse: 608.0124 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0871 - loss: 0.2049 - mae: 0.2863 - mse: 0.1910 - pearson_correlation: 1.4435e-16 - r2_keras: -96.7000 - rmse: 0.8602 - sae: 2590.1921 - sse: 3030.5315\n","Epoch 49: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0729 - loss: 0.1962 - mae: 0.2670 - mse: 0.1702 - pearson_correlation: 1.0188e-16 - r2_keras: -80.0391 - rmse: 0.8551 - sae: 1893.3820 - sse: 2206.9294 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5507 - val_mse: 0.4574 - val_pearson_correlation: -1.3283e-16 - val_r2_keras: -42.3742 - val_rmse: 1.0725 - val_sae: 436.7045 - val_sse: 608.4582 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0868 - loss: 0.2046 - mae: 0.2857 - mse: 0.1902 - pearson_correlation: 3.4909e-16 - r2_keras: -96.7630 - rmse: 0.8604 - sae: 2590.8369 - sse: 3032.4873\n","Epoch 50: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0726 - loss: 0.1960 - mae: 0.2665 - mse: 0.1695 - pearson_correlation: 2.8341e-16 - r2_keras: -80.0991 - rmse: 0.8554 - sae: 1893.8885 - sse: 2208.4443 - val_huber_loss: 0.2212 - val_loss: 0.3390 - val_mae: 0.5508 - val_mse: 0.4575 - val_pearson_correlation: -4.7114e-17 - val_r2_keras: -42.3865 - val_rmse: 1.0726 - val_sae: 436.7130 - val_sse: 608.6310 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0865 - loss: 0.2043 - mae: 0.2850 - mse: 0.1895 - pearson_correlation: 6.6803e-17 - r2_keras: -96.8049 - rmse: 0.8606 - sae: 2591.0056 - sse: 3033.7842\n","Epoch 51: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0724 - loss: 0.1957 - mae: 0.2659 - mse: 0.1689 - pearson_correlation: 5.2046e-17 - r2_keras: -80.1243 - rmse: 0.8555 - sae: 1893.9828 - sse: 2209.2769 - val_huber_loss: 0.2211 - val_loss: 0.3389 - val_mae: 0.5507 - val_mse: 0.4573 - val_pearson_correlation: 5.9929e-17 - val_r2_keras: -42.4049 - val_rmse: 1.0729 - val_sae: 436.7583 - val_sse: 608.8881 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0862 - loss: 0.2040 - mae: 0.2843 - mse: 0.1888 - pearson_correlation: -2.5149e-16 - r2_keras: -96.8713 - rmse: 0.8609 - sae: 2591.4131 - sse: 3035.8445\n","Epoch 52: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0722 - loss: 0.1954 - mae: 0.2653 - mse: 0.1683 - pearson_correlation: -1.6391e-16 - r2_keras: -80.1668 - rmse: 0.8557 - sae: 1894.2561 - sse: 2210.6304 - val_huber_loss: 0.2211 - val_loss: 0.3389 - val_mae: 0.5507 - val_mse: 0.4574 - val_pearson_correlation: -2.0111e-16 - val_r2_keras: -42.4206 - val_rmse: 1.0730 - val_sae: 436.8211 - val_sse: 609.1096 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0859 - loss: 0.2037 - mae: 0.2837 - mse: 0.1880 - pearson_correlation: -3.2723e-17 - r2_keras: -96.9245 - rmse: 0.8611 - sae: 2591.9526 - sse: 3037.4951\n","Epoch 53: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0719 - loss: 0.1952 - mae: 0.2648 - mse: 0.1676 - pearson_correlation: -3.1196e-17 - r2_keras: -80.2158 - rmse: 0.8560 - sae: 1894.6606 - sse: 2211.8889 - val_huber_loss: 0.2211 - val_loss: 0.3389 - val_mae: 0.5508 - val_mse: 0.4573 - val_pearson_correlation: -3.7214e-16 - val_r2_keras: -42.4314 - val_rmse: 1.0732 - val_sae: 436.8214 - val_sse: 609.2601 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0857 - loss: 0.2035 - mae: 0.2830 - mse: 0.1873 - pearson_correlation: -1.4500e-16 - r2_keras: -96.9637 - rmse: 0.8613 - sae: 2592.0566 - sse: 3038.7124\n","Epoch 54: val_loss did not improve from 0.33513\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0717 - loss: 0.1949 - mae: 0.2641 - mse: 0.1671 - pearson_correlation: -1.4923e-16 - r2_keras: -80.2340 - rmse: 0.8560 - sae: 1894.6990 - sse: 2212.6077 - val_huber_loss: 0.2210 - val_loss: 0.3388 - val_mae: 0.5506 - val_mse: 0.4572 - val_pearson_correlation: -1.5819e-16 - val_r2_keras: -42.4515 - val_rmse: 1.0734 - val_sae: 436.8964 - val_sse: 609.5424 - learning_rate: 1.0000e-05\n","| \u001b[39m4        \u001b[39m | \u001b[39m-0.3388  \u001b[39m | \u001b[39m0.0004215\u001b[39m | \u001b[39m25.45    \u001b[39m | \u001b[39m10.84    \u001b[39m | \u001b[39m13.33    \u001b[39m | \u001b[39m95.95    \u001b[39m | \u001b[39m48.23    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 0.8321 - loss: 1.0846 - mae: 1.2541 - mse: 3.0748 - pearson_correlation: 1.1337e-16 - r2_keras: -320.7417 - rmse: 1.5609 - sae: 4727.8628 - sse: 9980.0254\n","Epoch 1: val_loss improved from inf to 1.01836, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 643ms/step - huber_loss: 1.5449 - loss: 1.5201 - mae: 1.6879 - mse: 7.3020 - pearson_correlation: -1.7750e-16 - r2_keras: -817.9007 - rmse: 2.7768 - sae: 4103.7227 - sse: 13743.0566 - val_huber_loss: 0.7546 - val_loss: 1.0184 - val_mae: 1.2206 - val_mse: 2.0576 - val_pearson_correlation: -3.5014e-16 - val_r2_keras: -49.4196 - val_rmse: 1.1563 - val_sae: 512.1649 - val_sse: 707.2919 - learning_rate: 0.0072\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 2.1891 - loss: 2.4528 - mae: 2.6423 - mse: 10.7289 - pearson_correlation: 3.0647e-17 - r2_keras: -1230.2533 - rmse: 3.0536 - sae: 10237.8359 - sse: 38191.9375\n","Epoch 2: val_loss improved from 1.01836 to 0.64008, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 1.7762 - loss: 2.2018 - mae: 2.3748 - mse: 9.1065 - pearson_correlation: 2.9600e-17 - r2_keras: -900.2703 - rmse: 2.6691 - sae: 7217.5952 - sse: 26404.7949 - val_huber_loss: 0.3740 - val_loss: 0.6401 - val_mae: 0.7508 - val_mse: 1.0302 - val_pearson_correlation: -3.5334e-17 - val_r2_keras: -28.7197 - val_rmse: 0.8878 - val_sae: 347.9713 - val_sse: 416.9110 - learning_rate: 0.0072\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.8235 - loss: 1.0895 - mae: 1.2274 - mse: 2.4108 - pearson_correlation: -2.7585e-17 - r2_keras: -283.0467 - rmse: 1.4667 - sae: 4794.2720 - sse: 8810.7744\n","Epoch 3: val_loss improved from 0.64008 to 0.47546, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.6126 - loss: 0.9612 - mae: 1.0731 - mse: 2.0053 - pearson_correlation: 1.3702e-16 - r2_keras: -206.0922 - rmse: 1.2751 - sae: 3372.4795 - sse: 6081.7959 - val_huber_loss: 0.2096 - val_loss: 0.4755 - val_mae: 0.4542 - val_mse: 0.5454 - val_pearson_correlation: -3.2391e-16 - val_r2_keras: -25.1653 - val_rmse: 0.8330 - val_sae: 291.2608 - val_sse: 367.0494 - learning_rate: 0.0072\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.3537 - loss: 0.6196 - mae: 0.6750 - mse: 0.9012 - pearson_correlation: 8.2350e-17 - r2_keras: -165.6998 - rmse: 1.1236 - sae: 3256.8364 - sse: 5170.8184\n","Epoch 4: val_loss improved from 0.47546 to 0.43496, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.2947 - loss: 0.5836 - mae: 0.6370 - mse: 0.7931 - pearson_correlation: 1.0917e-16 - r2_keras: -124.7429 - rmse: 1.0190 - sae: 2335.6880 - sse: 3618.5842 - val_huber_loss: 0.1699 - val_loss: 0.4350 - val_mae: 0.3801 - val_mse: 0.4359 - val_pearson_correlation: -1.1356e-16 - val_r2_keras: -26.7725 - val_rmse: 0.8582 - val_sae: 297.6774 - val_sse: 389.5954 - learning_rate: 0.0072\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1812 - loss: 0.4463 - mae: 0.4225 - mse: 0.4297 - pearson_correlation: 2.5513e-16 - r2_keras: -126.1937 - rmse: 0.9814 - sae: 2711.7422 - sse: 3945.3901\n","Epoch 5: val_loss did not improve from 0.43496\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1551 - loss: 0.4303 - mae: 0.4023 - mse: 0.3856 - pearson_correlation: 1.9702e-16 - r2_keras: -100.4355 - rmse: 0.9424 - sae: 1980.3986 - sse: 2825.4441 - val_huber_loss: 0.2405 - val_loss: 0.5044 - val_mae: 0.5737 - val_mse: 0.5145 - val_pearson_correlation: 1.2363e-16 - val_r2_keras: -32.2404 - val_rmse: 0.9389 - val_sae: 400.3545 - val_sse: 466.3006 - learning_rate: 0.0072\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4239 - loss: 0.6878 - mae: 0.7861 - mse: 1.0244 - pearson_correlation: -1.7197e-17 - r2_keras: -143.0938 - rmse: 1.0446 - sae: 3449.2544 - sse: 4469.6094\n","Epoch 6: val_loss did not improve from 0.43496\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.4778 - loss: 0.7206 - mae: 0.8203 - mse: 1.1320 - pearson_correlation: 5.9791e-17 - r2_keras: -148.9336 - rmse: 1.2147 - sae: 2602.5618 - sse: 3611.6494 - val_huber_loss: 0.2445 - val_loss: 0.5083 - val_mae: 0.5858 - val_mse: 0.5442 - val_pearson_correlation: -4.0195e-17 - val_r2_keras: -37.0167 - val_rmse: 1.0041 - val_sae: 431.9415 - val_sse: 533.3023 - learning_rate: 0.0072\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3172 - loss: 0.5809 - mae: 0.7192 - mse: 0.7681 - pearson_correlation: -6.1545e-16 - r2_keras: -141.1428 - rmse: 1.0375 - sae: 3543.0640 - sse: 4409.0908\n","Epoch 7: val_loss did not improve from 0.43496\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2877 - loss: 0.5629 - mae: 0.6864 - mse: 0.7105 - pearson_correlation: -4.0761e-16 - r2_keras: -116.1587 - rmse: 1.0259 - sae: 2572.7085 - sse: 3202.1101 - val_huber_loss: 0.3031 - val_loss: 0.5661 - val_mae: 0.5963 - val_mse: 0.8094 - val_pearson_correlation: -1.1268e-17 - val_r2_keras: -33.8083 - val_rmse: 0.9608 - val_sae: 362.9577 - val_sse: 488.2942 - learning_rate: 0.0072\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1995 - loss: 0.4625 - mae: 0.4630 - mse: 0.4221 - pearson_correlation: -2.7323e-17 - r2_keras: -113.0758 - rmse: 0.9295 - sae: 2779.7310 - sse: 3538.4885\n","Epoch 8: val_loss did not improve from 0.43496\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1849 - loss: 0.4535 - mae: 0.4626 - mse: 0.3996 - pearson_correlation: -8.4258e-17 - r2_keras: -93.3915 - rmse: 0.9221 - sae: 2038.1080 - sse: 2574.1328 - val_huber_loss: 0.2185 - val_loss: 0.4804 - val_mae: 0.5337 - val_mse: 0.4888 - val_pearson_correlation: 7.1062e-17 - val_r2_keras: -34.2058 - val_rmse: 0.9662 - val_sae: 383.8630 - val_sse: 493.8705 - learning_rate: 0.0072\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1914 - loss: 0.4532 - mae: 0.4891 - mse: 0.4316 - pearson_correlation: 6.7960e-17 - r2_keras: -128.8565 - rmse: 0.9917 - sae: 2969.8179 - sse: 4027.9854\n","Epoch 9: val_loss did not improve from 0.43496\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1636 - loss: 0.4361 - mae: 0.4679 - mse: 0.3881 - pearson_correlation: -1.8098e-17 - r2_keras: -101.0764 - rmse: 0.9392 - sae: 2152.4597 - sse: 2867.2029 - val_huber_loss: 0.1825 - val_loss: 0.4429 - val_mae: 0.4670 - val_mse: 0.3736 - val_pearson_correlation: 2.1833e-16 - val_r2_keras: -47.2027 - val_rmse: 1.1306 - val_sae: 454.8598 - val_sse: 676.1928 - learning_rate: 0.0072\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2023 - loss: 0.4627 - mae: 0.4708 - mse: 0.4472 - pearson_correlation: 1.8928e-16 - r2_keras: -138.0601 - rmse: 1.0262 - sae: 2994.6812 - sse: 4313.4707\n","Epoch 10: val_loss improved from 0.43496 to 0.39379, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.1562 - loss: 0.4346 - mae: 0.4236 - mse: 0.3825 - pearson_correlation: 1.8680e-16 - r2_keras: -109.7165 - rmse: 0.9838 - sae: 2169.8105 - sse: 3086.9026 - val_huber_loss: 0.1337 - val_loss: 0.3938 - val_mae: 0.3493 - val_mse: 0.2928 - val_pearson_correlation: -9.5253e-17 - val_r2_keras: -35.3049 - val_rmse: 0.9812 - val_sae: 380.7147 - val_sse: 509.2891 - learning_rate: 0.0014\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1016 - loss: 0.3616 - mae: 0.3100 - mse: 0.2218 - pearson_correlation: 4.4503e-16 - r2_keras: -100.5452 - rmse: 0.8769 - sae: 2558.0142 - sse: 3149.8064\n","Epoch 11: val_loss did not improve from 0.39379\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0855 - loss: 0.3518 - mae: 0.2922 - mse: 0.1985 - pearson_correlation: 3.3178e-16 - r2_keras: -83.5987 - rmse: 0.8750 - sae: 1874.8102 - sse: 2298.1304 - val_huber_loss: 0.1364 - val_loss: 0.3960 - val_mae: 0.3366 - val_mse: 0.3059 - val_pearson_correlation: -2.6820e-16 - val_r2_keras: -34.6112 - val_rmse: 0.9718 - val_sae: 370.3242 - val_sse: 499.5584 - learning_rate: 0.0014\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0866 - loss: 0.3462 - mae: 0.2721 - mse: 0.1864 - pearson_correlation: -1.7309e-16 - r2_keras: -97.7636 - rmse: 0.8648 - sae: 2535.7832 - sse: 3063.5225\n","Epoch 12: val_loss did not improve from 0.39379\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0750 - loss: 0.3391 - mae: 0.2640 - mse: 0.1696 - pearson_correlation: -1.2164e-16 - r2_keras: -81.4763 - rmse: 0.8646 - sae: 1860.0649 - sse: 2237.4648 - val_huber_loss: 0.1366 - val_loss: 0.3958 - val_mae: 0.3344 - val_mse: 0.3065 - val_pearson_correlation: -5.3198e-17 - val_r2_keras: -34.7498 - val_rmse: 0.9737 - val_sae: 369.6318 - val_sse: 501.5020 - learning_rate: 0.0014\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0821 - loss: 0.3413 - mae: 0.2596 - mse: 0.1751 - pearson_correlation: -6.0359e-16 - r2_keras: -98.1930 - rmse: 0.8667 - sae: 2546.9365 - sse: 3076.8440\n","Epoch 13: val_loss improved from 0.39379 to 0.39331, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.0714 - loss: 0.3347 - mae: 0.2535 - mse: 0.1598 - pearson_correlation: -3.6885e-16 - r2_keras: -81.5560 - rmse: 0.8640 - sae: 1866.7653 - sse: 2243.9221 - val_huber_loss: 0.1346 - val_loss: 0.3933 - val_mae: 0.3300 - val_mse: 0.3003 - val_pearson_correlation: -8.4631e-17 - val_r2_keras: -34.8817 - val_rmse: 0.9755 - val_sae: 370.0062 - val_sse: 503.3525 - learning_rate: 0.0014\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0797 - loss: 0.3384 - mae: 0.2538 - mse: 0.1691 - pearson_correlation: -2.3775e-16 - r2_keras: -98.7500 - rmse: 0.8691 - sae: 2555.7373 - sse: 3094.1191\n","Epoch 14: val_loss improved from 0.39331 to 0.39194, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0693 - loss: 0.3321 - mae: 0.2478 - mse: 0.1545 - pearson_correlation: -1.8370e-16 - r2_keras: -81.7778 - rmse: 0.8643 - sae: 1871.8827 - sse: 2253.6855 - val_huber_loss: 0.1338 - val_loss: 0.3919 - val_mae: 0.3285 - val_mse: 0.2965 - val_pearson_correlation: -1.9882e-16 - val_r2_keras: -35.1635 - val_rmse: 0.9793 - val_sae: 371.5369 - val_sse: 507.3057 - learning_rate: 0.0014\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0780 - loss: 0.3361 - mae: 0.2495 - mse: 0.1649 - pearson_correlation: 1.3441e-16 - r2_keras: -99.4126 - rmse: 0.8720 - sae: 2563.1460 - sse: 3114.6724\n","Epoch 15: val_loss improved from 0.39194 to 0.39038, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0676 - loss: 0.3298 - mae: 0.2434 - mse: 0.1505 - pearson_correlation: 1.0891e-16 - r2_keras: -82.1719 - rmse: 0.8659 - sae: 1876.4706 - sse: 2266.8291 - val_huber_loss: 0.1328 - val_loss: 0.3904 - val_mae: 0.3275 - val_mse: 0.2933 - val_pearson_correlation: -3.2420e-16 - val_r2_keras: -35.1736 - val_rmse: 0.9794 - val_sae: 371.1732 - val_sse: 507.4476 - learning_rate: 0.0014\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0760 - loss: 0.3336 - mae: 0.2456 - mse: 0.1600 - pearson_correlation: 1.9251e-17 - r2_keras: -99.5443 - rmse: 0.8726 - sae: 2565.1392 - sse: 3118.7598\n","Epoch 16: val_loss improved from 0.39038 to 0.38972, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0658 - loss: 0.3274 - mae: 0.2392 - mse: 0.1460 - pearson_correlation: 3.4024e-17 - r2_keras: -82.2310 - rmse: 0.8660 - sae: 1877.3528 - sse: 2269.2163 - val_huber_loss: 0.1328 - val_loss: 0.3897 - val_mae: 0.3282 - val_mse: 0.2917 - val_pearson_correlation: 1.3497e-16 - val_r2_keras: -35.3683 - val_rmse: 0.9820 - val_sae: 372.2311 - val_sse: 510.1790 - learning_rate: 0.0014\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0745 - loss: 0.3315 - mae: 0.2428 - mse: 0.1565 - pearson_correlation: 4.1899e-16 - r2_keras: -99.9277 - rmse: 0.8743 - sae: 2569.3384 - sse: 3130.6516\n","Epoch 17: val_loss improved from 0.38972 to 0.38898, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0644 - loss: 0.3253 - mae: 0.2361 - mse: 0.1427 - pearson_correlation: 2.5448e-16 - r2_keras: -82.5006 - rmse: 0.8672 - sae: 1880.0436 - sse: 2277.3093 - val_huber_loss: 0.1327 - val_loss: 0.3890 - val_mae: 0.3286 - val_mse: 0.2912 - val_pearson_correlation: 2.1859e-16 - val_r2_keras: -35.2983 - val_rmse: 0.9811 - val_sae: 371.6262 - val_sse: 509.1966 - learning_rate: 0.0014\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0729 - loss: 0.3291 - mae: 0.2397 - mse: 0.1524 - pearson_correlation: 1.1460e-16 - r2_keras: -100.1301 - rmse: 0.8751 - sae: 2571.3477 - sse: 3136.9304\n","Epoch 18: val_loss did not improve from 0.38898\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0629 - loss: 0.3230 - mae: 0.2325 - mse: 0.1390 - pearson_correlation: 6.5399e-17 - r2_keras: -82.6847 - rmse: 0.8682 - sae: 1881.3593 - sse: 2282.0718 - val_huber_loss: 0.1349 - val_loss: 0.3903 - val_mae: 0.3316 - val_mse: 0.2950 - val_pearson_correlation: -2.4773e-16 - val_r2_keras: -35.5321 - val_rmse: 0.9843 - val_sae: 372.7109 - val_sse: 512.4756 - learning_rate: 0.0014\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0714 - loss: 0.3269 - mae: 0.2361 - mse: 0.1489 - pearson_correlation: -4.6126e-16 - r2_keras: -100.1019 - rmse: 0.8750 - sae: 2569.8298 - sse: 3136.0552\n","Epoch 19: val_loss improved from 0.38898 to 0.38855, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0616 - loss: 0.3208 - mae: 0.2288 - mse: 0.1358 - pearson_correlation: -3.3292e-16 - r2_keras: -82.8092 - rmse: 0.8694 - sae: 1880.9896 - sse: 2283.1687 - val_huber_loss: 0.1339 - val_loss: 0.3885 - val_mae: 0.3312 - val_mse: 0.2928 - val_pearson_correlation: 6.2637e-17 - val_r2_keras: -35.2224 - val_rmse: 0.9801 - val_sae: 371.2436 - val_sse: 508.1324 - learning_rate: 0.0014\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0699 - loss: 0.3246 - mae: 0.2317 - mse: 0.1458 - pearson_correlation: 2.0844e-16 - r2_keras: -100.1018 - rmse: 0.8750 - sae: 2567.6777 - sse: 3136.0508\n","Epoch 20: val_loss did not improve from 0.38855\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0604 - loss: 0.3187 - mae: 0.2246 - mse: 0.1329 - pearson_correlation: 2.1371e-16 - r2_keras: -82.7483 - rmse: 0.8689 - sae: 1878.9678 - sse: 2282.4529 - val_huber_loss: 0.1369 - val_loss: 0.3906 - val_mae: 0.3344 - val_mse: 0.2988 - val_pearson_correlation: 2.9592e-16 - val_r2_keras: -35.8473 - val_rmse: 0.9885 - val_sae: 374.1584 - val_sse: 516.8982 - learning_rate: 0.0014\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0683 - loss: 0.3221 - mae: 0.2300 - mse: 0.1417 - pearson_correlation: 2.4262e-16 - r2_keras: -101.2592 - rmse: 0.8800 - sae: 2583.2285 - sse: 3171.9536\n","Epoch 21: val_loss improved from 0.38855 to 0.38818, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0589 - loss: 0.3162 - mae: 0.2228 - mse: 0.1291 - pearson_correlation: 1.3667e-16 - r2_keras: -83.7711 - rmse: 0.8744 - sae: 1890.6910 - sse: 2309.3342 - val_huber_loss: 0.1354 - val_loss: 0.3882 - val_mae: 0.3339 - val_mse: 0.2948 - val_pearson_correlation: -1.4577e-16 - val_r2_keras: -35.3021 - val_rmse: 0.9812 - val_sae: 371.1230 - val_sse: 509.2501 - learning_rate: 0.0014\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0673 - loss: 0.3201 - mae: 0.2271 - mse: 0.1397 - pearson_correlation: 2.1763e-16 - r2_keras: -100.3860 - rmse: 0.8762 - sae: 2567.8193 - sse: 3144.8662\n","Epoch 22: val_loss did not improve from 0.38818\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0576 - loss: 0.3141 - mae: 0.2192 - mse: 0.1268 - pearson_correlation: 1.5405e-16 - r2_keras: -83.1686 - rmse: 0.8717 - sae: 1879.9098 - sse: 2291.0378 - val_huber_loss: 0.1386 - val_loss: 0.3903 - val_mae: 0.3399 - val_mse: 0.3013 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.3535 - val_rmse: 0.9818 - val_sae: 371.6951 - val_sse: 509.9714 - learning_rate: 0.0014\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0660 - loss: 0.3177 - mae: 0.2229 - mse: 0.1363 - pearson_correlation: -2.6867e-16 - r2_keras: -100.2042 - rmse: 0.8755 - sae: 2568.3765 - sse: 3139.2275\n","Epoch 23: val_loss improved from 0.38818 to 0.38547, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0564 - loss: 0.3117 - mae: 0.2152 - mse: 0.1237 - pearson_correlation: -1.8264e-16 - r2_keras: -83.3008 - rmse: 0.8734 - sae: 1881.5735 - sse: 2290.2505 - val_huber_loss: 0.1349 - val_loss: 0.3855 - val_mae: 0.3333 - val_mse: 0.2943 - val_pearson_correlation: -1.2694e-16 - val_r2_keras: -34.8774 - val_rmse: 0.9754 - val_sae: 369.1410 - val_sse: 503.2916 - learning_rate: 0.0014\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0650 - loss: 0.3156 - mae: 0.2219 - mse: 0.1342 - pearson_correlation: 2.6472e-17 - r2_keras: -100.9086 - rmse: 0.8785 - sae: 2573.7861 - sse: 3161.0781\n","Epoch 24: val_loss did not improve from 0.38547\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0556 - loss: 0.3097 - mae: 0.2141 - mse: 0.1219 - pearson_correlation: 1.7648e-17 - r2_keras: -83.1662 - rmse: 0.8701 - sae: 1882.0714 - sse: 2297.7302 - val_huber_loss: 0.1454 - val_loss: 0.3948 - val_mae: 0.3476 - val_mse: 0.3174 - val_pearson_correlation: 3.9526e-17 - val_r2_keras: -36.8255 - val_rmse: 1.0015 - val_sae: 379.7642 - val_sse: 530.6207 - learning_rate: 0.0014\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0640 - loss: 0.3133 - mae: 0.2199 - mse: 0.1314 - pearson_correlation: 3.9077e-16 - r2_keras: -104.7619 - rmse: 0.8949 - sae: 2618.1646 - sse: 3280.6011\n","Epoch 25: val_loss improved from 0.38547 to 0.37968, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.0543 - loss: 0.3073 - mae: 0.2140 - mse: 0.1189 - pearson_correlation: 2.1517e-16 - r2_keras: -86.2084 - rmse: 0.8852 - sae: 1914.5995 - sse: 2382.9651 - val_huber_loss: 0.1316 - val_loss: 0.3797 - val_mae: 0.3282 - val_mse: 0.2842 - val_pearson_correlation: -1.4683e-16 - val_r2_keras: -35.1001 - val_rmse: 0.9784 - val_sae: 369.7309 - val_sse: 506.4162 - learning_rate: 0.0014\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0629 - loss: 0.3110 - mae: 0.2241 - mse: 0.1295 - pearson_correlation: 5.3744e-16 - r2_keras: -106.5411 - rmse: 0.9024 - sae: 2638.5874 - sse: 3335.7910\n","Epoch 26: val_loss did not improve from 0.37968\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0540 - loss: 0.3054 - mae: 0.2158 - mse: 0.1178 - pearson_correlation: 3.3476e-16 - r2_keras: -86.0907 - rmse: 0.8787 - sae: 1921.7032 - sse: 2404.4631 - val_huber_loss: 0.1460 - val_loss: 0.3927 - val_mae: 0.3485 - val_mse: 0.3167 - val_pearson_correlation: 8.8682e-18 - val_r2_keras: -40.4047 - val_rmse: 1.0478 - val_sae: 399.6124 - val_sse: 580.8292 - learning_rate: 0.0014\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0644 - loss: 0.3111 - mae: 0.2161 - mse: 0.1322 - pearson_correlation: -5.2542e-16 - r2_keras: -111.2107 - rmse: 0.9218 - sae: 2699.3433 - sse: 3480.6362\n","Epoch 27: val_loss improved from 0.37968 to 0.36923, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0537 - loss: 0.3045 - mae: 0.2070 - mse: 0.1185 - pearson_correlation: -3.2535e-16 - r2_keras: -91.0188 - rmse: 0.9075 - sae: 1969.6256 - sse: 2522.3171 - val_huber_loss: 0.1240 - val_loss: 0.3692 - val_mae: 0.3160 - val_mse: 0.2649 - val_pearson_correlation: 5.4641e-18 - val_r2_keras: -34.0663 - val_rmse: 0.9643 - val_sae: 365.3885 - val_sse: 491.9143 - learning_rate: 0.0014\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0619 - loss: 0.3072 - mae: 0.2197 - mse: 0.1272 - pearson_correlation: -3.4921e-18 - r2_keras: -100.8962 - rmse: 0.8784 - sae: 2573.1543 - sse: 3160.6919\n","Epoch 28: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0545 - loss: 0.3025 - mae: 0.2167 - mse: 0.1175 - pearson_correlation: -5.4740e-17 - r2_keras: -84.9454 - rmse: 0.8854 - sae: 1888.4840 - sse: 2318.4397 - val_huber_loss: 0.2107 - val_loss: 0.4545 - val_mae: 0.4790 - val_mse: 0.4918 - val_pearson_correlation: 3.3415e-17 - val_r2_keras: -33.6778 - val_rmse: 0.9590 - val_sae: 363.7642 - val_sse: 486.4634 - learning_rate: 0.0014\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0886 - loss: 0.3324 - mae: 0.3188 - mse: 0.1816 - pearson_correlation: -1.9539e-16 - r2_keras: -87.3148 - rmse: 0.8178 - sae: 2461.4072 - sse: 2739.4155\n","Epoch 29: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0783 - loss: 0.3260 - mae: 0.3055 - mse: 0.1682 - pearson_correlation: -1.1618e-16 - r2_keras: -78.9561 - rmse: 0.8694 - sae: 1835.9271 - sse: 2073.5410 - val_huber_loss: 0.2057 - val_loss: 0.4483 - val_mae: 0.4617 - val_mse: 0.5003 - val_pearson_correlation: -2.4747e-17 - val_r2_keras: -29.3544 - val_rmse: 0.8972 - val_sae: 338.5964 - val_sse: 425.8151 - learning_rate: 0.0014\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0784 - loss: 0.3210 - mae: 0.2698 - mse: 0.1601 - pearson_correlation: 4.5141e-16 - r2_keras: -99.5774 - rmse: 0.8727 - sae: 2548.0596 - sse: 3119.7866\n","Epoch 30: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0690 - loss: 0.3151 - mae: 0.2625 - mse: 0.1480 - pearson_correlation: 2.7512e-16 - r2_keras: -80.4230 - rmse: 0.8495 - sae: 1857.8318 - sse: 2248.4338 - val_huber_loss: 0.1817 - val_loss: 0.4231 - val_mae: 0.4029 - val_mse: 0.4050 - val_pearson_correlation: -2.2878e-16 - val_r2_keras: -42.0643 - val_rmse: 1.0686 - val_sae: 408.0356 - val_sse: 604.1107 - learning_rate: 0.0014\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0918 - loss: 0.3331 - mae: 0.2952 - mse: 0.1857 - pearson_correlation: 7.6018e-18 - r2_keras: -143.1178 - rmse: 1.0447 - sae: 3132.3008 - sse: 4470.3525\n","Epoch 31: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0779 - loss: 0.3245 - mae: 0.2866 - mse: 0.1683 - pearson_correlation: -4.9587e-17 - r2_keras: -110.5254 - rmse: 0.9740 - sae: 2252.6274 - sse: 3161.4275 - val_huber_loss: 0.1466 - val_loss: 0.3867 - val_mae: 0.4107 - val_mse: 0.3010 - val_pearson_correlation: -3.6348e-17 - val_r2_keras: -44.1707 - val_rmse: 1.0945 - val_sae: 430.6856 - val_sse: 633.6593 - learning_rate: 0.0014\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0753 - loss: 0.3154 - mae: 0.2522 - mse: 0.1558 - pearson_correlation: 7.1684e-16 - r2_keras: -122.5318 - rmse: 0.9672 - sae: 2813.5938 - sse: 3831.8010\n","Epoch 32: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0635 - loss: 0.3081 - mae: 0.2486 - mse: 0.1404 - pearson_correlation: 4.9116e-16 - r2_keras: -99.1579 - rmse: 0.9428 - sae: 2049.6570 - sse: 2763.3682 - val_huber_loss: 0.1477 - val_loss: 0.3865 - val_mae: 0.3835 - val_mse: 0.3152 - val_pearson_correlation: -2.5007e-16 - val_r2_keras: -38.2494 - val_rmse: 1.0202 - val_sae: 392.4694 - val_sse: 550.5950 - learning_rate: 0.0014\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0637 - loss: 0.3025 - mae: 0.2467 - mse: 0.1299 - pearson_correlation: -1.9618e-16 - r2_keras: -97.1112 - rmse: 0.8620 - sae: 2540.3054 - sse: 3043.2861\n","Epoch 33: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0511 - loss: 0.2948 - mae: 0.2319 - mse: 0.1140 - pearson_correlation: -1.6767e-16 - r2_keras: -81.6445 - rmse: 0.8678 - sae: 1865.8971 - sse: 2231.0491 - val_huber_loss: 0.1442 - val_loss: 0.3827 - val_mae: 0.3592 - val_mse: 0.3077 - val_pearson_correlation: -3.9443e-17 - val_r2_keras: -36.8289 - val_rmse: 1.0016 - val_sae: 379.9063 - val_sse: 530.6683 - learning_rate: 2.8884e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0568 - loss: 0.2953 - mae: 0.2098 - mse: 0.1158 - pearson_correlation: 4.9957e-16 - r2_keras: -100.5549 - rmse: 0.8770 - sae: 2566.1208 - sse: 3150.1064\n","Epoch 34: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0452 - loss: 0.2883 - mae: 0.1970 - mse: 0.1012 - pearson_correlation: 3.0380e-16 - r2_keras: -83.8966 - rmse: 0.8775 - sae: 1881.8080 - sse: 2301.7498 - val_huber_loss: 0.1453 - val_loss: 0.3835 - val_mae: 0.3517 - val_mse: 0.3111 - val_pearson_correlation: -1.7054e-16 - val_r2_keras: -36.3196 - val_rmse: 0.9948 - val_sae: 374.7520 - val_sse: 523.5233 - learning_rate: 2.8884e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0549 - loss: 0.2931 - mae: 0.1998 - mse: 0.1118 - pearson_correlation: -2.1297e-16 - r2_keras: -102.2641 - rmse: 0.8843 - sae: 2581.3047 - sse: 3203.1240\n","Epoch 35: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0436 - loss: 0.2862 - mae: 0.1874 - mse: 0.0976 - pearson_correlation: -2.1049e-16 - r2_keras: -85.1052 - rmse: 0.8830 - sae: 1891.7771 - sse: 2337.9048 - val_huber_loss: 0.1469 - val_loss: 0.3848 - val_mae: 0.3495 - val_mse: 0.3157 - val_pearson_correlation: -5.5521e-17 - val_r2_keras: -36.1381 - val_rmse: 0.9924 - val_sae: 372.3406 - val_sse: 520.9771 - learning_rate: 2.8884e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0539 - loss: 0.2917 - mae: 0.1956 - mse: 0.1095 - pearson_correlation: -2.0248e-16 - r2_keras: -103.1153 - rmse: 0.8880 - sae: 2588.0676 - sse: 3229.5259\n","Epoch 36: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0426 - loss: 0.2849 - mae: 0.1832 - mse: 0.0955 - pearson_correlation: -1.4694e-16 - r2_keras: -85.7194 - rmse: 0.8858 - sae: 1896.2140 - sse: 2356.0552 - val_huber_loss: 0.1479 - val_loss: 0.3854 - val_mae: 0.3491 - val_mse: 0.3184 - val_pearson_correlation: -2.9886e-16 - val_r2_keras: -36.0369 - val_rmse: 0.9910 - val_sae: 371.0501 - val_sse: 519.5571 - learning_rate: 2.8884e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0530 - loss: 0.2905 - mae: 0.1922 - mse: 0.1076 - pearson_correlation: -5.1815e-16 - r2_keras: -103.7625 - rmse: 0.8907 - sae: 2592.7144 - sse: 3249.6018\n","Epoch 37: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0419 - loss: 0.2837 - mae: 0.1798 - mse: 0.0937 - pearson_correlation: -2.9857e-16 - r2_keras: -86.1853 - rmse: 0.8879 - sae: 1899.3512 - sse: 2369.8428 - val_huber_loss: 0.1483 - val_loss: 0.3854 - val_mae: 0.3484 - val_mse: 0.3195 - val_pearson_correlation: -1.6225e-16 - val_r2_keras: -36.0107 - val_rmse: 0.9907 - val_sae: 370.4230 - val_sse: 519.1899 - learning_rate: 2.8884e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0521 - loss: 0.2892 - mae: 0.1890 - mse: 0.1058 - pearson_correlation: 2.9788e-17 - r2_keras: -104.3892 - rmse: 0.8934 - sae: 2597.4038 - sse: 3269.0405\n","Epoch 38: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0410 - loss: 0.2824 - mae: 0.1759 - mse: 0.0919 - pearson_correlation: 6.6220e-17 - r2_keras: -86.4805 - rmse: 0.8886 - sae: 1901.7186 - sse: 2381.3635 - val_huber_loss: 0.1480 - val_loss: 0.3851 - val_mae: 0.3470 - val_mse: 0.3189 - val_pearson_correlation: 2.2278e-16 - val_r2_keras: -36.0486 - val_rmse: 0.9912 - val_sae: 370.4318 - val_sse: 519.7222 - learning_rate: 5.7768e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0519 - loss: 0.2889 - mae: 0.1882 - mse: 0.1053 - pearson_correlation: 3.3623e-16 - r2_keras: -104.6117 - rmse: 0.8943 - sae: 2599.4487 - sse: 3275.9424\n","Epoch 39: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0408 - loss: 0.2822 - mae: 0.1752 - mse: 0.0915 - pearson_correlation: 2.0870e-16 - r2_keras: -86.6343 - rmse: 0.8893 - sae: 1903.0834 - sse: 2386.0295 - val_huber_loss: 0.1479 - val_loss: 0.3849 - val_mae: 0.3463 - val_mse: 0.3185 - val_pearson_correlation: 1.5179e-17 - val_r2_keras: -36.0687 - val_rmse: 0.9915 - val_sae: 370.4284 - val_sse: 520.0034 - learning_rate: 5.7768e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0517 - loss: 0.2886 - mae: 0.1874 - mse: 0.1049 - pearson_correlation: -9.9989e-17 - r2_keras: -104.8112 - rmse: 0.8952 - sae: 2601.2229 - sse: 3282.1299\n","Epoch 40: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0406 - loss: 0.2819 - mae: 0.1744 - mse: 0.0911 - pearson_correlation: -8.8110e-17 - r2_keras: -86.7714 - rmse: 0.8899 - sae: 1904.2623 - sse: 2390.2026 - val_huber_loss: 0.1479 - val_loss: 0.3848 - val_mae: 0.3458 - val_mse: 0.3185 - val_pearson_correlation: 7.3196e-17 - val_r2_keras: -36.1341 - val_rmse: 0.9923 - val_sae: 370.6992 - val_sse: 520.9207 - learning_rate: 5.7768e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0515 - loss: 0.2883 - mae: 0.1867 - mse: 0.1045 - pearson_correlation: -5.8048e-17 - r2_keras: -104.9801 - rmse: 0.8959 - sae: 2602.6484 - sse: 3287.3691\n","Epoch 41: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0405 - loss: 0.2816 - mae: 0.1738 - mse: 0.0907 - pearson_correlation: 5.8889e-18 - r2_keras: -86.8948 - rmse: 0.8905 - sae: 1905.2271 - sse: 2393.8223 - val_huber_loss: 0.1482 - val_loss: 0.3849 - val_mae: 0.3458 - val_mse: 0.3191 - val_pearson_correlation: 6.3033e-17 - val_r2_keras: -36.1638 - val_rmse: 0.9927 - val_sae: 370.7898 - val_sse: 521.3374 - learning_rate: 5.7768e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0513 - loss: 0.2881 - mae: 0.1860 - mse: 0.1041 - pearson_correlation: -7.6153e-17 - r2_keras: -105.1324 - rmse: 0.8965 - sae: 2603.9536 - sse: 3292.0942\n","Epoch 42: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0403 - loss: 0.2814 - mae: 0.1731 - mse: 0.0904 - pearson_correlation: -6.4471e-17 - r2_keras: -87.0161 - rmse: 0.8911 - sae: 1906.1792 - sse: 2397.2034 - val_huber_loss: 0.1481 - val_loss: 0.3847 - val_mae: 0.3452 - val_mse: 0.3190 - val_pearson_correlation: -3.5340e-16 - val_r2_keras: -36.1310 - val_rmse: 0.9923 - val_sae: 370.5161 - val_sse: 520.8773 - learning_rate: 5.7768e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0511 - loss: 0.2878 - mae: 0.1854 - mse: 0.1037 - pearson_correlation: 1.2231e-16 - r2_keras: -105.2658 - rmse: 0.8971 - sae: 2605.0801 - sse: 3296.2310\n","Epoch 43: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0401 - loss: 0.2811 - mae: 0.1724 - mse: 0.0900 - pearson_correlation: 7.6394e-17 - r2_keras: -87.0775 - rmse: 0.8912 - sae: 1906.7672 - sse: 2399.6384 - val_huber_loss: 0.1481 - val_loss: 0.3847 - val_mae: 0.3451 - val_mse: 0.3189 - val_pearson_correlation: 2.6479e-16 - val_r2_keras: -36.1594 - val_rmse: 0.9927 - val_sae: 370.6707 - val_sse: 521.2764 - learning_rate: 1.1554e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0511 - loss: 0.2877 - mae: 0.1853 - mse: 0.1036 - pearson_correlation: 1.2308e-16 - r2_keras: -105.3042 - rmse: 0.8972 - sae: 2605.4226 - sse: 3297.4248\n","Epoch 44: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0401 - loss: 0.2810 - mae: 0.1722 - mse: 0.0899 - pearson_correlation: 1.2064e-16 - r2_keras: -87.1091 - rmse: 0.8914 - sae: 1907.0210 - sse: 2400.5044 - val_huber_loss: 0.1480 - val_loss: 0.3847 - val_mae: 0.3450 - val_mse: 0.3189 - val_pearson_correlation: -1.9911e-16 - val_r2_keras: -36.1749 - val_rmse: 0.9929 - val_sae: 370.7526 - val_sse: 521.4941 - learning_rate: 1.1554e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0510 - loss: 0.2877 - mae: 0.1851 - mse: 0.1035 - pearson_correlation: 1.9239e-16 - r2_keras: -105.3409 - rmse: 0.8974 - sae: 2605.7407 - sse: 3298.5603\n","Epoch 45: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0401 - loss: 0.2810 - mae: 0.1721 - mse: 0.0899 - pearson_correlation: 1.3855e-16 - r2_keras: -87.1372 - rmse: 0.8915 - sae: 1907.2471 - sse: 2401.3044 - val_huber_loss: 0.1480 - val_loss: 0.3846 - val_mae: 0.3449 - val_mse: 0.3188 - val_pearson_correlation: -2.0656e-16 - val_r2_keras: -36.1910 - val_rmse: 0.9931 - val_sae: 370.8357 - val_sse: 521.7196 - learning_rate: 1.1554e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0510 - loss: 0.2876 - mae: 0.1850 - mse: 0.1034 - pearson_correlation: 6.4019e-16 - r2_keras: -105.3769 - rmse: 0.8975 - sae: 2606.0317 - sse: 3299.6787\n","Epoch 46: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0400 - loss: 0.2809 - mae: 0.1719 - mse: 0.0898 - pearson_correlation: 4.5594e-16 - r2_keras: -87.1641 - rmse: 0.8916 - sae: 1907.4484 - sse: 2402.0837 - val_huber_loss: 0.1481 - val_loss: 0.3846 - val_mae: 0.3449 - val_mse: 0.3189 - val_pearson_correlation: -1.3346e-16 - val_r2_keras: -36.2009 - val_rmse: 0.9932 - val_sae: 370.8800 - val_sse: 521.8583 - learning_rate: 1.1554e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0509 - loss: 0.2875 - mae: 0.1848 - mse: 0.1033 - pearson_correlation: -6.3688e-16 - r2_keras: -105.4148 - rmse: 0.8977 - sae: 2606.3521 - sse: 3300.8525\n","Epoch 47: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0400 - loss: 0.2808 - mae: 0.1718 - mse: 0.0897 - pearson_correlation: -4.4258e-16 - r2_keras: -87.1928 - rmse: 0.8918 - sae: 1907.6759 - sse: 2402.9070 - val_huber_loss: 0.1481 - val_loss: 0.3846 - val_mae: 0.3448 - val_mse: 0.3189 - val_pearson_correlation: -1.2086e-16 - val_r2_keras: -36.2021 - val_rmse: 0.9932 - val_sae: 370.8760 - val_sse: 521.8755 - learning_rate: 1.1554e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0509 - loss: 0.2874 - mae: 0.1847 - mse: 0.1032 - pearson_correlation: 3.6010e-16 - r2_keras: -105.4465 - rmse: 0.8978 - sae: 2606.6025 - sse: 3301.8379\n","Epoch 48: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0399 - loss: 0.2808 - mae: 0.1716 - mse: 0.0896 - pearson_correlation: 2.2721e-16 - r2_keras: -87.2129 - rmse: 0.8919 - sae: 1907.8301 - sse: 2403.5510 - val_huber_loss: 0.1481 - val_loss: 0.3846 - val_mae: 0.3448 - val_mse: 0.3190 - val_pearson_correlation: -5.5382e-17 - val_r2_keras: -36.2094 - val_rmse: 0.9933 - val_sae: 370.9081 - val_sse: 521.9781 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0509 - loss: 0.2874 - mae: 0.1845 - mse: 0.1032 - pearson_correlation: -1.5662e-16 - r2_keras: -105.4831 - rmse: 0.8980 - sae: 2606.9167 - sse: 3302.9712\n","Epoch 49: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0399 - loss: 0.2807 - mae: 0.1715 - mse: 0.0895 - pearson_correlation: -1.6439e-16 - r2_keras: -87.2413 - rmse: 0.8920 - sae: 1908.0562 - sse: 2404.3545 - val_huber_loss: 0.1482 - val_loss: 0.3847 - val_mae: 0.3448 - val_mse: 0.3192 - val_pearson_correlation: 1.7113e-16 - val_r2_keras: -36.2182 - val_rmse: 0.9935 - val_sae: 370.9508 - val_sse: 522.1013 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0508 - loss: 0.2873 - mae: 0.1844 - mse: 0.1031 - pearson_correlation: -1.0355e-16 - r2_keras: -105.5163 - rmse: 0.8981 - sae: 2607.2139 - sse: 3304.0034\n","Epoch 50: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0399 - loss: 0.2806 - mae: 0.1713 - mse: 0.0895 - pearson_correlation: -9.3020e-17 - r2_keras: -87.2655 - rmse: 0.8921 - sae: 1908.2584 - sse: 2405.0667 - val_huber_loss: 0.1482 - val_loss: 0.3847 - val_mae: 0.3447 - val_mse: 0.3192 - val_pearson_correlation: 2.6922e-16 - val_r2_keras: -36.2239 - val_rmse: 0.9935 - val_sae: 370.9641 - val_sse: 522.1816 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0508 - loss: 0.2872 - mae: 0.1842 - mse: 0.1030 - pearson_correlation: 6.0405e-18 - r2_keras: -105.5446 - rmse: 0.8983 - sae: 2607.4087 - sse: 3304.8792\n","Epoch 51: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0398 - loss: 0.2806 - mae: 0.1712 - mse: 0.0894 - pearson_correlation: 3.3152e-17 - r2_keras: -87.2865 - rmse: 0.8922 - sae: 1908.3895 - sse: 2405.6753 - val_huber_loss: 0.1482 - val_loss: 0.3847 - val_mae: 0.3447 - val_mse: 0.3193 - val_pearson_correlation: -7.0441e-17 - val_r2_keras: -36.2277 - val_rmse: 0.9936 - val_sae: 370.9798 - val_sse: 522.2338 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0507 - loss: 0.2872 - mae: 0.1841 - mse: 0.1029 - pearson_correlation: -4.1554e-16 - r2_keras: -105.5769 - rmse: 0.8984 - sae: 2607.6914 - sse: 3305.8806\n","Epoch 52: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0398 - loss: 0.2805 - mae: 0.1710 - mse: 0.0893 - pearson_correlation: -3.2414e-16 - r2_keras: -87.3090 - rmse: 0.8923 - sae: 1908.5751 - sse: 2406.3545 - val_huber_loss: 0.1483 - val_loss: 0.3847 - val_mae: 0.3448 - val_mse: 0.3195 - val_pearson_correlation: 7.7971e-17 - val_r2_keras: -36.2338 - val_rmse: 0.9937 - val_sae: 371.0012 - val_sse: 522.3193 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0507 - loss: 0.2871 - mae: 0.1839 - mse: 0.1028 - pearson_correlation: -6.2112e-16 - r2_keras: -105.6137 - rmse: 0.8985 - sae: 2608.0039 - sse: 3307.0242\n","Epoch 53: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0398 - loss: 0.2805 - mae: 0.1709 - mse: 0.0892 - pearson_correlation: -3.6698e-16 - r2_keras: -87.3369 - rmse: 0.8924 - sae: 1908.7960 - sse: 2407.1555 - val_huber_loss: 0.1484 - val_loss: 0.3847 - val_mae: 0.3447 - val_mse: 0.3196 - val_pearson_correlation: 3.2447e-16 - val_r2_keras: -36.2327 - val_rmse: 0.9937 - val_sae: 370.9803 - val_sse: 522.3045 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0506 - loss: 0.2870 - mae: 0.1838 - mse: 0.1027 - pearson_correlation: -5.5920e-16 - r2_keras: -105.6426 - rmse: 0.8987 - sae: 2608.2168 - sse: 3307.9197\n","Epoch 54: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0397 - loss: 0.2804 - mae: 0.1707 - mse: 0.0891 - pearson_correlation: -3.9164e-16 - r2_keras: -87.3557 - rmse: 0.8925 - sae: 1908.9252 - sse: 2407.7476 - val_huber_loss: 0.1483 - val_loss: 0.3847 - val_mae: 0.3446 - val_mse: 0.3195 - val_pearson_correlation: -1.7866e-16 - val_r2_keras: -36.2210 - val_rmse: 0.9935 - val_sae: 370.9099 - val_sse: 522.1404 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0506 - loss: 0.2870 - mae: 0.1836 - mse: 0.1026 - pearson_correlation: -4.1150e-16 - r2_keras: -105.6738 - rmse: 0.8988 - sae: 2608.4468 - sse: 3308.8867\n","Epoch 55: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0397 - loss: 0.2803 - mae: 0.1706 - mse: 0.0890 - pearson_correlation: -3.0774e-16 - r2_keras: -87.3749 - rmse: 0.8926 - sae: 1909.0671 - sse: 2408.3738 - val_huber_loss: 0.1484 - val_loss: 0.3848 - val_mae: 0.3447 - val_mse: 0.3197 - val_pearson_correlation: 6.7917e-17 - val_r2_keras: -36.2310 - val_rmse: 0.9936 - val_sae: 370.9588 - val_sse: 522.2806 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0506 - loss: 0.2869 - mae: 0.1835 - mse: 0.1025 - pearson_correlation: 1.4880e-16 - r2_keras: -105.7132 - rmse: 0.8990 - sae: 2608.7896 - sse: 3310.1094\n","Epoch 56: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0396 - loss: 0.2803 - mae: 0.1704 - mse: 0.0890 - pearson_correlation: 1.0262e-16 - r2_keras: -87.4045 - rmse: 0.8927 - sae: 1909.3052 - sse: 2409.2283 - val_huber_loss: 0.1485 - val_loss: 0.3848 - val_mae: 0.3447 - val_mse: 0.3200 - val_pearson_correlation: -3.2443e-16 - val_r2_keras: -36.2364 - val_rmse: 0.9937 - val_sae: 370.9723 - val_sse: 522.3568 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0505 - loss: 0.2868 - mae: 0.1833 - mse: 0.1024 - pearson_correlation: -1.3916e-16 - r2_keras: -105.7428 - rmse: 0.8991 - sae: 2609.0261 - sse: 3311.0278\n","Epoch 57: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0396 - loss: 0.2802 - mae: 0.1702 - mse: 0.0889 - pearson_correlation: -1.1845e-16 - r2_keras: -87.4275 - rmse: 0.8928 - sae: 1909.4720 - sse: 2409.8784 - val_huber_loss: 0.1485 - val_loss: 0.3848 - val_mae: 0.3448 - val_mse: 0.3201 - val_pearson_correlation: 2.6650e-16 - val_r2_keras: -36.2453 - val_rmse: 0.9938 - val_sae: 371.0122 - val_sse: 522.4811 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0505 - loss: 0.2868 - mae: 0.1832 - mse: 0.1024 - pearson_correlation: 2.9546e-16 - r2_keras: -105.7751 - rmse: 0.8992 - sae: 2609.2349 - sse: 3312.0312\n","Epoch 58: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0396 - loss: 0.2801 - mae: 0.1701 - mse: 0.0888 - pearson_correlation: 2.4748e-16 - r2_keras: -87.4499 - rmse: 0.8929 - sae: 1909.6038 - sse: 2410.5576 - val_huber_loss: 0.1485 - val_loss: 0.3848 - val_mae: 0.3447 - val_mse: 0.3200 - val_pearson_correlation: 9.3100e-17 - val_r2_keras: -36.2226 - val_rmse: 0.9935 - val_sae: 370.8830 - val_sse: 522.1628 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0504 - loss: 0.2867 - mae: 0.1830 - mse: 0.1023 - pearson_correlation: -3.5746e-16 - r2_keras: -105.8109 - rmse: 0.8994 - sae: 2609.5376 - sse: 3313.1411\n","Epoch 59: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0395 - loss: 0.2801 - mae: 0.1699 - mse: 0.0887 - pearson_correlation: -1.5868e-16 - r2_keras: -87.4707 - rmse: 0.8930 - sae: 1909.7881 - sse: 2411.2612 - val_huber_loss: 0.1486 - val_loss: 0.3849 - val_mae: 0.3448 - val_mse: 0.3203 - val_pearson_correlation: 2.6911e-16 - val_r2_keras: -36.2361 - val_rmse: 0.9937 - val_sae: 370.9445 - val_sse: 522.3525 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0504 - loss: 0.2866 - mae: 0.1828 - mse: 0.1022 - pearson_correlation: 1.9042e-16 - r2_keras: -105.8470 - rmse: 0.8995 - sae: 2609.8550 - sse: 3314.2603\n","Epoch 60: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0395 - loss: 0.2800 - mae: 0.1698 - mse: 0.0886 - pearson_correlation: 1.9629e-16 - r2_keras: -87.4990 - rmse: 0.8931 - sae: 1910.0126 - sse: 2412.0569 - val_huber_loss: 0.1486 - val_loss: 0.3848 - val_mae: 0.3447 - val_mse: 0.3203 - val_pearson_correlation: 3.9006e-16 - val_r2_keras: -36.2196 - val_rmse: 0.9935 - val_sae: 370.8435 - val_sse: 522.1205 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0503 - loss: 0.2865 - mae: 0.1827 - mse: 0.1021 - pearson_correlation: 7.0310e-16 - r2_keras: -105.8852 - rmse: 0.8997 - sae: 2610.1658 - sse: 3315.4443\n","Epoch 61: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0395 - loss: 0.2799 - mae: 0.1696 - mse: 0.0886 - pearson_correlation: 4.4390e-16 - r2_keras: -87.5234 - rmse: 0.8932 - sae: 1910.2130 - sse: 2412.8342 - val_huber_loss: 0.1487 - val_loss: 0.3849 - val_mae: 0.3448 - val_mse: 0.3204 - val_pearson_correlation: -3.7721e-17 - val_r2_keras: -36.2395 - val_rmse: 0.9937 - val_sae: 370.9526 - val_sse: 522.4001 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0503 - loss: 0.2865 - mae: 0.1825 - mse: 0.1020 - pearson_correlation: -2.7528e-16 - r2_keras: -105.9183 - rmse: 0.8998 - sae: 2610.4336 - sse: 3316.4707\n","Epoch 62: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0394 - loss: 0.2799 - mae: 0.1694 - mse: 0.0885 - pearson_correlation: -2.0407e-16 - r2_keras: -87.5457 - rmse: 0.8933 - sae: 1910.3832 - sse: 2413.5215 - val_huber_loss: 0.1488 - val_loss: 0.3849 - val_mae: 0.3447 - val_mse: 0.3206 - val_pearson_correlation: 1.0563e-16 - val_r2_keras: -36.2367 - val_rmse: 0.9937 - val_sae: 370.9116 - val_sse: 522.3607 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0503 - loss: 0.2864 - mae: 0.1824 - mse: 0.1019 - pearson_correlation: -7.6760e-16 - r2_keras: -105.9501 - rmse: 0.9000 - sae: 2610.6479 - sse: 3317.4595\n","Epoch 63: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0394 - loss: 0.2798 - mae: 0.1693 - mse: 0.0884 - pearson_correlation: -4.4497e-16 - r2_keras: -87.5706 - rmse: 0.8935 - sae: 1910.5336 - sse: 2414.2231 - val_huber_loss: 0.1488 - val_loss: 0.3849 - val_mae: 0.3447 - val_mse: 0.3206 - val_pearson_correlation: -3.6999e-16 - val_r2_keras: -36.2148 - val_rmse: 0.9934 - val_sae: 370.7816 - val_sse: 522.0535 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0502 - loss: 0.2863 - mae: 0.1822 - mse: 0.1018 - pearson_correlation: -1.2729e-16 - r2_keras: -105.9855 - rmse: 0.9001 - sae: 2610.9397 - sse: 3318.5554\n","Epoch 64: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0394 - loss: 0.2797 - mae: 0.1691 - mse: 0.0883 - pearson_correlation: -8.3147e-17 - r2_keras: -87.5901 - rmse: 0.8935 - sae: 1910.7081 - sse: 2414.9070 - val_huber_loss: 0.1488 - val_loss: 0.3849 - val_mae: 0.3447 - val_mse: 0.3207 - val_pearson_correlation: 7.0170e-16 - val_r2_keras: -36.2356 - val_rmse: 0.9937 - val_sae: 370.8970 - val_sse: 522.3455 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0502 - loss: 0.2863 - mae: 0.1821 - mse: 0.1018 - pearson_correlation: -2.5991e-16 - r2_keras: -106.0293 - rmse: 0.9003 - sae: 2611.3247 - sse: 3319.9138\n","Epoch 65: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0393 - loss: 0.2797 - mae: 0.1690 - mse: 0.0882 - pearson_correlation: -2.6399e-16 - r2_keras: -87.6237 - rmse: 0.8937 - sae: 1910.9771 - sse: 2415.8640 - val_huber_loss: 0.1488 - val_loss: 0.3849 - val_mae: 0.3447 - val_mse: 0.3208 - val_pearson_correlation: 2.5159e-16 - val_r2_keras: -36.2268 - val_rmse: 0.9936 - val_sae: 370.8322 - val_sse: 522.2214 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0501 - loss: 0.2862 - mae: 0.1819 - mse: 0.1017 - pearson_correlation: 3.3978e-16 - r2_keras: -106.0596 - rmse: 0.9004 - sae: 2611.5801 - sse: 3320.8564\n","Epoch 66: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0393 - loss: 0.2796 - mae: 0.1688 - mse: 0.0882 - pearson_correlation: 2.3251e-16 - r2_keras: -87.6439 - rmse: 0.8938 - sae: 1911.1381 - sse: 2416.4917 - val_huber_loss: 0.1490 - val_loss: 0.3850 - val_mae: 0.3448 - val_mse: 0.3211 - val_pearson_correlation: 2.5150e-18 - val_r2_keras: -36.2370 - val_rmse: 0.9937 - val_sae: 370.8767 - val_sse: 522.3648 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0501 - loss: 0.2861 - mae: 0.1818 - mse: 0.1016 - pearson_correlation: -6.3448e-16 - r2_keras: -106.1033 - rmse: 0.9006 - sae: 2611.9780 - sse: 3322.2119\n","Epoch 67: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0392 - loss: 0.2795 - mae: 0.1686 - mse: 0.0881 - pearson_correlation: -3.9902e-16 - r2_keras: -87.6746 - rmse: 0.8939 - sae: 1911.4095 - sse: 2417.4133 - val_huber_loss: 0.1490 - val_loss: 0.3850 - val_mae: 0.3448 - val_mse: 0.3211 - val_pearson_correlation: 7.7987e-17 - val_r2_keras: -36.2284 - val_rmse: 0.9936 - val_sae: 370.8105 - val_sse: 522.2444 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0501 - loss: 0.2861 - mae: 0.1816 - mse: 0.1015 - pearson_correlation: 3.7959e-16 - r2_keras: -106.1295 - rmse: 0.9007 - sae: 2612.1089 - sse: 3323.0227\n","Epoch 68: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0392 - loss: 0.2795 - mae: 0.1685 - mse: 0.0880 - pearson_correlation: 1.8203e-16 - r2_keras: -87.6921 - rmse: 0.8940 - sae: 1911.4869 - sse: 2417.9553 - val_huber_loss: 0.1490 - val_loss: 0.3850 - val_mae: 0.3447 - val_mse: 0.3212 - val_pearson_correlation: 2.9177e-16 - val_r2_keras: -36.2342 - val_rmse: 0.9937 - val_sae: 370.8343 - val_sse: 522.3250 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0500 - loss: 0.2860 - mae: 0.1814 - mse: 0.1014 - pearson_correlation: 1.7907e-16 - r2_keras: -106.1738 - rmse: 0.9009 - sae: 2612.5146 - sse: 3324.3977\n","Epoch 69: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0392 - loss: 0.2794 - mae: 0.1683 - mse: 0.0879 - pearson_correlation: 1.9467e-16 - r2_keras: -87.7249 - rmse: 0.8941 - sae: 1911.7670 - sse: 2418.9089 - val_huber_loss: 0.1490 - val_loss: 0.3850 - val_mae: 0.3447 - val_mse: 0.3213 - val_pearson_correlation: 2.9440e-16 - val_r2_keras: -36.2230 - val_rmse: 0.9935 - val_sae: 370.7587 - val_sse: 522.1677 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0500 - loss: 0.2859 - mae: 0.1813 - mse: 0.1013 - pearson_correlation: -2.2721e-16 - r2_keras: -106.2097 - rmse: 0.9011 - sae: 2612.8115 - sse: 3325.5095\n","Epoch 70: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0391 - loss: 0.2793 - mae: 0.1681 - mse: 0.0878 - pearson_correlation: -1.2923e-16 - r2_keras: -87.7458 - rmse: 0.8942 - sae: 1911.9448 - sse: 2419.6157 - val_huber_loss: 0.1491 - val_loss: 0.3850 - val_mae: 0.3448 - val_mse: 0.3215 - val_pearson_correlation: 2.1127e-16 - val_r2_keras: -36.2356 - val_rmse: 0.9937 - val_sae: 370.8225 - val_sse: 522.3450 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0499 - loss: 0.2859 - mae: 0.1811 - mse: 0.1012 - pearson_correlation: -6.4811e-16 - r2_keras: -106.2487 - rmse: 0.9012 - sae: 2613.1338 - sse: 3326.7192\n","Epoch 71: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0391 - loss: 0.2792 - mae: 0.1680 - mse: 0.0878 - pearson_correlation: -4.5945e-16 - r2_keras: -87.7778 - rmse: 0.8944 - sae: 1912.1893 - sse: 2420.4919 - val_huber_loss: 0.1491 - val_loss: 0.3849 - val_mae: 0.3446 - val_mse: 0.3213 - val_pearson_correlation: -3.6988e-16 - val_r2_keras: -36.2237 - val_rmse: 0.9935 - val_sae: 370.7498 - val_sse: 522.1776 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0499 - loss: 0.2858 - mae: 0.1810 - mse: 0.1012 - pearson_correlation: 1.0889e-18 - r2_keras: -106.2767 - rmse: 0.9013 - sae: 2613.3723 - sse: 3327.5891\n","Epoch 72: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0391 - loss: 0.2792 - mae: 0.1678 - mse: 0.0877 - pearson_correlation: -6.9755e-18 - r2_keras: -87.7916 - rmse: 0.8944 - sae: 1912.3108 - sse: 2421.0151 - val_huber_loss: 0.1492 - val_loss: 0.3850 - val_mae: 0.3447 - val_mse: 0.3217 - val_pearson_correlation: -4.8805e-16 - val_r2_keras: -36.2285 - val_rmse: 0.9936 - val_sae: 370.7645 - val_sse: 522.2449 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0499 - loss: 0.2857 - mae: 0.1808 - mse: 0.1011 - pearson_correlation: 1.6978e-16 - r2_keras: -106.3224 - rmse: 0.9015 - sae: 2613.7869 - sse: 3329.0078\n","Epoch 73: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0390 - loss: 0.2791 - mae: 0.1677 - mse: 0.0876 - pearson_correlation: 1.2688e-16 - r2_keras: -87.8234 - rmse: 0.8945 - sae: 1912.5922 - sse: 2421.9768 - val_huber_loss: 0.1493 - val_loss: 0.3851 - val_mae: 0.3448 - val_mse: 0.3218 - val_pearson_correlation: -2.9687e-16 - val_r2_keras: -36.2276 - val_rmse: 0.9936 - val_sae: 370.7489 - val_sse: 522.2324 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0498 - loss: 0.2856 - mae: 0.1807 - mse: 0.1010 - pearson_correlation: 3.8276e-16 - r2_keras: -106.3357 - rmse: 0.9016 - sae: 2613.8254 - sse: 3329.4177\n","Epoch 74: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0390 - loss: 0.2790 - mae: 0.1675 - mse: 0.0875 - pearson_correlation: 2.8597e-16 - r2_keras: -87.8351 - rmse: 0.8946 - sae: 1912.6237 - sse: 2422.2827 - val_huber_loss: 0.1493 - val_loss: 0.3851 - val_mae: 0.3448 - val_mse: 0.3220 - val_pearson_correlation: -6.5427e-17 - val_r2_keras: -36.2210 - val_rmse: 0.9935 - val_sae: 370.7063 - val_sse: 522.1407 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0498 - loss: 0.2856 - mae: 0.1805 - mse: 0.1009 - pearson_correlation: 1.0524e-16 - r2_keras: -106.3711 - rmse: 0.9017 - sae: 2614.1514 - sse: 3330.5173\n","Epoch 75: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0390 - loss: 0.2790 - mae: 0.1674 - mse: 0.0875 - pearson_correlation: 3.8504e-17 - r2_keras: -87.8586 - rmse: 0.8947 - sae: 1912.8365 - sse: 2423.0149 - val_huber_loss: 0.1494 - val_loss: 0.3851 - val_mae: 0.3448 - val_mse: 0.3221 - val_pearson_correlation: 1.7364e-16 - val_r2_keras: -36.2190 - val_rmse: 0.9935 - val_sae: 370.6897 - val_sse: 522.1119 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0498 - loss: 0.2855 - mae: 0.1804 - mse: 0.1008 - pearson_correlation: -5.4099e-17 - r2_keras: -106.3947 - rmse: 0.9018 - sae: 2614.3594 - sse: 3331.2493\n","Epoch 76: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0389 - loss: 0.2789 - mae: 0.1673 - mse: 0.0874 - pearson_correlation: -1.1252e-17 - r2_keras: -87.8719 - rmse: 0.8947 - sae: 1912.9526 - sse: 2423.4739 - val_huber_loss: 0.1494 - val_loss: 0.3851 - val_mae: 0.3449 - val_mse: 0.3222 - val_pearson_correlation: 1.1829e-16 - val_r2_keras: -36.2160 - val_rmse: 0.9934 - val_sae: 370.6616 - val_sse: 522.0704 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0497 - loss: 0.2854 - mae: 0.1803 - mse: 0.1008 - pearson_correlation: -2.2854e-16 - r2_keras: -106.4276 - rmse: 0.9020 - sae: 2614.6140 - sse: 3332.2695\n","Epoch 77: val_loss did not improve from 0.36923\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0389 - loss: 0.2788 - mae: 0.1671 - mse: 0.0873 - pearson_correlation: -1.3354e-16 - r2_keras: -87.8968 - rmse: 0.8949 - sae: 1913.1359 - sse: 2424.1890 - val_huber_loss: 0.1495 - val_loss: 0.3852 - val_mae: 0.3449 - val_mse: 0.3224 - val_pearson_correlation: 2.7687e-16 - val_r2_keras: -36.2141 - val_rmse: 0.9934 - val_sae: 370.6500 - val_sse: 522.0441 - learning_rate: 1.0000e-05\n","| \u001b[39m5        \u001b[39m | \u001b[39m-0.3852  \u001b[39m | \u001b[39m0.007221 \u001b[39m | \u001b[39m79.18    \u001b[39m | \u001b[39m41.94    \u001b[39m | \u001b[39m43.28    \u001b[39m | \u001b[39m97.4     \u001b[39m | \u001b[39m86.71    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 1.5489 - loss: 1.7069 - mae: 2.0148 - mse: 5.5041 - pearson_correlation: 1.0157e-16 - r2_keras: -551.5088 - rmse: 2.0455 - sae: 6928.8887 - sse: 17138.1309\n","Epoch 1: val_loss improved from inf to 0.40446, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 675ms/step - huber_loss: 1.1972 - loss: 1.4929 - mae: 1.7745 - mse: 4.6246 - pearson_correlation: 1.3770e-16 - r2_keras: -394.1633 - rmse: 1.7294 - sae: 4843.3652 - sse: 11740.0693 - val_huber_loss: 0.2463 - val_loss: 0.4045 - val_mae: 0.6063 - val_mse: 0.5928 - val_pearson_correlation: -2.6080e-16 - val_r2_keras: -22.2486 - val_rmse: 0.7852 - val_sae: 326.7879 - val_sse: 326.1334 - learning_rate: 0.0017\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2532 - loss: 0.4114 - mae: 0.5721 - mse: 0.6031 - pearson_correlation: -5.7847e-17 - r2_keras: -121.0131 - rmse: 0.9612 - sae: 3080.8491 - sse: 3784.6951\n","Epoch 2: val_loss improved from 0.40446 to 0.40324, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.2428 - loss: 0.4051 - mae: 0.5606 - mse: 0.5820 - pearson_correlation: 2.2019e-18 - r2_keras: -100.5464 - rmse: 0.9583 - sae: 2244.2900 - sse: 2760.1270 - val_huber_loss: 0.2451 - val_loss: 0.4032 - val_mae: 0.6017 - val_mse: 0.5954 - val_pearson_correlation: -5.8495e-18 - val_r2_keras: -22.1955 - val_rmse: 0.7843 - val_sae: 323.8676 - val_sse: 325.3888 - learning_rate: 0.0017\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2640 - loss: 0.4221 - mae: 0.5736 - mse: 0.6683 - pearson_correlation: 5.7395e-17 - r2_keras: -101.5710 - rmse: 0.8813 - sae: 2791.3206 - sse: 3181.6255\n","Epoch 3: val_loss improved from 0.40324 to 0.38984, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - huber_loss: 0.2175 - loss: 0.3939 - mae: 0.5393 - mse: 0.5837 - pearson_correlation: -5.3987e-17 - r2_keras: -85.2933 - rmse: 0.8865 - sae: 2033.6259 - sse: 2331.1990 - val_huber_loss: 0.2318 - val_loss: 0.3898 - val_mae: 0.5823 - val_mse: 0.5637 - val_pearson_correlation: 2.0041e-16 - val_r2_keras: -22.3287 - val_rmse: 0.7865 - val_sae: 322.9835 - val_sse: 327.2580 - learning_rate: 0.0017\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1254 - loss: 0.2835 - mae: 0.3485 - mse: 0.2936 - pearson_correlation: 1.5368e-16 - r2_keras: -90.0222 - rmse: 0.8302 - sae: 2462.4453 - sse: 2823.3936\n","Epoch 4: val_loss improved from 0.38984 to 0.37638, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.1199 - loss: 0.2801 - mae: 0.3489 - mse: 0.2786 - pearson_correlation: 9.7188e-17 - r2_keras: -72.4032 - rmse: 0.8054 - sae: 1794.5946 - sse: 2031.4888 - val_huber_loss: 0.2185 - val_loss: 0.3764 - val_mae: 0.5666 - val_mse: 0.5229 - val_pearson_correlation: 1.8963e-16 - val_r2_keras: -22.8223 - val_rmse: 0.7948 - val_sae: 329.9444 - val_sse: 334.1820 - learning_rate: 0.0017\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1381 - loss: 0.2960 - mae: 0.3435 - mse: 0.3187 - pearson_correlation: 4.7727e-16 - r2_keras: -119.2530 - rmse: 0.9543 - sae: 2670.2468 - sse: 3730.0981\n","Epoch 5: val_loss improved from 0.37638 to 0.36994, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.1165 - loss: 0.2828 - mae: 0.3303 - mse: 0.2841 - pearson_correlation: 3.1933e-16 - r2_keras: -92.9028 - rmse: 0.8979 - sae: 1936.9410 - sse: 2647.8335 - val_huber_loss: 0.2122 - val_loss: 0.3699 - val_mae: 0.5635 - val_mse: 0.4986 - val_pearson_correlation: -1.5285e-16 - val_r2_keras: -23.2962 - val_rmse: 0.8027 - val_sae: 333.8127 - val_sse: 340.8301 - learning_rate: 0.0017\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1146 - loss: 0.2723 - mae: 0.3552 - mse: 0.2519 - pearson_correlation: -4.5503e-16 - r2_keras: -93.7606 - rmse: 0.8471 - sae: 2537.7651 - sse: 2939.3555\n","Epoch 6: val_loss improved from 0.36994 to 0.36056, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1003 - loss: 0.2636 - mae: 0.3364 - mse: 0.2304 - pearson_correlation: -3.1170e-16 - r2_keras: -78.3147 - rmse: 0.8485 - sae: 1856.8595 - sse: 2148.9045 - val_huber_loss: 0.2030 - val_loss: 0.3606 - val_mae: 0.5511 - val_mse: 0.4636 - val_pearson_correlation: 3.7149e-16 - val_r2_keras: -24.8174 - val_rmse: 0.8274 - val_sae: 344.5926 - val_sse: 362.1690 - learning_rate: 0.0017\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1033 - loss: 0.2608 - mae: 0.3224 - mse: 0.2251 - pearson_correlation: 1.9527e-17 - r2_keras: -85.7206 - rmse: 0.8104 - sae: 2413.5698 - sse: 2689.9636\n","Epoch 7: val_loss improved from 0.36056 to 0.33988, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0914 - loss: 0.2536 - mae: 0.3070 - mse: 0.2069 - pearson_correlation: 2.4909e-17 - r2_keras: -72.1119 - rmse: 0.8165 - sae: 1772.0856 - sse: 1972.7574 - val_huber_loss: 0.1825 - val_loss: 0.3399 - val_mae: 0.5163 - val_mse: 0.4164 - val_pearson_correlation: 2.5910e-16 - val_r2_keras: -24.9693 - val_rmse: 0.8299 - val_sae: 342.5893 - val_sse: 364.2996 - learning_rate: 0.0017\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0907 - loss: 0.2481 - mae: 0.2891 - mse: 0.1991 - pearson_correlation: -5.2104e-18 - r2_keras: -101.2390 - rmse: 0.8799 - sae: 2553.1240 - sse: 3171.3252\n","Epoch 8: val_loss improved from 0.33988 to 0.30261, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - huber_loss: 0.0802 - loss: 0.2416 - mae: 0.2809 - mse: 0.1830 - pearson_correlation: -4.7802e-17 - r2_keras: -81.2686 - rmse: 0.8519 - sae: 1858.4204 - sse: 2279.7195 - val_huber_loss: 0.1454 - val_loss: 0.3026 - val_mae: 0.4387 - val_mse: 0.3115 - val_pearson_correlation: -2.1033e-16 - val_r2_keras: -28.9972 - val_rmse: 0.8919 - val_sae: 361.2023 - val_sse: 420.8039 - learning_rate: 0.0017\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0897 - loss: 0.2469 - mae: 0.2673 - mse: 0.1997 - pearson_correlation: 6.7544e-16 - r2_keras: -106.2629 - rmse: 0.9013 - sae: 2580.2146 - sse: 3327.1606\n","Epoch 9: val_loss did not improve from 0.30261\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0774 - loss: 0.2394 - mae: 0.2573 - mse: 0.1806 - pearson_correlation: 4.6004e-16 - r2_keras: -86.0068 - rmse: 0.8789 - sae: 1882.4830 - sse: 2399.9021 - val_huber_loss: 0.1469 - val_loss: 0.3039 - val_mae: 0.4301 - val_mse: 0.3182 - val_pearson_correlation: 2.5839e-16 - val_r2_keras: -29.3336 - val_rmse: 0.8969 - val_sae: 359.4264 - val_sse: 425.5233 - learning_rate: 0.0017\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0827 - loss: 0.2397 - mae: 0.2645 - mse: 0.1775 - pearson_correlation: 2.0598e-16 - r2_keras: -100.8674 - rmse: 0.8783 - sae: 2572.5896 - sse: 3159.7988\n","Epoch 10: val_loss improved from 0.30261 to 0.26765, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0713 - loss: 0.2327 - mae: 0.2598 - mse: 0.1612 - pearson_correlation: 1.3322e-16 - r2_keras: -84.9531 - rmse: 0.8855 - sae: 1896.3549 - sse: 2318.1599 - val_huber_loss: 0.1109 - val_loss: 0.2677 - val_mae: 0.3606 - val_mse: 0.2318 - val_pearson_correlation: -1.8110e-16 - val_r2_keras: -29.4269 - val_rmse: 0.8983 - val_sae: 340.6044 - val_sse: 426.8312 - learning_rate: 0.0017\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1259 - loss: 0.2827 - mae: 0.3438 - mse: 0.2959 - pearson_correlation: -3.7883e-16 - r2_keras: -110.4809 - rmse: 0.9188 - sae: 2729.3401 - sse: 3457.9990\n","Epoch 11: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1044 - loss: 0.2696 - mae: 0.3217 - mse: 0.2609 - pearson_correlation: -2.4227e-16 - r2_keras: -88.2017 - rmse: 0.8850 - sae: 1979.7886 - sse: 2479.8882 - val_huber_loss: 0.1349 - val_loss: 0.2914 - val_mae: 0.3715 - val_mse: 0.2990 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.3843 - val_rmse: 0.9409 - val_sae: 359.7628 - val_sse: 468.3191 - learning_rate: 0.0017\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0888 - loss: 0.2454 - mae: 0.2911 - mse: 0.1910 - pearson_correlation: -2.0167e-16 - r2_keras: -93.2866 - rmse: 0.8450 - sae: 2511.2932 - sse: 2924.6528\n","Epoch 12: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0800 - loss: 0.2400 - mae: 0.2790 - mse: 0.1775 - pearson_correlation: -1.0866e-16 - r2_keras: -79.6265 - rmse: 0.8610 - sae: 1847.1520 - sse: 2158.1968 - val_huber_loss: 0.1228 - val_loss: 0.2791 - val_mae: 0.3759 - val_mse: 0.2880 - val_pearson_correlation: -6.1765e-17 - val_r2_keras: -26.6263 - val_rmse: 0.8559 - val_sae: 327.8500 - val_sse: 387.5442 - learning_rate: 0.0017\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0871 - loss: 0.2434 - mae: 0.2822 - mse: 0.1822 - pearson_correlation: 1.8989e-16 - r2_keras: -92.1982 - rmse: 0.8401 - sae: 2487.6699 - sse: 2890.8921\n","Epoch 13: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0833 - loss: 0.2411 - mae: 0.2865 - mse: 0.1760 - pearson_correlation: 1.0737e-16 - r2_keras: -79.5605 - rmse: 0.8632 - sae: 1833.3428 - sse: 2143.4270 - val_huber_loss: 0.1706 - val_loss: 0.3266 - val_mae: 0.4652 - val_mse: 0.3846 - val_pearson_correlation: -1.3144e-16 - val_r2_keras: -35.5798 - val_rmse: 0.9849 - val_sae: 393.7145 - val_sse: 513.1457 - learning_rate: 0.0017\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1154 - loss: 0.2715 - mae: 0.3165 - mse: 0.2664 - pearson_correlation: -9.3208e-17 - r2_keras: -104.9199 - rmse: 0.8956 - sae: 2699.1582 - sse: 3285.5020\n","Epoch 14: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0918 - loss: 0.2571 - mae: 0.2937 - mse: 0.2305 - pearson_correlation: 6.2573e-18 - r2_keras: -86.1614 - rmse: 0.8844 - sae: 1965.4093 - sse: 2384.4446 - val_huber_loss: 0.1841 - val_loss: 0.3399 - val_mae: 0.4663 - val_mse: 0.3903 - val_pearson_correlation: -9.2776e-17 - val_r2_keras: -38.9939 - val_rmse: 1.0298 - val_sae: 393.1707 - val_sse: 561.0386 - learning_rate: 0.0017\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1205 - loss: 0.2764 - mae: 0.3379 - mse: 0.2639 - pearson_correlation: 6.5413e-16 - r2_keras: -114.7322 - rmse: 0.9362 - sae: 2615.9570 - sse: 3589.8682\n","Epoch 15: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1092 - loss: 0.2694 - mae: 0.3354 - mse: 0.2457 - pearson_correlation: 4.4749e-16 - r2_keras: -89.9969 - rmse: 0.8869 - sae: 1902.8531 - sse: 2555.6135 - val_huber_loss: 0.1499 - val_loss: 0.3055 - val_mae: 0.3949 - val_mse: 0.3151 - val_pearson_correlation: 8.3425e-17 - val_r2_keras: -42.7037 - val_rmse: 1.0765 - val_sae: 409.8314 - val_sse: 613.0801 - learning_rate: 0.0017\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0931 - loss: 0.2487 - mae: 0.3068 - mse: 0.1948 - pearson_correlation: -7.5284e-16 - r2_keras: -107.9718 - rmse: 0.9084 - sae: 2642.9624 - sse: 3380.1675\n","Epoch 16: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0776 - loss: 0.2393 - mae: 0.2884 - mse: 0.1742 - pearson_correlation: -5.0994e-16 - r2_keras: -91.8468 - rmse: 0.9230 - sae: 1943.3379 - sse: 2490.3796 - val_huber_loss: 0.1393 - val_loss: 0.2948 - val_mae: 0.3633 - val_mse: 0.3009 - val_pearson_correlation: -1.5093e-16 - val_r2_keras: -38.1907 - val_rmse: 1.0194 - val_sae: 387.9965 - val_sse: 549.7720 - learning_rate: 3.4536e-04\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0775 - loss: 0.2331 - mae: 0.2619 - mse: 0.1610 - pearson_correlation: -2.5599e-16 - r2_keras: -103.5046 - rmse: 0.8896 - sae: 2592.0947 - sse: 3241.6035\n","Epoch 17: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0617 - loss: 0.2234 - mae: 0.2412 - mse: 0.1406 - pearson_correlation: -1.9568e-16 - r2_keras: -86.9420 - rmse: 0.8949 - sae: 1902.5280 - sse: 2375.4031 - val_huber_loss: 0.1326 - val_loss: 0.2880 - val_mae: 0.3527 - val_mse: 0.2896 - val_pearson_correlation: -6.0939e-17 - val_r2_keras: -35.9660 - val_rmse: 0.9901 - val_sae: 376.9724 - val_sse: 518.5629 - learning_rate: 3.4536e-04\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0704 - loss: 0.2259 - mae: 0.2372 - mse: 0.1461 - pearson_correlation: -3.1181e-17 - r2_keras: -102.1716 - rmse: 0.8839 - sae: 2579.2383 - sse: 3200.2534\n","Epoch 18: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0555 - loss: 0.2168 - mae: 0.2181 - mse: 0.1268 - pearson_correlation: -2.1626e-17 - r2_keras: -85.3890 - rmse: 0.8856 - sae: 1891.4711 - sse: 2340.0447 - val_huber_loss: 0.1259 - val_loss: 0.2813 - val_mae: 0.3426 - val_mse: 0.2769 - val_pearson_correlation: -3.0376e-16 - val_r2_keras: -34.2468 - val_rmse: 0.9668 - val_sae: 367.0587 - val_sse: 494.4464 - learning_rate: 3.4536e-04\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0662 - loss: 0.2216 - mae: 0.2228 - mse: 0.1369 - pearson_correlation: -5.1235e-16 - r2_keras: -102.1278 - rmse: 0.8837 - sae: 2580.3364 - sse: 3198.8943\n","Epoch 19: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0510 - loss: 0.2124 - mae: 0.2038 - mse: 0.1175 - pearson_correlation: -3.9110e-16 - r2_keras: -85.0655 - rmse: 0.8830 - sae: 1890.5419 - sse: 2335.6855 - val_huber_loss: 0.1237 - val_loss: 0.2791 - val_mae: 0.3428 - val_mse: 0.2725 - val_pearson_correlation: -4.2731e-16 - val_r2_keras: -33.3997 - val_rmse: 0.9551 - val_sae: 362.3122 - val_sse: 482.5627 - learning_rate: 3.4536e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0635 - loss: 0.2188 - mae: 0.2137 - mse: 0.1309 - pearson_correlation: -1.6018e-17 - r2_keras: -102.1840 - rmse: 0.8840 - sae: 2583.3872 - sse: 3200.6389\n","Epoch 20: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0486 - loss: 0.2098 - mae: 0.1948 - mse: 0.1120 - pearson_correlation: -8.9553e-18 - r2_keras: -84.9650 - rmse: 0.8820 - sae: 1891.4227 - sse: 2335.2297 - val_huber_loss: 0.1226 - val_loss: 0.2778 - val_mae: 0.3444 - val_mse: 0.2691 - val_pearson_correlation: -3.4323e-17 - val_r2_keras: -33.0134 - val_rmse: 0.9497 - val_sae: 359.8531 - val_sse: 477.1443 - learning_rate: 3.4536e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0619 - loss: 0.2171 - mae: 0.2074 - mse: 0.1273 - pearson_correlation: -3.1309e-16 - r2_keras: -102.7149 - rmse: 0.8862 - sae: 2590.3640 - sse: 3217.1064\n","Epoch 21: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0469 - loss: 0.2080 - mae: 0.1873 - mse: 0.1084 - pearson_correlation: -2.1471e-16 - r2_keras: -85.4392 - rmse: 0.8845 - sae: 1896.5536 - sse: 2347.6196 - val_huber_loss: 0.1219 - val_loss: 0.2772 - val_mae: 0.3445 - val_mse: 0.2674 - val_pearson_correlation: 4.4748e-16 - val_r2_keras: -32.9522 - val_rmse: 0.9489 - val_sae: 359.1602 - val_sse: 476.2855 - learning_rate: 6.9073e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0615 - loss: 0.2168 - mae: 0.2065 - mse: 0.1265 - pearson_correlation: -3.8728e-16 - r2_keras: -102.7662 - rmse: 0.8865 - sae: 2591.6521 - sse: 3218.6982\n","Epoch 22: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0466 - loss: 0.2077 - mae: 0.1861 - mse: 0.1076 - pearson_correlation: -2.4794e-16 - r2_keras: -85.4812 - rmse: 0.8847 - sae: 1897.4163 - sse: 2348.7722 - val_huber_loss: 0.1215 - val_loss: 0.2767 - val_mae: 0.3448 - val_mse: 0.2663 - val_pearson_correlation: -2.3043e-17 - val_r2_keras: -32.8639 - val_rmse: 0.9476 - val_sae: 358.3553 - val_sse: 475.0468 - learning_rate: 6.9073e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0612 - loss: 0.2164 - mae: 0.2055 - mse: 0.1257 - pearson_correlation: -4.3441e-16 - r2_keras: -102.8200 - rmse: 0.8867 - sae: 2592.8538 - sse: 3220.3665\n","Epoch 23: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0462 - loss: 0.2073 - mae: 0.1850 - mse: 0.1069 - pearson_correlation: -3.3405e-16 - r2_keras: -85.5120 - rmse: 0.8849 - sae: 1898.1246 - sse: 2349.8250 - val_huber_loss: 0.1210 - val_loss: 0.2761 - val_mae: 0.3449 - val_mse: 0.2649 - val_pearson_correlation: 3.4619e-17 - val_r2_keras: -32.8312 - val_rmse: 0.9472 - val_sae: 357.9282 - val_sse: 474.5878 - learning_rate: 6.9073e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0609 - loss: 0.2160 - mae: 0.2044 - mse: 0.1250 - pearson_correlation: 3.8749e-16 - r2_keras: -102.9567 - rmse: 0.8873 - sae: 2594.8091 - sse: 3224.6079\n","Epoch 24: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0460 - loss: 0.2070 - mae: 0.1839 - mse: 0.1062 - pearson_correlation: 2.4295e-16 - r2_keras: -85.6094 - rmse: 0.8853 - sae: 1899.3975 - sse: 2352.7258 - val_huber_loss: 0.1208 - val_loss: 0.2760 - val_mae: 0.3456 - val_mse: 0.2643 - val_pearson_correlation: -1.6191e-16 - val_r2_keras: -32.7847 - val_rmse: 0.9465 - val_sae: 357.4489 - val_sse: 473.9358 - learning_rate: 6.9073e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0605 - loss: 0.2157 - mae: 0.2032 - mse: 0.1243 - pearson_correlation: 3.6616e-16 - r2_keras: -103.0994 - rmse: 0.8879 - sae: 2596.5276 - sse: 3229.0342\n","Epoch 25: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0457 - loss: 0.2067 - mae: 0.1827 - mse: 0.1055 - pearson_correlation: 2.5692e-16 - r2_keras: -85.7116 - rmse: 0.8858 - sae: 1900.5400 - sse: 2355.7598 - val_huber_loss: 0.1208 - val_loss: 0.2759 - val_mae: 0.3463 - val_mse: 0.2639 - val_pearson_correlation: -1.6212e-16 - val_r2_keras: -32.7588 - val_rmse: 0.9462 - val_sae: 357.2031 - val_sse: 473.5723 - learning_rate: 6.9073e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0603 - loss: 0.2154 - mae: 0.2023 - mse: 0.1237 - pearson_correlation: -4.2523e-16 - r2_keras: -103.2659 - rmse: 0.8886 - sae: 2598.8267 - sse: 3234.1978\n","Epoch 26: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0454 - loss: 0.2064 - mae: 0.1816 - mse: 0.1050 - pearson_correlation: -2.7154e-16 - r2_keras: -85.8337 - rmse: 0.8863 - sae: 1902.0798 - sse: 2359.3323 - val_huber_loss: 0.1206 - val_loss: 0.2757 - val_mae: 0.3460 - val_mse: 0.2634 - val_pearson_correlation: -3.4733e-17 - val_r2_keras: -32.7641 - val_rmse: 0.9462 - val_sae: 357.1056 - val_sse: 473.6460 - learning_rate: 1.3815e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0602 - loss: 0.2153 - mae: 0.2021 - mse: 0.1235 - pearson_correlation: 6.6863e-17 - r2_keras: -103.2784 - rmse: 0.8886 - sae: 2599.0723 - sse: 3234.5845\n","Epoch 27: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0454 - loss: 0.2063 - mae: 0.1814 - mse: 0.1048 - pearson_correlation: -2.7069e-17 - r2_keras: -85.8491 - rmse: 0.8864 - sae: 1902.2662 - sse: 2359.6729 - val_huber_loss: 0.1204 - val_loss: 0.2756 - val_mae: 0.3459 - val_mse: 0.2631 - val_pearson_correlation: 5.2093e-16 - val_r2_keras: -32.7675 - val_rmse: 0.9463 - val_sae: 357.0425 - val_sse: 473.6935 - learning_rate: 1.3815e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0601 - loss: 0.2153 - mae: 0.2019 - mse: 0.1234 - pearson_correlation: 3.0494e-16 - r2_keras: -103.2891 - rmse: 0.8887 - sae: 2599.2920 - sse: 3234.9187\n","Epoch 28: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0453 - loss: 0.2062 - mae: 0.1812 - mse: 0.1047 - pearson_correlation: 1.6749e-16 - r2_keras: -85.8646 - rmse: 0.8865 - sae: 1902.4449 - sse: 2359.9941 - val_huber_loss: 0.1204 - val_loss: 0.2755 - val_mae: 0.3459 - val_mse: 0.2630 - val_pearson_correlation: -1.8521e-16 - val_r2_keras: -32.7688 - val_rmse: 0.9463 - val_sae: 357.0049 - val_sse: 473.7121 - learning_rate: 1.3815e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0601 - loss: 0.2152 - mae: 0.2018 - mse: 0.1232 - pearson_correlation: -1.3903e-16 - r2_keras: -103.3130 - rmse: 0.8888 - sae: 2599.6812 - sse: 3235.6592\n","Epoch 29: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0453 - loss: 0.2062 - mae: 0.1811 - mse: 0.1046 - pearson_correlation: -5.4333e-17 - r2_keras: -85.8842 - rmse: 0.8866 - sae: 1902.7208 - sse: 2360.5310 - val_huber_loss: 0.1204 - val_loss: 0.2755 - val_mae: 0.3460 - val_mse: 0.2631 - val_pearson_correlation: 9.2630e-17 - val_r2_keras: -32.7641 - val_rmse: 0.9462 - val_sae: 356.9287 - val_sse: 473.6465 - learning_rate: 1.3815e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0600 - loss: 0.2151 - mae: 0.2015 - mse: 0.1231 - pearson_correlation: 1.2601e-16 - r2_keras: -103.3447 - rmse: 0.8889 - sae: 2600.1023 - sse: 3236.6411\n","Epoch 30: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0452 - loss: 0.2061 - mae: 0.1808 - mse: 0.1044 - pearson_correlation: 1.1468e-16 - r2_keras: -85.9084 - rmse: 0.8867 - sae: 1903.0038 - sse: 2361.2219 - val_huber_loss: 0.1204 - val_loss: 0.2755 - val_mae: 0.3461 - val_mse: 0.2631 - val_pearson_correlation: 1.2739e-16 - val_r2_keras: -32.7607 - val_rmse: 0.9462 - val_sae: 356.8736 - val_sse: 473.5986 - learning_rate: 1.3815e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0599 - loss: 0.2150 - mae: 0.2013 - mse: 0.1229 - pearson_correlation: -2.5395e-16 - r2_keras: -103.3562 - rmse: 0.8890 - sae: 2600.2588 - sse: 3236.9985\n","Epoch 31: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0451 - loss: 0.2060 - mae: 0.1805 - mse: 0.1043 - pearson_correlation: -2.5107e-16 - r2_keras: -85.9215 - rmse: 0.8868 - sae: 1903.1193 - sse: 2361.5232 - val_huber_loss: 0.1205 - val_loss: 0.2756 - val_mae: 0.3462 - val_mse: 0.2631 - val_pearson_correlation: -4.6338e-17 - val_r2_keras: -32.7542 - val_rmse: 0.9461 - val_sae: 356.8048 - val_sse: 473.5082 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0599 - loss: 0.2150 - mae: 0.2011 - mse: 0.1228 - pearson_correlation: 7.3401e-16 - r2_keras: -103.3804 - rmse: 0.8891 - sae: 2600.6064 - sse: 3237.7480\n","Epoch 32: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0451 - loss: 0.2060 - mae: 0.1804 - mse: 0.1042 - pearson_correlation: 4.8252e-16 - r2_keras: -85.9402 - rmse: 0.8869 - sae: 1903.3604 - sse: 2362.0532 - val_huber_loss: 0.1205 - val_loss: 0.2756 - val_mae: 0.3464 - val_mse: 0.2633 - val_pearson_correlation: 3.4756e-17 - val_r2_keras: -32.7530 - val_rmse: 0.9461 - val_sae: 356.7841 - val_sse: 473.4903 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0598 - loss: 0.2149 - mae: 0.2009 - mse: 0.1227 - pearson_correlation: -1.1324e-16 - r2_keras: -103.4035 - rmse: 0.8892 - sae: 2600.9146 - sse: 3238.4644\n","Epoch 33: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0450 - loss: 0.2059 - mae: 0.1802 - mse: 0.1041 - pearson_correlation: -7.0384e-17 - r2_keras: -85.9592 - rmse: 0.8870 - sae: 1903.5751 - sse: 2362.5735 - val_huber_loss: 0.1206 - val_loss: 0.2757 - val_mae: 0.3466 - val_mse: 0.2633 - val_pearson_correlation: -2.2018e-16 - val_r2_keras: -32.7478 - val_rmse: 0.9460 - val_sae: 356.7282 - val_sse: 473.4182 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0597 - loss: 0.2148 - mae: 0.2007 - mse: 0.1225 - pearson_correlation: -2.4865e-16 - r2_keras: -103.4296 - rmse: 0.8893 - sae: 2601.2900 - sse: 3239.2744\n","Epoch 34: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0450 - loss: 0.2058 - mae: 0.1800 - mse: 0.1039 - pearson_correlation: -1.9131e-16 - r2_keras: -85.9794 - rmse: 0.8871 - sae: 1903.8285 - sse: 2363.1462 - val_huber_loss: 0.1206 - val_loss: 0.2757 - val_mae: 0.3467 - val_mse: 0.2634 - val_pearson_correlation: 1.7385e-16 - val_r2_keras: -32.7456 - val_rmse: 0.9460 - val_sae: 356.6959 - val_sse: 473.3874 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0597 - loss: 0.2148 - mae: 0.2005 - mse: 0.1224 - pearson_correlation: -3.6212e-16 - r2_keras: -103.4320 - rmse: 0.8893 - sae: 2601.3442 - sse: 3239.3494\n","Epoch 35: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0449 - loss: 0.2058 - mae: 0.1798 - mse: 0.1038 - pearson_correlation: -2.1078e-16 - r2_keras: -85.9850 - rmse: 0.8871 - sae: 1903.8735 - sse: 2363.2432 - val_huber_loss: 0.1207 - val_loss: 0.2757 - val_mae: 0.3468 - val_mse: 0.2635 - val_pearson_correlation: 3.3606e-16 - val_r2_keras: -32.7488 - val_rmse: 0.9460 - val_sae: 356.7169 - val_sse: 473.4317 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0596 - loss: 0.2147 - mae: 0.2003 - mse: 0.1222 - pearson_correlation: 2.4691e-16 - r2_keras: -103.4478 - rmse: 0.8894 - sae: 2601.6255 - sse: 3239.8386\n","Epoch 36: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0449 - loss: 0.2057 - mae: 0.1796 - mse: 0.1037 - pearson_correlation: 3.0244e-16 - r2_keras: -86.0001 - rmse: 0.8872 - sae: 1904.0764 - sse: 2363.6226 - val_huber_loss: 0.1208 - val_loss: 0.2758 - val_mae: 0.3471 - val_mse: 0.2637 - val_pearson_correlation: -1.3911e-16 - val_r2_keras: -32.7408 - val_rmse: 0.9459 - val_sae: 356.6449 - val_sse: 473.3190 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0595 - loss: 0.2146 - mae: 0.2001 - mse: 0.1220 - pearson_correlation: -3.5461e-17 - r2_keras: -103.4752 - rmse: 0.8895 - sae: 2601.9973 - sse: 3240.6909\n","Epoch 37: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0448 - loss: 0.2056 - mae: 0.1793 - mse: 0.1035 - pearson_correlation: -8.4878e-17 - r2_keras: -86.0251 - rmse: 0.8874 - sae: 1904.3339 - sse: 2364.2695 - val_huber_loss: 0.1208 - val_loss: 0.2758 - val_mae: 0.3471 - val_mse: 0.2637 - val_pearson_correlation: -4.6363e-17 - val_r2_keras: -32.7445 - val_rmse: 0.9460 - val_sae: 356.6187 - val_sse: 473.3719 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0595 - loss: 0.2145 - mae: 0.1999 - mse: 0.1219 - pearson_correlation: -2.3180e-16 - r2_keras: -103.5136 - rmse: 0.8896 - sae: 2602.3762 - sse: 3241.8804\n","Epoch 38: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0448 - loss: 0.2056 - mae: 0.1791 - mse: 0.1034 - pearson_correlation: -9.3319e-17 - r2_keras: -86.0573 - rmse: 0.8875 - sae: 1904.6199 - sse: 2365.1399 - val_huber_loss: 0.1209 - val_loss: 0.2759 - val_mae: 0.3473 - val_mse: 0.2638 - val_pearson_correlation: -3.5937e-16 - val_r2_keras: -32.7413 - val_rmse: 0.9459 - val_sae: 356.6046 - val_sse: 473.3271 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0594 - loss: 0.2144 - mae: 0.1996 - mse: 0.1218 - pearson_correlation: -3.4394e-16 - r2_keras: -103.5370 - rmse: 0.8897 - sae: 2602.6848 - sse: 3242.6062\n","Epoch 39: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0447 - loss: 0.2055 - mae: 0.1788 - mse: 0.1033 - pearson_correlation: -2.6074e-16 - r2_keras: -86.0781 - rmse: 0.8876 - sae: 1904.8356 - sse: 2365.6846 - val_huber_loss: 0.1210 - val_loss: 0.2760 - val_mae: 0.3476 - val_mse: 0.2640 - val_pearson_correlation: 1.1596e-17 - val_r2_keras: -32.7351 - val_rmse: 0.9458 - val_sae: 356.5434 - val_sse: 473.2398 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0593 - loss: 0.2143 - mae: 0.1994 - mse: 0.1216 - pearson_correlation: 6.0305e-16 - r2_keras: -103.5607 - rmse: 0.8898 - sae: 2603.0452 - sse: 3243.3418\n","Epoch 40: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0446 - loss: 0.2054 - mae: 0.1786 - mse: 0.1031 - pearson_correlation: 4.2752e-16 - r2_keras: -86.0984 - rmse: 0.8877 - sae: 1905.0923 - sse: 2366.2288 - val_huber_loss: 0.1211 - val_loss: 0.2761 - val_mae: 0.3479 - val_mse: 0.2643 - val_pearson_correlation: 4.8700e-16 - val_r2_keras: -32.7373 - val_rmse: 0.9459 - val_sae: 356.5629 - val_sse: 473.2708 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0592 - loss: 0.2143 - mae: 0.1992 - mse: 0.1214 - pearson_correlation: -5.1576e-16 - r2_keras: -103.5815 - rmse: 0.8899 - sae: 2603.3074 - sse: 3243.9878\n","Epoch 41: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0446 - loss: 0.2053 - mae: 0.1784 - mse: 0.1030 - pearson_correlation: -3.5998e-16 - r2_keras: -86.1199 - rmse: 0.8879 - sae: 1905.2643 - sse: 2366.7483 - val_huber_loss: 0.1210 - val_loss: 0.2761 - val_mae: 0.3478 - val_mse: 0.2642 - val_pearson_correlation: -3.4779e-16 - val_r2_keras: -32.7416 - val_rmse: 0.9459 - val_sae: 356.5089 - val_sse: 473.3302 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0592 - loss: 0.2142 - mae: 0.1990 - mse: 0.1213 - pearson_correlation: -1.7395e-16 - r2_keras: -103.5957 - rmse: 0.8900 - sae: 2603.4189 - sse: 3244.4290\n","Epoch 42: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0445 - loss: 0.2053 - mae: 0.1782 - mse: 0.1028 - pearson_correlation: -1.0578e-16 - r2_keras: -86.1365 - rmse: 0.8880 - sae: 1905.3661 - sse: 2367.1255 - val_huber_loss: 0.1212 - val_loss: 0.2762 - val_mae: 0.3482 - val_mse: 0.2645 - val_pearson_correlation: -1.2756e-16 - val_r2_keras: -32.7366 - val_rmse: 0.9458 - val_sae: 356.4948 - val_sse: 473.2602 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0591 - loss: 0.2141 - mae: 0.1987 - mse: 0.1211 - pearson_correlation: -5.4494e-17 - r2_keras: -103.6315 - rmse: 0.8902 - sae: 2603.8403 - sse: 3245.5376\n","Epoch 43: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0444 - loss: 0.2052 - mae: 0.1779 - mse: 0.1027 - pearson_correlation: -2.7844e-17 - r2_keras: -86.1663 - rmse: 0.8881 - sae: 1905.6642 - sse: 2367.9353 - val_huber_loss: 0.1213 - val_loss: 0.2763 - val_mae: 0.3485 - val_mse: 0.2648 - val_pearson_correlation: 1.5074e-16 - val_r2_keras: -32.7376 - val_rmse: 0.9459 - val_sae: 356.5012 - val_sse: 473.2742 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0590 - loss: 0.2140 - mae: 0.1985 - mse: 0.1209 - pearson_correlation: -6.7646e-16 - r2_keras: -103.6587 - rmse: 0.8903 - sae: 2604.2397 - sse: 3246.3823\n","Epoch 44: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0444 - loss: 0.2051 - mae: 0.1777 - mse: 0.1025 - pearson_correlation: -4.9677e-16 - r2_keras: -86.1934 - rmse: 0.8883 - sae: 1905.9388 - sse: 2368.6028 - val_huber_loss: 0.1214 - val_loss: 0.2763 - val_mae: 0.3485 - val_mse: 0.2648 - val_pearson_correlation: 9.2727e-17 - val_r2_keras: -32.7463 - val_rmse: 0.9460 - val_sae: 356.4868 - val_sse: 473.3971 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0589 - loss: 0.2139 - mae: 0.1983 - mse: 0.1208 - pearson_correlation: 5.5567e-17 - r2_keras: -103.7062 - rmse: 0.8905 - sae: 2604.7620 - sse: 3247.8557\n","Epoch 45: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0443 - loss: 0.2050 - mae: 0.1774 - mse: 0.1024 - pearson_correlation: -1.0425e-17 - r2_keras: -86.2331 - rmse: 0.8885 - sae: 1906.3334 - sse: 2369.6794 - val_huber_loss: 0.1214 - val_loss: 0.2764 - val_mae: 0.3487 - val_mse: 0.2649 - val_pearson_correlation: 2.0869e-16 - val_r2_keras: -32.7413 - val_rmse: 0.9459 - val_sae: 356.4381 - val_sse: 473.3267 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0588 - loss: 0.2138 - mae: 0.1981 - mse: 0.1205 - pearson_correlation: 1.0689e-16 - r2_keras: -103.7328 - rmse: 0.8906 - sae: 2605.1997 - sse: 3248.6802\n","Epoch 46: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0442 - loss: 0.2049 - mae: 0.1772 - mse: 0.1022 - pearson_correlation: 7.6343e-17 - r2_keras: -86.2581 - rmse: 0.8886 - sae: 1906.6542 - sse: 2370.3147 - val_huber_loss: 0.1215 - val_loss: 0.2764 - val_mae: 0.3488 - val_mse: 0.2650 - val_pearson_correlation: -2.5506e-16 - val_r2_keras: -32.7415 - val_rmse: 0.9459 - val_sae: 356.4229 - val_sse: 473.3290 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0588 - loss: 0.2137 - mae: 0.1980 - mse: 0.1204 - pearson_correlation: 6.0896e-16 - r2_keras: -103.7480 - rmse: 0.8906 - sae: 2605.4341 - sse: 3249.1521\n","Epoch 47: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0442 - loss: 0.2048 - mae: 0.1770 - mse: 0.1020 - pearson_correlation: 4.2714e-16 - r2_keras: -86.2783 - rmse: 0.8887 - sae: 1906.8131 - sse: 2370.7468 - val_huber_loss: 0.1215 - val_loss: 0.2764 - val_mae: 0.3489 - val_mse: 0.2650 - val_pearson_correlation: -8.1171e-17 - val_r2_keras: -32.7382 - val_rmse: 0.9459 - val_sae: 356.2952 - val_sse: 473.2829 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0587 - loss: 0.2136 - mae: 0.1976 - mse: 0.1202 - pearson_correlation: 9.2788e-17 - r2_keras: -103.7972 - rmse: 0.8909 - sae: 2605.8376 - sse: 3250.6797\n","Epoch 48: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0441 - loss: 0.2048 - mae: 0.1767 - mse: 0.1019 - pearson_correlation: -3.2937e-17 - r2_keras: -86.3181 - rmse: 0.8889 - sae: 1907.1165 - sse: 2371.8474 - val_huber_loss: 0.1216 - val_loss: 0.2765 - val_mae: 0.3491 - val_mse: 0.2652 - val_pearson_correlation: 2.3188e-16 - val_r2_keras: -32.7419 - val_rmse: 0.9459 - val_sae: 356.3265 - val_sse: 473.3348 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0586 - loss: 0.2135 - mae: 0.1974 - mse: 0.1200 - pearson_correlation: -2.4325e-16 - r2_keras: -103.8212 - rmse: 0.8910 - sae: 2606.2246 - sse: 3251.4211\n","Epoch 49: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0440 - loss: 0.2047 - mae: 0.1765 - mse: 0.1017 - pearson_correlation: -1.8416e-16 - r2_keras: -86.3417 - rmse: 0.8891 - sae: 1907.4019 - sse: 2372.4309 - val_huber_loss: 0.1216 - val_loss: 0.2765 - val_mae: 0.3492 - val_mse: 0.2653 - val_pearson_correlation: -1.5071e-16 - val_r2_keras: -32.7428 - val_rmse: 0.9459 - val_sae: 356.2962 - val_sse: 473.3482 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0585 - loss: 0.2134 - mae: 0.1973 - mse: 0.1198 - pearson_correlation: -2.9760e-16 - r2_keras: -103.8278 - rmse: 0.8910 - sae: 2606.4177 - sse: 3251.6270\n","Epoch 50: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0440 - loss: 0.2046 - mae: 0.1763 - mse: 0.1016 - pearson_correlation: -2.4237e-16 - r2_keras: -86.3548 - rmse: 0.8892 - sae: 1907.5380 - sse: 2372.6702 - val_huber_loss: 0.1216 - val_loss: 0.2765 - val_mae: 0.3492 - val_mse: 0.2653 - val_pearson_correlation: 1.1587e-16 - val_r2_keras: -32.7545 - val_rmse: 0.9461 - val_sae: 356.2900 - val_sse: 473.5112 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0584 - loss: 0.2133 - mae: 0.1971 - mse: 0.1197 - pearson_correlation: 3.6358e-16 - r2_keras: -103.8613 - rmse: 0.8911 - sae: 2606.6582 - sse: 3252.6670\n","Epoch 51: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0439 - loss: 0.2045 - mae: 0.1761 - mse: 0.1014 - pearson_correlation: 2.5675e-16 - r2_keras: -86.3913 - rmse: 0.8894 - sae: 1907.7806 - sse: 2373.5295 - val_huber_loss: 0.1217 - val_loss: 0.2766 - val_mae: 0.3493 - val_mse: 0.2655 - val_pearson_correlation: 4.0543e-16 - val_r2_keras: -32.7609 - val_rmse: 0.9462 - val_sae: 356.3394 - val_sse: 473.6014 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0583 - loss: 0.2132 - mae: 0.1969 - mse: 0.1194 - pearson_correlation: -1.3160e-16 - r2_keras: -103.8944 - rmse: 0.8913 - sae: 2607.1887 - sse: 3253.6938\n","Epoch 52: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0438 - loss: 0.2044 - mae: 0.1759 - mse: 0.1012 - pearson_correlation: -4.7189e-17 - r2_keras: -86.4165 - rmse: 0.8895 - sae: 1908.1127 - sse: 2374.2507 - val_huber_loss: 0.1217 - val_loss: 0.2766 - val_mae: 0.3495 - val_mse: 0.2656 - val_pearson_correlation: -1.8538e-16 - val_r2_keras: -32.7568 - val_rmse: 0.9461 - val_sae: 356.2635 - val_sse: 473.5444 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0583 - loss: 0.2131 - mae: 0.1966 - mse: 0.1193 - pearson_correlation: -2.1091e-16 - r2_keras: -103.8672 - rmse: 0.8912 - sae: 2606.8247 - sse: 3252.8496\n","Epoch 53: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0438 - loss: 0.2043 - mae: 0.1756 - mse: 0.1011 - pearson_correlation: -1.0938e-16 - r2_keras: -86.4115 - rmse: 0.8895 - sae: 1907.9069 - sse: 2373.8428 - val_huber_loss: 0.1217 - val_loss: 0.2766 - val_mae: 0.3494 - val_mse: 0.2655 - val_pearson_correlation: 4.6329e-17 - val_r2_keras: -32.7642 - val_rmse: 0.9462 - val_sae: 356.2253 - val_sse: 473.6477 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0582 - loss: 0.2130 - mae: 0.1964 - mse: 0.1191 - pearson_correlation: 7.5554e-18 - r2_keras: -103.9428 - rmse: 0.8915 - sae: 2607.6450 - sse: 3255.1938\n","Epoch 54: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0437 - loss: 0.2042 - mae: 0.1753 - mse: 0.1010 - pearson_correlation: -3.6293e-17 - r2_keras: -86.4713 - rmse: 0.8898 - sae: 1908.5055 - sse: 2375.5151 - val_huber_loss: 0.1218 - val_loss: 0.2767 - val_mae: 0.3497 - val_mse: 0.2658 - val_pearson_correlation: -2.7790e-16 - val_r2_keras: -32.7699 - val_rmse: 0.9463 - val_sae: 356.2613 - val_sse: 473.7271 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0581 - loss: 0.2129 - mae: 0.1961 - mse: 0.1189 - pearson_correlation: -1.9801e-16 - r2_keras: -103.9859 - rmse: 0.8917 - sae: 2608.2876 - sse: 3256.5308\n","Epoch 55: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0436 - loss: 0.2041 - mae: 0.1751 - mse: 0.1008 - pearson_correlation: -5.5296e-17 - r2_keras: -86.5089 - rmse: 0.8900 - sae: 1908.9431 - sse: 2376.5103 - val_huber_loss: 0.1218 - val_loss: 0.2766 - val_mae: 0.3495 - val_mse: 0.2657 - val_pearson_correlation: -2.3135e-16 - val_r2_keras: -32.7916 - val_rmse: 0.9466 - val_sae: 356.3139 - val_sse: 474.0325 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0580 - loss: 0.2129 - mae: 0.1959 - mse: 0.1188 - pearson_correlation: 1.0847e-16 - r2_keras: -104.0191 - rmse: 0.8918 - sae: 2608.5371 - sse: 3257.5603\n","Epoch 56: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0436 - loss: 0.2041 - mae: 0.1748 - mse: 0.1007 - pearson_correlation: 6.1365e-17 - r2_keras: -86.5449 - rmse: 0.8902 - sae: 1909.2036 - sse: 2377.3596 - val_huber_loss: 0.1218 - val_loss: 0.2767 - val_mae: 0.3496 - val_mse: 0.2657 - val_pearson_correlation: 2.3126e-17 - val_r2_keras: -32.8002 - val_rmse: 0.9467 - val_sae: 356.3784 - val_sse: 474.1528 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0579 - loss: 0.2127 - mae: 0.1957 - mse: 0.1186 - pearson_correlation: -9.0265e-17 - r2_keras: -104.0512 - rmse: 0.8919 - sae: 2609.0742 - sse: 3258.5554\n","Epoch 57: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0435 - loss: 0.2040 - mae: 0.1747 - mse: 0.1005 - pearson_correlation: -9.0494e-17 - r2_keras: -86.5694 - rmse: 0.8903 - sae: 1909.5497 - sse: 2378.0601 - val_huber_loss: 0.1219 - val_loss: 0.2768 - val_mae: 0.3499 - val_mse: 0.2660 - val_pearson_correlation: -2.0816e-16 - val_r2_keras: -32.7978 - val_rmse: 0.9467 - val_sae: 356.3151 - val_sse: 474.1189 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0578 - loss: 0.2127 - mae: 0.1955 - mse: 0.1184 - pearson_correlation: 8.1514e-16 - r2_keras: -104.0557 - rmse: 0.8920 - sae: 2609.1086 - sse: 3258.6960\n","Epoch 58: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0435 - loss: 0.2039 - mae: 0.1744 - mse: 0.1003 - pearson_correlation: 4.8116e-16 - r2_keras: -86.5873 - rmse: 0.8905 - sae: 1909.6229 - sse: 2378.3284 - val_huber_loss: 0.1219 - val_loss: 0.2767 - val_mae: 0.3498 - val_mse: 0.2659 - val_pearson_correlation: 1.6180e-16 - val_r2_keras: -32.8126 - val_rmse: 0.9469 - val_sae: 356.3109 - val_sse: 474.3262 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0578 - loss: 0.2126 - mae: 0.1952 - mse: 0.1182 - pearson_correlation: -1.1140e-16 - r2_keras: -104.1254 - rmse: 0.8922 - sae: 2609.7993 - sse: 3260.8572\n","Epoch 59: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0434 - loss: 0.2038 - mae: 0.1742 - mse: 0.1002 - pearson_correlation: -1.1380e-16 - r2_keras: -86.6377 - rmse: 0.8907 - sae: 1910.0941 - sse: 2379.8154 - val_huber_loss: 0.1220 - val_loss: 0.2768 - val_mae: 0.3500 - val_mse: 0.2660 - val_pearson_correlation: 8.0895e-17 - val_r2_keras: -32.8134 - val_rmse: 0.9469 - val_sae: 356.2986 - val_sse: 474.3384 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0577 - loss: 0.2124 - mae: 0.1949 - mse: 0.1180 - pearson_correlation: 4.2717e-16 - r2_keras: -104.1278 - rmse: 0.8923 - sae: 2609.7944 - sse: 3260.9331\n","Epoch 60: val_loss did not improve from 0.26765\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0433 - loss: 0.2037 - mae: 0.1739 - mse: 0.1000 - pearson_correlation: 2.0744e-16 - r2_keras: -86.6481 - rmse: 0.8908 - sae: 1910.1393 - sse: 2379.9690 - val_huber_loss: 0.1220 - val_loss: 0.2768 - val_mae: 0.3501 - val_mse: 0.2661 - val_pearson_correlation: -1.7324e-16 - val_r2_keras: -32.8262 - val_rmse: 0.9471 - val_sae: 356.3865 - val_sse: 474.5182 - learning_rate: 1.0000e-05\n","| \u001b[35m6        \u001b[39m | \u001b[35m-0.2768  \u001b[39m | \u001b[35m0.001727 \u001b[39m | \u001b[35m87.27    \u001b[39m | \u001b[35m53.87    \u001b[39m | \u001b[35m72.07    \u001b[39m | \u001b[35m7.835    \u001b[39m | \u001b[35m85.11    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/step - huber_loss: 0.8588 - loss: 1.0663 - mae: 1.2601 - mse: 2.8956 - pearson_correlation: -5.7335e-16 - r2_keras: -376.5990 - rmse: 1.6910 - sae: 5212.8901 - sse: 11712.6475\n","Epoch 1: val_loss improved from inf to 0.48433, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 642ms/step - huber_loss: 0.7222 - loss: 0.9833 - mae: 1.1738 - mse: 2.5535 - pearson_correlation: -2.0148e-16 - r2_keras: -293.6430 - rmse: 1.5900 - sae: 3750.8171 - sse: 8311.7715 - val_huber_loss: 0.2758 - val_loss: 0.4843 - val_mae: 0.6449 - val_mse: 0.6455 - val_pearson_correlation: 6.4580e-17 - val_r2_keras: -23.9553 - val_rmse: 0.8135 - val_sae: 343.7079 - val_sse: 350.0755 - learning_rate: 0.0025\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.5464 - loss: 0.7550 - mae: 0.9862 - mse: 1.5087 - pearson_correlation: 4.2751e-17 - r2_keras: -262.7267 - rmse: 1.4132 - sae: 4348.4238 - sse: 8180.4731\n","Epoch 2: val_loss improved from 0.48433 to 0.40668, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.4626 - loss: 0.7039 - mae: 0.9138 - mse: 1.3402 - pearson_correlation: 5.1367e-17 - r2_keras: -201.9279 - rmse: 1.3098 - sae: 3121.9937 - sse: 5771.6509 - val_huber_loss: 0.1982 - val_loss: 0.4067 - val_mae: 0.5089 - val_mse: 0.4730 - val_pearson_correlation: -6.0528e-16 - val_r2_keras: -22.7755 - val_rmse: 0.7940 - val_sae: 311.8263 - val_sse: 333.5247 - learning_rate: 0.0025\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2836 - loss: 0.4921 - mae: 0.6599 - mse: 0.5965 - pearson_correlation: 4.3396e-18 - r2_keras: -118.6488 - rmse: 0.9519 - sae: 2884.6284 - sse: 3711.3564\n","Epoch 3: val_loss did not improve from 0.40668\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2386 - loss: 0.4647 - mae: 0.5989 - mse: 0.5421 - pearson_correlation: -6.4773e-17 - r2_keras: -97.9195 - rmse: 0.9437 - sae: 2093.1384 - sse: 2698.9099 - val_huber_loss: 0.2310 - val_loss: 0.4393 - val_mae: 0.5838 - val_mse: 0.5176 - val_pearson_correlation: -3.2808e-16 - val_r2_keras: -24.4058 - val_rmse: 0.8208 - val_sae: 352.4623 - val_sse: 356.3953 - learning_rate: 0.0025\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1275 - loss: 0.3358 - mae: 0.3648 - mse: 0.2845 - pearson_correlation: -1.3153e-16 - r2_keras: -123.5267 - rmse: 0.9711 - sae: 2892.3960 - sse: 3862.6641\n","Epoch 4: val_loss did not improve from 0.40668\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1229 - loss: 0.3330 - mae: 0.3651 - mse: 0.2744 - pearson_correlation: -5.4182e-17 - r2_keras: -94.7207 - rmse: 0.8991 - sae: 2079.7600 - sse: 2724.1145 - val_huber_loss: 0.2238 - val_loss: 0.4318 - val_mae: 0.5673 - val_mse: 0.5033 - val_pearson_correlation: 5.4582e-17 - val_r2_keras: -24.2670 - val_rmse: 0.8186 - val_sae: 347.3208 - val_sse: 354.4486 - learning_rate: 0.0025\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0984 - loss: 0.3063 - mae: 0.3168 - mse: 0.2052 - pearson_correlation: -1.5679e-16 - r2_keras: -107.8293 - rmse: 0.9078 - sae: 2667.7812 - sse: 3375.7473\n","Epoch 5: val_loss improved from 0.40668 to 0.39750, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0900 - loss: 0.3012 - mae: 0.3038 - mse: 0.1944 - pearson_correlation: -1.1233e-16 - r2_keras: -86.9974 - rmse: 0.8828 - sae: 1938.2072 - sse: 2431.6631 - val_huber_loss: 0.1899 - val_loss: 0.3975 - val_mae: 0.5234 - val_mse: 0.4218 - val_pearson_correlation: -3.4049e-16 - val_r2_keras: -24.5356 - val_rmse: 0.8229 - val_sae: 345.6517 - val_sse: 358.2166 - learning_rate: 0.0025\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0751 - loss: 0.2827 - mae: 0.2617 - mse: 0.1627 - pearson_correlation: -4.4517e-16 - r2_keras: -112.9457 - rmse: 0.9289 - sae: 2738.4817 - sse: 3534.4546\n","Epoch 6: val_loss did not improve from 0.39750\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0698 - loss: 0.2795 - mae: 0.2551 - mse: 0.1538 - pearson_correlation: -3.0388e-16 - r2_keras: -89.9577 - rmse: 0.8927 - sae: 1987.6478 - sse: 2532.1819 - val_huber_loss: 0.1943 - val_loss: 0.4016 - val_mae: 0.5113 - val_mse: 0.4411 - val_pearson_correlation: -1.0197e-16 - val_r2_keras: -24.3491 - val_rmse: 0.8199 - val_sae: 338.9954 - val_sse: 355.5998 - learning_rate: 0.0025\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0660 - loss: 0.2733 - mae: 0.2333 - mse: 0.1387 - pearson_correlation: 7.1721e-16 - r2_keras: -109.8925 - rmse: 0.9164 - sae: 2670.9763 - sse: 3439.7463\n","Epoch 7: val_loss did not improve from 0.39750\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0629 - loss: 0.2714 - mae: 0.2334 - mse: 0.1336 - pearson_correlation: 4.9588e-16 - r2_keras: -88.9400 - rmse: 0.8935 - sae: 1945.4474 - sse: 2480.9814 - val_huber_loss: 0.2112 - val_loss: 0.4181 - val_mae: 0.5448 - val_mse: 0.4939 - val_pearson_correlation: 1.0410e-16 - val_r2_keras: -24.3453 - val_rmse: 0.8198 - val_sae: 346.3320 - val_sse: 355.5471 - learning_rate: 0.0025\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0823 - loss: 0.2891 - mae: 0.2787 - mse: 0.1756 - pearson_correlation: -3.0435e-16 - r2_keras: -104.7667 - rmse: 0.8950 - sae: 2634.6560 - sse: 3280.7512\n","Epoch 8: val_loss did not improve from 0.39750\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0831 - loss: 0.2896 - mae: 0.2861 - mse: 0.1744 - pearson_correlation: -1.6902e-16 - r2_keras: -87.9966 - rmse: 0.9003 - sae: 1937.9930 - sse: 2404.0020 - val_huber_loss: 0.2284 - val_loss: 0.4349 - val_mae: 0.5358 - val_mse: 0.5697 - val_pearson_correlation: 1.4472e-16 - val_r2_keras: -24.3442 - val_rmse: 0.8198 - val_sae: 330.4585 - val_sse: 355.5314 - learning_rate: 0.0025\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0966 - loss: 0.3031 - mae: 0.3019 - mse: 0.2065 - pearson_correlation: 3.3762e-16 - r2_keras: -104.6442 - rmse: 0.8944 - sae: 2597.6831 - sse: 3276.9500\n","Epoch 9: val_loss improved from 0.39750 to 0.32977, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0841 - loss: 0.2954 - mae: 0.2886 - mse: 0.1887 - pearson_correlation: 2.1939e-16 - r2_keras: -85.2375 - rmse: 0.8771 - sae: 1894.1219 - sse: 2370.0627 - val_huber_loss: 0.1237 - val_loss: 0.3298 - val_mae: 0.3772 - val_mse: 0.2824 - val_pearson_correlation: 2.1243e-16 - val_r2_keras: -27.4055 - val_rmse: 0.8679 - val_sae: 334.5546 - val_sse: 398.4749 - learning_rate: 0.0025\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0872 - loss: 0.2932 - mae: 0.2951 - mse: 0.1780 - pearson_correlation: -5.6194e-16 - r2_keras: -119.3323 - rmse: 0.9546 - sae: 2769.1455 - sse: 3732.5588\n","Epoch 10: val_loss did not improve from 0.32977\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0885 - loss: 0.2940 - mae: 0.3006 - mse: 0.1791 - pearson_correlation: -3.1026e-16 - r2_keras: -93.2965 - rmse: 0.9013 - sae: 2003.9962 - sse: 2653.4717 - val_huber_loss: 0.1500 - val_loss: 0.3556 - val_mae: 0.3786 - val_mse: 0.3309 - val_pearson_correlation: -7.1636e-17 - val_r2_keras: -35.7896 - val_rmse: 0.9877 - val_sae: 377.8068 - val_sse: 516.0881 - learning_rate: 0.0025\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1195 - loss: 0.3252 - mae: 0.3400 - mse: 0.2567 - pearson_correlation: -3.7399e-16 - r2_keras: -138.7463 - rmse: 1.0287 - sae: 3072.7788 - sse: 4334.7568\n","Epoch 11: val_loss did not improve from 0.32977\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0991 - loss: 0.3127 - mae: 0.3225 - mse: 0.2283 - pearson_correlation: -2.7009e-16 - r2_keras: -108.0300 - rmse: 0.9671 - sae: 2214.3357 - sse: 3075.9436 - val_huber_loss: 0.1424 - val_loss: 0.3477 - val_mae: 0.3934 - val_mse: 0.3526 - val_pearson_correlation: 3.3950e-16 - val_r2_keras: -25.6153 - val_rmse: 0.8401 - val_sae: 327.2304 - val_sse: 373.3619 - learning_rate: 0.0025\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0999 - loss: 0.3051 - mae: 0.3337 - mse: 0.2023 - pearson_correlation: 3.6130e-16 - r2_keras: -95.3914 - rmse: 0.8544 - sae: 2526.2917 - sse: 2989.9417\n","Epoch 12: val_loss improved from 0.32977 to 0.31207, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0874 - loss: 0.2975 - mae: 0.3251 - mse: 0.1867 - pearson_correlation: 2.4970e-16 - r2_keras: -83.3392 - rmse: 0.8860 - sae: 1871.4309 - sse: 2228.8125 - val_huber_loss: 0.1073 - val_loss: 0.3121 - val_mae: 0.3459 - val_mse: 0.2358 - val_pearson_correlation: -1.7073e-16 - val_r2_keras: -29.7728 - val_rmse: 0.9033 - val_sae: 347.8005 - val_sse: 431.6837 - learning_rate: 0.0025\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0839 - loss: 0.2887 - mae: 0.2669 - mse: 0.1840 - pearson_correlation: 1.9940e-16 - r2_keras: -113.1638 - rmse: 0.9298 - sae: 2677.5220 - sse: 3541.2178\n","Epoch 13: val_loss did not improve from 0.31207\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0716 - loss: 0.2811 - mae: 0.2571 - mse: 0.1657 - pearson_correlation: 1.3098e-16 - r2_keras: -90.5253 - rmse: 0.8972 - sae: 1948.4594 - sse: 2541.6428 - val_huber_loss: 0.1529 - val_loss: 0.3571 - val_mae: 0.4117 - val_mse: 0.3502 - val_pearson_correlation: 7.6185e-17 - val_r2_keras: -31.1640 - val_rmse: 0.9235 - val_sae: 347.9258 - val_sse: 451.1997 - learning_rate: 0.0025\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0969 - loss: 0.3011 - mae: 0.3087 - mse: 0.2018 - pearson_correlation: -5.5763e-16 - r2_keras: -112.9817 - rmse: 0.9291 - sae: 2672.1963 - sse: 3535.5686\n","Epoch 14: val_loss did not improve from 0.31207\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0785 - loss: 0.2899 - mae: 0.2878 - mse: 0.1778 - pearson_correlation: -4.1749e-16 - r2_keras: -91.0129 - rmse: 0.9021 - sae: 1947.3615 - sse: 2545.0215 - val_huber_loss: 0.1635 - val_loss: 0.3672 - val_mae: 0.3969 - val_mse: 0.3713 - val_pearson_correlation: 1.3427e-16 - val_r2_keras: -43.8413 - val_rmse: 1.0905 - val_sae: 427.8271 - val_sse: 629.0389 - learning_rate: 0.0025\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0916 - loss: 0.2953 - mae: 0.2983 - mse: 0.1912 - pearson_correlation: -6.8674e-17 - r2_keras: -116.9093 - rmse: 0.9449 - sae: 2768.5500 - sse: 3657.3979\n","Epoch 15: val_loss did not improve from 0.31207\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0759 - loss: 0.2857 - mae: 0.2764 - mse: 0.1705 - pearson_correlation: -1.0525e-16 - r2_keras: -95.0074 - rmse: 0.9246 - sae: 2015.5750 - sse: 2642.3823 - val_huber_loss: 0.1691 - val_loss: 0.3723 - val_mae: 0.3874 - val_mse: 0.3749 - val_pearson_correlation: 8.1587e-18 - val_r2_keras: -28.5005 - val_rmse: 0.8845 - val_sae: 313.8447 - val_sse: 413.8360 - learning_rate: 0.0025\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0729 - loss: 0.2761 - mae: 0.2710 - mse: 0.1509 - pearson_correlation: -7.3831e-16 - r2_keras: -107.9311 - rmse: 0.9083 - sae: 2643.1113 - sse: 3378.9067\n","Epoch 16: val_loss improved from 0.31207 to 0.30540, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0729 - loss: 0.2760 - mae: 0.2651 - mse: 0.1522 - pearson_correlation: -4.2003e-16 - r2_keras: -89.2145 - rmse: 0.9017 - sae: 1932.8136 - sse: 2458.9792 - val_huber_loss: 0.1028 - val_loss: 0.3054 - val_mae: 0.3089 - val_mse: 0.2296 - val_pearson_correlation: -2.4392e-17 - val_r2_keras: -31.6869 - val_rmse: 0.9310 - val_sae: 352.8174 - val_sse: 458.5360 - learning_rate: 0.0025\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0804 - loss: 0.2830 - mae: 0.2762 - mse: 0.1619 - pearson_correlation: 1.7419e-16 - r2_keras: -103.6601 - rmse: 0.8903 - sae: 2619.0645 - sse: 3246.4246\n","Epoch 17: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0678 - loss: 0.2752 - mae: 0.2632 - mse: 0.1463 - pearson_correlation: 8.9040e-17 - r2_keras: -83.0864 - rmse: 0.8607 - sae: 1903.5367 - sse: 2332.1753 - val_huber_loss: 0.1505 - val_loss: 0.3524 - val_mae: 0.4199 - val_mse: 0.3183 - val_pearson_correlation: 1.3429e-16 - val_r2_keras: -39.9759 - val_rmse: 1.0424 - val_sae: 408.8545 - val_sse: 574.8146 - learning_rate: 0.0025\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0847 - loss: 0.2866 - mae: 0.2762 - mse: 0.1851 - pearson_correlation: 1.7874e-16 - r2_keras: -133.8267 - rmse: 1.0105 - sae: 2979.8835 - sse: 4182.1543\n","Epoch 18: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0738 - loss: 0.2799 - mae: 0.2644 - mse: 0.1687 - pearson_correlation: 1.2600e-16 - r2_keras: -106.1896 - rmse: 0.9674 - sae: 2156.4353 - sse: 2991.0935 - val_huber_loss: 0.1789 - val_loss: 0.3801 - val_mae: 0.4267 - val_mse: 0.3972 - val_pearson_correlation: -7.1643e-17 - val_r2_keras: -31.2074 - val_rmse: 0.9242 - val_sae: 340.9020 - val_sse: 451.8083 - learning_rate: 0.0025\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0838 - loss: 0.2850 - mae: 0.2921 - mse: 0.1802 - pearson_correlation: -4.8768e-16 - r2_keras: -101.1378 - rmse: 0.8795 - sae: 2560.5823 - sse: 3168.1865\n","Epoch 19: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0959 - loss: 0.2924 - mae: 0.2979 - mse: 0.1998 - pearson_correlation: -3.8864e-16 - r2_keras: -83.9188 - rmse: 0.8760 - sae: 1877.7020 - sse: 2309.5049 - val_huber_loss: 0.1119 - val_loss: 0.3126 - val_mae: 0.3316 - val_mse: 0.2327 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -46.1670 - val_rmse: 1.1184 - val_sae: 430.7092 - val_sse: 661.6644 - learning_rate: 0.0025\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1001 - loss: 0.3009 - mae: 0.3066 - mse: 0.2091 - pearson_correlation: -1.1583e-16 - r2_keras: -127.8052 - rmse: 0.9876 - sae: 2862.6116 - sse: 3995.3772\n","Epoch 20: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0855 - loss: 0.2919 - mae: 0.2870 - mse: 0.1895 - pearson_correlation: -3.3883e-17 - r2_keras: -101.3804 - rmse: 0.9454 - sae: 2073.5312 - sse: 2857.2505 - val_huber_loss: 0.1385 - val_loss: 0.3386 - val_mae: 0.4056 - val_mse: 0.2985 - val_pearson_correlation: -4.3434e-17 - val_r2_keras: -34.2184 - val_rmse: 0.9664 - val_sae: 374.2920 - val_sse: 494.0473 - learning_rate: 0.0025\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0725 - loss: 0.2726 - mae: 0.2587 - mse: 0.1497 - pearson_correlation: -7.6749e-16 - r2_keras: -106.1490 - rmse: 0.9008 - sae: 2610.6709 - sse: 3323.6279\n","Epoch 21: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0656 - loss: 0.2683 - mae: 0.2550 - mse: 0.1403 - pearson_correlation: -5.1328e-16 - r2_keras: -88.6143 - rmse: 0.9017 - sae: 1918.1747 - sse: 2429.0227 - val_huber_loss: 0.1307 - val_loss: 0.3300 - val_mae: 0.3471 - val_mse: 0.3011 - val_pearson_correlation: 1.5031e-16 - val_r2_keras: -29.1383 - val_rmse: 0.8940 - val_sae: 334.0848 - val_sse: 422.7836 - learning_rate: 0.0025\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0712 - loss: 0.2706 - mae: 0.2664 - mse: 0.1446 - pearson_correlation: 1.7941e-16 - r2_keras: -98.9376 - rmse: 0.8700 - sae: 2551.7844 - sse: 3099.9402\n","Epoch 22: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0600 - loss: 0.2637 - mae: 0.2491 - mse: 0.1305 - pearson_correlation: 8.0033e-17 - r2_keras: -81.5061 - rmse: 0.8614 - sae: 1865.9587 - sse: 2252.9121 - val_huber_loss: 0.1204 - val_loss: 0.3195 - val_mae: 0.3340 - val_mse: 0.2643 - val_pearson_correlation: -3.6662e-16 - val_r2_keras: -31.0239 - val_rmse: 0.9215 - val_sae: 346.3107 - val_sse: 449.2344 - learning_rate: 4.9426e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0600 - loss: 0.2592 - mae: 0.2347 - mse: 0.1219 - pearson_correlation: -1.8155e-17 - r2_keras: -102.9038 - rmse: 0.8870 - sae: 2578.1230 - sse: 3222.9653\n","Epoch 23: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0480 - loss: 0.2519 - mae: 0.2151 - mse: 0.1069 - pearson_correlation: 3.9644e-18 - r2_keras: -84.8971 - rmse: 0.8793 - sae: 1886.5756 - sse: 2343.6897 - val_huber_loss: 0.1178 - val_loss: 0.3168 - val_mae: 0.3339 - val_mse: 0.2548 - val_pearson_correlation: -1.0735e-16 - val_r2_keras: -32.1270 - val_rmse: 0.9373 - val_sae: 353.7198 - val_sse: 464.7086 - learning_rate: 4.9426e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0526 - loss: 0.2516 - mae: 0.2144 - mse: 0.1069 - pearson_correlation: -3.3552e-16 - r2_keras: -105.6490 - rmse: 0.8987 - sae: 2604.5410 - sse: 3308.1194\n","Epoch 24: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0422 - loss: 0.2453 - mae: 0.1976 - mse: 0.0939 - pearson_correlation: -2.0467e-16 - r2_keras: -87.2150 - rmse: 0.8913 - sae: 1906.3563 - sse: 2406.1804 - val_huber_loss: 0.1149 - val_loss: 0.3137 - val_mae: 0.3301 - val_mse: 0.2469 - val_pearson_correlation: -1.1879e-17 - val_r2_keras: -32.2100 - val_rmse: 0.9384 - val_sae: 354.3598 - val_sse: 465.8737 - learning_rate: 4.9426e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0485 - loss: 0.2472 - mae: 0.2020 - mse: 0.0982 - pearson_correlation: 8.4301e-16 - r2_keras: -107.0727 - rmse: 0.9047 - sae: 2620.3721 - sse: 3352.2803\n","Epoch 25: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0392 - loss: 0.2416 - mae: 0.1874 - mse: 0.0867 - pearson_correlation: 6.3304e-16 - r2_keras: -88.1300 - rmse: 0.8950 - sae: 1916.9244 - sse: 2435.2202 - val_huber_loss: 0.1184 - val_loss: 0.3170 - val_mae: 0.3354 - val_mse: 0.2546 - val_pearson_correlation: -1.7352e-16 - val_r2_keras: -32.7656 - val_rmse: 0.9463 - val_sae: 357.7456 - val_sse: 473.6682 - learning_rate: 4.9426e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0467 - loss: 0.2453 - mae: 0.1958 - mse: 0.0944 - pearson_correlation: 5.4451e-16 - r2_keras: -107.9070 - rmse: 0.9082 - sae: 2631.1997 - sse: 3378.1592\n","Epoch 26: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0377 - loss: 0.2398 - mae: 0.1817 - mse: 0.0832 - pearson_correlation: 3.8827e-16 - r2_keras: -89.1357 - rmse: 0.9011 - sae: 1925.9913 - sse: 2457.7461 - val_huber_loss: 0.1168 - val_loss: 0.3151 - val_mae: 0.3323 - val_mse: 0.2509 - val_pearson_correlation: -1.6399e-16 - val_r2_keras: -32.5012 - val_rmse: 0.9425 - val_sae: 355.6663 - val_sse: 469.9591 - learning_rate: 4.9426e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0452 - loss: 0.2435 - mae: 0.1915 - mse: 0.0914 - pearson_correlation: 2.9829e-17 - r2_keras: -108.2352 - rmse: 0.9095 - sae: 2633.6677 - sse: 3388.3386\n","Epoch 27: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0363 - loss: 0.2381 - mae: 0.1772 - mse: 0.0803 - pearson_correlation: 1.9939e-18 - r2_keras: -89.1638 - rmse: 0.9004 - sae: 1926.6448 - sse: 2462.2954 - val_huber_loss: 0.1174 - val_loss: 0.3156 - val_mae: 0.3337 - val_mse: 0.2518 - val_pearson_correlation: -4.6449e-17 - val_r2_keras: -32.6838 - val_rmse: 0.9451 - val_sae: 357.0682 - val_sse: 472.5193 - learning_rate: 9.8851e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0449 - loss: 0.2431 - mae: 0.1900 - mse: 0.0906 - pearson_correlation: -3.6501e-16 - r2_keras: -108.2661 - rmse: 0.9097 - sae: 2634.1316 - sse: 3389.2966\n","Epoch 28: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0359 - loss: 0.2377 - mae: 0.1757 - mse: 0.0795 - pearson_correlation: -1.6001e-16 - r2_keras: -89.2165 - rmse: 0.9008 - sae: 1927.0452 - sse: 2463.3110 - val_huber_loss: 0.1180 - val_loss: 0.3162 - val_mae: 0.3348 - val_mse: 0.2529 - val_pearson_correlation: 1.1528e-16 - val_r2_keras: -32.8395 - val_rmse: 0.9473 - val_sae: 358.1504 - val_sse: 474.7039 - learning_rate: 9.8851e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0445 - loss: 0.2427 - mae: 0.1887 - mse: 0.0898 - pearson_correlation: 3.4552e-16 - r2_keras: -108.2791 - rmse: 0.9097 - sae: 2634.2153 - sse: 3389.6995\n","Epoch 29: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0356 - loss: 0.2373 - mae: 0.1744 - mse: 0.0788 - pearson_correlation: 2.2865e-16 - r2_keras: -89.2576 - rmse: 0.9011 - sae: 1927.2070 - sse: 2463.9595 - val_huber_loss: 0.1188 - val_loss: 0.3169 - val_mae: 0.3360 - val_mse: 0.2547 - val_pearson_correlation: 1.2602e-16 - val_r2_keras: -32.9755 - val_rmse: 0.9492 - val_sae: 359.0393 - val_sse: 476.6120 - learning_rate: 9.8851e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0442 - loss: 0.2424 - mae: 0.1876 - mse: 0.0892 - pearson_correlation: -1.0618e-16 - r2_keras: -108.5338 - rmse: 0.9108 - sae: 2636.8340 - sse: 3397.6006\n","Epoch 30: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0353 - loss: 0.2369 - mae: 0.1734 - mse: 0.0782 - pearson_correlation: -8.6010e-17 - r2_keras: -89.4795 - rmse: 0.9022 - sae: 1929.1881 - sse: 2469.8384 - val_huber_loss: 0.1189 - val_loss: 0.3170 - val_mae: 0.3365 - val_mse: 0.2547 - val_pearson_correlation: 2.7475e-16 - val_r2_keras: -32.9925 - val_rmse: 0.9494 - val_sae: 359.4007 - val_sse: 476.8508 - learning_rate: 9.8851e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0438 - loss: 0.2418 - mae: 0.1859 - mse: 0.0882 - pearson_correlation: -3.4971e-16 - r2_keras: -108.4326 - rmse: 0.9103 - sae: 2635.9092 - sse: 3394.4622\n","Epoch 31: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0349 - loss: 0.2364 - mae: 0.1719 - mse: 0.0773 - pearson_correlation: -2.1875e-16 - r2_keras: -89.4019 - rmse: 0.9019 - sae: 1928.4845 - sse: 2467.6265 - val_huber_loss: 0.1199 - val_loss: 0.3179 - val_mae: 0.3379 - val_mse: 0.2571 - val_pearson_correlation: 5.7109e-17 - val_r2_keras: -33.0427 - val_rmse: 0.9501 - val_sae: 359.7604 - val_sse: 477.5548 - learning_rate: 9.8851e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0433 - loss: 0.2413 - mae: 0.1845 - mse: 0.0872 - pearson_correlation: 3.1363e-16 - r2_keras: -108.5669 - rmse: 0.9109 - sae: 2637.5498 - sse: 3398.6289\n","Epoch 32: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0346 - loss: 0.2360 - mae: 0.1704 - mse: 0.0764 - pearson_correlation: 1.7614e-16 - r2_keras: -89.5226 - rmse: 0.9025 - sae: 1929.6362 - sse: 2470.7693 - val_huber_loss: 0.1200 - val_loss: 0.3179 - val_mae: 0.3381 - val_mse: 0.2570 - val_pearson_correlation: 2.3879e-16 - val_r2_keras: -33.1423 - val_rmse: 0.9515 - val_sae: 360.4020 - val_sse: 478.9522 - learning_rate: 1.9770e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0432 - loss: 0.2412 - mae: 0.1840 - mse: 0.0869 - pearson_correlation: -5.1832e-16 - r2_keras: -108.6402 - rmse: 0.9112 - sae: 2638.2964 - sse: 3400.9019\n","Epoch 33: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0344 - loss: 0.2358 - mae: 0.1700 - mse: 0.0761 - pearson_correlation: -2.8555e-16 - r2_keras: -89.5679 - rmse: 0.9027 - sae: 1930.1127 - sse: 2472.2432 - val_huber_loss: 0.1200 - val_loss: 0.3179 - val_mae: 0.3382 - val_mse: 0.2568 - val_pearson_correlation: -1.1343e-16 - val_r2_keras: -33.1961 - val_rmse: 0.9523 - val_sae: 360.7561 - val_sse: 479.7070 - learning_rate: 1.9770e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0431 - loss: 0.2410 - mae: 0.1837 - mse: 0.0867 - pearson_correlation: 6.9685e-16 - r2_keras: -108.6954 - rmse: 0.9114 - sae: 2638.9617 - sse: 3402.6157\n","Epoch 34: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0344 - loss: 0.2357 - mae: 0.1697 - mse: 0.0760 - pearson_correlation: 4.2148e-16 - r2_keras: -89.6052 - rmse: 0.9028 - sae: 1930.5625 - sse: 2473.3921 - val_huber_loss: 0.1202 - val_loss: 0.3181 - val_mae: 0.3385 - val_mse: 0.2572 - val_pearson_correlation: -1.2467e-16 - val_r2_keras: -33.2148 - val_rmse: 0.9525 - val_sae: 360.9120 - val_sse: 479.9690 - learning_rate: 1.9770e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0430 - loss: 0.2409 - mae: 0.1834 - mse: 0.0864 - pearson_correlation: -2.0666e-16 - r2_keras: -108.7019 - rmse: 0.9115 - sae: 2639.0864 - sse: 3402.8162\n","Epoch 35: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0343 - loss: 0.2356 - mae: 0.1694 - mse: 0.0757 - pearson_correlation: -1.4031e-16 - r2_keras: -89.6128 - rmse: 0.9029 - sae: 1930.6582 - sse: 2473.5642 - val_huber_loss: 0.1203 - val_loss: 0.3182 - val_mae: 0.3387 - val_mse: 0.2574 - val_pearson_correlation: -1.8125e-16 - val_r2_keras: -33.2265 - val_rmse: 0.9527 - val_sae: 361.0120 - val_sse: 480.1331 - learning_rate: 1.9770e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0429 - loss: 0.2408 - mae: 0.1830 - mse: 0.0862 - pearson_correlation: 2.4369e-16 - r2_keras: -108.7228 - rmse: 0.9116 - sae: 2639.2983 - sse: 3403.4644\n","Epoch 36: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0342 - loss: 0.2355 - mae: 0.1691 - mse: 0.0755 - pearson_correlation: 1.8781e-16 - r2_keras: -89.6253 - rmse: 0.9029 - sae: 1930.7944 - sse: 2473.9797 - val_huber_loss: 0.1204 - val_loss: 0.3183 - val_mae: 0.3388 - val_mse: 0.2576 - val_pearson_correlation: -2.3791e-16 - val_r2_keras: -33.2245 - val_rmse: 0.9527 - val_sae: 361.0270 - val_sse: 480.1053 - learning_rate: 1.9770e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0428 - loss: 0.2407 - mae: 0.1828 - mse: 0.0860 - pearson_correlation: -3.2019e-16 - r2_keras: -108.7383 - rmse: 0.9116 - sae: 2639.5122 - sse: 3403.9463\n","Epoch 37: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0341 - loss: 0.2354 - mae: 0.1688 - mse: 0.0754 - pearson_correlation: -2.7853e-16 - r2_keras: -89.6309 - rmse: 0.9029 - sae: 1930.8986 - sse: 2474.2449 - val_huber_loss: 0.1204 - val_loss: 0.3183 - val_mae: 0.3389 - val_mse: 0.2576 - val_pearson_correlation: 2.2633e-17 - val_r2_keras: -33.2500 - val_rmse: 0.9530 - val_sae: 361.1805 - val_sse: 480.4626 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0427 - loss: 0.2406 - mae: 0.1826 - mse: 0.0859 - pearson_correlation: -1.3449e-16 - r2_keras: -108.7726 - rmse: 0.9118 - sae: 2639.8860 - sse: 3405.0081\n","Epoch 38: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0341 - loss: 0.2353 - mae: 0.1686 - mse: 0.0753 - pearson_correlation: -8.8813e-17 - r2_keras: -89.6569 - rmse: 0.9031 - sae: 1931.1635 - sse: 2474.9900 - val_huber_loss: 0.1204 - val_loss: 0.3183 - val_mae: 0.3391 - val_mse: 0.2577 - val_pearson_correlation: -9.0509e-17 - val_r2_keras: -33.2555 - val_rmse: 0.9531 - val_sae: 361.2272 - val_sse: 480.5397 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0427 - loss: 0.2405 - mae: 0.1824 - mse: 0.0858 - pearson_correlation: 4.9525e-16 - r2_keras: -108.7867 - rmse: 0.9118 - sae: 2640.0339 - sse: 3405.4458\n","Epoch 39: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0340 - loss: 0.2353 - mae: 0.1684 - mse: 0.0752 - pearson_correlation: 3.3861e-16 - r2_keras: -89.6691 - rmse: 0.9031 - sae: 1931.2731 - sse: 2475.3149 - val_huber_loss: 0.1205 - val_loss: 0.3184 - val_mae: 0.3393 - val_mse: 0.2579 - val_pearson_correlation: 6.7855e-17 - val_r2_keras: -33.2644 - val_rmse: 0.9532 - val_sae: 361.2935 - val_sse: 480.6649 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0426 - loss: 0.2405 - mae: 0.1822 - mse: 0.0857 - pearson_correlation: -1.0379e-15 - r2_keras: -108.8044 - rmse: 0.9119 - sae: 2640.2166 - sse: 3405.9966\n","Epoch 40: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0340 - loss: 0.2352 - mae: 0.1683 - mse: 0.0751 - pearson_correlation: -7.0547e-16 - r2_keras: -89.6810 - rmse: 0.9032 - sae: 1931.3857 - sse: 2475.6829 - val_huber_loss: 0.1205 - val_loss: 0.3183 - val_mae: 0.3392 - val_mse: 0.2577 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.2667 - val_rmse: 0.9533 - val_sae: 361.3166 - val_sse: 480.6970 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0426 - loss: 0.2404 - mae: 0.1820 - mse: 0.0856 - pearson_correlation: -6.1905e-17 - r2_keras: -108.8375 - rmse: 0.9120 - sae: 2640.6353 - sse: 3407.0217\n","Epoch 41: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0339 - loss: 0.2352 - mae: 0.1681 - mse: 0.0750 - pearson_correlation: -7.7588e-17 - r2_keras: -89.7061 - rmse: 0.9033 - sae: 1931.6860 - sse: 2476.4021 - val_huber_loss: 0.1206 - val_loss: 0.3185 - val_mae: 0.3394 - val_mse: 0.2581 - val_pearson_correlation: 1.1309e-17 - val_r2_keras: -33.2651 - val_rmse: 0.9532 - val_sae: 361.3358 - val_sse: 480.6748 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0425 - loss: 0.2403 - mae: 0.1818 - mse: 0.0854 - pearson_correlation: 3.5206e-16 - r2_keras: -108.8505 - rmse: 0.9121 - sae: 2640.8140 - sse: 3407.4246\n","Epoch 42: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0339 - loss: 0.2351 - mae: 0.1679 - mse: 0.0748 - pearson_correlation: 2.6679e-16 - r2_keras: -89.7204 - rmse: 0.9034 - sae: 1931.8173 - sse: 2476.7366 - val_huber_loss: 0.1207 - val_loss: 0.3185 - val_mae: 0.3395 - val_mse: 0.2583 - val_pearson_correlation: 1.3576e-16 - val_r2_keras: -33.2564 - val_rmse: 0.9531 - val_sae: 361.2955 - val_sse: 480.5522 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0424 - loss: 0.2403 - mae: 0.1816 - mse: 0.0853 - pearson_correlation: 7.0094e-17 - r2_keras: -108.8523 - rmse: 0.9121 - sae: 2640.8586 - sse: 3407.4795\n","Epoch 43: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0338 - loss: 0.2350 - mae: 0.1678 - mse: 0.0747 - pearson_correlation: 9.1484e-17 - r2_keras: -89.7197 - rmse: 0.9034 - sae: 1931.8369 - sse: 2476.7507 - val_huber_loss: 0.1207 - val_loss: 0.3185 - val_mae: 0.3395 - val_mse: 0.2582 - val_pearson_correlation: 1.2443e-16 - val_r2_keras: -33.2584 - val_rmse: 0.9531 - val_sae: 361.3232 - val_sse: 480.5808 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0424 - loss: 0.2402 - mae: 0.1814 - mse: 0.0852 - pearson_correlation: -2.6649e-16 - r2_keras: -108.8978 - rmse: 0.9123 - sae: 2641.3369 - sse: 3408.8921\n","Epoch 44: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0338 - loss: 0.2350 - mae: 0.1675 - mse: 0.0746 - pearson_correlation: -1.5655e-16 - r2_keras: -89.7499 - rmse: 0.9035 - sae: 1932.1561 - sse: 2477.6909 - val_huber_loss: 0.1208 - val_loss: 0.3186 - val_mae: 0.3397 - val_mse: 0.2584 - val_pearson_correlation: 6.7912e-17 - val_r2_keras: -33.2453 - val_rmse: 0.9530 - val_sae: 361.2572 - val_sse: 480.3972 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0423 - loss: 0.2401 - mae: 0.1812 - mse: 0.0851 - pearson_correlation: 2.0726e-16 - r2_keras: -108.9035 - rmse: 0.9123 - sae: 2641.4282 - sse: 3409.0701\n","Epoch 45: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0337 - loss: 0.2349 - mae: 0.1674 - mse: 0.0745 - pearson_correlation: 1.6012e-16 - r2_keras: -89.7580 - rmse: 0.9035 - sae: 1932.2290 - sse: 2477.8604 - val_huber_loss: 0.1209 - val_loss: 0.3187 - val_mae: 0.3398 - val_mse: 0.2586 - val_pearson_correlation: -2.1494e-16 - val_r2_keras: -33.2577 - val_rmse: 0.9531 - val_sae: 361.3550 - val_sse: 480.5712 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0423 - loss: 0.2401 - mae: 0.1810 - mse: 0.0850 - pearson_correlation: 2.6522e-16 - r2_keras: -108.9698 - rmse: 0.9126 - sae: 2642.0679 - sse: 3411.1260\n","Epoch 46: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0337 - loss: 0.2348 - mae: 0.1672 - mse: 0.0744 - pearson_correlation: 1.9201e-16 - r2_keras: -89.8076 - rmse: 0.9038 - sae: 1932.6797 - sse: 2479.2935 - val_huber_loss: 0.1209 - val_loss: 0.3187 - val_mae: 0.3400 - val_mse: 0.2588 - val_pearson_correlation: 2.1504e-16 - val_r2_keras: -33.2471 - val_rmse: 0.9530 - val_sae: 361.2876 - val_sse: 480.4216 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0422 - loss: 0.2400 - mae: 0.1808 - mse: 0.0848 - pearson_correlation: -2.2715e-17 - r2_keras: -108.9845 - rmse: 0.9126 - sae: 2642.2678 - sse: 3411.5803\n","Epoch 47: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0336 - loss: 0.2347 - mae: 0.1670 - mse: 0.0743 - pearson_correlation: -8.3939e-18 - r2_keras: -89.8227 - rmse: 0.9038 - sae: 1932.8290 - sse: 2479.6597 - val_huber_loss: 0.1211 - val_loss: 0.3189 - val_mae: 0.3402 - val_mse: 0.2593 - val_pearson_correlation: -3.3969e-17 - val_r2_keras: -33.2370 - val_rmse: 0.9528 - val_sae: 361.2520 - val_sse: 480.2802 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0422 - loss: 0.2399 - mae: 0.1806 - mse: 0.0847 - pearson_correlation: 7.6358e-16 - r2_keras: -108.9845 - rmse: 0.9126 - sae: 2642.2671 - sse: 3411.5820\n","Epoch 48: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0336 - loss: 0.2347 - mae: 0.1668 - mse: 0.0742 - pearson_correlation: 4.9893e-16 - r2_keras: -89.8216 - rmse: 0.9038 - sae: 1932.8234 - sse: 2479.6472 - val_huber_loss: 0.1210 - val_loss: 0.3188 - val_mae: 0.3401 - val_mse: 0.2589 - val_pearson_correlation: 4.5275e-17 - val_r2_keras: -33.2451 - val_rmse: 0.9530 - val_sae: 361.2890 - val_sse: 480.3937 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0421 - loss: 0.2398 - mae: 0.1804 - mse: 0.0846 - pearson_correlation: 7.3648e-17 - r2_keras: -109.0369 - rmse: 0.9129 - sae: 2642.8091 - sse: 3413.2063\n","Epoch 49: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0335 - loss: 0.2346 - mae: 0.1666 - mse: 0.0740 - pearson_correlation: -3.6972e-17 - r2_keras: -89.8542 - rmse: 0.9040 - sae: 1933.1665 - sse: 2480.7031 - val_huber_loss: 0.1212 - val_loss: 0.3189 - val_mae: 0.3404 - val_mse: 0.2594 - val_pearson_correlation: -2.2638e-16 - val_r2_keras: -33.2443 - val_rmse: 0.9529 - val_sae: 361.3003 - val_sse: 480.3830 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0420 - loss: 0.2398 - mae: 0.1802 - mse: 0.0845 - pearson_correlation: 7.3907e-18 - r2_keras: -109.0437 - rmse: 0.9129 - sae: 2642.8530 - sse: 3413.4175\n","Epoch 50: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0335 - loss: 0.2345 - mae: 0.1664 - mse: 0.0739 - pearson_correlation: -1.3616e-17 - r2_keras: -89.8777 - rmse: 0.9041 - sae: 1933.2715 - sse: 2481.0659 - val_huber_loss: 0.1212 - val_loss: 0.3189 - val_mae: 0.3404 - val_mse: 0.2593 - val_pearson_correlation: -1.2453e-16 - val_r2_keras: -33.2420 - val_rmse: 0.9529 - val_sae: 361.2913 - val_sse: 480.3505 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0420 - loss: 0.2397 - mae: 0.1800 - mse: 0.0843 - pearson_correlation: 1.5518e-16 - r2_keras: -109.0606 - rmse: 0.9130 - sae: 2643.1455 - sse: 3413.9414\n","Epoch 51: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0334 - loss: 0.2345 - mae: 0.1661 - mse: 0.0738 - pearson_correlation: 2.8435e-17 - r2_keras: -89.8888 - rmse: 0.9042 - sae: 1933.4541 - sse: 2481.4138 - val_huber_loss: 0.1212 - val_loss: 0.3189 - val_mae: 0.3404 - val_mse: 0.2592 - val_pearson_correlation: -1.8106e-16 - val_r2_keras: -33.2503 - val_rmse: 0.9530 - val_sae: 361.3447 - val_sse: 480.4676 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0419 - loss: 0.2396 - mae: 0.1797 - mse: 0.0842 - pearson_correlation: 8.2284e-17 - r2_keras: -109.1206 - rmse: 0.9132 - sae: 2643.7285 - sse: 3415.8032\n","Epoch 52: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0334 - loss: 0.2344 - mae: 0.1659 - mse: 0.0737 - pearson_correlation: 3.9688e-17 - r2_keras: -89.9326 - rmse: 0.9044 - sae: 1933.8595 - sse: 2482.6995 - val_huber_loss: 0.1213 - val_loss: 0.3190 - val_mae: 0.3405 - val_mse: 0.2595 - val_pearson_correlation: 1.3591e-16 - val_r2_keras: -33.2310 - val_rmse: 0.9528 - val_sae: 361.2321 - val_sse: 480.1960 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0418 - loss: 0.2395 - mae: 0.1794 - mse: 0.0840 - pearson_correlation: -1.9727e-16 - r2_keras: -109.1212 - rmse: 0.9132 - sae: 2643.7864 - sse: 3415.8225\n","Epoch 53: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0333 - loss: 0.2343 - mae: 0.1657 - mse: 0.0736 - pearson_correlation: -1.9471e-16 - r2_keras: -89.9335 - rmse: 0.9044 - sae: 1933.8937 - sse: 2482.7170 - val_huber_loss: 0.1214 - val_loss: 0.3191 - val_mae: 0.3408 - val_mse: 0.2598 - val_pearson_correlation: -1.3593e-16 - val_r2_keras: -33.2286 - val_rmse: 0.9527 - val_sae: 361.2445 - val_sse: 480.1627 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0418 - loss: 0.2394 - mae: 0.1792 - mse: 0.0839 - pearson_correlation: 1.0941e-16 - r2_keras: -109.1494 - rmse: 0.9133 - sae: 2643.9856 - sse: 3416.6958\n","Epoch 54: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0332 - loss: 0.2342 - mae: 0.1654 - mse: 0.0734 - pearson_correlation: 7.7998e-17 - r2_keras: -89.9547 - rmse: 0.9045 - sae: 1934.0314 - sse: 2483.3289 - val_huber_loss: 0.1214 - val_loss: 0.3191 - val_mae: 0.3407 - val_mse: 0.2597 - val_pearson_correlation: -1.8123e-16 - val_r2_keras: -33.2297 - val_rmse: 0.9527 - val_sae: 361.2519 - val_sse: 480.1785 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0417 - loss: 0.2394 - mae: 0.1790 - mse: 0.0838 - pearson_correlation: 1.6863e-17 - r2_keras: -109.2081 - rmse: 0.9136 - sae: 2644.5483 - sse: 3418.5176\n","Epoch 55: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0332 - loss: 0.2342 - mae: 0.1652 - mse: 0.0733 - pearson_correlation: -3.4239e-17 - r2_keras: -89.9994 - rmse: 0.9047 - sae: 1934.4274 - sse: 2484.6077 - val_huber_loss: 0.1215 - val_loss: 0.3191 - val_mae: 0.3409 - val_mse: 0.2599 - val_pearson_correlation: -1.3595e-16 - val_r2_keras: -33.2248 - val_rmse: 0.9527 - val_sae: 361.2394 - val_sse: 480.1093 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0417 - loss: 0.2393 - mae: 0.1787 - mse: 0.0836 - pearson_correlation: -8.2013e-16 - r2_keras: -109.2179 - rmse: 0.9136 - sae: 2644.6492 - sse: 3418.8208\n","Epoch 56: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0331 - loss: 0.2341 - mae: 0.1650 - mse: 0.0732 - pearson_correlation: -5.4591e-16 - r2_keras: -90.0124 - rmse: 0.9048 - sae: 1934.5137 - sse: 2484.8865 - val_huber_loss: 0.1216 - val_loss: 0.3192 - val_mae: 0.3410 - val_mse: 0.2601 - val_pearson_correlation: 2.2673e-17 - val_r2_keras: -33.2096 - val_rmse: 0.9525 - val_sae: 361.1661 - val_sse: 479.8958 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0416 - loss: 0.2392 - mae: 0.1786 - mse: 0.0835 - pearson_correlation: 7.9824e-17 - r2_keras: -109.2195 - rmse: 0.9136 - sae: 2644.6094 - sse: 3418.8718\n","Epoch 57: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0331 - loss: 0.2340 - mae: 0.1648 - mse: 0.0731 - pearson_correlation: -1.6686e-17 - r2_keras: -90.0078 - rmse: 0.9047 - sae: 1934.4639 - sse: 2484.8538 - val_huber_loss: 0.1217 - val_loss: 0.3193 - val_mae: 0.3413 - val_mse: 0.2601 - val_pearson_correlation: -3.3956e-17 - val_r2_keras: -33.2454 - val_rmse: 0.9530 - val_sae: 361.3595 - val_sse: 480.3980 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0415 - loss: 0.2391 - mae: 0.1783 - mse: 0.0834 - pearson_correlation: -2.7041e-16 - r2_keras: -109.2705 - rmse: 0.9138 - sae: 2645.0850 - sse: 3420.4521\n","Epoch 58: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0330 - loss: 0.2339 - mae: 0.1645 - mse: 0.0729 - pearson_correlation: -2.3748e-16 - r2_keras: -90.0599 - rmse: 0.9050 - sae: 1934.8357 - sse: 2486.1196 - val_huber_loss: 0.1217 - val_loss: 0.3193 - val_mae: 0.3413 - val_mse: 0.2603 - val_pearson_correlation: 4.4206e-16 - val_r2_keras: -33.2131 - val_rmse: 0.9525 - val_sae: 361.1779 - val_sse: 479.9457 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0415 - loss: 0.2390 - mae: 0.1781 - mse: 0.0832 - pearson_correlation: 5.5340e-16 - r2_keras: -109.2807 - rmse: 0.9139 - sae: 2645.1780 - sse: 3420.7681\n","Epoch 59: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0330 - loss: 0.2338 - mae: 0.1643 - mse: 0.0728 - pearson_correlation: 3.3780e-16 - r2_keras: -90.0641 - rmse: 0.9050 - sae: 1934.8966 - sse: 2486.2993 - val_huber_loss: 0.1217 - val_loss: 0.3193 - val_mae: 0.3414 - val_mse: 0.2603 - val_pearson_correlation: -6.8004e-17 - val_r2_keras: -33.2153 - val_rmse: 0.9525 - val_sae: 361.2236 - val_sse: 479.9756 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0414 - loss: 0.2389 - mae: 0.1778 - mse: 0.0831 - pearson_correlation: 4.4301e-16 - r2_keras: -109.2967 - rmse: 0.9139 - sae: 2645.4272 - sse: 3421.2659\n","Epoch 60: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0329 - loss: 0.2338 - mae: 0.1641 - mse: 0.0727 - pearson_correlation: 3.3656e-16 - r2_keras: -90.0771 - rmse: 0.9051 - sae: 1935.0565 - sse: 2486.6587 - val_huber_loss: 0.1219 - val_loss: 0.3195 - val_mae: 0.3416 - val_mse: 0.2607 - val_pearson_correlation: 2.2673e-17 - val_r2_keras: -33.2102 - val_rmse: 0.9525 - val_sae: 361.2064 - val_sse: 479.9046 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0413 - loss: 0.2389 - mae: 0.1777 - mse: 0.0830 - pearson_correlation: 3.7904e-16 - r2_keras: -109.2985 - rmse: 0.9139 - sae: 2645.3281 - sse: 3421.3220\n","Epoch 61: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0329 - loss: 0.2337 - mae: 0.1639 - mse: 0.0726 - pearson_correlation: 2.0305e-16 - r2_keras: -90.0778 - rmse: 0.9051 - sae: 1934.9824 - sse: 2486.6904 - val_huber_loss: 0.1218 - val_loss: 0.3193 - val_mae: 0.3416 - val_mse: 0.2604 - val_pearson_correlation: -3.8498e-16 - val_r2_keras: -33.2369 - val_rmse: 0.9528 - val_sae: 361.3348 - val_sse: 480.2787 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0413 - loss: 0.2388 - mae: 0.1774 - mse: 0.0829 - pearson_correlation: -3.9439e-18 - r2_keras: -109.4013 - rmse: 0.9144 - sae: 2646.2549 - sse: 3424.5115\n","Epoch 62: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0328 - loss: 0.2336 - mae: 0.1637 - mse: 0.0725 - pearson_correlation: 6.2140e-17 - r2_keras: -90.1492 - rmse: 0.9054 - sae: 1935.6056 - sse: 2488.8503 - val_huber_loss: 0.1221 - val_loss: 0.3196 - val_mae: 0.3421 - val_mse: 0.2610 - val_pearson_correlation: -1.4724e-16 - val_r2_keras: -33.2304 - val_rmse: 0.9527 - val_sae: 361.3310 - val_sse: 480.1873 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0412 - loss: 0.2387 - mae: 0.1772 - mse: 0.0827 - pearson_correlation: 4.2489e-16 - r2_keras: -109.4008 - rmse: 0.9144 - sae: 2646.1709 - sse: 3424.4946\n","Epoch 63: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0327 - loss: 0.2336 - mae: 0.1635 - mse: 0.0723 - pearson_correlation: 2.3537e-16 - r2_keras: -90.1685 - rmse: 0.9056 - sae: 1935.6244 - sse: 2489.0696 - val_huber_loss: 0.1220 - val_loss: 0.3195 - val_mae: 0.3421 - val_mse: 0.2609 - val_pearson_correlation: 2.2661e-17 - val_r2_keras: -33.2221 - val_rmse: 0.9526 - val_sae: 361.2689 - val_sse: 480.0712 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0412 - loss: 0.2386 - mae: 0.1770 - mse: 0.0826 - pearson_correlation: -1.3302e-16 - r2_keras: -109.4130 - rmse: 0.9144 - sae: 2646.2183 - sse: 3424.8728\n","Epoch 64: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0327 - loss: 0.2335 - mae: 0.1632 - mse: 0.0722 - pearson_correlation: -1.3911e-16 - r2_keras: -90.1695 - rmse: 0.9055 - sae: 1935.6122 - sse: 2489.2373 - val_huber_loss: 0.1221 - val_loss: 0.3196 - val_mae: 0.3422 - val_mse: 0.2610 - val_pearson_correlation: 4.5331e-17 - val_r2_keras: -33.2178 - val_rmse: 0.9526 - val_sae: 361.2392 - val_sse: 480.0107 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0411 - loss: 0.2386 - mae: 0.1768 - mse: 0.0824 - pearson_correlation: 4.6002e-17 - r2_keras: -109.4218 - rmse: 0.9144 - sae: 2646.3267 - sse: 3425.1465\n","Epoch 65: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0326 - loss: 0.2334 - mae: 0.1631 - mse: 0.0721 - pearson_correlation: 3.4869e-17 - r2_keras: -90.1827 - rmse: 0.9056 - sae: 1935.7207 - sse: 2489.5063 - val_huber_loss: 0.1222 - val_loss: 0.3197 - val_mae: 0.3423 - val_mse: 0.2613 - val_pearson_correlation: 2.9479e-16 - val_r2_keras: -33.2070 - val_rmse: 0.9524 - val_sae: 361.2027 - val_sse: 479.8596 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0410 - loss: 0.2385 - mae: 0.1766 - mse: 0.0823 - pearson_correlation: -5.6502e-17 - r2_keras: -109.4455 - rmse: 0.9145 - sae: 2646.5920 - sse: 3425.8799\n","Epoch 66: val_loss did not improve from 0.30540\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0326 - loss: 0.2333 - mae: 0.1629 - mse: 0.0720 - pearson_correlation: -6.7077e-17 - r2_keras: -90.1965 - rmse: 0.9057 - sae: 1935.8766 - sse: 2489.9717 - val_huber_loss: 0.1223 - val_loss: 0.3197 - val_mae: 0.3425 - val_mse: 0.2612 - val_pearson_correlation: 2.2656e-17 - val_r2_keras: -33.2268 - val_rmse: 0.9527 - val_sae: 361.3146 - val_sse: 480.1373 - learning_rate: 1.0000e-05\n","| \u001b[39m7        \u001b[39m | \u001b[39m-0.3197  \u001b[39m | \u001b[39m0.002471 \u001b[39m | \u001b[39m93.31    \u001b[39m | \u001b[39m80.55    \u001b[39m | \u001b[39m60.55    \u001b[39m | \u001b[39m17.44    \u001b[39m | \u001b[39m23.66    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 0.5329 - loss: 0.6798 - mae: 0.8432 - mse: 1.8718 - pearson_correlation: 2.8404e-16 - r2_keras: -341.5961 - rmse: 1.6107 - sae: 4366.6460 - sse: 10626.9033\n","Epoch 1: val_loss improved from inf to 0.39906, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 631ms/step - huber_loss: 0.5927 - loss: 0.7161 - mae: 0.8999 - mse: 1.8952 - pearson_correlation: 3.1717e-16 - r2_keras: -267.8101 - rmse: 1.5228 - sae: 3177.2429 - sse: 7558.6450 - val_huber_loss: 0.2522 - val_loss: 0.3991 - val_mae: 0.5914 - val_mse: 0.6260 - val_pearson_correlation: 2.4511e-16 - val_r2_keras: -22.0338 - val_rmse: 0.7815 - val_sae: 310.7322 - val_sse: 323.1208 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.4495 - loss: 0.5964 - mae: 0.7306 - mse: 1.5505 - pearson_correlation: 2.7438e-17 - r2_keras: -289.9942 - rmse: 1.4845 - sae: 3906.3757 - sse: 9026.2754\n","Epoch 2: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.4833 - loss: 0.6169 - mae: 0.7740 - mse: 1.5210 - pearson_correlation: 1.3171e-16 - r2_keras: -224.7147 - rmse: 1.3874 - sae: 2841.1694 - sse: 6389.5771 - val_huber_loss: 0.2552 - val_loss: 0.4021 - val_mae: 0.5680 - val_mse: 0.6609 - val_pearson_correlation: -2.1937e-16 - val_r2_keras: -22.4221 - val_rmse: 0.7881 - val_sae: 295.3347 - val_sse: 328.5671 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.4004 - loss: 0.5473 - mae: 0.6614 - mse: 1.3457 - pearson_correlation: -1.2234e-17 - r2_keras: -259.4264 - rmse: 1.4043 - sae: 3706.9141 - sse: 8078.0996\n","Epoch 3: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.4154 - loss: 0.5564 - mae: 0.6930 - mse: 1.2955 - pearson_correlation: -4.2792e-17 - r2_keras: -201.9090 - rmse: 1.3184 - sae: 2698.1155 - sse: 5728.9893 - val_huber_loss: 0.2615 - val_loss: 0.4084 - val_mae: 0.5568 - val_mse: 0.6972 - val_pearson_correlation: 1.1975e-16 - val_r2_keras: -23.2028 - val_rmse: 0.8011 - val_sae: 284.2714 - val_sse: 339.5192 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.3619 - loss: 0.5087 - mae: 0.6102 - mse: 1.1649 - pearson_correlation: -2.6031e-16 - r2_keras: -231.3296 - rmse: 1.3264 - sae: 3506.3110 - sse: 7206.5732\n","Epoch 4: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.3673 - loss: 0.5120 - mae: 0.6372 - mse: 1.1103 - pearson_correlation: -9.3208e-17 - r2_keras: -179.0225 - rmse: 1.2383 - sae: 2546.8726 - sse: 5099.2295 - val_huber_loss: 0.2685 - val_loss: 0.4153 - val_mae: 0.5556 - val_mse: 0.7270 - val_pearson_correlation: 5.4956e-16 - val_r2_keras: -24.1469 - val_rmse: 0.8166 - val_sae: 279.4211 - val_sse: 352.7633 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3312 - loss: 0.4781 - mae: 0.5709 - mse: 1.0190 - pearson_correlation: 3.1623e-17 - r2_keras: -209.4028 - rmse: 1.2623 - sae: 3375.2383 - sse: 6526.4331\n","Epoch 5: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.3314 - loss: 0.4782 - mae: 0.5930 - mse: 0.9649 - pearson_correlation: 1.1422e-16 - r2_keras: -161.8371 - rmse: 1.1770 - sae: 2449.5002 - sse: 4615.6846 - val_huber_loss: 0.2783 - val_loss: 0.4251 - val_mae: 0.5555 - val_mse: 0.7564 - val_pearson_correlation: -1.9897e-16 - val_r2_keras: -25.3989 - val_rmse: 0.8367 - val_sae: 283.0475 - val_sse: 370.3264 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3063 - loss: 0.4531 - mae: 0.5442 - mse: 0.9171 - pearson_correlation: -4.6247e-16 - r2_keras: -193.1818 - rmse: 1.2127 - sae: 3266.0908 - sse: 6023.2759\n","Epoch 6: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.3018 - loss: 0.4504 - mae: 0.5632 - mse: 0.8616 - pearson_correlation: -1.9516e-16 - r2_keras: -149.2169 - rmse: 1.1302 - sae: 2369.5754 - sse: 4259.0605 - val_huber_loss: 0.2821 - val_loss: 0.4289 - val_mae: 0.5490 - val_mse: 0.7644 - val_pearson_correlation: -2.7088e-16 - val_r2_keras: -26.5927 - val_rmse: 0.8554 - val_sae: 292.8656 - val_sse: 387.0738 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2833 - loss: 0.4302 - mae: 0.5226 - mse: 0.8243 - pearson_correlation: 1.7528e-16 - r2_keras: -178.2677 - rmse: 1.1652 - sae: 3175.8711 - sse: 5560.6582\n","Epoch 7: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2746 - loss: 0.4249 - mae: 0.5374 - mse: 0.7692 - pearson_correlation: 1.8912e-16 - r2_keras: -138.1929 - rmse: 1.0901 - sae: 2304.8123 - sse: 3937.9663 - val_huber_loss: 0.2861 - val_loss: 0.4329 - val_mae: 0.5472 - val_mse: 0.7768 - val_pearson_correlation: 2.9034e-16 - val_r2_keras: -27.9788 - val_rmse: 0.8766 - val_sae: 306.6240 - val_sse: 406.5181 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2789 - loss: 0.4257 - mae: 0.5184 - mse: 0.8067 - pearson_correlation: -1.8801e-16 - r2_keras: -175.4642 - rmse: 1.1560 - sae: 3158.0381 - sse: 5473.6982\n","Epoch 8: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2695 - loss: 0.4200 - mae: 0.5325 - mse: 0.7519 - pearson_correlation: -4.3028e-17 - r2_keras: -136.0736 - rmse: 1.0820 - sae: 2291.7534 - sse: 3877.0562 - val_huber_loss: 0.2949 - val_loss: 0.4417 - val_mae: 0.5637 - val_mse: 0.7968 - val_pearson_correlation: -1.6520e-17 - val_r2_keras: -29.4547 - val_rmse: 0.8987 - val_sae: 321.8390 - val_sse: 427.2213 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2748 - loss: 0.4216 - mae: 0.5147 - mse: 0.7910 - pearson_correlation: 4.7453e-17 - r2_keras: -172.9598 - rmse: 1.1478 - sae: 3141.5679 - sse: 5396.0156\n","Epoch 9: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2647 - loss: 0.4155 - mae: 0.5281 - mse: 0.7363 - pearson_correlation: 1.5805e-16 - r2_keras: -134.1777 - rmse: 1.0747 - sae: 2279.7944 - sse: 3822.6135 - val_huber_loss: 0.2917 - val_loss: 0.4385 - val_mae: 0.5717 - val_mse: 0.7677 - val_pearson_correlation: -1.2076e-16 - val_r2_keras: -29.8272 - val_rmse: 0.9041 - val_sae: 327.2252 - val_sse: 432.4466 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2707 - loss: 0.4175 - mae: 0.5112 - mse: 0.7748 - pearson_correlation: 1.1660e-16 - r2_keras: -170.3425 - rmse: 1.1391 - sae: 3125.8562 - sse: 5314.8301\n","Epoch 10: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2600 - loss: 0.4110 - mae: 0.5239 - mse: 0.7207 - pearson_correlation: -1.1533e-16 - r2_keras: -132.2403 - rmse: 1.0673 - sae: 2268.5259 - sse: 3766.2310 - val_huber_loss: 0.2721 - val_loss: 0.4189 - val_mae: 0.5614 - val_mse: 0.6827 - val_pearson_correlation: -4.9838e-17 - val_r2_keras: -29.7414 - val_rmse: 0.9029 - val_sae: 327.4146 - val_sse: 431.2441 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2667 - loss: 0.4135 - mae: 0.5078 - mse: 0.7592 - pearson_correlation: 1.9994e-16 - r2_keras: -167.7915 - rmse: 1.1306 - sae: 3110.7500 - sse: 5235.7017\n","Epoch 11: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2555 - loss: 0.4068 - mae: 0.5199 - mse: 0.7056 - pearson_correlation: 9.2414e-17 - r2_keras: -130.3524 - rmse: 1.0601 - sae: 2257.7354 - sse: 3711.2825 - val_huber_loss: 0.2596 - val_loss: 0.4064 - val_mae: 0.5555 - val_mse: 0.6234 - val_pearson_correlation: 5.0187e-16 - val_r2_keras: -30.1691 - val_rmse: 0.9091 - val_sae: 337.7102 - val_sse: 437.2439 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.2629 - loss: 0.4097 - mae: 0.5045 - mse: 0.7437 - pearson_correlation: -7.9322e-17 - r2_keras: -165.3700 - rmse: 1.1225 - sae: 3096.9368 - sse: 5160.5894\n","Epoch 12: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2512 - loss: 0.4026 - mae: 0.5159 - mse: 0.6907 - pearson_correlation: 6.1288e-17 - r2_keras: -128.5791 - rmse: 1.0534 - sae: 2247.9526 - sse: 3659.3430 - val_huber_loss: 0.2649 - val_loss: 0.4118 - val_mae: 0.5755 - val_mse: 0.6212 - val_pearson_correlation: 3.2807e-16 - val_r2_keras: -31.9433 - val_rmse: 0.9347 - val_sae: 355.9640 - val_sse: 462.1321 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2609 - loss: 0.4077 - mae: 0.5027 - mse: 0.7353 - pearson_correlation: 1.2075e-16 - r2_keras: -164.0497 - rmse: 1.1180 - sae: 3090.3110 - sse: 5119.6348\n","Epoch 13: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2489 - loss: 0.4005 - mae: 0.5139 - mse: 0.6827 - pearson_correlation: 6.1378e-17 - r2_keras: -127.6063 - rmse: 1.0497 - sae: 2243.1882 - sse: 3630.9539 - val_huber_loss: 0.2745 - val_loss: 0.4213 - val_mae: 0.5941 - val_mse: 0.6419 - val_pearson_correlation: 2.6634e-16 - val_r2_keras: -34.7147 - val_rmse: 0.9732 - val_sae: 375.9028 - val_sse: 501.0100 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2589 - loss: 0.4057 - mae: 0.5008 - mse: 0.7269 - pearson_correlation: -4.1009e-16 - r2_keras: -162.7770 - rmse: 1.1137 - sae: 3083.6951 - sse: 5080.1572\n","Epoch 14: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2467 - loss: 0.3983 - mae: 0.5118 - mse: 0.6747 - pearson_correlation: -2.1253e-16 - r2_keras: -126.6646 - rmse: 1.0460 - sae: 2238.4185 - sse: 3603.5413 - val_huber_loss: 0.2867 - val_loss: 0.4335 - val_mae: 0.6076 - val_mse: 0.6804 - val_pearson_correlation: 1.2449e-16 - val_r2_keras: -37.4947 - val_rmse: 1.0104 - val_sae: 393.8142 - val_sse: 540.0085 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2569 - loss: 0.4037 - mae: 0.4992 - mse: 0.7180 - pearson_correlation: -5.5086e-16 - r2_keras: -161.3219 - rmse: 1.1087 - sae: 3075.5383 - sse: 5035.0234\n","Epoch 15: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.2444 - loss: 0.3961 - mae: 0.5099 - mse: 0.6665 - pearson_correlation: -4.1554e-16 - r2_keras: -125.6016 - rmse: 1.0420 - sae: 2232.6294 - sse: 3572.3623 - val_huber_loss: 0.2980 - val_loss: 0.4448 - val_mae: 0.6144 - val_mse: 0.7219 - val_pearson_correlation: -1.1738e-16 - val_r2_keras: -40.1802 - val_rmse: 1.0450 - val_sae: 408.5069 - val_sse: 577.6803 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2548 - loss: 0.4017 - mae: 0.4975 - mse: 0.7092 - pearson_correlation: 5.5825e-16 - r2_keras: -159.9564 - rmse: 1.1040 - sae: 3068.6377 - sse: 4992.6670\n","Epoch 16: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.2422 - loss: 0.3940 - mae: 0.5079 - mse: 0.6582 - pearson_correlation: 2.3301e-16 - r2_keras: -124.6000 - rmse: 1.0381 - sae: 2227.7034 - sse: 3543.0542 - val_huber_loss: 0.3071 - val_loss: 0.4540 - val_mae: 0.6177 - val_mse: 0.7566 - val_pearson_correlation: 9.6730e-17 - val_r2_keras: -42.2878 - val_rmse: 1.0714 - val_sae: 419.7727 - val_sse: 607.2455 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2527 - loss: 0.3996 - mae: 0.4955 - mse: 0.7003 - pearson_correlation: 5.1000e-16 - r2_keras: -158.6084 - rmse: 1.0994 - sae: 3061.8140 - sse: 4950.8535\n","Epoch 17: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2398 - loss: 0.3917 - mae: 0.5056 - mse: 0.6497 - pearson_correlation: 3.6440e-16 - r2_keras: -123.6101 - rmse: 1.0343 - sae: 2222.8447 - sse: 3514.1082 - val_huber_loss: 0.3140 - val_loss: 0.4609 - val_mae: 0.6208 - val_mse: 0.7820 - val_pearson_correlation: -3.1844e-16 - val_r2_keras: -43.7240 - val_rmse: 1.0890 - val_sae: 427.4611 - val_sse: 627.3929 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.2506 - loss: 0.3975 - mae: 0.4936 - mse: 0.6913 - pearson_correlation: 2.0528e-16 - r2_keras: -157.1669 - rmse: 1.0944 - sae: 3054.4666 - sse: 4906.1406\n","Epoch 18: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.2374 - loss: 0.3894 - mae: 0.5034 - mse: 0.6411 - pearson_correlation: 1.7120e-16 - r2_keras: -122.5530 - rmse: 1.0301 - sae: 2217.6138 - sse: 3483.1721 - val_huber_loss: 0.3188 - val_loss: 0.4656 - val_mae: 0.6262 - val_mse: 0.7981 - val_pearson_correlation: 5.0436e-17 - val_r2_keras: -44.6434 - val_rmse: 1.1002 - val_sae: 432.4871 - val_sse: 640.2906 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.2485 - loss: 0.3954 - mae: 0.4917 - mse: 0.6821 - pearson_correlation: 5.3310e-16 - r2_keras: -155.7392 - rmse: 1.0895 - sae: 3047.6108 - sse: 4861.8550\n","Epoch 19: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2350 - loss: 0.3871 - mae: 0.5012 - mse: 0.6325 - pearson_correlation: 4.2943e-16 - r2_keras: -121.4996 - rmse: 1.0260 - sae: 2212.6892 - sse: 3452.4573 - val_huber_loss: 0.3211 - val_loss: 0.4680 - val_mae: 0.6287 - val_mse: 0.8056 - val_pearson_correlation: 2.6255e-16 - val_r2_keras: -45.1477 - val_rmse: 1.1062 - val_sae: 435.4513 - val_sse: 647.3649 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2464 - loss: 0.3932 - mae: 0.4897 - mse: 0.6731 - pearson_correlation: -1.7801e-16 - r2_keras: -154.3931 - rmse: 1.0848 - sae: 3041.0398 - sse: 4820.0991\n","Epoch 20: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2326 - loss: 0.3849 - mae: 0.4989 - mse: 0.6240 - pearson_correlation: -1.1868e-16 - r2_keras: -120.5201 - rmse: 1.0222 - sae: 2207.9973 - sse: 3423.6565 - val_huber_loss: 0.3226 - val_loss: 0.4694 - val_mae: 0.6304 - val_mse: 0.8094 - val_pearson_correlation: 1.2888e-16 - val_r2_keras: -45.3311 - val_rmse: 1.1084 - val_sae: 436.9616 - val_sse: 649.9372 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2444 - loss: 0.3912 - mae: 0.4879 - mse: 0.6645 - pearson_correlation: -5.0417e-17 - r2_keras: -152.9931 - rmse: 1.0799 - sae: 3033.4575 - sse: 4776.6729\n","Epoch 21: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2303 - loss: 0.3826 - mae: 0.4968 - mse: 0.6159 - pearson_correlation: 3.7857e-17 - r2_keras: -119.4923 - rmse: 1.0181 - sae: 2202.6101 - sse: 3393.5974 - val_huber_loss: 0.3229 - val_loss: 0.4697 - val_mae: 0.6308 - val_mse: 0.8087 - val_pearson_correlation: 2.9107e-17 - val_r2_keras: -45.3787 - val_rmse: 1.1090 - val_sae: 437.8714 - val_sse: 650.6057 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2423 - loss: 0.3891 - mae: 0.4858 - mse: 0.6559 - pearson_correlation: -5.9409e-18 - r2_keras: -151.7086 - rmse: 1.0754 - sae: 3026.9648 - sse: 4736.8311\n","Epoch 22: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2280 - loss: 0.3804 - mae: 0.4945 - mse: 0.6079 - pearson_correlation: -1.3753e-16 - r2_keras: -118.5594 - rmse: 1.0145 - sae: 2198.0010 - sse: 3366.1379 - val_huber_loss: 0.3224 - val_loss: 0.4692 - val_mae: 0.6304 - val_mse: 0.8048 - val_pearson_correlation: -4.2924e-16 - val_r2_keras: -45.3285 - val_rmse: 1.1084 - val_sae: 438.4439 - val_sse: 649.9013 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2402 - loss: 0.3871 - mae: 0.4841 - mse: 0.6474 - pearson_correlation: -2.0125e-16 - r2_keras: -150.3586 - rmse: 1.0706 - sae: 3019.8262 - sse: 4694.9546\n","Epoch 23: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2258 - loss: 0.3783 - mae: 0.4924 - mse: 0.5999 - pearson_correlation: -2.2134e-16 - r2_keras: -117.5918 - rmse: 1.0107 - sae: 2192.9958 - sse: 3337.4282 - val_huber_loss: 0.3219 - val_loss: 0.4688 - val_mae: 0.6301 - val_mse: 0.8014 - val_pearson_correlation: 5.8577e-17 - val_r2_keras: -45.1634 - val_rmse: 1.1064 - val_sae: 438.3578 - val_sse: 647.5850 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2382 - loss: 0.3850 - mae: 0.4822 - mse: 0.6390 - pearson_correlation: -2.1974e-16 - r2_keras: -149.0404 - rmse: 1.0659 - sae: 3012.9019 - sse: 4654.0654\n","Epoch 24: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2236 - loss: 0.3761 - mae: 0.4902 - mse: 0.5920 - pearson_correlation: -1.1617e-16 - r2_keras: -116.6337 - rmse: 1.0070 - sae: 2188.0847 - sse: 3309.2388 - val_huber_loss: 0.3214 - val_loss: 0.4682 - val_mae: 0.6297 - val_mse: 0.7969 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -45.0007 - val_rmse: 1.1045 - val_sae: 438.3121 - val_sse: 645.3021 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2362 - loss: 0.3830 - mae: 0.4803 - mse: 0.6307 - pearson_correlation: -1.2298e-16 - r2_keras: -147.7368 - rmse: 1.0613 - sae: 3006.0820 - sse: 4613.6309\n","Epoch 25: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2213 - loss: 0.3740 - mae: 0.4880 - mse: 0.5841 - pearson_correlation: -1.5982e-16 - r2_keras: -115.6911 - rmse: 1.0032 - sae: 2183.2710 - sse: 3281.4192 - val_huber_loss: 0.3204 - val_loss: 0.4672 - val_mae: 0.6289 - val_mse: 0.7912 - val_pearson_correlation: -5.4457e-16 - val_r2_keras: -44.8071 - val_rmse: 1.1021 - val_sae: 438.1229 - val_sse: 642.5871 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2342 - loss: 0.3810 - mae: 0.4783 - mse: 0.6223 - pearson_correlation: -1.6979e-16 - r2_keras: -146.4506 - rmse: 1.0567 - sae: 2999.4612 - sse: 4573.7324\n","Epoch 26: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2191 - loss: 0.3718 - mae: 0.4857 - mse: 0.5763 - pearson_correlation: -1.6587e-16 - r2_keras: -114.7650 - rmse: 0.9996 - sae: 2178.5894 - sse: 3254.0159 - val_huber_loss: 0.3191 - val_loss: 0.4660 - val_mae: 0.6275 - val_mse: 0.7851 - val_pearson_correlation: -8.0629e-17 - val_r2_keras: -44.5827 - val_rmse: 1.0994 - val_sae: 437.7800 - val_sse: 639.4395 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2321 - loss: 0.3789 - mae: 0.4761 - mse: 0.6139 - pearson_correlation: 8.3479e-17 - r2_keras: -145.1574 - rmse: 1.0521 - sae: 2992.4006 - sse: 4533.6206\n","Epoch 27: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2168 - loss: 0.3696 - mae: 0.4832 - mse: 0.5684 - pearson_correlation: 6.4179e-17 - r2_keras: -113.8443 - rmse: 0.9960 - sae: 2173.6370 - sse: 3226.5872 - val_huber_loss: 0.3180 - val_loss: 0.4648 - val_mae: 0.6265 - val_mse: 0.7789 - val_pearson_correlation: 9.3897e-17 - val_r2_keras: -44.3396 - val_rmse: 1.0965 - val_sae: 437.3986 - val_sse: 636.0294 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2299 - loss: 0.3767 - mae: 0.4740 - mse: 0.6049 - pearson_correlation: 5.2249e-18 - r2_keras: -143.7715 - rmse: 1.0471 - sae: 2985.4575 - sse: 4490.6309\n","Epoch 28: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2145 - loss: 0.3673 - mae: 0.4807 - mse: 0.5601 - pearson_correlation: -3.3717e-18 - r2_keras: -112.8403 - rmse: 0.9920 - sae: 2168.6958 - sse: 3196.9885 - val_huber_loss: 0.3169 - val_loss: 0.4638 - val_mae: 0.6255 - val_mse: 0.7733 - val_pearson_correlation: -8.5755e-18 - val_r2_keras: -44.1591 - val_rmse: 1.0943 - val_sae: 437.2887 - val_sse: 633.4967 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2278 - loss: 0.3746 - mae: 0.4717 - mse: 0.5962 - pearson_correlation: 1.1050e-16 - r2_keras: -142.3644 - rmse: 1.0420 - sae: 2977.8506 - sse: 4446.9849\n","Epoch 29: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.2121 - loss: 0.3651 - mae: 0.4781 - mse: 0.5518 - pearson_correlation: 2.1490e-16 - r2_keras: -111.8233 - rmse: 0.9879 - sae: 2163.3135 - sse: 3166.9648 - val_huber_loss: 0.3161 - val_loss: 0.4630 - val_mae: 0.6249 - val_mse: 0.7691 - val_pearson_correlation: -2.6274e-16 - val_r2_keras: -43.9596 - val_rmse: 1.0919 - val_sae: 436.9394 - val_sse: 630.6989 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.2257 - loss: 0.3725 - mae: 0.4694 - mse: 0.5876 - pearson_correlation: -1.1293e-16 - r2_keras: -140.9765 - rmse: 1.0369 - sae: 2970.7444 - sse: 4403.9346\n","Epoch 30: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2098 - loss: 0.3629 - mae: 0.4755 - mse: 0.5437 - pearson_correlation: 1.8151e-17 - r2_keras: -110.8252 - rmse: 0.9839 - sae: 2158.2971 - sse: 3137.4104 - val_huber_loss: 0.3152 - val_loss: 0.4620 - val_mae: 0.6240 - val_mse: 0.7639 - val_pearson_correlation: -4.3256e-16 - val_r2_keras: -43.7911 - val_rmse: 1.0899 - val_sae: 436.7935 - val_sse: 628.3349 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2237 - loss: 0.3705 - mae: 0.4673 - mse: 0.5792 - pearson_correlation: 1.0464e-16 - r2_keras: -139.6367 - rmse: 1.0320 - sae: 2963.5762 - sse: 4362.3755\n","Epoch 31: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.2076 - loss: 0.3607 - mae: 0.4730 - mse: 0.5359 - pearson_correlation: 1.0105e-16 - r2_keras: -109.8595 - rmse: 0.9800 - sae: 2153.2373 - sse: 3108.8538 - val_huber_loss: 0.3141 - val_loss: 0.4609 - val_mae: 0.6230 - val_mse: 0.7584 - val_pearson_correlation: 2.6940e-16 - val_r2_keras: -43.6124 - val_rmse: 1.0877 - val_sae: 436.5754 - val_sse: 625.8276 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2217 - loss: 0.3685 - mae: 0.4651 - mse: 0.5714 - pearson_correlation: -3.8394e-16 - r2_keras: -138.3976 - rmse: 1.0274 - sae: 2956.5483 - sse: 4323.9399\n","Epoch 32: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2055 - loss: 0.3586 - mae: 0.4705 - mse: 0.5286 - pearson_correlation: -1.9488e-16 - r2_keras: -108.9737 - rmse: 0.9765 - sae: 2148.3074 - sse: 3082.5295 - val_huber_loss: 0.3130 - val_loss: 0.4599 - val_mae: 0.6218 - val_mse: 0.7531 - val_pearson_correlation: 2.3571e-16 - val_r2_keras: -43.4294 - val_rmse: 1.0854 - val_sae: 436.2825 - val_sse: 623.2601 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2199 - loss: 0.3667 - mae: 0.4631 - mse: 0.5645 - pearson_correlation: 8.1964e-17 - r2_keras: -137.3164 - rmse: 1.0235 - sae: 2950.2507 - sse: 4290.4014\n","Epoch 33: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2035 - loss: 0.3567 - mae: 0.4682 - mse: 0.5220 - pearson_correlation: 1.0896e-16 - r2_keras: -108.1897 - rmse: 0.9733 - sae: 2143.8430 - sse: 3059.4290 - val_huber_loss: 0.3124 - val_loss: 0.4592 - val_mae: 0.6210 - val_mse: 0.7493 - val_pearson_correlation: -3.5081e-17 - val_r2_keras: -43.2459 - val_rmse: 1.0832 - val_sae: 435.9138 - val_sse: 620.6860 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2180 - loss: 0.3648 - mae: 0.4612 - mse: 0.5574 - pearson_correlation: -1.6712e-16 - r2_keras: -136.1734 - rmse: 1.0192 - sae: 2943.3579 - sse: 4254.9463\n","Epoch 34: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2014 - loss: 0.3548 - mae: 0.4658 - mse: 0.5153 - pearson_correlation: -9.3820e-17 - r2_keras: -107.3658 - rmse: 0.9699 - sae: 2138.9771 - sse: 3035.0671 - val_huber_loss: 0.3114 - val_loss: 0.4582 - val_mae: 0.6198 - val_mse: 0.7443 - val_pearson_correlation: -7.0438e-17 - val_r2_keras: -43.1150 - val_rmse: 1.0816 - val_sae: 435.8663 - val_sse: 618.8502 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2161 - loss: 0.3629 - mae: 0.4594 - mse: 0.5502 - pearson_correlation: 1.7680e-16 - r2_keras: -135.0080 - rmse: 1.0149 - sae: 2935.9092 - sse: 4218.7988\n","Epoch 35: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1993 - loss: 0.3527 - mae: 0.4636 - mse: 0.5085 - pearson_correlation: -3.5845e-17 - r2_keras: -106.5261 - rmse: 0.9665 - sae: 2133.7180 - sse: 3010.2312 - val_huber_loss: 0.3108 - val_loss: 0.4576 - val_mae: 0.6192 - val_mse: 0.7405 - val_pearson_correlation: 1.7684e-17 - val_r2_keras: -42.9679 - val_rmse: 1.0798 - val_sae: 435.7052 - val_sse: 616.7869 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2142 - loss: 0.3610 - mae: 0.4575 - mse: 0.5428 - pearson_correlation: -2.7415e-16 - r2_keras: -133.7964 - rmse: 1.0103 - sae: 2928.5576 - sse: 4181.2168\n","Epoch 36: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1972 - loss: 0.3507 - mae: 0.4613 - mse: 0.5014 - pearson_correlation: -2.4486e-16 - r2_keras: -105.6558 - rmse: 0.9630 - sae: 2128.5222 - sse: 2984.4429 - val_huber_loss: 0.3102 - val_loss: 0.4571 - val_mae: 0.6186 - val_mse: 0.7374 - val_pearson_correlation: -7.1034e-17 - val_r2_keras: -42.8084 - val_rmse: 1.0778 - val_sae: 435.4038 - val_sse: 614.5492 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2122 - loss: 0.3590 - mae: 0.4555 - mse: 0.5354 - pearson_correlation: -1.6386e-16 - r2_keras: -132.5812 - rmse: 1.0058 - sae: 2921.1533 - sse: 4143.5225\n","Epoch 37: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1952 - loss: 0.3487 - mae: 0.4589 - mse: 0.4946 - pearson_correlation: -1.8494e-16 - r2_keras: -104.7871 - rmse: 0.9594 - sae: 2123.3037 - sse: 2958.6262 - val_huber_loss: 0.3094 - val_loss: 0.4563 - val_mae: 0.6176 - val_mse: 0.7335 - val_pearson_correlation: 4.4538e-17 - val_r2_keras: -42.6895 - val_rmse: 1.0764 - val_sae: 435.2397 - val_sse: 612.8812 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.2102 - loss: 0.3571 - mae: 0.4536 - mse: 0.5281 - pearson_correlation: -1.3093e-16 - r2_keras: -131.4315 - rmse: 1.0014 - sae: 2914.4917 - sse: 4107.8594\n","Epoch 38: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1932 - loss: 0.3467 - mae: 0.4566 - mse: 0.4878 - pearson_correlation: -2.0882e-16 - r2_keras: -103.9710 - rmse: 0.9561 - sae: 2118.6353 - sse: 2934.2688 - val_huber_loss: 0.3086 - val_loss: 0.4554 - val_mae: 0.6166 - val_mse: 0.7296 - val_pearson_correlation: 3.8425e-16 - val_r2_keras: -42.5608 - val_rmse: 1.0748 - val_sae: 434.9935 - val_sse: 611.0751 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2083 - loss: 0.3552 - mae: 0.4516 - mse: 0.5209 - pearson_correlation: 3.1517e-17 - r2_keras: -130.3245 - rmse: 0.9973 - sae: 2908.2749 - sse: 4073.5217\n","Epoch 39: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1912 - loss: 0.3447 - mae: 0.4543 - mse: 0.4812 - pearson_correlation: -6.6868e-17 - r2_keras: -103.1813 - rmse: 0.9528 - sae: 2114.2444 - sse: 2910.7710 - val_huber_loss: 0.3078 - val_loss: 0.4546 - val_mae: 0.6156 - val_mse: 0.7262 - val_pearson_correlation: 1.7037e-16 - val_r2_keras: -42.4216 - val_rmse: 1.0731 - val_sae: 434.7004 - val_sse: 609.1223 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2064 - loss: 0.3533 - mae: 0.4495 - mse: 0.5140 - pearson_correlation: 1.1494e-16 - r2_keras: -129.1851 - rmse: 0.9929 - sae: 2901.3210 - sse: 4038.1802\n","Epoch 40: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1893 - loss: 0.3428 - mae: 0.4519 - mse: 0.4748 - pearson_correlation: 1.2341e-16 - r2_keras: -102.3750 - rmse: 0.9495 - sae: 2109.3716 - sse: 2886.6611 - val_huber_loss: 0.3068 - val_loss: 0.4536 - val_mae: 0.6144 - val_mse: 0.7222 - val_pearson_correlation: 8.0950e-17 - val_r2_keras: -42.3076 - val_rmse: 1.0717 - val_sae: 434.5318 - val_sse: 607.5241 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2046 - loss: 0.3514 - mae: 0.4476 - mse: 0.5072 - pearson_correlation: 1.6655e-16 - r2_keras: -128.1200 - rmse: 0.9888 - sae: 2894.9065 - sse: 4005.1411\n","Epoch 41: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1874 - loss: 0.3410 - mae: 0.4496 - mse: 0.4686 - pearson_correlation: 1.5523e-16 - r2_keras: -101.6258 - rmse: 0.9465 - sae: 2104.8801 - sse: 2864.1775 - val_huber_loss: 0.3058 - val_loss: 0.4526 - val_mae: 0.6131 - val_mse: 0.7183 - val_pearson_correlation: 1.8043e-16 - val_r2_keras: -42.1899 - val_rmse: 1.0702 - val_sae: 434.2932 - val_sse: 605.8722 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.2027 - loss: 0.3495 - mae: 0.4455 - mse: 0.5004 - pearson_correlation: -1.4554e-16 - r2_keras: -127.0849 - rmse: 0.9849 - sae: 2888.7776 - sse: 3973.0342\n","Epoch 42: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1856 - loss: 0.3391 - mae: 0.4473 - mse: 0.4624 - pearson_correlation: -1.2688e-16 - r2_keras: -100.8945 - rmse: 0.9435 - sae: 2100.5657 - sse: 2842.2881 - val_huber_loss: 0.3050 - val_loss: 0.4519 - val_mae: 0.6121 - val_mse: 0.7153 - val_pearson_correlation: -1.4477e-16 - val_r2_keras: -42.0742 - val_rmse: 1.0688 - val_sae: 434.0441 - val_sse: 604.2502 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2008 - loss: 0.3476 - mae: 0.4434 - mse: 0.4937 - pearson_correlation: -2.6314e-16 - r2_keras: -125.9659 - rmse: 0.9806 - sae: 2881.3647 - sse: 3938.3247\n","Epoch 43: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1837 - loss: 0.3372 - mae: 0.4449 - mse: 0.4562 - pearson_correlation: -9.5582e-17 - r2_keras: -100.1058 - rmse: 0.9402 - sae: 2095.3889 - sse: 2818.6477 - val_huber_loss: 0.3043 - val_loss: 0.4512 - val_mae: 0.6112 - val_mse: 0.7124 - val_pearson_correlation: -3.1744e-16 - val_r2_keras: -41.9919 - val_rmse: 1.0677 - val_sae: 433.9383 - val_sse: 603.0945 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1989 - loss: 0.3457 - mae: 0.4413 - mse: 0.4871 - pearson_correlation: 2.3003e-19 - r2_keras: -124.8879 - rmse: 0.9764 - sae: 2874.1802 - sse: 3904.8867\n","Epoch 44: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1819 - loss: 0.3354 - mae: 0.4425 - mse: 0.4502 - pearson_correlation: 1.2380e-16 - r2_keras: -99.3575 - rmse: 0.9372 - sae: 2090.4204 - sse: 2796.0081 - val_huber_loss: 0.3036 - val_loss: 0.4504 - val_mae: 0.6102 - val_mse: 0.7096 - val_pearson_correlation: 3.5452e-16 - val_r2_keras: -41.9051 - val_rmse: 1.0667 - val_sae: 433.7556 - val_sse: 601.8770 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1970 - loss: 0.3439 - mae: 0.4392 - mse: 0.4807 - pearson_correlation: 2.4154e-16 - r2_keras: -123.8439 - rmse: 0.9723 - sae: 2867.4077 - sse: 3872.5027\n","Epoch 45: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1801 - loss: 0.3335 - mae: 0.4402 - mse: 0.4444 - pearson_correlation: 2.1569e-16 - r2_keras: -98.6320 - rmse: 0.9342 - sae: 2085.7190 - sse: 2774.0723 - val_huber_loss: 0.3028 - val_loss: 0.4496 - val_mae: 0.6088 - val_mse: 0.7066 - val_pearson_correlation: 2.4591e-16 - val_r2_keras: -41.8348 - val_rmse: 1.0658 - val_sae: 433.6362 - val_sse: 600.8906 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1952 - loss: 0.3420 - mae: 0.4371 - mse: 0.4745 - pearson_correlation: 1.0694e-16 - r2_keras: -122.8428 - rmse: 0.9684 - sae: 2860.5278 - sse: 3841.4482\n","Epoch 46: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1783 - loss: 0.3317 - mae: 0.4378 - mse: 0.4388 - pearson_correlation: 7.0378e-17 - r2_keras: -97.9526 - rmse: 0.9315 - sae: 2081.0142 - sse: 2753.2292 - val_huber_loss: 0.3018 - val_loss: 0.4486 - val_mae: 0.6073 - val_mse: 0.7033 - val_pearson_correlation: 2.5533e-16 - val_r2_keras: -41.7863 - val_rmse: 1.0652 - val_sae: 433.5894 - val_sse: 600.2114 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1934 - loss: 0.3402 - mae: 0.4350 - mse: 0.4686 - pearson_correlation: -2.3491e-16 - r2_keras: -121.9166 - rmse: 0.9648 - sae: 2854.4475 - sse: 3812.7178\n","Epoch 47: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1766 - loss: 0.3300 - mae: 0.4355 - mse: 0.4334 - pearson_correlation: -2.3787e-16 - r2_keras: -97.3157 - rmse: 0.9289 - sae: 2076.8198 - sse: 2733.8477 - val_huber_loss: 0.3010 - val_loss: 0.4478 - val_mae: 0.6059 - val_mse: 0.7003 - val_pearson_correlation: 2.7388e-17 - val_r2_keras: -41.7542 - val_rmse: 1.0648 - val_sae: 433.6294 - val_sse: 599.7611 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1916 - loss: 0.3384 - mae: 0.4330 - mse: 0.4629 - pearson_correlation: 8.3202e-17 - r2_keras: -121.0105 - rmse: 0.9612 - sae: 2848.1338 - sse: 3784.6130\n","Epoch 48: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1749 - loss: 0.3282 - mae: 0.4332 - mse: 0.4282 - pearson_correlation: 2.2953e-16 - r2_keras: -96.7005 - rmse: 0.9265 - sae: 2072.5154 - sse: 2714.9805 - val_huber_loss: 0.3005 - val_loss: 0.4474 - val_mae: 0.6051 - val_mse: 0.6986 - val_pearson_correlation: 1.6456e-16 - val_r2_keras: -41.6906 - val_rmse: 1.0640 - val_sae: 433.4592 - val_sse: 598.8682 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1897 - loss: 0.3366 - mae: 0.4310 - mse: 0.4570 - pearson_correlation: -7.4111e-17 - r2_keras: -120.0067 - rmse: 0.9573 - sae: 2841.5278 - sse: 3753.4773\n","Epoch 49: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1732 - loss: 0.3265 - mae: 0.4310 - mse: 0.4229 - pearson_correlation: 9.8408e-17 - r2_keras: -96.0072 - rmse: 0.9236 - sae: 2067.9695 - sse: 2693.9404 - val_huber_loss: 0.2998 - val_loss: 0.4466 - val_mae: 0.6039 - val_mse: 0.6959 - val_pearson_correlation: -1.2813e-16 - val_r2_keras: -41.6613 - val_rmse: 1.0636 - val_sae: 433.5405 - val_sse: 598.4567 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1880 - loss: 0.3348 - mae: 0.4290 - mse: 0.4515 - pearson_correlation: -3.5544e-17 - r2_keras: -119.1023 - rmse: 0.9537 - sae: 2835.1382 - sse: 3725.4229\n","Epoch 50: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1715 - loss: 0.3247 - mae: 0.4287 - mse: 0.4179 - pearson_correlation: 2.9912e-17 - r2_keras: -95.3867 - rmse: 0.9211 - sae: 2063.5967 - sse: 2675.0322 - val_huber_loss: 0.2990 - val_loss: 0.4458 - val_mae: 0.6026 - val_mse: 0.6933 - val_pearson_correlation: 4.7642e-16 - val_r2_keras: -41.6192 - val_rmse: 1.0631 - val_sae: 433.5065 - val_sse: 597.8662 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1862 - loss: 0.3330 - mae: 0.4269 - mse: 0.4462 - pearson_correlation: 2.9611e-16 - r2_keras: -118.2393 - rmse: 0.9503 - sae: 2829.1465 - sse: 3698.6528\n","Epoch 51: val_loss did not improve from 0.39906\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1699 - loss: 0.3231 - mae: 0.4265 - mse: 0.4131 - pearson_correlation: 5.7988e-17 - r2_keras: -94.7980 - rmse: 0.9187 - sae: 2059.4885 - sse: 2657.0283 - val_huber_loss: 0.2984 - val_loss: 0.4452 - val_mae: 0.6014 - val_mse: 0.6914 - val_pearson_correlation: 2.5683e-16 - val_r2_keras: -41.5691 - val_rmse: 1.0625 - val_sae: 433.3732 - val_sse: 597.1636 - learning_rate: 1.0000e-05\n","| \u001b[39m8        \u001b[39m | \u001b[39m-0.4452  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m79.15    \u001b[39m | \u001b[39m52.9     \u001b[39m | \u001b[39m73.09    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m87.92    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 0.5655 - loss: 0.7619 - mae: 0.9408 - mse: 1.6296 - pearson_correlation: 2.1324e-16 - r2_keras: -326.7546 - rmse: 1.5755 - sae: 4946.1709 - sse: 10166.5381\n","Epoch 1: val_loss improved from inf to 0.44097, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 667ms/step - huber_loss: 0.5051 - loss: 0.7253 - mae: 0.8937 - mse: 1.5329 - pearson_correlation: -1.8514e-17 - r2_keras: -248.0252 - rmse: 1.4405 - sae: 3505.6404 - sse: 7135.7173 - val_huber_loss: 0.2440 - val_loss: 0.4410 - val_mae: 0.5484 - val_mse: 0.6256 - val_pearson_correlation: -6.9844e-17 - val_r2_keras: -22.9622 - val_rmse: 0.7971 - val_sae: 301.5199 - val_sse: 336.1450 - learning_rate: 0.0023\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4990 - loss: 0.6960 - mae: 0.8782 - mse: 1.3630 - pearson_correlation: 3.4076e-17 - r2_keras: -245.7121 - rmse: 1.3669 - sae: 4221.2920 - sse: 7652.7017\n","Epoch 2: val_loss improved from 0.44097 to 0.40701, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.3983 - loss: 0.6347 - mae: 0.8002 - mse: 1.1742 - pearson_correlation: -3.7277e-18 - r2_keras: -183.6860 - rmse: 1.2287 - sae: 3013.7322 - sse: 5338.8799 - val_huber_loss: 0.2100 - val_loss: 0.4070 - val_mae: 0.4502 - val_mse: 0.5538 - val_pearson_correlation: 1.1202e-16 - val_r2_keras: -24.5979 - val_rmse: 0.8239 - val_sae: 281.4739 - val_sse: 359.0903 - learning_rate: 0.0023\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2084 - loss: 0.4054 - mae: 0.5027 - mse: 0.4419 - pearson_correlation: 1.9689e-16 - r2_keras: -123.0328 - rmse: 0.9692 - sae: 2961.6313 - sse: 3847.3428\n","Epoch 3: val_loss did not improve from 0.40701\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.2028 - loss: 0.4020 - mae: 0.4937 - mse: 0.4441 - pearson_correlation: 2.1135e-16 - r2_keras: -108.7617 - rmse: 1.0136 - sae: 2182.7905 - sse: 2882.4646 - val_huber_loss: 0.2199 - val_loss: 0.4168 - val_mae: 0.4730 - val_mse: 0.5946 - val_pearson_correlation: 2.6191e-16 - val_r2_keras: -25.2154 - val_rmse: 0.8338 - val_sae: 289.5446 - val_sse: 367.7526 - learning_rate: 0.0023\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1508 - loss: 0.3477 - mae: 0.3983 - mse: 0.3259 - pearson_correlation: -3.9599e-18 - r2_keras: -90.4320 - rmse: 0.8321 - sae: 2523.0308 - sse: 2836.1077\n","Epoch 4: val_loss improved from 0.40701 to 0.36099, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.1392 - loss: 0.3406 - mae: 0.3811 - mse: 0.3075 - pearson_correlation: -9.2337e-18 - r2_keras: -74.1036 - rmse: 0.8204 - sae: 1838.8402 - sse: 2056.7056 - val_huber_loss: 0.1643 - val_loss: 0.3610 - val_mae: 0.4088 - val_mse: 0.4140 - val_pearson_correlation: -3.5451e-16 - val_r2_keras: -27.8193 - val_rmse: 0.8742 - val_sae: 317.5522 - val_sse: 404.2804 - learning_rate: 0.0023\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1075 - loss: 0.3042 - mae: 0.3078 - mse: 0.2217 - pearson_correlation: 2.6645e-16 - r2_keras: -106.9617 - rmse: 0.9042 - sae: 2676.2529 - sse: 3348.8354\n","Epoch 5: val_loss improved from 0.36099 to 0.33720, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0977 - loss: 0.2982 - mae: 0.3059 - mse: 0.2086 - pearson_correlation: 1.7158e-16 - r2_keras: -88.0764 - rmse: 0.8949 - sae: 1960.2775 - sse: 2433.1636 - val_huber_loss: 0.1408 - val_loss: 0.3372 - val_mae: 0.3876 - val_mse: 0.3549 - val_pearson_correlation: 1.6949e-16 - val_r2_keras: -28.0191 - val_rmse: 0.8772 - val_sae: 326.8219 - val_sse: 407.0825 - learning_rate: 0.0023\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0858 - loss: 0.2822 - mae: 0.2868 - mse: 0.1761 - pearson_correlation: 2.5074e-16 - r2_keras: -104.3246 - rmse: 0.8931 - sae: 2712.9680 - sse: 3267.0361\n","Epoch 6: val_loss improved from 0.33720 to 0.32869, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - huber_loss: 0.0816 - loss: 0.2796 - mae: 0.2870 - mse: 0.1701 - pearson_correlation: 1.7919e-16 - r2_keras: -82.5879 - rmse: 0.8536 - sae: 1965.5973 - sse: 2334.8721 - val_huber_loss: 0.1327 - val_loss: 0.3287 - val_mae: 0.3399 - val_mse: 0.3234 - val_pearson_correlation: -3.8408e-16 - val_r2_keras: -30.0413 - val_rmse: 0.9073 - val_sae: 331.9846 - val_sse: 435.4509 - learning_rate: 0.0023\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0740 - loss: 0.2701 - mae: 0.2471 - mse: 0.1516 - pearson_correlation: 3.0004e-17 - r2_keras: -112.6007 - rmse: 0.9275 - sae: 2742.7358 - sse: 3523.7515\n","Epoch 7: val_loss did not improve from 0.32869\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0645 - loss: 0.2642 - mae: 0.2390 - mse: 0.1394 - pearson_correlation: -1.0692e-17 - r2_keras: -90.8046 - rmse: 0.9015 - sae: 1994.4750 - sse: 2537.6787 - val_huber_loss: 0.1397 - val_loss: 0.3354 - val_mae: 0.3711 - val_mse: 0.3506 - val_pearson_correlation: 1.2364e-16 - val_r2_keras: -29.3518 - val_rmse: 0.8971 - val_sae: 330.0446 - val_sse: 425.7780 - learning_rate: 0.0023\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0707 - loss: 0.2663 - mae: 0.2605 - mse: 0.1439 - pearson_correlation: -4.7622e-17 - r2_keras: -101.9857 - rmse: 0.8831 - sae: 2576.3574 - sse: 3194.4863\n","Epoch 8: val_loss improved from 0.32869 to 0.31129, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.0702 - loss: 0.2660 - mae: 0.2657 - mse: 0.1429 - pearson_correlation: -4.8388e-17 - r2_keras: -85.3945 - rmse: 0.8862 - sae: 1896.4420 - sse: 2337.7175 - val_huber_loss: 0.1160 - val_loss: 0.3113 - val_mae: 0.3189 - val_mse: 0.2819 - val_pearson_correlation: -2.0062e-16 - val_r2_keras: -32.3296 - val_rmse: 0.9401 - val_sae: 345.6873 - val_sse: 467.5513 - learning_rate: 0.0023\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0944 - loss: 0.2897 - mae: 0.2839 - mse: 0.1948 - pearson_correlation: -2.3373e-16 - r2_keras: -104.4713 - rmse: 0.8937 - sae: 2586.8228 - sse: 3271.5864\n","Epoch 9: val_loss did not improve from 0.31129\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0921 - loss: 0.2883 - mae: 0.2841 - mse: 0.1922 - pearson_correlation: -1.4284e-16 - r2_keras: -89.8295 - rmse: 0.9157 - sae: 1906.6787 - sse: 2421.7029 - val_huber_loss: 0.2346 - val_loss: 0.4296 - val_mae: 0.5089 - val_mse: 0.6089 - val_pearson_correlation: -1.5554e-16 - val_r2_keras: -31.2811 - val_rmse: 0.9252 - val_sae: 338.0809 - val_sse: 452.8424 - learning_rate: 0.0023\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1291 - loss: 0.3241 - mae: 0.3578 - mse: 0.2690 - pearson_correlation: -4.4325e-16 - r2_keras: -125.5527 - rmse: 0.9790 - sae: 2983.0991 - sse: 3925.5059\n","Epoch 10: val_loss did not improve from 0.31129\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1246 - loss: 0.3213 - mae: 0.3627 - mse: 0.2614 - pearson_correlation: -2.3601e-16 - r2_keras: -95.8941 - rmse: 0.9026 - sae: 2139.5457 - sse: 2763.9309 - val_huber_loss: 0.1497 - val_loss: 0.3444 - val_mae: 0.3926 - val_mse: 0.3394 - val_pearson_correlation: -4.0252e-17 - val_r2_keras: -36.7843 - val_rmse: 1.0010 - val_sae: 397.5510 - val_sse: 530.0421 - learning_rate: 0.0023\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1309 - loss: 0.3255 - mae: 0.3768 - mse: 0.2741 - pearson_correlation: -6.1675e-16 - r2_keras: -137.0674 - rmse: 1.0225 - sae: 3171.7720 - sse: 4282.6792\n","Epoch 11: val_loss did not improve from 0.31129\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.1128 - loss: 0.3145 - mae: 0.3562 - mse: 0.2497 - pearson_correlation: -3.7605e-16 - r2_keras: -106.5051 - rmse: 0.9594 - sae: 2278.7139 - sse: 3036.4670 - val_huber_loss: 0.1584 - val_loss: 0.3526 - val_mae: 0.4053 - val_mse: 0.3758 - val_pearson_correlation: 1.5523e-16 - val_r2_keras: -37.3467 - val_rmse: 1.0084 - val_sae: 390.2477 - val_sse: 537.9323 - learning_rate: 0.0023\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0879 - loss: 0.2822 - mae: 0.2726 - mse: 0.1824 - pearson_correlation: -2.0456e-16 - r2_keras: -105.6915 - rmse: 0.8989 - sae: 2631.2375 - sse: 3309.4375\n","Epoch 12: val_loss improved from 0.31129 to 0.31018, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.0740 - loss: 0.2737 - mae: 0.2573 - mse: 0.1641 - pearson_correlation: -1.5507e-16 - r2_keras: -87.5211 - rmse: 0.8938 - sae: 1928.6527 - sse: 2410.3171 - val_huber_loss: 0.1163 - val_loss: 0.3102 - val_mae: 0.3382 - val_mse: 0.2722 - val_pearson_correlation: 2.0652e-16 - val_r2_keras: -33.2875 - val_rmse: 0.9535 - val_sae: 357.9681 - val_sse: 480.9891 - learning_rate: 0.0023\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0642 - loss: 0.2581 - mae: 0.2376 - mse: 0.1338 - pearson_correlation: -1.6474e-16 - r2_keras: -111.2900 - rmse: 0.9222 - sae: 2660.8145 - sse: 3483.0967\n","Epoch 13: val_loss did not improve from 0.31018\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0598 - loss: 0.2553 - mae: 0.2373 - mse: 0.1273 - pearson_correlation: -1.6705e-16 - r2_keras: -91.8985 - rmse: 0.9147 - sae: 1950.4535 - sse: 2533.6560 - val_huber_loss: 0.1205 - val_loss: 0.3139 - val_mae: 0.3326 - val_mse: 0.2736 - val_pearson_correlation: -3.0462e-16 - val_r2_keras: -31.2236 - val_rmse: 0.9244 - val_sae: 342.9585 - val_sse: 452.0367 - learning_rate: 0.0023\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0645 - loss: 0.2579 - mae: 0.2396 - mse: 0.1291 - pearson_correlation: -4.1023e-16 - r2_keras: -116.1395 - rmse: 0.9419 - sae: 2740.3848 - sse: 3633.5195\n","Epoch 14: val_loss improved from 0.31018 to 0.30071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0610 - loss: 0.2557 - mae: 0.2366 - mse: 0.1248 - pearson_correlation: -2.6674e-16 - r2_keras: -91.0357 - rmse: 0.8916 - sae: 1983.8204 - sse: 2585.8948 - val_huber_loss: 0.1078 - val_loss: 0.3007 - val_mae: 0.3384 - val_mse: 0.2270 - val_pearson_correlation: -1.4119e-16 - val_r2_keras: -40.5014 - val_rmse: 1.0491 - val_sae: 404.8344 - val_sse: 582.1867 - learning_rate: 0.0023\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0823 - loss: 0.2752 - mae: 0.2689 - mse: 0.1726 - pearson_correlation: -2.7717e-16 - r2_keras: -121.3643 - rmse: 0.9626 - sae: 2749.1948 - sse: 3795.5884\n","Epoch 15: val_loss did not improve from 0.30071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0708 - loss: 0.2681 - mae: 0.2628 - mse: 0.1570 - pearson_correlation: -1.8319e-16 - r2_keras: -99.1597 - rmse: 0.9462 - sae: 2007.2466 - sse: 2748.3772 - val_huber_loss: 0.1567 - val_loss: 0.3491 - val_mae: 0.3927 - val_mse: 0.3501 - val_pearson_correlation: 2.9008e-16 - val_r2_keras: -31.1626 - val_rmse: 0.9235 - val_sae: 339.0398 - val_sse: 451.1806 - learning_rate: 0.0023\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0973 - loss: 0.2897 - mae: 0.2998 - mse: 0.1989 - pearson_correlation: -1.2151e-16 - r2_keras: -116.2662 - rmse: 0.9424 - sae: 2813.6826 - sse: 3637.4497\n","Epoch 16: val_loss did not improve from 0.30071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0873 - loss: 0.2836 - mae: 0.2960 - mse: 0.1859 - pearson_correlation: -1.2301e-16 - r2_keras: -92.3328 - rmse: 0.9032 - sae: 2040.2913 - sse: 2602.7397 - val_huber_loss: 0.2602 - val_loss: 0.4522 - val_mae: 0.5401 - val_mse: 0.6357 - val_pearson_correlation: -8.2372e-17 - val_r2_keras: -54.3191 - val_rmse: 1.2112 - val_sae: 474.5264 - val_sse: 776.0221 - learning_rate: 0.0023\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0971 - loss: 0.2891 - mae: 0.2879 - mse: 0.2049 - pearson_correlation: 7.4929e-17 - r2_keras: -111.0929 - rmse: 0.9213 - sae: 2707.6479 - sse: 3476.9810\n","Epoch 17: val_loss did not improve from 0.30071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0832 - loss: 0.2806 - mae: 0.2747 - mse: 0.1859 - pearson_correlation: 5.5005e-17 - r2_keras: -92.6846 - rmse: 0.9217 - sae: 1985.6461 - sse: 2540.3420 - val_huber_loss: 0.1400 - val_loss: 0.3315 - val_mae: 0.3788 - val_mse: 0.3202 - val_pearson_correlation: 2.3605e-17 - val_r2_keras: -32.8867 - val_rmse: 0.9480 - val_sae: 352.8270 - val_sse: 475.3667 - learning_rate: 0.0023\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0748 - loss: 0.2663 - mae: 0.2542 - mse: 0.1512 - pearson_correlation: -3.0420e-16 - r2_keras: -109.9837 - rmse: 0.9168 - sae: 2675.8018 - sse: 3442.5752\n","Epoch 18: val_loss did not improve from 0.30071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0647 - loss: 0.2601 - mae: 0.2490 - mse: 0.1385 - pearson_correlation: -2.6408e-16 - r2_keras: -89.4913 - rmse: 0.8981 - sae: 1952.8934 - sse: 2488.6213 - val_huber_loss: 0.1209 - val_loss: 0.3118 - val_mae: 0.3371 - val_mse: 0.2749 - val_pearson_correlation: -2.5550e-16 - val_r2_keras: -32.7893 - val_rmse: 0.9466 - val_sae: 352.9870 - val_sse: 474.0006 - learning_rate: 0.0023\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0648 - loss: 0.2557 - mae: 0.2502 - mse: 0.1305 - pearson_correlation: -2.6886e-16 - r2_keras: -105.4228 - rmse: 0.8977 - sae: 2627.3833 - sse: 3301.1021\n","Epoch 19: val_loss did not improve from 0.30071\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0570 - loss: 0.2509 - mae: 0.2452 - mse: 0.1208 - pearson_correlation: -1.8158e-16 - r2_keras: -88.8413 - rmse: 0.9055 - sae: 1933.1127 - sse: 2422.3479 - val_huber_loss: 0.1162 - val_loss: 0.3065 - val_mae: 0.3689 - val_mse: 0.2395 - val_pearson_correlation: 2.1826e-16 - val_r2_keras: -39.8019 - val_rmse: 1.0402 - val_sae: 390.6778 - val_sse: 572.3733 - learning_rate: 0.0023\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0747 - loss: 0.2650 - mae: 0.2444 - mse: 0.1511 - pearson_correlation: -1.0625e-16 - r2_keras: -125.7958 - rmse: 0.9799 - sae: 2855.3545 - sse: 3933.0459\n","Epoch 20: val_loss improved from 0.30071 to 0.29627, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0622 - loss: 0.2574 - mae: 0.2315 - mse: 0.1355 - pearson_correlation: -2.1233e-16 - r2_keras: -100.9097 - rmse: 0.9477 - sae: 2074.9282 - sse: 2825.8889 - val_huber_loss: 0.1061 - val_loss: 0.2963 - val_mae: 0.3381 - val_mse: 0.2257 - val_pearson_correlation: -3.1436e-16 - val_r2_keras: -35.4512 - val_rmse: 0.9832 - val_sae: 363.3912 - val_sse: 511.3409 - learning_rate: 4.5490e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0517 - loss: 0.2418 - mae: 0.2122 - mse: 0.1034 - pearson_correlation: 4.7531e-16 - r2_keras: -112.8924 - rmse: 0.9287 - sae: 2713.2651 - sse: 3532.7998\n","Epoch 21: val_loss improved from 0.29627 to 0.29133, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.0421 - loss: 0.2360 - mae: 0.1991 - mse: 0.0918 - pearson_correlation: 2.4194e-16 - r2_keras: -91.3940 - rmse: 0.9057 - sae: 1976.9758 - sse: 2548.3430 - val_huber_loss: 0.1013 - val_loss: 0.2913 - val_mae: 0.3182 - val_mse: 0.2169 - val_pearson_correlation: 9.8708e-17 - val_r2_keras: -34.2451 - val_rmse: 0.9668 - val_sae: 357.3670 - val_sse: 494.4214 - learning_rate: 4.5490e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0440 - loss: 0.2341 - mae: 0.1974 - mse: 0.0880 - pearson_correlation: 3.6509e-16 - r2_keras: -110.1927 - rmse: 0.9176 - sae: 2675.7368 - sse: 3449.0586\n","Epoch 22: val_loss improved from 0.29133 to 0.28953, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0359 - loss: 0.2291 - mae: 0.1857 - mse: 0.0781 - pearson_correlation: 2.3798e-16 - r2_keras: -89.6063 - rmse: 0.8984 - sae: 1952.2866 - sse: 2492.6580 - val_huber_loss: 0.0997 - val_loss: 0.2895 - val_mae: 0.3103 - val_mse: 0.2132 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.7411 - val_rmse: 0.9598 - val_sae: 354.2221 - val_sse: 487.3522 - learning_rate: 4.5490e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0406 - loss: 0.2304 - mae: 0.1872 - mse: 0.0812 - pearson_correlation: 6.6280e-16 - r2_keras: -110.0515 - rmse: 0.9171 - sae: 2665.4033 - sse: 3444.6792\n","Epoch 23: val_loss improved from 0.28953 to 0.28877, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0329 - loss: 0.2258 - mae: 0.1764 - mse: 0.0719 - pearson_correlation: 4.8665e-16 - r2_keras: -89.6163 - rmse: 0.8989 - sae: 1945.7732 - sse: 2490.9592 - val_huber_loss: 0.0991 - val_loss: 0.2888 - val_mae: 0.3059 - val_mse: 0.2113 - val_pearson_correlation: 3.5917e-16 - val_r2_keras: -33.6842 - val_rmse: 0.9590 - val_sae: 354.2856 - val_sse: 486.5544 - learning_rate: 4.5490e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0380 - loss: 0.2277 - mae: 0.1800 - mse: 0.0760 - pearson_correlation: 1.9272e-16 - r2_keras: -109.2931 - rmse: 0.9139 - sae: 2653.8518 - sse: 3421.1543\n","Epoch 24: val_loss improved from 0.28877 to 0.28695, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0308 - loss: 0.2233 - mae: 0.1690 - mse: 0.0672 - pearson_correlation: 1.1083e-16 - r2_keras: -89.3295 - rmse: 0.8987 - sae: 1938.5804 - sse: 2477.8430 - val_huber_loss: 0.0974 - val_loss: 0.2870 - val_mae: 0.3010 - val_mse: 0.2076 - val_pearson_correlation: -1.9318e-16 - val_r2_keras: -33.4369 - val_rmse: 0.9556 - val_sae: 351.8767 - val_sse: 483.0845 - learning_rate: 4.5490e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0369 - loss: 0.2264 - mae: 0.1718 - mse: 0.0741 - pearson_correlation: 2.3726e-16 - r2_keras: -111.6573 - rmse: 0.9237 - sae: 2671.5000 - sse: 3494.4875\n","Epoch 25: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0296 - loss: 0.2219 - mae: 0.1613 - mse: 0.0652 - pearson_correlation: 1.2484e-16 - r2_keras: -90.9935 - rmse: 0.9060 - sae: 1950.6986 - sse: 2527.7627 - val_huber_loss: 0.1001 - val_loss: 0.2894 - val_mae: 0.3082 - val_mse: 0.2128 - val_pearson_correlation: -4.3873e-16 - val_r2_keras: -33.4060 - val_rmse: 0.9552 - val_sae: 351.0208 - val_sse: 482.6508 - learning_rate: 4.5490e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0359 - loss: 0.2251 - mae: 0.1703 - mse: 0.0717 - pearson_correlation: -2.8380e-16 - r2_keras: -110.1521 - rmse: 0.9175 - sae: 2656.6628 - sse: 3447.7988\n","Epoch 26: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0286 - loss: 0.2207 - mae: 0.1588 - mse: 0.0629 - pearson_correlation: -1.4866e-16 - r2_keras: -90.2499 - rmse: 0.9041 - sae: 1941.6052 - sse: 2499.6848 - val_huber_loss: 0.1012 - val_loss: 0.2903 - val_mae: 0.3126 - val_mse: 0.2165 - val_pearson_correlation: 1.6496e-16 - val_r2_keras: -32.7456 - val_rmse: 0.9460 - val_sae: 347.3139 - val_sse: 473.3870 - learning_rate: 4.5490e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0348 - loss: 0.2239 - mae: 0.1634 - mse: 0.0701 - pearson_correlation: -2.3902e-16 - r2_keras: -112.6117 - rmse: 0.9276 - sae: 2671.0210 - sse: 3524.0918\n","Epoch 27: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0277 - loss: 0.2195 - mae: 0.1520 - mse: 0.0613 - pearson_correlation: -1.4049e-16 - r2_keras: -91.9870 - rmse: 0.9116 - sae: 1951.4703 - sse: 2551.6897 - val_huber_loss: 0.1015 - val_loss: 0.2903 - val_mae: 0.3127 - val_mse: 0.2156 - val_pearson_correlation: -1.7242e-17 - val_r2_keras: -33.2098 - val_rmse: 0.9525 - val_sae: 349.9487 - val_sse: 479.8991 - learning_rate: 4.5490e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0338 - loss: 0.2226 - mae: 0.1613 - mse: 0.0677 - pearson_correlation: -2.5249e-16 - r2_keras: -110.7399 - rmse: 0.9199 - sae: 2659.0000 - sse: 3466.0310\n","Epoch 28: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0268 - loss: 0.2184 - mae: 0.1501 - mse: 0.0592 - pearson_correlation: -1.3116e-16 - r2_keras: -90.9782 - rmse: 0.9086 - sae: 1944.4547 - sse: 2515.7859 - val_huber_loss: 0.1050 - val_loss: 0.2936 - val_mae: 0.3206 - val_mse: 0.2250 - val_pearson_correlation: -3.5794e-17 - val_r2_keras: -32.5169 - val_rmse: 0.9428 - val_sae: 345.5140 - val_sse: 470.1787 - learning_rate: 4.5490e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0340 - loss: 0.2226 - mae: 0.1560 - mse: 0.0690 - pearson_correlation: 1.5944e-17 - r2_keras: -113.0823 - rmse: 0.9295 - sae: 2670.7012 - sse: 3538.6895\n","Epoch 29: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0268 - loss: 0.2182 - mae: 0.1447 - mse: 0.0600 - pearson_correlation: -2.1741e-17 - r2_keras: -92.4009 - rmse: 0.9138 - sae: 1951.5610 - sse: 2562.5964 - val_huber_loss: 0.1044 - val_loss: 0.2927 - val_mae: 0.3186 - val_mse: 0.2205 - val_pearson_correlation: 5.7376e-18 - val_r2_keras: -33.2394 - val_rmse: 0.9529 - val_sae: 349.8174 - val_sse: 480.3134 - learning_rate: 4.5490e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0335 - loss: 0.2218 - mae: 0.1596 - mse: 0.0671 - pearson_correlation: -1.0097e-16 - r2_keras: -110.8620 - rmse: 0.9204 - sae: 2661.9253 - sse: 3469.8196\n","Epoch 30: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0265 - loss: 0.2175 - mae: 0.1448 - mse: 0.0585 - pearson_correlation: -8.4703e-17 - r2_keras: -91.3834 - rmse: 0.9116 - sae: 1947.0536 - sse: 2522.1094 - val_huber_loss: 0.1057 - val_loss: 0.2939 - val_mae: 0.3225 - val_mse: 0.2240 - val_pearson_correlation: 1.3885e-16 - val_r2_keras: -33.0387 - val_rmse: 0.9501 - val_sae: 348.9871 - val_sse: 477.4979 - learning_rate: 9.0980e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0321 - loss: 0.2203 - mae: 0.1553 - mse: 0.0641 - pearson_correlation: -3.7425e-16 - r2_keras: -111.0873 - rmse: 0.9213 - sae: 2660.7092 - sse: 3476.8069\n","Epoch 31: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0252 - loss: 0.2161 - mae: 0.1410 - mse: 0.0558 - pearson_correlation: -3.0354e-16 - r2_keras: -91.4684 - rmse: 0.9117 - sae: 1946.0055 - sse: 2526.0039 - val_huber_loss: 0.1061 - val_loss: 0.2943 - val_mae: 0.3244 - val_mse: 0.2252 - val_pearson_correlation: -5.2047e-17 - val_r2_keras: -33.0272 - val_rmse: 0.9499 - val_sae: 349.4497 - val_sse: 477.3367 - learning_rate: 9.0980e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0311 - loss: 0.2193 - mae: 0.1521 - mse: 0.0622 - pearson_correlation: -5.2470e-16 - r2_keras: -111.3939 - rmse: 0.9226 - sae: 2661.7329 - sse: 3486.3174\n","Epoch 32: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0244 - loss: 0.2152 - mae: 0.1384 - mse: 0.0540 - pearson_correlation: -3.7060e-16 - r2_keras: -91.6628 - rmse: 0.9124 - sae: 1946.7653 - sse: 2532.2263 - val_huber_loss: 0.1064 - val_loss: 0.2945 - val_mae: 0.3252 - val_mse: 0.2260 - val_pearson_correlation: -1.4423e-16 - val_r2_keras: -33.0660 - val_rmse: 0.9505 - val_sae: 350.1118 - val_sse: 477.8821 - learning_rate: 9.0980e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0305 - loss: 0.2186 - mae: 0.1502 - mse: 0.0610 - pearson_correlation: -2.9353e-16 - r2_keras: -111.7243 - rmse: 0.9239 - sae: 2663.5659 - sse: 3496.5664\n","Epoch 33: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0239 - loss: 0.2146 - mae: 0.1372 - mse: 0.0530 - pearson_correlation: -2.1237e-16 - r2_keras: -91.8408 - rmse: 0.9130 - sae: 1947.8213 - sse: 2538.5632 - val_huber_loss: 0.1065 - val_loss: 0.2945 - val_mae: 0.3240 - val_mse: 0.2258 - val_pearson_correlation: 1.8430e-16 - val_r2_keras: -33.1052 - val_rmse: 0.9510 - val_sae: 350.3128 - val_sse: 478.4308 - learning_rate: 9.0980e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0301 - loss: 0.2181 - mae: 0.1487 - mse: 0.0602 - pearson_correlation: 8.1947e-17 - r2_keras: -112.2185 - rmse: 0.9260 - sae: 2666.2104 - sse: 3511.8948\n","Epoch 34: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0236 - loss: 0.2142 - mae: 0.1359 - mse: 0.0523 - pearson_correlation: 8.3739e-17 - r2_keras: -92.2167 - rmse: 0.9147 - sae: 1949.8088 - sse: 2549.3276 - val_huber_loss: 0.1061 - val_loss: 0.2940 - val_mae: 0.3227 - val_mse: 0.2246 - val_pearson_correlation: -6.2926e-17 - val_r2_keras: -33.2381 - val_rmse: 0.9529 - val_sae: 351.5386 - val_sse: 480.2959 - learning_rate: 9.0980e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0297 - loss: 0.2176 - mae: 0.1481 - mse: 0.0593 - pearson_correlation: 1.2360e-16 - r2_keras: -111.9821 - rmse: 0.9250 - sae: 2665.1565 - sse: 3504.5642\n","Epoch 35: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0233 - loss: 0.2137 - mae: 0.1350 - mse: 0.0516 - pearson_correlation: 6.6615e-17 - r2_keras: -92.0761 - rmse: 0.9142 - sae: 1949.0409 - sse: 2544.6396 - val_huber_loss: 0.1061 - val_loss: 0.2940 - val_mae: 0.3233 - val_mse: 0.2244 - val_pearson_correlation: -7.4168e-17 - val_r2_keras: -33.2895 - val_rmse: 0.9536 - val_sae: 351.9507 - val_sse: 481.0168 - learning_rate: 1.8196e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0296 - loss: 0.2175 - mae: 0.1479 - mse: 0.0591 - pearson_correlation: 5.8166e-16 - r2_keras: -112.1115 - rmse: 0.9255 - sae: 2666.2959 - sse: 3508.5776\n","Epoch 36: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0232 - loss: 0.2136 - mae: 0.1347 - mse: 0.0514 - pearson_correlation: 4.3595e-16 - r2_keras: -92.1646 - rmse: 0.9146 - sae: 1949.8103 - sse: 2547.3411 - val_huber_loss: 0.1061 - val_loss: 0.2939 - val_mae: 0.3233 - val_mse: 0.2241 - val_pearson_correlation: 1.5932e-16 - val_r2_keras: -33.3391 - val_rmse: 0.9543 - val_sae: 352.4052 - val_sse: 481.7122 - learning_rate: 1.8196e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0295 - loss: 0.2174 - mae: 0.1478 - mse: 0.0590 - pearson_correlation: 2.4136e-16 - r2_keras: -112.0662 - rmse: 0.9253 - sae: 2665.9839 - sse: 3507.1714\n","Epoch 37: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0232 - loss: 0.2135 - mae: 0.1347 - mse: 0.0513 - pearson_correlation: 1.3932e-16 - r2_keras: -92.1408 - rmse: 0.9145 - sae: 1949.6184 - sse: 2546.4788 - val_huber_loss: 0.1060 - val_loss: 0.2939 - val_mae: 0.3234 - val_mse: 0.2240 - val_pearson_correlation: -2.0468e-16 - val_r2_keras: -33.3525 - val_rmse: 0.9544 - val_sae: 352.5585 - val_sse: 481.9007 - learning_rate: 1.8196e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0294 - loss: 0.2173 - mae: 0.1475 - mse: 0.0589 - pearson_correlation: 5.2674e-16 - r2_keras: -112.2022 - rmse: 0.9259 - sae: 2667.1650 - sse: 3511.3911\n","Epoch 38: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0231 - loss: 0.2135 - mae: 0.1344 - mse: 0.0512 - pearson_correlation: 3.6693e-16 - r2_keras: -92.2353 - rmse: 0.9149 - sae: 1950.4283 - sse: 2549.3367 - val_huber_loss: 0.1062 - val_loss: 0.2940 - val_mae: 0.3239 - val_mse: 0.2243 - val_pearson_correlation: -1.0221e-16 - val_r2_keras: -33.3788 - val_rmse: 0.9548 - val_sae: 352.7334 - val_sse: 482.2695 - learning_rate: 1.8196e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0293 - loss: 0.2172 - mae: 0.1475 - mse: 0.0587 - pearson_correlation: -5.5107e-16 - r2_keras: -112.1427 - rmse: 0.9256 - sae: 2666.7173 - sse: 3509.5439\n","Epoch 39: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - huber_loss: 0.0231 - loss: 0.2134 - mae: 0.1344 - mse: 0.0510 - pearson_correlation: -4.0474e-16 - r2_keras: -92.1955 - rmse: 0.9148 - sae: 1950.1266 - sse: 2548.1045 - val_huber_loss: 0.1065 - val_loss: 0.2943 - val_mae: 0.3244 - val_mse: 0.2248 - val_pearson_correlation: 2.6681e-16 - val_r2_keras: -33.3833 - val_rmse: 0.9549 - val_sae: 352.7368 - val_sse: 482.3321 - learning_rate: 1.8196e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0293 - loss: 0.2171 - mae: 0.1475 - mse: 0.0586 - pearson_correlation: -9.7394e-17 - r2_keras: -112.0860 - rmse: 0.9254 - sae: 2666.0139 - sse: 3507.7861\n","Epoch 40: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0230 - loss: 0.2133 - mae: 0.1344 - mse: 0.0510 - pearson_correlation: -3.2564e-17 - r2_keras: -92.1634 - rmse: 0.9147 - sae: 1949.6650 - sse: 2546.9985 - val_huber_loss: 0.1064 - val_loss: 0.2942 - val_mae: 0.3244 - val_mse: 0.2247 - val_pearson_correlation: -2.6106e-16 - val_r2_keras: -33.3873 - val_rmse: 0.9549 - val_sae: 352.8064 - val_sse: 482.3892 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0292 - loss: 0.2170 - mae: 0.1472 - mse: 0.0585 - pearson_correlation: 3.7034e-17 - r2_keras: -112.1718 - rmse: 0.9258 - sae: 2666.7009 - sse: 3510.4487\n","Epoch 41: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0230 - loss: 0.2132 - mae: 0.1342 - mse: 0.0508 - pearson_correlation: -7.6740e-18 - r2_keras: -92.2220 - rmse: 0.9149 - sae: 1950.1254 - sse: 2548.7898 - val_huber_loss: 0.1064 - val_loss: 0.2942 - val_mae: 0.3245 - val_mse: 0.2247 - val_pearson_correlation: -1.3044e-16 - val_r2_keras: -33.3998 - val_rmse: 0.9551 - val_sae: 352.9240 - val_sse: 482.5635 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0292 - loss: 0.2170 - mae: 0.1472 - mse: 0.0583 - pearson_correlation: 4.4097e-16 - r2_keras: -112.1403 - rmse: 0.9256 - sae: 2666.4727 - sse: 3509.4697\n","Epoch 42: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0229 - loss: 0.2132 - mae: 0.1341 - mse: 0.0508 - pearson_correlation: 2.8734e-16 - r2_keras: -92.2048 - rmse: 0.9149 - sae: 1949.9821 - sse: 2548.1824 - val_huber_loss: 0.1064 - val_loss: 0.2942 - val_mae: 0.3246 - val_mse: 0.2247 - val_pearson_correlation: 2.2694e-16 - val_r2_keras: -33.3917 - val_rmse: 0.9550 - val_sae: 352.8723 - val_sse: 482.4498 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0292 - loss: 0.2170 - mae: 0.1470 - mse: 0.0583 - pearson_correlation: 7.0345e-16 - r2_keras: -112.2330 - rmse: 0.9260 - sae: 2667.1353 - sse: 3512.3462\n","Epoch 43: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0229 - loss: 0.2132 - mae: 0.1339 - mse: 0.0507 - pearson_correlation: 5.0961e-16 - r2_keras: -92.2705 - rmse: 0.9151 - sae: 1950.4371 - sse: 2550.1460 - val_huber_loss: 0.1065 - val_loss: 0.2943 - val_mae: 0.3248 - val_mse: 0.2248 - val_pearson_correlation: -2.8342e-17 - val_r2_keras: -33.4106 - val_rmse: 0.9553 - val_sae: 353.0096 - val_sse: 482.7152 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0291 - loss: 0.2169 - mae: 0.1470 - mse: 0.0582 - pearson_correlation: 2.4156e-16 - r2_keras: -112.1914 - rmse: 0.9258 - sae: 2666.8699 - sse: 3511.0542\n","Epoch 44: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0229 - loss: 0.2131 - mae: 0.1339 - mse: 0.0506 - pearson_correlation: 1.8842e-16 - r2_keras: -92.2413 - rmse: 0.9150 - sae: 1950.2446 - sse: 2549.2671 - val_huber_loss: 0.1066 - val_loss: 0.2944 - val_mae: 0.3251 - val_mse: 0.2250 - val_pearson_correlation: 1.3036e-16 - val_r2_keras: -33.4127 - val_rmse: 0.9553 - val_sae: 352.9794 - val_sse: 482.7451 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0291 - loss: 0.2168 - mae: 0.1469 - mse: 0.0581 - pearson_correlation: -4.5959e-16 - r2_keras: -112.1471 - rmse: 0.9257 - sae: 2666.2915 - sse: 3509.6802\n","Epoch 45: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0229 - loss: 0.2130 - mae: 0.1338 - mse: 0.0506 - pearson_correlation: -2.9976e-16 - r2_keras: -92.2192 - rmse: 0.9150 - sae: 1949.8787 - sse: 2548.4390 - val_huber_loss: 0.1066 - val_loss: 0.2943 - val_mae: 0.3251 - val_mse: 0.2250 - val_pearson_correlation: -1.2474e-16 - val_r2_keras: -33.4038 - val_rmse: 0.9552 - val_sae: 352.9825 - val_sse: 482.6199 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0290 - loss: 0.2168 - mae: 0.1467 - mse: 0.0580 - pearson_correlation: -1.6332e-17 - r2_keras: -112.2576 - rmse: 0.9261 - sae: 2667.2549 - sse: 3513.1084\n","Epoch 46: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0228 - loss: 0.2130 - mae: 0.1336 - mse: 0.0505 - pearson_correlation: 6.5229e-18 - r2_keras: -92.2944 - rmse: 0.9153 - sae: 1950.5273 - sse: 2550.7415 - val_huber_loss: 0.1067 - val_loss: 0.2944 - val_mae: 0.3251 - val_mse: 0.2251 - val_pearson_correlation: -6.2347e-17 - val_r2_keras: -33.4107 - val_rmse: 0.9553 - val_sae: 353.0283 - val_sse: 482.7167 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0289 - loss: 0.2167 - mae: 0.1466 - mse: 0.0579 - pearson_correlation: -1.1999e-16 - r2_keras: -112.2155 - rmse: 0.9259 - sae: 2666.9841 - sse: 3511.8042\n","Epoch 47: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0228 - loss: 0.2129 - mae: 0.1336 - mse: 0.0504 - pearson_correlation: -7.4188e-17 - r2_keras: -92.2686 - rmse: 0.9152 - sae: 1950.3540 - sse: 2549.8989 - val_huber_loss: 0.1068 - val_loss: 0.2946 - val_mae: 0.3257 - val_mse: 0.2255 - val_pearson_correlation: 6.7995e-17 - val_r2_keras: -33.4185 - val_rmse: 0.9554 - val_sae: 353.0128 - val_sse: 482.8267 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0289 - loss: 0.2167 - mae: 0.1466 - mse: 0.0579 - pearson_correlation: 2.4800e-16 - r2_keras: -112.1705 - rmse: 0.9258 - sae: 2666.4333 - sse: 3510.4077\n","Epoch 48: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0228 - loss: 0.2129 - mae: 0.1336 - mse: 0.0504 - pearson_correlation: 1.3053e-16 - r2_keras: -92.2441 - rmse: 0.9151 - sae: 1949.9991 - sse: 2549.0325 - val_huber_loss: 0.1069 - val_loss: 0.2946 - val_mae: 0.3257 - val_mse: 0.2256 - val_pearson_correlation: -1.7584e-16 - val_r2_keras: -33.3965 - val_rmse: 0.9551 - val_sae: 352.8799 - val_sse: 482.5178 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0289 - loss: 0.2166 - mae: 0.1463 - mse: 0.0578 - pearson_correlation: -5.0933e-16 - r2_keras: -112.3091 - rmse: 0.9263 - sae: 2667.5518 - sse: 3514.7080\n","Epoch 49: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0227 - loss: 0.2128 - mae: 0.1333 - mse: 0.0503 - pearson_correlation: -3.4949e-16 - r2_keras: -92.3411 - rmse: 0.9155 - sae: 1950.7618 - sse: 2551.9534 - val_huber_loss: 0.1068 - val_loss: 0.2945 - val_mae: 0.3256 - val_mse: 0.2254 - val_pearson_correlation: 3.1719e-16 - val_r2_keras: -33.4246 - val_rmse: 0.9554 - val_sae: 353.1393 - val_sse: 482.9125 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0288 - loss: 0.2165 - mae: 0.1463 - mse: 0.0576 - pearson_correlation: 2.9064e-16 - r2_keras: -112.2603 - rmse: 0.9261 - sae: 2667.2896 - sse: 3513.1921\n","Epoch 50: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0227 - loss: 0.2128 - mae: 0.1333 - mse: 0.0501 - pearson_correlation: 1.2499e-16 - r2_keras: -92.3068 - rmse: 0.9154 - sae: 1950.5765 - sse: 2550.9224 - val_huber_loss: 0.1071 - val_loss: 0.2948 - val_mae: 0.3262 - val_mse: 0.2261 - val_pearson_correlation: 5.4400e-16 - val_r2_keras: -33.4153 - val_rmse: 0.9553 - val_sae: 353.0147 - val_sse: 482.7816 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0288 - loss: 0.2165 - mae: 0.1464 - mse: 0.0576 - pearson_correlation: 7.3779e-17 - r2_keras: -112.2146 - rmse: 0.9259 - sae: 2666.6177 - sse: 3511.7739\n","Epoch 51: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0226 - loss: 0.2127 - mae: 0.1333 - mse: 0.0501 - pearson_correlation: 3.4277e-17 - r2_keras: -92.2826 - rmse: 0.9153 - sae: 1950.1350 - sse: 2550.0505 - val_huber_loss: 0.1071 - val_loss: 0.2948 - val_mae: 0.3261 - val_mse: 0.2260 - val_pearson_correlation: -9.6355e-17 - val_r2_keras: -33.4113 - val_rmse: 0.9553 - val_sae: 353.0406 - val_sse: 482.7249 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0287 - loss: 0.2164 - mae: 0.1460 - mse: 0.0575 - pearson_correlation: -3.1360e-16 - r2_keras: -112.3427 - rmse: 0.9265 - sae: 2667.7847 - sse: 3515.7498\n","Epoch 52: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0226 - loss: 0.2127 - mae: 0.1330 - mse: 0.0500 - pearson_correlation: -2.9353e-16 - r2_keras: -92.3721 - rmse: 0.9157 - sae: 1950.9391 - sse: 2552.7483 - val_huber_loss: 0.1072 - val_loss: 0.2948 - val_mae: 0.3264 - val_mse: 0.2261 - val_pearson_correlation: -5.0992e-17 - val_r2_keras: -33.4199 - val_rmse: 0.9554 - val_sae: 353.0476 - val_sse: 482.8454 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0287 - loss: 0.2163 - mae: 0.1460 - mse: 0.0573 - pearson_correlation: -1.6735e-16 - r2_keras: -112.2856 - rmse: 0.9262 - sae: 2667.1816 - sse: 3513.9785\n","Epoch 53: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0226 - loss: 0.2126 - mae: 0.1330 - mse: 0.0499 - pearson_correlation: -9.9146e-17 - r2_keras: -92.3354 - rmse: 0.9155 - sae: 1950.5237 - sse: 2551.5830 - val_huber_loss: 0.1073 - val_loss: 0.2949 - val_mae: 0.3265 - val_mse: 0.2263 - val_pearson_correlation: -1.5285e-16 - val_r2_keras: -33.4366 - val_rmse: 0.9556 - val_sae: 353.1901 - val_sse: 483.0808 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0286 - loss: 0.2163 - mae: 0.1460 - mse: 0.0573 - pearson_correlation: 8.0642e-17 - r2_keras: -112.2509 - rmse: 0.9261 - sae: 2667.0291 - sse: 3512.8999\n","Epoch 54: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0225 - loss: 0.2125 - mae: 0.1330 - mse: 0.0499 - pearson_correlation: 4.3828e-17 - r2_keras: -92.3177 - rmse: 0.9155 - sae: 1950.4369 - sse: 2550.9285 - val_huber_loss: 0.1075 - val_loss: 0.2951 - val_mae: 0.3271 - val_mse: 0.2268 - val_pearson_correlation: 2.9485e-16 - val_r2_keras: -33.4040 - val_rmse: 0.9552 - val_sae: 352.9494 - val_sse: 482.6226 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0286 - loss: 0.2162 - mae: 0.1458 - mse: 0.0572 - pearson_correlation: -3.9362e-16 - r2_keras: -112.3515 - rmse: 0.9265 - sae: 2667.6104 - sse: 3516.0220\n","Epoch 55: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0225 - loss: 0.2125 - mae: 0.1328 - mse: 0.0498 - pearson_correlation: -2.7483e-16 - r2_keras: -92.3847 - rmse: 0.9158 - sae: 1950.8519 - sse: 2553.0090 - val_huber_loss: 0.1074 - val_loss: 0.2950 - val_mae: 0.3268 - val_mse: 0.2266 - val_pearson_correlation: 3.8508e-16 - val_r2_keras: -33.4287 - val_rmse: 0.9555 - val_sae: 353.1331 - val_sse: 482.9702 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0285 - loss: 0.2161 - mae: 0.1457 - mse: 0.0570 - pearson_correlation: 1.1428e-16 - r2_keras: -112.2885 - rmse: 0.9262 - sae: 2667.0549 - sse: 3514.0667\n","Epoch 56: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0224 - loss: 0.2124 - mae: 0.1327 - mse: 0.0496 - pearson_correlation: 1.6472e-16 - r2_keras: -92.3490 - rmse: 0.9156 - sae: 1950.4836 - sse: 2551.7793 - val_huber_loss: 0.1075 - val_loss: 0.2951 - val_mae: 0.3270 - val_mse: 0.2268 - val_pearson_correlation: -2.8338e-16 - val_r2_keras: -33.4143 - val_rmse: 0.9553 - val_sae: 353.0158 - val_sse: 482.7678 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0285 - loss: 0.2161 - mae: 0.1455 - mse: 0.0570 - pearson_correlation: -2.4400e-16 - r2_keras: -112.4415 - rmse: 0.9269 - sae: 2668.4700 - sse: 3518.8125\n","Epoch 57: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0224 - loss: 0.2124 - mae: 0.1325 - mse: 0.0496 - pearson_correlation: -1.6019e-16 - r2_keras: -92.4549 - rmse: 0.9161 - sae: 1951.4460 - sse: 2554.9900 - val_huber_loss: 0.1077 - val_loss: 0.2952 - val_mae: 0.3277 - val_mse: 0.2271 - val_pearson_correlation: -1.9235e-16 - val_r2_keras: -33.4522 - val_rmse: 0.9558 - val_sae: 353.2208 - val_sse: 483.2990 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0284 - loss: 0.2160 - mae: 0.1456 - mse: 0.0569 - pearson_correlation: 4.7016e-16 - r2_keras: -112.3920 - rmse: 0.9267 - sae: 2668.1616 - sse: 3517.2783\n","Epoch 58: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0224 - loss: 0.2123 - mae: 0.1326 - mse: 0.0495 - pearson_correlation: 2.8036e-16 - r2_keras: -92.4280 - rmse: 0.9160 - sae: 1951.2880 - sse: 2554.0378 - val_huber_loss: 0.1078 - val_loss: 0.2953 - val_mae: 0.3277 - val_mse: 0.2273 - val_pearson_correlation: 1.3577e-16 - val_r2_keras: -33.4515 - val_rmse: 0.9558 - val_sae: 353.2553 - val_sse: 483.2898 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0284 - loss: 0.2159 - mae: 0.1455 - mse: 0.0568 - pearson_correlation: -4.0913e-16 - r2_keras: -112.3610 - rmse: 0.9265 - sae: 2667.9604 - sse: 3516.3169\n","Epoch 59: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0223 - loss: 0.2122 - mae: 0.1325 - mse: 0.0494 - pearson_correlation: -2.3389e-16 - r2_keras: -92.4109 - rmse: 0.9159 - sae: 1951.1464 - sse: 2553.4382 - val_huber_loss: 0.1079 - val_loss: 0.2955 - val_mae: 0.3280 - val_mse: 0.2277 - val_pearson_correlation: 1.1324e-17 - val_r2_keras: -33.4359 - val_rmse: 0.9556 - val_sae: 353.1039 - val_sse: 483.0703 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0284 - loss: 0.2159 - mae: 0.1453 - mse: 0.0567 - pearson_correlation: -8.2643e-16 - r2_keras: -112.4807 - rmse: 0.9270 - sae: 2668.7798 - sse: 3520.0288\n","Epoch 60: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0223 - loss: 0.2122 - mae: 0.1323 - mse: 0.0494 - pearson_correlation: -5.2863e-16 - r2_keras: -92.4925 - rmse: 0.9163 - sae: 1951.6881 - sse: 2555.9346 - val_huber_loss: 0.1079 - val_loss: 0.2954 - val_mae: 0.3280 - val_mse: 0.2276 - val_pearson_correlation: -7.3547e-17 - val_r2_keras: -33.4507 - val_rmse: 0.9558 - val_sae: 353.2358 - val_sse: 483.2788 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0283 - loss: 0.2158 - mae: 0.1452 - mse: 0.0565 - pearson_correlation: -2.9427e-16 - r2_keras: -112.4107 - rmse: 0.9267 - sae: 2668.1765 - sse: 3517.8574\n","Epoch 61: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0223 - loss: 0.2121 - mae: 0.1322 - mse: 0.0492 - pearson_correlation: -2.2345e-16 - r2_keras: -92.4524 - rmse: 0.9162 - sae: 1951.3163 - sse: 2554.5637 - val_huber_loss: 0.1082 - val_loss: 0.2956 - val_mae: 0.3285 - val_mse: 0.2281 - val_pearson_correlation: -3.1122e-16 - val_r2_keras: -33.4465 - val_rmse: 0.9557 - val_sae: 353.2090 - val_sse: 483.2188 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0283 - loss: 0.2157 - mae: 0.1453 - mse: 0.0565 - pearson_correlation: 7.2917e-17 - r2_keras: -112.3434 - rmse: 0.9265 - sae: 2667.4324 - sse: 3515.7690\n","Epoch 62: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0222 - loss: 0.2121 - mae: 0.1323 - mse: 0.0492 - pearson_correlation: 4.1174e-17 - r2_keras: -92.4069 - rmse: 0.9160 - sae: 1950.8239 - sse: 2553.1646 - val_huber_loss: 0.1083 - val_loss: 0.2958 - val_mae: 0.3290 - val_mse: 0.2285 - val_pearson_correlation: -7.3606e-17 - val_r2_keras: -33.4374 - val_rmse: 0.9556 - val_sae: 353.0698 - val_sse: 483.0915 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0282 - loss: 0.2157 - mae: 0.1450 - mse: 0.0564 - pearson_correlation: 2.2915e-18 - r2_keras: -112.4761 - rmse: 0.9270 - sae: 2668.5386 - sse: 3519.8857\n","Epoch 63: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0222 - loss: 0.2120 - mae: 0.1320 - mse: 0.0491 - pearson_correlation: 3.0438e-17 - r2_keras: -92.5031 - rmse: 0.9164 - sae: 1951.5951 - sse: 2556.0000 - val_huber_loss: 0.1083 - val_loss: 0.2958 - val_mae: 0.3289 - val_mse: 0.2284 - val_pearson_correlation: 1.5836e-16 - val_r2_keras: -33.4594 - val_rmse: 0.9559 - val_sae: 353.2745 - val_sse: 483.4003 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0281 - loss: 0.2156 - mae: 0.1450 - mse: 0.0563 - pearson_correlation: -2.4476e-16 - r2_keras: -112.4426 - rmse: 0.9269 - sae: 2668.3174 - sse: 3518.8474\n","Epoch 64: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0222 - loss: 0.2119 - mae: 0.1320 - mse: 0.0490 - pearson_correlation: -1.7226e-16 - r2_keras: -92.4823 - rmse: 0.9163 - sae: 1951.4156 - sse: 2555.3257 - val_huber_loss: 0.1084 - val_loss: 0.2958 - val_mae: 0.3290 - val_mse: 0.2285 - val_pearson_correlation: 2.9988e-16 - val_r2_keras: -33.4519 - val_rmse: 0.9558 - val_sae: 353.2179 - val_sse: 483.2943 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0281 - loss: 0.2156 - mae: 0.1447 - mse: 0.0563 - pearson_correlation: 7.3984e-16 - r2_keras: -112.5863 - rmse: 0.9275 - sae: 2669.7627 - sse: 3523.3042\n","Epoch 65: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0221 - loss: 0.2119 - mae: 0.1317 - mse: 0.0490 - pearson_correlation: 5.0066e-16 - r2_keras: -92.5789 - rmse: 0.9167 - sae: 1952.3868 - sse: 2558.3059 - val_huber_loss: 0.1085 - val_loss: 0.2959 - val_mae: 0.3295 - val_mse: 0.2287 - val_pearson_correlation: 3.3920e-17 - val_r2_keras: -33.4688 - val_rmse: 0.9561 - val_sae: 353.2725 - val_sse: 483.5315 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0281 - loss: 0.2155 - mae: 0.1447 - mse: 0.0561 - pearson_correlation: 2.6240e-16 - r2_keras: -112.5131 - rmse: 0.9272 - sae: 2668.9595 - sse: 3521.0342\n","Epoch 66: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0221 - loss: 0.2118 - mae: 0.1317 - mse: 0.0488 - pearson_correlation: 2.6822e-16 - r2_keras: -92.5376 - rmse: 0.9166 - sae: 1951.8973 - sse: 2556.8801 - val_huber_loss: 0.1086 - val_loss: 0.2960 - val_mae: 0.3294 - val_mse: 0.2288 - val_pearson_correlation: 9.0382e-17 - val_r2_keras: -33.4841 - val_rmse: 0.9563 - val_sae: 353.4319 - val_sse: 483.7461 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0280 - loss: 0.2154 - mae: 0.1447 - mse: 0.0560 - pearson_correlation: 7.7156e-17 - r2_keras: -112.4643 - rmse: 0.9270 - sae: 2668.6172 - sse: 3519.5210\n","Epoch 67: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0221 - loss: 0.2118 - mae: 0.1317 - mse: 0.0488 - pearson_correlation: 1.0178e-16 - r2_keras: -92.5093 - rmse: 0.9165 - sae: 1951.6691 - sse: 2555.9209 - val_huber_loss: 0.1087 - val_loss: 0.2961 - val_mae: 0.3298 - val_mse: 0.2291 - val_pearson_correlation: 1.7535e-16 - val_r2_keras: -33.4582 - val_rmse: 0.9559 - val_sae: 353.2100 - val_sse: 483.3827 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0280 - loss: 0.2154 - mae: 0.1445 - mse: 0.0560 - pearson_correlation: 5.1367e-17 - r2_keras: -112.5988 - rmse: 0.9275 - sae: 2669.6619 - sse: 3523.6936\n","Epoch 68: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0220 - loss: 0.2117 - mae: 0.1314 - mse: 0.0488 - pearson_correlation: 3.8371e-17 - r2_keras: -92.6014 - rmse: 0.9169 - sae: 1952.3505 - sse: 2558.7319 - val_huber_loss: 0.1088 - val_loss: 0.2962 - val_mae: 0.3304 - val_mse: 0.2294 - val_pearson_correlation: -3.3887e-17 - val_r2_keras: -33.4913 - val_rmse: 0.9564 - val_sae: 353.4297 - val_sse: 483.8479 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0279 - loss: 0.2153 - mae: 0.1446 - mse: 0.0559 - pearson_correlation: 5.2374e-16 - r2_keras: -112.5221 - rmse: 0.9272 - sae: 2669.2593 - sse: 3521.3125\n","Epoch 69: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0220 - loss: 0.2117 - mae: 0.1315 - mse: 0.0486 - pearson_correlation: 3.6236e-16 - r2_keras: -92.5511 - rmse: 0.9167 - sae: 1952.1276 - sse: 2557.1543 - val_huber_loss: 0.1088 - val_loss: 0.2962 - val_mae: 0.3303 - val_mse: 0.2294 - val_pearson_correlation: 1.1296e-17 - val_r2_keras: -33.4883 - val_rmse: 0.9563 - val_sae: 353.4362 - val_sse: 483.8049 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0279 - loss: 0.2152 - mae: 0.1445 - mse: 0.0558 - pearson_correlation: -9.9288e-18 - r2_keras: -112.4857 - rmse: 0.9270 - sae: 2668.8452 - sse: 3520.1860\n","Epoch 70: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0220 - loss: 0.2116 - mae: 0.1315 - mse: 0.0486 - pearson_correlation: -2.8893e-17 - r2_keras: -92.5316 - rmse: 0.9166 - sae: 1951.8475 - sse: 2556.4585 - val_huber_loss: 0.1090 - val_loss: 0.2963 - val_mae: 0.3306 - val_mse: 0.2297 - val_pearson_correlation: 1.5837e-16 - val_r2_keras: -33.4601 - val_rmse: 0.9559 - val_sae: 353.1888 - val_sse: 483.4105 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0278 - loss: 0.2152 - mae: 0.1442 - mse: 0.0557 - pearson_correlation: -1.1847e-16 - r2_keras: -112.6244 - rmse: 0.9276 - sae: 2669.8018 - sse: 3524.4878\n","Epoch 71: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0219 - loss: 0.2116 - mae: 0.1312 - mse: 0.0485 - pearson_correlation: -1.3342e-16 - r2_keras: -92.6271 - rmse: 0.9170 - sae: 1952.4763 - sse: 2559.3618 - val_huber_loss: 0.1091 - val_loss: 0.2964 - val_mae: 0.3306 - val_mse: 0.2298 - val_pearson_correlation: 3.9521e-17 - val_r2_keras: -33.4986 - val_rmse: 0.9565 - val_sae: 353.4940 - val_sse: 483.9507 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0278 - loss: 0.2151 - mae: 0.1442 - mse: 0.0556 - pearson_correlation: -4.6165e-16 - r2_keras: -112.5757 - rmse: 0.9274 - sae: 2669.8345 - sse: 3522.9766\n","Epoch 72: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0219 - loss: 0.2115 - mae: 0.1311 - mse: 0.0484 - pearson_correlation: -3.2013e-16 - r2_keras: -92.6004 - rmse: 0.9169 - sae: 1952.5157 - sse: 2558.4221 - val_huber_loss: 0.1092 - val_loss: 0.2965 - val_mae: 0.3311 - val_mse: 0.2302 - val_pearson_correlation: 7.3440e-17 - val_r2_keras: -33.4875 - val_rmse: 0.9563 - val_sae: 353.3416 - val_sse: 483.7948 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0278 - loss: 0.2151 - mae: 0.1439 - mse: 0.0555 - pearson_correlation: 1.3336e-16 - r2_keras: -112.7067 - rmse: 0.9280 - sae: 2670.7485 - sse: 3527.0396\n","Epoch 73: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0219 - loss: 0.2115 - mae: 0.1309 - mse: 0.0484 - pearson_correlation: 6.0064e-17 - r2_keras: -92.6976 - rmse: 0.9174 - sae: 1953.2028 - sse: 2561.2468 - val_huber_loss: 0.1091 - val_loss: 0.2964 - val_mae: 0.3311 - val_mse: 0.2300 - val_pearson_correlation: -1.9183e-16 - val_r2_keras: -33.5122 - val_rmse: 0.9567 - val_sae: 353.5518 - val_sse: 484.1405 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0277 - loss: 0.2150 - mae: 0.1439 - mse: 0.0554 - pearson_correlation: -2.1046e-16 - r2_keras: -112.6429 - rmse: 0.9277 - sae: 2670.2190 - sse: 3525.0605\n","Epoch 74: val_loss did not improve from 0.28695\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0218 - loss: 0.2114 - mae: 0.1309 - mse: 0.0482 - pearson_correlation: -1.0157e-16 - r2_keras: -92.6524 - rmse: 0.9172 - sae: 1952.8181 - sse: 2559.8965 - val_huber_loss: 0.1093 - val_loss: 0.2966 - val_mae: 0.3315 - val_mse: 0.2304 - val_pearson_correlation: -4.5168e-16 - val_r2_keras: -33.4984 - val_rmse: 0.9565 - val_sae: 353.4081 - val_sse: 483.9474 - learning_rate: 1.0000e-05\n","| \u001b[39m9        \u001b[39m | \u001b[39m-0.2966  \u001b[39m | \u001b[39m0.002274 \u001b[39m | \u001b[39m95.19    \u001b[39m | \u001b[39m69.61    \u001b[39m | \u001b[39m66.7     \u001b[39m | \u001b[39m15.65    \u001b[39m | \u001b[39m25.19    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.5361 - loss: 0.7186 - mae: 0.9044 - mse: 1.3713 - pearson_correlation: -8.9540e-17 - r2_keras: -157.7369 - rmse: 1.0964 - sae: 3472.2759 - sse: 4923.8208\n","Epoch 1: val_loss improved from inf to 0.42888, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 651ms/step - huber_loss: 0.4138 - loss: 0.6447 - mae: 0.8089 - mse: 1.1661 - pearson_correlation: 5.3336e-17 - r2_keras: -122.8005 - rmse: 1.0304 - sae: 2492.0256 - sse: 3493.4050 - val_huber_loss: 0.2435 - val_loss: 0.4289 - val_mae: 0.5197 - val_mse: 0.6398 - val_pearson_correlation: 1.5333e-16 - val_r2_keras: -23.5426 - val_rmse: 0.8067 - val_sae: 277.5978 - val_sse: 344.2867 - learning_rate: 0.0045\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4939 - loss: 0.6793 - mae: 0.8101 - mse: 1.8823 - pearson_correlation: 1.0868e-17 - r2_keras: -328.7353 - rmse: 1.5802 - sae: 4314.7852 - sse: 10227.9766\n","Epoch 2: val_loss improved from 0.42888 to 0.41367, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.4780 - loss: 0.6696 - mae: 0.8230 - mse: 1.7157 - pearson_correlation: 6.5792e-17 - r2_keras: -241.3070 - rmse: 1.3883 - sae: 3099.7300 - sse: 7082.3828 - val_huber_loss: 0.2284 - val_loss: 0.4137 - val_mae: 0.5357 - val_mse: 0.5786 - val_pearson_correlation: -6.7643e-17 - val_r2_keras: -22.4419 - val_rmse: 0.7884 - val_sae: 296.5031 - val_sse: 328.8460 - learning_rate: 0.0045\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.5293 - loss: 0.7146 - mae: 0.9657 - mse: 1.2116 - pearson_correlation: 1.6173e-16 - r2_keras: -231.3963 - rmse: 1.3266 - sae: 4588.3550 - sse: 7208.6436\n","Epoch 3: val_loss did not improve from 0.41367\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.5335 - loss: 0.7171 - mae: 0.9566 - mse: 1.2488 - pearson_correlation: 1.3311e-16 - r2_keras: -191.8922 - rmse: 1.3195 - sae: 3327.7969 - sse: 5251.0503 - val_huber_loss: 0.2530 - val_loss: 0.4381 - val_mae: 0.5302 - val_mse: 0.6782 - val_pearson_correlation: -7.3812e-17 - val_r2_keras: -24.6663 - val_rmse: 0.8250 - val_sae: 277.7227 - val_sse: 360.0501 - learning_rate: 0.0045\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.3219 - loss: 0.5070 - mae: 0.6936 - mse: 0.7200 - pearson_correlation: -8.5015e-17 - r2_keras: -124.8097 - rmse: 0.9761 - sae: 3278.5681 - sse: 3902.4595\n","Epoch 4: val_loss improved from 0.41367 to 0.39975, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.2919 - loss: 0.4888 - mae: 0.6684 - mse: 0.6731 - pearson_correlation: -2.5804e-17 - r2_keras: -99.6179 - rmse: 0.9397 - sae: 2364.5940 - sse: 2798.0562 - val_huber_loss: 0.2151 - val_loss: 0.3998 - val_mae: 0.4664 - val_mse: 0.5657 - val_pearson_correlation: 8.2216e-17 - val_r2_keras: -25.4452 - val_rmse: 0.8374 - val_sae: 285.1787 - val_sse: 370.9758 - learning_rate: 0.0045\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1963 - loss: 0.3810 - mae: 0.4338 - mse: 0.4559 - pearson_correlation: 1.2019e-16 - r2_keras: -137.6124 - rmse: 1.0246 - sae: 3009.7375 - sse: 4299.5825\n","Epoch 5: val_loss did not improve from 0.39975\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.2264 - loss: 0.3993 - mae: 0.4597 - mse: 0.5026 - pearson_correlation: 1.1043e-16 - r2_keras: -108.5677 - rmse: 0.9756 - sae: 2182.5789 - sse: 3067.6697 - val_huber_loss: 0.2660 - val_loss: 0.4502 - val_mae: 0.6133 - val_mse: 0.6777 - val_pearson_correlation: -5.8591e-17 - val_r2_keras: -26.6441 - val_rmse: 0.8562 - val_sae: 323.6433 - val_sse: 387.7951 - learning_rate: 0.0045\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2383 - loss: 0.4225 - mae: 0.5753 - mse: 0.5196 - pearson_correlation: 1.7141e-16 - r2_keras: -97.4669 - rmse: 0.8635 - sae: 2652.6484 - sse: 3054.3193\n","Epoch 6: val_loss improved from 0.39975 to 0.38628, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1971 - loss: 0.3974 - mae: 0.5330 - mse: 0.4638 - pearson_correlation: -2.8552e-17 - r2_keras: -80.0568 - rmse: 0.8529 - sae: 1938.2570 - sse: 2216.9993 - val_huber_loss: 0.2028 - val_loss: 0.3863 - val_mae: 0.5070 - val_mse: 0.4973 - val_pearson_correlation: 3.2221e-17 - val_r2_keras: -25.5493 - val_rmse: 0.8391 - val_sae: 315.1543 - val_sse: 372.4370 - learning_rate: 0.0045\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1549 - loss: 0.3384 - mae: 0.4389 - mse: 0.3339 - pearson_correlation: -4.3978e-16 - r2_keras: -87.4952 - rmse: 0.8186 - sae: 2488.3208 - sse: 2745.0103\n","Epoch 7: val_loss improved from 0.38628 to 0.34714, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1303 - loss: 0.3233 - mae: 0.4068 - mse: 0.3001 - pearson_correlation: -9.9602e-17 - r2_keras: -75.8117 - rmse: 0.8438 - sae: 1836.7235 - sse: 2038.9762 - val_huber_loss: 0.1646 - val_loss: 0.3471 - val_mae: 0.4304 - val_mse: 0.4017 - val_pearson_correlation: -1.1128e-16 - val_r2_keras: -25.0292 - val_rmse: 0.8308 - val_sae: 313.0808 - val_sse: 365.1405 - learning_rate: 0.0045\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1071 - loss: 0.2896 - mae: 0.3151 - mse: 0.2289 - pearson_correlation: 6.7152e-17 - r2_keras: -86.8330 - rmse: 0.8156 - sae: 2449.8208 - sse: 2724.4697\n","Epoch 8: val_loss improved from 0.34714 to 0.34096, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0989 - loss: 0.2845 - mae: 0.3055 - mse: 0.2162 - pearson_correlation: 7.5648e-17 - r2_keras: -75.7834 - rmse: 0.8452 - sae: 1808.5380 - sse: 2030.1293 - val_huber_loss: 0.1593 - val_loss: 0.3410 - val_mae: 0.4245 - val_mse: 0.3815 - val_pearson_correlation: -2.2548e-16 - val_r2_keras: -25.4286 - val_rmse: 0.8372 - val_sae: 325.3437 - val_sse: 370.7432 - learning_rate: 0.0045\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1458 - loss: 0.3275 - mae: 0.4368 - mse: 0.3089 - pearson_correlation: -1.2366e-16 - r2_keras: -76.5684 - rmse: 0.7664 - sae: 2377.8428 - sse: 2406.0732\n","Epoch 9: val_loss did not improve from 0.34096\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1478 - loss: 0.3286 - mae: 0.4284 - mse: 0.3122 - pearson_correlation: -7.5165e-17 - r2_keras: -75.9539 - rmse: 0.8658 - sae: 1792.4257 - sse: 1900.1340 - val_huber_loss: 0.1630 - val_loss: 0.3438 - val_mae: 0.4567 - val_mse: 0.3810 - val_pearson_correlation: 9.3760e-17 - val_r2_keras: -26.2419 - val_rmse: 0.8499 - val_sae: 337.9132 - val_sse: 382.1521 - learning_rate: 0.0045\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1639 - loss: 0.3446 - mae: 0.4406 - mse: 0.3566 - pearson_correlation: 4.5726e-16 - r2_keras: -79.6879 - rmse: 0.7817 - sae: 2396.5054 - sse: 2502.8384\n","Epoch 10: val_loss did not improve from 0.34096\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1546 - loss: 0.3389 - mae: 0.4284 - mse: 0.3413 - pearson_correlation: 3.4695e-16 - r2_keras: -69.8190 - rmse: 0.8125 - sae: 1777.4183 - sse: 1868.2867 - val_huber_loss: 0.1682 - val_loss: 0.3481 - val_mae: 0.4087 - val_mse: 0.3810 - val_pearson_correlation: -2.3713e-16 - val_r2_keras: -36.9844 - val_rmse: 1.0036 - val_sae: 378.4343 - val_sse: 532.8493 - learning_rate: 0.0045\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1745 - loss: 0.3544 - mae: 0.4080 - mse: 0.3933 - pearson_correlation: -2.7217e-16 - r2_keras: -155.6912 - rmse: 1.0893 - sae: 3281.6460 - sse: 4860.3657\n","Epoch 11: val_loss did not improve from 0.34096\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1713 - loss: 0.3523 - mae: 0.4064 - mse: 0.3919 - pearson_correlation: -1.8505e-16 - r2_keras: -119.9670 - rmse: 1.0131 - sae: 2353.3076 - sse: 3433.8616 - val_huber_loss: 0.2288 - val_loss: 0.4078 - val_mae: 0.4884 - val_mse: 0.5313 - val_pearson_correlation: 2.5410e-16 - val_r2_keras: -37.2308 - val_rmse: 1.0069 - val_sae: 370.4779 - val_sse: 536.3057 - learning_rate: 0.0045\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1705 - loss: 0.3495 - mae: 0.4077 - mse: 0.3686 - pearson_correlation: 4.8587e-16 - r2_keras: -115.9908 - rmse: 0.9413 - sae: 2649.7351 - sse: 3628.9094\n","Epoch 12: val_loss did not improve from 0.34096\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1606 - loss: 0.3434 - mae: 0.4079 - mse: 0.3554 - pearson_correlation: 4.3488e-16 - r2_keras: -93.8450 - rmse: 0.9174 - sae: 1940.4606 - sse: 2616.9370 - val_huber_loss: 0.1964 - val_loss: 0.3744 - val_mae: 0.4607 - val_mse: 0.4539 - val_pearson_correlation: -5.6231e-16 - val_r2_keras: -33.1596 - val_rmse: 0.9518 - val_sae: 365.6993 - val_sse: 479.1948 - learning_rate: 0.0045\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1291 - loss: 0.3071 - mae: 0.3568 - mse: 0.2722 - pearson_correlation: 8.4541e-16 - r2_keras: -99.9971 - rmse: 0.8746 - sae: 2544.9644 - sse: 3132.8025\n","Epoch 13: val_loss did not improve from 0.34096\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1170 - loss: 0.2996 - mae: 0.3465 - mse: 0.2555 - pearson_correlation: 5.7567e-16 - r2_keras: -81.5006 - rmse: 0.8581 - sae: 1861.9222 - sse: 2266.4707 - val_huber_loss: 0.1750 - val_loss: 0.3518 - val_mae: 0.4142 - val_mse: 0.3942 - val_pearson_correlation: 4.4053e-16 - val_r2_keras: -36.3944 - val_rmse: 0.9958 - val_sae: 374.8641 - val_sse: 524.5721 - learning_rate: 0.0045\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1322 - loss: 0.3090 - mae: 0.3387 - mse: 0.2823 - pearson_correlation: -3.7815e-16 - r2_keras: -117.4081 - rmse: 0.9469 - sae: 2737.6091 - sse: 3672.8699\n","Epoch 14: val_loss improved from 0.34096 to 0.32472, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - huber_loss: 0.1055 - loss: 0.2927 - mae: 0.3156 - mse: 0.2462 - pearson_correlation: -2.9677e-16 - r2_keras: -93.7053 - rmse: 0.9117 - sae: 1987.8788 - sse: 2633.5229 - val_huber_loss: 0.1482 - val_loss: 0.3247 - val_mae: 0.3824 - val_mse: 0.3275 - val_pearson_correlation: 4.4974e-16 - val_r2_keras: -34.3419 - val_rmse: 0.9681 - val_sae: 368.8346 - val_sse: 495.7798 - learning_rate: 8.9804e-04\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0911 - loss: 0.2676 - mae: 0.2833 - mse: 0.1876 - pearson_correlation: 5.4329e-16 - r2_keras: -105.0644 - rmse: 0.8962 - sae: 2621.9297 - sse: 3289.9863\n","Epoch 15: val_loss improved from 0.32472 to 0.31549, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0748 - loss: 0.2577 - mae: 0.2681 - mse: 0.1667 - pearson_correlation: 3.7562e-16 - r2_keras: -84.5003 - rmse: 0.8691 - sae: 1907.1422 - sse: 2366.8198 - val_huber_loss: 0.1393 - val_loss: 0.3155 - val_mae: 0.3626 - val_mse: 0.3066 - val_pearson_correlation: -1.7604e-16 - val_r2_keras: -33.9337 - val_rmse: 0.9625 - val_sae: 365.8295 - val_sse: 490.0543 - learning_rate: 8.9804e-04\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.2576 - mae: 0.2672 - mse: 0.1674 - pearson_correlation: 2.3093e-16 - r2_keras: -104.4640 - rmse: 0.8937 - sae: 2613.0759 - sse: 3271.3604\n","Epoch 16: val_loss improved from 0.31549 to 0.31029, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0678 - loss: 0.2493 - mae: 0.2536 - mse: 0.1500 - pearson_correlation: 1.2172e-16 - r2_keras: -84.0292 - rmse: 0.8667 - sae: 1901.0341 - sse: 2353.5713 - val_huber_loss: 0.1344 - val_loss: 0.3103 - val_mae: 0.3524 - val_mse: 0.2952 - val_pearson_correlation: 4.4564e-17 - val_r2_keras: -33.6217 - val_rmse: 0.9582 - val_sae: 363.1337 - val_sse: 485.6766 - learning_rate: 8.9804e-04\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0769 - loss: 0.2528 - mae: 0.2565 - mse: 0.1578 - pearson_correlation: -3.3669e-16 - r2_keras: -105.1272 - rmse: 0.8965 - sae: 2618.0891 - sse: 3291.9338\n","Epoch 17: val_loss improved from 0.31029 to 0.30837, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0643 - loss: 0.2451 - mae: 0.2438 - mse: 0.1417 - pearson_correlation: -2.2342e-16 - r2_keras: -84.4825 - rmse: 0.8687 - sae: 1904.4165 - sse: 2367.4177 - val_huber_loss: 0.1328 - val_loss: 0.3084 - val_mae: 0.3500 - val_mse: 0.2910 - val_pearson_correlation: -2.2971e-16 - val_r2_keras: -33.4788 - val_rmse: 0.9562 - val_sae: 361.3277 - val_sse: 483.6727 - learning_rate: 8.9804e-04\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0741 - loss: 0.2497 - mae: 0.2513 - mse: 0.1521 - pearson_correlation: 2.1584e-17 - r2_keras: -104.8928 - rmse: 0.8955 - sae: 2614.1294 - sse: 3284.6628\n","Epoch 18: val_loss improved from 0.30837 to 0.30748, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0618 - loss: 0.2421 - mae: 0.2386 - mse: 0.1363 - pearson_correlation: 5.9720e-17 - r2_keras: -84.5435 - rmse: 0.8700 - sae: 1902.6696 - sse: 2365.1191 - val_huber_loss: 0.1323 - val_loss: 0.3075 - val_mae: 0.3477 - val_mse: 0.2897 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.6317 - val_rmse: 0.9583 - val_sae: 362.2689 - val_sse: 485.8172 - learning_rate: 8.9804e-04\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0716 - loss: 0.2468 - mae: 0.2449 - mse: 0.1467 - pearson_correlation: 5.9223e-16 - r2_keras: -105.5902 - rmse: 0.8984 - sae: 2622.0574 - sse: 3306.2957\n","Epoch 19: val_loss improved from 0.30748 to 0.30694, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0595 - loss: 0.2393 - mae: 0.2324 - mse: 0.1312 - pearson_correlation: 3.8027e-16 - r2_keras: -85.1806 - rmse: 0.8736 - sae: 1908.6976 - sse: 2381.5608 - val_huber_loss: 0.1322 - val_loss: 0.3069 - val_mae: 0.3499 - val_mse: 0.2890 - val_pearson_correlation: -2.8195e-17 - val_r2_keras: -33.3273 - val_rmse: 0.9541 - val_sae: 359.8340 - val_sse: 481.5470 - learning_rate: 8.9804e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0701 - loss: 0.2448 - mae: 0.2413 - mse: 0.1437 - pearson_correlation: -8.6368e-16 - r2_keras: -105.7760 - rmse: 0.8992 - sae: 2623.8594 - sse: 3312.0583\n","Epoch 20: val_loss did not improve from 0.30694\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0578 - loss: 0.2373 - mae: 0.2286 - mse: 0.1280 - pearson_correlation: -6.0282e-16 - r2_keras: -85.3297 - rmse: 0.8743 - sae: 1909.9247 - sse: 2385.6980 - val_huber_loss: 0.1334 - val_loss: 0.3076 - val_mae: 0.3520 - val_mse: 0.2911 - val_pearson_correlation: 1.0926e-17 - val_r2_keras: -34.0730 - val_rmse: 0.9644 - val_sae: 364.4673 - val_sse: 492.0072 - learning_rate: 8.9804e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0678 - loss: 0.2421 - mae: 0.2377 - mse: 0.1390 - pearson_correlation: 3.5144e-16 - r2_keras: -105.0232 - rmse: 0.8961 - sae: 2613.9224 - sse: 3288.7070\n","Epoch 21: val_loss improved from 0.30694 to 0.30485, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0557 - loss: 0.2346 - mae: 0.2240 - mse: 0.1236 - pearson_correlation: 2.4292e-16 - r2_keras: -85.3541 - rmse: 0.8769 - sae: 1905.5142 - sse: 2376.3044 - val_huber_loss: 0.1311 - val_loss: 0.3048 - val_mae: 0.3464 - val_mse: 0.2863 - val_pearson_correlation: -3.0081e-16 - val_r2_keras: -32.7661 - val_rmse: 0.9463 - val_sae: 355.4787 - val_sse: 473.6750 - learning_rate: 8.9804e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0662 - loss: 0.2399 - mae: 0.2323 - mse: 0.1355 - pearson_correlation: 7.3798e-16 - r2_keras: -106.0634 - rmse: 0.9004 - sae: 2627.6997 - sse: 3320.9724\n","Epoch 22: val_loss did not improve from 0.30485\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0544 - loss: 0.2327 - mae: 0.2195 - mse: 0.1205 - pearson_correlation: 5.0887e-16 - r2_keras: -85.6175 - rmse: 0.8760 - sae: 1912.8662 - sse: 2392.7695 - val_huber_loss: 0.1400 - val_loss: 0.3132 - val_mae: 0.3702 - val_mse: 0.3066 - val_pearson_correlation: -1.6935e-16 - val_r2_keras: -34.8593 - val_rmse: 0.9752 - val_sae: 367.0839 - val_sse: 503.0375 - learning_rate: 8.9804e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0649 - loss: 0.2381 - mae: 0.2343 - mse: 0.1333 - pearson_correlation: 1.5694e-16 - r2_keras: -103.6971 - rmse: 0.8904 - sae: 2594.5781 - sse: 3247.5742\n","Epoch 23: val_loss improved from 0.30485 to 0.30127, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0526 - loss: 0.2305 - mae: 0.2189 - mse: 0.1176 - pearson_correlation: 9.0123e-17 - r2_keras: -85.2160 - rmse: 0.8798 - sae: 1895.7465 - sse: 2357.6321 - val_huber_loss: 0.1286 - val_loss: 0.3013 - val_mae: 0.3461 - val_mse: 0.2801 - val_pearson_correlation: 8.8491e-17 - val_r2_keras: -32.3613 - val_rmse: 0.9406 - val_sae: 352.0876 - val_sse: 467.9965 - learning_rate: 8.9804e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0631 - loss: 0.2357 - mae: 0.2250 - mse: 0.1295 - pearson_correlation: 1.8367e-16 - r2_keras: -103.6702 - rmse: 0.8903 - sae: 2596.2061 - sse: 3246.7378\n","Epoch 24: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0512 - loss: 0.2284 - mae: 0.2103 - mse: 0.1143 - pearson_correlation: 1.1200e-16 - r2_keras: -84.5676 - rmse: 0.8741 - sae: 1894.0879 - sse: 2349.6794 - val_huber_loss: 0.1448 - val_loss: 0.3168 - val_mae: 0.3789 - val_mse: 0.3199 - val_pearson_correlation: -8.1653e-17 - val_r2_keras: -35.8435 - val_rmse: 0.9884 - val_sae: 372.3105 - val_sse: 516.8440 - learning_rate: 8.9804e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0612 - loss: 0.2333 - mae: 0.2255 - mse: 0.1260 - pearson_correlation: -3.3354e-16 - r2_keras: -102.4074 - rmse: 0.8849 - sae: 2575.3889 - sse: 3207.5688\n","Epoch 25: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0495 - loss: 0.2261 - mae: 0.2100 - mse: 0.1111 - pearson_correlation: -1.1827e-16 - r2_keras: -84.7564 - rmse: 0.8796 - sae: 1884.2955 - sse: 2335.6560 - val_huber_loss: 0.1313 - val_loss: 0.3027 - val_mae: 0.3456 - val_mse: 0.2864 - val_pearson_correlation: -2.2692e-16 - val_r2_keras: -32.4073 - val_rmse: 0.9412 - val_sae: 351.6623 - val_sse: 468.6411 - learning_rate: 8.9804e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0609 - loss: 0.2324 - mae: 0.2160 - mse: 0.1246 - pearson_correlation: -4.0638e-16 - r2_keras: -106.5818 - rmse: 0.9026 - sae: 2626.1909 - sse: 3337.0537\n","Epoch 26: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0499 - loss: 0.2256 - mae: 0.2032 - mse: 0.1107 - pearson_correlation: -2.9191e-16 - r2_keras: -86.4567 - rmse: 0.8819 - sae: 1913.8602 - sse: 2409.2803 - val_huber_loss: 0.1470 - val_loss: 0.3178 - val_mae: 0.3805 - val_mse: 0.3276 - val_pearson_correlation: 3.6509e-16 - val_r2_keras: -37.6298 - val_rmse: 1.0121 - val_sae: 381.7220 - val_sse: 541.9036 - learning_rate: 8.9804e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0620 - loss: 0.2327 - mae: 0.2319 - mse: 0.1275 - pearson_correlation: 1.3843e-16 - r2_keras: -101.4222 - rmse: 0.8807 - sae: 2560.3276 - sse: 3177.0073\n","Epoch 27: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0513 - loss: 0.2262 - mae: 0.2135 - mse: 0.1138 - pearson_correlation: 4.6333e-17 - r2_keras: -85.5712 - rmse: 0.8892 - sae: 1881.6030 - sse: 2332.5447 - val_huber_loss: 0.1352 - val_loss: 0.3054 - val_mae: 0.3605 - val_mse: 0.2959 - val_pearson_correlation: 6.3029e-17 - val_r2_keras: -31.5414 - val_rmse: 0.9289 - val_sae: 348.3968 - val_sse: 456.4944 - learning_rate: 8.9804e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0595 - loss: 0.2296 - mae: 0.2105 - mse: 0.1214 - pearson_correlation: -1.4072e-16 - r2_keras: -104.1532 - rmse: 0.8924 - sae: 2605.3564 - sse: 3261.7207\n","Epoch 28: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0489 - loss: 0.2231 - mae: 0.2007 - mse: 0.1080 - pearson_correlation: -6.2523e-17 - r2_keras: -84.5289 - rmse: 0.8723 - sae: 1898.9459 - sse: 2355.4368 - val_huber_loss: 0.1532 - val_loss: 0.3226 - val_mae: 0.3865 - val_mse: 0.3405 - val_pearson_correlation: -4.7607e-17 - val_r2_keras: -37.9371 - val_rmse: 1.0161 - val_sae: 383.2190 - val_sse: 546.2132 - learning_rate: 8.9804e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0596 - loss: 0.2290 - mae: 0.2155 - mse: 0.1217 - pearson_correlation: -1.7521e-16 - r2_keras: -108.7972 - rmse: 0.9119 - sae: 2646.7573 - sse: 3405.7725\n","Epoch 29: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0489 - loss: 0.2225 - mae: 0.2024 - mse: 0.1082 - pearson_correlation: -9.1651e-18 - r2_keras: -90.8102 - rmse: 0.9126 - sae: 1939.5438 - sse: 2488.8352 - val_huber_loss: 0.1538 - val_loss: 0.3231 - val_mae: 0.3906 - val_mse: 0.3413 - val_pearson_correlation: -1.7328e-16 - val_r2_keras: -36.7255 - val_rmse: 1.0002 - val_sae: 376.6086 - val_sse: 529.2175 - learning_rate: 1.7961e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0558 - loss: 0.2252 - mae: 0.2041 - mse: 0.1137 - pearson_correlation: -3.7105e-16 - r2_keras: -106.4794 - rmse: 0.9022 - sae: 2621.1516 - sse: 3333.8760\n","Epoch 30: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0443 - loss: 0.2181 - mae: 0.1880 - mse: 0.0992 - pearson_correlation: -3.4101e-16 - r2_keras: -88.3023 - rmse: 0.8981 - sae: 1918.0081 - sse: 2429.6116 - val_huber_loss: 0.1536 - val_loss: 0.3227 - val_mae: 0.3926 - val_mse: 0.3391 - val_pearson_correlation: 5.0840e-17 - val_r2_keras: -35.9515 - val_rmse: 0.9899 - val_sae: 372.1109 - val_sse: 518.3600 - learning_rate: 1.7961e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0546 - loss: 0.2238 - mae: 0.2030 - mse: 0.1110 - pearson_correlation: -2.5549e-16 - r2_keras: -105.5053 - rmse: 0.8981 - sae: 2608.6296 - sse: 3303.6621\n","Epoch 31: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0428 - loss: 0.2166 - mae: 0.1859 - mse: 0.0962 - pearson_correlation: -2.1481e-16 - r2_keras: -87.2838 - rmse: 0.8923 - sae: 1908.1119 - sse: 2405.1387 - val_huber_loss: 0.1534 - val_loss: 0.3224 - val_mae: 0.3935 - val_mse: 0.3373 - val_pearson_correlation: -5.1589e-17 - val_r2_keras: -35.5440 - val_rmse: 0.9844 - val_sae: 369.7930 - val_sse: 512.6425 - learning_rate: 1.7961e-04\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0539 - loss: 0.2229 - mae: 0.2015 - mse: 0.1095 - pearson_correlation: -3.9398e-16 - r2_keras: -105.4401 - rmse: 0.8978 - sae: 2607.0891 - sse: 3301.6379\n","Epoch 32: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0421 - loss: 0.2157 - mae: 0.1841 - mse: 0.0948 - pearson_correlation: -2.5057e-16 - r2_keras: -87.0994 - rmse: 0.8909 - sae: 1906.5138 - sse: 2402.1372 - val_huber_loss: 0.1525 - val_loss: 0.3213 - val_mae: 0.3926 - val_mse: 0.3341 - val_pearson_correlation: -2.4002e-16 - val_r2_keras: -35.2357 - val_rmse: 0.9803 - val_sae: 368.1405 - val_sse: 508.3187 - learning_rate: 1.7961e-04\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0534 - loss: 0.2223 - mae: 0.1999 - mse: 0.1084 - pearson_correlation: -6.2637e-16 - r2_keras: -105.7262 - rmse: 0.8990 - sae: 2609.7285 - sse: 3310.5122\n","Epoch 33: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0416 - loss: 0.2150 - mae: 0.1823 - mse: 0.0937 - pearson_correlation: -5.3205e-16 - r2_keras: -87.2164 - rmse: 0.8911 - sae: 1907.9348 - sse: 2407.1882 - val_huber_loss: 0.1517 - val_loss: 0.3204 - val_mae: 0.3912 - val_mse: 0.3315 - val_pearson_correlation: 4.4687e-17 - val_r2_keras: -35.0336 - val_rmse: 0.9775 - val_sae: 366.7654 - val_sse: 505.4835 - learning_rate: 1.7961e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0529 - loss: 0.2216 - mae: 0.1991 - mse: 0.1074 - pearson_correlation: -9.5669e-16 - r2_keras: -105.5655 - rmse: 0.8983 - sae: 2605.4893 - sse: 3305.5298\n","Epoch 34: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0411 - loss: 0.2144 - mae: 0.1811 - mse: 0.0927 - pearson_correlation: -6.3519e-16 - r2_keras: -87.1039 - rmse: 0.8906 - sae: 1904.9738 - sse: 2403.8037 - val_huber_loss: 0.1519 - val_loss: 0.3205 - val_mae: 0.3923 - val_mse: 0.3317 - val_pearson_correlation: 6.8337e-17 - val_r2_keras: -35.0377 - val_rmse: 0.9776 - val_sae: 366.8386 - val_sse: 505.5401 - learning_rate: 3.5922e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0528 - loss: 0.2214 - mae: 0.1985 - mse: 0.1071 - pearson_correlation: -5.6194e-17 - r2_keras: -105.6884 - rmse: 0.8989 - sae: 2606.9697 - sse: 3309.3418\n","Epoch 35: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0410 - loss: 0.2142 - mae: 0.1806 - mse: 0.0924 - pearson_correlation: -7.3015e-17 - r2_keras: -87.1912 - rmse: 0.8910 - sae: 1905.9968 - sse: 2406.4077 - val_huber_loss: 0.1520 - val_loss: 0.3206 - val_mae: 0.3928 - val_mse: 0.3317 - val_pearson_correlation: 7.8850e-17 - val_r2_keras: -35.0378 - val_rmse: 0.9776 - val_sae: 366.8470 - val_sse: 505.5417 - learning_rate: 3.5922e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0526 - loss: 0.2212 - mae: 0.1980 - mse: 0.1068 - pearson_correlation: 3.8549e-16 - r2_keras: -105.7920 - rmse: 0.8993 - sae: 2608.0688 - sse: 3312.5557\n","Epoch 36: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0409 - loss: 0.2141 - mae: 0.1801 - mse: 0.0922 - pearson_correlation: 1.8158e-16 - r2_keras: -87.2650 - rmse: 0.8913 - sae: 1906.7598 - sse: 2408.6057 - val_huber_loss: 0.1520 - val_loss: 0.3206 - val_mae: 0.3931 - val_mse: 0.3315 - val_pearson_correlation: -2.7070e-16 - val_r2_keras: -35.0398 - val_rmse: 0.9776 - val_sae: 366.8592 - val_sse: 505.5696 - learning_rate: 3.5922e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0525 - loss: 0.2211 - mae: 0.1976 - mse: 0.1066 - pearson_correlation: -3.4703e-16 - r2_keras: -105.8250 - rmse: 0.8994 - sae: 2608.1611 - sse: 3313.5784\n","Epoch 37: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0408 - loss: 0.2139 - mae: 0.1797 - mse: 0.0920 - pearson_correlation: -3.3189e-16 - r2_keras: -87.2897 - rmse: 0.8914 - sae: 1906.8429 - sse: 2409.3193 - val_huber_loss: 0.1520 - val_loss: 0.3205 - val_mae: 0.3931 - val_mse: 0.3314 - val_pearson_correlation: -1.9712e-16 - val_r2_keras: -35.0382 - val_rmse: 0.9776 - val_sae: 366.7960 - val_sse: 505.5479 - learning_rate: 3.5922e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0524 - loss: 0.2209 - mae: 0.1972 - mse: 0.1063 - pearson_correlation: 4.5477e-16 - r2_keras: -105.8405 - rmse: 0.8995 - sae: 2607.9077 - sse: 3314.0576\n","Epoch 38: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0407 - loss: 0.2138 - mae: 0.1794 - mse: 0.0917 - pearson_correlation: 3.4304e-16 - r2_keras: -87.3047 - rmse: 0.8915 - sae: 1906.6849 - sse: 2409.6941 - val_huber_loss: 0.1521 - val_loss: 0.3205 - val_mae: 0.3933 - val_mse: 0.3313 - val_pearson_correlation: 3.0493e-16 - val_r2_keras: -35.0334 - val_rmse: 0.9775 - val_sae: 366.7744 - val_sse: 505.4802 - learning_rate: 3.5922e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0522 - loss: 0.2207 - mae: 0.1968 - mse: 0.1060 - pearson_correlation: 2.7045e-16 - r2_keras: -105.8941 - rmse: 0.8997 - sae: 2608.3281 - sse: 3315.7224\n","Epoch 39: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0406 - loss: 0.2136 - mae: 0.1789 - mse: 0.0915 - pearson_correlation: 1.7683e-16 - r2_keras: -87.3419 - rmse: 0.8917 - sae: 1906.9598 - sse: 2410.8206 - val_huber_loss: 0.1521 - val_loss: 0.3206 - val_mae: 0.3936 - val_mse: 0.3315 - val_pearson_correlation: 4.2303e-16 - val_r2_keras: -35.0459 - val_rmse: 0.9777 - val_sae: 366.8353 - val_sse: 505.6555 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0522 - loss: 0.2206 - mae: 0.1967 - mse: 0.1059 - pearson_correlation: 6.8968e-16 - r2_keras: -105.8914 - rmse: 0.8997 - sae: 2608.1660 - sse: 3315.6365\n","Epoch 40: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0405 - loss: 0.2135 - mae: 0.1788 - mse: 0.0914 - pearson_correlation: 4.6758e-16 - r2_keras: -87.3410 - rmse: 0.8917 - sae: 1906.8524 - sse: 2410.7744 - val_huber_loss: 0.1522 - val_loss: 0.3206 - val_mae: 0.3937 - val_mse: 0.3315 - val_pearson_correlation: -5.2537e-17 - val_r2_keras: -35.0528 - val_rmse: 0.9778 - val_sae: 366.8776 - val_sse: 505.7521 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0522 - loss: 0.2206 - mae: 0.1966 - mse: 0.1058 - pearson_correlation: -1.6435e-16 - r2_keras: -105.8902 - rmse: 0.8997 - sae: 2608.0200 - sse: 3315.6006\n","Epoch 41: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0405 - loss: 0.2135 - mae: 0.1787 - mse: 0.0913 - pearson_correlation: -1.4768e-16 - r2_keras: -87.3414 - rmse: 0.8917 - sae: 1906.7568 - sse: 2410.7646 - val_huber_loss: 0.1521 - val_loss: 0.3206 - val_mae: 0.3938 - val_mse: 0.3314 - val_pearson_correlation: -9.7175e-17 - val_r2_keras: -35.0576 - val_rmse: 0.9778 - val_sae: 366.9128 - val_sse: 505.8201 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0521 - loss: 0.2205 - mae: 0.1965 - mse: 0.1057 - pearson_correlation: -2.8903e-16 - r2_keras: -105.8981 - rmse: 0.8997 - sae: 2607.9941 - sse: 3315.8442\n","Epoch 42: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0405 - loss: 0.2134 - mae: 0.1786 - mse: 0.0912 - pearson_correlation: -2.2300e-16 - r2_keras: -87.3478 - rmse: 0.8917 - sae: 1906.7438 - sse: 2410.9404 - val_huber_loss: 0.1521 - val_loss: 0.3205 - val_mae: 0.3938 - val_mse: 0.3313 - val_pearson_correlation: -2.4952e-16 - val_r2_keras: -35.0562 - val_rmse: 0.9778 - val_sae: 366.9105 - val_sse: 505.7999 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0521 - loss: 0.2205 - mae: 0.1964 - mse: 0.1057 - pearson_correlation: 1.2578e-16 - r2_keras: -105.8973 - rmse: 0.8997 - sae: 2607.8076 - sse: 3315.8208\n","Epoch 43: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0404 - loss: 0.2134 - mae: 0.1785 - mse: 0.0912 - pearson_correlation: 1.3409e-16 - r2_keras: -87.3492 - rmse: 0.8917 - sae: 1906.6293 - sse: 2410.9465 - val_huber_loss: 0.1521 - val_loss: 0.3205 - val_mae: 0.3938 - val_mse: 0.3312 - val_pearson_correlation: 3.1778e-16 - val_r2_keras: -35.0588 - val_rmse: 0.9779 - val_sae: 366.9320 - val_sse: 505.8364 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0520 - loss: 0.2204 - mae: 0.1963 - mse: 0.1056 - pearson_correlation: 3.1471e-16 - r2_keras: -105.9032 - rmse: 0.8998 - sae: 2607.7751 - sse: 3316.0034\n","Epoch 44: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0404 - loss: 0.2133 - mae: 0.1784 - mse: 0.0911 - pearson_correlation: 2.3406e-16 - r2_keras: -87.3551 - rmse: 0.8918 - sae: 1906.6134 - sse: 2411.0916 - val_huber_loss: 0.1521 - val_loss: 0.3205 - val_mae: 0.3939 - val_mse: 0.3312 - val_pearson_correlation: 7.8783e-17 - val_r2_keras: -35.0604 - val_rmse: 0.9779 - val_sae: 366.9632 - val_sse: 505.8591 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0520 - loss: 0.2203 - mae: 0.1961 - mse: 0.1055 - pearson_correlation: 6.6530e-16 - r2_keras: -105.9312 - rmse: 0.8999 - sae: 2608.0649 - sse: 3316.8706\n","Epoch 45: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0403 - loss: 0.2133 - mae: 0.1783 - mse: 0.0910 - pearson_correlation: 3.8812e-16 - r2_keras: -87.3754 - rmse: 0.8918 - sae: 1906.8151 - sse: 2411.6899 - val_huber_loss: 0.1521 - val_loss: 0.3204 - val_mae: 0.3938 - val_mse: 0.3310 - val_pearson_correlation: 1.8120e-16 - val_r2_keras: -35.0605 - val_rmse: 0.9779 - val_sae: 366.9600 - val_sse: 505.8600 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0519 - loss: 0.2203 - mae: 0.1960 - mse: 0.1054 - pearson_correlation: 9.0330e-16 - r2_keras: -105.9388 - rmse: 0.8999 - sae: 2607.9883 - sse: 3317.1064\n","Epoch 46: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0403 - loss: 0.2132 - mae: 0.1782 - mse: 0.0909 - pearson_correlation: 5.9614e-16 - r2_keras: -87.3816 - rmse: 0.8919 - sae: 1906.7631 - sse: 2411.8596 - val_huber_loss: 0.1520 - val_loss: 0.3203 - val_mae: 0.3937 - val_mse: 0.3309 - val_pearson_correlation: 2.0224e-16 - val_r2_keras: -35.0569 - val_rmse: 0.9778 - val_sae: 366.9449 - val_sse: 505.8104 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0519 - loss: 0.2202 - mae: 0.1959 - mse: 0.1053 - pearson_correlation: -2.6346e-16 - r2_keras: -105.9427 - rmse: 0.8999 - sae: 2607.8772 - sse: 3317.2300\n","Epoch 47: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0403 - loss: 0.2131 - mae: 0.1781 - mse: 0.0908 - pearson_correlation: -1.6265e-16 - r2_keras: -87.3864 - rmse: 0.8919 - sae: 1906.7010 - sse: 2411.9670 - val_huber_loss: 0.1520 - val_loss: 0.3203 - val_mae: 0.3937 - val_mse: 0.3308 - val_pearson_correlation: 8.6669e-17 - val_r2_keras: -35.0580 - val_rmse: 0.9779 - val_sae: 366.9569 - val_sse: 505.8258 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0518 - loss: 0.2202 - mae: 0.1958 - mse: 0.1052 - pearson_correlation: 9.4541e-17 - r2_keras: -105.9614 - rmse: 0.9000 - sae: 2607.9846 - sse: 3317.8081\n","Epoch 48: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0402 - loss: 0.2131 - mae: 0.1779 - mse: 0.0907 - pearson_correlation: 1.8886e-17 - r2_keras: -87.4021 - rmse: 0.8920 - sae: 1906.7848 - sse: 2412.3916 - val_huber_loss: 0.1519 - val_loss: 0.3202 - val_mae: 0.3937 - val_mse: 0.3306 - val_pearson_correlation: 7.3530e-17 - val_r2_keras: -35.0607 - val_rmse: 0.9779 - val_sae: 366.9929 - val_sse: 505.8632 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0518 - loss: 0.2201 - mae: 0.1956 - mse: 0.1051 - pearson_correlation: 2.3764e-17 - r2_keras: -105.9884 - rmse: 0.9001 - sae: 2608.2339 - sse: 3318.6465\n","Epoch 49: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0402 - loss: 0.2130 - mae: 0.1778 - mse: 0.0906 - pearson_correlation: 1.1516e-17 - r2_keras: -87.4223 - rmse: 0.8921 - sae: 1906.9626 - sse: 2412.9763 - val_huber_loss: 0.1519 - val_loss: 0.3201 - val_mae: 0.3936 - val_mse: 0.3305 - val_pearson_correlation: -1.7074e-16 - val_r2_keras: -35.0533 - val_rmse: 0.9778 - val_sae: 366.9453 - val_sse: 505.7597 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0518 - loss: 0.2200 - mae: 0.1955 - mse: 0.1050 - pearson_correlation: -7.2790e-16 - r2_keras: -105.9939 - rmse: 0.9001 - sae: 2608.1179 - sse: 3318.8179\n","Epoch 50: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0402 - loss: 0.2130 - mae: 0.1777 - mse: 0.0906 - pearson_correlation: -4.6191e-16 - r2_keras: -87.4273 - rmse: 0.8921 - sae: 1906.8840 - sse: 2413.1057 - val_huber_loss: 0.1518 - val_loss: 0.3201 - val_mae: 0.3936 - val_mse: 0.3304 - val_pearson_correlation: 6.3039e-17 - val_r2_keras: -35.0553 - val_rmse: 0.9778 - val_sae: 366.9858 - val_sse: 505.7878 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0517 - loss: 0.2200 - mae: 0.1954 - mse: 0.1049 - pearson_correlation: 5.0911e-16 - r2_keras: -106.0422 - rmse: 0.9003 - sae: 2608.7136 - sse: 3320.3142\n","Epoch 51: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0401 - loss: 0.2129 - mae: 0.1775 - mse: 0.0905 - pearson_correlation: 3.6969e-16 - r2_keras: -87.4620 - rmse: 0.8923 - sae: 1907.2948 - sse: 2414.1328 - val_huber_loss: 0.1518 - val_loss: 0.3200 - val_mae: 0.3934 - val_mse: 0.3302 - val_pearson_correlation: 3.2843e-16 - val_r2_keras: -35.0471 - val_rmse: 0.9777 - val_sae: 366.9281 - val_sse: 505.6724 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0517 - loss: 0.2199 - mae: 0.1953 - mse: 0.1048 - pearson_correlation: 1.2337e-16 - r2_keras: -106.0510 - rmse: 0.9004 - sae: 2608.5908 - sse: 3320.5891\n","Epoch 52: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0401 - loss: 0.2128 - mae: 0.1774 - mse: 0.0904 - pearson_correlation: 7.6194e-17 - r2_keras: -87.4698 - rmse: 0.8923 - sae: 1907.2135 - sse: 2414.3386 - val_huber_loss: 0.1517 - val_loss: 0.3200 - val_mae: 0.3935 - val_mse: 0.3301 - val_pearson_correlation: 2.2593e-16 - val_r2_keras: -35.0505 - val_rmse: 0.9777 - val_sae: 366.9761 - val_sse: 505.7200 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0516 - loss: 0.2198 - mae: 0.1951 - mse: 0.1047 - pearson_correlation: 3.4512e-16 - r2_keras: -106.0929 - rmse: 0.9006 - sae: 2609.1145 - sse: 3321.8884\n","Epoch 53: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0400 - loss: 0.2128 - mae: 0.1772 - mse: 0.0903 - pearson_correlation: 2.3527e-16 - r2_keras: -87.5008 - rmse: 0.8925 - sae: 1907.5753 - sse: 2415.2405 - val_huber_loss: 0.1517 - val_loss: 0.3199 - val_mae: 0.3933 - val_mse: 0.3299 - val_pearson_correlation: 1.3138e-17 - val_r2_keras: -35.0455 - val_rmse: 0.9777 - val_sae: 366.9395 - val_sse: 505.6501 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0516 - loss: 0.2198 - mae: 0.1950 - mse: 0.1046 - pearson_correlation: -6.4654e-17 - r2_keras: -106.0988 - rmse: 0.9006 - sae: 2608.9167 - sse: 3322.0706\n","Epoch 54: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0400 - loss: 0.2127 - mae: 0.1771 - mse: 0.0902 - pearson_correlation: -4.3103e-17 - r2_keras: -87.5083 - rmse: 0.8925 - sae: 1907.4569 - sse: 2415.4043 - val_huber_loss: 0.1517 - val_loss: 0.3198 - val_mae: 0.3933 - val_mse: 0.3298 - val_pearson_correlation: 2.5483e-16 - val_r2_keras: -35.0500 - val_rmse: 0.9777 - val_sae: 366.9861 - val_sse: 505.7131 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0515 - loss: 0.2197 - mae: 0.1948 - mse: 0.1045 - pearson_correlation: -5.6671e-16 - r2_keras: -106.1248 - rmse: 0.9007 - sae: 2609.1992 - sse: 3322.8760\n","Epoch 55: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0400 - loss: 0.2126 - mae: 0.1770 - mse: 0.0901 - pearson_correlation: -4.5822e-16 - r2_keras: -87.5262 - rmse: 0.8926 - sae: 1907.6437 - sse: 2415.9480 - val_huber_loss: 0.1516 - val_loss: 0.3198 - val_mae: 0.3932 - val_mse: 0.3297 - val_pearson_correlation: -2.3645e-16 - val_r2_keras: -35.0491 - val_rmse: 0.9777 - val_sae: 366.9773 - val_sse: 505.7000 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0515 - loss: 0.2196 - mae: 0.1947 - mse: 0.1044 - pearson_correlation: -7.1538e-16 - r2_keras: -106.1195 - rmse: 0.9007 - sae: 2608.9077 - sse: 3322.7119\n","Epoch 56: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0399 - loss: 0.2126 - mae: 0.1769 - mse: 0.0900 - pearson_correlation: -5.3050e-16 - r2_keras: -87.5324 - rmse: 0.8926 - sae: 1907.4924 - sse: 2415.9526 - val_huber_loss: 0.1516 - val_loss: 0.3198 - val_mae: 0.3933 - val_mse: 0.3297 - val_pearson_correlation: -1.5764e-17 - val_r2_keras: -35.0487 - val_rmse: 0.9777 - val_sae: 366.9954 - val_sse: 505.6951 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0514 - loss: 0.2196 - mae: 0.1945 - mse: 0.1043 - pearson_correlation: 3.6437e-16 - r2_keras: -106.1851 - rmse: 0.9009 - sae: 2609.6941 - sse: 3324.7478\n","Epoch 57: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0399 - loss: 0.2125 - mae: 0.1767 - mse: 0.0899 - pearson_correlation: 2.8958e-16 - r2_keras: -87.5755 - rmse: 0.8928 - sae: 1908.0081 - sse: 2417.3020 - val_huber_loss: 0.1516 - val_loss: 0.3197 - val_mae: 0.3933 - val_mse: 0.3296 - val_pearson_correlation: 4.2036e-16 - val_r2_keras: -35.0491 - val_rmse: 0.9777 - val_sae: 367.0077 - val_sse: 505.7004 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0514 - loss: 0.2195 - mae: 0.1944 - mse: 0.1042 - pearson_correlation: 2.2779e-16 - r2_keras: -106.2002 - rmse: 0.9010 - sae: 2609.7271 - sse: 3325.2148\n","Epoch 58: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0398 - loss: 0.2125 - mae: 0.1765 - mse: 0.0899 - pearson_correlation: 2.5380e-16 - r2_keras: -87.5909 - rmse: 0.8929 - sae: 1908.0559 - sse: 2417.6765 - val_huber_loss: 0.1516 - val_loss: 0.3197 - val_mae: 0.3933 - val_mse: 0.3296 - val_pearson_correlation: 2.3378e-16 - val_r2_keras: -35.0539 - val_rmse: 0.9778 - val_sae: 367.0428 - val_sse: 505.7679 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0513 - loss: 0.2194 - mae: 0.1942 - mse: 0.1041 - pearson_correlation: 2.1375e-16 - r2_keras: -106.2598 - rmse: 0.9013 - sae: 2610.4241 - sse: 3327.0664\n","Epoch 59: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0398 - loss: 0.2124 - mae: 0.1764 - mse: 0.0898 - pearson_correlation: 1.6064e-16 - r2_keras: -87.6315 - rmse: 0.8931 - sae: 1908.5145 - sse: 2418.9207 - val_huber_loss: 0.1516 - val_loss: 0.3197 - val_mae: 0.3932 - val_mse: 0.3296 - val_pearson_correlation: -1.3128e-17 - val_r2_keras: -35.0658 - val_rmse: 0.9780 - val_sae: 367.0996 - val_sse: 505.9352 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0513 - loss: 0.2193 - mae: 0.1941 - mse: 0.1040 - pearson_correlation: 6.5392e-16 - r2_keras: -106.2404 - rmse: 0.9012 - sae: 2609.9878 - sse: 3326.4644\n","Epoch 60: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0398 - loss: 0.2123 - mae: 0.1762 - mse: 0.0897 - pearson_correlation: 3.8847e-16 - r2_keras: -87.6311 - rmse: 0.8931 - sae: 1908.2804 - sse: 2418.6655 - val_huber_loss: 0.1517 - val_loss: 0.3197 - val_mae: 0.3933 - val_mse: 0.3296 - val_pearson_correlation: -5.2513e-18 - val_r2_keras: -35.0647 - val_rmse: 0.9779 - val_sae: 367.1091 - val_sse: 505.9192 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0512 - loss: 0.2193 - mae: 0.1939 - mse: 0.1039 - pearson_correlation: 7.6995e-16 - r2_keras: -106.3001 - rmse: 0.9014 - sae: 2610.7146 - sse: 3328.3162\n","Epoch 61: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0397 - loss: 0.2123 - mae: 0.1761 - mse: 0.0896 - pearson_correlation: 5.0726e-16 - r2_keras: -87.6667 - rmse: 0.8933 - sae: 1908.7350 - sse: 2419.8511 - val_huber_loss: 0.1517 - val_loss: 0.3197 - val_mae: 0.3933 - val_mse: 0.3296 - val_pearson_correlation: 3.2282e-16 - val_r2_keras: -35.0758 - val_rmse: 0.9781 - val_sae: 367.1672 - val_sse: 506.0750 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0512 - loss: 0.2192 - mae: 0.1938 - mse: 0.1038 - pearson_correlation: -7.7849e-16 - r2_keras: -106.2888 - rmse: 0.9014 - sae: 2610.3794 - sse: 3327.9644\n","Epoch 62: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0397 - loss: 0.2122 - mae: 0.1759 - mse: 0.0895 - pearson_correlation: -5.5696e-16 - r2_keras: -87.6684 - rmse: 0.8933 - sae: 1908.5526 - sse: 2419.7261 - val_huber_loss: 0.1516 - val_loss: 0.3197 - val_mae: 0.3932 - val_mse: 0.3295 - val_pearson_correlation: 1.1025e-16 - val_r2_keras: -35.0709 - val_rmse: 0.9780 - val_sae: 367.1284 - val_sse: 506.0070 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0511 - loss: 0.2191 - mae: 0.1936 - mse: 0.1037 - pearson_correlation: 5.7410e-17 - r2_keras: -106.3255 - rmse: 0.9015 - sae: 2610.6641 - sse: 3329.1035\n","Epoch 63: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0396 - loss: 0.2122 - mae: 0.1758 - mse: 0.0894 - pearson_correlation: -2.7290e-17 - r2_keras: -87.6964 - rmse: 0.8934 - sae: 1908.7517 - sse: 2420.5259 - val_huber_loss: 0.1517 - val_loss: 0.3196 - val_mae: 0.3933 - val_mse: 0.3295 - val_pearson_correlation: 1.2072e-16 - val_r2_keras: -35.0785 - val_rmse: 0.9781 - val_sae: 367.2001 - val_sse: 506.1137 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0511 - loss: 0.2191 - mae: 0.1935 - mse: 0.1036 - pearson_correlation: 1.0554e-16 - r2_keras: -106.3472 - rmse: 0.9016 - sae: 2610.9004 - sse: 3329.7769\n","Epoch 64: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0396 - loss: 0.2121 - mae: 0.1756 - mse: 0.0893 - pearson_correlation: 1.6889e-17 - r2_keras: -87.7146 - rmse: 0.8935 - sae: 1908.9240 - sse: 2421.0193 - val_huber_loss: 0.1517 - val_loss: 0.3197 - val_mae: 0.3934 - val_mse: 0.3297 - val_pearson_correlation: -1.6263e-16 - val_r2_keras: -35.0906 - val_rmse: 0.9783 - val_sae: 367.2618 - val_sse: 506.2822 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0510 - loss: 0.2190 - mae: 0.1933 - mse: 0.1035 - pearson_correlation: -6.4236e-16 - r2_keras: -106.3654 - rmse: 0.9017 - sae: 2610.9570 - sse: 3330.3413\n","Epoch 65: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0396 - loss: 0.2120 - mae: 0.1755 - mse: 0.0892 - pearson_correlation: -4.4635e-16 - r2_keras: -87.7334 - rmse: 0.8936 - sae: 1908.9915 - sse: 2421.4729 - val_huber_loss: 0.1518 - val_loss: 0.3197 - val_mae: 0.3934 - val_mse: 0.3297 - val_pearson_correlation: -1.4951e-16 - val_r2_keras: -35.0907 - val_rmse: 0.9783 - val_sae: 367.2788 - val_sse: 506.2838 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0510 - loss: 0.2190 - mae: 0.1932 - mse: 0.1034 - pearson_correlation: 2.0471e-16 - r2_keras: -106.3986 - rmse: 0.9018 - sae: 2611.3633 - sse: 3331.3696\n","Epoch 66: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0395 - loss: 0.2120 - mae: 0.1753 - mse: 0.0892 - pearson_correlation: 1.8388e-16 - r2_keras: -87.7578 - rmse: 0.8938 - sae: 1909.2627 - sse: 2422.1851 - val_huber_loss: 0.1517 - val_loss: 0.3197 - val_mae: 0.3933 - val_mse: 0.3297 - val_pearson_correlation: 1.1540e-16 - val_r2_keras: -35.0945 - val_rmse: 0.9783 - val_sae: 367.2910 - val_sse: 506.3381 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0509 - loss: 0.2189 - mae: 0.1930 - mse: 0.1033 - pearson_correlation: 3.8438e-16 - r2_keras: -106.4029 - rmse: 0.9019 - sae: 2611.2207 - sse: 3331.5022\n","Epoch 67: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0395 - loss: 0.2119 - mae: 0.1752 - mse: 0.0891 - pearson_correlation: 2.3729e-16 - r2_keras: -87.7639 - rmse: 0.8938 - sae: 1909.1819 - sse: 2422.3127 - val_huber_loss: 0.1518 - val_loss: 0.3197 - val_mae: 0.3934 - val_mse: 0.3298 - val_pearson_correlation: -2.5176e-16 - val_r2_keras: -35.0963 - val_rmse: 0.9784 - val_sae: 367.3056 - val_sse: 506.3631 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0509 - loss: 0.2188 - mae: 0.1929 - mse: 0.1032 - pearson_correlation: -3.1691e-16 - r2_keras: -106.4165 - rmse: 0.9019 - sae: 2611.3057 - sse: 3331.9248\n","Epoch 68: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0395 - loss: 0.2118 - mae: 0.1751 - mse: 0.0890 - pearson_correlation: -1.8801e-16 - r2_keras: -87.7765 - rmse: 0.8939 - sae: 1909.2448 - sse: 2422.6350 - val_huber_loss: 0.1518 - val_loss: 0.3197 - val_mae: 0.3934 - val_mse: 0.3298 - val_pearson_correlation: -3.1731e-16 - val_r2_keras: -35.0978 - val_rmse: 0.9784 - val_sae: 367.3239 - val_sse: 506.3843 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0508 - loss: 0.2187 - mae: 0.1927 - mse: 0.1031 - pearson_correlation: -4.0319e-16 - r2_keras: -106.4506 - rmse: 0.9021 - sae: 2611.6125 - sse: 3332.9824\n","Epoch 69: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0394 - loss: 0.2118 - mae: 0.1749 - mse: 0.0889 - pearson_correlation: -3.1960e-16 - r2_keras: -87.8056 - rmse: 0.8940 - sae: 1909.4791 - sse: 2423.4150 - val_huber_loss: 0.1518 - val_loss: 0.3197 - val_mae: 0.3935 - val_mse: 0.3298 - val_pearson_correlation: 7.3408e-17 - val_r2_keras: -35.1043 - val_rmse: 0.9785 - val_sae: 367.3654 - val_sse: 506.4747 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0508 - loss: 0.2187 - mae: 0.1926 - mse: 0.1030 - pearson_correlation: 6.1989e-16 - r2_keras: -106.4647 - rmse: 0.9021 - sae: 2611.6455 - sse: 3333.4207\n","Epoch 70: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0394 - loss: 0.2117 - mae: 0.1748 - mse: 0.0888 - pearson_correlation: 4.4427e-16 - r2_keras: -87.8146 - rmse: 0.8941 - sae: 1909.4900 - sse: 2423.7019 - val_huber_loss: 0.1519 - val_loss: 0.3197 - val_mae: 0.3935 - val_mse: 0.3299 - val_pearson_correlation: 1.5725e-16 - val_r2_keras: -35.1135 - val_rmse: 0.9786 - val_sae: 367.4348 - val_sse: 506.6045 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0508 - loss: 0.2186 - mae: 0.1924 - mse: 0.1029 - pearson_correlation: -4.4069e-16 - r2_keras: -106.5021 - rmse: 0.9023 - sae: 2612.0615 - sse: 3334.5793\n","Epoch 71: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0393 - loss: 0.2117 - mae: 0.1746 - mse: 0.0887 - pearson_correlation: -3.1875e-16 - r2_keras: -87.8498 - rmse: 0.8942 - sae: 1909.8174 - sse: 2424.5957 - val_huber_loss: 0.1519 - val_loss: 0.3197 - val_mae: 0.3936 - val_mse: 0.3300 - val_pearson_correlation: 1.0483e-17 - val_r2_keras: -35.1137 - val_rmse: 0.9786 - val_sae: 367.4230 - val_sse: 506.6066 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0507 - loss: 0.2185 - mae: 0.1923 - mse: 0.1028 - pearson_correlation: 3.0598e-16 - r2_keras: -106.5123 - rmse: 0.9023 - sae: 2612.0591 - sse: 3334.8955\n","Epoch 72: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0393 - loss: 0.2116 - mae: 0.1745 - mse: 0.0886 - pearson_correlation: 2.5390e-16 - r2_keras: -87.8581 - rmse: 0.8943 - sae: 1909.8126 - sse: 2424.8245 - val_huber_loss: 0.1519 - val_loss: 0.3197 - val_mae: 0.3936 - val_mse: 0.3300 - val_pearson_correlation: -1.7556e-16 - val_r2_keras: -35.1186 - val_rmse: 0.9787 - val_sae: 367.4880 - val_sse: 506.6763 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0507 - loss: 0.2185 - mae: 0.1922 - mse: 0.1027 - pearson_correlation: -5.1837e-16 - r2_keras: -106.5435 - rmse: 0.9025 - sae: 2612.5278 - sse: 3335.8638\n","Epoch 73: val_loss did not improve from 0.30127\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0393 - loss: 0.2115 - mae: 0.1744 - mse: 0.0886 - pearson_correlation: -3.2493e-16 - r2_keras: -87.8833 - rmse: 0.8944 - sae: 1910.1429 - sse: 2425.5208 - val_huber_loss: 0.1519 - val_loss: 0.3197 - val_mae: 0.3936 - val_mse: 0.3300 - val_pearson_correlation: -2.0960e-17 - val_r2_keras: -35.1217 - val_rmse: 0.9787 - val_sae: 367.4890 - val_sse: 506.7184 - learning_rate: 1.0000e-05\n","| \u001b[39m10       \u001b[39m | \u001b[39m-0.3197  \u001b[39m | \u001b[39m0.00449  \u001b[39m | \u001b[39m88.53    \u001b[39m | \u001b[39m65.03    \u001b[39m | \u001b[39m75.05    \u001b[39m | \u001b[39m8.863    \u001b[39m | \u001b[39m99.85    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/step - huber_loss: 1.3710 - loss: 1.5339 - mae: 1.8065 - mse: 4.5961 - pearson_correlation: -1.7612e-16 - r2_keras: -594.1541 - rmse: 2.1230 - sae: 7605.7993 - sse: 18460.9355\n","Epoch 1: val_loss improved from inf to 0.41672, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 651ms/step - huber_loss: 1.2453 - loss: 1.4575 - mae: 1.7355 - mse: 4.2642 - pearson_correlation: -1.2326e-16 - r2_keras: -449.2741 - rmse: 1.9319 - sae: 5415.9829 - sse: 12934.9023 - val_huber_loss: 0.2529 - val_loss: 0.4167 - val_mae: 0.6054 - val_mse: 0.6218 - val_pearson_correlation: -1.6570e-17 - val_r2_keras: -22.0614 - val_rmse: 0.7820 - val_sae: 318.1536 - val_sse: 323.5082 - learning_rate: 0.0028\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2348 - loss: 0.3987 - mae: 0.5482 - mse: 0.5919 - pearson_correlation: 8.2669e-17 - r2_keras: -87.5293 - rmse: 0.8188 - sae: 2577.4800 - sse: 2746.0696\n","Epoch 2: val_loss improved from 0.41672 to 0.40472, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - huber_loss: 0.2068 - loss: 0.3816 - mae: 0.5153 - mse: 0.5404 - pearson_correlation: 1.2086e-16 - r2_keras: -73.6094 - rmse: 0.8247 - sae: 1885.1385 - sse: 2013.5822 - val_huber_loss: 0.2411 - val_loss: 0.4047 - val_mae: 0.5530 - val_mse: 0.6230 - val_pearson_correlation: 6.7373e-17 - val_r2_keras: -22.3655 - val_rmse: 0.7872 - val_sae: 294.3555 - val_sse: 327.7731 - learning_rate: 0.0028\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1795 - loss: 0.3431 - mae: 0.4532 - mse: 0.4240 - pearson_correlation: -9.4727e-17 - r2_keras: -92.6040 - rmse: 0.8419 - sae: 2597.7251 - sse: 2903.4775\n","Epoch 3: val_loss improved from 0.40472 to 0.40343, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.1656 - loss: 0.3347 - mae: 0.4397 - mse: 0.4008 - pearson_correlation: -5.4419e-17 - r2_keras: -74.6063 - rmse: 0.8179 - sae: 1887.6764 - sse: 2090.5310 - val_huber_loss: 0.2400 - val_loss: 0.4034 - val_mae: 0.5223 - val_mse: 0.6428 - val_pearson_correlation: -3.9529e-17 - val_r2_keras: -23.3019 - val_rmse: 0.8028 - val_sae: 281.0744 - val_sse: 340.9096 - learning_rate: 0.0028\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1598 - loss: 0.3232 - mae: 0.3849 - mse: 0.3859 - pearson_correlation: 4.2642e-16 - r2_keras: -111.3344 - rmse: 0.9223 - sae: 2605.3745 - sse: 3484.4722\n","Epoch 4: val_loss improved from 0.40343 to 0.39245, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.1346 - loss: 0.3078 - mae: 0.3661 - mse: 0.3434 - pearson_correlation: 3.0753e-16 - r2_keras: -86.1153 - rmse: 0.8618 - sae: 1882.8871 - sse: 2466.3894 - val_huber_loss: 0.2294 - val_loss: 0.3924 - val_mae: 0.4985 - val_mse: 0.6154 - val_pearson_correlation: -3.0853e-17 - val_r2_keras: -23.6468 - val_rmse: 0.8084 - val_sae: 279.5387 - val_sse: 345.7482 - learning_rate: 0.0028\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1030 - loss: 0.2661 - mae: 0.2894 - mse: 0.2407 - pearson_correlation: -9.0256e-17 - r2_keras: -103.7637 - rmse: 0.8907 - sae: 2564.6152 - sse: 3249.6396\n","Epoch 5: val_loss did not improve from 0.39245\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0934 - loss: 0.2602 - mae: 0.2825 - mse: 0.2223 - pearson_correlation: 1.5332e-17 - r2_keras: -84.7933 - rmse: 0.8759 - sae: 1872.5818 - sse: 2353.5305 - val_huber_loss: 0.2363 - val_loss: 0.3990 - val_mae: 0.5213 - val_mse: 0.6445 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -23.4255 - val_rmse: 0.8048 - val_sae: 285.1494 - val_sse: 342.6429 - learning_rate: 0.0028\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1299 - loss: 0.2927 - mae: 0.3382 - mse: 0.2879 - pearson_correlation: 3.8708e-17 - r2_keras: -89.8352 - rmse: 0.8294 - sae: 2504.1802 - sse: 2817.5938\n","Epoch 6: val_loss improved from 0.39245 to 0.39082, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - huber_loss: 0.1154 - loss: 0.2838 - mae: 0.3342 - mse: 0.2646 - pearson_correlation: 1.0646e-16 - r2_keras: -78.0861 - rmse: 0.8569 - sae: 1850.6498 - sse: 2095.7451 - val_huber_loss: 0.2284 - val_loss: 0.3908 - val_mae: 0.5134 - val_mse: 0.6178 - val_pearson_correlation: -7.3407e-17 - val_r2_keras: -23.5823 - val_rmse: 0.8074 - val_sae: 290.2725 - val_sse: 344.8427 - learning_rate: 0.0028\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1287 - loss: 0.2911 - mae: 0.3426 - mse: 0.2982 - pearson_correlation: 3.0083e-16 - r2_keras: -90.1368 - rmse: 0.8308 - sae: 2531.8997 - sse: 2826.9504\n","Epoch 7: val_loss improved from 0.39082 to 0.38370, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1056 - loss: 0.2771 - mae: 0.3206 - mse: 0.2618 - pearson_correlation: 2.9024e-16 - r2_keras: -75.8333 - rmse: 0.8370 - sae: 1853.7277 - sse: 2073.1990 - val_huber_loss: 0.2216 - val_loss: 0.3837 - val_mae: 0.4926 - val_mse: 0.6045 - val_pearson_correlation: -1.3262e-16 - val_r2_keras: -24.0516 - val_rmse: 0.8151 - val_sae: 288.2570 - val_sse: 351.4268 - learning_rate: 0.0028\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1100 - loss: 0.2721 - mae: 0.3289 - mse: 0.2295 - pearson_correlation: -2.1994e-16 - r2_keras: -105.8373 - rmse: 0.8995 - sae: 2721.1038 - sse: 3313.9592\n","Epoch 8: val_loss improved from 0.38370 to 0.34472, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.1021 - loss: 0.2673 - mae: 0.3288 - mse: 0.2180 - pearson_correlation: -1.3165e-16 - r2_keras: -84.3214 - rmse: 0.8648 - sae: 1975.4962 - sse: 2374.6587 - val_huber_loss: 0.1830 - val_loss: 0.3447 - val_mae: 0.4391 - val_mse: 0.4681 - val_pearson_correlation: -2.5951e-17 - val_r2_keras: -24.7900 - val_rmse: 0.8270 - val_sae: 297.0426 - val_sse: 361.7851 - learning_rate: 0.0028\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1072 - loss: 0.2689 - mae: 0.3285 - mse: 0.2314 - pearson_correlation: -3.7605e-16 - r2_keras: -112.2943 - rmse: 0.9263 - sae: 2700.7156 - sse: 3514.2476\n","Epoch 9: val_loss improved from 0.34472 to 0.31161, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0890 - loss: 0.2578 - mae: 0.3144 - mse: 0.2058 - pearson_correlation: -2.6752e-16 - r2_keras: -90.5609 - rmse: 0.9003 - sae: 1970.4882 - sse: 2530.8801 - val_huber_loss: 0.1503 - val_loss: 0.3116 - val_mae: 0.4239 - val_mse: 0.3714 - val_pearson_correlation: -7.3193e-17 - val_r2_keras: -24.6478 - val_rmse: 0.8247 - val_sae: 306.8526 - val_sse: 359.7903 - learning_rate: 0.0028\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0915 - loss: 0.2529 - mae: 0.3000 - mse: 0.1953 - pearson_correlation: 1.5374e-16 - r2_keras: -98.5385 - rmse: 0.8682 - sae: 2605.5425 - sse: 3087.5586\n","Epoch 10: val_loss did not improve from 0.31161\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0757 - loss: 0.2432 - mae: 0.2848 - mse: 0.1736 - pearson_correlation: 1.3480e-16 - r2_keras: -84.3228 - rmse: 0.8863 - sae: 1916.6079 - sse: 2280.8184 - val_huber_loss: 0.2128 - val_loss: 0.3738 - val_mae: 0.4880 - val_mse: 0.5362 - val_pearson_correlation: 1.2816e-16 - val_r2_keras: -24.0891 - val_rmse: 0.8157 - val_sae: 293.6563 - val_sse: 351.9526 - learning_rate: 0.0028\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0988 - loss: 0.2597 - mae: 0.3127 - mse: 0.2120 - pearson_correlation: 5.5022e-16 - r2_keras: -83.9780 - rmse: 0.8022 - sae: 2420.5742 - sse: 2635.9124\n","Epoch 11: val_loss did not improve from 0.31161\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0908 - loss: 0.2548 - mae: 0.3120 - mse: 0.1993 - pearson_correlation: 2.4924e-16 - r2_keras: -76.3379 - rmse: 0.8560 - sae: 1808.1012 - sse: 1999.9209 - val_huber_loss: 0.2615 - val_loss: 0.4221 - val_mae: 0.5433 - val_mse: 0.7113 - val_pearson_correlation: 1.6040e-16 - val_r2_keras: -27.4068 - val_rmse: 0.8679 - val_sae: 323.5051 - val_sse: 398.4937 - learning_rate: 0.0028\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1798 - loss: 0.3404 - mae: 0.4581 - mse: 0.3991 - pearson_correlation: -3.8403e-16 - r2_keras: -96.4256 - rmse: 0.8590 - sae: 2746.9565 - sse: 3022.0195\n","Epoch 12: val_loss improved from 0.31161 to 0.30087, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.1475 - loss: 0.3208 - mae: 0.4214 - mse: 0.3525 - pearson_correlation: -2.1819e-16 - r2_keras: -80.7033 - rmse: 0.8617 - sae: 1997.8104 - sse: 2211.1914 - val_huber_loss: 0.1405 - val_loss: 0.3009 - val_mae: 0.3601 - val_mse: 0.3160 - val_pearson_correlation: 6.0102e-17 - val_r2_keras: -36.6752 - val_rmse: 0.9995 - val_sae: 393.0549 - val_sse: 528.5120 - learning_rate: 0.0028\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1412 - loss: 0.3015 - mae: 0.3591 - mse: 0.3131 - pearson_correlation: 4.1918e-16 - r2_keras: -103.2684 - rmse: 0.8886 - sae: 2632.1113 - sse: 3234.2769\n","Epoch 13: val_loss did not improve from 0.30087\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1283 - loss: 0.2936 - mae: 0.3584 - mse: 0.2911 - pearson_correlation: 1.9592e-16 - r2_keras: -84.3766 - rmse: 0.8737 - sae: 1921.7996 - sse: 2342.2737 - val_huber_loss: 0.1760 - val_loss: 0.3359 - val_mae: 0.4480 - val_mse: 0.3750 - val_pearson_correlation: -3.9750e-16 - val_r2_keras: -43.1843 - val_rmse: 1.0824 - val_sae: 420.7690 - val_sse: 619.8222 - learning_rate: 0.0028\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1483 - loss: 0.3083 - mae: 0.4205 - mse: 0.3044 - pearson_correlation: 7.0135e-17 - r2_keras: -120.8727 - rmse: 0.9607 - sae: 2875.9460 - sse: 3780.3376\n","Epoch 14: val_loss improved from 0.30087 to 0.29923, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - huber_loss: 0.1257 - loss: 0.2945 - mae: 0.3971 - mse: 0.2753 - pearson_correlation: -3.0016e-18 - r2_keras: -95.4723 - rmse: 0.9160 - sae: 2081.9751 - sse: 2698.8010 - val_huber_loss: 0.1396 - val_loss: 0.2992 - val_mae: 0.3470 - val_mse: 0.3185 - val_pearson_correlation: -2.8226e-16 - val_r2_keras: -36.1970 - val_rmse: 0.9932 - val_sae: 378.6910 - val_sse: 521.8040 - learning_rate: 0.0028\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0995 - loss: 0.2591 - mae: 0.3120 - mse: 0.2119 - pearson_correlation: 1.3047e-15 - r2_keras: -113.8000 - rmse: 0.9324 - sae: 2787.4053 - sse: 3560.9536\n","Epoch 15: val_loss improved from 0.29923 to 0.29478, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - huber_loss: 0.0865 - loss: 0.2511 - mae: 0.3049 - mse: 0.1934 - pearson_correlation: 8.2803e-16 - r2_keras: -93.0560 - rmse: 0.9172 - sae: 2032.9677 - sse: 2579.5100 - val_huber_loss: 0.1356 - val_loss: 0.2948 - val_mae: 0.3676 - val_mse: 0.3360 - val_pearson_correlation: 2.7300e-16 - val_r2_keras: -29.8277 - val_rmse: 0.9042 - val_sae: 352.1742 - val_sse: 432.4542 - learning_rate: 0.0028\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0964 - loss: 0.2556 - mae: 0.3022 - mse: 0.2026 - pearson_correlation: 5.0053e-17 - r2_keras: -96.6550 - rmse: 0.8600 - sae: 2561.6609 - sse: 3029.1350\n","Epoch 16: val_loss improved from 0.29478 to 0.25888, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0823 - loss: 0.2470 - mae: 0.2918 - mse: 0.1835 - pearson_correlation: 6.8084e-17 - r2_keras: -83.4576 - rmse: 0.8840 - sae: 1888.4143 - sse: 2246.4497 - val_huber_loss: 0.1002 - val_loss: 0.2589 - val_mae: 0.3464 - val_mse: 0.2099 - val_pearson_correlation: -4.3031e-17 - val_r2_keras: -29.0028 - val_rmse: 0.8920 - val_sae: 338.6238 - val_sse: 420.8831 - learning_rate: 0.0028\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0844 - loss: 0.2431 - mae: 0.2947 - mse: 0.1808 - pearson_correlation: 4.8867e-16 - r2_keras: -95.1660 - rmse: 0.8534 - sae: 2537.5703 - sse: 2982.9497\n","Epoch 17: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0741 - loss: 0.2368 - mae: 0.2803 - mse: 0.1659 - pearson_correlation: 3.6745e-16 - r2_keras: -81.1873 - rmse: 0.8692 - sae: 1866.7323 - sse: 2200.6726 - val_huber_loss: 0.1796 - val_loss: 0.3378 - val_mae: 0.4411 - val_mse: 0.4393 - val_pearson_correlation: 1.8082e-16 - val_r2_keras: -27.9050 - val_rmse: 0.8755 - val_sae: 330.5612 - val_sse: 405.4823 - learning_rate: 0.0028\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1184 - loss: 0.2766 - mae: 0.3405 - mse: 0.2423 - pearson_correlation: -2.1788e-16 - r2_keras: -107.3712 - rmse: 0.9059 - sae: 2713.2178 - sse: 3361.5378\n","Epoch 18: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0985 - loss: 0.2644 - mae: 0.3289 - mse: 0.2169 - pearson_correlation: -1.7054e-16 - r2_keras: -86.2925 - rmse: 0.8779 - sae: 1975.0276 - sse: 2417.5049 - val_huber_loss: 0.1593 - val_loss: 0.3169 - val_mae: 0.4392 - val_mse: 0.3423 - val_pearson_correlation: -1.7882e-17 - val_r2_keras: -40.3325 - val_rmse: 1.0469 - val_sae: 413.7528 - val_sse: 579.8164 - learning_rate: 0.0028\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1305 - loss: 0.2881 - mae: 0.3928 - mse: 0.2646 - pearson_correlation: -9.6569e-16 - r2_keras: -129.6860 - rmse: 0.9948 - sae: 3059.5977 - sse: 4053.7173\n","Epoch 19: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1058 - loss: 0.2731 - mae: 0.3677 - mse: 0.2339 - pearson_correlation: -6.5478e-16 - r2_keras: -100.5287 - rmse: 0.9312 - sae: 2201.9006 - sse: 2871.4451 - val_huber_loss: 0.1174 - val_loss: 0.2745 - val_mae: 0.3341 - val_mse: 0.2533 - val_pearson_correlation: -2.9477e-16 - val_r2_keras: -38.0353 - val_rmse: 1.0174 - val_sae: 392.2297 - val_sse: 547.5912 - learning_rate: 0.0028\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0907 - loss: 0.2478 - mae: 0.2786 - mse: 0.1868 - pearson_correlation: -1.3634e-16 - r2_keras: -123.1392 - rmse: 0.9696 - sae: 2852.3918 - sse: 3850.6421\n","Epoch 20: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0732 - loss: 0.2371 - mae: 0.2677 - mse: 0.1643 - pearson_correlation: -6.4274e-17 - r2_keras: -100.6039 - rmse: 0.9530 - sae: 2079.4919 - sse: 2788.1404 - val_huber_loss: 0.1256 - val_loss: 0.2821 - val_mae: 0.3645 - val_mse: 0.2770 - val_pearson_correlation: 9.8647e-17 - val_r2_keras: -28.3699 - val_rmse: 0.8825 - val_sae: 334.3388 - val_sse: 412.0046 - learning_rate: 0.0028\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1098 - loss: 0.2663 - mae: 0.3569 - mse: 0.2465 - pearson_correlation: 9.7710e-17 - r2_keras: -90.1950 - rmse: 0.8310 - sae: 2484.4780 - sse: 2828.7544\n","Epoch 21: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0953 - loss: 0.2574 - mae: 0.3431 - mse: 0.2235 - pearson_correlation: 1.5572e-17 - r2_keras: -82.4917 - rmse: 0.8905 - sae: 1855.8049 - sse: 2152.0498 - val_huber_loss: 0.1316 - val_loss: 0.2876 - val_mae: 0.3573 - val_mse: 0.3332 - val_pearson_correlation: 4.7499e-17 - val_r2_keras: -26.1302 - val_rmse: 0.8482 - val_sae: 320.2331 - val_sse: 380.5853 - learning_rate: 0.0028\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1090 - loss: 0.2650 - mae: 0.3298 - mse: 0.2287 - pearson_correlation: -3.9155e-16 - r2_keras: -94.6008 - rmse: 0.8509 - sae: 2537.0234 - sse: 2965.4163\n","Epoch 22: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0880 - loss: 0.2521 - mae: 0.3106 - mse: 0.2009 - pearson_correlation: -2.2795e-16 - r2_keras: -78.2091 - rmse: 0.8451 - sae: 1856.0695 - sse: 2158.4697 - val_huber_loss: 0.1077 - val_loss: 0.2635 - val_mae: 0.2986 - val_mse: 0.2662 - val_pearson_correlation: 1.4882e-17 - val_r2_keras: -28.8359 - val_rmse: 0.8895 - val_sae: 328.3231 - val_sse: 418.5410 - learning_rate: 5.5959e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0803 - loss: 0.2361 - mae: 0.2647 - mse: 0.1677 - pearson_correlation: 4.0065e-16 - r2_keras: -100.5338 - rmse: 0.8769 - sae: 2589.8042 - sse: 3149.4524\n","Epoch 23: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0618 - loss: 0.2248 - mae: 0.2422 - mse: 0.1438 - pearson_correlation: 2.6530e-16 - r2_keras: -83.1953 - rmse: 0.8715 - sae: 1893.4987 - sse: 2293.2512 - val_huber_loss: 0.1049 - val_loss: 0.2605 - val_mae: 0.2859 - val_mse: 0.2531 - val_pearson_correlation: 2.7176e-16 - val_r2_keras: -30.2042 - val_rmse: 0.9097 - val_sae: 334.9431 - val_sse: 437.7361 - learning_rate: 5.5959e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0703 - loss: 0.2259 - mae: 0.2378 - mse: 0.1455 - pearson_correlation: -6.2547e-16 - r2_keras: -104.3778 - rmse: 0.8933 - sae: 2625.2405 - sse: 3268.6875\n","Epoch 24: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0535 - loss: 0.2157 - mae: 0.2158 - mse: 0.1240 - pearson_correlation: -4.3012e-16 - r2_keras: -86.1617 - rmse: 0.8859 - sae: 1918.1707 - sse: 2377.4775 - val_huber_loss: 0.1037 - val_loss: 0.2592 - val_mae: 0.2842 - val_mse: 0.2470 - val_pearson_correlation: -3.3094e-16 - val_r2_keras: -30.6345 - val_rmse: 0.9159 - val_sae: 336.8728 - val_sse: 443.7721 - learning_rate: 5.5959e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0652 - loss: 0.2207 - mae: 0.2236 - mse: 0.1344 - pearson_correlation: 5.7225e-16 - r2_keras: -105.4318 - rmse: 0.8978 - sae: 2631.2383 - sse: 3301.3799\n","Epoch 25: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0497 - loss: 0.2112 - mae: 0.2029 - mse: 0.1147 - pearson_correlation: 4.0588e-16 - r2_keras: -86.9581 - rmse: 0.8897 - sae: 1922.6996 - sse: 2400.3726 - val_huber_loss: 0.1056 - val_loss: 0.2609 - val_mae: 0.2898 - val_mse: 0.2491 - val_pearson_correlation: -1.8398e-16 - val_r2_keras: -30.8009 - val_rmse: 0.9183 - val_sae: 337.1948 - val_sse: 446.1062 - learning_rate: 5.5959e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0626 - loss: 0.2179 - mae: 0.2133 - mse: 0.1289 - pearson_correlation: -3.9683e-16 - r2_keras: -106.4894 - rmse: 0.9022 - sae: 2641.4197 - sse: 3334.1873\n","Epoch 26: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0477 - loss: 0.2088 - mae: 0.1937 - mse: 0.1100 - pearson_correlation: -2.2062e-16 - r2_keras: -87.8305 - rmse: 0.8941 - sae: 1929.9055 - sse: 2424.2068 - val_huber_loss: 0.1066 - val_loss: 0.2616 - val_mae: 0.2964 - val_mse: 0.2486 - val_pearson_correlation: 9.1971e-17 - val_r2_keras: -30.8052 - val_rmse: 0.9184 - val_sae: 336.4142 - val_sse: 446.1663 - learning_rate: 5.5959e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0605 - loss: 0.2156 - mae: 0.2066 - mse: 0.1246 - pearson_correlation: -2.8680e-16 - r2_keras: -107.2402 - rmse: 0.9054 - sae: 2642.0630 - sse: 3357.4749\n","Epoch 27: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0458 - loss: 0.2066 - mae: 0.1861 - mse: 0.1060 - pearson_correlation: -1.1956e-16 - r2_keras: -88.4847 - rmse: 0.8975 - sae: 1930.9658 - sse: 2441.5347 - val_huber_loss: 0.1064 - val_loss: 0.2615 - val_mae: 0.2960 - val_mse: 0.2483 - val_pearson_correlation: 5.2639e-17 - val_r2_keras: -30.7872 - val_rmse: 0.9181 - val_sae: 336.1781 - val_sse: 445.9142 - learning_rate: 1.1192e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0601 - loss: 0.2151 - mae: 0.2046 - mse: 0.1238 - pearson_correlation: 4.8142e-17 - r2_keras: -107.3539 - rmse: 0.9058 - sae: 2642.8743 - sse: 3361.0017\n","Epoch 28: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0456 - loss: 0.2063 - mae: 0.1844 - mse: 0.1054 - pearson_correlation: 2.2352e-18 - r2_keras: -88.5562 - rmse: 0.8978 - sae: 1931.4705 - sse: 2443.8357 - val_huber_loss: 0.1066 - val_loss: 0.2616 - val_mae: 0.2965 - val_mse: 0.2486 - val_pearson_correlation: 3.1605e-16 - val_r2_keras: -30.7788 - val_rmse: 0.9180 - val_sae: 336.1174 - val_sse: 445.7966 - learning_rate: 1.1192e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0597 - loss: 0.2147 - mae: 0.2029 - mse: 0.1231 - pearson_correlation: 3.4626e-17 - r2_keras: -107.5277 - rmse: 0.9066 - sae: 2644.1875 - sse: 3366.3945\n","Epoch 29: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0453 - loss: 0.2059 - mae: 0.1829 - mse: 0.1048 - pearson_correlation: -1.1014e-17 - r2_keras: -88.6849 - rmse: 0.8984 - sae: 1932.4125 - sse: 2447.5808 - val_huber_loss: 0.1069 - val_loss: 0.2618 - val_mae: 0.2970 - val_mse: 0.2489 - val_pearson_correlation: -3.0266e-16 - val_r2_keras: -30.7912 - val_rmse: 0.9182 - val_sae: 336.2096 - val_sse: 445.9710 - learning_rate: 1.1192e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0594 - loss: 0.2143 - mae: 0.2013 - mse: 0.1225 - pearson_correlation: -8.0617e-17 - r2_keras: -107.7229 - rmse: 0.9074 - sae: 2645.7493 - sse: 3372.4487\n","Epoch 30: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0451 - loss: 0.2056 - mae: 0.1816 - mse: 0.1043 - pearson_correlation: 2.2967e-17 - r2_keras: -88.8170 - rmse: 0.8990 - sae: 1933.4767 - sse: 2451.6394 - val_huber_loss: 0.1071 - val_loss: 0.2619 - val_mae: 0.2974 - val_mse: 0.2491 - val_pearson_correlation: -2.2342e-16 - val_r2_keras: -30.8147 - val_rmse: 0.9185 - val_sae: 336.3248 - val_sse: 446.3001 - learning_rate: 1.1192e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0591 - loss: 0.2140 - mae: 0.1997 - mse: 0.1219 - pearson_correlation: 3.0275e-16 - r2_keras: -107.9281 - rmse: 0.9082 - sae: 2647.4692 - sse: 3378.8140\n","Epoch 31: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0448 - loss: 0.2053 - mae: 0.1803 - mse: 0.1037 - pearson_correlation: 1.9503e-16 - r2_keras: -88.9757 - rmse: 0.8997 - sae: 1934.7360 - sse: 2456.1409 - val_huber_loss: 0.1073 - val_loss: 0.2621 - val_mae: 0.2977 - val_mse: 0.2494 - val_pearson_correlation: 5.2513e-17 - val_r2_keras: -30.8328 - val_rmse: 0.9188 - val_sae: 336.4225 - val_sse: 446.5536 - learning_rate: 1.1192e-04\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0588 - loss: 0.2136 - mae: 0.1984 - mse: 0.1213 - pearson_correlation: -4.6339e-16 - r2_keras: -108.1261 - rmse: 0.9091 - sae: 2648.4382 - sse: 3384.9565\n","Epoch 32: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0445 - loss: 0.2049 - mae: 0.1788 - mse: 0.1032 - pearson_correlation: -3.0723e-16 - r2_keras: -89.1321 - rmse: 0.9005 - sae: 1935.4855 - sse: 2460.5215 - val_huber_loss: 0.1073 - val_loss: 0.2621 - val_mae: 0.2974 - val_mse: 0.2492 - val_pearson_correlation: 5.2407e-17 - val_r2_keras: -30.8723 - val_rmse: 0.9193 - val_sae: 336.5952 - val_sse: 447.1078 - learning_rate: 2.2384e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0587 - loss: 0.2135 - mae: 0.1981 - mse: 0.1211 - pearson_correlation: -3.1259e-16 - r2_keras: -108.1712 - rmse: 0.9093 - sae: 2648.8057 - sse: 3386.3555\n","Epoch 33: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0445 - loss: 0.2048 - mae: 0.1785 - mse: 0.1031 - pearson_correlation: -1.7100e-16 - r2_keras: -89.1629 - rmse: 0.9006 - sae: 1935.7389 - sse: 2461.4624 - val_huber_loss: 0.1073 - val_loss: 0.2621 - val_mae: 0.2973 - val_mse: 0.2491 - val_pearson_correlation: 3.6637e-16 - val_r2_keras: -30.8975 - val_rmse: 0.9197 - val_sae: 336.7058 - val_sse: 447.4622 - learning_rate: 2.2384e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0586 - loss: 0.2134 - mae: 0.1977 - mse: 0.1210 - pearson_correlation: -3.4390e-16 - r2_keras: -108.2081 - rmse: 0.9094 - sae: 2649.0588 - sse: 3387.4973\n","Epoch 34: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0444 - loss: 0.2047 - mae: 0.1782 - mse: 0.1029 - pearson_correlation: -2.2247e-16 - r2_keras: -89.1888 - rmse: 0.9007 - sae: 1935.9176 - sse: 2462.2400 - val_huber_loss: 0.1074 - val_loss: 0.2621 - val_mae: 0.2975 - val_mse: 0.2492 - val_pearson_correlation: -3.9220e-17 - val_r2_keras: -30.9138 - val_rmse: 0.9199 - val_sae: 336.7845 - val_sse: 447.6909 - learning_rate: 2.2384e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0585 - loss: 0.2133 - mae: 0.1973 - mse: 0.1208 - pearson_correlation: -2.1969e-16 - r2_keras: -108.2384 - rmse: 0.9095 - sae: 2649.1777 - sse: 3388.4395\n","Epoch 35: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0443 - loss: 0.2046 - mae: 0.1778 - mse: 0.1027 - pearson_correlation: -1.8385e-16 - r2_keras: -89.2089 - rmse: 0.9008 - sae: 1936.0017 - sse: 2462.8662 - val_huber_loss: 0.1074 - val_loss: 0.2621 - val_mae: 0.2974 - val_mse: 0.2490 - val_pearson_correlation: 3.9170e-17 - val_r2_keras: -30.9355 - val_rmse: 0.9203 - val_sae: 336.9171 - val_sse: 447.9948 - learning_rate: 2.2384e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0584 - loss: 0.2132 - mae: 0.1969 - mse: 0.1206 - pearson_correlation: 3.7976e-16 - r2_keras: -108.2948 - rmse: 0.9098 - sae: 2649.6191 - sse: 3390.1880\n","Epoch 36: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0443 - loss: 0.2045 - mae: 0.1776 - mse: 0.1026 - pearson_correlation: 2.7356e-16 - r2_keras: -89.2507 - rmse: 0.9010 - sae: 1936.3231 - sse: 2464.0818 - val_huber_loss: 0.1075 - val_loss: 0.2622 - val_mae: 0.2976 - val_mse: 0.2491 - val_pearson_correlation: -7.8305e-17 - val_r2_keras: -30.9440 - val_rmse: 0.9204 - val_sae: 336.9358 - val_sse: 448.1143 - learning_rate: 2.2384e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0583 - loss: 0.2130 - mae: 0.1965 - mse: 0.1204 - pearson_correlation: -4.6549e-16 - r2_keras: -108.3393 - rmse: 0.9100 - sae: 2649.6187 - sse: 3391.5679\n","Epoch 37: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0442 - loss: 0.2044 - mae: 0.1771 - mse: 0.1024 - pearson_correlation: -3.0353e-16 - r2_keras: -89.2858 - rmse: 0.9012 - sae: 1936.3461 - sse: 2465.0645 - val_huber_loss: 0.1075 - val_loss: 0.2622 - val_mae: 0.2977 - val_mse: 0.2491 - val_pearson_correlation: -3.1307e-16 - val_r2_keras: -30.9535 - val_rmse: 0.9205 - val_sae: 336.9726 - val_sse: 448.2466 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0582 - loss: 0.2129 - mae: 0.1962 - mse: 0.1202 - pearson_correlation: 8.7431e-16 - r2_keras: -108.3676 - rmse: 0.9101 - sae: 2649.7222 - sse: 3392.4473\n","Epoch 38: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0441 - loss: 0.2043 - mae: 0.1769 - mse: 0.1023 - pearson_correlation: 5.9646e-16 - r2_keras: -89.3070 - rmse: 0.9013 - sae: 1936.4269 - sse: 2465.6787 - val_huber_loss: 0.1075 - val_loss: 0.2622 - val_mae: 0.2978 - val_mse: 0.2491 - val_pearson_correlation: 3.2596e-16 - val_r2_keras: -30.9619 - val_rmse: 0.9206 - val_sae: 337.0069 - val_sse: 448.3654 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0582 - loss: 0.2129 - mae: 0.1959 - mse: 0.1201 - pearson_correlation: -4.0909e-16 - r2_keras: -108.3993 - rmse: 0.9102 - sae: 2649.8162 - sse: 3393.4309\n","Epoch 39: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0441 - loss: 0.2043 - mae: 0.1767 - mse: 0.1022 - pearson_correlation: -2.5235e-16 - r2_keras: -89.3298 - rmse: 0.9014 - sae: 1936.4995 - sse: 2466.3530 - val_huber_loss: 0.1076 - val_loss: 0.2623 - val_mae: 0.2979 - val_mse: 0.2491 - val_pearson_correlation: 1.3036e-17 - val_r2_keras: -30.9654 - val_rmse: 0.9207 - val_sae: 337.0107 - val_sse: 448.4145 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0581 - loss: 0.2128 - mae: 0.1957 - mse: 0.1200 - pearson_correlation: -4.9429e-17 - r2_keras: -108.4236 - rmse: 0.9103 - sae: 2649.7930 - sse: 3394.1838\n","Epoch 40: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0440 - loss: 0.2042 - mae: 0.1765 - mse: 0.1021 - pearson_correlation: -4.3141e-17 - r2_keras: -89.3458 - rmse: 0.9014 - sae: 1936.4852 - sse: 2466.8535 - val_huber_loss: 0.1076 - val_loss: 0.2623 - val_mae: 0.2980 - val_mse: 0.2490 - val_pearson_correlation: 1.9545e-16 - val_r2_keras: -30.9723 - val_rmse: 0.9208 - val_sae: 337.0486 - val_sse: 448.5108 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0580 - loss: 0.2127 - mae: 0.1954 - mse: 0.1198 - pearson_correlation: -1.3255e-16 - r2_keras: -108.4645 - rmse: 0.9105 - sae: 2650.0029 - sse: 3395.4519\n","Epoch 41: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0440 - loss: 0.2041 - mae: 0.1763 - mse: 0.1020 - pearson_correlation: -4.2524e-17 - r2_keras: -89.3757 - rmse: 0.9016 - sae: 1936.6395 - sse: 2467.7300 - val_huber_loss: 0.1077 - val_loss: 0.2623 - val_mae: 0.2982 - val_mse: 0.2491 - val_pearson_correlation: 3.7783e-16 - val_r2_keras: -30.9736 - val_rmse: 0.9208 - val_sae: 337.0410 - val_sse: 448.5298 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0579 - loss: 0.2126 - mae: 0.1952 - mse: 0.1197 - pearson_correlation: -1.8032e-16 - r2_keras: -108.4855 - rmse: 0.9106 - sae: 2649.9482 - sse: 3396.1021\n","Epoch 42: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0439 - loss: 0.2041 - mae: 0.1761 - mse: 0.1018 - pearson_correlation: -1.2361e-16 - r2_keras: -89.3912 - rmse: 0.9016 - sae: 1936.6139 - sse: 2468.1812 - val_huber_loss: 0.1077 - val_loss: 0.2624 - val_mae: 0.2984 - val_mse: 0.2492 - val_pearson_correlation: -3.5165e-16 - val_r2_keras: -30.9794 - val_rmse: 0.9209 - val_sae: 337.0725 - val_sse: 448.6109 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0579 - loss: 0.2125 - mae: 0.1949 - mse: 0.1196 - pearson_correlation: -5.9667e-16 - r2_keras: -108.5341 - rmse: 0.9108 - sae: 2650.2383 - sse: 3397.6101\n","Epoch 43: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0439 - loss: 0.2040 - mae: 0.1758 - mse: 0.1017 - pearson_correlation: -4.5039e-16 - r2_keras: -89.4278 - rmse: 0.9018 - sae: 1936.8278 - sse: 2469.2351 - val_huber_loss: 0.1078 - val_loss: 0.2624 - val_mae: 0.2985 - val_mse: 0.2492 - val_pearson_correlation: 2.4738e-16 - val_r2_keras: -30.9837 - val_rmse: 0.9210 - val_sae: 337.0872 - val_sse: 448.6708 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0578 - loss: 0.2125 - mae: 0.1946 - mse: 0.1194 - pearson_correlation: 3.6136e-16 - r2_keras: -108.5700 - rmse: 0.9109 - sae: 2650.3218 - sse: 3398.7241\n","Epoch 44: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0438 - loss: 0.2039 - mae: 0.1756 - mse: 0.1016 - pearson_correlation: 2.0018e-16 - r2_keras: -89.4529 - rmse: 0.9019 - sae: 1936.8925 - sse: 2469.9924 - val_huber_loss: 0.1078 - val_loss: 0.2625 - val_mae: 0.2986 - val_mse: 0.2492 - val_pearson_correlation: 9.1095e-17 - val_r2_keras: -30.9916 - val_rmse: 0.9211 - val_sae: 337.1270 - val_sse: 448.7810 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0577 - loss: 0.2124 - mae: 0.1943 - mse: 0.1193 - pearson_correlation: -8.7771e-17 - r2_keras: -108.6208 - rmse: 0.9111 - sae: 2650.6206 - sse: 3400.2986\n","Epoch 45: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0438 - loss: 0.2039 - mae: 0.1753 - mse: 0.1015 - pearson_correlation: -8.0573e-17 - r2_keras: -89.4890 - rmse: 0.9021 - sae: 1937.1052 - sse: 2471.0681 - val_huber_loss: 0.1079 - val_loss: 0.2625 - val_mae: 0.2989 - val_mse: 0.2493 - val_pearson_correlation: -2.7328e-16 - val_r2_keras: -30.9913 - val_rmse: 0.9211 - val_sae: 337.1184 - val_sse: 448.7773 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0577 - loss: 0.2123 - mae: 0.1940 - mse: 0.1192 - pearson_correlation: 9.7282e-17 - r2_keras: -108.6536 - rmse: 0.9113 - sae: 2650.7349 - sse: 3401.3169\n","Epoch 46: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0437 - loss: 0.2038 - mae: 0.1751 - mse: 0.1014 - pearson_correlation: 7.8428e-17 - r2_keras: -89.5129 - rmse: 0.9022 - sae: 1937.1962 - sse: 2471.7708 - val_huber_loss: 0.1079 - val_loss: 0.2625 - val_mae: 0.2990 - val_mse: 0.2492 - val_pearson_correlation: 2.4711e-16 - val_r2_keras: -31.0002 - val_rmse: 0.9212 - val_sae: 337.1672 - val_sse: 448.9019 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0576 - loss: 0.2122 - mae: 0.1937 - mse: 0.1191 - pearson_correlation: 3.1976e-16 - r2_keras: -108.7069 - rmse: 0.9115 - sae: 2651.0400 - sse: 3402.9714\n","Epoch 47: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0437 - loss: 0.2037 - mae: 0.1748 - mse: 0.1013 - pearson_correlation: 2.1656e-16 - r2_keras: -89.5519 - rmse: 0.9024 - sae: 1937.4175 - sse: 2472.9146 - val_huber_loss: 0.1079 - val_loss: 0.2625 - val_mae: 0.2991 - val_mse: 0.2492 - val_pearson_correlation: -2.4696e-16 - val_r2_keras: -31.0093 - val_rmse: 0.9213 - val_sae: 337.2193 - val_sse: 449.0299 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0575 - loss: 0.2121 - mae: 0.1934 - mse: 0.1189 - pearson_correlation: 6.8946e-16 - r2_keras: -108.7576 - rmse: 0.9117 - sae: 2651.3496 - sse: 3404.5420\n","Epoch 48: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0436 - loss: 0.2037 - mae: 0.1746 - mse: 0.1012 - pearson_correlation: 4.9187e-16 - r2_keras: -89.5887 - rmse: 0.9025 - sae: 1937.6403 - sse: 2473.9961 - val_huber_loss: 0.1080 - val_loss: 0.2625 - val_mae: 0.2993 - val_mse: 0.2492 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -31.0102 - val_rmse: 0.9213 - val_sae: 337.2090 - val_sse: 449.0421 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0575 - loss: 0.2120 - mae: 0.1932 - mse: 0.1188 - pearson_correlation: -1.9163e-16 - r2_keras: -108.7869 - rmse: 0.9118 - sae: 2651.3792 - sse: 3405.4526\n","Epoch 49: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0435 - loss: 0.2036 - mae: 0.1744 - mse: 0.1011 - pearson_correlation: -1.5320e-16 - r2_keras: -89.6067 - rmse: 0.9026 - sae: 1937.6560 - sse: 2474.5850 - val_huber_loss: 0.1080 - val_loss: 0.2626 - val_mae: 0.2994 - val_mse: 0.2493 - val_pearson_correlation: 2.5990e-17 - val_r2_keras: -31.0126 - val_rmse: 0.9214 - val_sae: 337.2117 - val_sse: 449.0760 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0574 - loss: 0.2120 - mae: 0.1929 - mse: 0.1187 - pearson_correlation: 3.3041e-16 - r2_keras: -108.8384 - rmse: 0.9120 - sae: 2651.6882 - sse: 3407.0498\n","Epoch 50: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0435 - loss: 0.2035 - mae: 0.1741 - mse: 0.1010 - pearson_correlation: 1.9992e-16 - r2_keras: -89.6434 - rmse: 0.9028 - sae: 1937.8762 - sse: 2475.6782 - val_huber_loss: 0.1081 - val_loss: 0.2627 - val_mae: 0.2998 - val_mse: 0.2494 - val_pearson_correlation: 1.4294e-16 - val_r2_keras: -31.0132 - val_rmse: 0.9214 - val_sae: 337.2028 - val_sse: 449.0844 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0573 - loss: 0.2119 - mae: 0.1926 - mse: 0.1185 - pearson_correlation: -1.7188e-17 - r2_keras: -108.8733 - rmse: 0.9122 - sae: 2651.8291 - sse: 3408.1323\n","Epoch 51: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0434 - loss: 0.2034 - mae: 0.1739 - mse: 0.1009 - pearson_correlation: 2.7540e-17 - r2_keras: -89.6693 - rmse: 0.9029 - sae: 1937.9879 - sse: 2476.4307 - val_huber_loss: 0.1082 - val_loss: 0.2627 - val_mae: 0.2999 - val_mse: 0.2494 - val_pearson_correlation: -1.2988e-16 - val_r2_keras: -31.0209 - val_rmse: 0.9215 - val_sae: 337.2506 - val_sse: 449.1927 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0573 - loss: 0.2118 - mae: 0.1924 - mse: 0.1184 - pearson_correlation: -3.2427e-16 - r2_keras: -108.9271 - rmse: 0.9124 - sae: 2652.1680 - sse: 3409.8013\n","Epoch 52: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0434 - loss: 0.2034 - mae: 0.1737 - mse: 0.1007 - pearson_correlation: -1.8058e-16 - r2_keras: -89.7080 - rmse: 0.9030 - sae: 1938.2307 - sse: 2477.5762 - val_huber_loss: 0.1083 - val_loss: 0.2628 - val_mae: 0.3002 - val_mse: 0.2495 - val_pearson_correlation: 7.4021e-16 - val_r2_keras: -31.0229 - val_rmse: 0.9215 - val_sae: 337.2476 - val_sse: 449.2211 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0572 - loss: 0.2117 - mae: 0.1922 - mse: 0.1183 - pearson_correlation: 2.9691e-16 - r2_keras: -108.9692 - rmse: 0.9126 - sae: 2652.3486 - sse: 3411.1064\n","Epoch 53: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0433 - loss: 0.2033 - mae: 0.1735 - mse: 0.1006 - pearson_correlation: 2.1490e-16 - r2_keras: -89.7371 - rmse: 0.9032 - sae: 1938.3582 - sse: 2478.4583 - val_huber_loss: 0.1083 - val_loss: 0.2628 - val_mae: 0.3003 - val_mse: 0.2495 - val_pearson_correlation: 1.6875e-16 - val_r2_keras: -31.0298 - val_rmse: 0.9216 - val_sae: 337.2805 - val_sse: 449.3168 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0571 - loss: 0.2116 - mae: 0.1919 - mse: 0.1182 - pearson_correlation: -4.3772e-16 - r2_keras: -109.0219 - rmse: 0.9128 - sae: 2652.7290 - sse: 3412.7427\n","Epoch 54: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0433 - loss: 0.2032 - mae: 0.1732 - mse: 0.1005 - pearson_correlation: -3.7317e-16 - r2_keras: -89.7753 - rmse: 0.9033 - sae: 1938.6342 - sse: 2479.5852 - val_huber_loss: 0.1084 - val_loss: 0.2629 - val_mae: 0.3006 - val_mse: 0.2497 - val_pearson_correlation: -1.1682e-16 - val_r2_keras: -31.0304 - val_rmse: 0.9216 - val_sae: 337.2563 - val_sse: 449.3253 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0571 - loss: 0.2116 - mae: 0.1916 - mse: 0.1180 - pearson_correlation: -7.0886e-16 - r2_keras: -109.0559 - rmse: 0.9129 - sae: 2652.8044 - sse: 3413.7969\n","Epoch 55: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0432 - loss: 0.2031 - mae: 0.1730 - mse: 0.1004 - pearson_correlation: -5.0308e-16 - r2_keras: -89.7982 - rmse: 0.9034 - sae: 1938.6874 - sse: 2480.2905 - val_huber_loss: 0.1085 - val_loss: 0.2630 - val_mae: 0.3008 - val_mse: 0.2497 - val_pearson_correlation: 1.5570e-16 - val_r2_keras: -31.0382 - val_rmse: 0.9217 - val_sae: 337.3002 - val_sse: 449.4347 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0570 - loss: 0.2115 - mae: 0.1914 - mse: 0.1179 - pearson_correlation: -3.6925e-16 - r2_keras: -109.1108 - rmse: 0.9132 - sae: 2653.2354 - sse: 3415.4990\n","Epoch 56: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0432 - loss: 0.2031 - mae: 0.1728 - mse: 0.1003 - pearson_correlation: -2.5464e-16 - r2_keras: -89.8394 - rmse: 0.9036 - sae: 1938.9962 - sse: 2481.4792 - val_huber_loss: 0.1086 - val_loss: 0.2631 - val_mae: 0.3011 - val_mse: 0.2498 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -31.0401 - val_rmse: 0.9218 - val_sae: 337.2882 - val_sse: 449.4615 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0569 - loss: 0.2114 - mae: 0.1911 - mse: 0.1178 - pearson_correlation: -6.0804e-16 - r2_keras: -109.1362 - rmse: 0.9133 - sae: 2653.2515 - sse: 3416.2883\n","Epoch 57: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0431 - loss: 0.2030 - mae: 0.1725 - mse: 0.1002 - pearson_correlation: -4.1892e-16 - r2_keras: -89.8581 - rmse: 0.9037 - sae: 1939.0146 - sse: 2482.0266 - val_huber_loss: 0.1086 - val_loss: 0.2631 - val_mae: 0.3011 - val_mse: 0.2498 - val_pearson_correlation: -4.1476e-16 - val_r2_keras: -31.0555 - val_rmse: 0.9220 - val_sae: 337.3868 - val_sse: 449.6776 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0568 - loss: 0.2113 - mae: 0.1909 - mse: 0.1176 - pearson_correlation: -1.1880e-15 - r2_keras: -109.1907 - rmse: 0.9135 - sae: 2653.6616 - sse: 3417.9790\n","Epoch 58: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0431 - loss: 0.2029 - mae: 0.1723 - mse: 0.1001 - pearson_correlation: -7.9705e-16 - r2_keras: -89.8985 - rmse: 0.9039 - sae: 1939.3081 - sse: 2483.2007 - val_huber_loss: 0.1087 - val_loss: 0.2631 - val_mae: 0.3013 - val_mse: 0.2498 - val_pearson_correlation: -1.2959e-16 - val_r2_keras: -31.0583 - val_rmse: 0.9220 - val_sae: 337.3883 - val_sse: 449.7173 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0568 - loss: 0.2112 - mae: 0.1907 - mse: 0.1175 - pearson_correlation: 3.3005e-16 - r2_keras: -109.2314 - rmse: 0.9137 - sae: 2653.9041 - sse: 3419.2397\n","Epoch 59: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0430 - loss: 0.2028 - mae: 0.1721 - mse: 0.1000 - pearson_correlation: 2.2003e-16 - r2_keras: -89.9264 - rmse: 0.9040 - sae: 1939.4697 - sse: 2484.0505 - val_huber_loss: 0.1087 - val_loss: 0.2631 - val_mae: 0.3014 - val_mse: 0.2497 - val_pearson_correlation: 2.0731e-16 - val_r2_keras: -31.0608 - val_rmse: 0.9221 - val_sae: 337.3846 - val_sse: 449.7519 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0567 - loss: 0.2111 - mae: 0.1904 - mse: 0.1174 - pearson_correlation: 3.7583e-16 - r2_keras: -109.2439 - rmse: 0.9137 - sae: 2653.8303 - sse: 3419.6279\n","Epoch 60: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0430 - loss: 0.2028 - mae: 0.1719 - mse: 0.0998 - pearson_correlation: 1.8958e-16 - r2_keras: -89.9344 - rmse: 0.9040 - sae: 1939.4138 - sse: 2484.3057 - val_huber_loss: 0.1087 - val_loss: 0.2631 - val_mae: 0.3016 - val_mse: 0.2498 - val_pearson_correlation: 2.2021e-16 - val_r2_keras: -31.0653 - val_rmse: 0.9221 - val_sae: 337.3915 - val_sse: 449.8152 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0566 - loss: 0.2111 - mae: 0.1902 - mse: 0.1173 - pearson_correlation: 1.9006e-16 - r2_keras: -109.2895 - rmse: 0.9139 - sae: 2654.0986 - sse: 3421.0430\n","Epoch 61: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0429 - loss: 0.2027 - mae: 0.1717 - mse: 0.0997 - pearson_correlation: 1.1655e-16 - r2_keras: -89.9683 - rmse: 0.9042 - sae: 1939.6075 - sse: 2485.2893 - val_huber_loss: 0.1088 - val_loss: 0.2632 - val_mae: 0.3018 - val_mse: 0.2499 - val_pearson_correlation: -1.6836e-16 - val_r2_keras: -31.0679 - val_rmse: 0.9222 - val_sae: 337.4019 - val_sse: 449.8527 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0566 - loss: 0.2110 - mae: 0.1899 - mse: 0.1171 - pearson_correlation: -9.7365e-17 - r2_keras: -109.3213 - rmse: 0.9140 - sae: 2654.2034 - sse: 3422.0283\n","Epoch 62: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0429 - loss: 0.2026 - mae: 0.1714 - mse: 0.0996 - pearson_correlation: -8.6924e-17 - r2_keras: -89.9892 - rmse: 0.9043 - sae: 1939.6813 - sse: 2485.9438 - val_huber_loss: 0.1089 - val_loss: 0.2633 - val_mae: 0.3020 - val_mse: 0.2501 - val_pearson_correlation: -1.5541e-16 - val_r2_keras: -31.0684 - val_rmse: 0.9222 - val_sae: 337.3778 - val_sse: 449.8593 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0565 - loss: 0.2109 - mae: 0.1897 - mse: 0.1170 - pearson_correlation: -4.0508e-17 - r2_keras: -109.3613 - rmse: 0.9142 - sae: 2654.5239 - sse: 3423.2688\n","Epoch 63: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0428 - loss: 0.2026 - mae: 0.1713 - mse: 0.0995 - pearson_correlation: 2.5485e-17 - r2_keras: -90.0176 - rmse: 0.9044 - sae: 1939.9001 - sse: 2486.7908 - val_huber_loss: 0.1090 - val_loss: 0.2633 - val_mae: 0.3022 - val_mse: 0.2500 - val_pearson_correlation: 1.2945e-17 - val_r2_keras: -31.0761 - val_rmse: 0.9223 - val_sae: 337.4277 - val_sse: 449.9670 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0565 - loss: 0.2108 - mae: 0.1894 - mse: 0.1169 - pearson_correlation: 2.5507e-17 - r2_keras: -109.3878 - rmse: 0.9143 - sae: 2654.6008 - sse: 3424.0911\n","Epoch 64: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0428 - loss: 0.2025 - mae: 0.1710 - mse: 0.0994 - pearson_correlation: 2.2083e-17 - r2_keras: -90.0389 - rmse: 0.9045 - sae: 1939.9696 - sse: 2487.3823 - val_huber_loss: 0.1090 - val_loss: 0.2633 - val_mae: 0.3023 - val_mse: 0.2501 - val_pearson_correlation: 7.7625e-17 - val_r2_keras: -31.0860 - val_rmse: 0.9224 - val_sae: 337.4940 - val_sse: 450.1058 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0564 - loss: 0.2107 - mae: 0.1892 - mse: 0.1168 - pearson_correlation: 8.3305e-17 - r2_keras: -109.4472 - rmse: 0.9146 - sae: 2655.2026 - sse: 3425.9324\n","Epoch 65: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0427 - loss: 0.2024 - mae: 0.1708 - mse: 0.0993 - pearson_correlation: 9.8435e-18 - r2_keras: -90.0833 - rmse: 0.9047 - sae: 1940.3845 - sse: 2488.6653 - val_huber_loss: 0.1091 - val_loss: 0.2634 - val_mae: 0.3025 - val_mse: 0.2502 - val_pearson_correlation: -3.8815e-17 - val_r2_keras: -31.0849 - val_rmse: 0.9224 - val_sae: 337.4554 - val_sse: 450.0911 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0563 - loss: 0.2107 - mae: 0.1889 - mse: 0.1166 - pearson_correlation: -1.7421e-16 - r2_keras: -109.4590 - rmse: 0.9146 - sae: 2655.1167 - sse: 3426.3000\n","Epoch 66: val_loss did not improve from 0.25888\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0427 - loss: 0.2023 - mae: 0.1705 - mse: 0.0992 - pearson_correlation: -9.7525e-17 - r2_keras: -90.0925 - rmse: 0.9048 - sae: 1940.3315 - sse: 2488.9265 - val_huber_loss: 0.1092 - val_loss: 0.2635 - val_mae: 0.3027 - val_mse: 0.2503 - val_pearson_correlation: -1.5524e-16 - val_r2_keras: -31.0867 - val_rmse: 0.9224 - val_sae: 337.4482 - val_sse: 450.1151 - learning_rate: 1.0000e-05\n","| \u001b[35m11       \u001b[39m | \u001b[35m-0.2635  \u001b[39m | \u001b[35m0.002798 \u001b[39m | \u001b[35m89.49    \u001b[39m | \u001b[35m54.14    \u001b[39m | \u001b[35m71.78    \u001b[39m | \u001b[35m8.618    \u001b[39m | \u001b[35m84.35    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 1.4135 - loss: 1.5614 - mae: 1.8797 - mse: 5.4707 - pearson_correlation: 5.9795e-17 - r2_keras: -684.2451 - rmse: 2.2780 - sae: 7087.1523 - sse: 21255.4453\n","Epoch 1: val_loss improved from inf to 0.40348, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 622ms/step - huber_loss: 1.3521 - loss: 1.5241 - mae: 1.8358 - mse: 5.1815 - pearson_correlation: -2.6601e-18 - r2_keras: -551.6478 - rmse: 2.2100 - sae: 5151.2622 - sse: 15294.2432 - val_huber_loss: 0.2556 - val_loss: 0.4035 - val_mae: 0.6215 - val_mse: 0.6093 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -22.4201 - val_rmse: 0.7881 - val_sae: 330.4576 - val_sse: 328.5403 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 1.1403 - loss: 1.2882 - mae: 1.5892 - mse: 4.0315 - pearson_correlation: -2.0064e-17 - r2_keras: -511.6166 - rmse: 1.9703 - sae: 6117.1289 - sse: 15900.7246\n","Epoch 2: val_loss did not improve from 0.40348\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 1.0813 - loss: 1.2523 - mae: 1.5476 - mse: 3.7881 - pearson_correlation: -8.7034e-17 - r2_keras: -407.7845 - rmse: 1.8917 - sae: 4431.8223 - sse: 11386.8652 - val_huber_loss: 0.2589 - val_loss: 0.4068 - val_mae: 0.6315 - val_mse: 0.6069 - val_pearson_correlation: 1.1849e-16 - val_r2_keras: -22.7877 - val_rmse: 0.7942 - val_sae: 338.1955 - val_sse: 333.6960 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.7766 - loss: 0.9245 - mae: 1.1784 - mse: 2.2103 - pearson_correlation: 3.4094e-16 - r2_keras: -289.2103 - rmse: 1.4825 - sae: 4702.9785 - sse: 9001.9600\n","Epoch 3: val_loss improved from 0.40348 to 0.39738, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.7239 - loss: 0.8924 - mae: 1.1427 - mse: 2.1498 - pearson_correlation: 1.4194e-16 - r2_keras: -239.0886 - rmse: 1.4705 - sae: 3405.5657 - sse: 6548.1030 - val_huber_loss: 0.2495 - val_loss: 0.3974 - val_mae: 0.6182 - val_mse: 0.5732 - val_pearson_correlation: 2.1764e-16 - val_r2_keras: -23.1469 - val_rmse: 0.8002 - val_sae: 343.4039 - val_sse: 338.7359 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.5427 - loss: 0.6906 - mae: 0.9403 - mse: 1.5056 - pearson_correlation: -2.4737e-16 - r2_keras: -215.1196 - rmse: 1.2793 - sae: 3952.8647 - sse: 6703.7603\n","Epoch 4: val_loss improved from 0.39738 to 0.39233, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.5383 - loss: 0.6879 - mae: 0.9293 - mse: 1.5349 - pearson_correlation: -1.9519e-16 - r2_keras: -185.3346 - rmse: 1.3119 - sae: 2889.8557 - sse: 4964.8247 - val_huber_loss: 0.2444 - val_loss: 0.3923 - val_mae: 0.6161 - val_mse: 0.5434 - val_pearson_correlation: -6.4246e-16 - val_r2_keras: -23.8918 - val_rmse: 0.8125 - val_sae: 353.9080 - val_sse: 349.1848 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.4141 - loss: 0.5621 - mae: 0.8095 - mse: 1.0935 - pearson_correlation: -4.7745e-16 - r2_keras: -173.4343 - rmse: 1.1493 - sae: 3533.7881 - sse: 5410.7339\n","Epoch 5: val_loss did not improve from 0.39233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.4394 - loss: 0.5775 - mae: 0.8161 - mse: 1.1709 - pearson_correlation: -3.7917e-16 - r2_keras: -153.6923 - rmse: 1.2039 - sae: 2599.5269 - sse: 4057.6223 - val_huber_loss: 0.2474 - val_loss: 0.3953 - val_mae: 0.6224 - val_mse: 0.5281 - val_pearson_correlation: -4.1801e-18 - val_r2_keras: -25.5255 - val_rmse: 0.8387 - val_sae: 370.8633 - val_sse: 372.1031 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3258 - loss: 0.4737 - mae: 0.7116 - mse: 0.8129 - pearson_correlation: 2.6014e-16 - r2_keras: -149.1528 - rmse: 1.0663 - sae: 3286.2012 - sse: 4657.5508\n","Epoch 6: val_loss did not improve from 0.39233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.3702 - loss: 0.5007 - mae: 0.7302 - mse: 0.9209 - pearson_correlation: 2.0006e-16 - r2_keras: -134.6559 - rmse: 1.1320 - sae: 2425.6912 - sse: 3522.0847 - val_huber_loss: 0.2566 - val_loss: 0.4045 - val_mae: 0.6332 - val_mse: 0.5297 - val_pearson_correlation: -3.5639e-16 - val_r2_keras: -27.9580 - val_rmse: 0.8763 - val_sae: 388.7094 - val_sse: 406.2257 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.2571 - loss: 0.4050 - mae: 0.6222 - mse: 0.6000 - pearson_correlation: 3.1547e-16 - r2_keras: -130.3324 - rmse: 0.9973 - sae: 3078.9121 - sse: 4073.7661\n","Epoch 7: val_loss did not improve from 0.39233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.3141 - loss: 0.4397 - mae: 0.6507 - mse: 0.7247 - pearson_correlation: 1.8632e-16 - r2_keras: -119.2129 - rmse: 1.0684 - sae: 2278.7048 - sse: 3098.9233 - val_huber_loss: 0.2643 - val_loss: 0.4122 - val_mae: 0.6381 - val_mse: 0.5343 - val_pearson_correlation: 2.5531e-16 - val_r2_keras: -31.0048 - val_rmse: 0.9213 - val_sae: 406.7592 - val_sse: 448.9663 - learning_rate: 1.0000e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2122 - loss: 0.3601 - mae: 0.5561 - mse: 0.4631 - pearson_correlation: 2.0532e-17 - r2_keras: -116.7158 - rmse: 0.9442 - sae: 2910.1047 - sse: 3651.3955\n","Epoch 8: val_loss did not improve from 0.39233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2754 - loss: 0.3986 - mae: 0.5920 - mse: 0.5918 - pearson_correlation: 1.2619e-17 - r2_keras: -107.1875 - rmse: 1.0144 - sae: 2156.5918 - sse: 2782.7664 - val_huber_loss: 0.2569 - val_loss: 0.4048 - val_mae: 0.6448 - val_mse: 0.5167 - val_pearson_correlation: -2.8814e-16 - val_r2_keras: -33.9646 - val_rmse: 0.9629 - val_sae: 419.5139 - val_sse: 490.4873 - learning_rate: 1.0000e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1795 - loss: 0.3274 - mae: 0.5093 - mse: 0.3791 - pearson_correlation: 1.7624e-16 - r2_keras: -109.3101 - rmse: 0.9140 - sae: 2794.5405 - sse: 3421.6816\n","Epoch 9: val_loss did not improve from 0.39233\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2441 - loss: 0.3667 - mae: 0.5474 - mse: 0.5019 - pearson_correlation: 6.6861e-17 - r2_keras: -99.8765 - rmse: 0.9786 - sae: 2071.6699 - sse: 2601.7786 - val_huber_loss: 0.2647 - val_loss: 0.4125 - val_mae: 0.6677 - val_mse: 0.5343 - val_pearson_correlation: -1.4816e-16 - val_r2_keras: -36.7078 - val_rmse: 1.0000 - val_sae: 432.9810 - val_sse: 528.9693 - learning_rate: 1.0000e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1596 - loss: 0.3075 - mae: 0.4826 - mse: 0.3378 - pearson_correlation: 2.7456e-16 - r2_keras: -105.9216 - rmse: 0.8998 - sae: 2765.3210 - sse: 3316.5742\n","Epoch 10: val_loss improved from 0.39233 to 0.38345, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.2236 - loss: 0.3464 - mae: 0.5205 - mse: 0.4538 - pearson_correlation: 9.6184e-17 - r2_keras: -96.0792 - rmse: 0.9586 - sae: 2046.3557 - sse: 2513.6619 - val_huber_loss: 0.2356 - val_loss: 0.3834 - val_mae: 0.6443 - val_mse: 0.4714 - val_pearson_correlation: 5.0505e-16 - val_r2_keras: -37.9865 - val_rmse: 1.0168 - val_sae: 432.2406 - val_sse: 546.9062 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1538 - loss: 0.3017 - mae: 0.4696 - mse: 0.3261 - pearson_correlation: -1.9354e-17 - r2_keras: -103.9502 - rmse: 0.8915 - sae: 2736.3030 - sse: 3255.4226\n","Epoch 11: val_loss improved from 0.38345 to 0.32695, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - huber_loss: 0.2182 - loss: 0.3409 - mae: 0.5088 - mse: 0.4413 - pearson_correlation: -6.3030e-18 - r2_keras: -94.4896 - rmse: 0.9511 - sae: 2025.8672 - sse: 2469.6650 - val_huber_loss: 0.1791 - val_loss: 0.3269 - val_mae: 0.5575 - val_mse: 0.3581 - val_pearson_correlation: -4.4644e-17 - val_r2_keras: -38.5288 - val_rmse: 1.0238 - val_sae: 415.6307 - val_sse: 554.5145 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1495 - loss: 0.2974 - mae: 0.4598 - mse: 0.3171 - pearson_correlation: 4.5173e-16 - r2_keras: -102.6881 - rmse: 0.8861 - sae: 2716.3350 - sse: 3216.2759\n","Epoch 12: val_loss improved from 0.32695 to 0.29096, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - huber_loss: 0.2136 - loss: 0.3364 - mae: 0.4998 - mse: 0.4310 - pearson_correlation: 3.4715e-16 - r2_keras: -93.3698 - rmse: 0.9456 - sae: 2011.3707 - sse: 2440.3018 - val_huber_loss: 0.1431 - val_loss: 0.2910 - val_mae: 0.4738 - val_mse: 0.2861 - val_pearson_correlation: 4.9880e-17 - val_r2_keras: -39.6891 - val_rmse: 1.0387 - val_sae: 402.1776 - val_sse: 570.7917 - learning_rate: 2.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1458 - loss: 0.2937 - mae: 0.4525 - mse: 0.3098 - pearson_correlation: 7.8636e-16 - r2_keras: -101.8431 - rmse: 0.8825 - sae: 2702.6885 - sse: 3190.0649\n","Epoch 13: val_loss improved from 0.29096 to 0.27302, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.2096 - loss: 0.3325 - mae: 0.4926 - mse: 0.4222 - pearson_correlation: 4.8639e-16 - r2_keras: -92.5325 - rmse: 0.9412 - sae: 2001.0883 - sse: 2419.6140 - val_huber_loss: 0.1251 - val_loss: 0.2730 - val_mae: 0.4240 - val_mse: 0.2503 - val_pearson_correlation: -2.3131e-16 - val_r2_keras: -41.2882 - val_rmse: 1.0590 - val_sae: 396.9826 - val_sse: 593.2233 - learning_rate: 2.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1426 - loss: 0.2905 - mae: 0.4463 - mse: 0.3033 - pearson_correlation: -7.5978e-16 - r2_keras: -101.1588 - rmse: 0.8796 - sae: 2691.4617 - sse: 3168.8391\n","Epoch 14: val_loss improved from 0.27302 to 0.26583, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.2060 - loss: 0.3291 - mae: 0.4865 - mse: 0.4143 - pearson_correlation: -5.2930e-16 - r2_keras: -91.8042 - rmse: 0.9373 - sae: 1992.4401 - sse: 2402.2717 - val_huber_loss: 0.1180 - val_loss: 0.2658 - val_mae: 0.3895 - val_mse: 0.2359 - val_pearson_correlation: 3.0665e-16 - val_r2_keras: -42.5085 - val_rmse: 1.0741 - val_sae: 394.8945 - val_sse: 610.3418 - learning_rate: 2.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1399 - loss: 0.2878 - mae: 0.4410 - mse: 0.2980 - pearson_correlation: -4.4016e-16 - r2_keras: -100.6236 - rmse: 0.8773 - sae: 2681.7307 - sse: 3152.2380\n","Epoch 15: val_loss improved from 0.26583 to 0.26279, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.2027 - loss: 0.3260 - mae: 0.4811 - mse: 0.4073 - pearson_correlation: -2.7480e-16 - r2_keras: -91.1676 - rmse: 0.9338 - sae: 1984.7529 - sse: 2387.9219 - val_huber_loss: 0.1149 - val_loss: 0.2628 - val_mae: 0.3948 - val_mse: 0.2299 - val_pearson_correlation: 3.9361e-16 - val_r2_keras: -43.5366 - val_rmse: 1.0868 - val_sae: 395.8932 - val_sse: 624.7638 - learning_rate: 2.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1378 - loss: 0.2857 - mae: 0.4363 - mse: 0.2939 - pearson_correlation: 2.7142e-16 - r2_keras: -99.9529 - rmse: 0.8744 - sae: 2668.6792 - sse: 3131.4343\n","Epoch 16: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1999 - loss: 0.3235 - mae: 0.4763 - mse: 0.4012 - pearson_correlation: 1.3323e-16 - r2_keras: -90.4184 - rmse: 0.9297 - sae: 1974.6935 - sse: 2370.5093 - val_huber_loss: 0.1152 - val_loss: 0.2631 - val_mae: 0.3996 - val_mse: 0.2305 - val_pearson_correlation: 7.1254e-17 - val_r2_keras: -44.6653 - val_rmse: 1.1004 - val_sae: 402.3331 - val_sse: 640.5974 - learning_rate: 2.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1362 - loss: 0.2841 - mae: 0.4322 - mse: 0.2907 - pearson_correlation: 1.4624e-16 - r2_keras: -99.5814 - rmse: 0.8728 - sae: 2659.6013 - sse: 3119.9077\n","Epoch 17: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1973 - loss: 0.3212 - mae: 0.4717 - mse: 0.3959 - pearson_correlation: 6.4556e-17 - r2_keras: -89.9110 - rmse: 0.9268 - sae: 1967.4547 - sse: 2359.7791 - val_huber_loss: 0.1207 - val_loss: 0.2685 - val_mae: 0.4076 - val_mse: 0.2415 - val_pearson_correlation: -8.6349e-17 - val_r2_keras: -45.9699 - val_rmse: 1.1160 - val_sae: 411.9206 - val_sse: 658.8983 - learning_rate: 2.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1344 - loss: 0.2822 - mae: 0.4288 - mse: 0.2870 - pearson_correlation: 3.6584e-16 - r2_keras: -99.5261 - rmse: 0.8725 - sae: 2656.4507 - sse: 3118.1946\n","Epoch 18: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1943 - loss: 0.3187 - mae: 0.4676 - mse: 0.3898 - pearson_correlation: 3.3675e-16 - r2_keras: -89.5605 - rmse: 0.9243 - sae: 1964.0028 - sse: 2354.9583 - val_huber_loss: 0.1236 - val_loss: 0.2715 - val_mae: 0.4086 - val_mse: 0.2474 - val_pearson_correlation: 3.6363e-17 - val_r2_keras: -46.7047 - val_rmse: 1.1247 - val_sae: 416.0231 - val_sse: 669.2069 - learning_rate: 2.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1327 - loss: 0.2806 - mae: 0.4248 - mse: 0.2838 - pearson_correlation: 1.4470e-16 - r2_keras: -99.0695 - rmse: 0.8705 - sae: 2646.9351 - sse: 3104.0317\n","Epoch 19: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1914 - loss: 0.3163 - mae: 0.4630 - mse: 0.3841 - pearson_correlation: 3.9461e-17 - r2_keras: -88.9359 - rmse: 0.9207 - sae: 1956.2474 - sse: 2341.7600 - val_huber_loss: 0.1256 - val_loss: 0.2734 - val_mae: 0.4108 - val_mse: 0.2514 - val_pearson_correlation: 5.4983e-17 - val_r2_keras: -47.2441 - val_rmse: 1.1311 - val_sae: 419.1153 - val_sse: 676.7736 - learning_rate: 2.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1312 - loss: 0.2790 - mae: 0.4209 - mse: 0.2808 - pearson_correlation: -1.7700e-16 - r2_keras: -98.8542 - rmse: 0.8696 - sae: 2640.2019 - sse: 3097.3513\n","Epoch 20: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1886 - loss: 0.3140 - mae: 0.4585 - mse: 0.3785 - pearson_correlation: -2.0252e-16 - r2_keras: -88.4786 - rmse: 0.9177 - sae: 1950.4064 - sse: 2333.6255 - val_huber_loss: 0.1263 - val_loss: 0.2741 - val_mae: 0.4112 - val_mse: 0.2528 - val_pearson_correlation: 1.3789e-16 - val_r2_keras: -47.4829 - val_rmse: 1.1339 - val_sae: 420.4135 - val_sse: 680.1232 - learning_rate: 2.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1297 - loss: 0.2776 - mae: 0.4169 - mse: 0.2779 - pearson_correlation: 4.4777e-17 - r2_keras: -98.3821 - rmse: 0.8675 - sae: 2630.5588 - sse: 3082.7095\n","Epoch 21: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1856 - loss: 0.3116 - mae: 0.4537 - mse: 0.3729 - pearson_correlation: 2.1892e-17 - r2_keras: -87.8353 - rmse: 0.9139 - sae: 1942.4924 - sse: 2320.0107 - val_huber_loss: 0.1288 - val_loss: 0.2767 - val_mae: 0.4157 - val_mse: 0.2578 - val_pearson_correlation: 8.4556e-17 - val_r2_keras: -47.8025 - val_rmse: 1.1376 - val_sae: 422.4760 - val_sse: 684.6073 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1290 - loss: 0.2769 - mae: 0.4150 - mse: 0.2766 - pearson_correlation: 2.8534e-16 - r2_keras: -98.2981 - rmse: 0.8672 - sae: 2628.1389 - sse: 3080.1028\n","Epoch 22: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1843 - loss: 0.3105 - mae: 0.4516 - mse: 0.3703 - pearson_correlation: 2.5024e-16 - r2_keras: -87.6412 - rmse: 0.9127 - sae: 1940.2653 - sse: 2316.6523 - val_huber_loss: 0.1320 - val_loss: 0.2799 - val_mae: 0.4217 - val_mse: 0.2644 - val_pearson_correlation: -3.5676e-16 - val_r2_keras: -48.1694 - val_rmse: 1.1419 - val_sae: 424.9776 - val_sse: 689.7538 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1283 - loss: 0.2762 - mae: 0.4134 - mse: 0.2751 - pearson_correlation: -5.6327e-16 - r2_keras: -98.2278 - rmse: 0.8669 - sae: 2626.3516 - sse: 3077.9219\n","Epoch 23: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1829 - loss: 0.3094 - mae: 0.4495 - mse: 0.3677 - pearson_correlation: -3.7618e-16 - r2_keras: -87.4567 - rmse: 0.9114 - sae: 1938.4771 - sse: 2313.5850 - val_huber_loss: 0.1318 - val_loss: 0.2797 - val_mae: 0.4216 - val_mse: 0.2638 - val_pearson_correlation: 2.7865e-16 - val_r2_keras: -48.1174 - val_rmse: 1.1413 - val_sae: 424.5801 - val_sse: 689.0237 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1276 - loss: 0.2755 - mae: 0.4113 - mse: 0.2737 - pearson_correlation: -1.1522e-17 - r2_keras: -98.0094 - rmse: 0.8659 - sae: 2622.2261 - sse: 3071.1475\n","Epoch 24: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.1816 - loss: 0.3083 - mae: 0.4473 - mse: 0.3651 - pearson_correlation: 1.3219e-17 - r2_keras: -87.1617 - rmse: 0.9097 - sae: 1935.0624 - sse: 2307.3159 - val_huber_loss: 0.1313 - val_loss: 0.2792 - val_mae: 0.4209 - val_mse: 0.2628 - val_pearson_correlation: 1.2363e-16 - val_r2_keras: -48.0425 - val_rmse: 1.1404 - val_sae: 424.1010 - val_sse: 687.9733 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1268 - loss: 0.2747 - mae: 0.4093 - mse: 0.2722 - pearson_correlation: 2.6695e-16 - r2_keras: -97.9193 - rmse: 0.8655 - sae: 2619.7673 - sse: 3068.3542\n","Epoch 25: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.1802 - loss: 0.3072 - mae: 0.4449 - mse: 0.3624 - pearson_correlation: 2.0847e-16 - r2_keras: -86.9686 - rmse: 0.9084 - sae: 1932.8407 - sse: 2303.8928 - val_huber_loss: 0.1300 - val_loss: 0.2779 - val_mae: 0.4191 - val_mse: 0.2603 - val_pearson_correlation: 2.0673e-16 - val_r2_keras: -47.8699 - val_rmse: 1.1384 - val_sae: 423.0013 - val_sse: 685.5526 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1261 - loss: 0.2740 - mae: 0.4071 - mse: 0.2707 - pearson_correlation: -5.8489e-16 - r2_keras: -97.7466 - rmse: 0.8648 - sae: 2616.3250 - sse: 3062.9946\n","Epoch 26: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1788 - loss: 0.3060 - mae: 0.4424 - mse: 0.3598 - pearson_correlation: -4.7717e-16 - r2_keras: -86.7127 - rmse: 0.9069 - sae: 1929.8998 - sse: 2298.6694 - val_huber_loss: 0.1291 - val_loss: 0.2769 - val_mae: 0.4177 - val_mse: 0.2584 - val_pearson_correlation: -1.7148e-16 - val_r2_keras: -47.7361 - val_rmse: 1.1368 - val_sae: 422.1660 - val_sse: 683.6752 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1255 - loss: 0.2733 - mae: 0.4051 - mse: 0.2694 - pearson_correlation: -3.9414e-16 - r2_keras: -97.7283 - rmse: 0.8647 - sae: 2614.6814 - sse: 3062.4287\n","Epoch 27: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.1775 - loss: 0.3050 - mae: 0.4402 - mse: 0.3573 - pearson_correlation: -3.6825e-16 - r2_keras: -86.5754 - rmse: 0.9059 - sae: 1928.2001 - sse: 2296.8237 - val_huber_loss: 0.1301 - val_loss: 0.2780 - val_mae: 0.4203 - val_mse: 0.2605 - val_pearson_correlation: 2.5040e-16 - val_r2_keras: -47.8081 - val_rmse: 1.1377 - val_sae: 422.7786 - val_sse: 684.6854 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1247 - loss: 0.2726 - mae: 0.4035 - mse: 0.2679 - pearson_correlation: -1.2632e-16 - r2_keras: -97.6411 - rmse: 0.8643 - sae: 2612.9773 - sse: 3059.7249\n","Epoch 28: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1760 - loss: 0.3038 - mae: 0.4382 - mse: 0.3547 - pearson_correlation: -1.5241e-16 - r2_keras: -86.3765 - rmse: 0.9045 - sae: 1926.4222 - sse: 2293.3701 - val_huber_loss: 0.1283 - val_loss: 0.2762 - val_mae: 0.4174 - val_mse: 0.2569 - val_pearson_correlation: -5.6720e-17 - val_r2_keras: -47.5860 - val_rmse: 1.1351 - val_sae: 421.3586 - val_sse: 681.5692 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1240 - loss: 0.2719 - mae: 0.4015 - mse: 0.2664 - pearson_correlation: -2.9896e-16 - r2_keras: -97.6187 - rmse: 0.8642 - sae: 2612.0259 - sse: 3059.0273\n","Epoch 29: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1746 - loss: 0.3027 - mae: 0.4359 - mse: 0.3520 - pearson_correlation: -1.7507e-16 - r2_keras: -86.2328 - rmse: 0.9035 - sae: 1925.1874 - sse: 2291.3950 - val_huber_loss: 0.1267 - val_loss: 0.2746 - val_mae: 0.4153 - val_mse: 0.2538 - val_pearson_correlation: -1.1770e-16 - val_r2_keras: -47.3689 - val_rmse: 1.1325 - val_sae: 419.9641 - val_sse: 678.5244 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1233 - loss: 0.2712 - mae: 0.3996 - mse: 0.2652 - pearson_correlation: 6.7480e-16 - r2_keras: -97.4652 - rmse: 0.8635 - sae: 2609.2432 - sse: 3054.2688\n","Epoch 30: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1732 - loss: 0.3016 - mae: 0.4337 - mse: 0.3495 - pearson_correlation: 4.0946e-16 - r2_keras: -85.9857 - rmse: 0.9019 - sae: 1922.6567 - sse: 2286.5237 - val_huber_loss: 0.1263 - val_loss: 0.2742 - val_mae: 0.4154 - val_mse: 0.2530 - val_pearson_correlation: 4.3775e-17 - val_r2_keras: -47.2493 - val_rmse: 1.1311 - val_sae: 419.3448 - val_sse: 676.8470 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1229 - loss: 0.2708 - mae: 0.3983 - mse: 0.2644 - pearson_correlation: -9.4521e-16 - r2_keras: -97.4302 - rmse: 0.8634 - sae: 2607.4607 - sse: 3053.1807\n","Epoch 31: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.1717 - loss: 0.3005 - mae: 0.4319 - mse: 0.3471 - pearson_correlation: -4.7225e-16 - r2_keras: -85.7907 - rmse: 0.9005 - sae: 1920.5405 - sse: 2283.7852 - val_huber_loss: 0.1261 - val_loss: 0.2740 - val_mae: 0.4154 - val_mse: 0.2525 - val_pearson_correlation: 3.2991e-16 - val_r2_keras: -47.1628 - val_rmse: 1.1301 - val_sae: 418.9154 - val_sse: 675.6335 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1225 - loss: 0.2704 - mae: 0.3971 - mse: 0.2635 - pearson_correlation: 1.2176e-16 - r2_keras: -97.4939 - rmse: 0.8636 - sae: 2607.3291 - sse: 3055.1572\n","Epoch 32: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.1702 - loss: 0.2994 - mae: 0.4301 - mse: 0.3447 - pearson_correlation: 2.4676e-17 - r2_keras: -85.6823 - rmse: 0.8995 - sae: 1919.6117 - sse: 2283.3333 - val_huber_loss: 0.1249 - val_loss: 0.2728 - val_mae: 0.4138 - val_mse: 0.2501 - val_pearson_correlation: 4.0392e-16 - val_r2_keras: -46.9669 - val_rmse: 1.1278 - val_sae: 417.6954 - val_sse: 672.8855 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1221 - loss: 0.2700 - mae: 0.3957 - mse: 0.2628 - pearson_correlation: 7.4761e-16 - r2_keras: -97.3573 - rmse: 0.8630 - sae: 2604.5874 - sse: 3050.9209\n","Epoch 33: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1688 - loss: 0.2984 - mae: 0.4282 - mse: 0.3424 - pearson_correlation: 5.7733e-16 - r2_keras: -85.4335 - rmse: 0.8979 - sae: 1916.9048 - sse: 2278.6587 - val_huber_loss: 0.1239 - val_loss: 0.2718 - val_mae: 0.4123 - val_mse: 0.2481 - val_pearson_correlation: 4.7246e-16 - val_r2_keras: -46.8078 - val_rmse: 1.1260 - val_sae: 416.7448 - val_sse: 670.6533 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.1217 - loss: 0.2696 - mae: 0.3944 - mse: 0.2619 - pearson_correlation: -1.7026e-16 - r2_keras: -97.3375 - rmse: 0.8630 - sae: 2603.8901 - sse: 3050.3054\n","Epoch 34: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1674 - loss: 0.2974 - mae: 0.4264 - mse: 0.3403 - pearson_correlation: -2.1184e-16 - r2_keras: -85.2889 - rmse: 0.8968 - sae: 1915.6542 - sse: 2276.7073 - val_huber_loss: 0.1243 - val_loss: 0.2722 - val_mae: 0.4138 - val_mse: 0.2489 - val_pearson_correlation: 1.6337e-16 - val_r2_keras: -46.7878 - val_rmse: 1.1257 - val_sae: 416.8109 - val_sse: 670.3726 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1212 - loss: 0.2690 - mae: 0.3931 - mse: 0.2609 - pearson_correlation: -1.5976e-16 - r2_keras: -97.1522 - rmse: 0.8621 - sae: 2601.3633 - sse: 3044.5588\n","Epoch 35: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.1661 - loss: 0.2964 - mae: 0.4247 - mse: 0.3380 - pearson_correlation: -1.9502e-16 - r2_keras: -85.0253 - rmse: 0.8952 - sae: 1913.2013 - sse: 2271.2327 - val_huber_loss: 0.1225 - val_loss: 0.2704 - val_mae: 0.4108 - val_mse: 0.2453 - val_pearson_correlation: -8.8847e-17 - val_r2_keras: -46.5361 - val_rmse: 1.1228 - val_sae: 415.2192 - val_sse: 666.8419 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1206 - loss: 0.2685 - mae: 0.3914 - mse: 0.2598 - pearson_correlation: -1.2361e-16 - r2_keras: -97.0657 - rmse: 0.8618 - sae: 2600.1333 - sse: 3041.8748\n","Epoch 36: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1648 - loss: 0.2954 - mae: 0.4226 - mse: 0.3358 - pearson_correlation: -9.5787e-17 - r2_keras: -84.8488 - rmse: 0.8940 - sae: 1911.7174 - sse: 2268.0498 - val_huber_loss: 0.1212 - val_loss: 0.2691 - val_mae: 0.4089 - val_mse: 0.2427 - val_pearson_correlation: 1.9394e-18 - val_r2_keras: -46.3302 - val_rmse: 1.1203 - val_sae: 413.9654 - val_sse: 663.9539 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1201 - loss: 0.2680 - mae: 0.3898 - mse: 0.2588 - pearson_correlation: -4.5704e-16 - r2_keras: -96.8505 - rmse: 0.8608 - sae: 2597.1853 - sse: 3035.1990\n","Epoch 37: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1636 - loss: 0.2945 - mae: 0.4207 - mse: 0.3336 - pearson_correlation: -3.1597e-16 - r2_keras: -84.5804 - rmse: 0.8924 - sae: 1909.0430 - sse: 2262.1343 - val_huber_loss: 0.1203 - val_loss: 0.2682 - val_mae: 0.4077 - val_mse: 0.2409 - val_pearson_correlation: -4.1640e-16 - val_r2_keras: -46.1742 - val_rmse: 1.1185 - val_sae: 413.0536 - val_sse: 661.7651 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1196 - loss: 0.2674 - mae: 0.3883 - mse: 0.2577 - pearson_correlation: 1.7838e-16 - r2_keras: -96.7783 - rmse: 0.8605 - sae: 2595.8289 - sse: 3032.9595\n","Epoch 38: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1625 - loss: 0.2936 - mae: 0.4188 - mse: 0.3315 - pearson_correlation: 7.7968e-17 - r2_keras: -84.4204 - rmse: 0.8913 - sae: 1907.5145 - sse: 2259.3291 - val_huber_loss: 0.1188 - val_loss: 0.2667 - val_mae: 0.4054 - val_mse: 0.2379 - val_pearson_correlation: -1.1533e-16 - val_r2_keras: -45.9431 - val_rmse: 1.1157 - val_sae: 411.6193 - val_sse: 658.5231 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1190 - loss: 0.2669 - mae: 0.3865 - mse: 0.2566 - pearson_correlation: -2.3474e-16 - r2_keras: -96.5547 - rmse: 0.8595 - sae: 2592.6467 - sse: 3026.0234\n","Epoch 39: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1614 - loss: 0.2926 - mae: 0.4168 - mse: 0.3294 - pearson_correlation: -1.5318e-16 - r2_keras: -84.1522 - rmse: 0.8898 - sae: 1904.7404 - sse: 2253.3074 - val_huber_loss: 0.1174 - val_loss: 0.2652 - val_mae: 0.4031 - val_mse: 0.2351 - val_pearson_correlation: 1.9247e-16 - val_r2_keras: -45.7138 - val_rmse: 1.1130 - val_sae: 410.1915 - val_sse: 655.3067 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1184 - loss: 0.2663 - mae: 0.3847 - mse: 0.2555 - pearson_correlation: 5.4709e-16 - r2_keras: -96.3215 - rmse: 0.8585 - sae: 2589.5156 - sse: 3018.7900\n","Epoch 40: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1603 - loss: 0.2918 - mae: 0.4148 - mse: 0.3274 - pearson_correlation: 2.2686e-16 - r2_keras: -83.8823 - rmse: 0.8882 - sae: 1902.0157 - sse: 2247.1431 - val_huber_loss: 0.1168 - val_loss: 0.2647 - val_mae: 0.4024 - val_mse: 0.2340 - val_pearson_correlation: -2.5015e-16 - val_r2_keras: -45.5842 - val_rmse: 1.1115 - val_sae: 409.5086 - val_sse: 653.4880 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1179 - loss: 0.2657 - mae: 0.3831 - mse: 0.2544 - pearson_correlation: 3.5461e-16 - r2_keras: -96.2247 - rmse: 0.8581 - sae: 2588.3687 - sse: 3015.7883\n","Epoch 41: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1592 - loss: 0.2909 - mae: 0.4128 - mse: 0.3253 - pearson_correlation: 2.3752e-16 - r2_keras: -83.7258 - rmse: 0.8872 - sae: 1900.7291 - sse: 2244.0625 - val_huber_loss: 0.1158 - val_loss: 0.2636 - val_mae: 0.4008 - val_mse: 0.2318 - val_pearson_correlation: -1.6809e-16 - val_r2_keras: -45.3934 - val_rmse: 1.1092 - val_sae: 408.3756 - val_sse: 650.8117 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1173 - loss: 0.2652 - mae: 0.3813 - mse: 0.2533 - pearson_correlation: 2.1486e-16 - r2_keras: -95.9850 - rmse: 0.8570 - sae: 2585.3413 - sse: 3008.3521\n","Epoch 42: val_loss did not improve from 0.26279\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1582 - loss: 0.2900 - mae: 0.4108 - mse: 0.3234 - pearson_correlation: 2.1078e-16 - r2_keras: -83.4575 - rmse: 0.8856 - sae: 1898.0819 - sse: 2237.8330 - val_huber_loss: 0.1158 - val_loss: 0.2636 - val_mae: 0.4014 - val_mse: 0.2318 - val_pearson_correlation: 1.9816e-16 - val_r2_keras: -45.3103 - val_rmse: 1.1082 - val_sae: 408.0807 - val_sse: 649.6453 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1166 - loss: 0.2645 - mae: 0.3792 - mse: 0.2519 - pearson_correlation: -6.2579e-16 - r2_keras: -95.9034 - rmse: 0.8566 - sae: 2583.7786 - sse: 3005.8213\n","Epoch 43: val_loss improved from 0.26279 to 0.26255, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1571 - loss: 0.2891 - mae: 0.4085 - mse: 0.3212 - pearson_correlation: -3.3511e-16 - r2_keras: -83.3115 - rmse: 0.8846 - sae: 1896.5316 - sse: 2235.0710 - val_huber_loss: 0.1147 - val_loss: 0.2625 - val_mae: 0.3998 - val_mse: 0.2297 - val_pearson_correlation: 1.1141e-16 - val_r2_keras: -45.1201 - val_rmse: 1.1059 - val_sae: 406.9535 - val_sse: 646.9780 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1159 - loss: 0.2638 - mae: 0.3772 - mse: 0.2505 - pearson_correlation: 7.2369e-17 - r2_keras: -95.6397 - rmse: 0.8555 - sae: 2580.2832 - sse: 2997.6436\n","Epoch 44: val_loss improved from 0.26255 to 0.26152, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1559 - loss: 0.2881 - mae: 0.4063 - mse: 0.3188 - pearson_correlation: 4.9143e-18 - r2_keras: -83.0246 - rmse: 0.8830 - sae: 1893.6510 - sse: 2228.3162 - val_huber_loss: 0.1137 - val_loss: 0.2615 - val_mae: 0.3982 - val_mse: 0.2276 - val_pearson_correlation: 4.7536e-16 - val_r2_keras: -44.9378 - val_rmse: 1.1037 - val_sae: 405.8950 - val_sse: 644.4208 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1152 - loss: 0.2631 - mae: 0.3752 - mse: 0.2491 - pearson_correlation: 7.2597e-16 - r2_keras: -95.4166 - rmse: 0.8545 - sae: 2577.4639 - sse: 2990.7209\n","Epoch 45: val_loss improved from 0.26152 to 0.26067, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.1548 - loss: 0.2872 - mae: 0.4041 - mse: 0.3165 - pearson_correlation: 5.0481e-16 - r2_keras: -82.7691 - rmse: 0.8814 - sae: 1891.2853 - sse: 2222.4485 - val_huber_loss: 0.1128 - val_loss: 0.2607 - val_mae: 0.3968 - val_mse: 0.2259 - val_pearson_correlation: 3.9887e-16 - val_r2_keras: -44.7785 - val_rmse: 1.1018 - val_sae: 405.0273 - val_sse: 642.1851 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1146 - loss: 0.2624 - mae: 0.3733 - mse: 0.2477 - pearson_correlation: 9.4199e-16 - r2_keras: -95.3374 - rmse: 0.8541 - sae: 2576.6406 - sse: 2988.2668\n","Epoch 46: val_loss did not improve from 0.26067\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1537 - loss: 0.2863 - mae: 0.4020 - mse: 0.3143 - pearson_correlation: 5.1120e-16 - r2_keras: -82.6283 - rmse: 0.8805 - sae: 1890.3436 - sse: 2219.7800 - val_huber_loss: 0.1133 - val_loss: 0.2612 - val_mae: 0.3986 - val_mse: 0.2270 - val_pearson_correlation: -2.4276e-16 - val_r2_keras: -44.7532 - val_rmse: 1.1015 - val_sae: 405.3127 - val_sse: 641.8312 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1139 - loss: 0.2618 - mae: 0.3716 - mse: 0.2464 - pearson_correlation: -1.4584e-16 - r2_keras: -95.0812 - rmse: 0.8530 - sae: 2573.9062 - sse: 2980.3174\n","Epoch 47: val_loss improved from 0.26067 to 0.25984, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.1526 - loss: 0.2853 - mae: 0.4001 - mse: 0.3121 - pearson_correlation: 7.4821e-17 - r2_keras: -82.3576 - rmse: 0.8789 - sae: 1888.1337 - sse: 2213.3086 - val_huber_loss: 0.1120 - val_loss: 0.2598 - val_mae: 0.3960 - val_mse: 0.2243 - val_pearson_correlation: -1.2095e-17 - val_r2_keras: -44.5305 - val_rmse: 1.0988 - val_sae: 403.9352 - val_sse: 638.7074 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1132 - loss: 0.2611 - mae: 0.3695 - mse: 0.2450 - pearson_correlation: -4.3715e-16 - r2_keras: -94.9814 - rmse: 0.8526 - sae: 2572.7595 - sse: 2977.2217\n","Epoch 48: val_loss improved from 0.25984 to 0.25845, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - huber_loss: 0.1516 - loss: 0.2844 - mae: 0.3978 - mse: 0.3099 - pearson_correlation: -3.4443e-16 - r2_keras: -82.2032 - rmse: 0.8779 - sae: 1887.0549 - sse: 2210.2148 - val_huber_loss: 0.1106 - val_loss: 0.2584 - val_mae: 0.3934 - val_mse: 0.2215 - val_pearson_correlation: 1.9455e-16 - val_r2_keras: -44.2835 - val_rmse: 1.0958 - val_sae: 402.4287 - val_sse: 635.2416 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1126 - loss: 0.2604 - mae: 0.3673 - mse: 0.2436 - pearson_correlation: -1.2353e-16 - r2_keras: -94.7160 - rmse: 0.8514 - sae: 2569.4919 - sse: 2968.9912\n","Epoch 49: val_loss improved from 0.25845 to 0.25758, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1505 - loss: 0.2835 - mae: 0.3955 - mse: 0.3077 - pearson_correlation: -8.6790e-17 - r2_keras: -81.9251 - rmse: 0.8763 - sae: 1884.5111 - sse: 2203.5405 - val_huber_loss: 0.1097 - val_loss: 0.2576 - val_mae: 0.3918 - val_mse: 0.2198 - val_pearson_correlation: 1.5670e-16 - val_r2_keras: -44.0978 - val_rmse: 1.0936 - val_sae: 401.4142 - val_sse: 632.6367 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1119 - loss: 0.2598 - mae: 0.3652 - mse: 0.2422 - pearson_correlation: -4.8584e-16 - r2_keras: -94.5934 - rmse: 0.8508 - sae: 2568.0620 - sse: 2965.1880\n","Epoch 50: val_loss improved from 0.25758 to 0.25650, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1495 - loss: 0.2826 - mae: 0.3931 - mse: 0.3054 - pearson_correlation: -2.1530e-16 - r2_keras: -81.7521 - rmse: 0.8752 - sae: 1883.2313 - sse: 2199.9348 - val_huber_loss: 0.1086 - val_loss: 0.2565 - val_mae: 0.3899 - val_mse: 0.2176 - val_pearson_correlation: -2.6999e-16 - val_r2_keras: -43.8686 - val_rmse: 1.0908 - val_sae: 400.1052 - val_sse: 629.4220 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1113 - loss: 0.2591 - mae: 0.3629 - mse: 0.2409 - pearson_correlation: -2.4715e-16 - r2_keras: -94.2831 - rmse: 0.8495 - sae: 2564.4575 - sse: 2955.5635\n","Epoch 51: val_loss improved from 0.25650 to 0.25553, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1484 - loss: 0.2817 - mae: 0.3907 - mse: 0.3032 - pearson_correlation: -1.9986e-16 - r2_keras: -81.4406 - rmse: 0.8735 - sae: 1880.4193 - sse: 2192.2900 - val_huber_loss: 0.1077 - val_loss: 0.2555 - val_mae: 0.3882 - val_mse: 0.2157 - val_pearson_correlation: 1.8079e-16 - val_r2_keras: -43.6747 - val_rmse: 1.0884 - val_sae: 398.9677 - val_sse: 626.7015 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1106 - loss: 0.2585 - mae: 0.3604 - mse: 0.2397 - pearson_correlation: -3.0009e-16 - r2_keras: -94.0223 - rmse: 0.8483 - sae: 2561.2957 - sse: 2947.4719\n","Epoch 52: val_loss improved from 0.25553 to 0.25487, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1474 - loss: 0.2808 - mae: 0.3882 - mse: 0.3012 - pearson_correlation: -2.7020e-16 - r2_keras: -81.1725 - rmse: 0.8719 - sae: 1877.9727 - sse: 2185.7915 - val_huber_loss: 0.1070 - val_loss: 0.2549 - val_mae: 0.3872 - val_mse: 0.2144 - val_pearson_correlation: -1.0933e-16 - val_r2_keras: -43.5029 - val_rmse: 1.0863 - val_sae: 398.1015 - val_sse: 624.2914 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1100 - loss: 0.2579 - mae: 0.3580 - mse: 0.2383 - pearson_correlation: -4.7286e-16 - r2_keras: -93.9189 - rmse: 0.8478 - sae: 2560.5195 - sse: 2944.2644\n","Epoch 53: val_loss improved from 0.25487 to 0.25394, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - huber_loss: 0.1464 - loss: 0.2800 - mae: 0.3857 - mse: 0.2991 - pearson_correlation: -3.4730e-16 - r2_keras: -81.0293 - rmse: 0.8710 - sae: 1877.2440 - sse: 2182.7817 - val_huber_loss: 0.1061 - val_loss: 0.2539 - val_mae: 0.3855 - val_mse: 0.2125 - val_pearson_correlation: -6.8401e-17 - val_r2_keras: -43.2879 - val_rmse: 1.0837 - val_sae: 396.8718 - val_sse: 621.2761 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1094 - loss: 0.2573 - mae: 0.3557 - mse: 0.2371 - pearson_correlation: -4.2378e-16 - r2_keras: -93.5974 - rmse: 0.8464 - sae: 2557.0610 - sse: 2934.2925\n","Epoch 54: val_loss improved from 0.25394 to 0.25316, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1456 - loss: 0.2793 - mae: 0.3835 - mse: 0.2973 - pearson_correlation: -2.9043e-16 - r2_keras: -80.7301 - rmse: 0.8694 - sae: 1874.6923 - sse: 2175.1379 - val_huber_loss: 0.1053 - val_loss: 0.2532 - val_mae: 0.3842 - val_mse: 0.2109 - val_pearson_correlation: 2.0827e-18 - val_r2_keras: -43.0829 - val_rmse: 1.0812 - val_sae: 395.7477 - val_sse: 618.4000 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1089 - loss: 0.2567 - mae: 0.3533 - mse: 0.2360 - pearson_correlation: -5.4514e-16 - r2_keras: -93.3693 - rmse: 0.8454 - sae: 2554.2463 - sse: 2927.2178\n","Epoch 55: val_loss improved from 0.25316 to 0.25278, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.1448 - loss: 0.2786 - mae: 0.3812 - mse: 0.2955 - pearson_correlation: -2.5941e-16 - r2_keras: -80.4926 - rmse: 0.8680 - sae: 1872.5648 - sse: 2169.4197 - val_huber_loss: 0.1049 - val_loss: 0.2528 - val_mae: 0.3839 - val_mse: 0.2102 - val_pearson_correlation: 2.9259e-17 - val_r2_keras: -42.9447 - val_rmse: 1.0795 - val_sae: 395.1492 - val_sse: 616.4611 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1084 - loss: 0.2562 - mae: 0.3513 - mse: 0.2349 - pearson_correlation: -2.4121e-16 - r2_keras: -93.3103 - rmse: 0.8451 - sae: 2553.5879 - sse: 2925.3862\n","Epoch 56: val_loss improved from 0.25278 to 0.25200, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1439 - loss: 0.2779 - mae: 0.3790 - mse: 0.2937 - pearson_correlation: -1.5045e-16 - r2_keras: -80.3940 - rmse: 0.8673 - sae: 1871.9863 - sse: 2167.5029 - val_huber_loss: 0.1042 - val_loss: 0.2520 - val_mae: 0.3824 - val_mse: 0.2086 - val_pearson_correlation: -1.2387e-16 - val_r2_keras: -42.7460 - val_rmse: 1.0771 - val_sae: 394.0745 - val_sse: 613.6730 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1078 - loss: 0.2556 - mae: 0.3486 - mse: 0.2335 - pearson_correlation: 5.6492e-17 - r2_keras: -92.9342 - rmse: 0.8434 - sae: 2550.1445 - sse: 2913.7202\n","Epoch 57: val_loss improved from 0.25200 to 0.25200, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1432 - loss: 0.2772 - mae: 0.3765 - mse: 0.2919 - pearson_correlation: 2.5063e-16 - r2_keras: -80.0840 - rmse: 0.8657 - sae: 1869.5365 - sse: 2159.0312 - val_huber_loss: 0.1042 - val_loss: 0.2520 - val_mae: 0.3832 - val_mse: 0.2086 - val_pearson_correlation: 4.3159e-16 - val_r2_keras: -42.6411 - val_rmse: 1.0758 - val_sae: 393.8500 - val_sse: 612.2017 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1073 - loss: 0.2551 - mae: 0.3471 - mse: 0.2326 - pearson_correlation: -6.8797e-16 - r2_keras: -92.9349 - rmse: 0.8434 - sae: 2549.8149 - sse: 2913.7441\n","Epoch 58: val_loss improved from 0.25200 to 0.25109, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1424 - loss: 0.2765 - mae: 0.3748 - mse: 0.2904 - pearson_correlation: -3.6848e-16 - r2_keras: -80.0302 - rmse: 0.8653 - sae: 1869.1818 - sse: 2158.4097 - val_huber_loss: 0.1032 - val_loss: 0.2511 - val_mae: 0.3814 - val_mse: 0.2068 - val_pearson_correlation: -1.9480e-16 - val_r2_keras: -42.3927 - val_rmse: 1.0727 - val_sae: 392.4333 - val_sse: 608.7176 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1068 - loss: 0.2546 - mae: 0.3446 - mse: 0.2314 - pearson_correlation: 5.7657e-16 - r2_keras: -92.5064 - rmse: 0.8415 - sae: 2545.4004 - sse: 2900.4512\n","Epoch 59: val_loss improved from 0.25109 to 0.25106, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1417 - loss: 0.2759 - mae: 0.3725 - mse: 0.2887 - pearson_correlation: 4.3387e-16 - r2_keras: -79.6742 - rmse: 0.8634 - sae: 1866.0399 - sse: 2148.7229 - val_huber_loss: 0.1032 - val_loss: 0.2511 - val_mae: 0.3820 - val_mse: 0.2067 - val_pearson_correlation: -2.2510e-16 - val_r2_keras: -42.2844 - val_rmse: 1.0714 - val_sae: 392.1404 - val_sse: 607.1987 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1063 - loss: 0.2542 - mae: 0.3432 - mse: 0.2305 - pearson_correlation: -2.9594e-16 - r2_keras: -92.5270 - rmse: 0.8416 - sae: 2545.3237 - sse: 2901.0903\n","Epoch 60: val_loss improved from 0.25106 to 0.25002, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1410 - loss: 0.2753 - mae: 0.3710 - mse: 0.2873 - pearson_correlation: -6.2963e-17 - r2_keras: -79.6401 - rmse: 0.8631 - sae: 1865.8672 - sse: 2148.5881 - val_huber_loss: 0.1022 - val_loss: 0.2500 - val_mae: 0.3796 - val_mse: 0.2046 - val_pearson_correlation: 3.2674e-16 - val_r2_keras: -42.0414 - val_rmse: 1.0684 - val_sae: 390.6320 - val_sse: 603.7901 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1058 - loss: 0.2537 - mae: 0.3410 - mse: 0.2295 - pearson_correlation: -1.6747e-16 - r2_keras: -92.1777 - rmse: 0.8400 - sae: 2541.9463 - sse: 2890.2559\n","Epoch 61: val_loss improved from 0.25002 to 0.24958, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1403 - loss: 0.2747 - mae: 0.3688 - mse: 0.2857 - pearson_correlation: -2.4907e-16 - r2_keras: -79.3448 - rmse: 0.8615 - sae: 1863.4391 - sse: 2140.6333 - val_huber_loss: 0.1017 - val_loss: 0.2496 - val_mae: 0.3789 - val_mse: 0.2038 - val_pearson_correlation: 4.0731e-17 - val_r2_keras: -41.8889 - val_rmse: 1.0665 - val_sae: 389.9022 - val_sse: 601.6502 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1054 - loss: 0.2532 - mae: 0.3392 - mse: 0.2284 - pearson_correlation: 1.1303e-16 - r2_keras: -92.0422 - rmse: 0.8394 - sae: 2540.9128 - sse: 2886.0532\n","Epoch 62: val_loss improved from 0.24958 to 0.24947, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.1396 - loss: 0.2741 - mae: 0.3669 - mse: 0.2842 - pearson_correlation: 5.0208e-17 - r2_keras: -79.2213 - rmse: 0.8608 - sae: 1862.6985 - sse: 2137.4424 - val_huber_loss: 0.1016 - val_loss: 0.2495 - val_mae: 0.3793 - val_mse: 0.2035 - val_pearson_correlation: 2.8617e-16 - val_r2_keras: -41.7469 - val_rmse: 1.0647 - val_sae: 389.3962 - val_sse: 599.6581 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1050 - loss: 0.2528 - mae: 0.3381 - mse: 0.2276 - pearson_correlation: 5.6083e-17 - r2_keras: -91.9632 - rmse: 0.8390 - sae: 2539.7231 - sse: 2883.6021\n","Epoch 63: val_loss improved from 0.24947 to 0.24896, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1390 - loss: 0.2735 - mae: 0.3657 - mse: 0.2828 - pearson_correlation: 7.4847e-17 - r2_keras: -79.0987 - rmse: 0.8600 - sae: 1861.6893 - sse: 2134.9875 - val_huber_loss: 0.1011 - val_loss: 0.2490 - val_mae: 0.3783 - val_mse: 0.2025 - val_pearson_correlation: 8.2059e-17 - val_r2_keras: -41.5998 - val_rmse: 1.0629 - val_sae: 388.6566 - val_sse: 597.5947 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1045 - loss: 0.2523 - mae: 0.3362 - mse: 0.2264 - pearson_correlation: -3.5725e-16 - r2_keras: -91.9100 - rmse: 0.8388 - sae: 2540.1328 - sse: 2881.9526\n","Epoch 64: val_loss improved from 0.24896 to 0.24824, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1383 - loss: 0.2729 - mae: 0.3636 - mse: 0.2812 - pearson_correlation: -1.5531e-16 - r2_keras: -79.0202 - rmse: 0.8595 - sae: 1861.8705 - sse: 2133.3833 - val_huber_loss: 0.1004 - val_loss: 0.2482 - val_mae: 0.3768 - val_mse: 0.2011 - val_pearson_correlation: 2.6701e-16 - val_r2_keras: -41.3797 - val_rmse: 1.0601 - val_sae: 387.4460 - val_sse: 594.5073 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1041 - loss: 0.2519 - mae: 0.3346 - mse: 0.2255 - pearson_correlation: -9.4073e-17 - r2_keras: -91.5632 - rmse: 0.8372 - sae: 2537.1465 - sse: 2871.1941\n","Epoch 65: val_loss improved from 0.24824 to 0.24742, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.1376 - loss: 0.2723 - mae: 0.3619 - mse: 0.2797 - pearson_correlation: -1.1599e-16 - r2_keras: -78.7195 - rmse: 0.8579 - sae: 1859.6888 - sse: 2125.3953 - val_huber_loss: 0.0996 - val_loss: 0.2474 - val_mae: 0.3751 - val_mse: 0.1994 - val_pearson_correlation: -2.1717e-16 - val_r2_keras: -41.1624 - val_rmse: 1.0574 - val_sae: 386.2230 - val_sse: 591.4586 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1036 - loss: 0.2515 - mae: 0.3327 - mse: 0.2247 - pearson_correlation: 1.5476e-16 - r2_keras: -91.5136 - rmse: 0.8370 - sae: 2536.8560 - sse: 2869.6572\n","Epoch 66: val_loss improved from 0.24742 to 0.24736, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.1369 - loss: 0.2717 - mae: 0.3599 - mse: 0.2782 - pearson_correlation: 2.5597e-16 - r2_keras: -78.6463 - rmse: 0.8574 - sae: 1859.4387 - sse: 2123.8999 - val_huber_loss: 0.0995 - val_loss: 0.2474 - val_mae: 0.3754 - val_mse: 0.1993 - val_pearson_correlation: -4.8226e-17 - val_r2_keras: -40.9958 - val_rmse: 1.0553 - val_sae: 385.6354 - val_sse: 589.1212 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1032 - loss: 0.2510 - mae: 0.3312 - mse: 0.2236 - pearson_correlation: 1.5668e-16 - r2_keras: -91.3727 - rmse: 0.8364 - sae: 2535.8872 - sse: 2865.2866\n","Epoch 67: val_loss improved from 0.24736 to 0.24717, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.1362 - loss: 0.2711 - mae: 0.3582 - mse: 0.2766 - pearson_correlation: 5.3357e-17 - r2_keras: -78.4964 - rmse: 0.8565 - sae: 1858.6642 - sse: 2120.3298 - val_huber_loss: 0.0993 - val_loss: 0.2472 - val_mae: 0.3755 - val_mse: 0.1989 - val_pearson_correlation: -4.1840e-17 - val_r2_keras: -40.8228 - val_rmse: 1.0531 - val_sae: 384.9178 - val_sse: 586.6953 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1027 - loss: 0.2505 - mae: 0.3300 - mse: 0.2226 - pearson_correlation: 4.8721e-16 - r2_keras: -91.4528 - rmse: 0.8367 - sae: 2536.4048 - sse: 2867.7695\n","Epoch 68: val_loss improved from 0.24717 to 0.24642, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1354 - loss: 0.2704 - mae: 0.3568 - mse: 0.2750 - pearson_correlation: 4.0086e-16 - r2_keras: -78.4967 - rmse: 0.8563 - sae: 1858.8744 - sse: 2121.3623 - val_huber_loss: 0.0986 - val_loss: 0.2464 - val_mae: 0.3737 - val_mse: 0.1974 - val_pearson_correlation: 3.0571e-16 - val_r2_keras: -40.5887 - val_rmse: 1.0502 - val_sae: 383.5783 - val_sse: 583.4106 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1021 - loss: 0.2499 - mae: 0.3270 - mse: 0.2214 - pearson_correlation: 5.3019e-16 - r2_keras: -91.3916 - rmse: 0.8365 - sae: 2535.6963 - sse: 2865.8728\n","Epoch 69: val_loss improved from 0.24642 to 0.24629, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.1347 - loss: 0.2698 - mae: 0.3539 - mse: 0.2734 - pearson_correlation: 2.9170e-16 - r2_keras: -78.4079 - rmse: 0.8557 - sae: 1858.2948 - sse: 2119.5347 - val_huber_loss: 0.0985 - val_loss: 0.2463 - val_mae: 0.3739 - val_mse: 0.1971 - val_pearson_correlation: 4.8982e-17 - val_r2_keras: -40.3983 - val_rmse: 1.0478 - val_sae: 382.7906 - val_sse: 580.7404 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1017 - loss: 0.2495 - mae: 0.3253 - mse: 0.2205 - pearson_correlation: 2.3202e-16 - r2_keras: -91.2203 - rmse: 0.8357 - sae: 2533.8428 - sse: 2860.5596\n","Epoch 70: val_loss improved from 0.24629 to 0.24541, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1340 - loss: 0.2692 - mae: 0.3522 - mse: 0.2719 - pearson_correlation: 2.7076e-16 - r2_keras: -78.2307 - rmse: 0.8547 - sae: 1856.9012 - sse: 2115.2537 - val_huber_loss: 0.0976 - val_loss: 0.2454 - val_mae: 0.3716 - val_mse: 0.1954 - val_pearson_correlation: -1.1773e-16 - val_r2_keras: -40.1196 - val_rmse: 1.0442 - val_sae: 381.0487 - val_sse: 576.8297 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1013 - loss: 0.2491 - mae: 0.3235 - mse: 0.2197 - pearson_correlation: 3.9101e-17 - r2_keras: -91.0927 - rmse: 0.8351 - sae: 2532.5596 - sse: 2856.6003\n","Epoch 71: val_loss did not improve from 0.24541\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1334 - loss: 0.2687 - mae: 0.3503 - mse: 0.2706 - pearson_correlation: 4.8606e-17 - r2_keras: -78.0923 - rmse: 0.8538 - sae: 1855.9185 - sse: 2111.9890 - val_huber_loss: 0.0977 - val_loss: 0.2456 - val_mae: 0.3726 - val_mse: 0.1957 - val_pearson_correlation: 1.6877e-16 - val_r2_keras: -39.9987 - val_rmse: 1.0427 - val_sae: 380.7753 - val_sse: 575.1340 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1009 - loss: 0.2487 - mae: 0.3221 - mse: 0.2188 - pearson_correlation: 1.8642e-16 - r2_keras: -91.0870 - rmse: 0.8351 - sae: 2531.9736 - sse: 2856.4226\n","Epoch 72: val_loss improved from 0.24541 to 0.24538, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1328 - loss: 0.2681 - mae: 0.3488 - mse: 0.2692 - pearson_correlation: 1.7491e-16 - r2_keras: -78.0452 - rmse: 0.8534 - sae: 1855.4493 - sse: 2111.3623 - val_huber_loss: 0.0976 - val_loss: 0.2454 - val_mae: 0.3724 - val_mse: 0.1953 - val_pearson_correlation: 2.2635e-18 - val_r2_keras: -39.7851 - val_rmse: 1.0400 - val_sae: 379.7672 - val_sse: 572.1378 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1005 - loss: 0.2483 - mae: 0.3213 - mse: 0.2181 - pearson_correlation: 3.1915e-16 - r2_keras: -90.9100 - rmse: 0.8343 - sae: 2529.9980 - sse: 2850.9346\n","Epoch 73: val_loss improved from 0.24538 to 0.24492, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1322 - loss: 0.2676 - mae: 0.3478 - mse: 0.2679 - pearson_correlation: 3.3248e-16 - r2_keras: -77.8644 - rmse: 0.8524 - sae: 1853.9703 - sse: 2106.9661 - val_huber_loss: 0.0971 - val_loss: 0.2449 - val_mae: 0.3712 - val_mse: 0.1944 - val_pearson_correlation: 2.0729e-16 - val_r2_keras: -39.5569 - val_rmse: 1.0371 - val_sae: 378.5152 - val_sse: 568.9371 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1001 - loss: 0.2479 - mae: 0.3201 - mse: 0.2173 - pearson_correlation: -7.6002e-17 - r2_keras: -90.8138 - rmse: 0.8338 - sae: 2528.7263 - sse: 2847.9478\n","Epoch 74: val_loss did not improve from 0.24492\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1316 - loss: 0.2671 - mae: 0.3465 - mse: 0.2666 - pearson_correlation: 3.4464e-17 - r2_keras: -77.7452 - rmse: 0.8516 - sae: 1852.9951 - sse: 2104.3298 - val_huber_loss: 0.0972 - val_loss: 0.2450 - val_mae: 0.3715 - val_mse: 0.1945 - val_pearson_correlation: 1.7627e-16 - val_r2_keras: -39.3846 - val_rmse: 1.0349 - val_sae: 377.7896 - val_sse: 566.5197 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0998 - loss: 0.2476 - mae: 0.3195 - mse: 0.2166 - pearson_correlation: -1.0114e-15 - r2_keras: -90.6174 - rmse: 0.8330 - sae: 2526.5491 - sse: 2841.8584\n","Epoch 75: val_loss did not improve from 0.24492\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1310 - loss: 0.2666 - mae: 0.3456 - mse: 0.2654 - pearson_correlation: -7.0687e-16 - r2_keras: -77.5523 - rmse: 0.8505 - sae: 1851.3840 - sse: 2099.5425 - val_huber_loss: 0.0972 - val_loss: 0.2450 - val_mae: 0.3717 - val_mse: 0.1945 - val_pearson_correlation: 3.5398e-16 - val_r2_keras: -39.2474 - val_rmse: 1.0331 - val_sae: 377.2419 - val_sse: 564.5956 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0994 - loss: 0.2472 - mae: 0.3185 - mse: 0.2158 - pearson_correlation: -2.6051e-16 - r2_keras: -90.6051 - rmse: 0.8329 - sae: 2525.9841 - sse: 2841.4753\n","Epoch 76: val_loss improved from 0.24492 to 0.24457, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1304 - loss: 0.2661 - mae: 0.3444 - mse: 0.2641 - pearson_correlation: -1.6180e-16 - r2_keras: -77.4991 - rmse: 0.8501 - sae: 1850.9181 - sse: 2098.7598 - val_huber_loss: 0.0967 - val_loss: 0.2446 - val_mae: 0.3702 - val_mse: 0.1937 - val_pearson_correlation: 2.8689e-16 - val_r2_keras: -39.0141 - val_rmse: 1.0301 - val_sae: 375.8908 - val_sse: 561.3226 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0991 - loss: 0.2469 - mae: 0.3178 - mse: 0.2152 - pearson_correlation: 8.8979e-16 - r2_keras: -90.4569 - rmse: 0.8322 - sae: 2524.3030 - sse: 2836.8789\n","Epoch 77: val_loss did not improve from 0.24457\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1298 - loss: 0.2656 - mae: 0.3435 - mse: 0.2629 - pearson_correlation: 3.9820e-16 - r2_keras: -77.3417 - rmse: 0.8491 - sae: 1849.6549 - sse: 2095.0085 - val_huber_loss: 0.0968 - val_loss: 0.2446 - val_mae: 0.3704 - val_mse: 0.1938 - val_pearson_correlation: 3.8785e-16 - val_r2_keras: -38.8891 - val_rmse: 1.0285 - val_sae: 375.4029 - val_sse: 559.5691 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0988 - loss: 0.2466 - mae: 0.3168 - mse: 0.2145 - pearson_correlation: 1.7686e-16 - r2_keras: -90.4711 - rmse: 0.8323 - sae: 2524.0630 - sse: 2837.3184\n","Epoch 78: val_loss improved from 0.24457 to 0.24414, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1292 - loss: 0.2651 - mae: 0.3424 - mse: 0.2617 - pearson_correlation: 9.9976e-17 - r2_keras: -77.3086 - rmse: 0.8488 - sae: 1849.4286 - sse: 2094.8020 - val_huber_loss: 0.0963 - val_loss: 0.2441 - val_mae: 0.3687 - val_mse: 0.1928 - val_pearson_correlation: -7.2506e-17 - val_r2_keras: -38.6380 - val_rmse: 1.0252 - val_sae: 373.9377 - val_sse: 556.0466 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0985 - loss: 0.2463 - mae: 0.3160 - mse: 0.2139 - pearson_correlation: 1.2238e-16 - r2_keras: -90.3285 - rmse: 0.8316 - sae: 2522.4849 - sse: 2832.8970\n","Epoch 79: val_loss improved from 0.24414 to 0.24411, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.1286 - loss: 0.2647 - mae: 0.3414 - mse: 0.2604 - pearson_correlation: 1.1158e-16 - r2_keras: -77.1529 - rmse: 0.8479 - sae: 1848.2515 - sse: 2091.1431 - val_huber_loss: 0.0963 - val_loss: 0.2441 - val_mae: 0.3684 - val_mse: 0.1927 - val_pearson_correlation: -3.0313e-16 - val_r2_keras: -38.4791 - val_rmse: 1.0232 - val_sae: 373.1729 - val_sse: 553.8171 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0982 - loss: 0.2460 - mae: 0.3151 - mse: 0.2132 - pearson_correlation: 4.1778e-17 - r2_keras: -90.2532 - rmse: 0.8313 - sae: 2521.5085 - sse: 2830.5586\n","Epoch 80: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1280 - loss: 0.2642 - mae: 0.3404 - mse: 0.2592 - pearson_correlation: 6.1821e-17 - r2_keras: -77.0479 - rmse: 0.8472 - sae: 1847.4830 - sse: 2088.9417 - val_huber_loss: 0.0967 - val_loss: 0.2445 - val_mae: 0.3699 - val_mse: 0.1936 - val_pearson_correlation: 3.5563e-16 - val_r2_keras: -38.4150 - val_rmse: 1.0224 - val_sae: 373.2007 - val_sse: 552.9183 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0978 - loss: 0.2457 - mae: 0.3144 - mse: 0.2126 - pearson_correlation: 5.7986e-16 - r2_keras: -90.2475 - rmse: 0.8313 - sae: 2520.8345 - sse: 2830.3835\n","Epoch 81: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1274 - loss: 0.2637 - mae: 0.3394 - mse: 0.2580 - pearson_correlation: 2.8483e-16 - r2_keras: -77.0037 - rmse: 0.8468 - sae: 1847.0142 - sse: 2088.3511 - val_huber_loss: 0.0965 - val_loss: 0.2443 - val_mae: 0.3684 - val_mse: 0.1931 - val_pearson_correlation: 9.4837e-18 - val_r2_keras: -38.1886 - val_rmse: 1.0194 - val_sae: 371.8449 - val_sse: 549.7416 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0976 - loss: 0.2454 - mae: 0.3137 - mse: 0.2120 - pearson_correlation: 8.1416e-17 - r2_keras: -90.0519 - rmse: 0.8304 - sae: 2519.2178 - sse: 2824.3169\n","Epoch 82: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1268 - loss: 0.2632 - mae: 0.3385 - mse: 0.2567 - pearson_correlation: -1.4124e-17 - r2_keras: -76.8072 - rmse: 0.8457 - sae: 1845.7544 - sse: 2083.5308 - val_huber_loss: 0.0968 - val_loss: 0.2446 - val_mae: 0.3690 - val_mse: 0.1938 - val_pearson_correlation: -1.2382e-16 - val_r2_keras: -38.0506 - val_rmse: 1.0176 - val_sae: 371.2800 - val_sse: 547.8061 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0972 - loss: 0.2451 - mae: 0.3130 - mse: 0.2113 - pearson_correlation: -6.5171e-16 - r2_keras: -89.9185 - rmse: 0.8298 - sae: 2517.5508 - sse: 2820.1782\n","Epoch 83: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1261 - loss: 0.2626 - mae: 0.3377 - mse: 0.2554 - pearson_correlation: -3.4319e-16 - r2_keras: -76.6548 - rmse: 0.8447 - sae: 1844.4514 - sse: 2080.0273 - val_huber_loss: 0.0969 - val_loss: 0.2447 - val_mae: 0.3691 - val_mse: 0.1940 - val_pearson_correlation: 5.0232e-17 - val_r2_keras: -37.9055 - val_rmse: 1.0157 - val_sae: 370.6098 - val_sse: 545.7700 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0968 - loss: 0.2447 - mae: 0.3121 - mse: 0.2104 - pearson_correlation: -2.1317e-16 - r2_keras: -89.9092 - rmse: 0.8297 - sae: 2516.8677 - sse: 2819.8887\n","Epoch 84: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1255 - loss: 0.2621 - mae: 0.3366 - mse: 0.2540 - pearson_correlation: -7.5795e-17 - r2_keras: -76.5914 - rmse: 0.8442 - sae: 1843.8716 - sse: 2079.1638 - val_huber_loss: 0.0968 - val_loss: 0.2446 - val_mae: 0.3683 - val_mse: 0.1937 - val_pearson_correlation: -1.0458e-16 - val_r2_keras: -37.7393 - val_rmse: 1.0136 - val_sae: 369.7849 - val_sse: 543.4387 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0965 - loss: 0.2443 - mae: 0.3116 - mse: 0.2098 - pearson_correlation: -1.8363e-16 - r2_keras: -89.8381 - rmse: 0.8294 - sae: 2515.5566 - sse: 2817.6831\n","Epoch 85: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1248 - loss: 0.2616 - mae: 0.3358 - mse: 0.2528 - pearson_correlation: -1.8368e-16 - r2_keras: -76.4997 - rmse: 0.8436 - sae: 1842.9048 - sse: 2077.1738 - val_huber_loss: 0.0967 - val_loss: 0.2445 - val_mae: 0.3677 - val_mse: 0.1935 - val_pearson_correlation: 8.4614e-17 - val_r2_keras: -37.5664 - val_rmse: 1.0113 - val_sae: 368.9585 - val_sse: 541.0143 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0962 - loss: 0.2440 - mae: 0.3109 - mse: 0.2093 - pearson_correlation: -6.2071e-17 - r2_keras: -89.8472 - rmse: 0.8294 - sae: 2514.7451 - sse: 2817.9675\n","Epoch 86: val_loss did not improve from 0.24411\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1243 - loss: 0.2611 - mae: 0.3350 - mse: 0.2518 - pearson_correlation: -1.8231e-16 - r2_keras: -76.4548 - rmse: 0.8432 - sae: 1842.2491 - sse: 2076.7649 - val_huber_loss: 0.0964 - val_loss: 0.2442 - val_mae: 0.3662 - val_mse: 0.1929 - val_pearson_correlation: -3.3457e-16 - val_r2_keras: -37.3620 - val_rmse: 1.0086 - val_sae: 367.7715 - val_sse: 538.1458 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0959 - loss: 0.2437 - mae: 0.3104 - mse: 0.2086 - pearson_correlation: -4.8597e-16 - r2_keras: -89.7194 - rmse: 0.8289 - sae: 2513.4771 - sse: 2814.0029\n","Epoch 87: val_loss improved from 0.24411 to 0.24382, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1237 - loss: 0.2606 - mae: 0.3342 - mse: 0.2505 - pearson_correlation: -2.3538e-16 - r2_keras: -76.3091 - rmse: 0.8423 - sae: 1841.2300 - sse: 2073.4124 - val_huber_loss: 0.0960 - val_loss: 0.2438 - val_mae: 0.3653 - val_mse: 0.1922 - val_pearson_correlation: -9.7704e-17 - val_r2_keras: -37.2473 - val_rmse: 1.0071 - val_sae: 367.1317 - val_sse: 536.5372 - learning_rate: 1.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0957 - loss: 0.2435 - mae: 0.3098 - mse: 0.2082 - pearson_correlation: 1.1753e-16 - r2_keras: -89.6626 - rmse: 0.8286 - sae: 2512.1702 - sse: 2812.2395\n","Epoch 88: val_loss improved from 0.24382 to 0.24368, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1232 - loss: 0.2602 - mae: 0.3334 - mse: 0.2496 - pearson_correlation: 1.2873e-16 - r2_keras: -76.2348 - rmse: 0.8418 - sae: 1840.2771 - sse: 2071.8096 - val_huber_loss: 0.0959 - val_loss: 0.2437 - val_mae: 0.3644 - val_mse: 0.1919 - val_pearson_correlation: -1.0057e-16 - val_r2_keras: -37.1251 - val_rmse: 1.0055 - val_sae: 366.4674 - val_sse: 534.8226 - learning_rate: 1.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0954 - loss: 0.2432 - mae: 0.3089 - mse: 0.2075 - pearson_correlation: -6.8733e-17 - r2_keras: -89.7023 - rmse: 0.8288 - sae: 2512.3225 - sse: 2813.4712\n","Epoch 89: val_loss improved from 0.24368 to 0.24356, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.1226 - loss: 0.2597 - mae: 0.3324 - mse: 0.2484 - pearson_correlation: 7.8048e-18 - r2_keras: -76.2168 - rmse: 0.8415 - sae: 1840.2684 - sse: 2072.1089 - val_huber_loss: 0.0958 - val_loss: 0.2436 - val_mae: 0.3636 - val_mse: 0.1917 - val_pearson_correlation: 1.7982e-16 - val_r2_keras: -36.9975 - val_rmse: 1.0038 - val_sae: 365.7978 - val_sse: 533.0330 - learning_rate: 1.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0950 - loss: 0.2428 - mae: 0.3085 - mse: 0.2068 - pearson_correlation: -9.7691e-17 - r2_keras: -89.6301 - rmse: 0.8285 - sae: 2511.4346 - sse: 2811.2339\n","Epoch 90: val_loss improved from 0.24356 to 0.24345, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.1221 - loss: 0.2593 - mae: 0.3318 - mse: 0.2473 - pearson_correlation: 6.2993e-17 - r2_keras: -76.1132 - rmse: 0.8408 - sae: 1839.5470 - sse: 2069.9670 - val_huber_loss: 0.0956 - val_loss: 0.2434 - val_mae: 0.3633 - val_mse: 0.1914 - val_pearson_correlation: -4.2986e-16 - val_r2_keras: -36.9170 - val_rmse: 1.0027 - val_sae: 365.4630 - val_sse: 531.9038 - learning_rate: 1.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0948 - loss: 0.2426 - mae: 0.3078 - mse: 0.2064 - pearson_correlation: 1.5832e-16 - r2_keras: -89.6585 - rmse: 0.8286 - sae: 2510.6938 - sse: 2812.1133\n","Epoch 91: val_loss improved from 0.24345 to 0.24323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - huber_loss: 0.1216 - loss: 0.2589 - mae: 0.3309 - mse: 0.2464 - pearson_correlation: 2.2500e-16 - r2_keras: -76.1033 - rmse: 0.8407 - sae: 1839.0070 - sse: 2070.2148 - val_huber_loss: 0.0954 - val_loss: 0.2432 - val_mae: 0.3621 - val_mse: 0.1910 - val_pearson_correlation: -2.3080e-16 - val_r2_keras: -36.7808 - val_rmse: 1.0009 - val_sae: 364.6809 - val_sse: 529.9932 - learning_rate: 1.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0945 - loss: 0.2423 - mae: 0.3074 - mse: 0.2059 - pearson_correlation: -1.9429e-16 - r2_keras: -89.5838 - rmse: 0.8282 - sae: 2509.6855 - sse: 2809.7959\n","Epoch 92: val_loss improved from 0.24323 to 0.24306, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1210 - loss: 0.2585 - mae: 0.3303 - mse: 0.2454 - pearson_correlation: -2.1489e-16 - r2_keras: -76.0135 - rmse: 0.8401 - sae: 1838.2344 - sse: 2068.2012 - val_huber_loss: 0.0953 - val_loss: 0.2431 - val_mae: 0.3606 - val_mse: 0.1906 - val_pearson_correlation: 1.5694e-16 - val_r2_keras: -36.6723 - val_rmse: 0.9995 - val_sae: 364.0051 - val_sse: 528.4714 - learning_rate: 1.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0942 - loss: 0.2420 - mae: 0.3067 - mse: 0.2053 - pearson_correlation: 1.2440e-16 - r2_keras: -89.6361 - rmse: 0.8285 - sae: 2509.9712 - sse: 2811.4185\n","Epoch 93: val_loss did not improve from 0.24306\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1206 - loss: 0.2581 - mae: 0.3294 - mse: 0.2444 - pearson_correlation: 4.4848e-17 - r2_keras: -76.0117 - rmse: 0.8399 - sae: 1838.3448 - sse: 2068.8521 - val_huber_loss: 0.0953 - val_loss: 0.2431 - val_mae: 0.3600 - val_mse: 0.1906 - val_pearson_correlation: 1.7252e-16 - val_r2_keras: -36.5649 - val_rmse: 0.9981 - val_sae: 363.4972 - val_sse: 526.9639 - learning_rate: 1.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0940 - loss: 0.2418 - mae: 0.3063 - mse: 0.2047 - pearson_correlation: -4.9649e-16 - r2_keras: -89.5644 - rmse: 0.8282 - sae: 2509.0491 - sse: 2809.1948\n","Epoch 94: val_loss did not improve from 0.24306\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1201 - loss: 0.2576 - mae: 0.3288 - mse: 0.2434 - pearson_correlation: -2.9909e-16 - r2_keras: -75.9224 - rmse: 0.8394 - sae: 1837.6077 - sse: 2066.8831 - val_huber_loss: 0.0955 - val_loss: 0.2433 - val_mae: 0.3604 - val_mse: 0.1910 - val_pearson_correlation: 1.4278e-16 - val_r2_keras: -36.5181 - val_rmse: 0.9975 - val_sae: 363.3874 - val_sse: 526.3082 - learning_rate: 1.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0937 - loss: 0.2415 - mae: 0.3059 - mse: 0.2042 - pearson_correlation: 2.4143e-16 - r2_keras: -89.5113 - rmse: 0.8279 - sae: 2508.2258 - sse: 2807.5483\n","Epoch 95: val_loss improved from 0.24306 to 0.24300, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - huber_loss: 0.1195 - loss: 0.2572 - mae: 0.3282 - mse: 0.2424 - pearson_correlation: 1.4978e-17 - r2_keras: -75.8489 - rmse: 0.8389 - sae: 1837.0131 - sse: 2065.3379 - val_huber_loss: 0.0952 - val_loss: 0.2430 - val_mae: 0.3581 - val_mse: 0.1905 - val_pearson_correlation: 2.9710e-16 - val_r2_keras: -36.3683 - val_rmse: 0.9955 - val_sae: 362.4703 - val_sse: 524.2068 - learning_rate: 1.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0935 - loss: 0.2413 - mae: 0.3054 - mse: 0.2036 - pearson_correlation: 1.7144e-16 - r2_keras: -89.5529 - rmse: 0.8281 - sae: 2508.6963 - sse: 2808.8379\n","Epoch 96: val_loss improved from 0.24300 to 0.24294, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1190 - loss: 0.2568 - mae: 0.3275 - mse: 0.2413 - pearson_correlation: 1.4005e-16 - r2_keras: -75.8355 - rmse: 0.8386 - sae: 1837.2318 - sse: 2065.7163 - val_huber_loss: 0.0951 - val_loss: 0.2429 - val_mae: 0.3570 - val_mse: 0.1904 - val_pearson_correlation: 2.2750e-17 - val_r2_keras: -36.2570 - val_rmse: 0.9940 - val_sae: 361.9311 - val_sse: 522.6456 - learning_rate: 1.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0933 - loss: 0.2411 - mae: 0.3052 - mse: 0.2033 - pearson_correlation: 4.3015e-16 - r2_keras: -89.4799 - rmse: 0.8278 - sae: 2507.6743 - sse: 2806.5720\n","Epoch 97: val_loss improved from 0.24294 to 0.24291, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1184 - loss: 0.2564 - mae: 0.3270 - mse: 0.2403 - pearson_correlation: 1.9564e-16 - r2_keras: -75.7381 - rmse: 0.8380 - sae: 1836.4264 - sse: 2063.6338 - val_huber_loss: 0.0951 - val_loss: 0.2429 - val_mae: 0.3559 - val_mse: 0.1904 - val_pearson_correlation: 1.5225e-17 - val_r2_keras: -36.1478 - val_rmse: 0.9925 - val_sae: 361.3893 - val_sse: 521.1139 - learning_rate: 1.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0931 - loss: 0.2409 - mae: 0.3050 - mse: 0.2030 - pearson_correlation: 7.4368e-17 - r2_keras: -89.4137 - rmse: 0.8275 - sae: 2506.9341 - sse: 2804.5210\n","Epoch 98: val_loss improved from 0.24291 to 0.24287, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.1179 - loss: 0.2560 - mae: 0.3264 - mse: 0.2394 - pearson_correlation: 7.7783e-17 - r2_keras: -75.6464 - rmse: 0.8374 - sae: 1835.8217 - sse: 2061.7083 - val_huber_loss: 0.0951 - val_loss: 0.2429 - val_mae: 0.3545 - val_mse: 0.1903 - val_pearson_correlation: -5.8561e-17 - val_r2_keras: -36.0529 - val_rmse: 0.9912 - val_sae: 360.8861 - val_sse: 519.7821 - learning_rate: 1.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0929 - loss: 0.2407 - mae: 0.3045 - mse: 0.2026 - pearson_correlation: 3.6753e-16 - r2_keras: -89.4445 - rmse: 0.8276 - sae: 2507.2681 - sse: 2805.4751\n","Epoch 99: val_loss did not improve from 0.24287\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1173 - loss: 0.2556 - mae: 0.3256 - mse: 0.2383 - pearson_correlation: 1.5153e-16 - r2_keras: -75.6317 - rmse: 0.8372 - sae: 1836.0187 - sse: 2061.9309 - val_huber_loss: 0.0952 - val_loss: 0.2430 - val_mae: 0.3534 - val_mse: 0.1904 - val_pearson_correlation: -2.3267e-16 - val_r2_keras: -35.9334 - val_rmse: 0.9896 - val_sae: 360.2918 - val_sse: 518.1057 - learning_rate: 1.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0928 - loss: 0.2406 - mae: 0.3043 - mse: 0.2023 - pearson_correlation: -2.1062e-16 - r2_keras: -89.3906 - rmse: 0.8274 - sae: 2506.8613 - sse: 2803.8032\n","Epoch 100: val_loss did not improve from 0.24287\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1168 - loss: 0.2552 - mae: 0.3251 - mse: 0.2374 - pearson_correlation: -1.5689e-16 - r2_keras: -75.5457 - rmse: 0.8366 - sae: 1835.6526 - sse: 2060.2297 - val_huber_loss: 0.0952 - val_loss: 0.2430 - val_mae: 0.3525 - val_mse: 0.1906 - val_pearson_correlation: -2.2316e-16 - val_r2_keras: -35.8435 - val_rmse: 0.9884 - val_sae: 359.9026 - val_sse: 516.8451 - learning_rate: 1.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0926 - loss: 0.2404 - mae: 0.3038 - mse: 0.2020 - pearson_correlation: 2.9036e-16 - r2_keras: -89.3482 - rmse: 0.8272 - sae: 2506.3030 - sse: 2802.4883\n","Epoch 101: val_loss improved from 0.24287 to 0.24210, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - huber_loss: 0.1163 - loss: 0.2548 - mae: 0.3243 - mse: 0.2364 - pearson_correlation: 1.2543e-16 - r2_keras: -75.4811 - rmse: 0.8361 - sae: 1835.2521 - sse: 2058.9270 - val_huber_loss: 0.0943 - val_loss: 0.2421 - val_mae: 0.3455 - val_mse: 0.1887 - val_pearson_correlation: -3.0127e-16 - val_r2_keras: -35.7332 - val_rmse: 0.9870 - val_sae: 358.8085 - val_sse: 515.2968 - learning_rate: 1.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0926 - loss: 0.2403 - mae: 0.3025 - mse: 0.2018 - pearson_correlation: 4.2791e-16 - r2_keras: -89.6012 - rmse: 0.8283 - sae: 2509.2563 - sse: 2810.3364\n","Epoch 102: val_loss improved from 0.24210 to 0.24177, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1151 - loss: 0.2540 - mae: 0.3222 - mse: 0.2346 - pearson_correlation: 3.2158e-16 - r2_keras: -75.6267 - rmse: 0.8367 - sae: 1837.1260 - sse: 2063.8877 - val_huber_loss: 0.0940 - val_loss: 0.2418 - val_mae: 0.3418 - val_mse: 0.1881 - val_pearson_correlation: 2.3238e-17 - val_r2_keras: -35.6547 - val_rmse: 0.9859 - val_sae: 358.4328 - val_sse: 514.1956 - learning_rate: 1.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0925 - loss: 0.2402 - mae: 0.3022 - mse: 0.2016 - pearson_correlation: -2.3465e-16 - r2_keras: -89.6897 - rmse: 0.8287 - sae: 2510.4531 - sse: 2813.0803\n","Epoch 103: val_loss improved from 0.24177 to 0.24165, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1139 - loss: 0.2533 - mae: 0.3208 - mse: 0.2329 - pearson_correlation: 2.9955e-17 - r2_keras: -75.6678 - rmse: 0.8368 - sae: 1837.8040 - sse: 2065.5073 - val_huber_loss: 0.0939 - val_loss: 0.2417 - val_mae: 0.3389 - val_mse: 0.1878 - val_pearson_correlation: 4.1363e-17 - val_r2_keras: -35.6213 - val_rmse: 0.9855 - val_sae: 358.4498 - val_sse: 513.7277 - learning_rate: 1.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0920 - loss: 0.2398 - mae: 0.3025 - mse: 0.2006 - pearson_correlation: -7.7157e-17 - r2_keras: -90.0058 - rmse: 0.8302 - sae: 2514.6694 - sse: 2822.8857\n","Epoch 104: val_loss improved from 0.24165 to 0.24124, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.1125 - loss: 0.2522 - mae: 0.3200 - mse: 0.2305 - pearson_correlation: -1.8219e-16 - r2_keras: -75.8728 - rmse: 0.8377 - sae: 1840.5778 - sse: 2071.9775 - val_huber_loss: 0.0935 - val_loss: 0.2412 - val_mae: 0.3368 - val_mse: 0.1870 - val_pearson_correlation: 7.2527e-17 - val_r2_keras: -35.5549 - val_rmse: 0.9846 - val_sae: 358.5960 - val_sse: 512.7958 - learning_rate: 1.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0918 - loss: 0.2396 - mae: 0.3024 - mse: 0.2002 - pearson_correlation: 7.9360e-17 - r2_keras: -90.1615 - rmse: 0.8309 - sae: 2518.2607 - sse: 2827.7156\n","Epoch 105: val_loss improved from 0.24124 to 0.24083, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.1114 - loss: 0.2515 - mae: 0.3187 - mse: 0.2288 - pearson_correlation: -2.1828e-17 - r2_keras: -75.9911 - rmse: 0.8383 - sae: 1843.0187 - sse: 2075.3665 - val_huber_loss: 0.0931 - val_loss: 0.2408 - val_mae: 0.3360 - val_mse: 0.1861 - val_pearson_correlation: -1.3481e-16 - val_r2_keras: -35.5283 - val_rmse: 0.9842 - val_sae: 358.8864 - val_sse: 512.4236 - learning_rate: 1.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0917 - loss: 0.2395 - mae: 0.3023 - mse: 0.1998 - pearson_correlation: 1.4992e-16 - r2_keras: -90.3139 - rmse: 0.8316 - sae: 2521.4775 - sse: 2832.4429\n","Epoch 106: val_loss did not improve from 0.24083\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1106 - loss: 0.2510 - mae: 0.3177 - mse: 0.2274 - pearson_correlation: 5.9956e-17 - r2_keras: -76.0991 - rmse: 0.8388 - sae: 1845.2019 - sse: 2078.5933 - val_huber_loss: 0.0934 - val_loss: 0.2412 - val_mae: 0.3390 - val_mse: 0.1868 - val_pearson_correlation: -1.7086e-16 - val_r2_keras: -35.5798 - val_rmse: 0.9849 - val_sae: 359.6645 - val_sse: 513.1458 - learning_rate: 1.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0915 - loss: 0.2393 - mae: 0.3025 - mse: 0.1993 - pearson_correlation: -3.6828e-16 - r2_keras: -90.5508 - rmse: 0.8327 - sae: 2525.1763 - sse: 2839.7910\n","Epoch 107: val_loss did not improve from 0.24083\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1099 - loss: 0.2505 - mae: 0.3171 - mse: 0.2261 - pearson_correlation: -1.1531e-16 - r2_keras: -76.2675 - rmse: 0.8396 - sae: 1847.7673 - sse: 2083.6152 - val_huber_loss: 0.0931 - val_loss: 0.2409 - val_mae: 0.3379 - val_mse: 0.1863 - val_pearson_correlation: -1.3989e-16 - val_r2_keras: -35.5559 - val_rmse: 0.9846 - val_sae: 359.9327 - val_sse: 512.8099 - learning_rate: 1.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0914 - loss: 0.2392 - mae: 0.3020 - mse: 0.1990 - pearson_correlation: -3.6852e-16 - r2_keras: -90.6129 - rmse: 0.8329 - sae: 2526.6460 - sse: 2841.7173\n","Epoch 108: val_loss improved from 0.24083 to 0.24045, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.1091 - loss: 0.2499 - mae: 0.3157 - mse: 0.2247 - pearson_correlation: -2.5187e-16 - r2_keras: -76.3260 - rmse: 0.8400 - sae: 1848.8132 - sse: 2085.0996 - val_huber_loss: 0.0927 - val_loss: 0.2405 - val_mae: 0.3357 - val_mse: 0.1854 - val_pearson_correlation: 2.5894e-18 - val_r2_keras: -35.5650 - val_rmse: 0.9847 - val_sae: 360.4275 - val_sse: 512.9374 - learning_rate: 1.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0913 - loss: 0.2391 - mae: 0.3011 - mse: 0.1987 - pearson_correlation: 3.4695e-16 - r2_keras: -90.8506 - rmse: 0.8340 - sae: 2530.0220 - sse: 2849.0898\n","Epoch 109: val_loss did not improve from 0.24045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1081 - loss: 0.2493 - mae: 0.3139 - mse: 0.2231 - pearson_correlation: 3.0316e-16 - r2_keras: -76.5167 - rmse: 0.8410 - sae: 1851.2347 - sse: 2090.3938 - val_huber_loss: 0.0928 - val_loss: 0.2406 - val_mae: 0.3367 - val_mse: 0.1856 - val_pearson_correlation: 2.1214e-16 - val_r2_keras: -35.5904 - val_rmse: 0.9850 - val_sae: 361.0603 - val_sse: 513.2938 - learning_rate: 1.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0911 - loss: 0.2389 - mae: 0.3010 - mse: 0.1982 - pearson_correlation: -4.3483e-17 - r2_keras: -91.0267 - rmse: 0.8348 - sae: 2532.6318 - sse: 2854.5540\n","Epoch 110: val_loss improved from 0.24045 to 0.24035, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1072 - loss: 0.2487 - mae: 0.3126 - mse: 0.2217 - pearson_correlation: 1.8174e-18 - r2_keras: -76.6729 - rmse: 0.8418 - sae: 1853.1974 - sse: 2094.4900 - val_huber_loss: 0.0926 - val_loss: 0.2404 - val_mae: 0.3350 - val_mse: 0.1852 - val_pearson_correlation: 9.5717e-17 - val_r2_keras: -35.5849 - val_rmse: 0.9850 - val_sae: 361.4818 - val_sse: 513.2173 - learning_rate: 1.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0910 - loss: 0.2388 - mae: 0.2999 - mse: 0.1978 - pearson_correlation: -1.1434e-16 - r2_keras: -91.1953 - rmse: 0.8356 - sae: 2534.9043 - sse: 2859.7842\n","Epoch 111: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.1065 - loss: 0.2482 - mae: 0.3109 - mse: 0.2204 - pearson_correlation: -3.1024e-17 - r2_keras: -76.8143 - rmse: 0.8426 - sae: 1854.8934 - sse: 2098.3179 - val_huber_loss: 0.0928 - val_loss: 0.2406 - val_mae: 0.3362 - val_mse: 0.1856 - val_pearson_correlation: 1.8864e-16 - val_r2_keras: -35.6170 - val_rmse: 0.9854 - val_sae: 362.0904 - val_sse: 513.6678 - learning_rate: 1.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0908 - loss: 0.2386 - mae: 0.2995 - mse: 0.1974 - pearson_correlation: 6.0763e-16 - r2_keras: -91.3675 - rmse: 0.8364 - sae: 2537.1343 - sse: 2865.1240\n","Epoch 112: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.1058 - loss: 0.2477 - mae: 0.3098 - mse: 0.2192 - pearson_correlation: 3.6295e-16 - r2_keras: -76.9629 - rmse: 0.8434 - sae: 1856.6163 - sse: 2102.2744 - val_huber_loss: 0.0927 - val_loss: 0.2405 - val_mae: 0.3347 - val_mse: 0.1855 - val_pearson_correlation: -2.5073e-16 - val_r2_keras: -35.6027 - val_rmse: 0.9852 - val_sae: 362.3517 - val_sse: 513.4661 - learning_rate: 1.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0907 - loss: 0.2385 - mae: 0.2987 - mse: 0.1970 - pearson_correlation: 6.9724e-16 - r2_keras: -91.4346 - rmse: 0.8367 - sae: 2538.1453 - sse: 2867.2068\n","Epoch 113: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1052 - loss: 0.2473 - mae: 0.3084 - mse: 0.2180 - pearson_correlation: 4.8228e-16 - r2_keras: -77.0379 - rmse: 0.8439 - sae: 1857.4965 - sse: 2104.0173 - val_huber_loss: 0.0928 - val_loss: 0.2406 - val_mae: 0.3346 - val_mse: 0.1857 - val_pearson_correlation: -7.7463e-17 - val_r2_keras: -35.6314 - val_rmse: 0.9856 - val_sae: 362.8524 - val_sse: 513.8687 - learning_rate: 1.0000e-05\n","Epoch 114/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0905 - loss: 0.2383 - mae: 0.2982 - mse: 0.1965 - pearson_correlation: 3.1321e-16 - r2_keras: -91.6248 - rmse: 0.8375 - sae: 2540.5713 - sse: 2873.1045\n","Epoch 114: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1044 - loss: 0.2467 - mae: 0.3070 - mse: 0.2167 - pearson_correlation: 3.5594e-16 - r2_keras: -77.2107 - rmse: 0.8449 - sae: 1859.3787 - sse: 2108.4897 - val_huber_loss: 0.0930 - val_loss: 0.2407 - val_mae: 0.3344 - val_mse: 0.1859 - val_pearson_correlation: -4.9021e-17 - val_r2_keras: -35.6514 - val_rmse: 0.9859 - val_sae: 363.2957 - val_sse: 514.1501 - learning_rate: 1.0000e-05\n","Epoch 115/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0904 - loss: 0.2382 - mae: 0.2978 - mse: 0.1962 - pearson_correlation: 1.1484e-17 - r2_keras: -91.7603 - rmse: 0.8381 - sae: 2542.2131 - sse: 2877.3093\n","Epoch 115: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1039 - loss: 0.2464 - mae: 0.3060 - mse: 0.2157 - pearson_correlation: -4.7973e-17 - r2_keras: -77.3241 - rmse: 0.8455 - sae: 1860.6630 - sse: 2111.5627 - val_huber_loss: 0.0933 - val_loss: 0.2410 - val_mae: 0.3348 - val_mse: 0.1866 - val_pearson_correlation: -1.6258e-16 - val_r2_keras: -35.6453 - val_rmse: 0.9858 - val_sae: 363.5373 - val_sse: 514.0643 - learning_rate: 1.0000e-05\n","Epoch 116/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0898 - loss: 0.2375 - mae: 0.2965 - mse: 0.1947 - pearson_correlation: -3.8429e-16 - r2_keras: -91.7194 - rmse: 0.8379 - sae: 2541.3594 - sse: 2876.0403\n","Epoch 116: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1030 - loss: 0.2456 - mae: 0.3041 - mse: 0.2138 - pearson_correlation: -2.0129e-16 - r2_keras: -77.3329 - rmse: 0.8457 - sae: 1860.3461 - sse: 2111.1404 - val_huber_loss: 0.0933 - val_loss: 0.2410 - val_mae: 0.3326 - val_mse: 0.1865 - val_pearson_correlation: -3.3560e-17 - val_r2_keras: -35.6284 - val_rmse: 0.9856 - val_sae: 363.7863 - val_sse: 513.8271 - learning_rate: 1.0000e-05\n","Epoch 117/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0897 - loss: 0.2374 - mae: 0.2959 - mse: 0.1943 - pearson_correlation: -7.1878e-17 - r2_keras: -91.8039 - rmse: 0.8383 - sae: 2542.5386 - sse: 2878.6594\n","Epoch 117: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1025 - loss: 0.2453 - mae: 0.3033 - mse: 0.2128 - pearson_correlation: 6.9048e-17 - r2_keras: -77.3923 - rmse: 0.8459 - sae: 1861.2393 - sse: 2112.9229 - val_huber_loss: 0.0939 - val_loss: 0.2416 - val_mae: 0.3348 - val_mse: 0.1878 - val_pearson_correlation: 2.5808e-16 - val_r2_keras: -35.6422 - val_rmse: 0.9857 - val_sae: 364.1165 - val_sse: 514.0201 - learning_rate: 1.0000e-05\n","Epoch 118/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0891 - loss: 0.2369 - mae: 0.2951 - mse: 0.1931 - pearson_correlation: 2.3186e-16 - r2_keras: -91.7924 - rmse: 0.8383 - sae: 2541.7532 - sse: 2878.3047\n","Epoch 118: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.1017 - loss: 0.2445 - mae: 0.3019 - mse: 0.2111 - pearson_correlation: 1.6533e-16 - r2_keras: -77.4333 - rmse: 0.8463 - sae: 1861.0925 - sse: 2113.2561 - val_huber_loss: 0.0941 - val_loss: 0.2419 - val_mae: 0.3344 - val_mse: 0.1882 - val_pearson_correlation: -1.5742e-16 - val_r2_keras: -35.6428 - val_rmse: 0.9857 - val_sae: 364.3823 - val_sse: 514.0289 - learning_rate: 1.0000e-05\n","Epoch 119/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0890 - loss: 0.2367 - mae: 0.2947 - mse: 0.1926 - pearson_correlation: 3.6459e-16 - r2_keras: -91.9309 - rmse: 0.8389 - sae: 2543.1929 - sse: 2882.5999\n","Epoch 119: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.1012 - loss: 0.2442 - mae: 0.3012 - mse: 0.2102 - pearson_correlation: 1.7496e-16 - r2_keras: -77.5366 - rmse: 0.8468 - sae: 1862.1538 - sse: 2116.2490 - val_huber_loss: 0.0946 - val_loss: 0.2423 - val_mae: 0.3353 - val_mse: 0.1891 - val_pearson_correlation: 7.2306e-17 - val_r2_keras: -35.6285 - val_rmse: 0.9856 - val_sae: 364.4859 - val_sse: 513.8282 - learning_rate: 1.0000e-05\n","Epoch 120/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0884 - loss: 0.2362 - mae: 0.2937 - mse: 0.1914 - pearson_correlation: -1.9876e-16 - r2_keras: -91.8882 - rmse: 0.8387 - sae: 2542.0078 - sse: 2881.2744\n","Epoch 120: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.1005 - loss: 0.2435 - mae: 0.2999 - mse: 0.2086 - pearson_correlation: -6.0777e-17 - r2_keras: -77.5431 - rmse: 0.8470 - sae: 1861.6262 - sse: 2115.7754 - val_huber_loss: 0.0948 - val_loss: 0.2426 - val_mae: 0.3348 - val_mse: 0.1897 - val_pearson_correlation: 6.7141e-17 - val_r2_keras: -35.6284 - val_rmse: 0.9856 - val_sae: 364.7008 - val_sse: 513.8278 - learning_rate: 1.0000e-05\n","Epoch 121/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0883 - loss: 0.2360 - mae: 0.2933 - mse: 0.1910 - pearson_correlation: 1.2307e-16 - r2_keras: -91.9908 - rmse: 0.8392 - sae: 2542.8003 - sse: 2884.4570\n","Epoch 121: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1001 - loss: 0.2432 - mae: 0.2992 - mse: 0.2078 - pearson_correlation: 1.0059e-16 - r2_keras: -77.6135 - rmse: 0.8473 - sae: 1862.2018 - sse: 2117.9209 - val_huber_loss: 0.0953 - val_loss: 0.2430 - val_mae: 0.3353 - val_mse: 0.1906 - val_pearson_correlation: 3.1026e-17 - val_r2_keras: -35.5959 - val_rmse: 0.9851 - val_sae: 364.6403 - val_sse: 513.3719 - learning_rate: 1.0000e-05\n","Epoch 122/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0878 - loss: 0.2355 - mae: 0.2924 - mse: 0.1900 - pearson_correlation: -1.4990e-16 - r2_keras: -91.8866 - rmse: 0.8387 - sae: 2540.9277 - sse: 2881.2256\n","Epoch 122: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0993 - loss: 0.2426 - mae: 0.2982 - mse: 0.2063 - pearson_correlation: -1.0885e-16 - r2_keras: -77.5709 - rmse: 0.8473 - sae: 1861.1979 - sse: 2116.0811 - val_huber_loss: 0.0953 - val_loss: 0.2430 - val_mae: 0.3330 - val_mse: 0.1905 - val_pearson_correlation: -4.1408e-16 - val_r2_keras: -35.5663 - val_rmse: 0.9847 - val_sae: 364.6567 - val_sse: 512.9558 - learning_rate: 1.0000e-05\n","Epoch 123/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0875 - loss: 0.2353 - mae: 0.2919 - mse: 0.1892 - pearson_correlation: 3.5536e-16 - r2_keras: -91.9916 - rmse: 0.8392 - sae: 2542.2229 - sse: 2884.4829\n","Epoch 123: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0989 - loss: 0.2422 - mae: 0.2975 - mse: 0.2053 - pearson_correlation: 8.5311e-17 - r2_keras: -77.6453 - rmse: 0.8476 - sae: 1862.1317 - sse: 2118.3042 - val_huber_loss: 0.0958 - val_loss: 0.2435 - val_mae: 0.3341 - val_mse: 0.1915 - val_pearson_correlation: 1.0880e-16 - val_r2_keras: -35.5437 - val_rmse: 0.9844 - val_sae: 364.6880 - val_sse: 512.6389 - learning_rate: 1.0000e-05\n","Epoch 124/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0870 - loss: 0.2348 - mae: 0.2913 - mse: 0.1881 - pearson_correlation: -4.0388e-16 - r2_keras: -91.9258 - rmse: 0.8389 - sae: 2540.8770 - sse: 2882.4419\n","Epoch 124: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0982 - loss: 0.2416 - mae: 0.2966 - mse: 0.2038 - pearson_correlation: -3.0065e-16 - r2_keras: -77.6161 - rmse: 0.8476 - sae: 1861.4443 - sse: 2117.1160 - val_huber_loss: 0.0961 - val_loss: 0.2439 - val_mae: 0.3336 - val_mse: 0.1923 - val_pearson_correlation: -1.6088e-16 - val_r2_keras: -35.5020 - val_rmse: 0.9839 - val_sae: 364.6578 - val_sse: 512.0539 - learning_rate: 1.0000e-05\n","Epoch 125/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0868 - loss: 0.2346 - mae: 0.2913 - mse: 0.1875 - pearson_correlation: -1.8933e-16 - r2_keras: -91.9677 - rmse: 0.8391 - sae: 2541.5591 - sse: 2883.7402\n","Epoch 125: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0977 - loss: 0.2412 - mae: 0.2962 - mse: 0.2027 - pearson_correlation: -2.7249e-16 - r2_keras: -77.6040 - rmse: 0.8473 - sae: 1861.7911 - sse: 2117.5122 - val_huber_loss: 0.0966 - val_loss: 0.2443 - val_mae: 0.3339 - val_mse: 0.1932 - val_pearson_correlation: 3.4856e-16 - val_r2_keras: -35.4381 - val_rmse: 0.9830 - val_sae: 364.3506 - val_sse: 511.1573 - learning_rate: 1.0000e-05\n","Epoch 126/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0864 - loss: 0.2342 - mae: 0.2908 - mse: 0.1865 - pearson_correlation: 4.3556e-16 - r2_keras: -91.7818 - rmse: 0.8382 - sae: 2538.8198 - sse: 2877.9763\n","Epoch 126: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0970 - loss: 0.2406 - mae: 0.2954 - mse: 0.2012 - pearson_correlation: 2.6892e-16 - r2_keras: -77.4682 - rmse: 0.8467 - sae: 1860.0847 - sse: 2113.5295 - val_huber_loss: 0.0968 - val_loss: 0.2445 - val_mae: 0.3328 - val_mse: 0.1937 - val_pearson_correlation: 2.6059e-16 - val_r2_keras: -35.3897 - val_rmse: 0.9823 - val_sae: 364.2270 - val_sse: 510.4789 - learning_rate: 1.0000e-05\n","Epoch 127/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0862 - loss: 0.2340 - mae: 0.2906 - mse: 0.1860 - pearson_correlation: 3.7262e-16 - r2_keras: -91.8066 - rmse: 0.8383 - sae: 2539.1475 - sse: 2878.7461\n","Epoch 127: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0965 - loss: 0.2402 - mae: 0.2949 - mse: 0.2003 - pearson_correlation: 2.7663e-16 - r2_keras: -77.4533 - rmse: 0.8465 - sae: 1860.2157 - sse: 2113.6738 - val_huber_loss: 0.0972 - val_loss: 0.2450 - val_mae: 0.3330 - val_mse: 0.1946 - val_pearson_correlation: -3.0818e-16 - val_r2_keras: -35.3324 - val_rmse: 0.9816 - val_sae: 363.9480 - val_sse: 509.6744 - learning_rate: 1.0000e-05\n","Epoch 128/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0859 - loss: 0.2336 - mae: 0.2900 - mse: 0.1853 - pearson_correlation: -3.2227e-16 - r2_keras: -91.6451 - rmse: 0.8376 - sae: 2536.5713 - sse: 2873.7344\n","Epoch 128: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0959 - loss: 0.2397 - mae: 0.2941 - mse: 0.1990 - pearson_correlation: -1.3691e-16 - r2_keras: -77.3469 - rmse: 0.8460 - sae: 1858.6693 - sse: 2110.3477 - val_huber_loss: 0.0972 - val_loss: 0.2449 - val_mae: 0.3307 - val_mse: 0.1945 - val_pearson_correlation: 6.2713e-17 - val_r2_keras: -35.3141 - val_rmse: 0.9813 - val_sae: 363.9812 - val_sse: 509.4177 - learning_rate: 1.0000e-05\n","Epoch 129/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0856 - loss: 0.2334 - mae: 0.2896 - mse: 0.1847 - pearson_correlation: -4.2652e-16 - r2_keras: -91.6728 - rmse: 0.8377 - sae: 2537.0093 - sse: 2874.5935\n","Epoch 129: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0954 - loss: 0.2393 - mae: 0.2935 - mse: 0.1980 - pearson_correlation: -2.7963e-16 - r2_keras: -77.3370 - rmse: 0.8458 - sae: 1858.8877 - sse: 2110.5884 - val_huber_loss: 0.0975 - val_loss: 0.2453 - val_mae: 0.3313 - val_mse: 0.1953 - val_pearson_correlation: -2.7733e-16 - val_r2_keras: -35.2810 - val_rmse: 0.9809 - val_sae: 363.8102 - val_sse: 508.9539 - learning_rate: 1.0000e-05\n","Epoch 130/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0854 - loss: 0.2331 - mae: 0.2892 - mse: 0.1839 - pearson_correlation: 2.8446e-16 - r2_keras: -91.5581 - rmse: 0.8372 - sae: 2535.1990 - sse: 2871.0356\n","Epoch 130: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0948 - loss: 0.2389 - mae: 0.2928 - mse: 0.1968 - pearson_correlation: 2.4166e-16 - r2_keras: -77.2703 - rmse: 0.8456 - sae: 1857.9012 - sse: 2108.3308 - val_huber_loss: 0.0977 - val_loss: 0.2454 - val_mae: 0.3301 - val_mse: 0.1956 - val_pearson_correlation: -2.6182e-17 - val_r2_keras: -35.2603 - val_rmse: 0.9806 - val_sae: 363.8684 - val_sse: 508.6630 - learning_rate: 1.0000e-05\n","Epoch 131/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0851 - loss: 0.2328 - mae: 0.2889 - mse: 0.1831 - pearson_correlation: 6.7613e-18 - r2_keras: -91.6489 - rmse: 0.8376 - sae: 2536.5857 - sse: 2873.8530\n","Epoch 131: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0943 - loss: 0.2384 - mae: 0.2923 - mse: 0.1956 - pearson_correlation: 7.5090e-17 - r2_keras: -77.2954 - rmse: 0.8455 - sae: 1858.7058 - sse: 2109.7930 - val_huber_loss: 0.0981 - val_loss: 0.2459 - val_mae: 0.3310 - val_mse: 0.1966 - val_pearson_correlation: -1.4147e-16 - val_r2_keras: -35.2460 - val_rmse: 0.9804 - val_sae: 363.7689 - val_sse: 508.4632 - learning_rate: 1.0000e-05\n","Epoch 132/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0847 - loss: 0.2325 - mae: 0.2884 - mse: 0.1824 - pearson_correlation: 3.0572e-16 - r2_keras: -91.4406 - rmse: 0.8367 - sae: 2533.3691 - sse: 2867.3904\n","Epoch 132: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0938 - loss: 0.2380 - mae: 0.2915 - mse: 0.1945 - pearson_correlation: 1.4544e-16 - r2_keras: -77.1735 - rmse: 0.8451 - sae: 1856.8402 - sse: 2105.6846 - val_huber_loss: 0.0983 - val_loss: 0.2460 - val_mae: 0.3298 - val_mse: 0.1969 - val_pearson_correlation: 1.1013e-16 - val_r2_keras: -35.2223 - val_rmse: 0.9801 - val_sae: 363.7726 - val_sse: 508.1304 - learning_rate: 1.0000e-05\n","Epoch 133/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0844 - loss: 0.2321 - mae: 0.2880 - mse: 0.1816 - pearson_correlation: 6.7739e-16 - r2_keras: -91.5377 - rmse: 0.8371 - sae: 2534.7932 - sse: 2870.4038\n","Epoch 133: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0932 - loss: 0.2375 - mae: 0.2910 - mse: 0.1933 - pearson_correlation: 4.1456e-16 - r2_keras: -77.2430 - rmse: 0.8454 - sae: 1857.9869 - sse: 2107.7485 - val_huber_loss: 0.0984 - val_loss: 0.2461 - val_mae: 0.3282 - val_mse: 0.1971 - val_pearson_correlation: -6.8199e-17 - val_r2_keras: -35.2088 - val_rmse: 0.9799 - val_sae: 363.8793 - val_sse: 507.9414 - learning_rate: 1.0000e-05\n","Epoch 134/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0842 - loss: 0.2319 - mae: 0.2876 - mse: 0.1809 - pearson_correlation: 1.6802e-16 - r2_keras: -91.5243 - rmse: 0.8371 - sae: 2534.7446 - sse: 2869.9893\n","Epoch 134: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0928 - loss: 0.2371 - mae: 0.2903 - mse: 0.1924 - pearson_correlation: 1.0234e-16 - r2_keras: -77.1956 - rmse: 0.8450 - sae: 1857.7623 - sse: 2107.0210 - val_huber_loss: 0.0990 - val_loss: 0.2467 - val_mae: 0.3303 - val_mse: 0.1983 - val_pearson_correlation: 2.0997e-16 - val_r2_keras: -35.1984 - val_rmse: 0.9798 - val_sae: 363.7505 - val_sse: 507.7951 - learning_rate: 1.0000e-05\n","Epoch 135/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0838 - loss: 0.2316 - mae: 0.2871 - mse: 0.1801 - pearson_correlation: -4.5524e-17 - r2_keras: -91.3595 - rmse: 0.8363 - sae: 2532.2812 - sse: 2864.8774\n","Epoch 135: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0923 - loss: 0.2367 - mae: 0.2897 - mse: 0.1912 - pearson_correlation: -1.4601e-17 - r2_keras: -77.0889 - rmse: 0.8445 - sae: 1856.3383 - sse: 2103.6499 - val_huber_loss: 0.0993 - val_loss: 0.2470 - val_mae: 0.3298 - val_mse: 0.1990 - val_pearson_correlation: 2.7303e-16 - val_r2_keras: -35.1929 - val_rmse: 0.9797 - val_sae: 363.8715 - val_sse: 507.7173 - learning_rate: 1.0000e-05\n","Epoch 136/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0835 - loss: 0.2312 - mae: 0.2868 - mse: 0.1793 - pearson_correlation: 7.0629e-17 - r2_keras: -91.3838 - rmse: 0.8364 - sae: 2532.7427 - sse: 2865.6309\n","Epoch 136: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0917 - loss: 0.2362 - mae: 0.2892 - mse: 0.1901 - pearson_correlation: 1.4196e-16 - r2_keras: -77.1156 - rmse: 0.8447 - sae: 1856.8673 - sse: 2104.2751 - val_huber_loss: 0.0995 - val_loss: 0.2472 - val_mae: 0.3289 - val_mse: 0.1994 - val_pearson_correlation: 5.7784e-17 - val_r2_keras: -35.1785 - val_rmse: 0.9795 - val_sae: 363.9628 - val_sse: 507.5165 - learning_rate: 1.0000e-05\n","Epoch 137/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0832 - loss: 0.2310 - mae: 0.2862 - mse: 0.1785 - pearson_correlation: -4.4463e-17 - r2_keras: -91.4050 - rmse: 0.8365 - sae: 2533.0444 - sse: 2866.2886\n","Epoch 137: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0913 - loss: 0.2359 - mae: 0.2884 - mse: 0.1891 - pearson_correlation: -2.5133e-17 - r2_keras: -77.0880 - rmse: 0.8444 - sae: 1856.8127 - sse: 2104.2246 - val_huber_loss: 0.1000 - val_loss: 0.2478 - val_mae: 0.3309 - val_mse: 0.2007 - val_pearson_correlation: -1.1562e-16 - val_r2_keras: -35.1731 - val_rmse: 0.9794 - val_sae: 363.8345 - val_sse: 507.4408 - learning_rate: 1.0000e-05\n","Epoch 138/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0829 - loss: 0.2307 - mae: 0.2857 - mse: 0.1778 - pearson_correlation: 2.0357e-16 - r2_keras: -91.2370 - rmse: 0.8358 - sae: 2530.1121 - sse: 2861.0762\n","Epoch 138: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0908 - loss: 0.2355 - mae: 0.2877 - mse: 0.1881 - pearson_correlation: 1.8751e-16 - r2_keras: -76.9920 - rmse: 0.8440 - sae: 1855.1456 - sse: 2100.9375 - val_huber_loss: 0.1003 - val_loss: 0.2480 - val_mae: 0.3305 - val_mse: 0.2012 - val_pearson_correlation: 7.3606e-17 - val_r2_keras: -35.1642 - val_rmse: 0.9793 - val_sae: 363.9671 - val_sse: 507.3157 - learning_rate: 1.0000e-05\n","Epoch 139/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0826 - loss: 0.2303 - mae: 0.2852 - mse: 0.1770 - pearson_correlation: -3.5469e-16 - r2_keras: -91.3442 - rmse: 0.8363 - sae: 2531.5771 - sse: 2864.4001\n","Epoch 139: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0903 - loss: 0.2350 - mae: 0.2873 - mse: 0.1870 - pearson_correlation: -3.2690e-16 - r2_keras: -77.0782 - rmse: 0.8445 - sae: 1856.3396 - sse: 2103.3267 - val_huber_loss: 0.1004 - val_loss: 0.2482 - val_mae: 0.3304 - val_mse: 0.2015 - val_pearson_correlation: 3.9427e-16 - val_r2_keras: -35.1652 - val_rmse: 0.9793 - val_sae: 364.2275 - val_sse: 507.3297 - learning_rate: 1.0000e-05\n","Epoch 140/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0824 - loss: 0.2301 - mae: 0.2846 - mse: 0.1765 - pearson_correlation: -4.6897e-17 - r2_keras: -91.3242 - rmse: 0.8362 - sae: 2531.3208 - sse: 2863.7825\n","Epoch 140: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0899 - loss: 0.2347 - mae: 0.2863 - mse: 0.1862 - pearson_correlation: -4.0278e-17 - r2_keras: -77.0419 - rmse: 0.8442 - sae: 1855.9531 - sse: 2102.6443 - val_huber_loss: 0.1010 - val_loss: 0.2487 - val_mae: 0.3316 - val_mse: 0.2026 - val_pearson_correlation: -4.0485e-16 - val_r2_keras: -35.1678 - val_rmse: 0.9793 - val_sae: 364.1242 - val_sse: 507.3664 - learning_rate: 1.0000e-05\n","Epoch 141/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0821 - loss: 0.2298 - mae: 0.2839 - mse: 0.1758 - pearson_correlation: 7.4552e-17 - r2_keras: -91.2254 - rmse: 0.8357 - sae: 2529.1804 - sse: 2860.7173\n","Epoch 141: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0895 - loss: 0.2343 - mae: 0.2857 - mse: 0.1853 - pearson_correlation: 2.4975e-17 - r2_keras: -77.0109 - rmse: 0.8442 - sae: 1854.8929 - sse: 2101.0110 - val_huber_loss: 0.1010 - val_loss: 0.2487 - val_mae: 0.3311 - val_mse: 0.2027 - val_pearson_correlation: 2.3671e-16 - val_r2_keras: -35.1522 - val_rmse: 0.9791 - val_sae: 364.3174 - val_sse: 507.1465 - learning_rate: 1.0000e-05\n","Epoch 142/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0818 - loss: 0.2295 - mae: 0.2833 - mse: 0.1751 - pearson_correlation: 1.4044e-16 - r2_keras: -91.2836 - rmse: 0.8360 - sae: 2529.8042 - sse: 2862.5229\n","Epoch 142: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0891 - loss: 0.2339 - mae: 0.2853 - mse: 0.1844 - pearson_correlation: 1.9737e-16 - r2_keras: -77.0642 - rmse: 0.8445 - sae: 1855.4967 - sse: 2102.3835 - val_huber_loss: 0.1013 - val_loss: 0.2490 - val_mae: 0.3320 - val_mse: 0.2035 - val_pearson_correlation: -8.9423e-17 - val_r2_keras: -35.1556 - val_rmse: 0.9792 - val_sae: 364.5786 - val_sse: 507.1945 - learning_rate: 1.0000e-05\n","Epoch 143/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0815 - loss: 0.2293 - mae: 0.2829 - mse: 0.1746 - pearson_correlation: -4.9265e-16 - r2_keras: -91.3642 - rmse: 0.8363 - sae: 2530.4910 - sse: 2865.0205\n","Epoch 143: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0888 - loss: 0.2337 - mae: 0.2843 - mse: 0.1838 - pearson_correlation: -3.4059e-16 - r2_keras: -77.0766 - rmse: 0.8444 - sae: 1855.5992 - sse: 2103.5647 - val_huber_loss: 0.1017 - val_loss: 0.2494 - val_mae: 0.3324 - val_mse: 0.2044 - val_pearson_correlation: 1.3695e-16 - val_r2_keras: -35.1248 - val_rmse: 0.9788 - val_sae: 364.2068 - val_sse: 506.7633 - learning_rate: 1.0000e-05\n","Epoch 144/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0813 - loss: 0.2290 - mae: 0.2819 - mse: 0.1741 - pearson_correlation: 1.0150e-16 - r2_keras: -91.1873 - rmse: 0.8355 - sae: 2527.4055 - sse: 2859.5339\n","Epoch 144: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0884 - loss: 0.2333 - mae: 0.2837 - mse: 0.1831 - pearson_correlation: 1.2818e-17 - r2_keras: -76.9852 - rmse: 0.8441 - sae: 1853.8462 - sse: 2100.2183 - val_huber_loss: 0.1018 - val_loss: 0.2495 - val_mae: 0.3319 - val_mse: 0.2045 - val_pearson_correlation: 1.2651e-16 - val_r2_keras: -35.1033 - val_rmse: 0.9785 - val_sae: 364.3932 - val_sse: 506.4604 - learning_rate: 1.0000e-05\n","Epoch 145/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0810 - loss: 0.2287 - mae: 0.2813 - mse: 0.1735 - pearson_correlation: 1.8548e-16 - r2_keras: -91.2248 - rmse: 0.8357 - sae: 2527.4971 - sse: 2860.6970\n","Epoch 145: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - huber_loss: 0.0880 - loss: 0.2330 - mae: 0.2833 - mse: 0.1822 - pearson_correlation: 1.2096e-16 - r2_keras: -77.0152 - rmse: 0.8443 - sae: 1854.0601 - sse: 2101.0530 - val_huber_loss: 0.1021 - val_loss: 0.2498 - val_mae: 0.3329 - val_mse: 0.2053 - val_pearson_correlation: -4.7468e-17 - val_r2_keras: -35.0904 - val_rmse: 0.9783 - val_sae: 364.5060 - val_sse: 506.2802 - learning_rate: 1.0000e-05\n","Epoch 146/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0807 - loss: 0.2284 - mae: 0.2809 - mse: 0.1728 - pearson_correlation: 2.8981e-16 - r2_keras: -91.2514 - rmse: 0.8358 - sae: 2527.5161 - sse: 2861.5215\n","Epoch 146: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0877 - loss: 0.2327 - mae: 0.2823 - mse: 0.1815 - pearson_correlation: 1.8689e-16 - r2_keras: -76.9815 - rmse: 0.8439 - sae: 1853.6469 - sse: 2100.9990 - val_huber_loss: 0.1024 - val_loss: 0.2501 - val_mae: 0.3327 - val_mse: 0.2060 - val_pearson_correlation: -2.3256e-16 - val_r2_keras: -35.0365 - val_rmse: 0.9776 - val_sae: 363.9698 - val_sse: 505.5242 - learning_rate: 1.0000e-05\n","Epoch 147/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0805 - loss: 0.2282 - mae: 0.2799 - mse: 0.1724 - pearson_correlation: -2.8060e-16 - r2_keras: -91.0509 - rmse: 0.8349 - sae: 2524.3083 - sse: 2855.3049\n","Epoch 147: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0873 - loss: 0.2324 - mae: 0.2817 - mse: 0.1809 - pearson_correlation: -1.1368e-16 - r2_keras: -76.8728 - rmse: 0.8435 - sae: 1851.8248 - sse: 2097.1472 - val_huber_loss: 0.1026 - val_loss: 0.2503 - val_mae: 0.3331 - val_mse: 0.2065 - val_pearson_correlation: 4.5979e-16 - val_r2_keras: -35.0432 - val_rmse: 0.9776 - val_sae: 364.2319 - val_sse: 505.6173 - learning_rate: 1.0000e-05\n","Epoch 148/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0802 - loss: 0.2279 - mae: 0.2796 - mse: 0.1719 - pearson_correlation: 9.4959e-17 - r2_keras: -91.0125 - rmse: 0.8347 - sae: 2523.0576 - sse: 2854.1128\n","Epoch 148: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0869 - loss: 0.2320 - mae: 0.2815 - mse: 0.1801 - pearson_correlation: 1.9567e-16 - r2_keras: -76.8470 - rmse: 0.8434 - sae: 1851.1016 - sse: 2096.3501 - val_huber_loss: 0.1028 - val_loss: 0.2505 - val_mae: 0.3327 - val_mse: 0.2069 - val_pearson_correlation: 5.8191e-17 - val_r2_keras: -35.0140 - val_rmse: 0.9773 - val_sae: 364.2986 - val_sse: 505.2083 - learning_rate: 1.0000e-05\n","Epoch 149/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0800 - loss: 0.2277 - mae: 0.2787 - mse: 0.1713 - pearson_correlation: 6.4443e-16 - r2_keras: -91.0493 - rmse: 0.8349 - sae: 2523.3301 - sse: 2855.2537\n","Epoch 149: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0866 - loss: 0.2317 - mae: 0.2807 - mse: 0.1793 - pearson_correlation: 3.4823e-16 - r2_keras: -76.8888 - rmse: 0.8437 - sae: 1851.4722 - sse: 2097.3135 - val_huber_loss: 0.1031 - val_loss: 0.2508 - val_mae: 0.3341 - val_mse: 0.2077 - val_pearson_correlation: 3.9117e-16 - val_r2_keras: -35.0372 - val_rmse: 0.9776 - val_sae: 364.6586 - val_sse: 505.5334 - learning_rate: 1.0000e-05\n","Epoch 150/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0797 - loss: 0.2274 - mae: 0.2783 - mse: 0.1707 - pearson_correlation: 4.9110e-16 - r2_keras: -91.1297 - rmse: 0.8353 - sae: 2523.5811 - sse: 2857.7495\n","Epoch 150: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0862 - loss: 0.2314 - mae: 0.2796 - mse: 0.1787 - pearson_correlation: 2.4109e-16 - r2_keras: -76.8720 - rmse: 0.8433 - sae: 1851.0573 - sse: 2098.1506 - val_huber_loss: 0.1033 - val_loss: 0.2510 - val_mae: 0.3338 - val_mse: 0.2081 - val_pearson_correlation: 1.0592e-16 - val_r2_keras: -34.9903 - val_rmse: 0.9769 - val_sae: 364.1359 - val_sse: 504.8764 - learning_rate: 1.0000e-05\n","Epoch 151/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0795 - loss: 0.2272 - mae: 0.2771 - mse: 0.1703 - pearson_correlation: 4.1683e-16 - r2_keras: -90.9426 - rmse: 0.8344 - sae: 2520.7251 - sse: 2851.9429\n","Epoch 151: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0859 - loss: 0.2311 - mae: 0.2790 - mse: 0.1780 - pearson_correlation: 2.0669e-16 - r2_keras: -76.7855 - rmse: 0.8431 - sae: 1849.6143 - sse: 2094.7295 - val_huber_loss: 0.1033 - val_loss: 0.2510 - val_mae: 0.3336 - val_mse: 0.2081 - val_pearson_correlation: -4.2344e-17 - val_r2_keras: -35.0059 - val_rmse: 0.9771 - val_sae: 364.4895 - val_sse: 505.0945 - learning_rate: 1.0000e-05\n","Epoch 152/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0791 - loss: 0.2268 - mae: 0.2762 - mse: 0.1694 - pearson_correlation: 5.6381e-16 - r2_keras: -91.0780 - rmse: 0.8350 - sae: 2521.3538 - sse: 2856.1431\n","Epoch 152: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0854 - loss: 0.2306 - mae: 0.2783 - mse: 0.1770 - pearson_correlation: 3.2633e-16 - r2_keras: -76.8852 - rmse: 0.8436 - sae: 1850.1958 - sse: 2097.6396 - val_huber_loss: 0.1034 - val_loss: 0.2511 - val_mae: 0.3338 - val_mse: 0.2085 - val_pearson_correlation: 2.7537e-16 - val_r2_keras: -34.9929 - val_rmse: 0.9770 - val_sae: 364.6126 - val_sse: 504.9124 - learning_rate: 1.0000e-05\n","Epoch 153/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0787 - loss: 0.2263 - mae: 0.2751 - mse: 0.1685 - pearson_correlation: 2.7700e-16 - r2_keras: -91.2021 - rmse: 0.8356 - sae: 2522.4463 - sse: 2859.9951\n","Epoch 153: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0849 - loss: 0.2302 - mae: 0.2773 - mse: 0.1760 - pearson_correlation: 1.1983e-16 - r2_keras: -76.9702 - rmse: 0.8440 - sae: 1851.0397 - sse: 2100.2341 - val_huber_loss: 0.1036 - val_loss: 0.2513 - val_mae: 0.3345 - val_mse: 0.2089 - val_pearson_correlation: 1.7468e-16 - val_r2_keras: -35.0054 - val_rmse: 0.9771 - val_sae: 364.8937 - val_sse: 505.0879 - learning_rate: 1.0000e-05\n","Epoch 154/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0784 - loss: 0.2261 - mae: 0.2743 - mse: 0.1680 - pearson_correlation: 3.9769e-16 - r2_keras: -91.3090 - rmse: 0.8361 - sae: 2522.8882 - sse: 2863.3110\n","Epoch 154: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0845 - loss: 0.2298 - mae: 0.2759 - mse: 0.1753 - pearson_correlation: 1.5378e-16 - r2_keras: -76.9670 - rmse: 0.8436 - sae: 1850.7113 - sse: 2101.5708 - val_huber_loss: 0.1038 - val_loss: 0.2515 - val_mae: 0.3342 - val_mse: 0.2093 - val_pearson_correlation: 4.2431e-17 - val_r2_keras: -34.9566 - val_rmse: 0.9765 - val_sae: 364.3633 - val_sse: 504.4034 - learning_rate: 1.0000e-05\n","Epoch 155/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0781 - loss: 0.2258 - mae: 0.2728 - mse: 0.1674 - pearson_correlation: 8.1070e-16 - r2_keras: -91.2097 - rmse: 0.8356 - sae: 2521.0908 - sse: 2860.2295\n","Epoch 155: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0841 - loss: 0.2295 - mae: 0.2749 - mse: 0.1745 - pearson_correlation: 5.1699e-16 - r2_keras: -76.9348 - rmse: 0.8436 - sae: 1849.9252 - sse: 2099.9155 - val_huber_loss: 0.1039 - val_loss: 0.2516 - val_mae: 0.3345 - val_mse: 0.2096 - val_pearson_correlation: -1.1136e-16 - val_r2_keras: -34.9663 - val_rmse: 0.9766 - val_sae: 364.6041 - val_sse: 504.5385 - learning_rate: 1.0000e-05\n","Epoch 156/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0777 - loss: 0.2254 - mae: 0.2720 - mse: 0.1667 - pearson_correlation: 9.4377e-17 - r2_keras: -91.3232 - rmse: 0.8362 - sae: 2521.4521 - sse: 2863.7510\n","Epoch 156: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0837 - loss: 0.2290 - mae: 0.2742 - mse: 0.1736 - pearson_correlation: 7.1048e-17 - r2_keras: -77.0067 - rmse: 0.8439 - sae: 1850.2577 - sse: 2102.2190 - val_huber_loss: 0.1040 - val_loss: 0.2517 - val_mae: 0.3339 - val_mse: 0.2098 - val_pearson_correlation: -2.4427e-16 - val_r2_keras: -34.9272 - val_rmse: 0.9761 - val_sae: 364.5758 - val_sse: 503.9911 - learning_rate: 1.0000e-05\n","Epoch 157/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0774 - loss: 0.2251 - mae: 0.2707 - mse: 0.1659 - pearson_correlation: 5.4571e-17 - r2_keras: -91.4076 - rmse: 0.8365 - sae: 2522.2053 - sse: 2866.3667\n","Epoch 157: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0833 - loss: 0.2286 - mae: 0.2732 - mse: 0.1727 - pearson_correlation: 5.3544e-17 - r2_keras: -77.0620 - rmse: 0.8442 - sae: 1850.8615 - sse: 2103.9524 - val_huber_loss: 0.1041 - val_loss: 0.2518 - val_mae: 0.3344 - val_mse: 0.2102 - val_pearson_correlation: -3.3970e-16 - val_r2_keras: -34.9451 - val_rmse: 0.9763 - val_sae: 364.7775 - val_sse: 504.2416 - learning_rate: 1.0000e-05\n","Epoch 158/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0772 - loss: 0.2249 - mae: 0.2701 - mse: 0.1655 - pearson_correlation: 5.0759e-18 - r2_keras: -91.4950 - rmse: 0.8369 - sae: 2522.6445 - sse: 2869.0779\n","Epoch 158: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0829 - loss: 0.2284 - mae: 0.2718 - mse: 0.1721 - pearson_correlation: 4.5182e-17 - r2_keras: -77.0375 - rmse: 0.8437 - sae: 1850.4301 - sse: 2104.7888 - val_huber_loss: 0.1042 - val_loss: 0.2519 - val_mae: 0.3333 - val_mse: 0.2104 - val_pearson_correlation: -2.1825e-16 - val_r2_keras: -34.8693 - val_rmse: 0.9753 - val_sae: 364.0654 - val_sse: 503.1791 - learning_rate: 1.0000e-05\n","Epoch 159/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0770 - loss: 0.2247 - mae: 0.2689 - mse: 0.1652 - pearson_correlation: 1.5676e-16 - r2_keras: -91.3424 - rmse: 0.8362 - sae: 2520.7808 - sse: 2864.3472\n","Epoch 159: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0826 - loss: 0.2281 - mae: 0.2711 - mse: 0.1716 - pearson_correlation: -1.7941e-17 - r2_keras: -76.9611 - rmse: 0.8435 - sae: 1849.5459 - sse: 2101.9312 - val_huber_loss: 0.1043 - val_loss: 0.2520 - val_mae: 0.3335 - val_mse: 0.2107 - val_pearson_correlation: -1.5981e-17 - val_r2_keras: -34.8510 - val_rmse: 0.9750 - val_sae: 364.1972 - val_sse: 502.9214 - learning_rate: 1.0000e-05\n","Epoch 160/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0767 - loss: 0.2244 - mae: 0.2684 - mse: 0.1645 - pearson_correlation: 1.3179e-16 - r2_keras: -91.4218 - rmse: 0.8366 - sae: 2520.9675 - sse: 2866.8086\n","Epoch 160: val_loss did not improve from 0.24035\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0823 - loss: 0.2278 - mae: 0.2707 - mse: 0.1708 - pearson_correlation: 1.0599e-16 - r2_keras: -77.0240 - rmse: 0.8438 - sae: 1849.8500 - sse: 2103.6892 - val_huber_loss: 0.1045 - val_loss: 0.2522 - val_mae: 0.3339 - val_mse: 0.2112 - val_pearson_correlation: 1.2253e-16 - val_r2_keras: -34.8548 - val_rmse: 0.9751 - val_sae: 364.3476 - val_sse: 502.9744 - learning_rate: 1.0000e-05\n","| \u001b[35m12       \u001b[39m | \u001b[35m-0.2522  \u001b[39m | \u001b[35m0.0001   \u001b[39m | \u001b[35m90.28    \u001b[39m | \u001b[35m52.12    \u001b[39m | \u001b[35m71.87    \u001b[39m | \u001b[35m5.727    \u001b[39m | \u001b[35m80.45    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.5391 - loss: 0.7038 - mae: 0.9279 - mse: 1.2716 - pearson_correlation: -1.8351e-16 - r2_keras: -192.4606 - rmse: 1.2104 - sae: 3927.1758 - sse: 6000.9048\n","Epoch 1: val_loss improved from inf to 0.42068, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 617ms/step - huber_loss: 0.5360 - loss: 0.7019 - mae: 0.9258 - mse: 1.3046 - pearson_correlation: -1.2435e-16 - r2_keras: -160.3091 - rmse: 1.2085 - sae: 2841.5745 - sse: 4379.8979 - val_huber_loss: 0.2561 - val_loss: 0.4207 - val_mae: 0.6112 - val_mse: 0.6242 - val_pearson_correlation: 2.5312e-16 - val_r2_keras: -22.1296 - val_rmse: 0.7832 - val_sae: 321.5070 - val_sse: 324.4649 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3371 - loss: 0.5017 - mae: 0.7044 - mse: 0.7394 - pearson_correlation: -4.7841e-16 - r2_keras: -153.0324 - rmse: 1.0800 - sae: 3500.7969 - sse: 4777.8911\n","Epoch 2: val_loss did not improve from 0.42068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3438 - loss: 0.5058 - mae: 0.6991 - mse: 0.7680 - pearson_correlation: -2.8846e-16 - r2_keras: -128.0414 - rmse: 1.0826 - sae: 2542.3567 - sse: 3494.3840 - val_huber_loss: 0.2599 - val_loss: 0.4245 - val_mae: 0.6117 - val_mse: 0.6345 - val_pearson_correlation: 1.2477e-16 - val_r2_keras: -22.1662 - val_rmse: 0.7838 - val_sae: 318.7076 - val_sse: 324.9773 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2743 - loss: 0.4389 - mae: 0.6230 - mse: 0.5948 - pearson_correlation: -6.2921e-16 - r2_keras: -134.4662 - rmse: 1.0129 - sae: 3248.7961 - sse: 4201.9932\n","Epoch 3: val_loss did not improve from 0.42068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2739 - loss: 0.4387 - mae: 0.6115 - mse: 0.6019 - pearson_correlation: -3.2730e-16 - r2_keras: -111.3910 - rmse: 1.0071 - sae: 2358.7720 - sse: 3060.3303 - val_huber_loss: 0.2707 - val_loss: 0.4353 - val_mae: 0.6263 - val_mse: 0.6609 - val_pearson_correlation: 1.3318e-16 - val_r2_keras: -22.3189 - val_rmse: 0.7864 - val_sae: 320.0179 - val_sse: 327.1195 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2219 - loss: 0.3865 - mae: 0.5573 - mse: 0.4738 - pearson_correlation: 3.2429e-16 - r2_keras: -124.5991 - rmse: 0.9753 - sae: 3083.0112 - sse: 3895.9270\n","Epoch 4: val_loss did not improve from 0.42068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.2230 - loss: 0.3872 - mae: 0.5445 - mse: 0.4778 - pearson_correlation: 2.8414e-16 - r2_keras: -103.0412 - rmse: 0.9684 - sae: 2241.6174 - sse: 2835.5034 - val_huber_loss: 0.2854 - val_loss: 0.4500 - val_mae: 0.6480 - val_mse: 0.6940 - val_pearson_correlation: -7.0102e-17 - val_r2_keras: -22.6598 - val_rmse: 0.7921 - val_sae: 325.2613 - val_sse: 331.9027 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1878 - loss: 0.3524 - mae: 0.5040 - mse: 0.3966 - pearson_correlation: -5.4710e-16 - r2_keras: -118.5036 - rmse: 0.9513 - sae: 2963.5679 - sse: 3706.8535\n","Epoch 5: val_loss did not improve from 0.42068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1899 - loss: 0.3537 - mae: 0.4960 - mse: 0.3984 - pearson_correlation: -3.4561e-16 - r2_keras: -97.2367 - rmse: 0.9385 - sae: 2156.8950 - sse: 2689.0347 - val_huber_loss: 0.2934 - val_loss: 0.4580 - val_mae: 0.6633 - val_mse: 0.7102 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -23.2499 - val_rmse: 0.8019 - val_sae: 333.7864 - val_sse: 340.1805 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1627 - loss: 0.3273 - mae: 0.4575 - mse: 0.3408 - pearson_correlation: 1.0247e-16 - r2_keras: -114.6923 - rmse: 0.9360 - sae: 2868.8098 - sse: 3588.6318\n","Epoch 6: val_loss did not improve from 0.42068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1632 - loss: 0.3276 - mae: 0.4526 - mse: 0.3393 - pearson_correlation: 1.9948e-17 - r2_keras: -93.0509 - rmse: 0.9145 - sae: 2087.7134 - sse: 2590.9250 - val_huber_loss: 0.2832 - val_loss: 0.4478 - val_mae: 0.6507 - val_mse: 0.6782 - val_pearson_correlation: 2.6962e-16 - val_r2_keras: -23.9521 - val_rmse: 0.8134 - val_sae: 341.6759 - val_sse: 350.0310 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1440 - loss: 0.3086 - mae: 0.4080 - mse: 0.3054 - pearson_correlation: 1.0041e-15 - r2_keras: -110.8454 - rmse: 0.9203 - sae: 2796.8159 - sse: 3469.3032\n","Epoch 7: val_loss did not improve from 0.42068\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1411 - loss: 0.3068 - mae: 0.4070 - mse: 0.2988 - pearson_correlation: 6.6360e-16 - r2_keras: -89.1891 - rmse: 0.8927 - sae: 2034.0925 - sse: 2496.1567 - val_huber_loss: 0.2644 - val_loss: 0.4290 - val_mae: 0.6248 - val_mse: 0.6307 - val_pearson_correlation: 1.6267e-16 - val_r2_keras: -25.0763 - val_rmse: 0.8316 - val_sae: 349.7817 - val_sse: 365.8010 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1405 - loss: 0.3051 - mae: 0.4004 - mse: 0.2978 - pearson_correlation: 1.2776e-16 - r2_keras: -110.5066 - rmse: 0.9189 - sae: 2791.7520 - sse: 3458.7959\n","Epoch 8: val_loss improved from 0.42068 to 0.41442, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1373 - loss: 0.3031 - mae: 0.3998 - mse: 0.2909 - pearson_correlation: 8.2253e-17 - r2_keras: -88.8619 - rmse: 0.8909 - sae: 2030.0361 - sse: 2487.9631 - val_huber_loss: 0.2498 - val_loss: 0.4144 - val_mae: 0.6053 - val_mse: 0.5916 - val_pearson_correlation: 1.4398e-16 - val_r2_keras: -27.2940 - val_rmse: 0.8662 - val_sae: 365.0428 - val_sse: 396.9113 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1376 - loss: 0.3021 - mae: 0.3937 - mse: 0.2915 - pearson_correlation: 1.9608e-16 - r2_keras: -110.3529 - rmse: 0.9183 - sae: 2789.6252 - sse: 3454.0283\n","Epoch 9: val_loss improved from 0.41442 to 0.40869, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1338 - loss: 0.2999 - mae: 0.3932 - mse: 0.2840 - pearson_correlation: 6.1821e-17 - r2_keras: -88.6368 - rmse: 0.8893 - sae: 2027.7533 - sse: 2483.3455 - val_huber_loss: 0.2441 - val_loss: 0.4087 - val_mae: 0.5840 - val_mse: 0.5684 - val_pearson_correlation: 7.4742e-17 - val_r2_keras: -29.8983 - val_rmse: 0.9052 - val_sae: 384.3937 - val_sse: 433.4452 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1348 - loss: 0.2994 - mae: 0.3876 - mse: 0.2858 - pearson_correlation: 2.1692e-17 - r2_keras: -110.1182 - rmse: 0.9173 - sae: 2786.4290 - sse: 3446.7490\n","Epoch 10: val_loss improved from 0.40869 to 0.39011, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1307 - loss: 0.2969 - mae: 0.3871 - mse: 0.2778 - pearson_correlation: 4.8199e-17 - r2_keras: -88.3821 - rmse: 0.8878 - sae: 2025.0570 - sse: 2477.3411 - val_huber_loss: 0.2255 - val_loss: 0.3901 - val_mae: 0.5299 - val_mse: 0.5121 - val_pearson_correlation: -3.0253e-16 - val_r2_keras: -31.8870 - val_rmse: 0.9339 - val_sae: 391.7406 - val_sse: 461.3417 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1321 - loss: 0.2966 - mae: 0.3813 - mse: 0.2799 - pearson_correlation: -5.0033e-16 - r2_keras: -110.0036 - rmse: 0.9169 - sae: 2784.3872 - sse: 3443.1936\n","Epoch 11: val_loss did not improve from 0.39011\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1276 - loss: 0.2939 - mae: 0.3810 - mse: 0.2716 - pearson_correlation: -3.0165e-16 - r2_keras: -88.2506 - rmse: 0.8870 - sae: 2023.4479 - sse: 2474.3245 - val_huber_loss: 0.2277 - val_loss: 0.3923 - val_mae: 0.5506 - val_mse: 0.5079 - val_pearson_correlation: -3.6568e-16 - val_r2_keras: -33.7872 - val_rmse: 0.9605 - val_sae: 404.4129 - val_sse: 487.9991 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1293 - loss: 0.2939 - mae: 0.3751 - mse: 0.2741 - pearson_correlation: -4.0247e-16 - r2_keras: -109.8263 - rmse: 0.9161 - sae: 2782.0649 - sse: 3437.6924\n","Epoch 12: val_loss did not improve from 0.39011\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1245 - loss: 0.2910 - mae: 0.3749 - mse: 0.2655 - pearson_correlation: -2.9239e-16 - r2_keras: -88.0601 - rmse: 0.8859 - sae: 2021.6311 - sse: 2469.8083 - val_huber_loss: 0.2467 - val_loss: 0.4113 - val_mae: 0.5876 - val_mse: 0.5414 - val_pearson_correlation: 2.5349e-16 - val_r2_keras: -36.0270 - val_rmse: 0.9909 - val_sae: 423.6811 - val_sse: 519.4192 - learning_rate: 2.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1269 - loss: 0.2915 - mae: 0.3698 - mse: 0.2688 - pearson_correlation: 3.8794e-17 - r2_keras: -109.6767 - rmse: 0.9155 - sae: 2779.7407 - sse: 3433.0513\n","Epoch 13: val_loss did not improve from 0.39011\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1217 - loss: 0.2883 - mae: 0.3695 - mse: 0.2598 - pearson_correlation: 1.3759e-17 - r2_keras: -87.8951 - rmse: 0.8849 - sae: 2019.7958 - sse: 2465.9497 - val_huber_loss: 0.2441 - val_loss: 0.4087 - val_mae: 0.5856 - val_mse: 0.5288 - val_pearson_correlation: -3.8315e-16 - val_r2_keras: -38.2766 - val_rmse: 1.0206 - val_sae: 436.3499 - val_sse: 550.9770 - learning_rate: 2.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1247 - loss: 0.2893 - mae: 0.3653 - mse: 0.2641 - pearson_correlation: -3.0916e-17 - r2_keras: -109.3910 - rmse: 0.9143 - sae: 2775.6460 - sse: 3424.1919\n","Epoch 14: val_loss improved from 0.39011 to 0.38833, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1193 - loss: 0.2860 - mae: 0.3649 - mse: 0.2549 - pearson_correlation: 1.7863e-17 - r2_keras: -87.6600 - rmse: 0.8837 - sae: 2016.8678 - sse: 2459.5193 - val_huber_loss: 0.2238 - val_loss: 0.3883 - val_mae: 0.5529 - val_mse: 0.4787 - val_pearson_correlation: -1.5980e-16 - val_r2_keras: -39.6116 - val_rmse: 1.0378 - val_sae: 438.9086 - val_sse: 569.7034 - learning_rate: 2.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1224 - loss: 0.2870 - mae: 0.3605 - mse: 0.2591 - pearson_correlation: 2.0426e-16 - r2_keras: -109.2138 - rmse: 0.9136 - sae: 2773.0581 - sse: 3418.6934\n","Epoch 15: val_loss improved from 0.38833 to 0.36644, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1167 - loss: 0.2835 - mae: 0.3599 - mse: 0.2495 - pearson_correlation: 1.6059e-16 - r2_keras: -87.4874 - rmse: 0.8827 - sae: 2014.8955 - sse: 2455.2144 - val_huber_loss: 0.2019 - val_loss: 0.3664 - val_mae: 0.5203 - val_mse: 0.4277 - val_pearson_correlation: 2.8635e-16 - val_r2_keras: -40.4850 - val_rmse: 1.0489 - val_sae: 437.8887 - val_sse: 581.9562 - learning_rate: 2.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1204 - loss: 0.2850 - mae: 0.3562 - mse: 0.2551 - pearson_correlation: -1.1763e-16 - r2_keras: -108.8851 - rmse: 0.9122 - sae: 2767.6084 - sse: 3408.4990\n","Epoch 16: val_loss improved from 0.36644 to 0.35084, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1143 - loss: 0.2812 - mae: 0.3553 - mse: 0.2450 - pearson_correlation: -9.8886e-17 - r2_keras: -87.2012 - rmse: 0.8812 - sae: 2011.0844 - sse: 2447.6313 - val_huber_loss: 0.1863 - val_loss: 0.3508 - val_mae: 0.4944 - val_mse: 0.3925 - val_pearson_correlation: 2.7493e-16 - val_r2_keras: -41.3546 - val_rmse: 1.0598 - val_sae: 437.0494 - val_sse: 594.1544 - learning_rate: 2.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1182 - loss: 0.2828 - mae: 0.3515 - mse: 0.2501 - pearson_correlation: -6.3362e-16 - r2_keras: -108.7344 - rmse: 0.9116 - sae: 2764.5349 - sse: 3403.8223\n","Epoch 17: val_loss improved from 0.35084 to 0.34097, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1118 - loss: 0.2789 - mae: 0.3504 - mse: 0.2398 - pearson_correlation: -4.4086e-16 - r2_keras: -87.0828 - rmse: 0.8806 - sae: 2008.9847 - sse: 2444.3037 - val_huber_loss: 0.1764 - val_loss: 0.3410 - val_mae: 0.4714 - val_mse: 0.3703 - val_pearson_correlation: -1.9424e-16 - val_r2_keras: -42.2715 - val_rmse: 1.0712 - val_sae: 436.3772 - val_sse: 607.0175 - learning_rate: 2.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1161 - loss: 0.2806 - mae: 0.3470 - mse: 0.2453 - pearson_correlation: -1.7739e-16 - r2_keras: -108.5247 - rmse: 0.9107 - sae: 2761.0527 - sse: 3397.3193\n","Epoch 18: val_loss improved from 0.34097 to 0.33516, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - huber_loss: 0.1094 - loss: 0.2766 - mae: 0.3456 - mse: 0.2347 - pearson_correlation: -7.9182e-17 - r2_keras: -86.9051 - rmse: 0.8796 - sae: 2006.5090 - sse: 2439.5237 - val_huber_loss: 0.1706 - val_loss: 0.3352 - val_mae: 0.4560 - val_mse: 0.3570 - val_pearson_correlation: -4.2970e-17 - val_r2_keras: -43.0003 - val_rmse: 1.0802 - val_sae: 436.0953 - val_sse: 617.2409 - learning_rate: 2.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1142 - loss: 0.2788 - mae: 0.3433 - mse: 0.2415 - pearson_correlation: -5.7774e-16 - r2_keras: -108.1847 - rmse: 0.9093 - sae: 2755.1616 - sse: 3386.7739\n","Epoch 19: val_loss improved from 0.33516 to 0.33187, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.1074 - loss: 0.2746 - mae: 0.3416 - mse: 0.2307 - pearson_correlation: -4.7990e-16 - r2_keras: -86.6615 - rmse: 0.8785 - sae: 2002.5389 - sse: 2432.2949 - val_huber_loss: 0.1673 - val_loss: 0.3319 - val_mae: 0.4474 - val_mse: 0.3496 - val_pearson_correlation: -7.6149e-17 - val_r2_keras: -43.4295 - val_rmse: 1.0854 - val_sae: 435.9003 - val_sse: 623.2616 - learning_rate: 2.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1122 - loss: 0.2767 - mae: 0.3391 - mse: 0.2368 - pearson_correlation: -9.3393e-17 - r2_keras: -107.9368 - rmse: 0.9083 - sae: 2750.9868 - sse: 3379.0847\n","Epoch 20: val_loss improved from 0.33187 to 0.32931, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1051 - loss: 0.2724 - mae: 0.3370 - mse: 0.2259 - pearson_correlation: -4.3712e-17 - r2_keras: -86.4872 - rmse: 0.8778 - sae: 1999.7001 - sse: 2427.0625 - val_huber_loss: 0.1648 - val_loss: 0.3293 - val_mae: 0.4421 - val_mse: 0.3439 - val_pearson_correlation: -1.0066e-16 - val_r2_keras: -43.6423 - val_rmse: 1.0880 - val_sae: 435.5215 - val_sse: 626.2472 - learning_rate: 2.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1101 - loss: 0.2746 - mae: 0.3347 - mse: 0.2320 - pearson_correlation: -3.3397e-16 - r2_keras: -107.6625 - rmse: 0.9071 - sae: 2746.1719 - sse: 3370.5745\n","Epoch 21: val_loss improved from 0.32931 to 0.32743, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1030 - loss: 0.2703 - mae: 0.3324 - mse: 0.2211 - pearson_correlation: -2.1028e-16 - r2_keras: -86.3052 - rmse: 0.8770 - sae: 1996.4949 - sse: 2421.3999 - val_huber_loss: 0.1629 - val_loss: 0.3274 - val_mae: 0.4388 - val_mse: 0.3398 - val_pearson_correlation: 1.6703e-17 - val_r2_keras: -43.7345 - val_rmse: 1.0892 - val_sae: 435.1521 - val_sse: 627.5400 - learning_rate: 2.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1081 - loss: 0.2727 - mae: 0.3308 - mse: 0.2275 - pearson_correlation: 1.3298e-15 - r2_keras: -107.4453 - rmse: 0.9062 - sae: 2742.0059 - sse: 3363.8367\n","Epoch 22: val_loss improved from 0.32743 to 0.32573, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1009 - loss: 0.2683 - mae: 0.3281 - mse: 0.2165 - pearson_correlation: 8.8449e-16 - r2_keras: -86.1601 - rmse: 0.8764 - sae: 1993.6908 - sse: 2416.9048 - val_huber_loss: 0.1612 - val_loss: 0.3257 - val_mae: 0.4359 - val_mse: 0.3362 - val_pearson_correlation: 3.3374e-16 - val_r2_keras: -43.7277 - val_rmse: 1.0891 - val_sae: 434.5339 - val_sse: 627.4451 - learning_rate: 2.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1065 - loss: 0.2710 - mae: 0.3274 - mse: 0.2240 - pearson_correlation: 1.1524e-16 - r2_keras: -107.1484 - rmse: 0.9050 - sae: 2735.9387 - sse: 3354.6289\n","Epoch 23: val_loss improved from 0.32573 to 0.32433, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - huber_loss: 0.0992 - loss: 0.2666 - mae: 0.3245 - mse: 0.2130 - pearson_correlation: 1.0769e-16 - r2_keras: -85.9783 - rmse: 0.8757 - sae: 1989.6782 - sse: 2410.9543 - val_huber_loss: 0.1598 - val_loss: 0.3243 - val_mae: 0.4332 - val_mse: 0.3332 - val_pearson_correlation: -2.6660e-16 - val_r2_keras: -43.7426 - val_rmse: 1.0893 - val_sae: 434.1996 - val_sse: 627.6547 - learning_rate: 2.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1045 - loss: 0.2690 - mae: 0.3231 - mse: 0.2192 - pearson_correlation: 8.1631e-16 - r2_keras: -106.9845 - rmse: 0.9043 - sae: 2732.3394 - sse: 3349.5454\n","Epoch 24: val_loss improved from 0.32433 to 0.32327, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0973 - loss: 0.2646 - mae: 0.3201 - mse: 0.2084 - pearson_correlation: 4.9489e-16 - r2_keras: -85.8815 - rmse: 0.8754 - sae: 1987.2452 - sse: 2407.7112 - val_huber_loss: 0.1587 - val_loss: 0.3233 - val_mae: 0.4322 - val_mse: 0.3310 - val_pearson_correlation: -4.9954e-17 - val_r2_keras: -43.7244 - val_rmse: 1.0890 - val_sae: 433.6740 - val_sse: 627.3994 - learning_rate: 2.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1028 - loss: 0.2673 - mae: 0.3194 - mse: 0.2154 - pearson_correlation: -6.5477e-16 - r2_keras: -106.6357 - rmse: 0.9028 - sae: 2725.5708 - sse: 3338.7261\n","Epoch 25: val_loss improved from 0.32327 to 0.32277, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.0956 - loss: 0.2629 - mae: 0.3163 - mse: 0.2047 - pearson_correlation: -4.3856e-16 - r2_keras: -85.6751 - rmse: 0.8747 - sae: 1982.7529 - sse: 2400.8049 - val_huber_loss: 0.1582 - val_loss: 0.3228 - val_mae: 0.4321 - val_mse: 0.3301 - val_pearson_correlation: -1.4986e-16 - val_r2_keras: -43.7199 - val_rmse: 1.0890 - val_sae: 433.3943 - val_sse: 627.3353 - learning_rate: 2.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1009 - loss: 0.2655 - mae: 0.3154 - mse: 0.2110 - pearson_correlation: 5.7488e-16 - r2_keras: -106.6201 - rmse: 0.9028 - sae: 2723.4099 - sse: 3338.2422\n","Epoch 26: val_loss improved from 0.32277 to 0.32184, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0938 - loss: 0.2611 - mae: 0.3122 - mse: 0.2004 - pearson_correlation: 3.7507e-16 - r2_keras: -85.6889 - rmse: 0.8748 - sae: 1981.3085 - sse: 2400.7666 - val_huber_loss: 0.1573 - val_loss: 0.3218 - val_mae: 0.4311 - val_mse: 0.3284 - val_pearson_correlation: -3.3322e-16 - val_r2_keras: -43.6678 - val_rmse: 1.0884 - val_sae: 432.7884 - val_sse: 626.6047 - learning_rate: 2.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0993 - loss: 0.2638 - mae: 0.3121 - mse: 0.2072 - pearson_correlation: -1.3651e-16 - r2_keras: -106.4403 - rmse: 0.9020 - sae: 2718.2153 - sse: 3332.6636\n","Epoch 27: val_loss improved from 0.32184 to 0.32093, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0921 - loss: 0.2594 - mae: 0.3087 - mse: 0.1968 - pearson_correlation: -1.4405e-16 - r2_keras: -85.5946 - rmse: 0.8746 - sae: 1977.8524 - sse: 2397.3479 - val_huber_loss: 0.1564 - val_loss: 0.3209 - val_mae: 0.4299 - val_mse: 0.3266 - val_pearson_correlation: -1.1674e-16 - val_r2_keras: -43.6164 - val_rmse: 1.0877 - val_sae: 432.2680 - val_sse: 625.8832 - learning_rate: 2.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0976 - loss: 0.2621 - mae: 0.3088 - mse: 0.2034 - pearson_correlation: 2.7002e-16 - r2_keras: -106.3335 - rmse: 0.9016 - sae: 2714.3572 - sse: 3329.3496\n","Epoch 28: val_loss improved from 0.32093 to 0.32002, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0905 - loss: 0.2578 - mae: 0.3053 - mse: 0.1932 - pearson_correlation: 9.8648e-17 - r2_keras: -85.5564 - rmse: 0.8746 - sae: 1975.3219 - sse: 2395.5254 - val_huber_loss: 0.1555 - val_loss: 0.3200 - val_mae: 0.4287 - val_mse: 0.3246 - val_pearson_correlation: -3.3368e-17 - val_r2_keras: -43.5844 - val_rmse: 1.0873 - val_sae: 431.8476 - val_sse: 625.4341 - learning_rate: 2.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0959 - loss: 0.2604 - mae: 0.3057 - mse: 0.1994 - pearson_correlation: -1.9704e-16 - r2_keras: -106.3061 - rmse: 0.9015 - sae: 2712.0381 - sse: 3328.5020\n","Epoch 29: val_loss improved from 0.32002 to 0.31935, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0889 - loss: 0.2561 - mae: 0.3020 - mse: 0.1894 - pearson_correlation: -8.2651e-17 - r2_keras: -85.5621 - rmse: 0.8747 - sae: 1973.7848 - sse: 2395.2407 - val_huber_loss: 0.1548 - val_loss: 0.3194 - val_mae: 0.4275 - val_mse: 0.3232 - val_pearson_correlation: 1.6700e-17 - val_r2_keras: -43.5376 - val_rmse: 1.0868 - val_sae: 431.3272 - val_sse: 624.7780 - learning_rate: 2.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0942 - loss: 0.2588 - mae: 0.3026 - mse: 0.1957 - pearson_correlation: 7.7005e-16 - r2_keras: -106.1377 - rmse: 0.9007 - sae: 2707.0627 - sse: 3323.2788\n","Epoch 30: val_loss improved from 0.31935 to 0.31899, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0873 - loss: 0.2546 - mae: 0.2989 - mse: 0.1858 - pearson_correlation: 5.4572e-16 - r2_keras: -85.4917 - rmse: 0.8746 - sae: 1970.5575 - sse: 2392.2498 - val_huber_loss: 0.1545 - val_loss: 0.3190 - val_mae: 0.4268 - val_mse: 0.3226 - val_pearson_correlation: -3.3432e-17 - val_r2_keras: -43.5131 - val_rmse: 1.0865 - val_sae: 431.0121 - val_sse: 624.4351 - learning_rate: 2.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0927 - loss: 0.2572 - mae: 0.2995 - mse: 0.1921 - pearson_correlation: -1.2832e-16 - r2_keras: -106.1744 - rmse: 0.9009 - sae: 2705.4199 - sse: 3324.4165\n","Epoch 31: val_loss improved from 0.31899 to 0.31863, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0859 - loss: 0.2531 - mae: 0.2956 - mse: 0.1825 - pearson_correlation: -1.4894e-17 - r2_keras: -85.5343 - rmse: 0.8749 - sae: 1969.4680 - sse: 2393.2212 - val_huber_loss: 0.1541 - val_loss: 0.3186 - val_mae: 0.4256 - val_mse: 0.3220 - val_pearson_correlation: 1.1730e-16 - val_r2_keras: -43.4066 - val_rmse: 1.0852 - val_sae: 430.2460 - val_sse: 622.9402 - learning_rate: 2.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0912 - loss: 0.2557 - mae: 0.2963 - mse: 0.1887 - pearson_correlation: -1.4212e-15 - r2_keras: -106.0603 - rmse: 0.9004 - sae: 2701.2119 - sse: 3320.8760\n","Epoch 32: val_loss improved from 0.31863 to 0.31788, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0844 - loss: 0.2516 - mae: 0.2924 - mse: 0.1792 - pearson_correlation: -9.1123e-16 - r2_keras: -85.4787 - rmse: 0.8748 - sae: 1966.6401 - sse: 2391.1013 - val_huber_loss: 0.1534 - val_loss: 0.3179 - val_mae: 0.4243 - val_mse: 0.3203 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -43.3614 - val_rmse: 1.0846 - val_sae: 429.7910 - val_sse: 622.3065 - learning_rate: 2.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0898 - loss: 0.2543 - mae: 0.2935 - mse: 0.1856 - pearson_correlation: -4.5309e-16 - r2_keras: -106.0035 - rmse: 0.9002 - sae: 2697.9834 - sse: 3319.1160\n","Epoch 33: val_loss improved from 0.31788 to 0.31777, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0831 - loss: 0.2502 - mae: 0.2896 - mse: 0.1762 - pearson_correlation: -2.6992e-16 - r2_keras: -85.4736 - rmse: 0.8749 - sae: 1964.5023 - sse: 2390.3120 - val_huber_loss: 0.1533 - val_loss: 0.3178 - val_mae: 0.4239 - val_mse: 0.3202 - val_pearson_correlation: 4.5339e-16 - val_r2_keras: -43.3380 - val_rmse: 1.0843 - val_sae: 429.4714 - val_sse: 621.9786 - learning_rate: 2.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0883 - loss: 0.2528 - mae: 0.2904 - mse: 0.1822 - pearson_correlation: -5.6463e-16 - r2_keras: -106.0976 - rmse: 0.9006 - sae: 2697.4651 - sse: 3322.0325\n","Epoch 34: val_loss improved from 0.31777 to 0.31737, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0816 - loss: 0.2487 - mae: 0.2863 - mse: 0.1729 - pearson_correlation: -4.3259e-16 - r2_keras: -85.5525 - rmse: 0.8753 - sae: 1964.1371 - sse: 2392.4460 - val_huber_loss: 0.1529 - val_loss: 0.3174 - val_mae: 0.4228 - val_mse: 0.3195 - val_pearson_correlation: 1.5125e-16 - val_r2_keras: -43.2841 - val_rmse: 1.0837 - val_sae: 428.9722 - val_sse: 621.2217 - learning_rate: 2.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0868 - loss: 0.2513 - mae: 0.2873 - mse: 0.1789 - pearson_correlation: -7.9521e-17 - r2_keras: -106.0838 - rmse: 0.9005 - sae: 2694.5811 - sse: 3321.6050\n","Epoch 35: val_loss did not improve from 0.31737\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0802 - loss: 0.2473 - mae: 0.2833 - mse: 0.1698 - pearson_correlation: -6.7004e-17 - r2_keras: -85.5849 - rmse: 0.8756 - sae: 1962.2405 - sse: 2392.6489 - val_huber_loss: 0.1530 - val_loss: 0.3175 - val_mae: 0.4226 - val_mse: 0.3200 - val_pearson_correlation: 1.0080e-16 - val_r2_keras: -43.3060 - val_rmse: 1.0839 - val_sae: 428.8539 - val_sse: 621.5290 - learning_rate: 2.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0853 - loss: 0.2498 - mae: 0.2844 - mse: 0.1755 - pearson_correlation: -1.9026e-16 - r2_keras: -106.1868 - rmse: 0.9010 - sae: 2693.9001 - sse: 3324.8018\n","Epoch 36: val_loss did not improve from 0.31737\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0787 - loss: 0.2458 - mae: 0.2803 - mse: 0.1665 - pearson_correlation: -9.4940e-17 - r2_keras: -85.6803 - rmse: 0.8762 - sae: 1961.8298 - sse: 2395.0938 - val_huber_loss: 0.1529 - val_loss: 0.3174 - val_mae: 0.4217 - val_mse: 0.3201 - val_pearson_correlation: -2.1864e-16 - val_r2_keras: -43.2468 - val_rmse: 1.0832 - val_sae: 428.2989 - val_sse: 620.6985 - learning_rate: 2.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0836 - loss: 0.2481 - mae: 0.2810 - mse: 0.1719 - pearson_correlation: 1.3849e-15 - r2_keras: -106.2020 - rmse: 0.9010 - sae: 2691.2637 - sse: 3325.2729\n","Epoch 37: val_loss improved from 0.31737 to 0.31702, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0771 - loss: 0.2442 - mae: 0.2769 - mse: 0.1630 - pearson_correlation: 8.9738e-16 - r2_keras: -85.6986 - rmse: 0.8763 - sae: 1960.0717 - sse: 2395.5042 - val_huber_loss: 0.1525 - val_loss: 0.3170 - val_mae: 0.4208 - val_mse: 0.3193 - val_pearson_correlation: -4.3718e-16 - val_r2_keras: -43.2305 - val_rmse: 1.0830 - val_sae: 427.9744 - val_sse: 620.4702 - learning_rate: 2.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0820 - loss: 0.2465 - mae: 0.2780 - mse: 0.1683 - pearson_correlation: 1.2331e-15 - r2_keras: -106.2608 - rmse: 0.9013 - sae: 2689.9014 - sse: 3327.0947\n","Epoch 38: val_loss did not improve from 0.31702\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0756 - loss: 0.2426 - mae: 0.2739 - mse: 0.1597 - pearson_correlation: 7.8532e-16 - r2_keras: -85.7650 - rmse: 0.8767 - sae: 1959.2086 - sse: 2397.0378 - val_huber_loss: 0.1527 - val_loss: 0.3172 - val_mae: 0.4207 - val_mse: 0.3198 - val_pearson_correlation: -5.2123e-16 - val_r2_keras: -43.2378 - val_rmse: 1.0831 - val_sae: 427.8308 - val_sse: 620.5720 - learning_rate: 2.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0805 - loss: 0.2450 - mae: 0.2752 - mse: 0.1650 - pearson_correlation: -1.2267e-16 - r2_keras: -106.3738 - rmse: 0.9017 - sae: 2689.4868 - sse: 3330.6003\n","Epoch 39: val_loss improved from 0.31702 to 0.31688, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0742 - loss: 0.2411 - mae: 0.2710 - mse: 0.1565 - pearson_correlation: -1.2540e-16 - r2_keras: -85.8675 - rmse: 0.8773 - sae: 1958.9543 - sse: 2399.6936 - val_huber_loss: 0.1524 - val_loss: 0.3169 - val_mae: 0.4198 - val_mse: 0.3193 - val_pearson_correlation: 1.3455e-16 - val_r2_keras: -43.2059 - val_rmse: 1.0827 - val_sae: 427.3753 - val_sse: 620.1255 - learning_rate: 2.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0791 - loss: 0.2435 - mae: 0.2730 - mse: 0.1619 - pearson_correlation: -7.3851e-16 - r2_keras: -106.4546 - rmse: 0.9021 - sae: 2688.5283 - sse: 3333.1077\n","Epoch 40: val_loss improved from 0.31688 to 0.31658, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0729 - loss: 0.2398 - mae: 0.2687 - mse: 0.1536 - pearson_correlation: -5.0816e-16 - r2_keras: -85.9528 - rmse: 0.8778 - sae: 1958.3632 - sse: 2401.7339 - val_huber_loss: 0.1521 - val_loss: 0.3166 - val_mae: 0.4192 - val_mse: 0.3186 - val_pearson_correlation: -5.0425e-17 - val_r2_keras: -43.2207 - val_rmse: 1.0829 - val_sae: 427.1702 - val_sse: 620.3329 - learning_rate: 2.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0777 - loss: 0.2422 - mae: 0.2707 - mse: 0.1591 - pearson_correlation: 4.6855e-16 - r2_keras: -106.5238 - rmse: 0.9024 - sae: 2688.1047 - sse: 3335.2551\n","Epoch 41: val_loss improved from 0.31658 to 0.31569, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0715 - loss: 0.2384 - mae: 0.2659 - mse: 0.1507 - pearson_correlation: 2.6980e-16 - r2_keras: -85.9849 - rmse: 0.8778 - sae: 1957.9565 - sse: 2403.0005 - val_huber_loss: 0.1512 - val_loss: 0.3157 - val_mae: 0.4170 - val_mse: 0.3168 - val_pearson_correlation: -2.5308e-16 - val_r2_keras: -43.0581 - val_rmse: 1.0809 - val_sae: 426.1105 - val_sse: 618.0522 - learning_rate: 2.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0765 - loss: 0.2410 - mae: 0.2685 - mse: 0.1565 - pearson_correlation: 3.9275e-16 - r2_keras: -106.4635 - rmse: 0.9021 - sae: 2685.4097 - sse: 3333.3848\n","Epoch 42: val_loss improved from 0.31569 to 0.31525, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0703 - loss: 0.2372 - mae: 0.2636 - mse: 0.1482 - pearson_correlation: 1.6402e-16 - r2_keras: -85.9650 - rmse: 0.8778 - sae: 1956.1655 - sse: 2401.9919 - val_huber_loss: 0.1508 - val_loss: 0.3153 - val_mae: 0.4160 - val_mse: 0.3159 - val_pearson_correlation: 1.1823e-16 - val_r2_keras: -43.0134 - val_rmse: 1.0803 - val_sae: 425.6580 - val_sse: 617.4254 - learning_rate: 2.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0752 - loss: 0.2397 - mae: 0.2664 - mse: 0.1537 - pearson_correlation: 5.1972e-16 - r2_keras: -106.4856 - rmse: 0.9022 - sae: 2684.9829 - sse: 3334.0703\n","Epoch 43: val_loss improved from 0.31525 to 0.31440, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.0690 - loss: 0.2359 - mae: 0.2613 - mse: 0.1455 - pearson_correlation: 3.8990e-16 - r2_keras: -85.9953 - rmse: 0.8781 - sae: 1955.8501 - sse: 2402.6309 - val_huber_loss: 0.1499 - val_loss: 0.3144 - val_mae: 0.4151 - val_mse: 0.3141 - val_pearson_correlation: 2.0289e-16 - val_r2_keras: -42.9795 - val_rmse: 1.0799 - val_sae: 425.1288 - val_sse: 616.9496 - learning_rate: 2.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0739 - loss: 0.2383 - mae: 0.2638 - mse: 0.1509 - pearson_correlation: 3.5741e-16 - r2_keras: -106.6189 - rmse: 0.9028 - sae: 2684.8408 - sse: 3338.2024\n","Epoch 44: val_loss improved from 0.31440 to 0.31429, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0678 - loss: 0.2346 - mae: 0.2588 - mse: 0.1429 - pearson_correlation: 2.0294e-16 - r2_keras: -86.1470 - rmse: 0.8790 - sae: 1955.9603 - sse: 2406.1235 - val_huber_loss: 0.1498 - val_loss: 0.3143 - val_mae: 0.4143 - val_mse: 0.3141 - val_pearson_correlation: -1.1870e-16 - val_r2_keras: -42.8510 - val_rmse: 1.0784 - val_sae: 424.3166 - val_sse: 615.1464 - learning_rate: 2.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0727 - loss: 0.2372 - mae: 0.2617 - mse: 0.1485 - pearson_correlation: -2.8804e-16 - r2_keras: -106.6185 - rmse: 0.9028 - sae: 2683.8760 - sse: 3338.1924\n","Epoch 45: val_loss improved from 0.31429 to 0.31405, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0666 - loss: 0.2335 - mae: 0.2565 - mse: 0.1404 - pearson_correlation: -2.3327e-16 - r2_keras: -86.1388 - rmse: 0.8789 - sae: 1955.2415 - sse: 2406.0237 - val_huber_loss: 0.1496 - val_loss: 0.3140 - val_mae: 0.4134 - val_mse: 0.3138 - val_pearson_correlation: 2.0393e-16 - val_r2_keras: -42.7506 - val_rmse: 1.0771 - val_sae: 423.6368 - val_sse: 613.7380 - learning_rate: 2.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0717 - loss: 0.2361 - mae: 0.2596 - mse: 0.1462 - pearson_correlation: 1.8369e-16 - r2_keras: -106.5763 - rmse: 0.9026 - sae: 2681.9468 - sse: 3336.8818\n","Epoch 46: val_loss improved from 0.31405 to 0.31378, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0655 - loss: 0.2324 - mae: 0.2541 - mse: 0.1381 - pearson_correlation: 9.4937e-17 - r2_keras: -86.0989 - rmse: 0.8787 - sae: 1953.8431 - sse: 2405.0115 - val_huber_loss: 0.1493 - val_loss: 0.3138 - val_mae: 0.4127 - val_mse: 0.3135 - val_pearson_correlation: -1.1931e-16 - val_r2_keras: -42.6355 - val_rmse: 1.0757 - val_sae: 422.9070 - val_sse: 612.1240 - learning_rate: 2.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0706 - loss: 0.2351 - mae: 0.2574 - mse: 0.1440 - pearson_correlation: -1.1738e-16 - r2_keras: -106.5417 - rmse: 0.9024 - sae: 2680.2905 - sse: 3335.8093\n","Epoch 47: val_loss improved from 0.31378 to 0.31344, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - huber_loss: 0.0644 - loss: 0.2313 - mae: 0.2519 - mse: 0.1359 - pearson_correlation: -1.4690e-16 - r2_keras: -86.1034 - rmse: 0.8788 - sae: 1952.7603 - sse: 2404.6201 - val_huber_loss: 0.1490 - val_loss: 0.3134 - val_mae: 0.4120 - val_mse: 0.3128 - val_pearson_correlation: -6.8216e-16 - val_r2_keras: -42.6017 - val_rmse: 1.0753 - val_sae: 422.5285 - val_sse: 611.6492 - learning_rate: 2.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0695 - loss: 0.2339 - mae: 0.2552 - mse: 0.1416 - pearson_correlation: 5.5916e-16 - r2_keras: -106.5785 - rmse: 0.9026 - sae: 2679.3247 - sse: 3336.9512\n","Epoch 48: val_loss improved from 0.31344 to 0.31331, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - huber_loss: 0.0633 - loss: 0.2302 - mae: 0.2494 - mse: 0.1335 - pearson_correlation: 3.8845e-16 - r2_keras: -86.1370 - rmse: 0.8790 - sae: 1952.0747 - sse: 2405.4880 - val_huber_loss: 0.1489 - val_loss: 0.3133 - val_mae: 0.4111 - val_mse: 0.3128 - val_pearson_correlation: -1.7086e-17 - val_r2_keras: -42.5341 - val_rmse: 1.0745 - val_sae: 421.9704 - val_sse: 610.7004 - learning_rate: 2.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0685 - loss: 0.2329 - mae: 0.2532 - mse: 0.1395 - pearson_correlation: -2.8800e-17 - r2_keras: -106.5105 - rmse: 0.9023 - sae: 2677.6484 - sse: 3334.8425\n","Epoch 49: val_loss improved from 0.31331 to 0.31259, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0622 - loss: 0.2291 - mae: 0.2472 - mse: 0.1313 - pearson_correlation: 6.2528e-18 - r2_keras: -86.1022 - rmse: 0.8789 - sae: 1950.9058 - sse: 2404.2053 - val_huber_loss: 0.1481 - val_loss: 0.3126 - val_mae: 0.4092 - val_mse: 0.3116 - val_pearson_correlation: -1.8851e-16 - val_r2_keras: -42.3894 - val_rmse: 1.0727 - val_sae: 420.9746 - val_sse: 608.6712 - learning_rate: 2.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.2319 - mae: 0.2514 - mse: 0.1372 - pearson_correlation: -4.1935e-16 - r2_keras: -106.5079 - rmse: 0.9023 - sae: 2676.5166 - sse: 3334.7603\n","Epoch 50: val_loss improved from 0.31259 to 0.31170, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0612 - loss: 0.2281 - mae: 0.2453 - mse: 0.1291 - pearson_correlation: -2.0240e-16 - r2_keras: -86.1267 - rmse: 0.8792 - sae: 1950.1865 - sse: 2404.4587 - val_huber_loss: 0.1472 - val_loss: 0.3117 - val_mae: 0.4082 - val_mse: 0.3096 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -42.0591 - val_rmse: 1.0686 - val_sae: 419.4117 - val_sse: 604.0379 - learning_rate: 2.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0663 - loss: 0.2308 - mae: 0.2489 - mse: 0.1349 - pearson_correlation: -2.3315e-16 - r2_keras: -106.5907 - rmse: 0.9027 - sae: 2677.0688 - sse: 3337.3296\n","Epoch 51: val_loss improved from 0.31170 to 0.31152, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0600 - loss: 0.2269 - mae: 0.2426 - mse: 0.1267 - pearson_correlation: -1.4756e-16 - r2_keras: -86.0959 - rmse: 0.8786 - sae: 1950.0946 - sse: 2405.1626 - val_huber_loss: 0.1471 - val_loss: 0.3115 - val_mae: 0.4072 - val_mse: 0.3094 - val_pearson_correlation: -8.6455e-17 - val_r2_keras: -42.0558 - val_rmse: 1.0685 - val_sae: 419.0703 - val_sse: 603.9911 - learning_rate: 2.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0656 - loss: 0.2300 - mae: 0.2475 - mse: 0.1334 - pearson_correlation: 9.0094e-17 - r2_keras: -106.3613 - rmse: 0.9017 - sae: 2672.0527 - sse: 3330.2134\n","Epoch 52: val_loss did not improve from 0.31152\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0592 - loss: 0.2261 - mae: 0.2409 - mse: 0.1251 - pearson_correlation: 1.2444e-16 - r2_keras: -86.0446 - rmse: 0.8789 - sae: 1947.1012 - sse: 2401.6111 - val_huber_loss: 0.1471 - val_loss: 0.3116 - val_mae: 0.4065 - val_mse: 0.3098 - val_pearson_correlation: 8.6480e-17 - val_r2_keras: -42.0502 - val_rmse: 1.0685 - val_sae: 418.8615 - val_sse: 603.9130 - learning_rate: 2.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0646 - loss: 0.2290 - mae: 0.2454 - mse: 0.1313 - pearson_correlation: -2.7988e-16 - r2_keras: -106.4399 - rmse: 0.9020 - sae: 2672.0830 - sse: 3332.6504\n","Epoch 53: val_loss improved from 0.31152 to 0.31023, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0581 - loss: 0.2251 - mae: 0.2385 - mse: 0.1230 - pearson_correlation: -2.3437e-16 - r2_keras: -86.0983 - rmse: 0.8791 - sae: 1947.0853 - sse: 2403.2507 - val_huber_loss: 0.1458 - val_loss: 0.3102 - val_mae: 0.4052 - val_mse: 0.3069 - val_pearson_correlation: 3.1372e-16 - val_r2_keras: -41.7644 - val_rmse: 1.0649 - val_sae: 417.3721 - val_sse: 599.9038 - learning_rate: 2.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0636 - loss: 0.2280 - mae: 0.2430 - mse: 0.1292 - pearson_correlation: -2.8549e-16 - r2_keras: -106.6390 - rmse: 0.9029 - sae: 2673.8115 - sse: 3338.8276\n","Epoch 54: val_loss improved from 0.31023 to 0.31005, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0572 - loss: 0.2241 - mae: 0.2363 - mse: 0.1210 - pearson_correlation: -2.1272e-16 - r2_keras: -86.2514 - rmse: 0.8799 - sae: 1948.1390 - sse: 2407.6077 - val_huber_loss: 0.1456 - val_loss: 0.3101 - val_mae: 0.4042 - val_mse: 0.3067 - val_pearson_correlation: -1.2179e-16 - val_r2_keras: -41.7972 - val_rmse: 1.0653 - val_sae: 417.2304 - val_sse: 600.3636 - learning_rate: 2.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0628 - loss: 0.2273 - mae: 0.2414 - mse: 0.1276 - pearson_correlation: 2.9660e-16 - r2_keras: -106.5066 - rmse: 0.9023 - sae: 2671.0386 - sse: 3334.7195\n","Epoch 55: val_loss did not improve from 0.31005\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0563 - loss: 0.2233 - mae: 0.2342 - mse: 0.1192 - pearson_correlation: 1.8509e-16 - r2_keras: -86.1806 - rmse: 0.8797 - sae: 1946.3683 - sse: 2405.0742 - val_huber_loss: 0.1459 - val_loss: 0.3103 - val_mae: 0.4046 - val_mse: 0.3076 - val_pearson_correlation: 1.0454e-16 - val_r2_keras: -41.7749 - val_rmse: 1.0650 - val_sae: 416.8810 - val_sse: 600.0508 - learning_rate: 2.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0621 - loss: 0.2266 - mae: 0.2402 - mse: 0.1261 - pearson_correlation: 5.1993e-16 - r2_keras: -106.5556 - rmse: 0.9025 - sae: 2671.0879 - sse: 3336.2393\n","Epoch 56: val_loss improved from 0.31005 to 0.30856, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0555 - loss: 0.2225 - mae: 0.2326 - mse: 0.1176 - pearson_correlation: 2.7649e-16 - r2_keras: -86.2735 - rmse: 0.8803 - sae: 1946.4713 - sse: 2406.7935 - val_huber_loss: 0.1441 - val_loss: 0.3086 - val_mae: 0.4021 - val_mse: 0.3036 - val_pearson_correlation: 2.0221e-16 - val_r2_keras: -41.4077 - val_rmse: 1.0605 - val_sae: 414.8836 - val_sse: 594.8994 - learning_rate: 2.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0613 - loss: 0.2258 - mae: 0.2376 - mse: 0.1245 - pearson_correlation: -2.9022e-16 - r2_keras: -106.3506 - rmse: 0.9016 - sae: 2667.2048 - sse: 3329.8804\n","Epoch 57: val_loss did not improve from 0.30856\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0546 - loss: 0.2217 - mae: 0.2301 - mse: 0.1159 - pearson_correlation: -2.1687e-16 - r2_keras: -86.0412 - rmse: 0.8789 - sae: 1943.4794 - sse: 2401.4326 - val_huber_loss: 0.1450 - val_loss: 0.3095 - val_mae: 0.4027 - val_mse: 0.3061 - val_pearson_correlation: 1.7561e-17 - val_r2_keras: -41.4944 - val_rmse: 1.0615 - val_sae: 415.2419 - val_sse: 596.1163 - learning_rate: 2.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0608 - loss: 0.2252 - mae: 0.2372 - mse: 0.1233 - pearson_correlation: -2.3473e-16 - r2_keras: -106.4504 - rmse: 0.9021 - sae: 2667.7441 - sse: 3332.9756\n","Epoch 58: val_loss improved from 0.30856 to 0.30809, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0539 - loss: 0.2210 - mae: 0.2293 - mse: 0.1146 - pearson_correlation: -2.1244e-16 - r2_keras: -86.2346 - rmse: 0.8803 - sae: 1944.2406 - sse: 2404.9839 - val_huber_loss: 0.1437 - val_loss: 0.3081 - val_mae: 0.4004 - val_mse: 0.3028 - val_pearson_correlation: -3.3262e-16 - val_r2_keras: -41.5730 - val_rmse: 1.0625 - val_sae: 415.0411 - val_sse: 597.2189 - learning_rate: 2.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0599 - loss: 0.2243 - mae: 0.2343 - mse: 0.1215 - pearson_correlation: -3.1865e-16 - r2_keras: -106.4385 - rmse: 0.9020 - sae: 2667.1851 - sse: 3332.6091\n","Epoch 59: val_loss improved from 0.30809 to 0.30745, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0530 - loss: 0.2201 - mae: 0.2263 - mse: 0.1127 - pearson_correlation: -1.8343e-16 - r2_keras: -86.1997 - rmse: 0.8800 - sae: 1943.7936 - sse: 2404.4233 - val_huber_loss: 0.1431 - val_loss: 0.3075 - val_mae: 0.3995 - val_mse: 0.3021 - val_pearson_correlation: -4.3480e-16 - val_r2_keras: -41.0699 - val_rmse: 1.0562 - val_sae: 412.6547 - val_sse: 590.1615 - learning_rate: 2.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0593 - loss: 0.2237 - mae: 0.2332 - mse: 0.1201 - pearson_correlation: -7.2983e-16 - r2_keras: -106.5756 - rmse: 0.9026 - sae: 2667.8228 - sse: 3336.8604\n","Epoch 60: val_loss improved from 0.30745 to 0.30688, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0523 - loss: 0.2194 - mae: 0.2250 - mse: 0.1113 - pearson_correlation: -5.2823e-16 - r2_keras: -86.3307 - rmse: 0.8808 - sae: 1944.1527 - sse: 2407.7217 - val_huber_loss: 0.1425 - val_loss: 0.3069 - val_mae: 0.3974 - val_mse: 0.3005 - val_pearson_correlation: 4.4164e-16 - val_r2_keras: -41.2360 - val_rmse: 1.0583 - val_sae: 413.0037 - val_sse: 592.4911 - learning_rate: 2.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0586 - loss: 0.2230 - mae: 0.2311 - mse: 0.1188 - pearson_correlation: 7.0879e-16 - r2_keras: -106.3649 - rmse: 0.9017 - sae: 2663.6714 - sse: 3330.3247\n","Epoch 61: val_loss improved from 0.30688 to 0.30679, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.0515 - loss: 0.2186 - mae: 0.2227 - mse: 0.1098 - pearson_correlation: 4.8818e-16 - r2_keras: -86.1944 - rmse: 0.8802 - sae: 1941.4825 - sse: 2403.4136 - val_huber_loss: 0.1424 - val_loss: 0.3068 - val_mae: 0.3965 - val_mse: 0.3011 - val_pearson_correlation: 1.2408e-16 - val_r2_keras: -41.1211 - val_rmse: 1.0569 - val_sae: 412.3445 - val_sse: 590.8790 - learning_rate: 2.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0579 - loss: 0.2223 - mae: 0.2302 - mse: 0.1174 - pearson_correlation: -3.3128e-16 - r2_keras: -106.5475 - rmse: 0.9025 - sae: 2665.9390 - sse: 3335.9893\n","Epoch 62: val_loss improved from 0.30679 to 0.30535, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0507 - loss: 0.2179 - mae: 0.2210 - mse: 0.1083 - pearson_correlation: -1.5063e-16 - r2_keras: -86.3761 - rmse: 0.8813 - sae: 1943.0526 - sse: 2407.8933 - val_huber_loss: 0.1410 - val_loss: 0.3053 - val_mae: 0.3944 - val_mse: 0.2976 - val_pearson_correlation: 1.5111e-16 - val_r2_keras: -41.0191 - val_rmse: 1.0556 - val_sae: 411.4631 - val_sse: 589.4490 - learning_rate: 2.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0572 - loss: 0.2216 - mae: 0.2281 - mse: 0.1159 - pearson_correlation: -3.2051e-17 - r2_keras: -106.4921 - rmse: 0.9022 - sae: 2664.1489 - sse: 3334.2712\n","Epoch 63: val_loss improved from 0.30535 to 0.30479, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0499 - loss: 0.2172 - mae: 0.2189 - mse: 0.1068 - pearson_correlation: -1.7309e-17 - r2_keras: -86.3907 - rmse: 0.8816 - sae: 1942.0281 - sse: 2407.3525 - val_huber_loss: 0.1404 - val_loss: 0.3048 - val_mae: 0.3920 - val_mse: 0.2969 - val_pearson_correlation: -8.9792e-18 - val_r2_keras: -40.5728 - val_rmse: 1.0500 - val_sae: 409.2824 - val_sse: 583.1884 - learning_rate: 2.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0566 - loss: 0.2210 - mae: 0.2254 - mse: 0.1147 - pearson_correlation: 6.0869e-16 - r2_keras: -106.4837 - rmse: 0.9022 - sae: 2663.4114 - sse: 3334.0083\n","Epoch 64: val_loss improved from 0.30479 to 0.30460, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0493 - loss: 0.2165 - mae: 0.2162 - mse: 0.1054 - pearson_correlation: 4.2068e-16 - r2_keras: -86.3138 - rmse: 0.8809 - sae: 1941.2067 - sse: 2406.3411 - val_huber_loss: 0.1402 - val_loss: 0.3046 - val_mae: 0.3932 - val_mse: 0.2962 - val_pearson_correlation: -4.4845e-17 - val_r2_keras: -40.7225 - val_rmse: 1.0519 - val_sae: 409.7461 - val_sse: 585.2870 - learning_rate: 2.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0560 - loss: 0.2204 - mae: 0.2246 - mse: 0.1135 - pearson_correlation: 4.0566e-16 - r2_keras: -106.4271 - rmse: 0.9020 - sae: 2661.1851 - sse: 3332.2544\n","Epoch 65: val_loss improved from 0.30460 to 0.30321, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0486 - loss: 0.2159 - mae: 0.2150 - mse: 0.1041 - pearson_correlation: 3.1950e-16 - r2_keras: -86.3740 - rmse: 0.8816 - sae: 1940.0918 - sse: 2406.3210 - val_huber_loss: 0.1388 - val_loss: 0.3032 - val_mae: 0.3897 - val_mse: 0.2930 - val_pearson_correlation: 9.8738e-17 - val_r2_keras: -40.6313 - val_rmse: 1.0507 - val_sae: 408.6967 - val_sse: 584.0084 - learning_rate: 2.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0554 - loss: 0.2197 - mae: 0.2228 - mse: 0.1120 - pearson_correlation: -2.7043e-16 - r2_keras: -106.7089 - rmse: 0.9031 - sae: 2664.1003 - sse: 3340.9946\n","Epoch 66: val_loss did not improve from 0.30321\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0478 - loss: 0.2152 - mae: 0.2130 - mse: 0.1026 - pearson_correlation: -1.7076e-16 - r2_keras: -86.5545 - rmse: 0.8824 - sae: 1941.9349 - sse: 2412.0610 - val_huber_loss: 0.1390 - val_loss: 0.3034 - val_mae: 0.3898 - val_mse: 0.2936 - val_pearson_correlation: 4.5893e-16 - val_r2_keras: -40.5553 - val_rmse: 1.0497 - val_sae: 408.1364 - val_sse: 582.9429 - learning_rate: 2.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0548 - loss: 0.2192 - mae: 0.2213 - mse: 0.1109 - pearson_correlation: 3.1652e-16 - r2_keras: -106.5731 - rmse: 0.9026 - sae: 2661.3625 - sse: 3336.7822\n","Epoch 67: val_loss improved from 0.30321 to 0.30251, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0472 - loss: 0.2146 - mae: 0.2112 - mse: 0.1014 - pearson_correlation: 1.8918e-16 - r2_keras: -86.5134 - rmse: 0.8824 - sae: 1940.2529 - sse: 2409.8333 - val_huber_loss: 0.1382 - val_loss: 0.3025 - val_mae: 0.3883 - val_mse: 0.2923 - val_pearson_correlation: -1.7360e-16 - val_r2_keras: -40.0019 - val_rmse: 1.0427 - val_sae: 405.7266 - val_sse: 575.1788 - learning_rate: 2.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0543 - loss: 0.2187 - mae: 0.2198 - mse: 0.1098 - pearson_correlation: -9.8353e-17 - r2_keras: -106.6799 - rmse: 0.9030 - sae: 2662.1353 - sse: 3340.0972\n","Epoch 68: val_loss improved from 0.30251 to 0.30233, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0466 - loss: 0.2140 - mae: 0.2098 - mse: 0.1002 - pearson_correlation: -1.0674e-16 - r2_keras: -86.5510 - rmse: 0.8824 - sae: 1940.5127 - sse: 2411.6479 - val_huber_loss: 0.1380 - val_loss: 0.3023 - val_mae: 0.3897 - val_mse: 0.2912 - val_pearson_correlation: 2.5338e-16 - val_r2_keras: -40.4058 - val_rmse: 1.0479 - val_sae: 407.1579 - val_sse: 580.8445 - learning_rate: 2.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0536 - loss: 0.2180 - mae: 0.2178 - mse: 0.1084 - pearson_correlation: -2.1501e-16 - r2_keras: -106.4552 - rmse: 0.9021 - sae: 2657.9602 - sse: 3333.1270\n","Epoch 69: val_loss improved from 0.30233 to 0.30147, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0459 - loss: 0.2133 - mae: 0.2077 - mse: 0.0988 - pearson_correlation: -8.1868e-17 - r2_keras: -86.4856 - rmse: 0.8825 - sae: 1938.1566 - sse: 2407.9915 - val_huber_loss: 0.1371 - val_loss: 0.3015 - val_mae: 0.3850 - val_mse: 0.2898 - val_pearson_correlation: 4.5754e-16 - val_r2_keras: -39.8945 - val_rmse: 1.0414 - val_sae: 404.4351 - val_sse: 573.6719 - learning_rate: 2.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0530 - loss: 0.2173 - mae: 0.2156 - mse: 0.1070 - pearson_correlation: -6.6467e-16 - r2_keras: -106.9856 - rmse: 0.9043 - sae: 2663.8521 - sse: 3349.5781\n","Epoch 70: val_loss did not improve from 0.30147\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0452 - loss: 0.2126 - mae: 0.2054 - mse: 0.0973 - pearson_correlation: -4.9562e-16 - r2_keras: -86.7751 - rmse: 0.8834 - sae: 1941.7296 - sse: 2418.2070 - val_huber_loss: 0.1375 - val_loss: 0.3018 - val_mae: 0.3885 - val_mse: 0.2901 - val_pearson_correlation: 9.1027e-18 - val_r2_keras: -40.2116 - val_rmse: 1.0454 - val_sae: 406.1330 - val_sse: 578.1204 - learning_rate: 2.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0524 - loss: 0.2168 - mae: 0.2145 - mse: 0.1059 - pearson_correlation: 4.9481e-16 - r2_keras: -106.7427 - rmse: 0.9033 - sae: 2659.7725 - sse: 3342.0422\n","Epoch 71: val_loss did not improve from 0.30147\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0446 - loss: 0.2120 - mae: 0.2040 - mse: 0.0961 - pearson_correlation: 3.5786e-16 - r2_keras: -86.7459 - rmse: 0.8839 - sae: 1939.4904 - sse: 2414.7407 - val_huber_loss: 0.1375 - val_loss: 0.3018 - val_mae: 0.3858 - val_mse: 0.2912 - val_pearson_correlation: -6.4194e-17 - val_r2_keras: -39.8650 - val_rmse: 1.0410 - val_sae: 404.3948 - val_sse: 573.2589 - learning_rate: 2.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0518 - loss: 0.2162 - mae: 0.2131 - mse: 0.1046 - pearson_correlation: -7.1027e-16 - r2_keras: -106.9844 - rmse: 0.9043 - sae: 2662.2544 - sse: 3349.5422\n","Epoch 72: val_loss improved from 0.30147 to 0.30050, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0440 - loss: 0.2114 - mae: 0.2025 - mse: 0.0948 - pearson_correlation: -4.5730e-16 - r2_keras: -86.9174 - rmse: 0.8847 - sae: 1941.0538 - sse: 2419.8613 - val_huber_loss: 0.1362 - val_loss: 0.3005 - val_mae: 0.3854 - val_mse: 0.2874 - val_pearson_correlation: 1.7388e-16 - val_r2_keras: -39.9676 - val_rmse: 1.0423 - val_sae: 404.5244 - val_sse: 574.6984 - learning_rate: 2.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0513 - loss: 0.2156 - mae: 0.2119 - mse: 0.1034 - pearson_correlation: -4.1502e-16 - r2_keras: -107.1424 - rmse: 0.9050 - sae: 2662.9834 - sse: 3354.4412\n","Epoch 73: val_loss did not improve from 0.30050\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0433 - loss: 0.2108 - mae: 0.2009 - mse: 0.0935 - pearson_correlation: -3.0673e-16 - r2_keras: -87.0345 - rmse: 0.8853 - sae: 1941.5707 - sse: 2423.2659 - val_huber_loss: 0.1369 - val_loss: 0.3012 - val_mae: 0.3851 - val_mse: 0.2897 - val_pearson_correlation: -1.1903e-16 - val_r2_keras: -39.9267 - val_rmse: 1.0418 - val_sae: 403.9438 - val_sse: 574.1241 - learning_rate: 2.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0507 - loss: 0.2151 - mae: 0.2106 - mse: 0.1023 - pearson_correlation: 5.7037e-16 - r2_keras: -107.1783 - rmse: 0.9051 - sae: 2662.0146 - sse: 3355.5542\n","Epoch 74: val_loss improved from 0.30050 to 0.29939, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0427 - loss: 0.2102 - mae: 0.1994 - mse: 0.0924 - pearson_correlation: 4.1579e-16 - r2_keras: -87.1104 - rmse: 0.8858 - sae: 1941.0814 - sse: 2424.6182 - val_huber_loss: 0.1351 - val_loss: 0.2994 - val_mae: 0.3837 - val_mse: 0.2852 - val_pearson_correlation: -1.8446e-17 - val_r2_keras: -39.6574 - val_rmse: 1.0383 - val_sae: 402.4434 - val_sse: 570.3462 - learning_rate: 2.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0502 - loss: 0.2146 - mae: 0.2093 - mse: 0.1012 - pearson_correlation: 4.6980e-16 - r2_keras: -107.2940 - rmse: 0.9056 - sae: 2663.4595 - sse: 3359.1440\n","Epoch 75: val_loss did not improve from 0.29939\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0422 - loss: 0.2097 - mae: 0.1982 - mse: 0.0913 - pearson_correlation: 4.1682e-16 - r2_keras: -87.1815 - rmse: 0.8861 - sae: 1941.9548 - sse: 2426.9404 - val_huber_loss: 0.1366 - val_loss: 0.3009 - val_mae: 0.3848 - val_mse: 0.2890 - val_pearson_correlation: 2.9429e-16 - val_r2_keras: -39.7394 - val_rmse: 1.0394 - val_sae: 402.8744 - val_sse: 571.4970 - learning_rate: 2.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0497 - loss: 0.2140 - mae: 0.2078 - mse: 0.1002 - pearson_correlation: -5.1493e-17 - r2_keras: -106.8512 - rmse: 0.9037 - sae: 2656.7246 - sse: 3345.4102\n","Epoch 76: val_loss improved from 0.29939 to 0.29882, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0416 - loss: 0.2091 - mae: 0.1966 - mse: 0.0902 - pearson_correlation: -9.9030e-18 - r2_keras: -86.9590 - rmse: 0.8855 - sae: 1937.8158 - sse: 2418.6367 - val_huber_loss: 0.1345 - val_loss: 0.2988 - val_mae: 0.3811 - val_mse: 0.2841 - val_pearson_correlation: -7.3667e-17 - val_r2_keras: -39.6480 - val_rmse: 1.0382 - val_sae: 401.5956 - val_sse: 570.2148 - learning_rate: 2.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0492 - loss: 0.2135 - mae: 0.2069 - mse: 0.0991 - pearson_correlation: 1.0615e-15 - r2_keras: -107.3765 - rmse: 0.9059 - sae: 2662.9900 - sse: 3361.7051\n","Epoch 77: val_loss did not improve from 0.29882\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0411 - loss: 0.2086 - mae: 0.1952 - mse: 0.0891 - pearson_correlation: 7.4231e-16 - r2_keras: -87.3076 - rmse: 0.8869 - sae: 1941.8320 - sse: 2429.4802 - val_huber_loss: 0.1366 - val_loss: 0.3009 - val_mae: 0.3851 - val_mse: 0.2895 - val_pearson_correlation: 3.8824e-16 - val_r2_keras: -39.5396 - val_rmse: 1.0368 - val_sae: 401.9612 - val_sse: 568.6943 - learning_rate: 2.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0489 - loss: 0.2132 - mae: 0.2056 - mse: 0.0984 - pearson_correlation: 1.6358e-18 - r2_keras: -106.7773 - rmse: 0.9034 - sae: 2654.1890 - sse: 3343.1160\n","Epoch 78: val_loss improved from 0.29882 to 0.29817, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0408 - loss: 0.2082 - mae: 0.1944 - mse: 0.0884 - pearson_correlation: 3.0129e-17 - r2_keras: -87.0350 - rmse: 0.8864 - sae: 1936.5098 - sse: 2418.5774 - val_huber_loss: 0.1339 - val_loss: 0.2982 - val_mae: 0.3811 - val_mse: 0.2820 - val_pearson_correlation: -1.9149e-16 - val_r2_keras: -40.0257 - val_rmse: 1.0430 - val_sae: 403.3750 - val_sse: 575.5131 - learning_rate: 2.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0484 - loss: 0.2127 - mae: 0.2045 - mse: 0.0973 - pearson_correlation: 3.5428e-16 - r2_keras: -107.6729 - rmse: 0.9072 - sae: 2665.4119 - sse: 3370.8984\n","Epoch 79: val_loss did not improve from 0.29817\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0402 - loss: 0.2077 - mae: 0.1924 - mse: 0.0872 - pearson_correlation: 2.5387e-16 - r2_keras: -87.6744 - rmse: 0.8893 - sae: 1944.0481 - sse: 2437.5950 - val_huber_loss: 0.1345 - val_loss: 0.2988 - val_mae: 0.3816 - val_mse: 0.2840 - val_pearson_correlation: 9.2671e-17 - val_r2_keras: -39.3876 - val_rmse: 1.0349 - val_sae: 400.3060 - val_sse: 566.5615 - learning_rate: 2.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0480 - loss: 0.2123 - mae: 0.2029 - mse: 0.0965 - pearson_correlation: -3.5896e-16 - r2_keras: -107.4421 - rmse: 0.9062 - sae: 2660.4834 - sse: 3363.7378\n","Epoch 80: val_loss did not improve from 0.29817\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0397 - loss: 0.2072 - mae: 0.1911 - mse: 0.0863 - pearson_correlation: -2.4716e-16 - r2_keras: -87.4534 - rmse: 0.8880 - sae: 1940.4315 - sse: 2432.0332 - val_huber_loss: 0.1345 - val_loss: 0.2988 - val_mae: 0.3815 - val_mse: 0.2841 - val_pearson_correlation: 1.4694e-16 - val_r2_keras: -39.7515 - val_rmse: 1.0395 - val_sae: 401.9389 - val_sse: 571.6664 - learning_rate: 2.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0475 - loss: 0.2118 - mae: 0.2025 - mse: 0.0956 - pearson_correlation: -1.1100e-16 - r2_keras: -107.1521 - rmse: 0.9050 - sae: 2655.9719 - sse: 3354.7424\n","Epoch 81: val_loss improved from 0.29817 to 0.29767, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0392 - loss: 0.2067 - mae: 0.1903 - mse: 0.0853 - pearson_correlation: -1.1631e-16 - r2_keras: -87.3148 - rmse: 0.8877 - sae: 1937.6707 - sse: 2426.6785 - val_huber_loss: 0.1334 - val_loss: 0.2977 - val_mae: 0.3773 - val_mse: 0.2818 - val_pearson_correlation: -1.8449e-16 - val_r2_keras: -39.5022 - val_rmse: 1.0364 - val_sae: 400.0152 - val_sse: 568.1694 - learning_rate: 2.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0472 - loss: 0.2114 - mae: 0.2013 - mse: 0.0948 - pearson_correlation: 1.0780e-17 - r2_keras: -107.7567 - rmse: 0.9075 - sae: 2662.6680 - sse: 3373.4973\n","Epoch 82: val_loss did not improve from 0.29767\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0387 - loss: 0.2063 - mae: 0.1888 - mse: 0.0844 - pearson_correlation: -1.9230e-17 - r2_keras: -87.7312 - rmse: 0.8895 - sae: 1942.0311 - sse: 2439.3381 - val_huber_loss: 0.1336 - val_loss: 0.2979 - val_mae: 0.3801 - val_mse: 0.2819 - val_pearson_correlation: -1.5616e-16 - val_r2_keras: -39.7058 - val_rmse: 1.0390 - val_sae: 401.1659 - val_sse: 571.0252 - learning_rate: 2.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0467 - loss: 0.2110 - mae: 0.2006 - mse: 0.0939 - pearson_correlation: 1.6829e-16 - r2_keras: -107.2630 - rmse: 0.9055 - sae: 2655.6499 - sse: 3358.1819\n","Epoch 83: val_loss improved from 0.29767 to 0.29663, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0383 - loss: 0.2058 - mae: 0.1880 - mse: 0.0835 - pearson_correlation: 1.1150e-16 - r2_keras: -87.4625 - rmse: 0.8886 - sae: 1937.6567 - sse: 2429.8369 - val_huber_loss: 0.1324 - val_loss: 0.2966 - val_mae: 0.3764 - val_mse: 0.2789 - val_pearson_correlation: 2.4964e-16 - val_r2_keras: -39.3600 - val_rmse: 1.0345 - val_sae: 398.9834 - val_sse: 566.1743 - learning_rate: 2.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0463 - loss: 0.2105 - mae: 0.1986 - mse: 0.0930 - pearson_correlation: -4.2833e-16 - r2_keras: -107.7749 - rmse: 0.9076 - sae: 2660.8657 - sse: 3374.0620\n","Epoch 84: val_loss did not improve from 0.29663\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0379 - loss: 0.2054 - mae: 0.1862 - mse: 0.0827 - pearson_correlation: -2.5422e-16 - r2_keras: -87.7019 - rmse: 0.8892 - sae: 1940.6951 - sse: 2439.2283 - val_huber_loss: 0.1328 - val_loss: 0.2970 - val_mae: 0.3780 - val_mse: 0.2802 - val_pearson_correlation: -6.4325e-17 - val_r2_keras: -39.6577 - val_rmse: 1.0383 - val_sae: 400.2227 - val_sse: 570.3503 - learning_rate: 2.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0459 - loss: 0.2101 - mae: 0.1988 - mse: 0.0921 - pearson_correlation: -3.0111e-16 - r2_keras: -107.7881 - rmse: 0.9077 - sae: 2661.6431 - sse: 3374.4697\n","Epoch 85: val_loss improved from 0.29663 to 0.29579, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0375 - loss: 0.2050 - mae: 0.1858 - mse: 0.0818 - pearson_correlation: -1.8390e-16 - r2_keras: -87.8765 - rmse: 0.8907 - sae: 1941.7686 - sse: 2441.4463 - val_huber_loss: 0.1315 - val_loss: 0.2958 - val_mae: 0.3773 - val_mse: 0.2767 - val_pearson_correlation: 1.4810e-16 - val_r2_keras: -39.3170 - val_rmse: 1.0340 - val_sae: 398.6737 - val_sse: 565.5706 - learning_rate: 2.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0454 - loss: 0.2097 - mae: 0.1964 - mse: 0.0912 - pearson_correlation: -1.0422e-16 - r2_keras: -107.7926 - rmse: 0.9077 - sae: 2658.7729 - sse: 3374.6091\n","Epoch 86: val_loss did not improve from 0.29579\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0369 - loss: 0.2045 - mae: 0.1837 - mse: 0.0808 - pearson_correlation: -7.3833e-17 - r2_keras: -87.7818 - rmse: 0.8898 - sae: 1939.5001 - sse: 2440.3926 - val_huber_loss: 0.1318 - val_loss: 0.2961 - val_mae: 0.3753 - val_mse: 0.2776 - val_pearson_correlation: 1.8419e-17 - val_r2_keras: -39.4779 - val_rmse: 1.0360 - val_sae: 399.0034 - val_sse: 567.8282 - learning_rate: 2.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0450 - loss: 0.2092 - mae: 0.1961 - mse: 0.0904 - pearson_correlation: -5.3679e-16 - r2_keras: -108.1260 - rmse: 0.9091 - sae: 2662.6777 - sse: 3384.9526\n","Epoch 87: val_loss improved from 0.29579 to 0.29480, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0365 - loss: 0.2041 - mae: 0.1832 - mse: 0.0799 - pearson_correlation: -4.0764e-16 - r2_keras: -87.9923 - rmse: 0.8907 - sae: 1942.0227 - sse: 2447.1497 - val_huber_loss: 0.1306 - val_loss: 0.2948 - val_mae: 0.3738 - val_mse: 0.2750 - val_pearson_correlation: 1.5638e-16 - val_r2_keras: -39.5032 - val_rmse: 1.0364 - val_sae: 398.2552 - val_sse: 568.1833 - learning_rate: 2.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0446 - loss: 0.2088 - mae: 0.1954 - mse: 0.0896 - pearson_correlation: 6.0133e-16 - r2_keras: -108.2940 - rmse: 0.9098 - sae: 2665.5049 - sse: 3390.1631\n","Epoch 88: val_loss did not improve from 0.29480\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0362 - loss: 0.2037 - mae: 0.1823 - mse: 0.0792 - pearson_correlation: 4.3450e-16 - r2_keras: -88.2440 - rmse: 0.8923 - sae: 1944.3405 - sse: 2452.2627 - val_huber_loss: 0.1314 - val_loss: 0.2956 - val_mae: 0.3766 - val_mse: 0.2770 - val_pearson_correlation: -1.1177e-16 - val_r2_keras: -39.0560 - val_rmse: 1.0306 - val_sae: 397.0533 - val_sse: 561.9095 - learning_rate: 2.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0442 - loss: 0.2084 - mae: 0.1930 - mse: 0.0887 - pearson_correlation: 4.5254e-16 - r2_keras: -107.7991 - rmse: 0.9077 - sae: 2657.4111 - sse: 3374.8110\n","Epoch 89: val_loss improved from 0.29480 to 0.29389, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0357 - loss: 0.2032 - mae: 0.1803 - mse: 0.0783 - pearson_correlation: 3.4918e-16 - r2_keras: -87.8398 - rmse: 0.8903 - sae: 1938.7443 - sse: 2441.1562 - val_huber_loss: 0.1297 - val_loss: 0.2939 - val_mae: 0.3763 - val_mse: 0.2716 - val_pearson_correlation: 8.2919e-17 - val_r2_keras: -39.4708 - val_rmse: 1.0360 - val_sae: 398.6476 - val_sse: 567.7283 - learning_rate: 2.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0437 - loss: 0.2079 - mae: 0.1921 - mse: 0.0876 - pearson_correlation: 4.0513e-16 - r2_keras: -108.0328 - rmse: 0.9087 - sae: 2657.6667 - sse: 3382.0615\n","Epoch 90: val_loss did not improve from 0.29389\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0352 - loss: 0.2027 - mae: 0.1793 - mse: 0.0772 - pearson_correlation: 1.9147e-16 - r2_keras: -87.9823 - rmse: 0.8909 - sae: 1938.9285 - sse: 2445.8342 - val_huber_loss: 0.1300 - val_loss: 0.2942 - val_mae: 0.3721 - val_mse: 0.2735 - val_pearson_correlation: 1.3903e-16 - val_r2_keras: -39.2135 - val_rmse: 1.0327 - val_sae: 397.1314 - val_sse: 564.1198 - learning_rate: 2.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0434 - loss: 0.2076 - mae: 0.1921 - mse: 0.0870 - pearson_correlation: -4.7961e-16 - r2_keras: -109.0051 - rmse: 0.9127 - sae: 2670.1914 - sse: 3412.2195\n","Epoch 91: val_loss did not improve from 0.29389\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0349 - loss: 0.2024 - mae: 0.1791 - mse: 0.0766 - pearson_correlation: -2.8732e-16 - r2_keras: -88.6424 - rmse: 0.8936 - sae: 1947.1210 - sse: 2466.0796 - val_huber_loss: 0.1302 - val_loss: 0.2944 - val_mae: 0.3728 - val_mse: 0.2740 - val_pearson_correlation: -3.0452e-16 - val_r2_keras: -39.3196 - val_rmse: 1.0340 - val_sae: 396.8694 - val_sse: 565.6072 - learning_rate: 2.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0428 - loss: 0.2070 - mae: 0.1906 - mse: 0.0858 - pearson_correlation: -3.9666e-16 - r2_keras: -108.1116 - rmse: 0.9090 - sae: 2658.5793 - sse: 3384.5054\n","Epoch 92: val_loss improved from 0.29389 to 0.29366, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0343 - loss: 0.2018 - mae: 0.1771 - mse: 0.0755 - pearson_correlation: -2.7440e-16 - r2_keras: -88.1702 - rmse: 0.8923 - sae: 1939.9860 - sse: 2449.0510 - val_huber_loss: 0.1295 - val_loss: 0.2937 - val_mae: 0.3742 - val_mse: 0.2717 - val_pearson_correlation: -2.7779e-17 - val_r2_keras: -39.2580 - val_rmse: 1.0332 - val_sae: 397.1477 - val_sse: 564.7432 - learning_rate: 2.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0424 - loss: 0.2065 - mae: 0.1892 - mse: 0.0849 - pearson_correlation: -3.5961e-16 - r2_keras: -108.1816 - rmse: 0.9093 - sae: 2657.1902 - sse: 3386.6760\n","Epoch 93: val_loss improved from 0.29366 to 0.29155, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0340 - loss: 0.2014 - mae: 0.1760 - mse: 0.0746 - pearson_correlation: -3.1523e-16 - r2_keras: -88.2356 - rmse: 0.8926 - sae: 1939.0568 - sse: 2450.7178 - val_huber_loss: 0.1274 - val_loss: 0.2915 - val_mae: 0.3706 - val_mse: 0.2663 - val_pearson_correlation: 8.2043e-17 - val_r2_keras: -39.8023 - val_rmse: 1.0402 - val_sae: 398.5719 - val_sse: 572.3793 - learning_rate: 2.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0419 - loss: 0.2061 - mae: 0.1877 - mse: 0.0840 - pearson_correlation: -3.0047e-17 - r2_keras: -108.8696 - rmse: 0.9122 - sae: 2666.6260 - sse: 3408.0190\n","Epoch 94: val_loss did not improve from 0.29155\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0335 - loss: 0.2010 - mae: 0.1740 - mse: 0.0738 - pearson_correlation: 6.0533e-18 - r2_keras: -88.7673 - rmse: 0.8952 - sae: 1945.5609 - sse: 2465.8030 - val_huber_loss: 0.1296 - val_loss: 0.2938 - val_mae: 0.3736 - val_mse: 0.2724 - val_pearson_correlation: 6.4918e-16 - val_r2_keras: -39.1483 - val_rmse: 1.0318 - val_sae: 395.9367 - val_sse: 563.2042 - learning_rate: 2.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0414 - loss: 0.2056 - mae: 0.1868 - mse: 0.0830 - pearson_correlation: -5.8001e-17 - r2_keras: -108.8088 - rmse: 0.9119 - sae: 2663.9490 - sse: 3406.1304\n","Epoch 95: val_loss did not improve from 0.29155\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0330 - loss: 0.2005 - mae: 0.1729 - mse: 0.0727 - pearson_correlation: -1.7967e-17 - r2_keras: -88.7175 - rmse: 0.8949 - sae: 1943.6709 - sse: 2464.4358 - val_huber_loss: 0.1274 - val_loss: 0.2916 - val_mae: 0.3694 - val_mse: 0.2665 - val_pearson_correlation: 5.5064e-16 - val_r2_keras: -39.4663 - val_rmse: 1.0359 - val_sae: 396.6138 - val_sse: 567.6658 - learning_rate: 2.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0409 - loss: 0.2050 - mae: 0.1856 - mse: 0.0819 - pearson_correlation: 9.0218e-17 - r2_keras: -108.7777 - rmse: 0.9118 - sae: 2662.7148 - sse: 3405.1675\n","Epoch 96: val_loss did not improve from 0.29155\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0325 - loss: 0.2000 - mae: 0.1720 - mse: 0.0717 - pearson_correlation: 6.4200e-17 - r2_keras: -88.6779 - rmse: 0.8947 - sae: 1942.9362 - sse: 2463.5728 - val_huber_loss: 0.1278 - val_loss: 0.2919 - val_mae: 0.3712 - val_mse: 0.2676 - val_pearson_correlation: 2.6607e-16 - val_r2_keras: -39.5354 - val_rmse: 1.0368 - val_sae: 396.5587 - val_sse: 568.6348 - learning_rate: 2.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0404 - loss: 0.2046 - mae: 0.1849 - mse: 0.0810 - pearson_correlation: 4.1696e-16 - r2_keras: -109.0150 - rmse: 0.9128 - sae: 2664.9072 - sse: 3412.5288\n","Epoch 97: val_loss improved from 0.29155 to 0.29111, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0321 - loss: 0.1995 - mae: 0.1707 - mse: 0.0708 - pearson_correlation: 2.9134e-16 - r2_keras: -89.0056 - rmse: 0.8968 - sae: 1944.8695 - sse: 2470.4683 - val_huber_loss: 0.1270 - val_loss: 0.2911 - val_mae: 0.3717 - val_mse: 0.2654 - val_pearson_correlation: -3.2205e-16 - val_r2_keras: -39.4083 - val_rmse: 1.0352 - val_sae: 396.1746 - val_sse: 566.8520 - learning_rate: 2.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0398 - loss: 0.2039 - mae: 0.1825 - mse: 0.0797 - pearson_correlation: -9.8608e-17 - r2_keras: -108.6354 - rmse: 0.9112 - sae: 2659.0303 - sse: 3400.7539\n","Epoch 98: val_loss did not improve from 0.29111\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0316 - loss: 0.1989 - mae: 0.1687 - mse: 0.0696 - pearson_correlation: -8.1395e-17 - r2_keras: -88.6874 - rmse: 0.8952 - sae: 1940.8009 - sse: 2461.8540 - val_huber_loss: 0.1278 - val_loss: 0.2919 - val_mae: 0.3717 - val_mse: 0.2682 - val_pearson_correlation: -5.9395e-16 - val_r2_keras: -39.1007 - val_rmse: 1.0312 - val_sae: 395.0199 - val_sse: 562.5368 - learning_rate: 2.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0394 - loss: 0.2035 - mae: 0.1818 - mse: 0.0789 - pearson_correlation: 2.1110e-16 - r2_keras: -109.1875 - rmse: 0.9135 - sae: 2665.8000 - sse: 3417.8784\n","Epoch 99: val_loss improved from 0.29111 to 0.28943, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0313 - loss: 0.1986 - mae: 0.1680 - mse: 0.0690 - pearson_correlation: 1.8889e-16 - r2_keras: -89.1023 - rmse: 0.8971 - sae: 1945.3068 - sse: 2473.8203 - val_huber_loss: 0.1253 - val_loss: 0.2894 - val_mae: 0.3667 - val_mse: 0.2615 - val_pearson_correlation: 2.0929e-16 - val_r2_keras: -39.7475 - val_rmse: 1.0395 - val_sae: 396.2225 - val_sse: 571.6110 - learning_rate: 2.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0390 - loss: 0.2031 - mae: 0.1803 - mse: 0.0780 - pearson_correlation: -5.1477e-16 - r2_keras: -108.9711 - rmse: 0.9126 - sae: 2663.4016 - sse: 3411.1675\n","Epoch 100: val_loss did not improve from 0.28943\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0309 - loss: 0.1982 - mae: 0.1664 - mse: 0.0681 - pearson_correlation: -3.3874e-16 - r2_keras: -89.0182 - rmse: 0.8970 - sae: 1944.1522 - sse: 2470.0515 - val_huber_loss: 0.1264 - val_loss: 0.2905 - val_mae: 0.3709 - val_mse: 0.2642 - val_pearson_correlation: 8.3306e-17 - val_r2_keras: -39.1430 - val_rmse: 1.0318 - val_sae: 394.1480 - val_sse: 563.1304 - learning_rate: 2.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0384 - loss: 0.2026 - mae: 0.1789 - mse: 0.0769 - pearson_correlation: 1.4848e-16 - r2_keras: -108.9164 - rmse: 0.9124 - sae: 2659.5413 - sse: 3409.4683\n","Epoch 101: val_loss improved from 0.28943 to 0.28871, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0304 - loss: 0.1977 - mae: 0.1651 - mse: 0.0671 - pearson_correlation: 5.1202e-17 - r2_keras: -89.0332 - rmse: 0.8973 - sae: 1941.6288 - sse: 2469.5225 - val_huber_loss: 0.1246 - val_loss: 0.2887 - val_mae: 0.3655 - val_mse: 0.2597 - val_pearson_correlation: -2.8169e-16 - val_r2_keras: -39.7855 - val_rmse: 1.0400 - val_sae: 396.3250 - val_sse: 572.1437 - learning_rate: 2.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0380 - loss: 0.2021 - mae: 0.1773 - mse: 0.0760 - pearson_correlation: -1.0233e-16 - r2_keras: -109.0919 - rmse: 0.9131 - sae: 2664.0432 - sse: 3414.9141\n","Epoch 102: val_loss did not improve from 0.28871\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0301 - loss: 0.1973 - mae: 0.1636 - mse: 0.0664 - pearson_correlation: -3.8608e-17 - r2_keras: -89.1685 - rmse: 0.8980 - sae: 1944.7390 - sse: 2473.3679 - val_huber_loss: 0.1274 - val_loss: 0.2915 - val_mae: 0.3697 - val_mse: 0.2676 - val_pearson_correlation: 6.8717e-16 - val_r2_keras: -39.0363 - val_rmse: 1.0304 - val_sae: 393.4633 - val_sse: 561.6341 - learning_rate: 2.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0376 - loss: 0.2017 - mae: 0.1770 - mse: 0.0752 - pearson_correlation: -1.7503e-16 - r2_keras: -109.4640 - rmse: 0.9146 - sae: 2666.1777 - sse: 3426.4563\n","Epoch 103: val_loss improved from 0.28871 to 0.28864, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0297 - loss: 0.1969 - mae: 0.1631 - mse: 0.0656 - pearson_correlation: -9.7727e-17 - r2_keras: -89.4497 - rmse: 0.8993 - sae: 1946.0586 - sse: 2481.4517 - val_huber_loss: 0.1245 - val_loss: 0.2886 - val_mae: 0.3679 - val_mse: 0.2589 - val_pearson_correlation: 2.1941e-16 - val_r2_keras: -39.5333 - val_rmse: 1.0368 - val_sae: 395.0628 - val_sse: 568.6062 - learning_rate: 2.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0371 - loss: 0.2012 - mae: 0.1752 - mse: 0.0742 - pearson_correlation: -5.4922e-16 - r2_keras: -108.6931 - rmse: 0.9114 - sae: 2655.1831 - sse: 3402.5437\n","Epoch 104: val_loss improved from 0.28864 to 0.28836, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0292 - loss: 0.1964 - mae: 0.1616 - mse: 0.0646 - pearson_correlation: -3.8690e-16 - r2_keras: -88.9098 - rmse: 0.8969 - sae: 1939.0441 - sse: 2465.2043 - val_huber_loss: 0.1243 - val_loss: 0.2884 - val_mae: 0.3638 - val_mse: 0.2594 - val_pearson_correlation: -1.9269e-16 - val_r2_keras: -39.4363 - val_rmse: 1.0355 - val_sae: 394.3185 - val_sse: 567.2449 - learning_rate: 2.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0370 - loss: 0.2011 - mae: 0.1748 - mse: 0.0740 - pearson_correlation: -6.5052e-16 - r2_keras: -110.0830 - rmse: 0.9172 - sae: 2673.8550 - sse: 3445.6550\n","Epoch 105: val_loss did not improve from 0.28836\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0291 - loss: 0.1963 - mae: 0.1609 - mse: 0.0644 - pearson_correlation: -4.3544e-16 - r2_keras: -89.8856 - rmse: 0.9012 - sae: 1951.3292 - sse: 2494.5227 - val_huber_loss: 0.1269 - val_loss: 0.2910 - val_mae: 0.3721 - val_mse: 0.2650 - val_pearson_correlation: 1.6531e-16 - val_r2_keras: -39.3982 - val_rmse: 1.0350 - val_sae: 394.7950 - val_sse: 566.7106 - learning_rate: 2.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0363 - loss: 0.2004 - mae: 0.1730 - mse: 0.0726 - pearson_correlation: 4.2419e-16 - r2_keras: -108.8872 - rmse: 0.9122 - sae: 2656.1030 - sse: 3408.5649\n","Epoch 106: val_loss improved from 0.28836 to 0.28731, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0285 - loss: 0.1956 - mae: 0.1587 - mse: 0.0631 - pearson_correlation: 2.4043e-16 - r2_keras: -89.2101 - rmse: 0.8989 - sae: 1940.0406 - sse: 2471.2234 - val_huber_loss: 0.1232 - val_loss: 0.2873 - val_mae: 0.3644 - val_mse: 0.2562 - val_pearson_correlation: -6.3764e-17 - val_r2_keras: -39.6447 - val_rmse: 1.0382 - val_sae: 394.8379 - val_sse: 570.1686 - learning_rate: 2.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0360 - loss: 0.2000 - mae: 0.1714 - mse: 0.0719 - pearson_correlation: 5.5112e-16 - r2_keras: -109.5442 - rmse: 0.9150 - sae: 2665.9465 - sse: 3428.9429\n","Epoch 107: val_loss did not improve from 0.28731\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0282 - loss: 0.1953 - mae: 0.1579 - mse: 0.0625 - pearson_correlation: 3.7005e-16 - r2_keras: -89.5731 - rmse: 0.9001 - sae: 1946.2885 - sse: 2483.9290 - val_huber_loss: 0.1268 - val_loss: 0.2909 - val_mae: 0.3693 - val_mse: 0.2657 - val_pearson_correlation: 5.5470e-17 - val_r2_keras: -39.1262 - val_rmse: 1.0315 - val_sae: 393.0241 - val_sse: 562.8945 - learning_rate: 2.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0356 - loss: 0.1997 - mae: 0.1713 - mse: 0.0713 - pearson_correlation: -8.2577e-16 - r2_keras: -109.7874 - rmse: 0.9160 - sae: 2667.0679 - sse: 3436.4866\n","Epoch 108: val_loss did not improve from 0.28731\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0279 - loss: 0.1950 - mae: 0.1573 - mse: 0.0619 - pearson_correlation: -5.7895e-16 - r2_keras: -89.7833 - rmse: 0.9012 - sae: 1946.9784 - sse: 2489.5225 - val_huber_loss: 0.1240 - val_loss: 0.2881 - val_mae: 0.3661 - val_mse: 0.2574 - val_pearson_correlation: -1.1773e-16 - val_r2_keras: -39.8546 - val_rmse: 1.0409 - val_sae: 395.5031 - val_sse: 573.1121 - learning_rate: 2.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0351 - loss: 0.1992 - mae: 0.1699 - mse: 0.0703 - pearson_correlation: 8.6975e-16 - r2_keras: -109.3838 - rmse: 0.9143 - sae: 2660.6887 - sse: 3423.9668\n","Epoch 109: val_loss did not improve from 0.28731\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0275 - loss: 0.1946 - mae: 0.1558 - mse: 0.0610 - pearson_correlation: 5.5757e-16 - r2_keras: -89.5439 - rmse: 0.9003 - sae: 1943.2716 - sse: 2481.5242 - val_huber_loss: 0.1258 - val_loss: 0.2899 - val_mae: 0.3685 - val_mse: 0.2626 - val_pearson_correlation: 4.1451e-16 - val_r2_keras: -39.2727 - val_rmse: 1.0334 - val_sae: 393.5992 - val_sse: 564.9502 - learning_rate: 2.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0348 - loss: 0.1988 - mae: 0.1683 - mse: 0.0695 - pearson_correlation: 3.7157e-16 - r2_keras: -109.7164 - rmse: 0.9157 - sae: 2664.0503 - sse: 3434.2844\n","Epoch 110: val_loss improved from 0.28731 to 0.28705, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0272 - loss: 0.1942 - mae: 0.1546 - mse: 0.0603 - pearson_correlation: 3.2435e-16 - r2_keras: -89.8052 - rmse: 0.9016 - sae: 1945.2013 - sse: 2488.8665 - val_huber_loss: 0.1230 - val_loss: 0.2871 - val_mae: 0.3639 - val_mse: 0.2557 - val_pearson_correlation: 1.0012e-16 - val_r2_keras: -39.6465 - val_rmse: 1.0382 - val_sae: 394.3362 - val_sse: 570.1937 - learning_rate: 2.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0345 - loss: 0.1985 - mae: 0.1671 - mse: 0.0690 - pearson_correlation: 1.7031e-16 - r2_keras: -109.8243 - rmse: 0.9161 - sae: 2666.8108 - sse: 3437.6316\n","Epoch 111: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0269 - loss: 0.1939 - mae: 0.1532 - mse: 0.0598 - pearson_correlation: 1.4969e-16 - r2_keras: -89.8738 - rmse: 0.9018 - sae: 1947.2343 - sse: 2491.0581 - val_huber_loss: 0.1263 - val_loss: 0.2903 - val_mae: 0.3689 - val_mse: 0.2634 - val_pearson_correlation: 3.2027e-16 - val_r2_keras: -39.4906 - val_rmse: 1.0362 - val_sae: 394.2276 - val_sse: 568.0064 - learning_rate: 2.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0340 - loss: 0.1980 - mae: 0.1673 - mse: 0.0680 - pearson_correlation: -3.8344e-17 - r2_keras: -109.8880 - rmse: 0.9164 - sae: 2664.2915 - sse: 3439.6079\n","Epoch 112: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0265 - loss: 0.1935 - mae: 0.1528 - mse: 0.0589 - pearson_correlation: 2.3975e-17 - r2_keras: -89.9510 - rmse: 0.9023 - sae: 1945.5494 - sse: 2492.7827 - val_huber_loss: 0.1237 - val_loss: 0.2877 - val_mae: 0.3668 - val_mse: 0.2566 - val_pearson_correlation: 4.1867e-16 - val_r2_keras: -39.6357 - val_rmse: 1.0381 - val_sae: 394.3833 - val_sse: 570.0414 - learning_rate: 2.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0336 - loss: 0.1976 - mae: 0.1658 - mse: 0.0672 - pearson_correlation: 3.6556e-16 - r2_keras: -109.4878 - rmse: 0.9147 - sae: 2659.2666 - sse: 3427.1941\n","Epoch 113: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0262 - loss: 0.1931 - mae: 0.1520 - mse: 0.0582 - pearson_correlation: 3.6544e-16 - r2_keras: -89.6766 - rmse: 0.9011 - sae: 1942.2764 - sse: 2484.4185 - val_huber_loss: 0.1247 - val_loss: 0.2887 - val_mae: 0.3649 - val_mse: 0.2601 - val_pearson_correlation: 1.9145e-16 - val_r2_keras: -39.5787 - val_rmse: 1.0373 - val_sae: 393.8524 - val_sse: 569.2419 - learning_rate: 2.0000e-05\n","Epoch 114/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0335 - loss: 0.1975 - mae: 0.1656 - mse: 0.0669 - pearson_correlation: 3.3263e-16 - r2_keras: -110.7213 - rmse: 0.9198 - sae: 2675.5730 - sse: 3465.4536\n","Epoch 114: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0260 - loss: 0.1930 - mae: 0.1514 - mse: 0.0579 - pearson_correlation: 1.9917e-16 - r2_keras: -90.5182 - rmse: 0.9047 - sae: 1953.0193 - sse: 2510.1516 - val_huber_loss: 0.1249 - val_loss: 0.2889 - val_mae: 0.3695 - val_mse: 0.2591 - val_pearson_correlation: 3.9782e-16 - val_r2_keras: -39.8568 - val_rmse: 1.0409 - val_sae: 395.0054 - val_sse: 573.1442 - learning_rate: 2.0000e-05\n","Epoch 115/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0329 - loss: 0.1969 - mae: 0.1645 - mse: 0.0657 - pearson_correlation: -2.6623e-16 - r2_keras: -109.7154 - rmse: 0.9157 - sae: 2658.5796 - sse: 3434.2537\n","Epoch 115: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0255 - loss: 0.1924 - mae: 0.1498 - mse: 0.0568 - pearson_correlation: -1.9566e-16 - r2_keras: -89.8992 - rmse: 0.9024 - sae: 1942.2408 - sse: 2489.9558 - val_huber_loss: 0.1244 - val_loss: 0.2884 - val_mae: 0.3660 - val_mse: 0.2589 - val_pearson_correlation: 5.3678e-16 - val_r2_keras: -39.6921 - val_rmse: 1.0388 - val_sae: 394.5729 - val_sse: 570.8332 - learning_rate: 2.0000e-05\n","Epoch 116/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0325 - loss: 0.1965 - mae: 0.1617 - mse: 0.0649 - pearson_correlation: 3.6369e-16 - r2_keras: -110.2147 - rmse: 0.9177 - sae: 2667.0823 - sse: 3449.7395\n","Epoch 116: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0252 - loss: 0.1920 - mae: 0.1475 - mse: 0.0560 - pearson_correlation: 2.5276e-16 - r2_keras: -90.3658 - rmse: 0.9049 - sae: 1948.0416 - sse: 2501.8486 - val_huber_loss: 0.1240 - val_loss: 0.2880 - val_mae: 0.3679 - val_mse: 0.2576 - val_pearson_correlation: -2.6369e-16 - val_r2_keras: -39.6704 - val_rmse: 1.0385 - val_sae: 394.1887 - val_sse: 570.5295 - learning_rate: 1.0000e-05\n","Epoch 117/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0322 - loss: 0.1962 - mae: 0.1610 - mse: 0.0643 - pearson_correlation: -6.4808e-17 - r2_keras: -109.9503 - rmse: 0.9166 - sae: 2662.0427 - sse: 3441.5410\n","Epoch 117: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0249 - loss: 0.1917 - mae: 0.1465 - mse: 0.0555 - pearson_correlation: -6.5625e-17 - r2_keras: -90.1125 - rmse: 0.9035 - sae: 1944.4943 - sse: 2495.4795 - val_huber_loss: 0.1240 - val_loss: 0.2879 - val_mae: 0.3672 - val_mse: 0.2575 - val_pearson_correlation: 2.9953e-16 - val_r2_keras: -39.7302 - val_rmse: 1.0393 - val_sae: 394.2583 - val_sse: 571.3677 - learning_rate: 1.0000e-05\n","Epoch 118/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0320 - loss: 0.1960 - mae: 0.1607 - mse: 0.0639 - pearson_correlation: 2.1313e-16 - r2_keras: -110.2556 - rmse: 0.9179 - sae: 2665.4854 - sse: 3451.0098\n","Epoch 118: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0247 - loss: 0.1916 - mae: 0.1462 - mse: 0.0551 - pearson_correlation: 3.9551e-17 - r2_keras: -90.3277 - rmse: 0.9044 - sae: 1946.8065 - sse: 2501.9287 - val_huber_loss: 0.1247 - val_loss: 0.2886 - val_mae: 0.3688 - val_mse: 0.2593 - val_pearson_correlation: -2.9141e-16 - val_r2_keras: -39.6164 - val_rmse: 1.0378 - val_sae: 393.9386 - val_sse: 569.7712 - learning_rate: 1.0000e-05\n","Epoch 119/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0318 - loss: 0.1957 - mae: 0.1599 - mse: 0.0635 - pearson_correlation: 2.1548e-16 - r2_keras: -110.2565 - rmse: 0.9179 - sae: 2664.8315 - sse: 3451.0386\n","Epoch 119: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0246 - loss: 0.1914 - mae: 0.1457 - mse: 0.0548 - pearson_correlation: 9.5387e-17 - r2_keras: -90.3243 - rmse: 0.9044 - sae: 1946.2802 - sse: 2501.9006 - val_huber_loss: 0.1236 - val_loss: 0.2876 - val_mae: 0.3669 - val_mse: 0.2566 - val_pearson_correlation: 2.9863e-16 - val_r2_keras: -39.8265 - val_rmse: 1.0405 - val_sae: 394.3805 - val_sse: 572.7181 - learning_rate: 1.0000e-05\n","Epoch 120/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0316 - loss: 0.1956 - mae: 0.1599 - mse: 0.0632 - pearson_correlation: -7.0231e-17 - r2_keras: -110.4050 - rmse: 0.9185 - sae: 2666.5410 - sse: 3455.6426\n","Epoch 120: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0245 - loss: 0.1912 - mae: 0.1454 - mse: 0.0545 - pearson_correlation: -3.9937e-17 - r2_keras: -90.4478 - rmse: 0.9050 - sae: 1947.6122 - sse: 2505.2576 - val_huber_loss: 0.1246 - val_loss: 0.2885 - val_mae: 0.3686 - val_mse: 0.2590 - val_pearson_correlation: 4.5407e-17 - val_r2_keras: -39.7027 - val_rmse: 1.0389 - val_sae: 393.9869 - val_sse: 570.9823 - learning_rate: 1.0000e-05\n","Epoch 121/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0314 - loss: 0.1953 - mae: 0.1592 - mse: 0.0627 - pearson_correlation: -3.8355e-16 - r2_keras: -110.5259 - rmse: 0.9190 - sae: 2667.3914 - sse: 3459.3950\n","Epoch 121: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0242 - loss: 0.1910 - mae: 0.1450 - mse: 0.0541 - pearson_correlation: -2.9183e-16 - r2_keras: -90.5341 - rmse: 0.9054 - sae: 1948.1044 - sse: 2507.8259 - val_huber_loss: 0.1238 - val_loss: 0.2878 - val_mae: 0.3674 - val_mse: 0.2571 - val_pearson_correlation: -4.7040e-16 - val_r2_keras: -39.8314 - val_rmse: 1.0406 - val_sae: 394.2434 - val_sse: 572.7870 - learning_rate: 1.0000e-05\n","Epoch 122/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0312 - loss: 0.1952 - mae: 0.1592 - mse: 0.0624 - pearson_correlation: 1.9378e-16 - r2_keras: -110.6247 - rmse: 0.9194 - sae: 2668.1343 - sse: 3462.4590\n","Epoch 122: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0241 - loss: 0.1908 - mae: 0.1447 - mse: 0.0537 - pearson_correlation: 1.4811e-16 - r2_keras: -90.6023 - rmse: 0.9057 - sae: 1948.6627 - sse: 2509.8960 - val_huber_loss: 0.1250 - val_loss: 0.2889 - val_mae: 0.3693 - val_mse: 0.2600 - val_pearson_correlation: 1.5452e-16 - val_r2_keras: -39.6668 - val_rmse: 1.0385 - val_sae: 393.7450 - val_sse: 570.4788 - learning_rate: 1.0000e-05\n","Epoch 123/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0310 - loss: 0.1950 - mae: 0.1582 - mse: 0.0620 - pearson_correlation: 3.5689e-17 - r2_keras: -110.6057 - rmse: 0.9193 - sae: 2667.3938 - sse: 3461.8687\n","Epoch 123: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0239 - loss: 0.1907 - mae: 0.1438 - mse: 0.0534 - pearson_correlation: 4.0966e-17 - r2_keras: -90.6149 - rmse: 0.9059 - sae: 1948.1852 - sse: 2509.7996 - val_huber_loss: 0.1239 - val_loss: 0.2878 - val_mae: 0.3678 - val_mse: 0.2570 - val_pearson_correlation: -2.2520e-16 - val_r2_keras: -39.9838 - val_rmse: 1.0425 - val_sae: 394.7161 - val_sse: 574.9257 - learning_rate: 1.0000e-05\n","Epoch 124/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0308 - loss: 0.1948 - mae: 0.1581 - mse: 0.0616 - pearson_correlation: -2.8565e-16 - r2_keras: -110.5569 - rmse: 0.9191 - sae: 2666.6169 - sse: 3460.3560\n","Epoch 124: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0238 - loss: 0.1905 - mae: 0.1440 - mse: 0.0531 - pearson_correlation: -2.5234e-16 - r2_keras: -90.5618 - rmse: 0.9056 - sae: 1947.6510 - sse: 2508.5498 - val_huber_loss: 0.1249 - val_loss: 0.2889 - val_mae: 0.3688 - val_mse: 0.2601 - val_pearson_correlation: 7.2628e-17 - val_r2_keras: -39.7034 - val_rmse: 1.0389 - val_sae: 393.7116 - val_sse: 570.9921 - learning_rate: 1.0000e-05\n","Epoch 125/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0306 - loss: 0.1946 - mae: 0.1572 - mse: 0.0613 - pearson_correlation: -6.8480e-16 - r2_keras: -110.7523 - rmse: 0.9199 - sae: 2669.5664 - sse: 3466.4150\n","Epoch 125: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0236 - loss: 0.1903 - mae: 0.1432 - mse: 0.0527 - pearson_correlation: -5.3714e-16 - r2_keras: -90.7338 - rmse: 0.9065 - sae: 1949.6481 - sse: 2513.0793 - val_huber_loss: 0.1244 - val_loss: 0.2884 - val_mae: 0.3690 - val_mse: 0.2584 - val_pearson_correlation: -9.0146e-18 - val_r2_keras: -39.9492 - val_rmse: 1.0421 - val_sae: 394.4303 - val_sse: 574.4404 - learning_rate: 1.0000e-05\n","Epoch 126/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0304 - loss: 0.1943 - mae: 0.1574 - mse: 0.0608 - pearson_correlation: 1.3109e-16 - r2_keras: -110.7457 - rmse: 0.9199 - sae: 2668.1606 - sse: 3466.2114\n","Epoch 126: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0234 - loss: 0.1901 - mae: 0.1431 - mse: 0.0523 - pearson_correlation: 5.2991e-17 - r2_keras: -90.6836 - rmse: 0.9060 - sae: 1948.6156 - sse: 2512.4058 - val_huber_loss: 0.1248 - val_loss: 0.2888 - val_mae: 0.3694 - val_mse: 0.2594 - val_pearson_correlation: 1.1760e-16 - val_r2_keras: -39.8259 - val_rmse: 1.0405 - val_sae: 394.0372 - val_sse: 572.7098 - learning_rate: 1.0000e-05\n","Epoch 127/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0302 - loss: 0.1941 - mae: 0.1565 - mse: 0.0604 - pearson_correlation: 1.9591e-16 - r2_keras: -110.7141 - rmse: 0.9198 - sae: 2667.4014 - sse: 3465.2317\n","Epoch 127: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0233 - loss: 0.1899 - mae: 0.1423 - mse: 0.0519 - pearson_correlation: 2.1469e-16 - r2_keras: -90.7003 - rmse: 0.9063 - sae: 1948.2056 - sse: 2512.1948 - val_huber_loss: 0.1251 - val_loss: 0.2890 - val_mae: 0.3696 - val_mse: 0.2602 - val_pearson_correlation: 3.3413e-16 - val_r2_keras: -39.8998 - val_rmse: 1.0414 - val_sae: 394.3780 - val_sse: 573.7466 - learning_rate: 1.0000e-05\n","Epoch 128/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0300 - loss: 0.1939 - mae: 0.1555 - mse: 0.0600 - pearson_correlation: 5.6934e-17 - r2_keras: -110.7839 - rmse: 0.9201 - sae: 2668.8354 - sse: 3467.3972\n","Epoch 128: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0231 - loss: 0.1897 - mae: 0.1412 - mse: 0.0516 - pearson_correlation: 1.9114e-17 - r2_keras: -90.7739 - rmse: 0.9067 - sae: 1949.2236 - sse: 2513.9568 - val_huber_loss: 0.1249 - val_loss: 0.2888 - val_mae: 0.3703 - val_mse: 0.2593 - val_pearson_correlation: -3.7015e-16 - val_r2_keras: -39.8888 - val_rmse: 1.0413 - val_sae: 394.2670 - val_sse: 573.5921 - learning_rate: 1.0000e-05\n","Epoch 129/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0298 - loss: 0.1938 - mae: 0.1554 - mse: 0.0596 - pearson_correlation: 1.4989e-16 - r2_keras: -110.6885 - rmse: 0.9197 - sae: 2666.0801 - sse: 3464.4385\n","Epoch 129: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0230 - loss: 0.1896 - mae: 0.1412 - mse: 0.0513 - pearson_correlation: 1.7194e-16 - r2_keras: -90.6948 - rmse: 0.9063 - sae: 1947.4344 - sse: 2511.8022 - val_huber_loss: 0.1256 - val_loss: 0.2895 - val_mae: 0.3701 - val_mse: 0.2612 - val_pearson_correlation: 9.8976e-17 - val_r2_keras: -40.0273 - val_rmse: 1.0431 - val_sae: 394.8127 - val_sse: 575.5353 - learning_rate: 1.0000e-05\n","Epoch 130/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0296 - loss: 0.1935 - mae: 0.1550 - mse: 0.0592 - pearson_correlation: 2.1031e-16 - r2_keras: -111.1367 - rmse: 0.9215 - sae: 2672.0630 - sse: 3478.3401\n","Epoch 130: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0228 - loss: 0.1894 - mae: 0.1406 - mse: 0.0509 - pearson_correlation: 1.7617e-16 - r2_keras: -91.0104 - rmse: 0.9077 - sae: 1951.3750 - sse: 2521.2671 - val_huber_loss: 0.1254 - val_loss: 0.2893 - val_mae: 0.3712 - val_mse: 0.2605 - val_pearson_correlation: 2.9743e-16 - val_r2_keras: -39.9505 - val_rmse: 1.0421 - val_sae: 394.5042 - val_sse: 574.4574 - learning_rate: 1.0000e-05\n","Epoch 131/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0294 - loss: 0.1934 - mae: 0.1542 - mse: 0.0589 - pearson_correlation: -2.3702e-16 - r2_keras: -110.8071 - rmse: 0.9202 - sae: 2666.5525 - sse: 3468.1169\n","Epoch 131: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0227 - loss: 0.1892 - mae: 0.1402 - mse: 0.0506 - pearson_correlation: -1.1179e-16 - r2_keras: -90.7991 - rmse: 0.9068 - sae: 1947.8180 - sse: 2514.5508 - val_huber_loss: 0.1257 - val_loss: 0.2896 - val_mae: 0.3703 - val_mse: 0.2613 - val_pearson_correlation: -1.0766e-16 - val_r2_keras: -40.1321 - val_rmse: 1.0444 - val_sae: 395.1159 - val_sse: 577.0056 - learning_rate: 1.0000e-05\n","Epoch 132/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0293 - loss: 0.1932 - mae: 0.1539 - mse: 0.0585 - pearson_correlation: -2.7240e-16 - r2_keras: -111.2463 - rmse: 0.9220 - sae: 2672.8433 - sse: 3481.7402\n","Epoch 132: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0225 - loss: 0.1891 - mae: 0.1396 - mse: 0.0503 - pearson_correlation: -2.7053e-16 - r2_keras: -91.1063 - rmse: 0.9082 - sae: 1951.9749 - sse: 2523.8020 - val_huber_loss: 0.1259 - val_loss: 0.2898 - val_mae: 0.3721 - val_mse: 0.2616 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -39.9961 - val_rmse: 1.0427 - val_sae: 394.6384 - val_sse: 575.0981 - learning_rate: 1.0000e-05\n","Epoch 133/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0290 - loss: 0.1929 - mae: 0.1531 - mse: 0.0580 - pearson_correlation: -3.7252e-16 - r2_keras: -110.9083 - rmse: 0.9206 - sae: 2667.1191 - sse: 3471.2551\n","Epoch 133: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0223 - loss: 0.1888 - mae: 0.1388 - mse: 0.0498 - pearson_correlation: -2.6031e-16 - r2_keras: -90.8973 - rmse: 0.9074 - sae: 1948.2428 - sse: 2517.0034 - val_huber_loss: 0.1253 - val_loss: 0.2892 - val_mae: 0.3703 - val_mse: 0.2602 - val_pearson_correlation: 3.5841e-16 - val_r2_keras: -40.1694 - val_rmse: 1.0449 - val_sae: 395.1638 - val_sse: 577.5293 - learning_rate: 1.0000e-05\n","Epoch 134/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0289 - loss: 0.1928 - mae: 0.1525 - mse: 0.0577 - pearson_correlation: -1.1316e-15 - r2_keras: -111.2316 - rmse: 0.9219 - sae: 2671.3232 - sse: 3481.2832\n","Epoch 134: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0222 - loss: 0.1887 - mae: 0.1383 - mse: 0.0496 - pearson_correlation: -7.6635e-16 - r2_keras: -91.1306 - rmse: 0.9084 - sae: 1951.1249 - sse: 2523.8970 - val_huber_loss: 0.1264 - val_loss: 0.2903 - val_mae: 0.3722 - val_mse: 0.2629 - val_pearson_correlation: 3.1466e-16 - val_r2_keras: -40.0416 - val_rmse: 1.0432 - val_sae: 394.6943 - val_sse: 575.7359 - learning_rate: 1.0000e-05\n","Epoch 135/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0287 - loss: 0.1926 - mae: 0.1521 - mse: 0.0573 - pearson_correlation: 4.9687e-17 - r2_keras: -111.2007 - rmse: 0.9218 - sae: 2670.7554 - sse: 3480.3252\n","Epoch 135: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0220 - loss: 0.1885 - mae: 0.1379 - mse: 0.0492 - pearson_correlation: 4.1657e-17 - r2_keras: -91.1115 - rmse: 0.9084 - sae: 1950.6542 - sse: 2523.2756 - val_huber_loss: 0.1255 - val_loss: 0.2894 - val_mae: 0.3714 - val_mse: 0.2605 - val_pearson_correlation: 1.7836e-17 - val_r2_keras: -40.3295 - val_rmse: 1.0469 - val_sae: 395.5401 - val_sse: 579.7754 - learning_rate: 1.0000e-05\n","Epoch 136/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0285 - loss: 0.1924 - mae: 0.1516 - mse: 0.0570 - pearson_correlation: 9.9596e-17 - r2_keras: -111.2339 - rmse: 0.9219 - sae: 2670.8691 - sse: 3481.3550\n","Epoch 136: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0219 - loss: 0.1884 - mae: 0.1373 - mse: 0.0490 - pearson_correlation: 9.7086e-17 - r2_keras: -91.1477 - rmse: 0.9086 - sae: 1950.8907 - sse: 2524.1277 - val_huber_loss: 0.1265 - val_loss: 0.2903 - val_mae: 0.3728 - val_mse: 0.2629 - val_pearson_correlation: 2.6915e-16 - val_r2_keras: -40.1171 - val_rmse: 1.0442 - val_sae: 394.9320 - val_sse: 576.7947 - learning_rate: 1.0000e-05\n","Epoch 137/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0283 - loss: 0.1922 - mae: 0.1511 - mse: 0.0566 - pearson_correlation: 1.7991e-16 - r2_keras: -111.3029 - rmse: 0.9222 - sae: 2671.2058 - sse: 3483.4956\n","Epoch 137: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0217 - loss: 0.1882 - mae: 0.1369 - mse: 0.0485 - pearson_correlation: 1.0631e-16 - r2_keras: -91.1968 - rmse: 0.9088 - sae: 1951.0371 - sse: 2525.5906 - val_huber_loss: 0.1259 - val_loss: 0.2898 - val_mae: 0.3724 - val_mse: 0.2612 - val_pearson_correlation: -2.8543e-16 - val_r2_keras: -40.3205 - val_rmse: 1.0468 - val_sae: 395.4962 - val_sse: 579.6488 - learning_rate: 1.0000e-05\n","Epoch 138/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0281 - loss: 0.1920 - mae: 0.1506 - mse: 0.0562 - pearson_correlation: 1.6537e-17 - r2_keras: -111.3369 - rmse: 0.9223 - sae: 2671.3359 - sse: 3484.5493\n","Epoch 138: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0215 - loss: 0.1880 - mae: 0.1366 - mse: 0.0482 - pearson_correlation: -7.7360e-18 - r2_keras: -91.2107 - rmse: 0.9088 - sae: 1951.1205 - sse: 2526.1902 - val_huber_loss: 0.1268 - val_loss: 0.2907 - val_mae: 0.3732 - val_mse: 0.2637 - val_pearson_correlation: -1.6122e-16 - val_r2_keras: -40.1676 - val_rmse: 1.0448 - val_sae: 395.0106 - val_sse: 577.5033 - learning_rate: 1.0000e-05\n","Epoch 139/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0279 - loss: 0.1918 - mae: 0.1505 - mse: 0.0558 - pearson_correlation: -2.4073e-16 - r2_keras: -111.4770 - rmse: 0.9229 - sae: 2672.3176 - sse: 3488.8960\n","Epoch 139: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0214 - loss: 0.1878 - mae: 0.1360 - mse: 0.0479 - pearson_correlation: -1.9963e-16 - r2_keras: -91.3356 - rmse: 0.9094 - sae: 1951.8322 - sse: 2529.4580 - val_huber_loss: 0.1262 - val_loss: 0.2901 - val_mae: 0.3733 - val_mse: 0.2619 - val_pearson_correlation: 2.2256e-16 - val_r2_keras: -40.3991 - val_rmse: 1.0478 - val_sae: 395.9431 - val_sse: 580.7505 - learning_rate: 1.0000e-05\n","Epoch 140/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0277 - loss: 0.1916 - mae: 0.1496 - mse: 0.0554 - pearson_correlation: 5.9810e-16 - r2_keras: -111.3050 - rmse: 0.9222 - sae: 2670.0273 - sse: 3483.5618\n","Epoch 140: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0212 - loss: 0.1876 - mae: 0.1356 - mse: 0.0475 - pearson_correlation: 5.2310e-16 - r2_keras: -91.2063 - rmse: 0.9089 - sae: 1950.3331 - sse: 2525.7302 - val_huber_loss: 0.1268 - val_loss: 0.2907 - val_mae: 0.3733 - val_mse: 0.2636 - val_pearson_correlation: -1.4309e-16 - val_r2_keras: -40.2243 - val_rmse: 1.0456 - val_sae: 395.2970 - val_sse: 578.2990 - learning_rate: 1.0000e-05\n","Epoch 141/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0276 - loss: 0.1914 - mae: 0.1493 - mse: 0.0551 - pearson_correlation: 1.2370e-17 - r2_keras: -111.5845 - rmse: 0.9234 - sae: 2673.1477 - sse: 3492.2319\n","Epoch 141: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0211 - loss: 0.1875 - mae: 0.1350 - mse: 0.0472 - pearson_correlation: 1.3344e-17 - r2_keras: -91.4351 - rmse: 0.9100 - sae: 1952.4558 - sse: 2532.0076 - val_huber_loss: 0.1269 - val_loss: 0.2907 - val_mae: 0.3743 - val_mse: 0.2630 - val_pearson_correlation: 2.3091e-16 - val_r2_keras: -40.5025 - val_rmse: 1.0491 - val_sae: 396.4231 - val_sse: 582.2014 - learning_rate: 1.0000e-05\n","Epoch 142/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0273 - loss: 0.1912 - mae: 0.1485 - mse: 0.0546 - pearson_correlation: 1.8189e-16 - r2_keras: -111.3365 - rmse: 0.9223 - sae: 2669.1726 - sse: 3484.5376\n","Epoch 142: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0209 - loss: 0.1873 - mae: 0.1340 - mse: 0.0468 - pearson_correlation: 7.2023e-17 - r2_keras: -91.2822 - rmse: 0.9094 - sae: 1949.9454 - sse: 2527.0242 - val_huber_loss: 0.1271 - val_loss: 0.2910 - val_mae: 0.3740 - val_mse: 0.2640 - val_pearson_correlation: -3.2061e-16 - val_r2_keras: -40.3821 - val_rmse: 1.0476 - val_sae: 395.9958 - val_sse: 580.5132 - learning_rate: 1.0000e-05\n","Epoch 143/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0271 - loss: 0.1910 - mae: 0.1479 - mse: 0.0543 - pearson_correlation: 1.1423e-16 - r2_keras: -111.7456 - rmse: 0.9240 - sae: 2674.6074 - sse: 3497.2283\n","Epoch 143: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0208 - loss: 0.1871 - mae: 0.1341 - mse: 0.0466 - pearson_correlation: 1.0164e-16 - r2_keras: -91.5432 - rmse: 0.9104 - sae: 1953.3959 - sse: 2535.3464 - val_huber_loss: 0.1269 - val_loss: 0.2908 - val_mae: 0.3747 - val_mse: 0.2632 - val_pearson_correlation: -8.8636e-18 - val_r2_keras: -40.5523 - val_rmse: 1.0497 - val_sae: 396.4395 - val_sse: 582.9001 - learning_rate: 1.0000e-05\n","Epoch 144/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0269 - loss: 0.1908 - mae: 0.1477 - mse: 0.0539 - pearson_correlation: -5.4355e-16 - r2_keras: -111.6167 - rmse: 0.9235 - sae: 2672.4482 - sse: 3493.2292\n","Epoch 144: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0206 - loss: 0.1869 - mae: 0.1332 - mse: 0.0461 - pearson_correlation: -3.5047e-16 - r2_keras: -91.4588 - rmse: 0.9101 - sae: 1952.0292 - sse: 2532.6997 - val_huber_loss: 0.1277 - val_loss: 0.2916 - val_mae: 0.3756 - val_mse: 0.2651 - val_pearson_correlation: 3.5570e-17 - val_r2_keras: -40.4358 - val_rmse: 1.0482 - val_sae: 396.2056 - val_sse: 581.2662 - learning_rate: 1.0000e-05\n","Epoch 145/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0268 - loss: 0.1906 - mae: 0.1469 - mse: 0.0535 - pearson_correlation: 6.4869e-16 - r2_keras: -111.6089 - rmse: 0.9235 - sae: 2670.9536 - sse: 3492.9888\n","Epoch 145: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0205 - loss: 0.1868 - mae: 0.1328 - mse: 0.0459 - pearson_correlation: 4.0031e-16 - r2_keras: -91.5203 - rmse: 0.9106 - sae: 1951.3356 - sse: 2533.3210 - val_huber_loss: 0.1268 - val_loss: 0.2907 - val_mae: 0.3750 - val_mse: 0.2626 - val_pearson_correlation: -6.6078e-16 - val_r2_keras: -40.7885 - val_rmse: 1.0527 - val_sae: 397.5109 - val_sse: 586.2139 - learning_rate: 1.0000e-05\n","Epoch 146/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0266 - loss: 0.1905 - mae: 0.1465 - mse: 0.0532 - pearson_correlation: 1.7913e-16 - r2_keras: -111.8406 - rmse: 0.9244 - sae: 2674.4753 - sse: 3500.1733\n","Epoch 146: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0204 - loss: 0.1866 - mae: 0.1329 - mse: 0.0456 - pearson_correlation: -3.6888e-17 - r2_keras: -91.6077 - rmse: 0.9107 - sae: 1953.4210 - sse: 2537.3250 - val_huber_loss: 0.1278 - val_loss: 0.2917 - val_mae: 0.3758 - val_mse: 0.2655 - val_pearson_correlation: 1.7734e-17 - val_r2_keras: -40.5332 - val_rmse: 1.0495 - val_sae: 396.4916 - val_sse: 582.6326 - learning_rate: 1.0000e-05\n","Epoch 147/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0265 - loss: 0.1903 - mae: 0.1464 - mse: 0.0529 - pearson_correlation: -2.7658e-16 - r2_keras: -112.1830 - rmse: 0.9258 - sae: 2678.0923 - sse: 3510.7954\n","Epoch 147: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0202 - loss: 0.1865 - mae: 0.1322 - mse: 0.0453 - pearson_correlation: -1.7422e-16 - r2_keras: -91.8803 - rmse: 0.9120 - sae: 1955.8544 - sse: 2544.9260 - val_huber_loss: 0.1274 - val_loss: 0.2913 - val_mae: 0.3759 - val_mse: 0.2641 - val_pearson_correlation: -1.7662e-17 - val_r2_keras: -40.6922 - val_rmse: 1.0515 - val_sae: 397.0060 - val_sse: 584.8625 - learning_rate: 1.0000e-05\n","Epoch 148/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0262 - loss: 0.1900 - mae: 0.1455 - mse: 0.0524 - pearson_correlation: -6.6593e-16 - r2_keras: -111.6784 - rmse: 0.9237 - sae: 2671.2510 - sse: 3495.1431\n","Epoch 148: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0200 - loss: 0.1863 - mae: 0.1314 - mse: 0.0449 - pearson_correlation: -3.3537e-16 - r2_keras: -91.5218 - rmse: 0.9104 - sae: 1951.3265 - sse: 2534.2314 - val_huber_loss: 0.1281 - val_loss: 0.2919 - val_mae: 0.3762 - val_mse: 0.2659 - val_pearson_correlation: 1.1517e-16 - val_r2_keras: -40.5765 - val_rmse: 1.0500 - val_sae: 396.7868 - val_sse: 583.2397 - learning_rate: 1.0000e-05\n","Epoch 149/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0260 - loss: 0.1898 - mae: 0.1453 - mse: 0.0520 - pearson_correlation: -1.6559e-16 - r2_keras: -111.9355 - rmse: 0.9248 - sae: 2674.4285 - sse: 3503.1182\n","Epoch 149: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0198 - loss: 0.1861 - mae: 0.1310 - mse: 0.0445 - pearson_correlation: -1.1209e-16 - r2_keras: -91.7280 - rmse: 0.9114 - sae: 1953.4703 - sse: 2539.9561 - val_huber_loss: 0.1277 - val_loss: 0.2916 - val_mae: 0.3756 - val_mse: 0.2648 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -40.7675 - val_rmse: 1.0524 - val_sae: 397.3658 - val_sse: 585.9187 - learning_rate: 1.0000e-05\n","Epoch 150/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0259 - loss: 0.1897 - mae: 0.1440 - mse: 0.0518 - pearson_correlation: 4.2662e-16 - r2_keras: -111.8298 - rmse: 0.9244 - sae: 2673.2695 - sse: 3499.8376\n","Epoch 150: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0198 - loss: 0.1860 - mae: 0.1301 - mse: 0.0443 - pearson_correlation: 2.6082e-16 - r2_keras: -91.7294 - rmse: 0.9118 - sae: 1953.1307 - sse: 2538.6123 - val_huber_loss: 0.1281 - val_loss: 0.2919 - val_mae: 0.3769 - val_mse: 0.2654 - val_pearson_correlation: 6.1692e-17 - val_r2_keras: -40.7796 - val_rmse: 1.0526 - val_sae: 397.6179 - val_sse: 586.0881 - learning_rate: 1.0000e-05\n","Epoch 151/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0257 - loss: 0.1895 - mae: 0.1434 - mse: 0.0513 - pearson_correlation: 2.8502e-17 - r2_keras: -111.9138 - rmse: 0.9247 - sae: 2673.0044 - sse: 3502.4458\n","Epoch 151: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0196 - loss: 0.1858 - mae: 0.1300 - mse: 0.0440 - pearson_correlation: -1.3292e-18 - r2_keras: -91.7018 - rmse: 0.9113 - sae: 1952.5109 - sse: 2539.3704 - val_huber_loss: 0.1276 - val_loss: 0.2914 - val_mae: 0.3757 - val_mse: 0.2646 - val_pearson_correlation: -2.2015e-16 - val_r2_keras: -40.7850 - val_rmse: 1.0526 - val_sae: 397.3012 - val_sse: 586.1649 - learning_rate: 1.0000e-05\n","Epoch 152/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0256 - loss: 0.1894 - mae: 0.1434 - mse: 0.0511 - pearson_correlation: 7.8792e-17 - r2_keras: -112.2738 - rmse: 0.9262 - sae: 2678.1313 - sse: 3513.6101\n","Epoch 152: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0195 - loss: 0.1857 - mae: 0.1293 - mse: 0.0437 - pearson_correlation: 1.5280e-17 - r2_keras: -91.9520 - rmse: 0.9123 - sae: 1955.9318 - sse: 2546.9336 - val_huber_loss: 0.1287 - val_loss: 0.2925 - val_mae: 0.3773 - val_mse: 0.2670 - val_pearson_correlation: -3.5300e-17 - val_r2_keras: -40.7156 - val_rmse: 1.0518 - val_sae: 397.2300 - val_sse: 585.1908 - learning_rate: 1.0000e-05\n","Epoch 153/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0253 - loss: 0.1891 - mae: 0.1431 - mse: 0.0506 - pearson_correlation: -1.8647e-16 - r2_keras: -112.1490 - rmse: 0.9257 - sae: 2675.2422 - sse: 3509.7407\n","Epoch 153: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0193 - loss: 0.1854 - mae: 0.1289 - mse: 0.0433 - pearson_correlation: -7.0175e-17 - r2_keras: -91.8814 - rmse: 0.9121 - sae: 1954.0239 - sse: 2544.5015 - val_huber_loss: 0.1278 - val_loss: 0.2916 - val_mae: 0.3759 - val_mse: 0.2647 - val_pearson_correlation: 1.5816e-16 - val_r2_keras: -40.8750 - val_rmse: 1.0538 - val_sae: 397.6056 - val_sse: 587.4272 - learning_rate: 1.0000e-05\n","Epoch 154/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0252 - loss: 0.1890 - mae: 0.1424 - mse: 0.0504 - pearson_correlation: 2.1270e-17 - r2_keras: -112.0995 - rmse: 0.9255 - sae: 2674.8496 - sse: 3508.2039\n","Epoch 154: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0192 - loss: 0.1853 - mae: 0.1284 - mse: 0.0431 - pearson_correlation: -1.9640e-17 - r2_keras: -91.8559 - rmse: 0.9120 - sae: 1953.8291 - sse: 2543.5649 - val_huber_loss: 0.1288 - val_loss: 0.2925 - val_mae: 0.3768 - val_mse: 0.2670 - val_pearson_correlation: -2.6414e-16 - val_r2_keras: -40.7981 - val_rmse: 1.0528 - val_sae: 397.4334 - val_sse: 586.3486 - learning_rate: 1.0000e-05\n","Epoch 155/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0250 - loss: 0.1888 - mae: 0.1423 - mse: 0.0500 - pearson_correlation: -1.5334e-17 - r2_keras: -112.3622 - rmse: 0.9265 - sae: 2677.6089 - sse: 3516.3533\n","Epoch 155: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0190 - loss: 0.1852 - mae: 0.1282 - mse: 0.0427 - pearson_correlation: 6.6359e-18 - r2_keras: -92.0806 - rmse: 0.9132 - sae: 1955.8521 - sse: 2549.5796 - val_huber_loss: 0.1289 - val_loss: 0.2927 - val_mae: 0.3779 - val_mse: 0.2669 - val_pearson_correlation: 3.9455e-16 - val_r2_keras: -40.9768 - val_rmse: 1.0551 - val_sae: 398.2726 - val_sse: 588.8557 - learning_rate: 1.0000e-05\n","Epoch 156/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0248 - loss: 0.1886 - mae: 0.1404 - mse: 0.0496 - pearson_correlation: 3.6741e-16 - r2_keras: -112.1125 - rmse: 0.9255 - sae: 2673.7715 - sse: 3508.6094\n","Epoch 156: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0189 - loss: 0.1850 - mae: 0.1264 - mse: 0.0424 - pearson_correlation: 9.1500e-17 - r2_keras: -91.9111 - rmse: 0.9125 - sae: 1953.2491 - sse: 2544.3801 - val_huber_loss: 0.1286 - val_loss: 0.2924 - val_mae: 0.3773 - val_mse: 0.2666 - val_pearson_correlation: -3.6801e-16 - val_r2_keras: -40.9707 - val_rmse: 1.0550 - val_sae: 398.0830 - val_sse: 588.7700 - learning_rate: 1.0000e-05\n","Epoch 157/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0247 - loss: 0.1885 - mae: 0.1412 - mse: 0.0493 - pearson_correlation: 1.9140e-16 - r2_keras: -112.6326 - rmse: 0.9276 - sae: 2680.3301 - sse: 3524.7397\n","Epoch 157: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0188 - loss: 0.1849 - mae: 0.1274 - mse: 0.0422 - pearson_correlation: 9.3728e-17 - r2_keras: -92.1875 - rmse: 0.9133 - sae: 1957.3347 - sse: 2554.3103 - val_huber_loss: 0.1299 - val_loss: 0.2937 - val_mae: 0.3783 - val_mse: 0.2694 - val_pearson_correlation: 6.9096e-16 - val_r2_keras: -41.0584 - val_rmse: 1.0561 - val_sae: 398.4209 - val_sse: 590.0003 - learning_rate: 1.0000e-05\n","Epoch 158/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0245 - loss: 0.1883 - mae: 0.1405 - mse: 0.0489 - pearson_correlation: -8.4156e-17 - r2_keras: -112.5676 - rmse: 0.9274 - sae: 2678.3403 - sse: 3522.7246\n","Epoch 158: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0186 - loss: 0.1847 - mae: 0.1264 - mse: 0.0418 - pearson_correlation: -3.5921e-17 - r2_keras: -92.2558 - rmse: 0.9141 - sae: 1956.4468 - sse: 2554.2761 - val_huber_loss: 0.1292 - val_loss: 0.2930 - val_mae: 0.3789 - val_mse: 0.2674 - val_pearson_correlation: -9.6149e-17 - val_r2_keras: -41.0823 - val_rmse: 1.0564 - val_sae: 398.7098 - val_sse: 590.3347 - learning_rate: 1.0000e-05\n","Epoch 159/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0243 - loss: 0.1880 - mae: 0.1392 - mse: 0.0485 - pearson_correlation: -9.5659e-17 - r2_keras: -112.2747 - rmse: 0.9262 - sae: 2673.6914 - sse: 3513.6387\n","Epoch 159: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0185 - loss: 0.1845 - mae: 0.1255 - mse: 0.0415 - pearson_correlation: -6.8837e-17 - r2_keras: -92.0020 - rmse: 0.9128 - sae: 1953.1909 - sse: 2547.5325 - val_huber_loss: 0.1295 - val_loss: 0.2933 - val_mae: 0.3775 - val_mse: 0.2685 - val_pearson_correlation: -1.3951e-16 - val_r2_keras: -41.1672 - val_rmse: 1.0574 - val_sae: 398.9297 - val_sse: 591.5261 - learning_rate: 1.0000e-05\n","Epoch 160/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0242 - loss: 0.1879 - mae: 0.1392 - mse: 0.0483 - pearson_correlation: -7.9456e-16 - r2_keras: -112.9208 - rmse: 0.9288 - sae: 2683.3237 - sse: 3533.6814\n","Epoch 160: val_loss did not improve from 0.28705\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0184 - loss: 0.1844 - mae: 0.1254 - mse: 0.0413 - pearson_correlation: -4.6054e-16 - r2_keras: -92.4418 - rmse: 0.9146 - sae: 1959.4606 - sse: 2561.0002 - val_huber_loss: 0.1298 - val_loss: 0.2935 - val_mae: 0.3796 - val_mse: 0.2689 - val_pearson_correlation: -2.6181e-17 - val_r2_keras: -41.1203 - val_rmse: 1.0569 - val_sae: 398.5916 - val_sse: 590.8677 - learning_rate: 1.0000e-05\n","| \u001b[39m13       \u001b[39m | \u001b[39m-0.2935  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m89.5     \u001b[39m | \u001b[39m49.37    \u001b[39m | \u001b[39m70.9     \u001b[39m | \u001b[39m11.33    \u001b[39m | \u001b[39m79.18    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.6095 - loss: 0.7628 - mae: 1.0286 - mse: 1.5302 - pearson_correlation: -1.8495e-16 - r2_keras: -163.4859 - rmse: 1.1161 - sae: 3619.6426 - sse: 5102.1470\n","Epoch 1: val_loss improved from inf to 0.38666, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 614ms/step - huber_loss: 0.5165 - loss: 0.7063 - mae: 0.9589 - mse: 1.3723 - pearson_correlation: 1.3461e-17 - r2_keras: -133.0207 - rmse: 1.0926 - sae: 2626.6013 - sse: 3687.2148 - val_huber_loss: 0.2328 - val_loss: 0.3867 - val_mae: 0.5538 - val_mse: 0.5890 - val_pearson_correlation: -2.7343e-16 - val_r2_keras: -22.1434 - val_rmse: 0.7834 - val_sae: 300.7124 - val_sse: 324.6584 - learning_rate: 0.0024\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2955 - loss: 0.4493 - mae: 0.6165 - mse: 0.7080 - pearson_correlation: -1.9656e-16 - r2_keras: -95.2550 - rmse: 0.8538 - sae: 2725.9817 - sse: 2985.7087\n","Epoch 2: val_loss improved from 0.38666 to 0.37514, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.3511 - loss: 0.4832 - mae: 0.6669 - mse: 0.7662 - pearson_correlation: -1.3531e-16 - r2_keras: -93.1199 - rmse: 0.9557 - sae: 2061.3015 - sse: 2341.7866 - val_huber_loss: 0.2212 - val_loss: 0.3751 - val_mae: 0.5349 - val_mse: 0.5617 - val_pearson_correlation: 8.5562e-17 - val_r2_keras: -22.2991 - val_rmse: 0.7860 - val_sae: 302.0544 - val_sse: 326.8426 - learning_rate: 0.0024\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1463 - loss: 0.3002 - mae: 0.4045 - mse: 0.3098 - pearson_correlation: -4.9529e-16 - r2_keras: -101.0356 - rmse: 0.8790 - sae: 2629.5830 - sse: 3165.0156\n","Epoch 3: val_loss did not improve from 0.37514\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1435 - loss: 0.2985 - mae: 0.4010 - mse: 0.3062 - pearson_correlation: -3.9666e-16 - r2_keras: -81.2033 - rmse: 0.8520 - sae: 1917.4056 - sse: 2276.3369 - val_huber_loss: 0.2297 - val_loss: 0.3833 - val_mae: 0.5647 - val_mse: 0.5699 - val_pearson_correlation: -1.5477e-16 - val_r2_keras: -22.2710 - val_rmse: 0.7856 - val_sae: 316.8766 - val_sse: 326.4485 - learning_rate: 0.0024\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1343 - loss: 0.2879 - mae: 0.3906 - mse: 0.2827 - pearson_correlation: 6.0195e-16 - r2_keras: -82.8645 - rmse: 0.7969 - sae: 2382.0728 - sse: 2601.3721\n","Epoch 4: val_loss did not improve from 0.37514\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1275 - loss: 0.2837 - mae: 0.3848 - mse: 0.2716 - pearson_correlation: 4.2649e-16 - r2_keras: -72.5500 - rmse: 0.8279 - sae: 1770.2277 - sse: 1941.1693 - val_huber_loss: 0.2423 - val_loss: 0.3956 - val_mae: 0.6024 - val_mse: 0.5818 - val_pearson_correlation: -1.2145e-16 - val_r2_keras: -22.8010 - val_rmse: 0.7945 - val_sae: 337.8679 - val_sse: 333.8833 - learning_rate: 0.0024\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1261 - loss: 0.2795 - mae: 0.3840 - mse: 0.2631 - pearson_correlation: 5.6292e-17 - r2_keras: -89.5858 - rmse: 0.8283 - sae: 2567.6426 - sse: 2809.8569\n","Epoch 5: val_loss improved from 0.37514 to 0.36911, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.1192 - loss: 0.2752 - mae: 0.3721 - mse: 0.2529 - pearson_correlation: 7.5096e-17 - r2_keras: -74.1112 - rmse: 0.8231 - sae: 1876.3422 - sse: 2045.9126 - val_huber_loss: 0.2161 - val_loss: 0.3691 - val_mae: 0.5615 - val_mse: 0.5167 - val_pearson_correlation: 2.9938e-16 - val_r2_keras: -23.6250 - val_rmse: 0.8081 - val_sae: 341.8200 - val_sse: 345.4422 - learning_rate: 0.0024\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0893 - loss: 0.2423 - mae: 0.2737 - mse: 0.1899 - pearson_correlation: -1.5190e-16 - r2_keras: -98.1676 - rmse: 0.8666 - sae: 2543.7183 - sse: 3076.0554\n","Epoch 6: val_loss improved from 0.36911 to 0.36256, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0856 - loss: 0.2400 - mae: 0.2725 - mse: 0.1833 - pearson_correlation: -1.6379e-16 - r2_keras: -79.9197 - rmse: 0.8495 - sae: 1854.6820 - sse: 2224.4014 - val_huber_loss: 0.2099 - val_loss: 0.3626 - val_mae: 0.5526 - val_mse: 0.4868 - val_pearson_correlation: -2.7044e-16 - val_r2_keras: -25.3562 - val_rmse: 0.8360 - val_sae: 360.4999 - val_sse: 369.7278 - learning_rate: 0.0024\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0894 - loss: 0.2421 - mae: 0.2796 - mse: 0.1831 - pearson_correlation: -5.4320e-16 - r2_keras: -100.2577 - rmse: 0.8757 - sae: 2645.6694 - sse: 3140.8879\n","Epoch 7: val_loss did not improve from 0.36256\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0836 - loss: 0.2385 - mae: 0.2812 - mse: 0.1752 - pearson_correlation: -3.3088e-16 - r2_keras: -83.5886 - rmse: 0.8757 - sae: 1938.1436 - sse: 2294.3149 - val_huber_loss: 0.2118 - val_loss: 0.3640 - val_mae: 0.5584 - val_mse: 0.4851 - val_pearson_correlation: -2.2641e-16 - val_r2_keras: -26.3590 - val_rmse: 0.8518 - val_sae: 368.9436 - val_sse: 383.7947 - learning_rate: 0.0024\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1029 - loss: 0.2551 - mae: 0.3257 - mse: 0.2146 - pearson_correlation: -2.6591e-16 - r2_keras: -95.1570 - rmse: 0.8533 - sae: 2564.5752 - sse: 2982.6699\n","Epoch 8: val_loss improved from 0.36256 to 0.35589, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - huber_loss: 0.0948 - loss: 0.2502 - mae: 0.3236 - mse: 0.2030 - pearson_correlation: -1.3933e-16 - r2_keras: -80.2995 - rmse: 0.8617 - sae: 1886.8768 - sse: 2190.1428 - val_huber_loss: 0.2041 - val_loss: 0.3559 - val_mae: 0.5396 - val_mse: 0.4626 - val_pearson_correlation: 1.5855e-16 - val_r2_keras: -29.4527 - val_rmse: 0.8986 - val_sae: 376.8230 - val_sse: 427.1937 - learning_rate: 0.0024\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1292 - loss: 0.2811 - mae: 0.3972 - mse: 0.2661 - pearson_correlation: -4.4663e-16 - r2_keras: -104.9209 - rmse: 0.8956 - sae: 2769.4792 - sse: 3285.5334\n","Epoch 9: val_loss did not improve from 0.35589\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1122 - loss: 0.2707 - mae: 0.3822 - mse: 0.2438 - pearson_correlation: -3.2458e-16 - r2_keras: -86.7454 - rmse: 0.8894 - sae: 2027.5775 - sse: 2391.3088 - val_huber_loss: 0.3426 - val_loss: 0.4941 - val_mae: 0.7069 - val_mse: 0.7394 - val_pearson_correlation: -5.6397e-17 - val_r2_keras: -38.3170 - val_rmse: 1.0211 - val_sae: 451.2449 - val_sse: 551.5433 - learning_rate: 0.0024\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1598 - loss: 0.3113 - mae: 0.4447 - mse: 0.3413 - pearson_correlation: 2.3695e-16 - r2_keras: -110.3535 - rmse: 0.9183 - sae: 2932.3411 - sse: 3454.0461\n","Epoch 10: val_loss improved from 0.35589 to 0.29140, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.1444 - loss: 0.3019 - mae: 0.4344 - mse: 0.3182 - pearson_correlation: 1.7305e-16 - r2_keras: -93.3432 - rmse: 0.9289 - sae: 2150.5942 - sse: 2538.5596 - val_huber_loss: 0.1403 - val_loss: 0.2914 - val_mae: 0.3769 - val_mse: 0.3186 - val_pearson_correlation: 2.5514e-16 - val_r2_keras: -31.9154 - val_rmse: 0.9343 - val_sae: 368.0112 - val_sse: 461.7411 - learning_rate: 0.0024\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1309 - loss: 0.2821 - mae: 0.3894 - mse: 0.2822 - pearson_correlation: -3.2328e-16 - r2_keras: -117.3770 - rmse: 0.9468 - sae: 3005.1055 - sse: 3671.9053\n","Epoch 11: val_loss did not improve from 0.29140\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1159 - loss: 0.2729 - mae: 0.3755 - mse: 0.2599 - pearson_correlation: -1.6588e-16 - r2_keras: -95.7752 - rmse: 0.9296 - sae: 2184.1306 - sse: 2657.4026 - val_huber_loss: 0.1577 - val_loss: 0.3084 - val_mae: 0.4251 - val_mse: 0.3519 - val_pearson_correlation: 2.5849e-16 - val_r2_keras: -37.8901 - val_rmse: 1.0155 - val_sae: 406.9351 - val_sse: 545.5552 - learning_rate: 0.0024\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1236 - loss: 0.2744 - mae: 0.3285 - mse: 0.2593 - pearson_correlation: -1.4265e-16 - r2_keras: -111.4390 - rmse: 0.9228 - sae: 2799.6584 - sse: 3487.7158\n","Epoch 12: val_loss did not improve from 0.29140\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1129 - loss: 0.2678 - mae: 0.3225 - mse: 0.2439 - pearson_correlation: -1.1999e-16 - r2_keras: -94.1634 - rmse: 0.9326 - sae: 2056.9314 - sse: 2562.1387 - val_huber_loss: 0.1573 - val_loss: 0.3076 - val_mae: 0.4377 - val_mse: 0.3717 - val_pearson_correlation: -1.5628e-16 - val_r2_keras: -31.1342 - val_rmse: 0.9231 - val_sae: 361.6043 - val_sse: 450.7826 - learning_rate: 0.0024\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1279 - loss: 0.2783 - mae: 0.4075 - mse: 0.2634 - pearson_correlation: 2.6475e-16 - r2_keras: -107.4437 - rmse: 0.9062 - sae: 2763.1030 - sse: 3363.7876\n","Epoch 13: val_loss did not improve from 0.29140\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1182 - loss: 0.2723 - mae: 0.3923 - mse: 0.2501 - pearson_correlation: 2.2775e-16 - r2_keras: -89.7087 - rmse: 0.9072 - sae: 2030.7157 - sse: 2458.5093 - val_huber_loss: 0.1473 - val_loss: 0.2972 - val_mae: 0.3967 - val_mse: 0.3347 - val_pearson_correlation: 1.2023e-16 - val_r2_keras: -32.0202 - val_rmse: 0.9358 - val_sae: 359.2892 - val_sse: 463.2109 - learning_rate: 0.0024\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1116 - loss: 0.2615 - mae: 0.3743 - mse: 0.2265 - pearson_correlation: -1.5475e-16 - r2_keras: -95.6242 - rmse: 0.8554 - sae: 2577.5178 - sse: 2997.1606\n","Epoch 14: val_loss did not improve from 0.29140\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0956 - loss: 0.2517 - mae: 0.3557 - mse: 0.2063 - pearson_correlation: -1.5340e-16 - r2_keras: -81.0738 - rmse: 0.8670 - sae: 1899.4695 - sse: 2205.2324 - val_huber_loss: 0.1664 - val_loss: 0.3158 - val_mae: 0.4273 - val_mse: 0.3809 - val_pearson_correlation: -7.3843e-17 - val_r2_keras: -34.9710 - val_rmse: 0.9767 - val_sae: 368.6519 - val_sse: 504.6047 - learning_rate: 0.0024\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0948 - loss: 0.2441 - mae: 0.3123 - mse: 0.1928 - pearson_correlation: -4.7917e-16 - r2_keras: -96.2452 - rmse: 0.8582 - sae: 2542.5928 - sse: 3016.4233\n","Epoch 15: val_loss improved from 0.29140 to 0.26145, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.0798 - loss: 0.2350 - mae: 0.2952 - mse: 0.1739 - pearson_correlation: -2.8193e-16 - r2_keras: -81.9264 - rmse: 0.8725 - sae: 1875.1517 - sse: 2223.2190 - val_huber_loss: 0.1126 - val_loss: 0.2615 - val_mae: 0.3069 - val_mse: 0.2545 - val_pearson_correlation: -5.2845e-17 - val_r2_keras: -30.2725 - val_rmse: 0.9107 - val_sae: 342.8148 - val_sse: 438.6940 - learning_rate: 0.0024\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0912 - loss: 0.2400 - mae: 0.2782 - mse: 0.1857 - pearson_correlation: -2.5103e-17 - r2_keras: -99.8469 - rmse: 0.8739 - sae: 2643.3386 - sse: 3128.1450\n","Epoch 16: val_loss did not improve from 0.26145\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0837 - loss: 0.2354 - mae: 0.2760 - mse: 0.1760 - pearson_correlation: 4.3709e-18 - r2_keras: -81.9120 - rmse: 0.8623 - sae: 1927.3279 - sse: 2269.3657 - val_huber_loss: 0.1499 - val_loss: 0.2982 - val_mae: 0.4063 - val_mse: 0.3269 - val_pearson_correlation: 1.8605e-16 - val_r2_keras: -38.7069 - val_rmse: 1.0261 - val_sae: 399.0955 - val_sse: 557.0133 - learning_rate: 0.0024\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0854 - loss: 0.2337 - mae: 0.2689 - mse: 0.1771 - pearson_correlation: 3.1940e-16 - r2_keras: -110.9117 - rmse: 0.9206 - sae: 2742.5769 - sse: 3471.3608\n","Epoch 17: val_loss did not improve from 0.26145\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0769 - loss: 0.2284 - mae: 0.2586 - mse: 0.1655 - pearson_correlation: 2.3797e-16 - r2_keras: -91.8811 - rmse: 0.9156 - sae: 2007.4775 - sse: 2528.5872 - val_huber_loss: 0.1318 - val_loss: 0.2795 - val_mae: 0.3575 - val_mse: 0.2942 - val_pearson_correlation: -2.5497e-16 - val_r2_keras: -30.9333 - val_rmse: 0.9202 - val_sae: 350.7965 - val_sse: 447.9643 - learning_rate: 0.0024\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0916 - loss: 0.2393 - mae: 0.2996 - mse: 0.1950 - pearson_correlation: -4.5469e-16 - r2_keras: -88.8038 - rmse: 0.8247 - sae: 2459.4258 - sse: 2785.6016\n","Epoch 18: val_loss did not improve from 0.26145\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0866 - loss: 0.2362 - mae: 0.2997 - mse: 0.1865 - pearson_correlation: -2.8533e-16 - r2_keras: -74.8748 - rmse: 0.8323 - sae: 1809.0210 - sse: 2044.8136 - val_huber_loss: 0.1539 - val_loss: 0.3010 - val_mae: 0.4340 - val_mse: 0.3407 - val_pearson_correlation: -3.6022e-16 - val_r2_keras: -34.3383 - val_rmse: 0.9680 - val_sae: 374.2233 - val_sse: 495.7296 - learning_rate: 0.0024\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0988 - loss: 0.2459 - mae: 0.3315 - mse: 0.2075 - pearson_correlation: 2.4001e-16 - r2_keras: -108.5349 - rmse: 0.9108 - sae: 2714.4009 - sse: 3397.6362\n","Epoch 19: val_loss did not improve from 0.26145\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0812 - loss: 0.2351 - mae: 0.3109 - mse: 0.1841 - pearson_correlation: 2.0973e-16 - r2_keras: -88.7475 - rmse: 0.8960 - sae: 1983.9420 - sse: 2461.2659 - val_huber_loss: 0.1290 - val_loss: 0.2755 - val_mae: 0.3462 - val_mse: 0.2798 - val_pearson_correlation: -2.7142e-16 - val_r2_keras: -35.2587 - val_rmse: 0.9806 - val_sae: 372.1113 - val_sse: 508.6403 - learning_rate: 0.0024\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0843 - loss: 0.2308 - mae: 0.2566 - mse: 0.1781 - pearson_correlation: -1.4922e-16 - r2_keras: -105.0953 - rmse: 0.8964 - sae: 2625.0940 - sse: 3290.9438\n","Epoch 20: val_loss improved from 0.26145 to 0.25575, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0730 - loss: 0.2238 - mae: 0.2557 - mse: 0.1624 - pearson_correlation: -7.6151e-17 - r2_keras: -86.3005 - rmse: 0.8850 - sae: 1924.0458 - sse: 2388.3323 - val_huber_loss: 0.1100 - val_loss: 0.2557 - val_mae: 0.3230 - val_mse: 0.2363 - val_pearson_correlation: -5.2782e-17 - val_r2_keras: -35.0107 - val_rmse: 0.9772 - val_sae: 375.4862 - val_sse: 505.1622 - learning_rate: 0.0024\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1050 - loss: 0.2508 - mae: 0.3453 - mse: 0.2230 - pearson_correlation: 3.7097e-16 - r2_keras: -116.0838 - rmse: 0.9416 - sae: 2936.2734 - sse: 3631.7935\n","Epoch 21: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0981 - loss: 0.2465 - mae: 0.3472 - mse: 0.2119 - pearson_correlation: 2.3627e-16 - r2_keras: -94.4724 - rmse: 0.9225 - sae: 2143.4465 - sse: 2625.4924 - val_huber_loss: 0.1616 - val_loss: 0.3067 - val_mae: 0.4175 - val_mse: 0.3425 - val_pearson_correlation: -1.6691e-16 - val_r2_keras: -42.9261 - val_rmse: 1.0793 - val_sae: 430.4039 - val_sse: 616.2007 - learning_rate: 0.0024\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1185 - loss: 0.2636 - mae: 0.3603 - mse: 0.2521 - pearson_correlation: 4.4560e-16 - r2_keras: -125.3591 - rmse: 0.9782 - sae: 3020.1821 - sse: 3919.5017\n","Epoch 22: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1039 - loss: 0.2546 - mae: 0.3482 - mse: 0.2312 - pearson_correlation: 2.2442e-16 - r2_keras: -100.7572 - rmse: 0.9477 - sae: 2190.0955 - sse: 2818.4849 - val_huber_loss: 0.1327 - val_loss: 0.2773 - val_mae: 0.3950 - val_mse: 0.2952 - val_pearson_correlation: -3.4050e-17 - val_r2_keras: -35.0773 - val_rmse: 0.9781 - val_sae: 372.2630 - val_sse: 506.0956 - learning_rate: 0.0024\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1102 - loss: 0.2548 - mae: 0.3641 - mse: 0.2320 - pearson_correlation: -1.4789e-16 - r2_keras: -123.0952 - rmse: 0.9694 - sae: 3014.7300 - sse: 3849.2769\n","Epoch 23: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1127 - loss: 0.2563 - mae: 0.3736 - mse: 0.2328 - pearson_correlation: -1.2894e-16 - r2_keras: -100.1835 - rmse: 0.9496 - sae: 2201.3979 - sse: 2782.6433 - val_huber_loss: 0.2623 - val_loss: 0.4064 - val_mae: 0.6451 - val_mse: 0.5690 - val_pearson_correlation: -1.2803e-16 - val_r2_keras: -46.2351 - val_rmse: 1.1192 - val_sae: 463.4504 - val_sse: 662.6197 - learning_rate: 0.0024\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1069 - loss: 0.2509 - mae: 0.3636 - mse: 0.2184 - pearson_correlation: 2.7017e-17 - r2_keras: -112.4803 - rmse: 0.9270 - sae: 2847.9521 - sse: 3520.0161\n","Epoch 24: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0933 - loss: 0.2426 - mae: 0.3418 - mse: 0.2013 - pearson_correlation: -6.9333e-19 - r2_keras: -93.5763 - rmse: 0.9252 - sae: 2081.1313 - sse: 2568.6421 - val_huber_loss: 0.1673 - val_loss: 0.3107 - val_mae: 0.4614 - val_mse: 0.3798 - val_pearson_correlation: -9.7686e-17 - val_r2_keras: -29.1017 - val_rmse: 0.8934 - val_sae: 337.6763 - val_sse: 422.2699 - learning_rate: 0.0024\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1148 - loss: 0.2583 - mae: 0.3887 - mse: 0.2426 - pearson_correlation: -5.3933e-16 - r2_keras: -94.0396 - rmse: 0.8484 - sae: 2516.9751 - sse: 2948.0088\n","Epoch 25: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0944 - loss: 0.2458 - mae: 0.3643 - mse: 0.2150 - pearson_correlation: -3.3337e-16 - r2_keras: -80.3966 - rmse: 0.8655 - sae: 1861.7314 - sse: 2176.9126 - val_huber_loss: 0.1402 - val_loss: 0.2829 - val_mae: 0.3698 - val_mse: 0.3099 - val_pearson_correlation: -4.9565e-16 - val_r2_keras: -34.5109 - val_rmse: 0.9704 - val_sae: 363.3847 - val_sse: 498.1502 - learning_rate: 0.0024\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0913 - loss: 0.2340 - mae: 0.2751 - mse: 0.2036 - pearson_correlation: 2.0220e-17 - r2_keras: -110.8177 - rmse: 0.9202 - sae: 2643.9102 - sse: 3468.4448\n","Epoch 26: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0705 - loss: 0.2213 - mae: 0.2553 - mse: 0.1740 - pearson_correlation: -8.0077e-17 - r2_keras: -90.9089 - rmse: 0.9077 - sae: 1934.5812 - sse: 2515.9744 - val_huber_loss: 0.1245 - val_loss: 0.2670 - val_mae: 0.3465 - val_mse: 0.2765 - val_pearson_correlation: 2.2705e-17 - val_r2_keras: -33.4578 - val_rmse: 0.9559 - val_sae: 355.2704 - val_sse: 483.3773 - learning_rate: 4.7206e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0802 - loss: 0.2227 - mae: 0.2443 - mse: 0.1762 - pearson_correlation: 2.2852e-16 - r2_keras: -109.5574 - rmse: 0.9150 - sae: 2644.0940 - sse: 3429.3523\n","Epoch 27: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0613 - loss: 0.2112 - mae: 0.2250 - mse: 0.1499 - pearson_correlation: 1.6976e-16 - r2_keras: -89.7019 - rmse: 0.9012 - sae: 1932.8551 - sse: 2485.6099 - val_huber_loss: 0.1208 - val_loss: 0.2632 - val_mae: 0.3381 - val_mse: 0.2683 - val_pearson_correlation: 8.0191e-17 - val_r2_keras: -33.2619 - val_rmse: 0.9532 - val_sae: 354.2946 - val_sse: 480.6303 - learning_rate: 4.7206e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0760 - loss: 0.2184 - mae: 0.2316 - mse: 0.1645 - pearson_correlation: 2.6637e-16 - r2_keras: -108.4402 - rmse: 0.9104 - sae: 2641.0791 - sse: 3394.6990\n","Epoch 28: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0580 - loss: 0.2074 - mae: 0.2128 - mse: 0.1400 - pearson_correlation: 2.2379e-16 - r2_keras: -88.9408 - rmse: 0.8979 - sae: 1930.8104 - sse: 2462.3159 - val_huber_loss: 0.1188 - val_loss: 0.2610 - val_mae: 0.3330 - val_mse: 0.2635 - val_pearson_correlation: -2.6833e-16 - val_r2_keras: -32.8651 - val_rmse: 0.9476 - val_sae: 351.8520 - val_sse: 475.0631 - learning_rate: 4.7206e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0728 - loss: 0.2150 - mae: 0.2270 - mse: 0.1553 - pearson_correlation: -6.4958e-17 - r2_keras: -106.8291 - rmse: 0.9036 - sae: 2630.0825 - sse: 3344.7231\n","Epoch 29: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0556 - loss: 0.2045 - mae: 0.2089 - mse: 0.1324 - pearson_correlation: -7.7274e-17 - r2_keras: -87.8818 - rmse: 0.8936 - sae: 1923.6381 - sse: 2429.1765 - val_huber_loss: 0.1174 - val_loss: 0.2594 - val_mae: 0.3301 - val_mse: 0.2598 - val_pearson_correlation: 9.4729e-17 - val_r2_keras: -32.5526 - val_rmse: 0.9433 - val_sae: 349.6475 - val_sse: 470.6798 - learning_rate: 4.7206e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0701 - loss: 0.2121 - mae: 0.2231 - mse: 0.1486 - pearson_correlation: 5.8577e-16 - r2_keras: -106.0055 - rmse: 0.9002 - sae: 2623.7256 - sse: 3319.1772\n","Epoch 30: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0535 - loss: 0.2019 - mae: 0.2058 - mse: 0.1266 - pearson_correlation: 3.7830e-16 - r2_keras: -87.3107 - rmse: 0.8911 - sae: 1919.4886 - sse: 2411.8867 - val_huber_loss: 0.1159 - val_loss: 0.2577 - val_mae: 0.3261 - val_mse: 0.2559 - val_pearson_correlation: 1.4314e-16 - val_r2_keras: -32.4089 - val_rmse: 0.9412 - val_sae: 348.4079 - val_sse: 468.6634 - learning_rate: 4.7206e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0677 - loss: 0.2094 - mae: 0.2190 - mse: 0.1426 - pearson_correlation: -9.6503e-18 - r2_keras: -105.2199 - rmse: 0.8969 - sae: 2617.9458 - sse: 3294.8083\n","Epoch 31: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0515 - loss: 0.1996 - mae: 0.2008 - mse: 0.1215 - pearson_correlation: 4.4233e-17 - r2_keras: -86.7626 - rmse: 0.8887 - sae: 1915.1097 - sse: 2395.3552 - val_huber_loss: 0.1151 - val_loss: 0.2568 - val_mae: 0.3258 - val_mse: 0.2537 - val_pearson_correlation: -1.4331e-16 - val_r2_keras: -32.3605 - val_rmse: 0.9406 - val_sae: 348.5264 - val_sse: 467.9844 - learning_rate: 9.4412e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0673 - loss: 0.2090 - mae: 0.2178 - mse: 0.1419 - pearson_correlation: 6.5464e-16 - r2_keras: -105.2794 - rmse: 0.8971 - sae: 2618.6543 - sse: 3296.6543\n","Epoch 32: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0512 - loss: 0.1992 - mae: 0.1999 - mse: 0.1208 - pearson_correlation: 5.2889e-16 - r2_keras: -86.8253 - rmse: 0.8890 - sae: 1915.7181 - sse: 2396.8555 - val_huber_loss: 0.1146 - val_loss: 0.2563 - val_mae: 0.3257 - val_mse: 0.2524 - val_pearson_correlation: -4.7765e-17 - val_r2_keras: -32.3448 - val_rmse: 0.9403 - val_sae: 348.6964 - val_sse: 467.7646 - learning_rate: 9.4412e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0669 - loss: 0.2086 - mae: 0.2167 - mse: 0.1411 - pearson_correlation: 1.0290e-16 - r2_keras: -105.3934 - rmse: 0.8976 - sae: 2619.6599 - sse: 3300.1904\n","Epoch 33: val_loss did not improve from 0.25575\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0509 - loss: 0.1988 - mae: 0.1990 - mse: 0.1201 - pearson_correlation: 6.1643e-17 - r2_keras: -86.9419 - rmse: 0.8897 - sae: 1916.5919 - sse: 2399.6892 - val_huber_loss: 0.1142 - val_loss: 0.2558 - val_mae: 0.3253 - val_mse: 0.2512 - val_pearson_correlation: 8.3600e-17 - val_r2_keras: -32.3351 - val_rmse: 0.9402 - val_sae: 348.7289 - val_sse: 467.6284 - learning_rate: 9.4412e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0666 - loss: 0.2082 - mae: 0.2156 - mse: 0.1403 - pearson_correlation: -3.5390e-16 - r2_keras: -105.5070 - rmse: 0.8981 - sae: 2620.6494 - sse: 3303.7144\n","Epoch 34: val_loss improved from 0.25575 to 0.25547, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0506 - loss: 0.1984 - mae: 0.1980 - mse: 0.1194 - pearson_correlation: -1.8641e-16 - r2_keras: -87.0383 - rmse: 0.8902 - sae: 1917.3434 - sse: 2402.2812 - val_huber_loss: 0.1139 - val_loss: 0.2555 - val_mae: 0.3251 - val_mse: 0.2503 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.3452 - val_rmse: 0.9403 - val_sae: 348.8376 - val_sse: 467.7698 - learning_rate: 9.4412e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0662 - loss: 0.2077 - mae: 0.2147 - mse: 0.1395 - pearson_correlation: 3.4158e-16 - r2_keras: -105.5626 - rmse: 0.8983 - sae: 2621.0747 - sse: 3305.4397\n","Epoch 35: val_loss improved from 0.25547 to 0.25499, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0503 - loss: 0.1980 - mae: 0.1969 - mse: 0.1187 - pearson_correlation: 2.3206e-16 - r2_keras: -87.0962 - rmse: 0.8905 - sae: 1917.6859 - sse: 2403.6760 - val_huber_loss: 0.1135 - val_loss: 0.2550 - val_mae: 0.3246 - val_mse: 0.2492 - val_pearson_correlation: -9.5424e-17 - val_r2_keras: -32.3524 - val_rmse: 0.9404 - val_sae: 348.8568 - val_sse: 467.8708 - learning_rate: 9.4412e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0658 - loss: 0.2073 - mae: 0.2136 - mse: 0.1388 - pearson_correlation: -5.2883e-16 - r2_keras: -105.7413 - rmse: 0.8991 - sae: 2622.5090 - sse: 3310.9819\n","Epoch 36: val_loss improved from 0.25499 to 0.25468, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0499 - loss: 0.1976 - mae: 0.1958 - mse: 0.1180 - pearson_correlation: -3.4214e-16 - r2_keras: -87.2199 - rmse: 0.8911 - sae: 1918.6260 - sse: 2407.4241 - val_huber_loss: 0.1133 - val_loss: 0.2547 - val_mae: 0.3240 - val_mse: 0.2484 - val_pearson_correlation: -7.1502e-17 - val_r2_keras: -32.3674 - val_rmse: 0.9407 - val_sae: 348.9037 - val_sse: 468.0809 - learning_rate: 9.4412e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0654 - loss: 0.2068 - mae: 0.2126 - mse: 0.1380 - pearson_correlation: 7.1645e-17 - r2_keras: -105.9109 - rmse: 0.8998 - sae: 2623.7629 - sse: 3316.2412\n","Epoch 37: val_loss improved from 0.25468 to 0.25439, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0496 - loss: 0.1972 - mae: 0.1946 - mse: 0.1173 - pearson_correlation: -3.3687e-17 - r2_keras: -87.3493 - rmse: 0.8917 - sae: 1919.4474 - sse: 2411.1228 - val_huber_loss: 0.1131 - val_loss: 0.2544 - val_mae: 0.3238 - val_mse: 0.2477 - val_pearson_correlation: 4.1698e-16 - val_r2_keras: -32.3769 - val_rmse: 0.9408 - val_sae: 348.8040 - val_sse: 468.2149 - learning_rate: 9.4412e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0650 - loss: 0.2063 - mae: 0.2118 - mse: 0.1371 - pearson_correlation: -1.1494e-17 - r2_keras: -105.8401 - rmse: 0.8995 - sae: 2623.0337 - sse: 3314.0476\n","Epoch 38: val_loss improved from 0.25439 to 0.25399, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0493 - loss: 0.1967 - mae: 0.1939 - mse: 0.1165 - pearson_correlation: 8.4138e-17 - r2_keras: -87.3103 - rmse: 0.8916 - sae: 1918.9503 - sse: 2409.7559 - val_huber_loss: 0.1128 - val_loss: 0.2540 - val_mae: 0.3232 - val_mse: 0.2468 - val_pearson_correlation: 1.5470e-16 - val_r2_keras: -32.3984 - val_rmse: 0.9411 - val_sae: 348.8279 - val_sse: 468.5171 - learning_rate: 9.4412e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0647 - loss: 0.2059 - mae: 0.2106 - mse: 0.1365 - pearson_correlation: -4.0977e-16 - r2_keras: -106.1101 - rmse: 0.9006 - sae: 2625.1675 - sse: 3322.4211\n","Epoch 39: val_loss improved from 0.25399 to 0.25374, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0489 - loss: 0.1963 - mae: 0.1927 - mse: 0.1159 - pearson_correlation: -3.5089e-16 - r2_keras: -87.5357 - rmse: 0.8927 - sae: 1920.4823 - sse: 2415.8711 - val_huber_loss: 0.1126 - val_loss: 0.2537 - val_mae: 0.3231 - val_mse: 0.2462 - val_pearson_correlation: 2.0218e-16 - val_r2_keras: -32.4146 - val_rmse: 0.9413 - val_sae: 348.7236 - val_sse: 468.7433 - learning_rate: 9.4412e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0643 - loss: 0.2055 - mae: 0.2100 - mse: 0.1358 - pearson_correlation: -7.8010e-17 - r2_keras: -106.1255 - rmse: 0.9007 - sae: 2625.3325 - sse: 3322.8984\n","Epoch 40: val_loss improved from 0.25374 to 0.25342, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.0486 - loss: 0.1959 - mae: 0.1921 - mse: 0.1152 - pearson_correlation: -1.7459e-17 - r2_keras: -87.5433 - rmse: 0.8927 - sae: 1920.5117 - sse: 2416.1580 - val_huber_loss: 0.1124 - val_loss: 0.2534 - val_mae: 0.3230 - val_mse: 0.2455 - val_pearson_correlation: 2.8524e-16 - val_r2_keras: -32.4321 - val_rmse: 0.9416 - val_sae: 348.6676 - val_sse: 468.9893 - learning_rate: 9.4412e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0640 - loss: 0.2050 - mae: 0.2091 - mse: 0.1351 - pearson_correlation: 6.6401e-17 - r2_keras: -106.3233 - rmse: 0.9015 - sae: 2626.5083 - sse: 3329.0344\n","Epoch 41: val_loss improved from 0.25342 to 0.25318, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0483 - loss: 0.1955 - mae: 0.1912 - mse: 0.1146 - pearson_correlation: -2.6411e-17 - r2_keras: -87.7070 - rmse: 0.8935 - sae: 1921.4119 - sse: 2420.6223 - val_huber_loss: 0.1122 - val_loss: 0.2532 - val_mae: 0.3227 - val_mse: 0.2450 - val_pearson_correlation: -1.6615e-16 - val_r2_keras: -32.4601 - val_rmse: 0.9420 - val_sae: 348.7176 - val_sse: 469.3822 - learning_rate: 9.4412e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0636 - loss: 0.2046 - mae: 0.2081 - mse: 0.1344 - pearson_correlation: 4.4075e-16 - r2_keras: -106.5572 - rmse: 0.9025 - sae: 2627.9910 - sse: 3336.2898\n","Epoch 42: val_loss improved from 0.25318 to 0.25280, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0480 - loss: 0.1951 - mae: 0.1901 - mse: 0.1140 - pearson_correlation: 2.7836e-16 - r2_keras: -87.9023 - rmse: 0.8945 - sae: 1922.4740 - sse: 2425.9202 - val_huber_loss: 0.1119 - val_loss: 0.2528 - val_mae: 0.3227 - val_mse: 0.2442 - val_pearson_correlation: -3.7984e-16 - val_r2_keras: -32.4622 - val_rmse: 0.9420 - val_sae: 348.4886 - val_sse: 469.4107 - learning_rate: 9.4412e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0633 - loss: 0.2041 - mae: 0.2076 - mse: 0.1337 - pearson_correlation: 2.0746e-16 - r2_keras: -106.5106 - rmse: 0.9023 - sae: 2626.9917 - sse: 3334.8442\n","Epoch 43: val_loss improved from 0.25280 to 0.25230, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0477 - loss: 0.1946 - mae: 0.1896 - mse: 0.1133 - pearson_correlation: 1.6577e-16 - r2_keras: -87.9006 - rmse: 0.8947 - sae: 1921.9396 - sse: 2425.3013 - val_huber_loss: 0.1115 - val_loss: 0.2523 - val_mae: 0.3224 - val_mse: 0.2431 - val_pearson_correlation: 7.1332e-17 - val_r2_keras: -32.4400 - val_rmse: 0.9417 - val_sae: 348.0764 - val_sse: 469.0994 - learning_rate: 9.4412e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0629 - loss: 0.2037 - mae: 0.2069 - mse: 0.1329 - pearson_correlation: -1.7681e-16 - r2_keras: -106.6239 - rmse: 0.9028 - sae: 2627.8625 - sse: 3338.3584\n","Epoch 44: val_loss improved from 0.25230 to 0.25229, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0475 - loss: 0.1942 - mae: 0.1887 - mse: 0.1126 - pearson_correlation: -1.3849e-16 - r2_keras: -87.9598 - rmse: 0.8948 - sae: 1922.3470 - sse: 2427.4519 - val_huber_loss: 0.1117 - val_loss: 0.2523 - val_mae: 0.3229 - val_mse: 0.2431 - val_pearson_correlation: -2.2547e-16 - val_r2_keras: -32.4729 - val_rmse: 0.9421 - val_sae: 348.2001 - val_sse: 469.5617 - learning_rate: 9.4412e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0626 - loss: 0.2032 - mae: 0.2065 - mse: 0.1320 - pearson_correlation: 1.9539e-16 - r2_keras: -106.5607 - rmse: 0.9025 - sae: 2627.0850 - sse: 3336.3984\n","Epoch 45: val_loss improved from 0.25229 to 0.25187, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0472 - loss: 0.1938 - mae: 0.1882 - mse: 0.1119 - pearson_correlation: 1.3197e-16 - r2_keras: -87.9975 - rmse: 0.8953 - sae: 1922.2026 - sse: 2427.0820 - val_huber_loss: 0.1113 - val_loss: 0.2519 - val_mae: 0.3227 - val_mse: 0.2422 - val_pearson_correlation: 3.5621e-17 - val_r2_keras: -32.4566 - val_rmse: 0.9419 - val_sae: 348.1275 - val_sse: 469.3323 - learning_rate: 9.4412e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0622 - loss: 0.2028 - mae: 0.2043 - mse: 0.1317 - pearson_correlation: -1.1574e-16 - r2_keras: -107.2776 - rmse: 0.9055 - sae: 2633.3774 - sse: 3358.6367\n","Epoch 46: val_loss improved from 0.25187 to 0.25137, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0469 - loss: 0.1934 - mae: 0.1862 - mse: 0.1116 - pearson_correlation: -1.0447e-16 - r2_keras: -88.5036 - rmse: 0.8976 - sae: 1926.4362 - sse: 2442.2383 - val_huber_loss: 0.1110 - val_loss: 0.2514 - val_mae: 0.3231 - val_mse: 0.2412 - val_pearson_correlation: 1.1310e-16 - val_r2_keras: -32.4193 - val_rmse: 0.9414 - val_sae: 347.5538 - val_sse: 468.8092 - learning_rate: 9.4412e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0619 - loss: 0.2023 - mae: 0.2049 - mse: 0.1305 - pearson_correlation: 6.9736e-16 - r2_keras: -106.7056 - rmse: 0.9031 - sae: 2627.8936 - sse: 3340.8916\n","Epoch 47: val_loss improved from 0.25137 to 0.25133, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0466 - loss: 0.1930 - mae: 0.1863 - mse: 0.1105 - pearson_correlation: 4.9054e-16 - r2_keras: -88.1017 - rmse: 0.8958 - sae: 1922.6255 - sse: 2430.1675 - val_huber_loss: 0.1110 - val_loss: 0.2513 - val_mae: 0.3230 - val_mse: 0.2412 - val_pearson_correlation: 1.1871e-17 - val_r2_keras: -32.4757 - val_rmse: 0.9422 - val_sae: 347.7975 - val_sse: 469.6014 - learning_rate: 9.4412e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0617 - loss: 0.2020 - mae: 0.2027 - mse: 0.1309 - pearson_correlation: -2.6738e-16 - r2_keras: -107.6896 - rmse: 0.9072 - sae: 2636.4009 - sse: 3371.4158\n","Epoch 48: val_loss improved from 0.25133 to 0.25110, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0464 - loss: 0.1927 - mae: 0.1845 - mse: 0.1107 - pearson_correlation: -2.2079e-16 - r2_keras: -88.8261 - rmse: 0.8991 - sae: 1928.5953 - sse: 2451.3188 - val_huber_loss: 0.1109 - val_loss: 0.2511 - val_mae: 0.3229 - val_mse: 0.2408 - val_pearson_correlation: -4.1603e-16 - val_r2_keras: -32.4538 - val_rmse: 0.9419 - val_sae: 347.4203 - val_sse: 469.2936 - learning_rate: 9.4412e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0613 - loss: 0.2014 - mae: 0.2021 - mse: 0.1294 - pearson_correlation: -1.1734e-16 - r2_keras: -107.2915 - rmse: 0.9056 - sae: 2632.6338 - sse: 3359.0657\n","Epoch 49: val_loss improved from 0.25110 to 0.25050, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0461 - loss: 0.1922 - mae: 0.1838 - mse: 0.1095 - pearson_correlation: -8.5014e-17 - r2_keras: -88.5997 - rmse: 0.8984 - sae: 1926.1703 - sse: 2443.5430 - val_huber_loss: 0.1105 - val_loss: 0.2505 - val_mae: 0.3231 - val_mse: 0.2397 - val_pearson_correlation: 1.7893e-17 - val_r2_keras: -32.3944 - val_rmse: 0.9410 - val_sae: 346.8788 - val_sse: 468.4604 - learning_rate: 9.4412e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0611 - loss: 0.2011 - mae: 0.2022 - mse: 0.1292 - pearson_correlation: 4.4979e-16 - r2_keras: -107.3271 - rmse: 0.9057 - sae: 2632.4270 - sse: 3360.1724\n","Epoch 50: val_loss did not improve from 0.25050\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0459 - loss: 0.1919 - mae: 0.1835 - mse: 0.1093 - pearson_correlation: 2.3521e-16 - r2_keras: -88.5865 - rmse: 0.8981 - sae: 1925.7996 - sse: 2443.8464 - val_huber_loss: 0.1110 - val_loss: 0.2510 - val_mae: 0.3233 - val_mse: 0.2407 - val_pearson_correlation: -9.4921e-17 - val_r2_keras: -32.4843 - val_rmse: 0.9423 - val_sae: 347.5814 - val_sse: 469.7220 - learning_rate: 9.4412e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0607 - loss: 0.2006 - mae: 0.2000 - mse: 0.1282 - pearson_correlation: -2.7745e-16 - r2_keras: -107.7245 - rmse: 0.9074 - sae: 2635.8777 - sse: 3372.4971\n","Epoch 51: val_loss improved from 0.25050 to 0.25045, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0456 - loss: 0.1914 - mae: 0.1815 - mse: 0.1084 - pearson_correlation: -1.4778e-16 - r2_keras: -88.9564 - rmse: 0.9001 - sae: 1928.5619 - sse: 2453.2954 - val_huber_loss: 0.1107 - val_loss: 0.2505 - val_mae: 0.3234 - val_mse: 0.2399 - val_pearson_correlation: 5.9508e-17 - val_r2_keras: -32.4324 - val_rmse: 0.9416 - val_sae: 346.9712 - val_sse: 468.9930 - learning_rate: 9.4412e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0604 - loss: 0.2002 - mae: 0.1999 - mse: 0.1273 - pearson_correlation: -1.0522e-15 - r2_keras: -107.3438 - rmse: 0.9058 - sae: 2632.3062 - sse: 3360.6885\n","Epoch 52: val_loss improved from 0.25045 to 0.25009, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.0453 - loss: 0.1910 - mae: 0.1811 - mse: 0.1077 - pearson_correlation: -6.8796e-16 - r2_keras: -88.7466 - rmse: 0.8994 - sae: 1926.3519 - sse: 2445.9385 - val_huber_loss: 0.1104 - val_loss: 0.2501 - val_mae: 0.3234 - val_mse: 0.2392 - val_pearson_correlation: 6.5624e-17 - val_r2_keras: -32.3959 - val_rmse: 0.9411 - val_sae: 346.5044 - val_sse: 468.4807 - learning_rate: 9.4412e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0602 - loss: 0.1999 - mae: 0.1985 - mse: 0.1279 - pearson_correlation: -3.8302e-16 - r2_keras: -108.3403 - rmse: 0.9100 - sae: 2641.0000 - sse: 3391.5996\n","Epoch 53: val_loss improved from 0.25009 to 0.24998, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0451 - loss: 0.1907 - mae: 0.1799 - mse: 0.1080 - pearson_correlation: -1.5387e-16 - r2_keras: -89.3563 - rmse: 0.9018 - sae: 1931.8060 - sse: 2465.9055 - val_huber_loss: 0.1104 - val_loss: 0.2500 - val_mae: 0.3237 - val_mse: 0.2393 - val_pearson_correlation: -3.2282e-16 - val_r2_keras: -32.3595 - val_rmse: 0.9405 - val_sae: 346.0332 - val_sse: 467.9710 - learning_rate: 9.4412e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0598 - loss: 0.1994 - mae: 0.1986 - mse: 0.1260 - pearson_correlation: -1.6670e-17 - r2_keras: -107.3751 - rmse: 0.9059 - sae: 2632.3591 - sse: 3361.6587\n","Epoch 54: val_loss improved from 0.24998 to 0.24957, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0448 - loss: 0.1902 - mae: 0.1797 - mse: 0.1065 - pearson_correlation: 4.0986e-17 - r2_keras: -88.8164 - rmse: 0.8999 - sae: 1926.5385 - sse: 2447.1604 - val_huber_loss: 0.1102 - val_loss: 0.2496 - val_mae: 0.3236 - val_mse: 0.2385 - val_pearson_correlation: 4.3144e-16 - val_r2_keras: -32.3199 - val_rmse: 0.9400 - val_sae: 345.6804 - val_sse: 467.4150 - learning_rate: 9.4412e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0596 - loss: 0.1990 - mae: 0.1967 - mse: 0.1262 - pearson_correlation: -3.4147e-16 - r2_keras: -108.3529 - rmse: 0.9100 - sae: 2641.3662 - sse: 3391.9890\n","Epoch 55: val_loss did not improve from 0.24957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0446 - loss: 0.1899 - mae: 0.1781 - mse: 0.1066 - pearson_correlation: -1.9904e-16 - r2_keras: -89.4477 - rmse: 0.9025 - sae: 1932.3920 - sse: 2467.1392 - val_huber_loss: 0.1104 - val_loss: 0.2497 - val_mae: 0.3242 - val_mse: 0.2390 - val_pearson_correlation: -1.3786e-16 - val_r2_keras: -32.3100 - val_rmse: 0.9399 - val_sae: 345.6985 - val_sse: 467.2765 - learning_rate: 9.4412e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0592 - loss: 0.1985 - mae: 0.1959 - mse: 0.1249 - pearson_correlation: -7.2678e-17 - r2_keras: -107.9291 - rmse: 0.9082 - sae: 2637.2271 - sse: 3378.8433\n","Epoch 56: val_loss did not improve from 0.24957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0443 - loss: 0.1894 - mae: 0.1771 - mse: 0.1054 - pearson_correlation: -2.4950e-17 - r2_keras: -89.2048 - rmse: 0.9016 - sae: 1929.7902 - sse: 2458.8398 - val_huber_loss: 0.1105 - val_loss: 0.2496 - val_mae: 0.3239 - val_mse: 0.2392 - val_pearson_correlation: -2.1566e-16 - val_r2_keras: -32.3294 - val_rmse: 0.9401 - val_sae: 345.5525 - val_sse: 467.5480 - learning_rate: 9.4412e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0589 - loss: 0.1981 - mae: 0.1947 - mse: 0.1243 - pearson_correlation: -3.1443e-17 - r2_keras: -108.1766 - rmse: 0.9093 - sae: 2639.0029 - sse: 3386.5225\n","Epoch 57: val_loss improved from 0.24957 to 0.24921, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - huber_loss: 0.0441 - loss: 0.1890 - mae: 0.1760 - mse: 0.1050 - pearson_correlation: -2.4305e-17 - r2_keras: -89.4410 - rmse: 0.9029 - sae: 1931.1969 - sse: 2464.7939 - val_huber_loss: 0.1102 - val_loss: 0.2492 - val_mae: 0.3240 - val_mse: 0.2385 - val_pearson_correlation: -1.8634e-16 - val_r2_keras: -32.2725 - val_rmse: 0.9393 - val_sae: 344.9861 - val_sse: 466.7498 - learning_rate: 9.4412e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0588 - loss: 0.1978 - mae: 0.1940 - mse: 0.1244 - pearson_correlation: -6.8466e-16 - r2_keras: -108.4083 - rmse: 0.9102 - sae: 2640.8042 - sse: 3393.7087\n","Epoch 58: val_loss did not improve from 0.24921\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0440 - loss: 0.1887 - mae: 0.1755 - mse: 0.1050 - pearson_correlation: -4.9988e-16 - r2_keras: -89.6022 - rmse: 0.9036 - sae: 1932.6027 - sse: 2469.6641 - val_huber_loss: 0.1104 - val_loss: 0.2493 - val_mae: 0.3240 - val_mse: 0.2388 - val_pearson_correlation: -3.6103e-16 - val_r2_keras: -32.2527 - val_rmse: 0.9390 - val_sae: 344.7151 - val_sse: 466.4725 - learning_rate: 9.4412e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0584 - loss: 0.1973 - mae: 0.1933 - mse: 0.1231 - pearson_correlation: 1.6772e-16 - r2_keras: -108.2571 - rmse: 0.9096 - sae: 2639.9597 - sse: 3389.0186\n","Epoch 59: val_loss improved from 0.24921 to 0.24911, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0437 - loss: 0.1883 - mae: 0.1746 - mse: 0.1039 - pearson_correlation: 1.5515e-16 - r2_keras: -89.5435 - rmse: 0.9036 - sae: 1932.0417 - sse: 2467.0305 - val_huber_loss: 0.1104 - val_loss: 0.2491 - val_mae: 0.3239 - val_mse: 0.2387 - val_pearson_correlation: 1.4454e-16 - val_r2_keras: -32.2382 - val_rmse: 0.9388 - val_sae: 344.5097 - val_sse: 466.2689 - learning_rate: 9.4412e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0581 - loss: 0.1969 - mae: 0.1911 - mse: 0.1230 - pearson_correlation: 1.1569e-15 - r2_keras: -108.7682 - rmse: 0.9117 - sae: 2644.4580 - sse: 3404.8733\n","Epoch 60: val_loss improved from 0.24911 to 0.24909, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0435 - loss: 0.1879 - mae: 0.1728 - mse: 0.1038 - pearson_correlation: 8.2469e-16 - r2_keras: -89.8523 - rmse: 0.9047 - sae: 1934.9907 - sse: 2477.2266 - val_huber_loss: 0.1105 - val_loss: 0.2491 - val_mae: 0.3248 - val_mse: 0.2388 - val_pearson_correlation: -2.3555e-16 - val_r2_keras: -32.1952 - val_rmse: 0.9382 - val_sae: 343.9672 - val_sse: 465.6661 - learning_rate: 9.4412e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0580 - loss: 0.1966 - mae: 0.1935 - mse: 0.1219 - pearson_correlation: -3.8196e-16 - r2_keras: -107.9614 - rmse: 0.9084 - sae: 2638.3813 - sse: 3379.8474\n","Epoch 61: val_loss improved from 0.24909 to 0.24896, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - huber_loss: 0.0434 - loss: 0.1877 - mae: 0.1742 - mse: 0.1029 - pearson_correlation: -1.9812e-16 - r2_keras: -89.3901 - rmse: 0.9031 - sae: 1931.0160 - sse: 2461.4294 - val_huber_loss: 0.1105 - val_loss: 0.2490 - val_mae: 0.3242 - val_mse: 0.2389 - val_pearson_correlation: 4.8304e-17 - val_r2_keras: -32.2178 - val_rmse: 0.9385 - val_sae: 343.8800 - val_sse: 465.9827 - learning_rate: 9.4412e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0579 - loss: 0.1964 - mae: 0.1890 - mse: 0.1236 - pearson_correlation: 1.6091e-16 - r2_keras: -109.7022 - rmse: 0.9156 - sae: 2652.8086 - sse: 3433.8435\n","Epoch 62: val_loss improved from 0.24896 to 0.24884, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.0432 - loss: 0.1874 - mae: 0.1710 - mse: 0.1041 - pearson_correlation: 7.7226e-17 - r2_keras: -90.4795 - rmse: 0.9073 - sae: 1940.5249 - sse: 2496.5930 - val_huber_loss: 0.1105 - val_loss: 0.2488 - val_mae: 0.3254 - val_mse: 0.2388 - val_pearson_correlation: 3.6887e-16 - val_r2_keras: -32.1726 - val_rmse: 0.9379 - val_sae: 343.8741 - val_sse: 465.3484 - learning_rate: 9.4412e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0573 - loss: 0.1956 - mae: 0.1908 - mse: 0.1207 - pearson_correlation: 9.0386e-18 - r2_keras: -108.3884 - rmse: 0.9102 - sae: 2641.6147 - sse: 3393.0903\n","Epoch 63: val_loss did not improve from 0.24884\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0427 - loss: 0.1868 - mae: 0.1718 - mse: 0.1017 - pearson_correlation: 1.2661e-17 - r2_keras: -89.7100 - rmse: 0.9046 - sae: 1933.3536 - sse: 2470.6716 - val_huber_loss: 0.1108 - val_loss: 0.2490 - val_mae: 0.3249 - val_mse: 0.2397 - val_pearson_correlation: 1.5761e-16 - val_r2_keras: -32.1523 - val_rmse: 0.9376 - val_sae: 343.0179 - val_sse: 465.0639 - learning_rate: 9.4412e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0572 - loss: 0.1954 - mae: 0.1863 - mse: 0.1214 - pearson_correlation: -1.3082e-16 - r2_keras: -109.4855 - rmse: 0.9147 - sae: 2651.1621 - sse: 3427.1230\n","Epoch 64: val_loss did not improve from 0.24884\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0426 - loss: 0.1865 - mae: 0.1682 - mse: 0.1023 - pearson_correlation: -1.0718e-16 - r2_keras: -90.3867 - rmse: 0.9072 - sae: 1939.4623 - sse: 2492.7185 - val_huber_loss: 0.1110 - val_loss: 0.2491 - val_mae: 0.3263 - val_mse: 0.2398 - val_pearson_correlation: -2.3643e-16 - val_r2_keras: -32.1517 - val_rmse: 0.9376 - val_sae: 343.1245 - val_sse: 465.0561 - learning_rate: 9.4412e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0567 - loss: 0.1948 - mae: 0.1885 - mse: 0.1191 - pearson_correlation: -2.7686e-16 - r2_keras: -108.4368 - rmse: 0.9104 - sae: 2643.0295 - sse: 3394.5933\n","Epoch 65: val_loss improved from 0.24884 to 0.24863, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0423 - loss: 0.1860 - mae: 0.1694 - mse: 0.1004 - pearson_correlation: -1.3649e-16 - r2_keras: -89.7509 - rmse: 0.9048 - sae: 1934.1613 - sse: 2471.7751 - val_huber_loss: 0.1107 - val_loss: 0.2486 - val_mae: 0.3260 - val_mse: 0.2392 - val_pearson_correlation: 2.9169e-16 - val_r2_keras: -32.1165 - val_rmse: 0.9371 - val_sae: 342.6255 - val_sse: 464.5612 - learning_rate: 9.4412e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0566 - loss: 0.1946 - mae: 0.1850 - mse: 0.1203 - pearson_correlation: 5.7819e-16 - r2_keras: -109.6924 - rmse: 0.9156 - sae: 2653.5486 - sse: 3433.5386\n","Epoch 66: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0421 - loss: 0.1858 - mae: 0.1670 - mse: 0.1013 - pearson_correlation: 3.4557e-16 - r2_keras: -90.5462 - rmse: 0.9079 - sae: 1941.0731 - sse: 2497.2485 - val_huber_loss: 0.1110 - val_loss: 0.2489 - val_mae: 0.3274 - val_mse: 0.2398 - val_pearson_correlation: 1.1532e-16 - val_r2_keras: -32.1277 - val_rmse: 0.9373 - val_sae: 342.9762 - val_sse: 464.7187 - learning_rate: 9.4412e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0560 - loss: 0.1939 - mae: 0.1868 - mse: 0.1178 - pearson_correlation: 7.3084e-16 - r2_keras: -108.7479 - rmse: 0.9117 - sae: 2645.9937 - sse: 3404.2427\n","Epoch 67: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0418 - loss: 0.1852 - mae: 0.1679 - mse: 0.0992 - pearson_correlation: 4.9878e-16 - r2_keras: -90.0266 - rmse: 0.9062 - sae: 1936.4169 - sse: 2479.0090 - val_huber_loss: 0.1113 - val_loss: 0.2490 - val_mae: 0.3274 - val_mse: 0.2405 - val_pearson_correlation: 1.9475e-16 - val_r2_keras: -32.1063 - val_rmse: 0.9370 - val_sae: 342.1444 - val_sse: 464.4183 - learning_rate: 9.4412e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0559 - loss: 0.1936 - mae: 0.1833 - mse: 0.1183 - pearson_correlation: 2.4277e-16 - r2_keras: -109.6670 - rmse: 0.9155 - sae: 2653.7515 - sse: 3432.7532\n","Epoch 68: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - huber_loss: 0.0416 - loss: 0.1849 - mae: 0.1650 - mse: 0.0996 - pearson_correlation: 1.3533e-16 - r2_keras: -90.5741 - rmse: 0.9082 - sae: 1941.2423 - sse: 2497.2510 - val_huber_loss: 0.1115 - val_loss: 0.2491 - val_mae: 0.3286 - val_mse: 0.2408 - val_pearson_correlation: -2.4346e-17 - val_r2_keras: -32.1068 - val_rmse: 0.9370 - val_sae: 342.3426 - val_sse: 464.4252 - learning_rate: 9.4412e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0556 - loss: 0.1932 - mae: 0.1859 - mse: 0.1168 - pearson_correlation: -4.0181e-17 - r2_keras: -108.9029 - rmse: 0.9123 - sae: 2647.8425 - sse: 3409.0500\n","Epoch 69: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0414 - loss: 0.1845 - mae: 0.1669 - mse: 0.0984 - pearson_correlation: -4.1633e-17 - r2_keras: -90.1477 - rmse: 0.9068 - sae: 1937.6727 - sse: 2482.4231 - val_huber_loss: 0.1116 - val_loss: 0.2491 - val_mae: 0.3291 - val_mse: 0.2411 - val_pearson_correlation: -1.0368e-16 - val_r2_keras: -32.0794 - val_rmse: 0.9366 - val_sae: 341.7607 - val_sse: 464.0408 - learning_rate: 9.4412e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0553 - loss: 0.1928 - mae: 0.1825 - mse: 0.1171 - pearson_correlation: 3.1391e-16 - r2_keras: -109.8732 - rmse: 0.9163 - sae: 2655.7122 - sse: 3439.1484\n","Epoch 70: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0412 - loss: 0.1842 - mae: 0.1642 - mse: 0.0985 - pearson_correlation: 1.6446e-16 - r2_keras: -90.6883 - rmse: 0.9086 - sae: 1942.4381 - sse: 2501.2415 - val_huber_loss: 0.1120 - val_loss: 0.2494 - val_mae: 0.3295 - val_mse: 0.2418 - val_pearson_correlation: 1.3364e-16 - val_r2_keras: -32.1563 - val_rmse: 0.9377 - val_sae: 342.3444 - val_sse: 465.1206 - learning_rate: 9.4412e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0551 - loss: 0.1924 - mae: 0.1837 - mse: 0.1155 - pearson_correlation: 2.9567e-16 - r2_keras: -109.0281 - rmse: 0.9128 - sae: 2649.0522 - sse: 3412.9351\n","Epoch 71: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0409 - loss: 0.1838 - mae: 0.1649 - mse: 0.0971 - pearson_correlation: 2.1028e-16 - r2_keras: -90.2607 - rmse: 0.9074 - sae: 1938.7216 - sse: 2485.3591 - val_huber_loss: 0.1119 - val_loss: 0.2492 - val_mae: 0.3296 - val_mse: 0.2416 - val_pearson_correlation: -3.5266e-16 - val_r2_keras: -32.1464 - val_rmse: 0.9375 - val_sae: 342.1135 - val_sse: 464.9807 - learning_rate: 1.8882e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0549 - loss: 0.1922 - mae: 0.1830 - mse: 0.1153 - pearson_correlation: 1.2635e-15 - r2_keras: -109.2958 - rmse: 0.9139 - sae: 2651.6104 - sse: 3421.2378\n","Epoch 72: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0408 - loss: 0.1836 - mae: 0.1641 - mse: 0.0969 - pearson_correlation: 8.0771e-16 - r2_keras: -90.4261 - rmse: 0.9080 - sae: 1940.3436 - sse: 2490.7402 - val_huber_loss: 0.1119 - val_loss: 0.2492 - val_mae: 0.3297 - val_mse: 0.2416 - val_pearson_correlation: 9.7323e-17 - val_r2_keras: -32.1455 - val_rmse: 0.9375 - val_sae: 341.9739 - val_sse: 464.9687 - learning_rate: 1.8882e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0548 - loss: 0.1921 - mae: 0.1825 - mse: 0.1152 - pearson_correlation: -1.8969e-16 - r2_keras: -109.4678 - rmse: 0.9146 - sae: 2653.1970 - sse: 3426.5732\n","Epoch 73: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0407 - loss: 0.1835 - mae: 0.1637 - mse: 0.0968 - pearson_correlation: -8.0294e-17 - r2_keras: -90.5300 - rmse: 0.9084 - sae: 1941.3395 - sse: 2494.1709 - val_huber_loss: 0.1119 - val_loss: 0.2492 - val_mae: 0.3297 - val_mse: 0.2416 - val_pearson_correlation: 1.7646e-16 - val_r2_keras: -32.1422 - val_rmse: 0.9375 - val_sae: 341.8688 - val_sse: 464.9223 - learning_rate: 1.8882e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0547 - loss: 0.1920 - mae: 0.1821 - mse: 0.1151 - pearson_correlation: 7.8683e-17 - r2_keras: -109.6301 - rmse: 0.9153 - sae: 2654.6741 - sse: 3431.6074\n","Epoch 74: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0406 - loss: 0.1834 - mae: 0.1633 - mse: 0.0968 - pearson_correlation: -3.2552e-19 - r2_keras: -90.6329 - rmse: 0.9088 - sae: 1942.2971 - sse: 2497.4661 - val_huber_loss: 0.1120 - val_loss: 0.2492 - val_mae: 0.3297 - val_mse: 0.2416 - val_pearson_correlation: -6.6950e-17 - val_r2_keras: -32.1384 - val_rmse: 0.9374 - val_sae: 341.8127 - val_sse: 464.8694 - learning_rate: 1.8882e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0546 - loss: 0.1919 - mae: 0.1821 - mse: 0.1149 - pearson_correlation: 1.8573e-16 - r2_keras: -109.6125 - rmse: 0.9152 - sae: 2654.4941 - sse: 3431.0601\n","Epoch 75: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0406 - loss: 0.1833 - mae: 0.1632 - mse: 0.0966 - pearson_correlation: 8.0939e-17 - r2_keras: -90.6235 - rmse: 0.9088 - sae: 1942.1443 - sse: 2497.1282 - val_huber_loss: 0.1119 - val_loss: 0.2491 - val_mae: 0.3296 - val_mse: 0.2414 - val_pearson_correlation: 6.0888e-17 - val_r2_keras: -32.1320 - val_rmse: 0.9373 - val_sae: 341.7281 - val_sse: 464.7786 - learning_rate: 1.8882e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0546 - loss: 0.1918 - mae: 0.1820 - mse: 0.1149 - pearson_correlation: -3.4974e-16 - r2_keras: -109.6669 - rmse: 0.9155 - sae: 2654.9810 - sse: 3432.7500\n","Epoch 76: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0405 - loss: 0.1832 - mae: 0.1632 - mse: 0.0966 - pearson_correlation: -2.6122e-16 - r2_keras: -90.6470 - rmse: 0.9088 - sae: 1942.4362 - sse: 2498.1045 - val_huber_loss: 0.1119 - val_loss: 0.2491 - val_mae: 0.3297 - val_mse: 0.2415 - val_pearson_correlation: -8.5244e-17 - val_r2_keras: -32.1337 - val_rmse: 0.9374 - val_sae: 341.7055 - val_sse: 464.8031 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0545 - loss: 0.1917 - mae: 0.1820 - mse: 0.1147 - pearson_correlation: 2.0466e-16 - r2_keras: -109.5903 - rmse: 0.9151 - sae: 2654.3696 - sse: 3430.3730\n","Epoch 77: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0405 - loss: 0.1832 - mae: 0.1632 - mse: 0.0964 - pearson_correlation: 1.1664e-16 - r2_keras: -90.5990 - rmse: 0.9086 - sae: 1942.0264 - sse: 2496.5557 - val_huber_loss: 0.1120 - val_loss: 0.2492 - val_mae: 0.3298 - val_mse: 0.2416 - val_pearson_correlation: 2.5573e-16 - val_r2_keras: -32.1350 - val_rmse: 0.9374 - val_sae: 341.6894 - val_sse: 464.8220 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0545 - loss: 0.1917 - mae: 0.1819 - mse: 0.1146 - pearson_correlation: -4.1663e-16 - r2_keras: -109.5997 - rmse: 0.9152 - sae: 2654.4951 - sse: 3430.6650\n","Epoch 78: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0404 - loss: 0.1831 - mae: 0.1631 - mse: 0.0964 - pearson_correlation: -2.2496e-16 - r2_keras: -90.6093 - rmse: 0.9087 - sae: 1942.1119 - sse: 2496.7974 - val_huber_loss: 0.1120 - val_loss: 0.2492 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: 2.7398e-16 - val_r2_keras: -32.1370 - val_rmse: 0.9374 - val_sae: 341.6739 - val_sse: 464.8493 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0545 - loss: 0.1916 - mae: 0.1818 - mse: 0.1145 - pearson_correlation: -1.1019e-16 - r2_keras: -109.6036 - rmse: 0.9152 - sae: 2654.5327 - sse: 3430.7844\n","Epoch 79: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0404 - loss: 0.1831 - mae: 0.1630 - mse: 0.0963 - pearson_correlation: -1.5429e-16 - r2_keras: -90.6129 - rmse: 0.9087 - sae: 1942.1276 - sse: 2496.8896 - val_huber_loss: 0.1120 - val_loss: 0.2492 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: -1.6439e-16 - val_r2_keras: -32.1383 - val_rmse: 0.9374 - val_sae: 341.6414 - val_sse: 464.8681 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0544 - loss: 0.1916 - mae: 0.1817 - mse: 0.1144 - pearson_correlation: 7.7659e-17 - r2_keras: -109.6003 - rmse: 0.9152 - sae: 2654.5002 - sse: 3430.6821\n","Epoch 80: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0404 - loss: 0.1830 - mae: 0.1628 - mse: 0.0962 - pearson_correlation: 9.6309e-17 - r2_keras: -90.6122 - rmse: 0.9087 - sae: 1942.1232 - sse: 2496.8386 - val_huber_loss: 0.1120 - val_loss: 0.2492 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: 9.1334e-17 - val_r2_keras: -32.1368 - val_rmse: 0.9374 - val_sae: 341.6327 - val_sse: 464.8471 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0544 - loss: 0.1915 - mae: 0.1816 - mse: 0.1143 - pearson_correlation: -2.0672e-16 - r2_keras: -109.6072 - rmse: 0.9152 - sae: 2654.5908 - sse: 3430.8960\n","Epoch 81: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0403 - loss: 0.1830 - mae: 0.1627 - mse: 0.0961 - pearson_correlation: -1.0813e-16 - r2_keras: -90.6205 - rmse: 0.9088 - sae: 1942.1862 - sse: 2497.0249 - val_huber_loss: 0.1120 - val_loss: 0.2492 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: 6.0885e-18 - val_r2_keras: -32.1383 - val_rmse: 0.9374 - val_sae: 341.6358 - val_sse: 464.8673 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0544 - loss: 0.1915 - mae: 0.1815 - mse: 0.1143 - pearson_correlation: 4.1342e-16 - r2_keras: -109.6136 - rmse: 0.9152 - sae: 2654.6611 - sse: 3431.0947\n","Epoch 82: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0403 - loss: 0.1829 - mae: 0.1626 - mse: 0.0961 - pearson_correlation: 2.2616e-16 - r2_keras: -90.6317 - rmse: 0.9089 - sae: 1942.2482 - sse: 2497.2383 - val_huber_loss: 0.1120 - val_loss: 0.2491 - val_mae: 0.3298 - val_mse: 0.2416 - val_pearson_correlation: -4.8713e-17 - val_r2_keras: -32.1373 - val_rmse: 0.9374 - val_sae: 341.5983 - val_sse: 464.8539 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0543 - loss: 0.1914 - mae: 0.1813 - mse: 0.1144 - pearson_correlation: -1.3252e-16 - r2_keras: -109.7643 - rmse: 0.9159 - sae: 2655.9275 - sse: 3435.7686\n","Epoch 83: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0403 - loss: 0.1829 - mae: 0.1625 - mse: 0.0961 - pearson_correlation: -1.0154e-16 - r2_keras: -90.7313 - rmse: 0.9093 - sae: 1943.1008 - sse: 2500.3447 - val_huber_loss: 0.1120 - val_loss: 0.2491 - val_mae: 0.3299 - val_mse: 0.2416 - val_pearson_correlation: 4.2617e-17 - val_r2_keras: -32.1385 - val_rmse: 0.9374 - val_sae: 341.6438 - val_sse: 464.8699 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0543 - loss: 0.1914 - mae: 0.1813 - mse: 0.1141 - pearson_correlation: -2.5270e-16 - r2_keras: -109.6810 - rmse: 0.9155 - sae: 2655.1895 - sse: 3433.1855\n","Epoch 84: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0403 - loss: 0.1828 - mae: 0.1625 - mse: 0.0960 - pearson_correlation: -1.9648e-16 - r2_keras: -90.6809 - rmse: 0.9091 - sae: 1942.6195 - sse: 2498.6829 - val_huber_loss: 0.1120 - val_loss: 0.2491 - val_mae: 0.3299 - val_mse: 0.2416 - val_pearson_correlation: -1.4003e-16 - val_r2_keras: -32.1404 - val_rmse: 0.9375 - val_sae: 341.6128 - val_sse: 464.8975 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0542 - loss: 0.1913 - mae: 0.1812 - mse: 0.1140 - pearson_correlation: 9.0190e-17 - r2_keras: -109.6640 - rmse: 0.9155 - sae: 2655.0317 - sse: 3432.6604\n","Epoch 85: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0402 - loss: 0.1828 - mae: 0.1624 - mse: 0.0959 - pearson_correlation: 5.1887e-17 - r2_keras: -90.6699 - rmse: 0.9090 - sae: 1942.5280 - sse: 2498.3354 - val_huber_loss: 0.1120 - val_loss: 0.2491 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: -1.3394e-16 - val_r2_keras: -32.1408 - val_rmse: 0.9375 - val_sae: 341.5975 - val_sse: 464.9023 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0542 - loss: 0.1913 - mae: 0.1812 - mse: 0.1140 - pearson_correlation: 1.2534e-16 - r2_keras: -109.6531 - rmse: 0.9154 - sae: 2654.9668 - sse: 3432.3198\n","Epoch 86: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0402 - loss: 0.1827 - mae: 0.1623 - mse: 0.0958 - pearson_correlation: -1.3641e-17 - r2_keras: -90.6686 - rmse: 0.9091 - sae: 1942.4884 - sse: 2498.1797 - val_huber_loss: 0.1120 - val_loss: 0.2490 - val_mae: 0.3298 - val_mse: 0.2415 - val_pearson_correlation: 7.3059e-17 - val_r2_keras: -32.1412 - val_rmse: 0.9375 - val_sae: 341.5742 - val_sse: 464.9082 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0542 - loss: 0.1912 - mae: 0.1810 - mse: 0.1140 - pearson_correlation: 3.5184e-16 - r2_keras: -109.8044 - rmse: 0.9160 - sae: 2656.2576 - sse: 3437.0142\n","Epoch 87: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0402 - loss: 0.1827 - mae: 0.1622 - mse: 0.0959 - pearson_correlation: 2.1150e-16 - r2_keras: -90.7709 - rmse: 0.9095 - sae: 1943.3676 - sse: 2501.3250 - val_huber_loss: 0.1120 - val_loss: 0.2491 - val_mae: 0.3298 - val_mse: 0.2416 - val_pearson_correlation: 2.9830e-16 - val_r2_keras: -32.1435 - val_rmse: 0.9375 - val_sae: 341.5734 - val_sse: 464.9401 - learning_rate: 1.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0541 - loss: 0.1912 - mae: 0.1811 - mse: 0.1138 - pearson_correlation: 2.4950e-16 - r2_keras: -109.7014 - rmse: 0.9156 - sae: 2655.3442 - sse: 3433.8176\n","Epoch 88: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0402 - loss: 0.1826 - mae: 0.1622 - mse: 0.0957 - pearson_correlation: 1.3669e-16 - r2_keras: -90.7083 - rmse: 0.9092 - sae: 1942.7789 - sse: 2499.2656 - val_huber_loss: 0.1120 - val_loss: 0.2491 - val_mae: 0.3298 - val_mse: 0.2417 - val_pearson_correlation: 9.7404e-17 - val_r2_keras: -32.1440 - val_rmse: 0.9375 - val_sae: 341.5680 - val_sse: 464.9472 - learning_rate: 1.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0541 - loss: 0.1911 - mae: 0.1810 - mse: 0.1137 - pearson_correlation: 4.9222e-16 - r2_keras: -109.6937 - rmse: 0.9156 - sae: 2655.2942 - sse: 3433.5801\n","Epoch 89: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0401 - loss: 0.1826 - mae: 0.1621 - mse: 0.0956 - pearson_correlation: 3.6766e-16 - r2_keras: -90.7063 - rmse: 0.9093 - sae: 1942.7484 - sse: 2499.1443 - val_huber_loss: 0.1121 - val_loss: 0.2491 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: 6.0879e-17 - val_r2_keras: -32.1448 - val_rmse: 0.9375 - val_sae: 341.5376 - val_sse: 464.9583 - learning_rate: 1.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0541 - loss: 0.1911 - mae: 0.1807 - mse: 0.1137 - pearson_correlation: 2.6808e-16 - r2_keras: -109.8009 - rmse: 0.9160 - sae: 2656.2227 - sse: 3436.9058\n","Epoch 90: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0401 - loss: 0.1826 - mae: 0.1619 - mse: 0.0956 - pearson_correlation: 2.4293e-16 - r2_keras: -90.7769 - rmse: 0.9095 - sae: 1943.3712 - sse: 2501.3508 - val_huber_loss: 0.1120 - val_loss: 0.2490 - val_mae: 0.3298 - val_mse: 0.2416 - val_pearson_correlation: -1.0960e-16 - val_r2_keras: -32.1397 - val_rmse: 0.9374 - val_sae: 341.5558 - val_sse: 464.8867 - learning_rate: 1.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0540 - loss: 0.1910 - mae: 0.1807 - mse: 0.1137 - pearson_correlation: 3.4174e-16 - r2_keras: -109.8469 - rmse: 0.9162 - sae: 2656.5647 - sse: 3438.3325\n","Epoch 91: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0401 - loss: 0.1825 - mae: 0.1619 - mse: 0.0956 - pearson_correlation: 2.5252e-16 - r2_keras: -90.8083 - rmse: 0.9097 - sae: 1943.5896 - sse: 2502.3108 - val_huber_loss: 0.1121 - val_loss: 0.2490 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: -6.6978e-17 - val_r2_keras: -32.1402 - val_rmse: 0.9375 - val_sae: 341.5291 - val_sse: 464.8943 - learning_rate: 1.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0540 - loss: 0.1910 - mae: 0.1808 - mse: 0.1135 - pearson_correlation: 1.2001e-16 - r2_keras: -109.7162 - rmse: 0.9157 - sae: 2655.4280 - sse: 3434.2791\n","Epoch 92: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0400 - loss: 0.1825 - mae: 0.1619 - mse: 0.0954 - pearson_correlation: 6.8483e-17 - r2_keras: -90.7224 - rmse: 0.9093 - sae: 1942.8508 - sse: 2499.6228 - val_huber_loss: 0.1121 - val_loss: 0.2490 - val_mae: 0.3300 - val_mse: 0.2417 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -32.1406 - val_rmse: 0.9375 - val_sae: 341.5008 - val_sse: 464.8994 - learning_rate: 1.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0540 - loss: 0.1909 - mae: 0.1806 - mse: 0.1135 - pearson_correlation: 2.5283e-16 - r2_keras: -109.8267 - rmse: 0.9161 - sae: 2656.4282 - sse: 3437.7041\n","Epoch 93: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0400 - loss: 0.1824 - mae: 0.1617 - mse: 0.0954 - pearson_correlation: 1.7513e-16 - r2_keras: -90.7981 - rmse: 0.9096 - sae: 1943.5144 - sse: 2501.9309 - val_huber_loss: 0.1121 - val_loss: 0.2490 - val_mae: 0.3300 - val_mse: 0.2418 - val_pearson_correlation: -1.2178e-17 - val_r2_keras: -32.1401 - val_rmse: 0.9375 - val_sae: 341.5037 - val_sse: 464.8936 - learning_rate: 1.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0539 - loss: 0.1909 - mae: 0.1805 - mse: 0.1134 - pearson_correlation: 6.8066e-17 - r2_keras: -109.8022 - rmse: 0.9160 - sae: 2656.2515 - sse: 3436.9463\n","Epoch 94: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0400 - loss: 0.1824 - mae: 0.1617 - mse: 0.0953 - pearson_correlation: 9.6397e-17 - r2_keras: -90.7852 - rmse: 0.9096 - sae: 1943.3951 - sse: 2501.4646 - val_huber_loss: 0.1121 - val_loss: 0.2490 - val_mae: 0.3299 - val_mse: 0.2417 - val_pearson_correlation: -1.6445e-16 - val_r2_keras: -32.1357 - val_rmse: 0.9374 - val_sae: 341.4513 - val_sse: 464.8309 - learning_rate: 1.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0539 - loss: 0.1908 - mae: 0.1805 - mse: 0.1134 - pearson_correlation: 9.0566e-17 - r2_keras: -109.8164 - rmse: 0.9161 - sae: 2656.2974 - sse: 3437.3848\n","Epoch 95: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0400 - loss: 0.1823 - mae: 0.1617 - mse: 0.0953 - pearson_correlation: 9.4949e-17 - r2_keras: -90.7900 - rmse: 0.9096 - sae: 1943.4218 - sse: 2501.7029 - val_huber_loss: 0.1121 - val_loss: 0.2490 - val_mae: 0.3301 - val_mse: 0.2418 - val_pearson_correlation: -1.4010e-16 - val_r2_keras: -32.1356 - val_rmse: 0.9374 - val_sae: 341.4270 - val_sse: 464.8301 - learning_rate: 1.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0539 - loss: 0.1908 - mae: 0.1806 - mse: 0.1132 - pearson_correlation: -2.5154e-16 - r2_keras: -109.7198 - rmse: 0.9157 - sae: 2655.4817 - sse: 3434.3896\n","Epoch 96: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0399 - loss: 0.1823 - mae: 0.1617 - mse: 0.0951 - pearson_correlation: -1.9074e-16 - r2_keras: -90.7293 - rmse: 0.9094 - sae: 1942.8763 - sse: 2499.7493 - val_huber_loss: 0.1121 - val_loss: 0.2490 - val_mae: 0.3300 - val_mse: 0.2418 - val_pearson_correlation: -2.5586e-16 - val_r2_keras: -32.1336 - val_rmse: 0.9374 - val_sae: 341.4107 - val_sse: 464.8013 - learning_rate: 1.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0538 - loss: 0.1907 - mae: 0.1803 - mse: 0.1133 - pearson_correlation: 3.9495e-16 - r2_keras: -109.8860 - rmse: 0.9164 - sae: 2656.9395 - sse: 3439.5454\n","Epoch 97: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0399 - loss: 0.1823 - mae: 0.1614 - mse: 0.0952 - pearson_correlation: 2.4520e-16 - r2_keras: -90.8391 - rmse: 0.9098 - sae: 1943.8370 - sse: 2503.1750 - val_huber_loss: 0.1122 - val_loss: 0.2490 - val_mae: 0.3301 - val_mse: 0.2419 - val_pearson_correlation: 2.0103e-16 - val_r2_keras: -32.1323 - val_rmse: 0.9373 - val_sae: 341.4269 - val_sse: 464.7836 - learning_rate: 1.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0538 - loss: 0.1907 - mae: 0.1803 - mse: 0.1130 - pearson_correlation: 2.5924e-16 - r2_keras: -109.7781 - rmse: 0.9159 - sae: 2655.9426 - sse: 3436.1973\n","Epoch 98: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0399 - loss: 0.1822 - mae: 0.1615 - mse: 0.0950 - pearson_correlation: 1.5144e-16 - r2_keras: -90.7716 - rmse: 0.9096 - sae: 1943.2072 - sse: 2500.9946 - val_huber_loss: 0.1122 - val_loss: 0.2491 - val_mae: 0.3302 - val_mse: 0.2420 - val_pearson_correlation: -1.3402e-16 - val_r2_keras: -32.1336 - val_rmse: 0.9374 - val_sae: 341.3911 - val_sse: 464.8012 - learning_rate: 1.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0537 - loss: 0.1906 - mae: 0.1802 - mse: 0.1130 - pearson_correlation: -2.1082e-16 - r2_keras: -109.8822 - rmse: 0.9164 - sae: 2656.8591 - sse: 3439.4280\n","Epoch 99: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0399 - loss: 0.1822 - mae: 0.1613 - mse: 0.0950 - pearson_correlation: -1.7840e-16 - r2_keras: -90.8409 - rmse: 0.9098 - sae: 1943.8068 - sse: 2503.1477 - val_huber_loss: 0.1122 - val_loss: 0.2491 - val_mae: 0.3302 - val_mse: 0.2420 - val_pearson_correlation: -1.0357e-16 - val_r2_keras: -32.1324 - val_rmse: 0.9373 - val_sae: 341.3766 - val_sse: 464.7852 - learning_rate: 1.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0537 - loss: 0.1906 - mae: 0.1801 - mse: 0.1129 - pearson_correlation: 7.4303e-17 - r2_keras: -109.8595 - rmse: 0.9163 - sae: 2656.6470 - sse: 3438.7224\n","Epoch 100: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0398 - loss: 0.1821 - mae: 0.1613 - mse: 0.0949 - pearson_correlation: 8.0804e-17 - r2_keras: -90.8245 - rmse: 0.9098 - sae: 1943.6385 - sse: 2502.6624 - val_huber_loss: 0.1122 - val_loss: 0.2490 - val_mae: 0.3302 - val_mse: 0.2419 - val_pearson_correlation: -3.0466e-17 - val_r2_keras: -32.1303 - val_rmse: 0.9373 - val_sae: 341.3457 - val_sse: 464.7560 - learning_rate: 1.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0537 - loss: 0.1905 - mae: 0.1801 - mse: 0.1129 - pearson_correlation: 1.8676e-16 - r2_keras: -109.8839 - rmse: 0.9164 - sae: 2656.8271 - sse: 3439.4805\n","Epoch 101: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0398 - loss: 0.1821 - mae: 0.1613 - mse: 0.0949 - pearson_correlation: 1.0969e-16 - r2_keras: -90.8397 - rmse: 0.9098 - sae: 1943.7759 - sse: 2503.1553 - val_huber_loss: 0.1123 - val_loss: 0.2491 - val_mae: 0.3303 - val_mse: 0.2421 - val_pearson_correlation: -3.6556e-17 - val_r2_keras: -32.1320 - val_rmse: 0.9373 - val_sae: 341.3562 - val_sse: 464.7786 - learning_rate: 1.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0537 - loss: 0.1905 - mae: 0.1801 - mse: 0.1127 - pearson_correlation: -1.5239e-16 - r2_keras: -109.7859 - rmse: 0.9160 - sae: 2655.9834 - sse: 3436.4412\n","Epoch 102: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0398 - loss: 0.1820 - mae: 0.1613 - mse: 0.0948 - pearson_correlation: -7.6913e-17 - r2_keras: -90.7791 - rmse: 0.9096 - sae: 1943.2253 - sse: 2501.1838 - val_huber_loss: 0.1123 - val_loss: 0.2491 - val_mae: 0.3303 - val_mse: 0.2422 - val_pearson_correlation: 1.0358e-16 - val_r2_keras: -32.1325 - val_rmse: 0.9373 - val_sae: 341.3344 - val_sse: 464.7860 - learning_rate: 1.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0536 - loss: 0.1904 - mae: 0.1798 - mse: 0.1127 - pearson_correlation: -1.7782e-16 - r2_keras: -109.9089 - rmse: 0.9165 - sae: 2657.0977 - sse: 3440.2556\n","Epoch 103: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0398 - loss: 0.1820 - mae: 0.1610 - mse: 0.0948 - pearson_correlation: -1.0209e-16 - r2_keras: -90.8641 - rmse: 0.9100 - sae: 1943.9686 - sse: 2503.7625 - val_huber_loss: 0.1123 - val_loss: 0.2491 - val_mae: 0.3303 - val_mse: 0.2421 - val_pearson_correlation: -4.0219e-16 - val_r2_keras: -32.1285 - val_rmse: 0.9373 - val_sae: 341.3137 - val_sse: 464.7296 - learning_rate: 1.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0536 - loss: 0.1904 - mae: 0.1798 - mse: 0.1127 - pearson_correlation: 3.3366e-16 - r2_keras: -109.9114 - rmse: 0.9165 - sae: 2657.0337 - sse: 3440.3337\n","Epoch 104: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0398 - loss: 0.1819 - mae: 0.1611 - mse: 0.0947 - pearson_correlation: 1.5826e-16 - r2_keras: -90.8603 - rmse: 0.9099 - sae: 1943.9196 - sse: 2503.7500 - val_huber_loss: 0.1124 - val_loss: 0.2491 - val_mae: 0.3305 - val_mse: 0.2422 - val_pearson_correlation: -1.7059e-16 - val_r2_keras: -32.1304 - val_rmse: 0.9373 - val_sae: 341.3747 - val_sse: 464.7563 - learning_rate: 1.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0536 - loss: 0.1903 - mae: 0.1800 - mse: 0.1125 - pearson_correlation: 5.8629e-17 - r2_keras: -109.8225 - rmse: 0.9161 - sae: 2656.2827 - sse: 3437.5754\n","Epoch 105: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0397 - loss: 0.1819 - mae: 0.1611 - mse: 0.0946 - pearson_correlation: 7.8293e-18 - r2_keras: -90.8062 - rmse: 0.9097 - sae: 1943.4313 - sse: 2501.9724 - val_huber_loss: 0.1124 - val_loss: 0.2492 - val_mae: 0.3305 - val_mse: 0.2423 - val_pearson_correlation: -2.8029e-16 - val_r2_keras: -32.1296 - val_rmse: 0.9373 - val_sae: 341.3252 - val_sse: 464.7454 - learning_rate: 1.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0535 - loss: 0.1903 - mae: 0.1796 - mse: 0.1125 - pearson_correlation: -3.4975e-16 - r2_keras: -109.9428 - rmse: 0.9166 - sae: 2657.3330 - sse: 3441.3066\n","Epoch 106: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0397 - loss: 0.1819 - mae: 0.1609 - mse: 0.0946 - pearson_correlation: -2.2988e-16 - r2_keras: -90.8845 - rmse: 0.9100 - sae: 1944.1132 - sse: 2504.4380 - val_huber_loss: 0.1124 - val_loss: 0.2492 - val_mae: 0.3305 - val_mse: 0.2424 - val_pearson_correlation: -1.5236e-16 - val_r2_keras: -32.1264 - val_rmse: 0.9373 - val_sae: 341.2823 - val_sse: 464.7007 - learning_rate: 1.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0535 - loss: 0.1902 - mae: 0.1796 - mse: 0.1124 - pearson_correlation: -9.3267e-16 - r2_keras: -109.8899 - rmse: 0.9164 - sae: 2656.8267 - sse: 3439.6655\n","Epoch 107: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0397 - loss: 0.1818 - mae: 0.1609 - mse: 0.0945 - pearson_correlation: -6.2836e-16 - r2_keras: -90.8488 - rmse: 0.9099 - sae: 1943.7800 - sse: 2503.3391 - val_huber_loss: 0.1124 - val_loss: 0.2491 - val_mae: 0.3304 - val_mse: 0.2423 - val_pearson_correlation: 1.2191e-17 - val_r2_keras: -32.1230 - val_rmse: 0.9372 - val_sae: 341.2653 - val_sse: 464.6530 - learning_rate: 1.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0535 - loss: 0.1902 - mae: 0.1796 - mse: 0.1124 - pearson_correlation: -5.4903e-16 - r2_keras: -109.9271 - rmse: 0.9165 - sae: 2657.0981 - sse: 3440.8198\n","Epoch 108: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0396 - loss: 0.1818 - mae: 0.1609 - mse: 0.0945 - pearson_correlation: -3.1503e-16 - r2_keras: -90.8774 - rmse: 0.9100 - sae: 1943.9717 - sse: 2504.1523 - val_huber_loss: 0.1124 - val_loss: 0.2491 - val_mae: 0.3305 - val_mse: 0.2424 - val_pearson_correlation: 4.2672e-17 - val_r2_keras: -32.1215 - val_rmse: 0.9372 - val_sae: 341.2435 - val_sse: 464.6315 - learning_rate: 1.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0534 - loss: 0.1901 - mae: 0.1795 - mse: 0.1123 - pearson_correlation: 4.8220e-16 - r2_keras: -109.9069 - rmse: 0.9165 - sae: 2656.9541 - sse: 3440.1938\n","Epoch 109: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0396 - loss: 0.1817 - mae: 0.1608 - mse: 0.0944 - pearson_correlation: 3.2476e-16 - r2_keras: -90.8675 - rmse: 0.9100 - sae: 1943.8859 - sse: 2503.7773 - val_huber_loss: 0.1125 - val_loss: 0.2491 - val_mae: 0.3305 - val_mse: 0.2424 - val_pearson_correlation: -3.6566e-17 - val_r2_keras: -32.1283 - val_rmse: 0.9373 - val_sae: 341.2546 - val_sse: 464.7271 - learning_rate: 1.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0534 - loss: 0.1901 - mae: 0.1796 - mse: 0.1121 - pearson_correlation: 1.0466e-16 - r2_keras: -109.8491 - rmse: 0.9162 - sae: 2656.3164 - sse: 3438.4009\n","Epoch 110: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0396 - loss: 0.1817 - mae: 0.1608 - mse: 0.0943 - pearson_correlation: 5.8268e-17 - r2_keras: -90.8351 - rmse: 0.9099 - sae: 1943.4967 - sse: 2502.6536 - val_huber_loss: 0.1124 - val_loss: 0.2491 - val_mae: 0.3304 - val_mse: 0.2423 - val_pearson_correlation: 1.0969e-16 - val_r2_keras: -32.1277 - val_rmse: 0.9373 - val_sae: 341.2741 - val_sse: 464.7193 - learning_rate: 1.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0533 - loss: 0.1900 - mae: 0.1794 - mse: 0.1122 - pearson_correlation: 1.8749e-16 - r2_keras: -110.0378 - rmse: 0.9170 - sae: 2657.7075 - sse: 3444.2544\n","Epoch 111: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0396 - loss: 0.1816 - mae: 0.1606 - mse: 0.0943 - pearson_correlation: 5.2677e-17 - r2_keras: -90.9651 - rmse: 0.9104 - sae: 1944.4366 - sse: 2506.6047 - val_huber_loss: 0.1125 - val_loss: 0.2491 - val_mae: 0.3305 - val_mse: 0.2424 - val_pearson_correlation: -2.4371e-17 - val_r2_keras: -32.1336 - val_rmse: 0.9374 - val_sae: 341.2809 - val_sse: 464.8011 - learning_rate: 1.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0533 - loss: 0.1899 - mae: 0.1794 - mse: 0.1119 - pearson_correlation: -2.0924e-17 - r2_keras: -109.8878 - rmse: 0.9164 - sae: 2656.2612 - sse: 3439.5996\n","Epoch 112: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0395 - loss: 0.1815 - mae: 0.1607 - mse: 0.0941 - pearson_correlation: 3.0423e-17 - r2_keras: -90.8671 - rmse: 0.9101 - sae: 1943.4993 - sse: 2503.5264 - val_huber_loss: 0.1125 - val_loss: 0.2491 - val_mae: 0.3304 - val_mse: 0.2425 - val_pearson_correlation: -1.5838e-16 - val_r2_keras: -32.1384 - val_rmse: 0.9374 - val_sae: 341.2795 - val_sse: 464.8690 - learning_rate: 1.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0532 - loss: 0.1899 - mae: 0.1791 - mse: 0.1119 - pearson_correlation: -1.0659e-16 - r2_keras: -109.9939 - rmse: 0.9168 - sae: 2657.0864 - sse: 3442.8931\n","Epoch 113: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0395 - loss: 0.1815 - mae: 0.1605 - mse: 0.0940 - pearson_correlation: -3.9848e-17 - r2_keras: -90.9438 - rmse: 0.9104 - sae: 1944.0709 - sse: 2505.7908 - val_huber_loss: 0.1125 - val_loss: 0.2491 - val_mae: 0.3304 - val_mse: 0.2425 - val_pearson_correlation: 7.9184e-17 - val_r2_keras: -32.1381 - val_rmse: 0.9374 - val_sae: 341.2901 - val_sse: 464.8655 - learning_rate: 1.0000e-05\n","Epoch 114/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0532 - loss: 0.1898 - mae: 0.1792 - mse: 0.1117 - pearson_correlation: 1.1762e-16 - r2_keras: -109.9464 - rmse: 0.9166 - sae: 2656.5903 - sse: 3441.4180\n","Epoch 114: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0394 - loss: 0.1814 - mae: 0.1605 - mse: 0.0939 - pearson_correlation: 6.8559e-17 - r2_keras: -90.9109 - rmse: 0.9103 - sae: 1943.7142 - sse: 2504.7930 - val_huber_loss: 0.1125 - val_loss: 0.2491 - val_mae: 0.3304 - val_mse: 0.2424 - val_pearson_correlation: 9.7465e-17 - val_r2_keras: -32.1374 - val_rmse: 0.9374 - val_sae: 341.2543 - val_sse: 464.8556 - learning_rate: 1.0000e-05\n","Epoch 115/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0531 - loss: 0.1897 - mae: 0.1792 - mse: 0.1117 - pearson_correlation: -4.1817e-18 - r2_keras: -109.9576 - rmse: 0.9167 - sae: 2656.5513 - sse: 3441.7666\n","Epoch 115: val_loss did not improve from 0.24863\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0394 - loss: 0.1814 - mae: 0.1606 - mse: 0.0939 - pearson_correlation: -9.9733e-17 - r2_keras: -90.9165 - rmse: 0.9103 - sae: 1943.6991 - sse: 2505.0032 - val_huber_loss: 0.1125 - val_loss: 0.2491 - val_mae: 0.3304 - val_mse: 0.2425 - val_pearson_correlation: 1.5837e-16 - val_r2_keras: -32.1394 - val_rmse: 0.9374 - val_sae: 341.2353 - val_sse: 464.8826 - learning_rate: 1.0000e-05\n","| \u001b[35m14       \u001b[39m | \u001b[35m-0.2491  \u001b[39m | \u001b[35m0.00236  \u001b[39m | \u001b[35m90.51    \u001b[39m | \u001b[35m56.49    \u001b[39m | \u001b[35m67.16    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m80.18    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.4729 - loss: 0.6345 - mae: 0.7895 - mse: 1.2161 - pearson_correlation: 4.0174e-16 - r2_keras: -165.0319 - rmse: 1.1213 - sae: 3306.7075 - sse: 5150.1025\n","Epoch 1: val_loss improved from inf to 0.40658, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 617ms/step - huber_loss: 0.4029 - loss: 0.5919 - mae: 0.7457 - mse: 1.0898 - pearson_correlation: 2.7533e-16 - r2_keras: -125.6512 - rmse: 1.0297 - sae: 2373.1118 - sse: 3620.6509 - val_huber_loss: 0.2444 - val_loss: 0.4066 - val_mae: 0.5722 - val_mse: 0.6157 - val_pearson_correlation: 1.0222e-16 - val_r2_keras: -22.0650 - val_rmse: 0.7821 - val_sae: 303.7667 - val_sse: 323.5579 - learning_rate: 0.0029\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.6205 - loss: 0.7827 - mae: 1.0187 - mse: 1.5320 - pearson_correlation: 1.1951e-16 - r2_keras: -185.9100 - rmse: 1.1897 - sae: 3790.0405 - sse: 5797.7139\n","Epoch 2: val_loss improved from 0.40658 to 0.40543, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.5403 - loss: 0.7338 - mae: 0.9538 - mse: 1.3980 - pearson_correlation: 2.6366e-16 - r2_keras: -145.3126 - rmse: 1.1222 - sae: 2724.3271 - sse: 4119.7544 - val_huber_loss: 0.2433 - val_loss: 0.4054 - val_mae: 0.5338 - val_mse: 0.6410 - val_pearson_correlation: -5.6538e-16 - val_r2_keras: -22.9470 - val_rmse: 0.7969 - val_sae: 284.9405 - val_sse: 335.9305 - learning_rate: 0.0029\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2753 - loss: 0.4374 - mae: 0.6299 - mse: 0.6045 - pearson_correlation: 3.3811e-16 - r2_keras: -90.1029 - rmse: 0.8306 - sae: 2647.8921 - sse: 2825.8982\n","Epoch 3: val_loss improved from 0.40543 to 0.40396, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.2444 - loss: 0.4186 - mae: 0.6053 - mse: 0.5594 - pearson_correlation: 2.0428e-16 - r2_keras: -73.3019 - rmse: 0.8139 - sae: 1927.3823 - sse: 2043.0691 - val_huber_loss: 0.2421 - val_loss: 0.4040 - val_mae: 0.5091 - val_mse: 0.6432 - val_pearson_correlation: -2.1797e-16 - val_r2_keras: -23.8208 - val_rmse: 0.8113 - val_sae: 278.0381 - val_sse: 348.1891 - learning_rate: 0.0029\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1426 - loss: 0.3044 - mae: 0.4223 - mse: 0.3109 - pearson_correlation: -4.4341e-16 - r2_keras: -89.1126 - rmse: 0.8261 - sae: 2605.2285 - sse: 2795.1794\n","Epoch 4: val_loss improved from 0.40396 to 0.38113, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1335 - loss: 0.2988 - mae: 0.4148 - mse: 0.2950 - pearson_correlation: -3.8942e-16 - r2_keras: -73.6554 - rmse: 0.8204 - sae: 1899.9662 - sse: 2034.4816 - val_huber_loss: 0.2197 - val_loss: 0.3811 - val_mae: 0.4645 - val_mse: 0.5809 - val_pearson_correlation: 4.3520e-17 - val_r2_keras: -24.6373 - val_rmse: 0.8245 - val_sae: 282.0273 - val_sse: 359.6429 - learning_rate: 0.0029\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1330 - loss: 0.2944 - mae: 0.3787 - mse: 0.2878 - pearson_correlation: -2.2499e-16 - r2_keras: -85.7715 - rmse: 0.8106 - sae: 2491.9912 - sse: 2691.5425\n","Epoch 5: val_loss did not improve from 0.38113\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1260 - loss: 0.2901 - mae: 0.3711 - mse: 0.2755 - pearson_correlation: -2.2315e-16 - r2_keras: -73.2261 - rmse: 0.8262 - sae: 1833.5359 - sse: 1986.4818 - val_huber_loss: 0.2233 - val_loss: 0.3843 - val_mae: 0.4707 - val_mse: 0.5956 - val_pearson_correlation: 7.3624e-16 - val_r2_keras: -25.1682 - val_rmse: 0.8330 - val_sae: 286.1557 - val_sse: 367.0901 - learning_rate: 0.0029\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1451 - loss: 0.3060 - mae: 0.3788 - mse: 0.3271 - pearson_correlation: 2.7686e-16 - r2_keras: -84.7039 - rmse: 0.8056 - sae: 2426.3726 - sse: 2658.4270\n","Epoch 6: val_loss improved from 0.38113 to 0.37523, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.1315 - loss: 0.2978 - mae: 0.3730 - mse: 0.3036 - pearson_correlation: 1.8121e-16 - r2_keras: -73.7977 - rmse: 0.8339 - sae: 1795.1327 - sse: 1979.4578 - val_huber_loss: 0.2147 - val_loss: 0.3752 - val_mae: 0.4656 - val_mse: 0.5733 - val_pearson_correlation: 3.2874e-16 - val_r2_keras: -26.3111 - val_rmse: 0.8510 - val_sae: 299.1664 - val_sse: 383.1225 - learning_rate: 0.0029\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1151 - loss: 0.2756 - mae: 0.3356 - mse: 0.2601 - pearson_correlation: -8.1975e-17 - r2_keras: -89.1205 - rmse: 0.8261 - sae: 2460.2192 - sse: 2795.4243\n","Epoch 7: val_loss improved from 0.37523 to 0.32487, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.1020 - loss: 0.2676 - mae: 0.3227 - mse: 0.2382 - pearson_correlation: -1.1021e-16 - r2_keras: -73.0244 - rmse: 0.8145 - sae: 1794.4689 - sse: 2027.1812 - val_huber_loss: 0.1649 - val_loss: 0.3249 - val_mae: 0.4323 - val_mse: 0.4072 - val_pearson_correlation: -2.7657e-16 - val_r2_keras: -27.8452 - val_rmse: 0.8746 - val_sae: 328.7524 - val_sse: 404.6443 - learning_rate: 0.0029\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1078 - loss: 0.2679 - mae: 0.3104 - mse: 0.2425 - pearson_correlation: 1.0452e-16 - r2_keras: -107.1922 - rmse: 0.9052 - sae: 2651.5740 - sse: 3355.9854\n","Epoch 8: val_loss improved from 0.32487 to 0.32273, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0967 - loss: 0.2610 - mae: 0.3043 - mse: 0.2235 - pearson_correlation: 4.4561e-17 - r2_keras: -84.2175 - rmse: 0.8589 - sae: 1918.0070 - sse: 2390.8621 - val_huber_loss: 0.1632 - val_loss: 0.3227 - val_mae: 0.4296 - val_mse: 0.4001 - val_pearson_correlation: -3.5150e-16 - val_r2_keras: -29.2286 - val_rmse: 0.8953 - val_sae: 343.6863 - val_sse: 424.0501 - learning_rate: 0.0029\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1120 - loss: 0.2715 - mae: 0.3509 - mse: 0.2342 - pearson_correlation: -2.4541e-16 - r2_keras: -103.6947 - rmse: 0.8904 - sae: 2669.7041 - sse: 3247.4973\n","Epoch 9: val_loss did not improve from 0.32273\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1092 - loss: 0.2697 - mae: 0.3543 - mse: 0.2286 - pearson_correlation: -2.2272e-16 - r2_keras: -83.5786 - rmse: 0.8651 - sae: 1947.2428 - sse: 2338.3936 - val_huber_loss: 0.1906 - val_loss: 0.3496 - val_mae: 0.4913 - val_mse: 0.4382 - val_pearson_correlation: 2.3361e-17 - val_r2_keras: -33.9003 - val_rmse: 0.9620 - val_sae: 369.2055 - val_sse: 489.5858 - learning_rate: 0.0029\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1310 - loss: 0.2900 - mae: 0.3582 - mse: 0.2735 - pearson_correlation: -7.0764e-17 - r2_keras: -118.3960 - rmse: 0.9509 - sae: 2861.2043 - sse: 3703.5151\n","Epoch 10: val_loss improved from 0.32273 to 0.28497, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.1229 - loss: 0.2851 - mae: 0.3498 - mse: 0.2657 - pearson_correlation: -8.6624e-17 - r2_keras: -91.7875 - rmse: 0.8904 - sae: 2060.6445 - sse: 2623.7312 - val_huber_loss: 0.1264 - val_loss: 0.2850 - val_mae: 0.3925 - val_mse: 0.2636 - val_pearson_correlation: -3.4869e-16 - val_r2_keras: -33.0879 - val_rmse: 0.9508 - val_sae: 381.9240 - val_sse: 478.1894 - learning_rate: 0.0029\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1162 - loss: 0.2748 - mae: 0.3682 - mse: 0.2579 - pearson_correlation: -1.7629e-16 - r2_keras: -97.5691 - rmse: 0.8640 - sae: 2563.4951 - sse: 3057.4917\n","Epoch 11: val_loss did not improve from 0.28497\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1019 - loss: 0.2660 - mae: 0.3498 - mse: 0.2353 - pearson_correlation: -1.4214e-16 - r2_keras: -81.6497 - rmse: 0.8666 - sae: 1880.8715 - sse: 2236.9983 - val_huber_loss: 0.1397 - val_loss: 0.2977 - val_mae: 0.3998 - val_mse: 0.3108 - val_pearson_correlation: -1.5371e-16 - val_r2_keras: -28.7460 - val_rmse: 0.8881 - val_sae: 347.5178 - val_sse: 417.2795 - learning_rate: 0.0029\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1130 - loss: 0.2709 - mae: 0.3213 - mse: 0.2502 - pearson_correlation: -2.0727e-16 - r2_keras: -91.3743 - rmse: 0.8364 - sae: 2488.5671 - sse: 2865.3354\n","Epoch 12: val_loss did not improve from 0.28497\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1042 - loss: 0.2655 - mae: 0.3224 - mse: 0.2346 - pearson_correlation: -5.7970e-17 - r2_keras: -77.7207 - rmse: 0.8499 - sae: 1836.2714 - sse: 2111.2515 - val_huber_loss: 0.1546 - val_loss: 0.3119 - val_mae: 0.4432 - val_mse: 0.3302 - val_pearson_correlation: 1.0802e-16 - val_r2_keras: -29.9305 - val_rmse: 0.9057 - val_sae: 360.0733 - val_sse: 433.8963 - learning_rate: 0.0029\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1230 - loss: 0.2803 - mae: 0.3568 - mse: 0.2767 - pearson_correlation: 3.4667e-16 - r2_keras: -89.7270 - rmse: 0.8289 - sae: 2454.1465 - sse: 2814.2368\n","Epoch 13: val_loss did not improve from 0.28497\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1039 - loss: 0.2686 - mae: 0.3439 - mse: 0.2472 - pearson_correlation: 1.8142e-16 - r2_keras: -76.8107 - rmse: 0.8466 - sae: 1808.0243 - sse: 2079.3936 - val_huber_loss: 0.1346 - val_loss: 0.2912 - val_mae: 0.3784 - val_mse: 0.2957 - val_pearson_correlation: -1.2032e-16 - val_r2_keras: -34.1523 - val_rmse: 0.9655 - val_sae: 392.0132 - val_sse: 493.1208 - learning_rate: 0.0029\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1035 - loss: 0.2601 - mae: 0.3085 - mse: 0.2256 - pearson_correlation: 3.3629e-18 - r2_keras: -97.3335 - rmse: 0.8629 - sae: 2577.9731 - sse: 3050.1807\n","Epoch 14: val_loss improved from 0.28497 to 0.27957, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0870 - loss: 0.2500 - mae: 0.2908 - mse: 0.2017 - pearson_correlation: -4.7677e-17 - r2_keras: -79.7793 - rmse: 0.8508 - sae: 1878.1108 - sse: 2212.0281 - val_huber_loss: 0.1237 - val_loss: 0.2796 - val_mae: 0.3465 - val_mse: 0.2814 - val_pearson_correlation: -5.4836e-16 - val_r2_keras: -30.3201 - val_rmse: 0.9113 - val_sae: 345.6793 - val_sse: 439.3618 - learning_rate: 0.0029\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1012 - loss: 0.2571 - mae: 0.3259 - mse: 0.2100 - pearson_correlation: -5.2001e-17 - r2_keras: -97.3101 - rmse: 0.8628 - sae: 2575.5464 - sse: 3049.4575\n","Epoch 15: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0990 - loss: 0.2557 - mae: 0.3336 - mse: 0.2058 - pearson_correlation: -2.7450e-17 - r2_keras: -82.9482 - rmse: 0.8782 - sae: 1905.5964 - sse: 2248.8992 - val_huber_loss: 0.3462 - val_loss: 0.5013 - val_mae: 0.6655 - val_mse: 0.8193 - val_pearson_correlation: 4.8868e-16 - val_r2_keras: -40.0849 - val_rmse: 1.0438 - val_sae: 401.8594 - val_sse: 576.3435 - learning_rate: 0.0029\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1548 - loss: 0.3100 - mae: 0.4204 - mse: 0.3175 - pearson_correlation: 1.2208e-16 - r2_keras: -112.2130 - rmse: 0.9259 - sae: 2843.1836 - sse: 3511.7266\n","Epoch 16: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1271 - loss: 0.2931 - mae: 0.3914 - mse: 0.2823 - pearson_correlation: -7.5042e-17 - r2_keras: -88.5544 - rmse: 0.8823 - sae: 2056.7617 - sse: 2506.2986 - val_huber_loss: 0.1444 - val_loss: 0.2988 - val_mae: 0.3489 - val_mse: 0.3211 - val_pearson_correlation: 4.7932e-16 - val_r2_keras: -40.8592 - val_rmse: 1.0536 - val_sae: 413.1292 - val_sse: 587.2051 - learning_rate: 0.0029\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1134 - loss: 0.2678 - mae: 0.3160 - mse: 0.2465 - pearson_correlation: -1.9787e-16 - r2_keras: -103.7779 - rmse: 0.8908 - sae: 2607.5933 - sse: 3250.0803\n","Epoch 17: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1002 - loss: 0.2598 - mae: 0.3097 - mse: 0.2265 - pearson_correlation: -1.5022e-16 - r2_keras: -87.4185 - rmse: 0.8981 - sae: 1919.9780 - sse: 2384.5066 - val_huber_loss: 0.2641 - val_loss: 0.4179 - val_mae: 0.5073 - val_mse: 0.6701 - val_pearson_correlation: -4.3683e-16 - val_r2_keras: -30.2467 - val_rmse: 0.9103 - val_sae: 320.1142 - val_sse: 438.3320 - learning_rate: 0.0029\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1029 - loss: 0.2566 - mae: 0.3109 - mse: 0.2169 - pearson_correlation: -1.0854e-16 - r2_keras: -82.4600 - rmse: 0.7950 - sae: 2403.2036 - sse: 2588.8242\n","Epoch 18: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0968 - loss: 0.2529 - mae: 0.3181 - mse: 0.2072 - pearson_correlation: -1.6523e-16 - r2_keras: -72.6295 - rmse: 0.8295 - sae: 1783.1198 - sse: 1936.9009 - val_huber_loss: 0.1727 - val_loss: 0.3257 - val_mae: 0.4074 - val_mse: 0.3968 - val_pearson_correlation: -1.6265e-16 - val_r2_keras: -39.6833 - val_rmse: 1.0387 - val_sae: 405.7163 - val_sse: 570.7096 - learning_rate: 0.0029\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1089 - loss: 0.2620 - mae: 0.3283 - mse: 0.2430 - pearson_correlation: -1.1988e-16 - r2_keras: -93.6058 - rmse: 0.8464 - sae: 2515.2134 - sse: 2934.5542\n","Epoch 19: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1027 - loss: 0.2581 - mae: 0.3304 - mse: 0.2302 - pearson_correlation: -1.1970e-16 - r2_keras: -76.8076 - rmse: 0.8354 - sae: 1838.9187 - sse: 2129.2354 - val_huber_loss: 0.2154 - val_loss: 0.3678 - val_mae: 0.4815 - val_mse: 0.5022 - val_pearson_correlation: -4.3310e-16 - val_r2_keras: -53.6664 - val_rmse: 1.2040 - val_sae: 460.6518 - val_sse: 766.8661 - learning_rate: 0.0029\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1776 - loss: 0.3299 - mae: 0.3915 - mse: 0.4273 - pearson_correlation: -1.8052e-17 - r2_keras: -125.9760 - rmse: 0.9806 - sae: 2931.3511 - sse: 3938.6357\n","Epoch 20: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1657 - loss: 0.3227 - mae: 0.3887 - mse: 0.4010 - pearson_correlation: -7.6470e-17 - r2_keras: -103.8242 - rmse: 0.9709 - sae: 2136.5034 - sse: 2862.3940 - val_huber_loss: 0.1577 - val_loss: 0.3100 - val_mae: 0.3762 - val_mse: 0.3571 - val_pearson_correlation: -7.8025e-17 - val_r2_keras: -46.5098 - val_rmse: 1.1224 - val_sae: 425.1685 - val_sse: 666.4721 - learning_rate: 5.8709e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1191 - loss: 0.2713 - mae: 0.2999 - mse: 0.2722 - pearson_correlation: 5.6609e-17 - r2_keras: -105.0977 - rmse: 0.8964 - sae: 2655.9570 - sse: 3291.0190\n","Epoch 21: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1083 - loss: 0.2647 - mae: 0.2947 - mse: 0.2533 - pearson_correlation: 8.9773e-17 - r2_keras: -88.4187 - rmse: 0.9029 - sae: 1946.1337 - sse: 2413.2107 - val_huber_loss: 0.1418 - val_loss: 0.2939 - val_mae: 0.3324 - val_mse: 0.3159 - val_pearson_correlation: 6.6916e-17 - val_r2_keras: -42.9403 - val_rmse: 1.0795 - val_sae: 406.8792 - val_sse: 616.3986 - learning_rate: 5.8709e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1017 - loss: 0.2538 - mae: 0.2963 - mse: 0.2287 - pearson_correlation: -4.5782e-16 - r2_keras: -100.5597 - rmse: 0.8770 - sae: 2608.1201 - sse: 3150.2563\n","Epoch 22: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0911 - loss: 0.2473 - mae: 0.2856 - mse: 0.2112 - pearson_correlation: -2.5423e-16 - r2_keras: -84.6400 - rmse: 0.8837 - sae: 1912.5000 - sse: 2310.5317 - val_huber_loss: 0.1385 - val_loss: 0.2903 - val_mae: 0.3285 - val_mse: 0.3104 - val_pearson_correlation: 1.7904e-16 - val_r2_keras: -40.1174 - val_rmse: 1.0442 - val_sae: 393.1637 - val_sse: 576.7992 - learning_rate: 5.8709e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0938 - loss: 0.2456 - mae: 0.2850 - mse: 0.2080 - pearson_correlation: -2.9210e-16 - r2_keras: -99.8643 - rmse: 0.8740 - sae: 2601.0505 - sse: 3128.6860\n","Epoch 23: val_loss did not improve from 0.27957\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0832 - loss: 0.2392 - mae: 0.2723 - mse: 0.1911 - pearson_correlation: -2.7153e-16 - r2_keras: -83.5655 - rmse: 0.8766 - sae: 1905.4232 - sse: 2288.9851 - val_huber_loss: 0.1346 - val_loss: 0.2863 - val_mae: 0.3266 - val_mse: 0.3027 - val_pearson_correlation: 3.7799e-17 - val_r2_keras: -38.1871 - val_rmse: 1.0194 - val_sae: 383.9769 - val_sse: 549.7205 - learning_rate: 5.8709e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0886 - loss: 0.2403 - mae: 0.2778 - mse: 0.1948 - pearson_correlation: 1.5459e-16 - r2_keras: -99.8604 - rmse: 0.8740 - sae: 2597.5037 - sse: 3128.5645\n","Epoch 24: val_loss improved from 0.27957 to 0.27760, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.0777 - loss: 0.2336 - mae: 0.2649 - mse: 0.1779 - pearson_correlation: 1.9945e-16 - r2_keras: -83.1536 - rmse: 0.8731 - sae: 1901.6332 - sse: 2284.1038 - val_huber_loss: 0.1261 - val_loss: 0.2776 - val_mae: 0.3217 - val_mse: 0.2818 - val_pearson_correlation: 4.0751e-17 - val_r2_keras: -35.8869 - val_rmse: 0.9890 - val_sae: 373.4526 - val_sse: 517.4540 - learning_rate: 5.8709e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0834 - loss: 0.2349 - mae: 0.2680 - mse: 0.1824 - pearson_correlation: 7.4804e-17 - r2_keras: -99.9773 - rmse: 0.8745 - sae: 2595.1943 - sse: 3132.1895\n","Epoch 25: val_loss improved from 0.27760 to 0.25406, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - huber_loss: 0.0718 - loss: 0.2278 - mae: 0.2561 - mse: 0.1650 - pearson_correlation: 6.8326e-18 - r2_keras: -82.5966 - rmse: 0.8679 - sae: 1897.1598 - sse: 2279.0725 - val_huber_loss: 0.1028 - val_loss: 0.2541 - val_mae: 0.2989 - val_mse: 0.2319 - val_pearson_correlation: -4.8229e-17 - val_r2_keras: -32.0036 - val_rmse: 0.9355 - val_sae: 350.9446 - val_sse: 462.9774 - learning_rate: 5.8709e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0799 - loss: 0.2312 - mae: 0.2568 - mse: 0.1740 - pearson_correlation: 3.7959e-16 - r2_keras: -101.0713 - rmse: 0.8792 - sae: 2597.0938 - sse: 3166.1245\n","Epoch 26: val_loss did not improve from 0.25406\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0659 - loss: 0.2226 - mae: 0.2423 - mse: 0.1541 - pearson_correlation: 2.9216e-16 - r2_keras: -82.3297 - rmse: 0.8622 - sae: 1893.0245 - sse: 2290.0100 - val_huber_loss: 0.1034 - val_loss: 0.2543 - val_mae: 0.2988 - val_mse: 0.2345 - val_pearson_correlation: -1.2365e-17 - val_r2_keras: -31.5592 - val_rmse: 0.9292 - val_sae: 348.0699 - val_sse: 456.7438 - learning_rate: 5.8709e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0744 - loss: 0.2253 - mae: 0.2425 - mse: 0.1614 - pearson_correlation: -4.4174e-16 - r2_keras: -100.6604 - rmse: 0.8774 - sae: 2588.8240 - sse: 3153.3770\n","Epoch 27: val_loss did not improve from 0.25406\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0611 - loss: 0.2172 - mae: 0.2298 - mse: 0.1426 - pearson_correlation: -2.7811e-16 - r2_keras: -82.3783 - rmse: 0.8639 - sae: 1889.5245 - sse: 2285.2952 - val_huber_loss: 0.1050 - val_loss: 0.2557 - val_mae: 0.3030 - val_mse: 0.2370 - val_pearson_correlation: -1.0619e-16 - val_r2_keras: -30.5823 - val_rmse: 0.9152 - val_sae: 335.8307 - val_sse: 443.0404 - learning_rate: 5.8709e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0739 - loss: 0.2246 - mae: 0.2357 - mse: 0.1599 - pearson_correlation: 3.7650e-16 - r2_keras: -101.2216 - rmse: 0.8798 - sae: 2594.1987 - sse: 3170.7856\n","Epoch 28: val_loss improved from 0.25406 to 0.24638, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0600 - loss: 0.2161 - mae: 0.2221 - mse: 0.1405 - pearson_correlation: 3.5150e-16 - r2_keras: -82.4854 - rmse: 0.8631 - sae: 1891.3192 - sse: 2293.7688 - val_huber_loss: 0.0960 - val_loss: 0.2464 - val_mae: 0.2796 - val_mse: 0.2114 - val_pearson_correlation: -3.6493e-17 - val_r2_keras: -31.9326 - val_rmse: 0.9345 - val_sae: 348.5891 - val_sse: 461.9823 - learning_rate: 5.8709e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0715 - loss: 0.2219 - mae: 0.2330 - mse: 0.1543 - pearson_correlation: -5.2716e-16 - r2_keras: -101.1259 - rmse: 0.8794 - sae: 2601.9116 - sse: 3167.8184\n","Epoch 29: val_loss did not improve from 0.24638\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0584 - loss: 0.2139 - mae: 0.2219 - mse: 0.1361 - pearson_correlation: -3.4021e-16 - r2_keras: -83.0717 - rmse: 0.8687 - sae: 1900.4340 - sse: 2299.4153 - val_huber_loss: 0.1055 - val_loss: 0.2556 - val_mae: 0.3084 - val_mse: 0.2320 - val_pearson_correlation: 2.5376e-16 - val_r2_keras: -30.8798 - val_rmse: 0.9195 - val_sae: 338.0351 - val_sse: 447.2134 - learning_rate: 5.8709e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0682 - loss: 0.2182 - mae: 0.2269 - mse: 0.1467 - pearson_correlation: 1.7523e-16 - r2_keras: -102.1001 - rmse: 0.8836 - sae: 2602.1128 - sse: 3198.0352\n","Epoch 30: val_loss improved from 0.24638 to 0.24211, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - huber_loss: 0.0550 - loss: 0.2102 - mae: 0.2142 - mse: 0.1286 - pearson_correlation: 1.0140e-16 - r2_keras: -83.3412 - rmse: 0.8681 - sae: 1896.7252 - sse: 2315.1040 - val_huber_loss: 0.0924 - val_loss: 0.2421 - val_mae: 0.2799 - val_mse: 0.2004 - val_pearson_correlation: -1.8108e-16 - val_r2_keras: -32.1538 - val_rmse: 0.9376 - val_sae: 347.6185 - val_sse: 465.0844 - learning_rate: 5.8709e-04\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0686 - loss: 0.2183 - mae: 0.2278 - mse: 0.1470 - pearson_correlation: -4.7601e-18 - r2_keras: -103.8854 - rmse: 0.8912 - sae: 2626.1409 - sse: 3253.4126\n","Epoch 31: val_loss did not improve from 0.24211\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0551 - loss: 0.2101 - mae: 0.2154 - mse: 0.1286 - pearson_correlation: -2.3437e-17 - r2_keras: -85.1252 - rmse: 0.8784 - sae: 1917.4257 - sse: 2358.9875 - val_huber_loss: 0.1138 - val_loss: 0.2632 - val_mae: 0.3112 - val_mse: 0.2447 - val_pearson_correlation: -1.6548e-16 - val_r2_keras: -30.7319 - val_rmse: 0.9173 - val_sae: 333.3757 - val_sse: 445.1382 - learning_rate: 5.8709e-04\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0657 - loss: 0.2151 - mae: 0.2230 - mse: 0.1401 - pearson_correlation: 8.4533e-18 - r2_keras: -103.3748 - rmse: 0.8891 - sae: 2609.3633 - sse: 3237.5752\n","Epoch 32: val_loss improved from 0.24211 to 0.23854, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.0534 - loss: 0.2075 - mae: 0.2101 - mse: 0.1233 - pearson_correlation: 1.8890e-17 - r2_keras: -84.4179 - rmse: 0.8737 - sae: 1902.6617 - sse: 2344.1252 - val_huber_loss: 0.0895 - val_loss: 0.2385 - val_mae: 0.2743 - val_mse: 0.1908 - val_pearson_correlation: -1.2801e-16 - val_r2_keras: -32.8104 - val_rmse: 0.9469 - val_sae: 354.6078 - val_sse: 474.2965 - learning_rate: 5.8709e-04\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0659 - loss: 0.2149 - mae: 0.2246 - mse: 0.1406 - pearson_correlation: -2.2502e-16 - r2_keras: -103.8233 - rmse: 0.8910 - sae: 2626.0679 - sse: 3251.4883\n","Epoch 33: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0545 - loss: 0.2079 - mae: 0.2159 - mse: 0.1250 - pearson_correlation: -1.0661e-16 - r2_keras: -86.5721 - rmse: 0.8910 - sae: 1928.0392 - sse: 2375.1619 - val_huber_loss: 0.1370 - val_loss: 0.2856 - val_mae: 0.3644 - val_mse: 0.2998 - val_pearson_correlation: 3.9611e-17 - val_r2_keras: -30.8725 - val_rmse: 0.9193 - val_sae: 337.0432 - val_sse: 447.1111 - learning_rate: 5.8709e-04\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0666 - loss: 0.2153 - mae: 0.2270 - mse: 0.1403 - pearson_correlation: -2.6317e-16 - r2_keras: -102.6919 - rmse: 0.8861 - sae: 2606.4226 - sse: 3216.3928\n","Epoch 34: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0555 - loss: 0.2085 - mae: 0.2165 - mse: 0.1254 - pearson_correlation: -1.0451e-16 - r2_keras: -84.0602 - rmse: 0.8726 - sae: 1900.8954 - sse: 2331.1484 - val_huber_loss: 0.0951 - val_loss: 0.2434 - val_mae: 0.2882 - val_mse: 0.1998 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -34.1630 - val_rmse: 0.9656 - val_sae: 365.0008 - val_sse: 493.2706 - learning_rate: 5.8709e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0656 - loss: 0.2139 - mae: 0.2275 - mse: 0.1395 - pearson_correlation: -5.3216e-17 - r2_keras: -105.1681 - rmse: 0.8967 - sae: 2642.6733 - sse: 3293.2004\n","Epoch 35: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0556 - loss: 0.2077 - mae: 0.2186 - mse: 0.1256 - pearson_correlation: -1.1626e-17 - r2_keras: -87.7185 - rmse: 0.8969 - sae: 1939.2682 - sse: 2405.9019 - val_huber_loss: 0.1208 - val_loss: 0.2687 - val_mae: 0.3309 - val_mse: 0.2602 - val_pearson_correlation: 4.0073e-16 - val_r2_keras: -30.5700 - val_rmse: 0.9150 - val_sae: 333.5623 - val_sse: 442.8669 - learning_rate: 5.8709e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0629 - loss: 0.2109 - mae: 0.2169 - mse: 0.1322 - pearson_correlation: -4.4430e-16 - r2_keras: -101.3210 - rmse: 0.8803 - sae: 2581.7876 - sse: 3173.8699\n","Epoch 36: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0510 - loss: 0.2036 - mae: 0.2043 - mse: 0.1164 - pearson_correlation: -1.9015e-16 - r2_keras: -83.6368 - rmse: 0.8730 - sae: 1887.5795 - sse: 2308.5530 - val_huber_loss: 0.0915 - val_loss: 0.2391 - val_mae: 0.2880 - val_mse: 0.1941 - val_pearson_correlation: -8.6908e-17 - val_r2_keras: -31.6062 - val_rmse: 0.9299 - val_sae: 343.5008 - val_sse: 457.4030 - learning_rate: 5.8709e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0618 - loss: 0.2094 - mae: 0.2156 - mse: 0.1312 - pearson_correlation: 5.4188e-16 - r2_keras: -103.6304 - rmse: 0.8901 - sae: 2609.1147 - sse: 3245.5029\n","Epoch 37: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0491 - loss: 0.2016 - mae: 0.2024 - mse: 0.1142 - pearson_correlation: 4.5604e-16 - r2_keras: -86.0713 - rmse: 0.8873 - sae: 1911.8329 - sse: 2366.8062 - val_huber_loss: 0.1157 - val_loss: 0.2629 - val_mae: 0.3196 - val_mse: 0.2457 - val_pearson_correlation: -2.4917e-16 - val_r2_keras: -30.8285 - val_rmse: 0.9187 - val_sae: 335.4166 - val_sse: 446.4930 - learning_rate: 5.8709e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0604 - loss: 0.2076 - mae: 0.2076 - mse: 0.1271 - pearson_correlation: -1.2761e-16 - r2_keras: -103.0504 - rmse: 0.8877 - sae: 2608.8484 - sse: 3227.5132\n","Epoch 38: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0478 - loss: 0.1999 - mae: 0.1931 - mse: 0.1105 - pearson_correlation: -1.9711e-16 - r2_keras: -84.9433 - rmse: 0.8793 - sae: 1905.0714 - sse: 2346.1174 - val_huber_loss: 0.1073 - val_loss: 0.2545 - val_mae: 0.3090 - val_mse: 0.2275 - val_pearson_correlation: 2.9345e-16 - val_r2_keras: -30.8784 - val_rmse: 0.9194 - val_sae: 335.5965 - val_sse: 447.1937 - learning_rate: 1.1742e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0592 - loss: 0.2064 - mae: 0.2067 - mse: 0.1248 - pearson_correlation: -1.9769e-17 - r2_keras: -103.2008 - rmse: 0.8883 - sae: 2609.5305 - sse: 3232.1787\n","Epoch 39: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0460 - loss: 0.1983 - mae: 0.1897 - mse: 0.1074 - pearson_correlation: -5.2000e-17 - r2_keras: -85.2749 - rmse: 0.8817 - sae: 1907.1711 - sse: 2351.9407 - val_huber_loss: 0.1032 - val_loss: 0.2503 - val_mae: 0.3054 - val_mse: 0.2185 - val_pearson_correlation: -2.9169e-16 - val_r2_keras: -30.9526 - val_rmse: 0.9205 - val_sae: 336.2887 - val_sse: 448.2339 - learning_rate: 1.1742e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0586 - loss: 0.2056 - mae: 0.2065 - mse: 0.1235 - pearson_correlation: -5.6843e-16 - r2_keras: -103.2897 - rmse: 0.8887 - sae: 2610.3467 - sse: 3234.9375\n","Epoch 40: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0452 - loss: 0.1975 - mae: 0.1886 - mse: 0.1059 - pearson_correlation: -3.7021e-16 - r2_keras: -85.4778 - rmse: 0.8832 - sae: 1908.5375 - sse: 2355.4644 - val_huber_loss: 0.1017 - val_loss: 0.2487 - val_mae: 0.3037 - val_mse: 0.2153 - val_pearson_correlation: -1.6183e-16 - val_r2_keras: -30.9861 - val_rmse: 0.9210 - val_sae: 335.9080 - val_sse: 448.7040 - learning_rate: 1.1742e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0582 - loss: 0.2052 - mae: 0.2065 - mse: 0.1227 - pearson_correlation: -9.2212e-17 - r2_keras: -103.3195 - rmse: 0.8888 - sae: 2610.0476 - sse: 3235.8589\n","Epoch 41: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0449 - loss: 0.1970 - mae: 0.1878 - mse: 0.1052 - pearson_correlation: -2.6675e-17 - r2_keras: -85.5667 - rmse: 0.8839 - sae: 1909.0283 - sse: 2356.8896 - val_huber_loss: 0.1014 - val_loss: 0.2483 - val_mae: 0.3048 - val_mse: 0.2146 - val_pearson_correlation: -7.7712e-17 - val_r2_keras: -30.9550 - val_rmse: 0.9205 - val_sae: 336.2038 - val_sse: 448.2678 - learning_rate: 1.1742e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0577 - loss: 0.2046 - mae: 0.2054 - mse: 0.1216 - pearson_correlation: 4.9667e-16 - r2_keras: -103.1695 - rmse: 0.8882 - sae: 2606.9307 - sse: 3231.2065\n","Epoch 42: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0445 - loss: 0.1965 - mae: 0.1869 - mse: 0.1042 - pearson_correlation: 3.9172e-16 - r2_keras: -85.5415 - rmse: 0.8841 - sae: 1907.1666 - sse: 2354.6650 - val_huber_loss: 0.1014 - val_loss: 0.2482 - val_mae: 0.3050 - val_mse: 0.2148 - val_pearson_correlation: 1.3617e-16 - val_r2_keras: -30.9541 - val_rmse: 0.9205 - val_sae: 335.6583 - val_sse: 448.2563 - learning_rate: 1.1742e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.0573 - loss: 0.2040 - mae: 0.2047 - mse: 0.1206 - pearson_correlation: 4.8146e-16 - r2_keras: -103.2550 - rmse: 0.8885 - sae: 2606.6084 - sse: 3233.8582\n","Epoch 43: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0441 - loss: 0.1960 - mae: 0.1857 - mse: 0.1033 - pearson_correlation: 3.4264e-16 - r2_keras: -85.5846 - rmse: 0.8842 - sae: 1906.9561 - sse: 2356.2700 - val_huber_loss: 0.1013 - val_loss: 0.2480 - val_mae: 0.3042 - val_mse: 0.2142 - val_pearson_correlation: 1.2954e-16 - val_r2_keras: -30.9768 - val_rmse: 0.9209 - val_sae: 335.5128 - val_sse: 448.5742 - learning_rate: 2.3484e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0571 - loss: 0.2039 - mae: 0.2044 - mse: 0.1202 - pearson_correlation: -1.9889e-16 - r2_keras: -103.2830 - rmse: 0.8887 - sae: 2606.8286 - sse: 3234.7292\n","Epoch 44: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0440 - loss: 0.1958 - mae: 0.1854 - mse: 0.1030 - pearson_correlation: -2.2176e-16 - r2_keras: -85.6186 - rmse: 0.8844 - sae: 1907.2023 - sse: 2357.0298 - val_huber_loss: 0.1013 - val_loss: 0.2480 - val_mae: 0.3039 - val_mse: 0.2140 - val_pearson_correlation: -2.5899e-16 - val_r2_keras: -30.9856 - val_rmse: 0.9210 - val_sae: 335.3993 - val_sse: 448.6973 - learning_rate: 2.3484e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0570 - loss: 0.2037 - mae: 0.2041 - mse: 0.1199 - pearson_correlation: -2.8723e-16 - r2_keras: -103.2719 - rmse: 0.8886 - sae: 2606.4080 - sse: 3234.3823\n","Epoch 45: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0438 - loss: 0.1957 - mae: 0.1851 - mse: 0.1027 - pearson_correlation: -2.6588e-16 - r2_keras: -85.6234 - rmse: 0.8845 - sae: 1907.0139 - sse: 2356.9417 - val_huber_loss: 0.1013 - val_loss: 0.2480 - val_mae: 0.3039 - val_mse: 0.2140 - val_pearson_correlation: -6.4740e-18 - val_r2_keras: -30.9884 - val_rmse: 0.9210 - val_sae: 335.3148 - val_sse: 448.7365 - learning_rate: 2.3484e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0569 - loss: 0.2036 - mae: 0.2039 - mse: 0.1197 - pearson_correlation: -2.6106e-16 - r2_keras: -103.2525 - rmse: 0.8885 - sae: 2605.9678 - sse: 3233.7832\n","Epoch 46: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0438 - loss: 0.1956 - mae: 0.1850 - mse: 0.1025 - pearson_correlation: -1.7231e-16 - r2_keras: -85.6322 - rmse: 0.8846 - sae: 1906.7828 - sse: 2356.7971 - val_huber_loss: 0.1014 - val_loss: 0.2480 - val_mae: 0.3034 - val_mse: 0.2140 - val_pearson_correlation: 3.1726e-16 - val_r2_keras: -30.9950 - val_rmse: 0.9211 - val_sae: 335.0625 - val_sse: 448.8297 - learning_rate: 2.3484e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0568 - loss: 0.2034 - mae: 0.2037 - mse: 0.1194 - pearson_correlation: 1.7182e-16 - r2_keras: -103.2781 - rmse: 0.8886 - sae: 2605.8232 - sse: 3234.5769\n","Epoch 47: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0437 - loss: 0.1954 - mae: 0.1847 - mse: 0.1022 - pearson_correlation: 1.0246e-16 - r2_keras: -85.6595 - rmse: 0.8848 - sae: 1906.7899 - sse: 2357.4460 - val_huber_loss: 0.1013 - val_loss: 0.2480 - val_mae: 0.3036 - val_mse: 0.2139 - val_pearson_correlation: -1.3594e-16 - val_r2_keras: -30.9953 - val_rmse: 0.9211 - val_sae: 335.1117 - val_sse: 448.8342 - learning_rate: 2.3484e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0567 - loss: 0.2033 - mae: 0.2034 - mse: 0.1191 - pearson_correlation: 1.5153e-16 - r2_keras: -103.2661 - rmse: 0.8886 - sae: 2605.5520 - sse: 3234.2029\n","Epoch 48: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0436 - loss: 0.1953 - mae: 0.1845 - mse: 0.1020 - pearson_correlation: 1.0533e-16 - r2_keras: -85.6580 - rmse: 0.8848 - sae: 1906.5985 - sse: 2357.2732 - val_huber_loss: 0.1014 - val_loss: 0.2480 - val_mae: 0.3033 - val_mse: 0.2140 - val_pearson_correlation: 9.7101e-17 - val_r2_keras: -31.0009 - val_rmse: 0.9212 - val_sae: 334.9651 - val_sse: 448.9125 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0566 - loss: 0.2032 - mae: 0.2033 - mse: 0.1190 - pearson_correlation: 2.1920e-16 - r2_keras: -103.2854 - rmse: 0.8887 - sae: 2605.5884 - sse: 3234.8037\n","Epoch 49: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0435 - loss: 0.1952 - mae: 0.1843 - mse: 0.1019 - pearson_correlation: 1.5734e-16 - r2_keras: -85.6798 - rmse: 0.8850 - sae: 1906.6519 - sse: 2357.7791 - val_huber_loss: 0.1014 - val_loss: 0.2480 - val_mae: 0.3030 - val_mse: 0.2139 - val_pearson_correlation: -1.2944e-16 - val_r2_keras: -31.0089 - val_rmse: 0.9213 - val_sae: 334.8914 - val_sse: 449.0239 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0565 - loss: 0.2031 - mae: 0.2032 - mse: 0.1189 - pearson_correlation: 6.6597e-16 - r2_keras: -103.2958 - rmse: 0.8887 - sae: 2605.6047 - sse: 3235.1245\n","Epoch 50: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0435 - loss: 0.1952 - mae: 0.1842 - mse: 0.1018 - pearson_correlation: 4.3536e-16 - r2_keras: -85.6893 - rmse: 0.8850 - sae: 1906.6891 - sse: 2358.0225 - val_huber_loss: 0.1014 - val_loss: 0.2479 - val_mae: 0.3031 - val_mse: 0.2139 - val_pearson_correlation: 1.9414e-17 - val_r2_keras: -31.0093 - val_rmse: 0.9213 - val_sae: 334.9053 - val_sse: 449.0294 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0565 - loss: 0.2030 - mae: 0.2031 - mse: 0.1187 - pearson_correlation: -3.6331e-16 - r2_keras: -103.2950 - rmse: 0.8887 - sae: 2605.4702 - sse: 3235.0996\n","Epoch 51: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0434 - loss: 0.1951 - mae: 0.1841 - mse: 0.1017 - pearson_correlation: -1.8792e-16 - r2_keras: -85.6985 - rmse: 0.8851 - sae: 1906.6310 - sse: 2358.1199 - val_huber_loss: 0.1014 - val_loss: 0.2479 - val_mae: 0.3029 - val_mse: 0.2138 - val_pearson_correlation: -6.4700e-18 - val_r2_keras: -31.0158 - val_rmse: 0.9214 - val_sae: 334.8488 - val_sse: 449.1216 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0564 - loss: 0.2030 - mae: 0.2030 - mse: 0.1187 - pearson_correlation: -3.9202e-16 - r2_keras: -103.3065 - rmse: 0.8888 - sae: 2605.4985 - sse: 3235.4585\n","Epoch 52: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0434 - loss: 0.1951 - mae: 0.1840 - mse: 0.1016 - pearson_correlation: -3.2941e-16 - r2_keras: -85.7085 - rmse: 0.8851 - sae: 1906.6757 - sse: 2358.3870 - val_huber_loss: 0.1013 - val_loss: 0.2479 - val_mae: 0.3031 - val_mse: 0.2138 - val_pearson_correlation: -3.2348e-17 - val_r2_keras: -31.0152 - val_rmse: 0.9214 - val_sae: 334.8853 - val_sse: 449.1133 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0564 - loss: 0.2029 - mae: 0.2028 - mse: 0.1185 - pearson_correlation: 2.8203e-18 - r2_keras: -103.3067 - rmse: 0.8888 - sae: 2605.3743 - sse: 3235.4629\n","Epoch 53: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0433 - loss: 0.1950 - mae: 0.1839 - mse: 0.1015 - pearson_correlation: 6.7337e-17 - r2_keras: -85.7132 - rmse: 0.8852 - sae: 1906.6385 - sse: 2358.4438 - val_huber_loss: 0.1013 - val_loss: 0.2478 - val_mae: 0.3031 - val_mse: 0.2135 - val_pearson_correlation: 2.0050e-16 - val_r2_keras: -31.0187 - val_rmse: 0.9215 - val_sae: 334.9509 - val_sse: 449.1615 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0563 - loss: 0.2029 - mae: 0.2028 - mse: 0.1184 - pearson_correlation: -2.0075e-16 - r2_keras: -103.3292 - rmse: 0.8889 - sae: 2605.7014 - sse: 3236.1599\n","Epoch 54: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0433 - loss: 0.1949 - mae: 0.1838 - mse: 0.1014 - pearson_correlation: -1.1834e-16 - r2_keras: -85.7379 - rmse: 0.8853 - sae: 1906.8636 - sse: 2359.0215 - val_huber_loss: 0.1014 - val_loss: 0.2479 - val_mae: 0.3030 - val_mse: 0.2137 - val_pearson_correlation: -8.4097e-17 - val_r2_keras: -31.0202 - val_rmse: 0.9215 - val_sae: 334.8340 - val_sse: 449.1832 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0562 - loss: 0.2028 - mae: 0.2026 - mse: 0.1183 - pearson_correlation: 4.8179e-16 - r2_keras: -103.3402 - rmse: 0.8889 - sae: 2605.5828 - sse: 3236.5022\n","Epoch 55: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0432 - loss: 0.1949 - mae: 0.1837 - mse: 0.1013 - pearson_correlation: 3.5906e-16 - r2_keras: -85.7481 - rmse: 0.8854 - sae: 1906.8262 - sse: 2359.2837 - val_huber_loss: 0.1013 - val_loss: 0.2479 - val_mae: 0.3033 - val_mse: 0.2137 - val_pearson_correlation: 2.9750e-16 - val_r2_keras: -31.0216 - val_rmse: 0.9215 - val_sae: 334.9100 - val_sse: 449.2031 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0562 - loss: 0.2027 - mae: 0.2025 - mse: 0.1181 - pearson_correlation: -6.7921e-16 - r2_keras: -103.3306 - rmse: 0.8889 - sae: 2605.3979 - sse: 3236.2056\n","Epoch 56: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0432 - loss: 0.1948 - mae: 0.1835 - mse: 0.1011 - pearson_correlation: -3.6679e-16 - r2_keras: -85.7501 - rmse: 0.8854 - sae: 1906.7131 - sse: 2359.1836 - val_huber_loss: 0.1013 - val_loss: 0.2478 - val_mae: 0.3031 - val_mse: 0.2136 - val_pearson_correlation: -2.7163e-16 - val_r2_keras: -31.0252 - val_rmse: 0.9215 - val_sae: 334.8346 - val_sse: 449.2535 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0561 - loss: 0.2026 - mae: 0.2024 - mse: 0.1180 - pearson_correlation: -3.0527e-16 - r2_keras: -103.3504 - rmse: 0.8890 - sae: 2605.4451 - sse: 3236.8198\n","Epoch 57: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0432 - loss: 0.1947 - mae: 0.1834 - mse: 0.1010 - pearson_correlation: -1.7686e-16 - r2_keras: -85.7663 - rmse: 0.8855 - sae: 1906.7850 - sse: 2359.6289 - val_huber_loss: 0.1013 - val_loss: 0.2478 - val_mae: 0.3033 - val_mse: 0.2136 - val_pearson_correlation: 2.1337e-16 - val_r2_keras: -31.0268 - val_rmse: 0.9216 - val_sae: 334.9205 - val_sse: 449.2760 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0561 - loss: 0.2026 - mae: 0.2022 - mse: 0.1179 - pearson_correlation: 7.1090e-16 - r2_keras: -103.3504 - rmse: 0.8890 - sae: 2605.4124 - sse: 3236.8196\n","Epoch 58: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0431 - loss: 0.1947 - mae: 0.1833 - mse: 0.1009 - pearson_correlation: 4.6791e-16 - r2_keras: -85.7747 - rmse: 0.8856 - sae: 1906.7679 - sse: 2359.7278 - val_huber_loss: 0.1014 - val_loss: 0.2478 - val_mae: 0.3032 - val_mse: 0.2137 - val_pearson_correlation: -1.6815e-16 - val_r2_keras: -31.0271 - val_rmse: 0.9216 - val_sae: 334.8166 - val_sse: 449.2795 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0560 - loss: 0.2025 - mae: 0.2021 - mse: 0.1178 - pearson_correlation: -3.0438e-16 - r2_keras: -103.3630 - rmse: 0.8890 - sae: 2605.3840 - sse: 3237.2090\n","Epoch 59: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0431 - loss: 0.1946 - mae: 0.1832 - mse: 0.1008 - pearson_correlation: -2.1237e-16 - r2_keras: -85.7873 - rmse: 0.8857 - sae: 1906.7953 - sse: 2360.0359 - val_huber_loss: 0.1013 - val_loss: 0.2478 - val_mae: 0.3033 - val_mse: 0.2135 - val_pearson_correlation: -5.1726e-17 - val_r2_keras: -31.0280 - val_rmse: 0.9216 - val_sae: 334.9086 - val_sse: 449.2927 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0559 - loss: 0.2024 - mae: 0.2019 - mse: 0.1176 - pearson_correlation: -3.9485e-16 - r2_keras: -103.3635 - rmse: 0.8890 - sae: 2605.3557 - sse: 3237.2246\n","Epoch 60: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0430 - loss: 0.1945 - mae: 0.1830 - mse: 0.1007 - pearson_correlation: -2.0398e-16 - r2_keras: -85.7973 - rmse: 0.8857 - sae: 1906.7853 - sse: 2360.1604 - val_huber_loss: 0.1013 - val_loss: 0.2478 - val_mae: 0.3032 - val_mse: 0.2135 - val_pearson_correlation: 4.5258e-17 - val_r2_keras: -31.0330 - val_rmse: 0.9217 - val_sae: 334.8337 - val_sse: 449.3627 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0559 - loss: 0.2024 - mae: 0.2018 - mse: 0.1175 - pearson_correlation: 2.9192e-16 - r2_keras: -103.3801 - rmse: 0.8891 - sae: 2605.3457 - sse: 3237.7390\n","Epoch 61: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0430 - loss: 0.1945 - mae: 0.1829 - mse: 0.1006 - pearson_correlation: 1.5855e-16 - r2_keras: -85.8124 - rmse: 0.8858 - sae: 1906.8258 - sse: 2360.5510 - val_huber_loss: 0.1013 - val_loss: 0.2477 - val_mae: 0.3034 - val_mse: 0.2134 - val_pearson_correlation: 8.4030e-17 - val_r2_keras: -31.0338 - val_rmse: 0.9217 - val_sae: 334.9296 - val_sse: 449.3743 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0558 - loss: 0.2022 - mae: 0.2017 - mse: 0.1173 - pearson_correlation: -9.9181e-17 - r2_keras: -103.3825 - rmse: 0.8891 - sae: 2605.3333 - sse: 3237.8152\n","Epoch 62: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0429 - loss: 0.1944 - mae: 0.1827 - mse: 0.1004 - pearson_correlation: -3.2654e-17 - r2_keras: -85.8214 - rmse: 0.8859 - sae: 1906.8121 - sse: 2360.6880 - val_huber_loss: 0.1013 - val_loss: 0.2477 - val_mae: 0.3033 - val_mse: 0.2135 - val_pearson_correlation: -1.9394e-17 - val_r2_keras: -31.0357 - val_rmse: 0.9217 - val_sae: 334.8390 - val_sse: 449.3996 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0558 - loss: 0.2022 - mae: 0.2016 - mse: 0.1172 - pearson_correlation: -4.4740e-16 - r2_keras: -103.3898 - rmse: 0.8891 - sae: 2605.2529 - sse: 3238.0425\n","Epoch 63: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0429 - loss: 0.1943 - mae: 0.1826 - mse: 0.1003 - pearson_correlation: -3.7463e-16 - r2_keras: -85.8292 - rmse: 0.8859 - sae: 1906.8033 - sse: 2360.8735 - val_huber_loss: 0.1013 - val_loss: 0.2477 - val_mae: 0.3035 - val_mse: 0.2134 - val_pearson_correlation: 6.4630e-17 - val_r2_keras: -31.0366 - val_rmse: 0.9217 - val_sae: 334.9382 - val_sse: 449.4128 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0557 - loss: 0.2021 - mae: 0.2014 - mse: 0.1170 - pearson_correlation: 5.2006e-16 - r2_keras: -103.3941 - rmse: 0.8891 - sae: 2605.2729 - sse: 3238.1733\n","Epoch 64: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0428 - loss: 0.1942 - mae: 0.1825 - mse: 0.1002 - pearson_correlation: 4.3588e-16 - r2_keras: -85.8418 - rmse: 0.8860 - sae: 1906.8268 - sse: 2361.0754 - val_huber_loss: 0.1013 - val_loss: 0.2477 - val_mae: 0.3033 - val_mse: 0.2134 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -31.0411 - val_rmse: 0.9218 - val_sae: 334.8675 - val_sse: 449.4767 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0557 - loss: 0.2020 - mae: 0.2013 - mse: 0.1169 - pearson_correlation: 1.6986e-16 - r2_keras: -103.4041 - rmse: 0.8892 - sae: 2605.2166 - sse: 3238.4841\n","Epoch 65: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0428 - loss: 0.1942 - mae: 0.1823 - mse: 0.1001 - pearson_correlation: 1.2953e-16 - r2_keras: -85.8508 - rmse: 0.8861 - sae: 1906.8301 - sse: 2361.3103 - val_huber_loss: 0.1013 - val_loss: 0.2476 - val_mae: 0.3036 - val_mse: 0.2133 - val_pearson_correlation: 1.0337e-16 - val_r2_keras: -31.0422 - val_rmse: 0.9218 - val_sae: 334.9792 - val_sse: 449.4920 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0556 - loss: 0.2019 - mae: 0.2011 - mse: 0.1167 - pearson_correlation: -2.8563e-16 - r2_keras: -103.4048 - rmse: 0.8892 - sae: 2605.1919 - sse: 3238.5054\n","Epoch 66: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0427 - loss: 0.1941 - mae: 0.1822 - mse: 0.0999 - pearson_correlation: -1.8871e-16 - r2_keras: -85.8493 - rmse: 0.8861 - sae: 1906.8075 - sse: 2361.3005 - val_huber_loss: 0.1014 - val_loss: 0.2477 - val_mae: 0.3039 - val_mse: 0.2135 - val_pearson_correlation: 1.2927e-17 - val_r2_keras: -31.0349 - val_rmse: 0.9217 - val_sae: 334.9489 - val_sse: 449.3884 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0555 - loss: 0.2019 - mae: 0.2010 - mse: 0.1166 - pearson_correlation: -6.0764e-16 - r2_keras: -103.3995 - rmse: 0.8892 - sae: 2605.0286 - sse: 3238.3413\n","Epoch 67: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0426 - loss: 0.1940 - mae: 0.1821 - mse: 0.0998 - pearson_correlation: -3.3827e-16 - r2_keras: -85.8597 - rmse: 0.8862 - sae: 1906.7433 - sse: 2361.3552 - val_huber_loss: 0.1014 - val_loss: 0.2477 - val_mae: 0.3037 - val_mse: 0.2135 - val_pearson_correlation: 1.6155e-16 - val_r2_keras: -31.0429 - val_rmse: 0.9218 - val_sae: 334.8827 - val_sse: 449.5012 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0554 - loss: 0.2018 - mae: 0.2008 - mse: 0.1165 - pearson_correlation: -4.6915e-16 - r2_keras: -103.4288 - rmse: 0.8893 - sae: 2605.1743 - sse: 3239.2495\n","Epoch 68: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0426 - loss: 0.1940 - mae: 0.1819 - mse: 0.0997 - pearson_correlation: -3.2990e-16 - r2_keras: -85.8811 - rmse: 0.8863 - sae: 1906.8778 - sse: 2361.9832 - val_huber_loss: 0.1014 - val_loss: 0.2477 - val_mae: 0.3040 - val_mse: 0.2135 - val_pearson_correlation: 1.0984e-16 - val_r2_keras: -31.0429 - val_rmse: 0.9218 - val_sae: 334.9770 - val_sse: 449.5014 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0554 - loss: 0.2017 - mae: 0.2007 - mse: 0.1164 - pearson_correlation: -2.2589e-16 - r2_keras: -103.4139 - rmse: 0.8892 - sae: 2605.0244 - sse: 3238.7896\n","Epoch 69: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0425 - loss: 0.1939 - mae: 0.1818 - mse: 0.0996 - pearson_correlation: -1.5145e-16 - r2_keras: -85.8793 - rmse: 0.8863 - sae: 1906.7747 - sse: 2361.7712 - val_huber_loss: 0.1014 - val_loss: 0.2477 - val_mae: 0.3038 - val_mse: 0.2135 - val_pearson_correlation: 6.4602e-17 - val_r2_keras: -31.0497 - val_rmse: 0.9219 - val_sae: 334.8965 - val_sse: 449.5969 - learning_rate: 1.0000e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0553 - loss: 0.2016 - mae: 0.2006 - mse: 0.1162 - pearson_correlation: 2.7083e-16 - r2_keras: -103.4503 - rmse: 0.8894 - sae: 2605.2603 - sse: 3239.9182\n","Epoch 70: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0425 - loss: 0.1938 - mae: 0.1816 - mse: 0.0995 - pearson_correlation: 1.4717e-16 - r2_keras: -85.9059 - rmse: 0.8864 - sae: 1906.9723 - sse: 2362.5510 - val_huber_loss: 0.1012 - val_loss: 0.2475 - val_mae: 0.3038 - val_mse: 0.2131 - val_pearson_correlation: 3.8735e-17 - val_r2_keras: -31.0577 - val_rmse: 0.9220 - val_sae: 335.0350 - val_sse: 449.7093 - learning_rate: 1.0000e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0553 - loss: 0.2016 - mae: 0.2004 - mse: 0.1161 - pearson_correlation: 2.3132e-16 - r2_keras: -103.4829 - rmse: 0.8895 - sae: 2605.7979 - sse: 3240.9302\n","Epoch 71: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0424 - loss: 0.1938 - mae: 0.1815 - mse: 0.0993 - pearson_correlation: 1.8330e-16 - r2_keras: -85.9366 - rmse: 0.8866 - sae: 1907.3221 - sse: 2363.3301 - val_huber_loss: 0.1014 - val_loss: 0.2476 - val_mae: 0.3037 - val_mse: 0.2134 - val_pearson_correlation: 7.1033e-17 - val_r2_keras: -31.0576 - val_rmse: 0.9220 - val_sae: 334.9217 - val_sse: 449.7074 - learning_rate: 1.0000e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0552 - loss: 0.2015 - mae: 0.2003 - mse: 0.1160 - pearson_correlation: 2.8650e-16 - r2_keras: -103.4782 - rmse: 0.8895 - sae: 2605.4736 - sse: 3240.7837\n","Epoch 72: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0424 - loss: 0.1937 - mae: 0.1814 - mse: 0.0992 - pearson_correlation: 2.1837e-16 - r2_keras: -85.9350 - rmse: 0.8866 - sae: 1907.1427 - sse: 2363.2505 - val_huber_loss: 0.1013 - val_loss: 0.2476 - val_mae: 0.3040 - val_mse: 0.2133 - val_pearson_correlation: -5.1653e-17 - val_r2_keras: -31.0568 - val_rmse: 0.9220 - val_sae: 335.0052 - val_sse: 449.6969 - learning_rate: 1.0000e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0551 - loss: 0.2014 - mae: 0.2001 - mse: 0.1158 - pearson_correlation: 1.2665e-17 - r2_keras: -103.4717 - rmse: 0.8895 - sae: 2605.3088 - sse: 3240.5820\n","Epoch 73: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0423 - loss: 0.1936 - mae: 0.1812 - mse: 0.0991 - pearson_correlation: -1.2932e-17 - r2_keras: -85.9381 - rmse: 0.8866 - sae: 1907.0397 - sse: 2363.2036 - val_huber_loss: 0.1014 - val_loss: 0.2477 - val_mae: 0.3038 - val_mse: 0.2135 - val_pearson_correlation: -2.5828e-17 - val_r2_keras: -31.0599 - val_rmse: 0.9220 - val_sae: 334.9209 - val_sse: 449.7401 - learning_rate: 1.0000e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0551 - loss: 0.2013 - mae: 0.2000 - mse: 0.1157 - pearson_correlation: -5.5155e-17 - r2_keras: -103.4863 - rmse: 0.8895 - sae: 2605.4146 - sse: 3241.0344\n","Epoch 74: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0423 - loss: 0.1936 - mae: 0.1811 - mse: 0.0990 - pearson_correlation: -2.9929e-17 - r2_keras: -85.9465 - rmse: 0.8867 - sae: 1907.1188 - sse: 2363.4902 - val_huber_loss: 0.1014 - val_loss: 0.2476 - val_mae: 0.3041 - val_mse: 0.2134 - val_pearson_correlation: -3.0989e-16 - val_r2_keras: -31.0604 - val_rmse: 0.9221 - val_sae: 334.9937 - val_sse: 449.7470 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0550 - loss: 0.2012 - mae: 0.1998 - mse: 0.1155 - pearson_correlation: -7.0069e-17 - r2_keras: -103.4866 - rmse: 0.8895 - sae: 2605.3242 - sse: 3241.0425\n","Epoch 75: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0422 - loss: 0.1935 - mae: 0.1809 - mse: 0.0988 - pearson_correlation: -1.2534e-17 - r2_keras: -85.9587 - rmse: 0.8868 - sae: 1907.0933 - sse: 2363.6360 - val_huber_loss: 0.1014 - val_loss: 0.2476 - val_mae: 0.3038 - val_mse: 0.2133 - val_pearson_correlation: -1.4198e-16 - val_r2_keras: -31.0688 - val_rmse: 0.9222 - val_sae: 334.9588 - val_sse: 449.8652 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0550 - loss: 0.2012 - mae: 0.1997 - mse: 0.1154 - pearson_correlation: 4.1353e-17 - r2_keras: -103.5123 - rmse: 0.8896 - sae: 2605.5454 - sse: 3241.8398\n","Epoch 76: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0422 - loss: 0.1934 - mae: 0.1808 - mse: 0.0988 - pearson_correlation: -2.3421e-18 - r2_keras: -85.9734 - rmse: 0.8868 - sae: 1907.2427 - sse: 2364.1389 - val_huber_loss: 0.1014 - val_loss: 0.2476 - val_mae: 0.3041 - val_mse: 0.2133 - val_pearson_correlation: 4.5176e-17 - val_r2_keras: -31.0669 - val_rmse: 0.9221 - val_sae: 335.0137 - val_sse: 449.8377 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0549 - loss: 0.2011 - mae: 0.1996 - mse: 0.1152 - pearson_correlation: -1.2097e-17 - r2_keras: -103.5088 - rmse: 0.8896 - sae: 2605.4165 - sse: 3241.7310\n","Epoch 77: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0421 - loss: 0.1933 - mae: 0.1807 - mse: 0.0986 - pearson_correlation: -1.4898e-17 - r2_keras: -85.9780 - rmse: 0.8869 - sae: 1907.1583 - sse: 2364.1484 - val_huber_loss: 0.1015 - val_loss: 0.2477 - val_mae: 0.3040 - val_mse: 0.2135 - val_pearson_correlation: 1.7426e-16 - val_r2_keras: -31.0718 - val_rmse: 0.9222 - val_sae: 334.9120 - val_sse: 449.9072 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0549 - loss: 0.2010 - mae: 0.1995 - mse: 0.1152 - pearson_correlation: -1.0406e-16 - r2_keras: -103.5309 - rmse: 0.8897 - sae: 2605.5713 - sse: 3242.4185\n","Epoch 78: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0421 - loss: 0.1933 - mae: 0.1806 - mse: 0.0986 - pearson_correlation: -4.9730e-17 - r2_keras: -85.9955 - rmse: 0.8870 - sae: 1907.3099 - sse: 2364.6379 - val_huber_loss: 0.1015 - val_loss: 0.2476 - val_mae: 0.3042 - val_mse: 0.2134 - val_pearson_correlation: -3.2257e-17 - val_r2_keras: -31.0749 - val_rmse: 0.9223 - val_sae: 335.0336 - val_sse: 449.9507 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0547 - loss: 0.2009 - mae: 0.1992 - mse: 0.1150 - pearson_correlation: 2.2781e-16 - r2_keras: -103.5321 - rmse: 0.8897 - sae: 2605.5881 - sse: 3242.4546\n","Epoch 79: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0420 - loss: 0.1932 - mae: 0.1803 - mse: 0.0984 - pearson_correlation: 5.6185e-17 - r2_keras: -85.9914 - rmse: 0.8869 - sae: 1907.3170 - sse: 2364.6047 - val_huber_loss: 0.1015 - val_loss: 0.2477 - val_mae: 0.3046 - val_mse: 0.2135 - val_pearson_correlation: -3.0330e-16 - val_r2_keras: -31.0686 - val_rmse: 0.9222 - val_sae: 335.0691 - val_sse: 449.8617 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0547 - loss: 0.2009 - mae: 0.1992 - mse: 0.1149 - pearson_correlation: -3.3382e-16 - r2_keras: -103.5347 - rmse: 0.8897 - sae: 2605.6514 - sse: 3242.5356\n","Epoch 80: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0420 - loss: 0.1931 - mae: 0.1803 - mse: 0.0983 - pearson_correlation: -1.9779e-16 - r2_keras: -86.0032 - rmse: 0.8870 - sae: 1907.3727 - sse: 2364.7778 - val_huber_loss: 0.1016 - val_loss: 0.2477 - val_mae: 0.3044 - val_mse: 0.2137 - val_pearson_correlation: -5.1629e-17 - val_r2_keras: -31.0740 - val_rmse: 0.9222 - val_sae: 334.9449 - val_sse: 449.9379 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0546 - loss: 0.2008 - mae: 0.1991 - mse: 0.1147 - pearson_correlation: -2.3246e-16 - r2_keras: -103.5753 - rmse: 0.8899 - sae: 2605.9644 - sse: 3243.7944\n","Epoch 81: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0419 - loss: 0.1930 - mae: 0.1802 - mse: 0.0981 - pearson_correlation: -2.4719e-16 - r2_keras: -86.0293 - rmse: 0.8871 - sae: 1907.6162 - sse: 2365.6047 - val_huber_loss: 0.1016 - val_loss: 0.2477 - val_mae: 0.3046 - val_mse: 0.2137 - val_pearson_correlation: 1.6129e-16 - val_r2_keras: -31.0766 - val_rmse: 0.9223 - val_sae: 335.0539 - val_sse: 449.9740 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0546 - loss: 0.2007 - mae: 0.1989 - mse: 0.1146 - pearson_correlation: 3.5390e-16 - r2_keras: -103.5737 - rmse: 0.8899 - sae: 2606.0171 - sse: 3243.7466\n","Epoch 82: val_loss did not improve from 0.23854\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0419 - loss: 0.1930 - mae: 0.1800 - mse: 0.0980 - pearson_correlation: 2.5129e-16 - r2_keras: -86.0374 - rmse: 0.8872 - sae: 1907.6519 - sse: 2365.6802 - val_huber_loss: 0.1016 - val_loss: 0.2478 - val_mae: 0.3044 - val_mse: 0.2138 - val_pearson_correlation: -3.4835e-16 - val_r2_keras: -31.0826 - val_rmse: 0.9224 - val_sae: 334.9669 - val_sse: 450.0588 - learning_rate: 1.0000e-05\n","| \u001b[35m15       \u001b[39m | \u001b[35m-0.2478  \u001b[39m | \u001b[35m0.002935 \u001b[39m | \u001b[35m91.02    \u001b[39m | \u001b[35m59.16    \u001b[39m | \u001b[35m73.85    \u001b[39m | \u001b[35m5.0      \u001b[39m | \u001b[35m77.38    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/step - huber_loss: 0.5345 - loss: 0.6910 - mae: 0.8987 - mse: 1.5695 - pearson_correlation: 3.0241e-16 - r2_keras: -259.9780 - rmse: 1.4058 - sae: 4286.9424 - sse: 8095.2124\n","Epoch 1: val_loss improved from inf to 0.38436, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 622ms/step - huber_loss: 0.8558 - loss: 0.8884 - mae: 1.1139 - mse: 2.2886 - pearson_correlation: 1.5228e-16 - r2_keras: -286.1885 - rmse: 1.6886 - sae: 3363.7354 - sse: 6724.6855 - val_huber_loss: 0.2149 - val_loss: 0.3844 - val_mae: 0.4546 - val_mse: 0.5729 - val_pearson_correlation: -4.8946e-17 - val_r2_keras: -25.0196 - val_rmse: 0.8307 - val_sae: 277.2886 - val_sse: 365.0051 - learning_rate: 0.0100\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2908 - loss: 0.4603 - mae: 0.6380 - mse: 0.7555 - pearson_correlation: 4.8687e-16 - r2_keras: -184.5204 - rmse: 1.1853 - sae: 3391.6665 - sse: 5754.6094\n","Epoch 2: val_loss did not improve from 0.38436\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.4202 - loss: 0.5390 - mae: 0.7271 - mse: 0.9542 - pearson_correlation: 3.1826e-16 - r2_keras: -152.9484 - rmse: 1.1787 - sae: 2508.9421 - sse: 4191.4526 - val_huber_loss: 0.2400 - val_loss: 0.4096 - val_mae: 0.5545 - val_mse: 0.6140 - val_pearson_correlation: -1.0777e-16 - val_r2_keras: -22.4658 - val_rmse: 0.7888 - val_sae: 297.6536 - val_sse: 329.1805 - learning_rate: 0.0100\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.5456 - loss: 0.7152 - mae: 0.9109 - mse: 1.2974 - pearson_correlation: -1.1070e-16 - r2_keras: -181.4571 - rmse: 1.1755 - sae: 3688.3809 - sse: 5659.5908\n","Epoch 3: val_loss did not improve from 0.38436\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.5283 - loss: 0.7047 - mae: 0.8965 - mse: 1.2913 - pearson_correlation: -8.6975e-17 - r2_keras: -164.6586 - rmse: 1.2522 - sae: 2731.2756 - sse: 4289.4229 - val_huber_loss: 0.3047 - val_loss: 0.4745 - val_mae: 0.6852 - val_mse: 0.7561 - val_pearson_correlation: 2.7936e-16 - val_r2_keras: -22.6636 - val_rmse: 0.7922 - val_sae: 328.8716 - val_sse: 331.9551 - learning_rate: 0.0100\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.5821 - loss: 0.7518 - mae: 1.0235 - mse: 1.4096 - pearson_correlation: -5.1120e-17 - r2_keras: -137.6372 - rmse: 1.0246 - sae: 3500.6555 - sse: 4300.3525\n","Epoch 4: val_loss did not improve from 0.38436\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.5166 - loss: 0.7119 - mae: 0.9685 - mse: 1.2968 - pearson_correlation: -3.4080e-17 - r2_keras: -123.0321 - rmse: 1.0801 - sae: 2586.6631 - sse: 3237.6567 - val_huber_loss: 0.2697 - val_loss: 0.4384 - val_mae: 0.6255 - val_mse: 0.6978 - val_pearson_correlation: -2.0256e-16 - val_r2_keras: -22.5449 - val_rmse: 0.7902 - val_sae: 319.5803 - val_sse: 330.2910 - learning_rate: 0.0100\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2499 - loss: 0.4186 - mae: 0.5809 - mse: 0.5864 - pearson_correlation: -1.1188e-16 - r2_keras: -80.4276 - rmse: 0.7853 - sae: 2495.4807 - sse: 2525.7815\n","Epoch 5: val_loss improved from 0.38436 to 0.38249, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.2192 - loss: 0.3998 - mae: 0.5443 - mse: 0.5354 - pearson_correlation: -2.0031e-16 - r2_keras: -67.5276 - rmse: 0.7900 - sae: 1822.1947 - sse: 1850.9199 - val_huber_loss: 0.2150 - val_loss: 0.3825 - val_mae: 0.5142 - val_mse: 0.5597 - val_pearson_correlation: 1.5506e-16 - val_r2_keras: -23.1425 - val_rmse: 0.8001 - val_sae: 301.3991 - val_sse: 338.6734 - learning_rate: 0.0100\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1996 - loss: 0.3670 - mae: 0.4958 - mse: 0.4531 - pearson_correlation: -1.4442e-16 - r2_keras: -103.8853 - rmse: 0.8912 - sae: 2575.8345 - sse: 3253.4106\n","Epoch 6: val_loss improved from 0.38249 to 0.38247, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1975 - loss: 0.3656 - mae: 0.4910 - mse: 0.4434 - pearson_correlation: -4.6316e-17 - r2_keras: -82.1415 - rmse: 0.8509 - sae: 1866.8800 - sse: 2323.9883 - val_huber_loss: 0.2163 - val_loss: 0.3825 - val_mae: 0.5033 - val_mse: 0.5540 - val_pearson_correlation: -1.1315e-17 - val_r2_keras: -24.8899 - val_rmse: 0.8286 - val_sae: 314.9892 - val_sse: 363.1862 - learning_rate: 0.0100\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2373 - loss: 0.4035 - mae: 0.5361 - mse: 0.5318 - pearson_correlation: 7.6852e-16 - r2_keras: -116.6038 - rmse: 0.9437 - sae: 2788.1272 - sse: 3647.9224\n","Epoch 7: val_loss improved from 0.38247 to 0.33521, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.2222 - loss: 0.3941 - mae: 0.5207 - mse: 0.5055 - pearson_correlation: 4.9301e-16 - r2_keras: -91.1246 - rmse: 0.8907 - sae: 2012.4523 - sse: 2592.9082 - val_huber_loss: 0.1702 - val_loss: 0.3352 - val_mae: 0.4286 - val_mse: 0.3892 - val_pearson_correlation: 2.1212e-16 - val_r2_keras: -26.6215 - val_rmse: 0.8558 - val_sae: 327.4031 - val_sse: 387.4776 - learning_rate: 0.0100\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2163 - loss: 0.3813 - mae: 0.5062 - mse: 0.4750 - pearson_correlation: 9.6012e-17 - r2_keras: -119.7101 - rmse: 0.9561 - sae: 2880.8872 - sse: 3744.2749\n","Epoch 8: val_loss did not improve from 0.33521\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.2078 - loss: 0.3760 - mae: 0.4984 - mse: 0.4588 - pearson_correlation: 1.7023e-16 - r2_keras: -94.6134 - rmse: 0.9122 - sae: 2087.6663 - sse: 2673.7759 - val_huber_loss: 0.1955 - val_loss: 0.3591 - val_mae: 0.4605 - val_mse: 0.4711 - val_pearson_correlation: 6.6860e-16 - val_r2_keras: -26.6803 - val_rmse: 0.8568 - val_sae: 327.1015 - val_sse: 388.3022 - learning_rate: 0.0100\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1830 - loss: 0.3466 - mae: 0.4431 - mse: 0.4087 - pearson_correlation: -2.2004e-16 - r2_keras: -101.4239 - rmse: 0.8807 - sae: 2609.9402 - sse: 3177.0603\n","Epoch 9: val_loss improved from 0.33521 to 0.27181, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1573 - loss: 0.3308 - mae: 0.4205 - mse: 0.3708 - pearson_correlation: -1.8611e-16 - r2_keras: -79.3132 - rmse: 0.8321 - sae: 1884.6962 - sse: 2259.1599 - val_huber_loss: 0.1098 - val_loss: 0.2718 - val_mae: 0.3205 - val_mse: 0.2376 - val_pearson_correlation: -1.1353e-16 - val_r2_keras: -33.2091 - val_rmse: 0.9525 - val_sae: 361.8761 - val_sse: 479.8889 - learning_rate: 0.0100\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1387 - loss: 0.3007 - mae: 0.3862 - mse: 0.3082 - pearson_correlation: -1.4745e-17 - r2_keras: -119.8645 - rmse: 0.9567 - sae: 2937.6670 - sse: 3749.0662\n","Epoch 10: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1510 - loss: 0.3080 - mae: 0.4097 - mse: 0.3194 - pearson_correlation: 8.2044e-18 - r2_keras: -95.0518 - rmse: 0.9156 - sae: 2132.4956 - sse: 2680.9048 - val_huber_loss: 0.1908 - val_loss: 0.3511 - val_mae: 0.5148 - val_mse: 0.3985 - val_pearson_correlation: -2.7120e-16 - val_r2_keras: -39.8403 - val_rmse: 1.0407 - val_sae: 442.4234 - val_sse: 572.9120 - learning_rate: 0.0100\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.2027 - loss: 0.3630 - mae: 0.5428 - mse: 0.4419 - pearson_correlation: 1.2158e-16 - r2_keras: -126.4555 - rmse: 0.9825 - sae: 3242.7026 - sse: 3953.5098\n","Epoch 11: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1861 - loss: 0.3527 - mae: 0.5253 - mse: 0.4147 - pearson_correlation: 7.9905e-18 - r2_keras: -104.3995 - rmse: 0.9742 - sae: 2355.1311 - sse: 2875.3079 - val_huber_loss: 0.2073 - val_loss: 0.3657 - val_mae: 0.5258 - val_mse: 0.5028 - val_pearson_correlation: -3.8022e-17 - val_r2_keras: -26.0788 - val_rmse: 0.8474 - val_sae: 337.4777 - val_sse: 379.8639 - learning_rate: 0.0100\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1856 - loss: 0.3440 - mae: 0.4998 - mse: 0.4131 - pearson_correlation: -3.3331e-16 - r2_keras: -68.7595 - rmse: 0.7268 - sae: 2337.2090 - sse: 2163.8523\n","Epoch 12: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1856 - loss: 0.3438 - mae: 0.4935 - mse: 0.4059 - pearson_correlation: -2.0395e-16 - r2_keras: -72.9594 - rmse: 0.8546 - sae: 1777.5309 - sse: 1764.5934 - val_huber_loss: 0.2807 - val_loss: 0.4371 - val_mae: 0.6299 - val_mse: 0.7088 - val_pearson_correlation: 5.3349e-17 - val_r2_keras: -25.5599 - val_rmse: 0.8392 - val_sae: 349.1569 - val_sse: 372.5858 - learning_rate: 0.0100\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2243 - loss: 0.3807 - mae: 0.5648 - mse: 0.5044 - pearson_correlation: -2.5762e-16 - r2_keras: -70.6757 - rmse: 0.7367 - sae: 2378.0229 - sse: 2223.2905\n","Epoch 13: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1940 - loss: 0.3621 - mae: 0.5349 - mse: 0.4568 - pearson_correlation: -2.4214e-16 - r2_keras: -68.3266 - rmse: 0.8189 - sae: 1787.0663 - sse: 1734.8920 - val_huber_loss: 0.2004 - val_loss: 0.3548 - val_mae: 0.5207 - val_mse: 0.4679 - val_pearson_correlation: -2.3715e-16 - val_r2_keras: -28.6002 - val_rmse: 0.8860 - val_sae: 355.1923 - val_sse: 415.2343 - learning_rate: 0.0100\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1647 - loss: 0.3191 - mae: 0.4826 - mse: 0.3555 - pearson_correlation: -5.0302e-16 - r2_keras: -85.4154 - rmse: 0.8090 - sae: 2619.2358 - sse: 2680.4980\n","Epoch 14: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.1583 - loss: 0.3150 - mae: 0.4671 - mse: 0.3426 - pearson_correlation: -3.2360e-16 - r2_keras: -75.5492 - rmse: 0.8466 - sae: 1933.6719 - sse: 2009.1528 - val_huber_loss: 0.2268 - val_loss: 0.3790 - val_mae: 0.5388 - val_mse: 0.4999 - val_pearson_correlation: 1.6268e-16 - val_r2_keras: -36.0796 - val_rmse: 0.9916 - val_sae: 400.9515 - val_sse: 520.1562 - learning_rate: 0.0100\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1689 - loss: 0.3211 - mae: 0.4412 - mse: 0.3693 - pearson_correlation: -3.7422e-16 - r2_keras: -105.7065 - rmse: 0.8989 - sae: 2794.2700 - sse: 3309.9016\n","Epoch 15: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1538 - loss: 0.3119 - mae: 0.4364 - mse: 0.3446 - pearson_correlation: -2.1356e-16 - r2_keras: -85.1517 - rmse: 0.8729 - sae: 2033.8705 - sse: 2382.7166 - val_huber_loss: 0.1566 - val_loss: 0.3083 - val_mae: 0.3952 - val_mse: 0.3478 - val_pearson_correlation: 1.6512e-16 - val_r2_keras: -33.8988 - val_rmse: 0.9620 - val_sae: 362.7425 - val_sse: 489.5639 - learning_rate: 0.0020\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1179 - loss: 0.2696 - mae: 0.3326 - mse: 0.2710 - pearson_correlation: -5.9968e-17 - r2_keras: -96.6132 - rmse: 0.8598 - sae: 2520.1277 - sse: 3027.8384\n","Epoch 16: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1067 - loss: 0.2627 - mae: 0.3310 - mse: 0.2503 - pearson_correlation: -3.0823e-17 - r2_keras: -77.8627 - rmse: 0.8354 - sae: 1836.8208 - sse: 2180.2837 - val_huber_loss: 0.1403 - val_loss: 0.2915 - val_mae: 0.3618 - val_mse: 0.3106 - val_pearson_correlation: 2.3697e-16 - val_r2_keras: -34.4206 - val_rmse: 0.9692 - val_sae: 363.6397 - val_sse: 496.8839 - learning_rate: 0.0020\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1087 - loss: 0.2598 - mae: 0.3041 - mse: 0.2513 - pearson_correlation: 1.6629e-16 - r2_keras: -98.3425 - rmse: 0.8674 - sae: 2533.5496 - sse: 3081.4805\n","Epoch 17: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0976 - loss: 0.2530 - mae: 0.3036 - mse: 0.2309 - pearson_correlation: 1.2666e-16 - r2_keras: -79.1523 - rmse: 0.8418 - sae: 1844.9081 - sse: 2217.6489 - val_huber_loss: 0.1369 - val_loss: 0.2874 - val_mae: 0.3527 - val_mse: 0.3028 - val_pearson_correlation: 8.4237e-17 - val_r2_keras: -35.0309 - val_rmse: 0.9775 - val_sae: 366.7774 - val_sse: 505.4459 - learning_rate: 0.0020\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1049 - loss: 0.2554 - mae: 0.2934 - mse: 0.2408 - pearson_correlation: 2.4314e-16 - r2_keras: -99.2826 - rmse: 0.8715 - sae: 2553.8716 - sse: 3110.6423\n","Epoch 18: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0930 - loss: 0.2481 - mae: 0.2907 - mse: 0.2201 - pearson_correlation: 2.3626e-16 - r2_keras: -80.1077 - rmse: 0.8476 - sae: 1859.7136 - sse: 2240.9451 - val_huber_loss: 0.1345 - val_loss: 0.2844 - val_mae: 0.3490 - val_mse: 0.2973 - val_pearson_correlation: 2.1602e-16 - val_r2_keras: -35.6509 - val_rmse: 0.9859 - val_sae: 370.2849 - val_sse: 514.1425 - learning_rate: 0.0020\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1022 - loss: 0.2520 - mae: 0.2897 - mse: 0.2316 - pearson_correlation: 5.1114e-16 - r2_keras: -99.9685 - rmse: 0.8744 - sae: 2569.8604 - sse: 3131.9175\n","Epoch 19: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0901 - loss: 0.2446 - mae: 0.2858 - mse: 0.2114 - pearson_correlation: 3.0541e-16 - r2_keras: -80.7477 - rmse: 0.8513 - sae: 1871.2281 - sse: 2257.2725 - val_huber_loss: 0.1389 - val_loss: 0.2879 - val_mae: 0.3538 - val_mse: 0.3076 - val_pearson_correlation: -6.1937e-17 - val_r2_keras: -35.5636 - val_rmse: 0.9847 - val_sae: 370.0232 - val_sse: 512.9180 - learning_rate: 0.0020\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0993 - loss: 0.2484 - mae: 0.2824 - mse: 0.2230 - pearson_correlation: -1.4780e-16 - r2_keras: -99.3852 - rmse: 0.8719 - sae: 2574.2766 - sse: 3113.8232\n","Epoch 20: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0866 - loss: 0.2407 - mae: 0.2767 - mse: 0.2027 - pearson_correlation: -4.4664e-17 - r2_keras: -81.1161 - rmse: 0.8565 - sae: 1878.0553 - sse: 2254.0918 - val_huber_loss: 0.1396 - val_loss: 0.2885 - val_mae: 0.3534 - val_mse: 0.3088 - val_pearson_correlation: -7.2356e-17 - val_r2_keras: -35.5021 - val_rmse: 0.9839 - val_sae: 370.1129 - val_sse: 512.0550 - learning_rate: 4.0000e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0984 - loss: 0.2473 - mae: 0.2811 - mse: 0.2206 - pearson_correlation: -2.3927e-16 - r2_keras: -98.8231 - rmse: 0.8695 - sae: 2569.5081 - sse: 3096.3862\n","Epoch 21: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0859 - loss: 0.2397 - mae: 0.2754 - mse: 0.2005 - pearson_correlation: -2.0969e-16 - r2_keras: -80.6738 - rmse: 0.8543 - sae: 1874.6053 - sse: 2241.6758 - val_huber_loss: 0.1399 - val_loss: 0.2886 - val_mae: 0.3531 - val_mse: 0.3092 - val_pearson_correlation: 2.7855e-16 - val_r2_keras: -35.5427 - val_rmse: 0.9844 - val_sae: 370.5348 - val_sse: 512.6256 - learning_rate: 4.0000e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0976 - loss: 0.2464 - mae: 0.2799 - mse: 0.2183 - pearson_correlation: 3.1137e-16 - r2_keras: -98.4735 - rmse: 0.8679 - sae: 2566.2898 - sse: 3085.5425\n","Epoch 22: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0852 - loss: 0.2388 - mae: 0.2743 - mse: 0.1986 - pearson_correlation: 2.0557e-16 - r2_keras: -80.4053 - rmse: 0.8529 - sae: 1872.3395 - sse: 2234.0308 - val_huber_loss: 0.1403 - val_loss: 0.2889 - val_mae: 0.3528 - val_mse: 0.3102 - val_pearson_correlation: -8.2448e-17 - val_r2_keras: -35.5664 - val_rmse: 0.9847 - val_sae: 370.7934 - val_sse: 512.9573 - learning_rate: 4.0000e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0968 - loss: 0.2454 - mae: 0.2785 - mse: 0.2161 - pearson_correlation: -8.6812e-17 - r2_keras: -98.2665 - rmse: 0.8670 - sae: 2564.6968 - sse: 3079.1230\n","Epoch 23: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0845 - loss: 0.2379 - mae: 0.2729 - mse: 0.1966 - pearson_correlation: -2.5614e-17 - r2_keras: -80.2508 - rmse: 0.8522 - sae: 1871.2286 - sse: 2229.5569 - val_huber_loss: 0.1405 - val_loss: 0.2889 - val_mae: 0.3518 - val_mse: 0.3112 - val_pearson_correlation: 2.4631e-16 - val_r2_keras: -35.6784 - val_rmse: 0.9862 - val_sae: 371.4515 - val_sse: 514.5289 - learning_rate: 4.0000e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0960 - loss: 0.2444 - mae: 0.2773 - mse: 0.2139 - pearson_correlation: -8.1506e-17 - r2_keras: -98.1615 - rmse: 0.8666 - sae: 2563.5750 - sse: 3075.8672\n","Epoch 24: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0839 - loss: 0.2369 - mae: 0.2718 - mse: 0.1947 - pearson_correlation: -6.4412e-17 - r2_keras: -80.1899 - rmse: 0.8520 - sae: 1870.5935 - sse: 2227.4929 - val_huber_loss: 0.1410 - val_loss: 0.2891 - val_mae: 0.3516 - val_mse: 0.3123 - val_pearson_correlation: 1.0257e-17 - val_r2_keras: -35.6936 - val_rmse: 0.9864 - val_sae: 371.5695 - val_sse: 514.7417 - learning_rate: 4.0000e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0948 - loss: 0.2429 - mae: 0.2749 - mse: 0.2106 - pearson_correlation: 7.8558e-18 - r2_keras: -98.0973 - rmse: 0.8663 - sae: 2563.2104 - sse: 3073.8757\n","Epoch 25: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0828 - loss: 0.2356 - mae: 0.2694 - mse: 0.1917 - pearson_correlation: 7.2292e-18 - r2_keras: -80.2757 - rmse: 0.8530 - sae: 1870.9827 - sse: 2227.6743 - val_huber_loss: 0.1415 - val_loss: 0.2895 - val_mae: 0.3519 - val_mse: 0.3132 - val_pearson_correlation: 2.6535e-16 - val_r2_keras: -35.8308 - val_rmse: 0.9883 - val_sae: 372.4019 - val_sse: 516.6667 - learning_rate: 8.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0945 - loss: 0.2426 - mae: 0.2743 - mse: 0.2098 - pearson_correlation: -3.1435e-17 - r2_keras: -98.0718 - rmse: 0.8662 - sae: 2562.8567 - sse: 3073.0837\n","Epoch 26: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0826 - loss: 0.2353 - mae: 0.2689 - mse: 0.1911 - pearson_correlation: -6.2787e-17 - r2_keras: -80.2593 - rmse: 0.8529 - sae: 1870.7616 - sse: 2227.1533 - val_huber_loss: 0.1418 - val_loss: 0.2898 - val_mae: 0.3521 - val_mse: 0.3138 - val_pearson_correlation: -5.0891e-17 - val_r2_keras: -35.9063 - val_rmse: 0.9893 - val_sae: 372.8539 - val_sse: 517.7261 - learning_rate: 8.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0942 - loss: 0.2422 - mae: 0.2737 - mse: 0.2090 - pearson_correlation: -1.9290e-16 - r2_keras: -98.0490 - rmse: 0.8661 - sae: 2562.6001 - sse: 3072.3765\n","Epoch 27: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0823 - loss: 0.2350 - mae: 0.2684 - mse: 0.1904 - pearson_correlation: -1.2860e-16 - r2_keras: -80.2422 - rmse: 0.8528 - sae: 1870.5948 - sse: 2226.6592 - val_huber_loss: 0.1421 - val_loss: 0.2900 - val_mae: 0.3520 - val_mse: 0.3144 - val_pearson_correlation: -1.6247e-16 - val_r2_keras: -35.9727 - val_rmse: 0.9902 - val_sae: 373.2469 - val_sse: 518.6575 - learning_rate: 8.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0939 - loss: 0.2419 - mae: 0.2732 - mse: 0.2083 - pearson_correlation: 1.5424e-16 - r2_keras: -98.0298 - rmse: 0.8660 - sae: 2562.3589 - sse: 3071.7793\n","Epoch 28: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0821 - loss: 0.2347 - mae: 0.2679 - mse: 0.1897 - pearson_correlation: 1.1478e-16 - r2_keras: -80.2293 - rmse: 0.8527 - sae: 1870.4430 - sse: 2226.2603 - val_huber_loss: 0.1422 - val_loss: 0.2901 - val_mae: 0.3519 - val_mse: 0.3148 - val_pearson_correlation: 2.1289e-16 - val_r2_keras: -36.0190 - val_rmse: 0.9908 - val_sae: 373.5010 - val_sse: 519.3065 - learning_rate: 8.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0936 - loss: 0.2415 - mae: 0.2727 - mse: 0.2075 - pearson_correlation: 1.0648e-16 - r2_keras: -98.0143 - rmse: 0.8659 - sae: 2562.1660 - sse: 3071.2998\n","Epoch 29: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0819 - loss: 0.2344 - mae: 0.2675 - mse: 0.1891 - pearson_correlation: 1.0088e-16 - r2_keras: -80.2163 - rmse: 0.8527 - sae: 1870.3099 - sse: 2225.9089 - val_huber_loss: 0.1424 - val_loss: 0.2903 - val_mae: 0.3519 - val_mse: 0.3152 - val_pearson_correlation: -1.6224e-16 - val_r2_keras: -36.0130 - val_rmse: 0.9907 - val_sae: 373.4567 - val_sse: 519.2226 - learning_rate: 8.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0933 - loss: 0.2411 - mae: 0.2720 - mse: 0.2066 - pearson_correlation: -4.8413e-18 - r2_keras: -97.9954 - rmse: 0.8658 - sae: 2562.1172 - sse: 3070.7134\n","Epoch 30: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0816 - loss: 0.2340 - mae: 0.2669 - mse: 0.1883 - pearson_correlation: -3.5027e-17 - r2_keras: -80.2346 - rmse: 0.8529 - sae: 1870.4296 - sse: 2225.8801 - val_huber_loss: 0.1426 - val_loss: 0.2904 - val_mae: 0.3520 - val_mse: 0.3155 - val_pearson_correlation: 2.4292e-16 - val_r2_keras: -36.0634 - val_rmse: 0.9914 - val_sae: 373.7517 - val_sse: 519.9301 - learning_rate: 1.6000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0933 - loss: 0.2411 - mae: 0.2719 - mse: 0.2064 - pearson_correlation: 1.8761e-17 - r2_keras: -97.9913 - rmse: 0.8658 - sae: 2562.0696 - sse: 3070.5864\n","Epoch 31: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0816 - loss: 0.2339 - mae: 0.2668 - mse: 0.1882 - pearson_correlation: -1.5317e-17 - r2_keras: -80.2318 - rmse: 0.8529 - sae: 1870.3990 - sse: 2225.7947 - val_huber_loss: 0.1427 - val_loss: 0.2905 - val_mae: 0.3520 - val_mse: 0.3157 - val_pearson_correlation: 4.0441e-17 - val_r2_keras: -36.0962 - val_rmse: 0.9918 - val_sae: 373.9406 - val_sse: 520.3901 - learning_rate: 1.6000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0932 - loss: 0.2410 - mae: 0.2718 - mse: 0.2062 - pearson_correlation: 2.2394e-17 - r2_keras: -97.9876 - rmse: 0.8658 - sae: 2562.0293 - sse: 3070.4724\n","Epoch 32: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0815 - loss: 0.2339 - mae: 0.2667 - mse: 0.1880 - pearson_correlation: 1.4929e-17 - r2_keras: -80.2293 - rmse: 0.8529 - sae: 1870.3739 - sse: 2225.7183 - val_huber_loss: 0.1427 - val_loss: 0.2905 - val_mae: 0.3519 - val_mse: 0.3158 - val_pearson_correlation: -1.0102e-17 - val_r2_keras: -36.1183 - val_rmse: 0.9921 - val_sae: 374.0633 - val_sse: 520.6997 - learning_rate: 1.6000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0931 - loss: 0.2409 - mae: 0.2717 - mse: 0.2061 - pearson_correlation: 1.4950e-16 - r2_keras: -97.9838 - rmse: 0.8658 - sae: 2561.9888 - sse: 3070.3540\n","Epoch 33: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0815 - loss: 0.2338 - mae: 0.2665 - mse: 0.1878 - pearson_correlation: 1.8513e-16 - r2_keras: -80.2267 - rmse: 0.8529 - sae: 1870.3488 - sse: 2225.6392 - val_huber_loss: 0.1428 - val_loss: 0.2905 - val_mae: 0.3519 - val_mse: 0.3159 - val_pearson_correlation: 3.3320e-16 - val_r2_keras: -36.1339 - val_rmse: 0.9923 - val_sae: 374.1447 - val_sse: 520.9184 - learning_rate: 1.6000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0930 - loss: 0.2408 - mae: 0.2715 - mse: 0.2059 - pearson_correlation: -5.2963e-16 - r2_keras: -97.9804 - rmse: 0.8658 - sae: 2561.9517 - sse: 3070.2468\n","Epoch 34: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0814 - loss: 0.2337 - mae: 0.2664 - mse: 0.1877 - pearson_correlation: -3.6302e-16 - r2_keras: -80.2245 - rmse: 0.8529 - sae: 1870.3264 - sse: 2225.5686 - val_huber_loss: 0.1428 - val_loss: 0.2905 - val_mae: 0.3519 - val_mse: 0.3160 - val_pearson_correlation: 1.0095e-16 - val_r2_keras: -36.1386 - val_rmse: 0.9924 - val_sae: 374.1646 - val_sse: 520.9841 - learning_rate: 1.6000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0930 - loss: 0.2407 - mae: 0.2714 - mse: 0.2056 - pearson_correlation: -2.5060e-16 - r2_keras: -97.9765 - rmse: 0.8658 - sae: 2561.9392 - sse: 3070.1270\n","Epoch 35: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0813 - loss: 0.2336 - mae: 0.2663 - mse: 0.1875 - pearson_correlation: -1.0349e-16 - r2_keras: -80.2252 - rmse: 0.8529 - sae: 1870.3357 - sse: 2225.5278 - val_huber_loss: 0.1428 - val_loss: 0.2906 - val_mae: 0.3518 - val_mse: 0.3161 - val_pearson_correlation: -1.8164e-16 - val_r2_keras: -36.1501 - val_rmse: 0.9925 - val_sae: 374.2251 - val_sse: 521.1451 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0929 - loss: 0.2407 - mae: 0.2713 - mse: 0.2055 - pearson_correlation: -7.4034e-16 - r2_keras: -97.9743 - rmse: 0.8658 - sae: 2561.9185 - sse: 3070.0596\n","Epoch 36: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0813 - loss: 0.2336 - mae: 0.2662 - mse: 0.1874 - pearson_correlation: -5.4124e-16 - r2_keras: -80.2238 - rmse: 0.8529 - sae: 1870.3234 - sse: 2225.4832 - val_huber_loss: 0.1429 - val_loss: 0.2906 - val_mae: 0.3518 - val_mse: 0.3162 - val_pearson_correlation: 6.0540e-17 - val_r2_keras: -36.1538 - val_rmse: 0.9926 - val_sae: 374.2418 - val_sse: 521.1969 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0929 - loss: 0.2406 - mae: 0.2712 - mse: 0.2054 - pearson_correlation: -2.8755e-16 - r2_keras: -97.9724 - rmse: 0.8657 - sae: 2561.9199 - sse: 3070.0002\n","Epoch 37: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0812 - loss: 0.2335 - mae: 0.2661 - mse: 0.1872 - pearson_correlation: -2.2349e-16 - r2_keras: -80.2221 - rmse: 0.8529 - sae: 1870.3241 - sse: 2225.4382 - val_huber_loss: 0.1429 - val_loss: 0.2906 - val_mae: 0.3518 - val_mse: 0.3162 - val_pearson_correlation: 1.6140e-16 - val_r2_keras: -36.1606 - val_rmse: 0.9927 - val_sae: 374.2741 - val_sse: 521.2929 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0928 - loss: 0.2405 - mae: 0.2711 - mse: 0.2052 - pearson_correlation: 3.2872e-16 - r2_keras: -97.9702 - rmse: 0.8657 - sae: 2561.9019 - sse: 3069.9307\n","Epoch 38: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0812 - loss: 0.2335 - mae: 0.2660 - mse: 0.1871 - pearson_correlation: 2.4100e-16 - r2_keras: -80.2206 - rmse: 0.8529 - sae: 1870.3136 - sse: 2225.3926 - val_huber_loss: 0.1429 - val_loss: 0.2906 - val_mae: 0.3517 - val_mse: 0.3163 - val_pearson_correlation: 3.2280e-16 - val_r2_keras: -36.1611 - val_rmse: 0.9927 - val_sae: 374.2714 - val_sse: 521.3002 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0928 - loss: 0.2405 - mae: 0.2710 - mse: 0.2051 - pearson_correlation: -1.8162e-18 - r2_keras: -97.9682 - rmse: 0.8657 - sae: 2561.9072 - sse: 3069.8708\n","Epoch 39: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0812 - loss: 0.2334 - mae: 0.2659 - mse: 0.1870 - pearson_correlation: 5.2439e-17 - r2_keras: -80.2190 - rmse: 0.8528 - sae: 1870.3174 - sse: 2225.3481 - val_huber_loss: 0.1429 - val_loss: 0.2906 - val_mae: 0.3517 - val_mse: 0.3164 - val_pearson_correlation: 8.0686e-17 - val_r2_keras: -36.1660 - val_rmse: 0.9928 - val_sae: 374.2921 - val_sse: 521.3680 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0927 - loss: 0.2404 - mae: 0.2709 - mse: 0.2049 - pearson_correlation: -2.8515e-16 - r2_keras: -97.9662 - rmse: 0.8657 - sae: 2561.8936 - sse: 3069.8071\n","Epoch 40: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0811 - loss: 0.2333 - mae: 0.2658 - mse: 0.1868 - pearson_correlation: -2.1196e-16 - r2_keras: -80.2177 - rmse: 0.8528 - sae: 1870.3104 - sse: 2225.3074 - val_huber_loss: 0.1429 - val_loss: 0.2906 - val_mae: 0.3517 - val_mse: 0.3164 - val_pearson_correlation: 2.5216e-16 - val_r2_keras: -36.1644 - val_rmse: 0.9927 - val_sae: 374.2782 - val_sse: 521.3469 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0926 - loss: 0.2403 - mae: 0.2708 - mse: 0.2048 - pearson_correlation: 1.8163e-18 - r2_keras: -97.9642 - rmse: 0.8657 - sae: 2561.9023 - sse: 3069.7471\n","Epoch 41: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0811 - loss: 0.2333 - mae: 0.2657 - mse: 0.1867 - pearson_correlation: 7.2746e-17 - r2_keras: -80.2161 - rmse: 0.8528 - sae: 1870.3165 - sse: 2225.2627 - val_huber_loss: 0.1430 - val_loss: 0.2906 - val_mae: 0.3516 - val_mse: 0.3165 - val_pearson_correlation: 2.2187e-16 - val_r2_keras: -36.1684 - val_rmse: 0.9928 - val_sae: 374.2940 - val_sse: 521.4026 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0926 - loss: 0.2402 - mae: 0.2707 - mse: 0.2046 - pearson_correlation: -7.9980e-16 - r2_keras: -97.9621 - rmse: 0.8657 - sae: 2561.8892 - sse: 3069.6790\n","Epoch 42: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0810 - loss: 0.2332 - mae: 0.2656 - mse: 0.1866 - pearson_correlation: -5.3320e-16 - r2_keras: -80.2141 - rmse: 0.8528 - sae: 1870.3066 - sse: 2225.2114 - val_huber_loss: 0.1430 - val_loss: 0.2906 - val_mae: 0.3516 - val_mse: 0.3165 - val_pearson_correlation: -1.1093e-16 - val_r2_keras: -36.1694 - val_rmse: 0.9928 - val_sae: 374.2926 - val_sse: 521.4164 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0925 - loss: 0.2402 - mae: 0.2706 - mse: 0.2044 - pearson_correlation: -3.7843e-16 - r2_keras: -97.9574 - rmse: 0.8657 - sae: 2561.8494 - sse: 3069.5342\n","Epoch 43: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0810 - loss: 0.2331 - mae: 0.2656 - mse: 0.1864 - pearson_correlation: -2.8011e-16 - r2_keras: -80.2114 - rmse: 0.8528 - sae: 1870.2841 - sse: 2225.1199 - val_huber_loss: 0.1430 - val_loss: 0.2906 - val_mae: 0.3516 - val_mse: 0.3166 - val_pearson_correlation: 8.0689e-17 - val_r2_keras: -36.1646 - val_rmse: 0.9927 - val_sae: 374.2612 - val_sse: 521.3489 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0925 - loss: 0.2401 - mae: 0.2705 - mse: 0.2043 - pearson_correlation: 2.7126e-16 - r2_keras: -97.9563 - rmse: 0.8657 - sae: 2561.8896 - sse: 3069.5012\n","Epoch 44: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0809 - loss: 0.2331 - mae: 0.2654 - mse: 0.1863 - pearson_correlation: 1.7289e-16 - r2_keras: -80.2101 - rmse: 0.8528 - sae: 1870.3102 - sse: 2225.0906 - val_huber_loss: 0.1430 - val_loss: 0.2906 - val_mae: 0.3515 - val_mse: 0.3166 - val_pearson_correlation: -3.4288e-16 - val_r2_keras: -36.1686 - val_rmse: 0.9928 - val_sae: 374.2770 - val_sse: 521.4056 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0924 - loss: 0.2400 - mae: 0.2704 - mse: 0.2041 - pearson_correlation: 6.6606e-17 - r2_keras: -97.9549 - rmse: 0.8657 - sae: 2561.8872 - sse: 3069.4570\n","Epoch 45: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0809 - loss: 0.2330 - mae: 0.2653 - mse: 0.1861 - pearson_correlation: 1.6582e-17 - r2_keras: -80.2087 - rmse: 0.8528 - sae: 1870.3079 - sse: 2225.0562 - val_huber_loss: 0.1430 - val_loss: 0.2906 - val_mae: 0.3515 - val_mse: 0.3167 - val_pearson_correlation: -5.0424e-16 - val_r2_keras: -36.1686 - val_rmse: 0.9928 - val_sae: 374.2711 - val_sse: 521.4050 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0923 - loss: 0.2399 - mae: 0.2703 - mse: 0.2039 - pearson_correlation: 1.0536e-16 - r2_keras: -97.9506 - rmse: 0.8656 - sae: 2561.8623 - sse: 3069.3242\n","Epoch 46: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0808 - loss: 0.2329 - mae: 0.2653 - mse: 0.1860 - pearson_correlation: 3.2486e-17 - r2_keras: -80.2063 - rmse: 0.8528 - sae: 1870.2953 - sse: 2224.9724 - val_huber_loss: 0.1430 - val_loss: 0.2906 - val_mae: 0.3515 - val_mse: 0.3167 - val_pearson_correlation: -2.2189e-16 - val_r2_keras: -36.1651 - val_rmse: 0.9927 - val_sae: 374.2461 - val_sse: 521.3560 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0923 - loss: 0.2399 - mae: 0.2701 - mse: 0.2037 - pearson_correlation: -5.1895e-16 - r2_keras: -97.9514 - rmse: 0.8657 - sae: 2561.9189 - sse: 3069.3496\n","Epoch 47: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0808 - loss: 0.2329 - mae: 0.2651 - mse: 0.1858 - pearson_correlation: -3.7180e-16 - r2_keras: -80.2066 - rmse: 0.8528 - sae: 1870.3346 - sse: 2224.9868 - val_huber_loss: 0.1431 - val_loss: 0.2906 - val_mae: 0.3514 - val_mse: 0.3168 - val_pearson_correlation: -2.3194e-16 - val_r2_keras: -36.1695 - val_rmse: 0.9928 - val_sae: 374.2639 - val_sse: 521.4175 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0922 - loss: 0.2398 - mae: 0.2700 - mse: 0.2036 - pearson_correlation: -3.7543e-17 - r2_keras: -97.9515 - rmse: 0.8657 - sae: 2561.9341 - sse: 3069.3521\n","Epoch 48: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0807 - loss: 0.2328 - mae: 0.2650 - mse: 0.1857 - pearson_correlation: -1.5092e-17 - r2_keras: -80.2064 - rmse: 0.8528 - sae: 1870.3445 - sse: 2224.9858 - val_huber_loss: 0.1431 - val_loss: 0.2906 - val_mae: 0.3514 - val_mse: 0.3169 - val_pearson_correlation: -2.6225e-16 - val_r2_keras: -36.1635 - val_rmse: 0.9927 - val_sae: 374.2265 - val_sse: 521.3341 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0921 - loss: 0.2397 - mae: 0.2699 - mse: 0.2034 - pearson_correlation: -4.7779e-16 - r2_keras: -97.9482 - rmse: 0.8656 - sae: 2561.9458 - sse: 3069.2490\n","Epoch 49: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0807 - loss: 0.2327 - mae: 0.2649 - mse: 0.1855 - pearson_correlation: -3.1654e-16 - r2_keras: -80.2041 - rmse: 0.8528 - sae: 1870.3538 - sse: 2224.9155 - val_huber_loss: 0.1431 - val_loss: 0.2906 - val_mae: 0.3513 - val_mse: 0.3169 - val_pearson_correlation: 3.0254e-17 - val_r2_keras: -36.1685 - val_rmse: 0.9928 - val_sae: 374.2474 - val_sse: 521.4041 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0921 - loss: 0.2396 - mae: 0.2698 - mse: 0.2032 - pearson_correlation: -6.0557e-17 - r2_keras: -97.9480 - rmse: 0.8656 - sae: 2561.9583 - sse: 3069.2429\n","Epoch 50: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0806 - loss: 0.2326 - mae: 0.2648 - mse: 0.1854 - pearson_correlation: -6.0243e-17 - r2_keras: -80.2047 - rmse: 0.8528 - sae: 1870.3677 - sse: 2224.9199 - val_huber_loss: 0.1431 - val_loss: 0.2906 - val_mae: 0.3513 - val_mse: 0.3169 - val_pearson_correlation: -1.6138e-16 - val_r2_keras: -36.1645 - val_rmse: 0.9927 - val_sae: 374.2193 - val_sse: 521.3475 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0920 - loss: 0.2395 - mae: 0.2697 - mse: 0.2030 - pearson_correlation: 1.8772e-16 - r2_keras: -97.9494 - rmse: 0.8656 - sae: 2562.0303 - sse: 3069.2866\n","Epoch 51: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0806 - loss: 0.2326 - mae: 0.2647 - mse: 0.1852 - pearson_correlation: 9.9314e-17 - r2_keras: -80.2055 - rmse: 0.8528 - sae: 1870.4178 - sse: 2224.9480 - val_huber_loss: 0.1431 - val_loss: 0.2906 - val_mae: 0.3512 - val_mse: 0.3170 - val_pearson_correlation: 2.0168e-16 - val_r2_keras: -36.1701 - val_rmse: 0.9928 - val_sae: 374.2427 - val_sse: 521.4258 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0920 - loss: 0.2395 - mae: 0.2696 - mse: 0.2029 - pearson_correlation: -5.9586e-16 - r2_keras: -97.9497 - rmse: 0.8656 - sae: 2562.0464 - sse: 3069.2969\n","Epoch 52: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0805 - loss: 0.2325 - mae: 0.2646 - mse: 0.1851 - pearson_correlation: -4.2705e-16 - r2_keras: -80.2057 - rmse: 0.8528 - sae: 1870.4298 - sse: 2224.9546 - val_huber_loss: 0.1431 - val_loss: 0.2906 - val_mae: 0.3512 - val_mse: 0.3170 - val_pearson_correlation: 6.0503e-17 - val_r2_keras: -36.1710 - val_rmse: 0.9928 - val_sae: 374.2414 - val_sse: 521.4394 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0919 - loss: 0.2394 - mae: 0.2695 - mse: 0.2027 - pearson_correlation: 2.6948e-16 - r2_keras: -97.9465 - rmse: 0.8656 - sae: 2562.0322 - sse: 3069.1965\n","Epoch 53: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0805 - loss: 0.2324 - mae: 0.2645 - mse: 0.1849 - pearson_correlation: 1.9953e-16 - r2_keras: -80.2043 - rmse: 0.8528 - sae: 1870.4259 - sse: 2224.8967 - val_huber_loss: 0.1432 - val_loss: 0.2906 - val_mae: 0.3512 - val_mse: 0.3171 - val_pearson_correlation: 1.4119e-16 - val_r2_keras: -36.1681 - val_rmse: 0.9928 - val_sae: 374.2180 - val_sse: 521.3978 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0918 - loss: 0.2393 - mae: 0.2694 - mse: 0.2025 - pearson_correlation: 3.2518e-16 - r2_keras: -97.9490 - rmse: 0.8656 - sae: 2562.1138 - sse: 3069.2739\n","Epoch 54: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0804 - loss: 0.2323 - mae: 0.2644 - mse: 0.1848 - pearson_correlation: 2.0487e-16 - r2_keras: -80.2060 - rmse: 0.8528 - sae: 1870.4833 - sse: 2224.9487 - val_huber_loss: 0.1432 - val_loss: 0.2906 - val_mae: 0.3511 - val_mse: 0.3171 - val_pearson_correlation: 1.0083e-16 - val_r2_keras: -36.1742 - val_rmse: 0.9929 - val_sae: 374.2430 - val_sse: 521.4841 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0918 - loss: 0.2392 - mae: 0.2693 - mse: 0.2023 - pearson_correlation: 2.1679e-16 - r2_keras: -97.9502 - rmse: 0.8656 - sae: 2562.1372 - sse: 3069.3125\n","Epoch 55: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0803 - loss: 0.2323 - mae: 0.2643 - mse: 0.1846 - pearson_correlation: 1.7234e-16 - r2_keras: -80.2063 - rmse: 0.8528 - sae: 1870.4977 - sse: 2224.9675 - val_huber_loss: 0.1432 - val_loss: 0.2906 - val_mae: 0.3511 - val_mse: 0.3172 - val_pearson_correlation: -3.0247e-17 - val_r2_keras: -36.1755 - val_rmse: 0.9929 - val_sae: 374.2445 - val_sse: 521.5017 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0917 - loss: 0.2391 - mae: 0.2692 - mse: 0.2021 - pearson_correlation: -3.4881e-16 - r2_keras: -97.9468 - rmse: 0.8656 - sae: 2562.1289 - sse: 3069.2070\n","Epoch 56: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0803 - loss: 0.2322 - mae: 0.2642 - mse: 0.1845 - pearson_correlation: -3.5574e-16 - r2_keras: -80.2051 - rmse: 0.8528 - sae: 1870.4994 - sse: 2224.9099 - val_huber_loss: 0.1432 - val_loss: 0.2906 - val_mae: 0.3511 - val_mse: 0.3173 - val_pearson_correlation: -2.0166e-17 - val_r2_keras: -36.1734 - val_rmse: 0.9929 - val_sae: 374.2255 - val_sse: 521.4724 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0916 - loss: 0.2390 - mae: 0.2690 - mse: 0.2019 - pearson_correlation: 3.7423e-16 - r2_keras: -97.9504 - rmse: 0.8656 - sae: 2562.2168 - sse: 3069.3176\n","Epoch 57: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0802 - loss: 0.2321 - mae: 0.2641 - mse: 0.1843 - pearson_correlation: 2.8326e-16 - r2_keras: -80.2077 - rmse: 0.8528 - sae: 1870.5619 - sse: 2224.9868 - val_huber_loss: 0.1432 - val_loss: 0.2906 - val_mae: 0.3510 - val_mse: 0.3174 - val_pearson_correlation: -7.0563e-17 - val_r2_keras: -36.1804 - val_rmse: 0.9930 - val_sae: 374.2556 - val_sse: 521.5711 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0915 - loss: 0.2390 - mae: 0.2689 - mse: 0.2017 - pearson_correlation: -2.5311e-16 - r2_keras: -97.9531 - rmse: 0.8657 - sae: 2562.2520 - sse: 3069.4004\n","Epoch 58: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0802 - loss: 0.2320 - mae: 0.2640 - mse: 0.1841 - pearson_correlation: -2.0450e-16 - r2_keras: -80.2100 - rmse: 0.8528 - sae: 1870.5894 - sse: 2225.0481 - val_huber_loss: 0.1432 - val_loss: 0.2906 - val_mae: 0.3510 - val_mse: 0.3174 - val_pearson_correlation: 1.1090e-16 - val_r2_keras: -36.1771 - val_rmse: 0.9929 - val_sae: 374.2319 - val_sse: 521.5244 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0915 - loss: 0.2389 - mae: 0.2688 - mse: 0.2016 - pearson_correlation: 5.7525e-16 - r2_keras: -97.9527 - rmse: 0.8657 - sae: 2562.2837 - sse: 3069.3887\n","Epoch 59: val_loss did not improve from 0.27181\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0801 - loss: 0.2320 - mae: 0.2639 - mse: 0.1840 - pearson_correlation: 3.9145e-16 - r2_keras: -80.2102 - rmse: 0.8528 - sae: 1870.6152 - sse: 2225.0457 - val_huber_loss: 0.1433 - val_loss: 0.2906 - val_mae: 0.3510 - val_mse: 0.3175 - val_pearson_correlation: -2.0159e-17 - val_r2_keras: -36.1833 - val_rmse: 0.9930 - val_sae: 374.2584 - val_sse: 521.6115 - learning_rate: 1.0000e-05\n","| \u001b[39m16       \u001b[39m | \u001b[39m-0.2906  \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m97.04    \u001b[39m | \u001b[39m55.61    \u001b[39m | \u001b[39m69.62    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m73.67    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.6322 - loss: 0.7906 - mae: 1.0441 - mse: 1.7261 - pearson_correlation: 9.6028e-18 - r2_keras: -298.4615 - rmse: 1.5059 - sae: 4854.2988 - sse: 9288.9229\n","Epoch 1: val_loss improved from inf to 0.39685, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 623ms/step - huber_loss: 0.6455 - loss: 0.7987 - mae: 1.0575 - mse: 1.7078 - pearson_correlation: -1.2269e-17 - r2_keras: -241.8468 - rmse: 1.4681 - sae: 3530.1113 - sse: 6699.4204 - val_huber_loss: 0.2384 - val_loss: 0.3969 - val_mae: 0.5776 - val_mse: 0.5872 - val_pearson_correlation: -6.2255e-17 - val_r2_keras: -22.0968 - val_rmse: 0.7826 - val_sae: 313.1068 - val_sse: 324.0045 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.5363 - loss: 0.6947 - mae: 0.9354 - mse: 1.4296 - pearson_correlation: -1.2011e-16 - r2_keras: -263.6808 - rmse: 1.4158 - sae: 4497.5156 - sse: 8210.0664\n","Epoch 2: val_loss improved from 0.39685 to 0.38992, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.5455 - loss: 0.7003 - mae: 0.9409 - mse: 1.4099 - pearson_correlation: -7.6341e-17 - r2_keras: -211.6078 - rmse: 1.3685 - sae: 3268.3557 - sse: 5897.4648 - val_huber_loss: 0.2315 - val_loss: 0.3899 - val_mae: 0.5618 - val_mse: 0.5658 - val_pearson_correlation: 2.4446e-16 - val_r2_keras: -22.2134 - val_rmse: 0.7846 - val_sae: 310.5560 - val_sse: 325.6407 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4847 - loss: 0.6431 - mae: 0.8759 - mse: 1.2678 - pearson_correlation: 7.1994e-17 - r2_keras: -241.0205 - rmse: 1.3538 - sae: 4274.7314 - sse: 7507.1719\n","Epoch 3: val_loss improved from 0.38992 to 0.38383, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.4855 - loss: 0.6436 - mae: 0.8752 - mse: 1.2365 - pearson_correlation: 5.5428e-18 - r2_keras: -192.0254 - rmse: 1.3000 - sae: 3103.6614 - sse: 5376.3706 - val_huber_loss: 0.2254 - val_loss: 0.3838 - val_mae: 0.5507 - val_mse: 0.5420 - val_pearson_correlation: -4.8359e-16 - val_r2_keras: -22.5052 - val_rmse: 0.7895 - val_sae: 311.8685 - val_sse: 329.7335 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.4399 - loss: 0.5983 - mae: 0.8188 - mse: 1.1260 - pearson_correlation: 5.4692e-18 - r2_keras: -219.6587 - rmse: 1.2927 - sae: 4069.6489 - sse: 6844.5571\n","Epoch 4: val_loss improved from 0.38383 to 0.37707, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.4327 - loss: 0.5939 - mae: 0.8117 - mse: 1.0877 - pearson_correlation: 6.1416e-17 - r2_keras: -174.5861 - rmse: 1.2387 - sae: 2954.0496 - sse: 4897.1133 - val_huber_loss: 0.2187 - val_loss: 0.3771 - val_mae: 0.5421 - val_mse: 0.5110 - val_pearson_correlation: -1.4752e-16 - val_r2_keras: -23.2141 - val_rmse: 0.8013 - val_sae: 316.7439 - val_sse: 339.6778 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3993 - loss: 0.5577 - mae: 0.7666 - mse: 0.9976 - pearson_correlation: -2.8349e-16 - r2_keras: -199.4256 - rmse: 1.2320 - sae: 3886.3276 - sse: 6216.9512\n","Epoch 5: val_loss improved from 0.37707 to 0.37616, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.3874 - loss: 0.5504 - mae: 0.7550 - mse: 0.9558 - pearson_correlation: -1.3442e-16 - r2_keras: -158.5921 - rmse: 1.1813 - sae: 2821.0212 - sse: 4449.3218 - val_huber_loss: 0.2178 - val_loss: 0.3762 - val_mae: 0.5309 - val_mse: 0.5007 - val_pearson_correlation: -2.1743e-17 - val_r2_keras: -24.3354 - val_rmse: 0.8197 - val_sae: 319.7071 - val_sse: 355.4081 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3673 - loss: 0.5257 - mae: 0.7209 - mse: 0.9012 - pearson_correlation: 3.4474e-16 - r2_keras: -184.9320 - rmse: 1.1866 - sae: 3731.0938 - sse: 5767.3774\n","Epoch 6: val_loss did not improve from 0.37616\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3515 - loss: 0.5161 - mae: 0.7069 - mse: 0.8569 - pearson_correlation: 3.6602e-16 - r2_keras: -147.2312 - rmse: 1.1390 - sae: 2709.6946 - sse: 4129.6826 - val_huber_loss: 0.2207 - val_loss: 0.3791 - val_mae: 0.5358 - val_mse: 0.5020 - val_pearson_correlation: -3.2721e-16 - val_r2_keras: -25.8970 - val_rmse: 0.8445 - val_sae: 326.6567 - val_sse: 377.3146 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.3411 - loss: 0.4995 - mae: 0.6839 - mse: 0.8156 - pearson_correlation: 3.6413e-16 - r2_keras: -173.9561 - rmse: 1.1511 - sae: 3630.7441 - sse: 5426.9189\n","Epoch 7: val_loss did not improve from 0.37616\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.3182 - loss: 0.4855 - mae: 0.6672 - mse: 0.7644 - pearson_correlation: 1.9331e-16 - r2_keras: -138.0997 - rmse: 1.1021 - sae: 2634.6624 - sse: 3881.4294 - val_huber_loss: 0.2226 - val_loss: 0.3810 - val_mae: 0.5377 - val_mse: 0.4988 - val_pearson_correlation: -3.5963e-16 - val_r2_keras: -27.7809 - val_rmse: 0.8736 - val_sae: 341.0234 - val_sse: 403.7412 - learning_rate: 1.0000e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.3177 - loss: 0.4761 - mae: 0.6524 - mse: 0.7409 - pearson_correlation: -5.1709e-16 - r2_keras: -162.2841 - rmse: 1.1120 - sae: 3526.9324 - sse: 5064.8691\n","Epoch 8: val_loss improved from 0.37616 to 0.37129, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.2880 - loss: 0.4580 - mae: 0.6326 - mse: 0.6844 - pearson_correlation: -3.2706e-16 - r2_keras: -128.9277 - rmse: 1.0655 - sae: 2558.6472 - sse: 3623.7498 - val_huber_loss: 0.2129 - val_loss: 0.3713 - val_mae: 0.5293 - val_mse: 0.4669 - val_pearson_correlation: -2.0063e-16 - val_r2_keras: -30.6021 - val_rmse: 0.9154 - val_sae: 365.2393 - val_sse: 443.3182 - learning_rate: 1.0000e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2924 - loss: 0.4508 - mae: 0.6198 - mse: 0.6693 - pearson_correlation: 1.3440e-16 - r2_keras: -152.8134 - rmse: 1.0793 - sae: 3433.9497 - sse: 4771.0986\n","Epoch 9: val_loss improved from 0.37129 to 0.36326, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - huber_loss: 0.2580 - loss: 0.4298 - mae: 0.5974 - mse: 0.6106 - pearson_correlation: 1.4739e-16 - r2_keras: -121.6921 - rmse: 1.0365 - sae: 2491.5046 - sse: 3417.0908 - val_huber_loss: 0.2049 - val_loss: 0.3633 - val_mae: 0.5402 - val_mse: 0.4407 - val_pearson_correlation: -3.0086e-16 - val_r2_keras: -33.6224 - val_rmse: 0.9582 - val_sae: 391.0919 - val_sse: 485.6871 - learning_rate: 1.0000e-04\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2665 - loss: 0.4248 - mae: 0.5874 - mse: 0.5993 - pearson_correlation: 7.3022e-16 - r2_keras: -143.2794 - rmse: 1.0453 - sae: 3338.7542 - sse: 4475.3652\n","Epoch 10: val_loss improved from 0.36326 to 0.35149, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.2267 - loss: 0.4006 - mae: 0.5619 - mse: 0.5375 - pearson_correlation: 5.9186e-16 - r2_keras: -114.8536 - rmse: 1.0100 - sae: 2424.7590 - sse: 3214.2759 - val_huber_loss: 0.1932 - val_loss: 0.3515 - val_mae: 0.5323 - val_mse: 0.4114 - val_pearson_correlation: 1.0296e-17 - val_r2_keras: -35.7205 - val_rmse: 0.9868 - val_sae: 403.8057 - val_sse: 515.1188 - learning_rate: 1.0000e-04\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2400 - loss: 0.3983 - mae: 0.5524 - mse: 0.5314 - pearson_correlation: 8.6376e-17 - r2_keras: -134.4649 - rmse: 1.0129 - sae: 3240.8574 - sse: 4201.9526\n","Epoch 11: val_loss improved from 0.35149 to 0.34365, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.2009 - loss: 0.3745 - mae: 0.5272 - mse: 0.4734 - pearson_correlation: 5.2234e-17 - r2_keras: -108.6667 - rmse: 0.9859 - sae: 2356.3860 - sse: 3028.3572 - val_huber_loss: 0.1853 - val_loss: 0.3436 - val_mae: 0.5219 - val_mse: 0.3931 - val_pearson_correlation: -5.8467e-17 - val_r2_keras: -37.4949 - val_rmse: 1.0104 - val_sae: 412.8105 - val_sse: 540.0112 - learning_rate: 1.0000e-04\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2134 - loss: 0.3718 - mae: 0.5173 - mse: 0.4671 - pearson_correlation: 2.1108e-17 - r2_keras: -125.9357 - rmse: 0.9804 - sae: 3135.8057 - sse: 3937.3862\n","Epoch 12: val_loss improved from 0.34365 to 0.33788, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.1759 - loss: 0.3489 - mae: 0.4929 - mse: 0.4132 - pearson_correlation: -5.2051e-17 - r2_keras: -102.4044 - rmse: 0.9597 - sae: 2281.3872 - sse: 2845.2219 - val_huber_loss: 0.1796 - val_loss: 0.3379 - val_mae: 0.5154 - val_mse: 0.3814 - val_pearson_correlation: 1.4373e-16 - val_r2_keras: -38.2132 - val_rmse: 1.0197 - val_sae: 417.4551 - val_sse: 550.0872 - learning_rate: 1.0000e-04\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1853 - loss: 0.3437 - mae: 0.4789 - mse: 0.4045 - pearson_correlation: 3.8731e-16 - r2_keras: -117.9570 - rmse: 0.9491 - sae: 3027.7070 - sse: 3689.8965\n","Epoch 13: val_loss improved from 0.33788 to 0.32585, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.1514 - loss: 0.3230 - mae: 0.4554 - mse: 0.3563 - pearson_correlation: 2.1974e-16 - r2_keras: -96.7464 - rmse: 0.9360 - sae: 2206.5039 - sse: 2676.2539 - val_huber_loss: 0.1675 - val_loss: 0.3259 - val_mae: 0.4942 - val_mse: 0.3584 - val_pearson_correlation: -2.2704e-16 - val_r2_keras: -37.5612 - val_rmse: 1.0112 - val_sae: 410.6328 - val_sse: 540.9404 - learning_rate: 1.0000e-04\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1611 - loss: 0.3194 - mae: 0.4363 - mse: 0.3491 - pearson_correlation: -1.7402e-16 - r2_keras: -109.3813 - rmse: 0.9143 - sae: 2892.8267 - sse: 3423.8896\n","Epoch 14: val_loss improved from 0.32585 to 0.31225, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - huber_loss: 0.1311 - loss: 0.3011 - mae: 0.4156 - mse: 0.3071 - pearson_correlation: -1.0316e-16 - r2_keras: -90.9823 - rmse: 0.9124 - sae: 2115.1616 - sse: 2498.3638 - val_huber_loss: 0.1539 - val_loss: 0.3122 - val_mae: 0.4676 - val_mse: 0.3344 - val_pearson_correlation: -4.2247e-17 - val_r2_keras: -35.8432 - val_rmse: 0.9884 - val_sae: 395.5721 - val_sse: 516.8411 - learning_rate: 1.0000e-04\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1422 - loss: 0.3005 - mae: 0.4015 - mse: 0.3042 - pearson_correlation: -6.9783e-16 - r2_keras: -103.0247 - rmse: 0.8876 - sae: 2777.9087 - sse: 3226.7173\n","Epoch 15: val_loss improved from 0.31225 to 0.29780, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.1153 - loss: 0.2841 - mae: 0.3835 - mse: 0.2675 - pearson_correlation: -4.2805e-16 - r2_keras: -86.6349 - rmse: 0.8937 - sae: 2037.3495 - sse: 2365.6296 - val_huber_loss: 0.1395 - val_loss: 0.2978 - val_mae: 0.4212 - val_mse: 0.3095 - val_pearson_correlation: 1.0111e-16 - val_r2_keras: -32.8305 - val_rmse: 0.9472 - val_sae: 369.8162 - val_sse: 474.5774 - learning_rate: 1.0000e-04\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1299 - loss: 0.2882 - mae: 0.3773 - mse: 0.2746 - pearson_correlation: -1.7532e-16 - r2_keras: -99.2132 - rmse: 0.8712 - sae: 2705.0254 - sse: 3108.4878\n","Epoch 16: val_loss improved from 0.29780 to 0.29505, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1049 - loss: 0.2730 - mae: 0.3600 - mse: 0.2412 - pearson_correlation: -1.1527e-16 - r2_keras: -84.1062 - rmse: 0.8829 - sae: 1987.4724 - sse: 2286.9548 - val_huber_loss: 0.1368 - val_loss: 0.2951 - val_mae: 0.3990 - val_mse: 0.3094 - val_pearson_correlation: -1.0699e-16 - val_r2_keras: -30.4739 - val_rmse: 0.9136 - val_sae: 348.0240 - val_sse: 441.5196 - learning_rate: 1.0000e-04\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1203 - loss: 0.2786 - mae: 0.3625 - mse: 0.2494 - pearson_correlation: 3.0955e-17 - r2_keras: -95.8789 - rmse: 0.8565 - sae: 2650.8394 - sse: 3005.0630\n","Epoch 17: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0969 - loss: 0.2643 - mae: 0.3446 - mse: 0.2191 - pearson_correlation: 8.6928e-17 - r2_keras: -81.8515 - rmse: 0.8728 - sae: 1951.4209 - sse: 2217.6311 - val_huber_loss: 0.1432 - val_loss: 0.3014 - val_mae: 0.4053 - val_mse: 0.3258 - val_pearson_correlation: 1.2930e-16 - val_r2_keras: -30.2036 - val_rmse: 0.9096 - val_sae: 345.1258 - val_sse: 437.7276 - learning_rate: 1.0000e-04\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1115 - loss: 0.2698 - mae: 0.3465 - mse: 0.2286 - pearson_correlation: 5.1226e-16 - r2_keras: -95.5330 - rmse: 0.8550 - sae: 2634.2058 - sse: 2994.3333\n","Epoch 18: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0893 - loss: 0.2562 - mae: 0.3281 - mse: 0.2004 - pearson_correlation: 3.8977e-16 - r2_keras: -81.7067 - rmse: 0.8725 - sae: 1939.8262 - sse: 2211.4841 - val_huber_loss: 0.1486 - val_loss: 0.3069 - val_mae: 0.4078 - val_mse: 0.3430 - val_pearson_correlation: 4.5578e-16 - val_r2_keras: -29.4995 - val_rmse: 0.8993 - val_sae: 340.5822 - val_sse: 427.8509 - learning_rate: 1.0000e-04\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1040 - loss: 0.2623 - mae: 0.3350 - mse: 0.2128 - pearson_correlation: 7.2082e-16 - r2_keras: -94.8490 - rmse: 0.8520 - sae: 2615.0117 - sse: 2973.1155\n","Epoch 19: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0824 - loss: 0.2491 - mae: 0.3156 - mse: 0.1856 - pearson_correlation: 5.3096e-16 - r2_keras: -81.0543 - rmse: 0.8689 - sae: 1925.2015 - sse: 2195.0354 - val_huber_loss: 0.1551 - val_loss: 0.3134 - val_mae: 0.4125 - val_mse: 0.3671 - val_pearson_correlation: -4.5457e-16 - val_r2_keras: -28.1390 - val_rmse: 0.8790 - val_sae: 332.5301 - val_sse: 408.7657 - learning_rate: 1.0000e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0996 - loss: 0.2578 - mae: 0.3238 - mse: 0.2049 - pearson_correlation: -7.0984e-16 - r2_keras: -95.9048 - rmse: 0.8567 - sae: 2620.7671 - sse: 3005.8643\n","Epoch 20: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0776 - loss: 0.2444 - mae: 0.3003 - mse: 0.1769 - pearson_correlation: -4.1357e-16 - r2_keras: -81.4286 - rmse: 0.8693 - sae: 1925.4301 - sse: 2213.0027 - val_huber_loss: 0.1587 - val_loss: 0.3169 - val_mae: 0.4163 - val_mse: 0.3802 - val_pearson_correlation: -6.0152e-16 - val_r2_keras: -28.3853 - val_rmse: 0.8827 - val_sae: 333.3209 - val_sse: 412.2204 - learning_rate: 1.0000e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0949 - loss: 0.2532 - mae: 0.3110 - mse: 0.1961 - pearson_correlation: -3.6987e-16 - r2_keras: -98.2425 - rmse: 0.8669 - sae: 2633.1875 - sse: 3078.3789\n","Epoch 21: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0731 - loss: 0.2399 - mae: 0.2863 - mse: 0.1682 - pearson_correlation: -2.2549e-16 - r2_keras: -82.6860 - rmse: 0.8736 - sae: 1930.9594 - sse: 2257.8135 - val_huber_loss: 0.1599 - val_loss: 0.3182 - val_mae: 0.4158 - val_mse: 0.3878 - val_pearson_correlation: -1.4165e-16 - val_r2_keras: -28.1128 - val_rmse: 0.8786 - val_sae: 331.8210 - val_sse: 408.3970 - learning_rate: 1.0000e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0910 - loss: 0.2492 - mae: 0.2997 - mse: 0.1894 - pearson_correlation: -3.0779e-16 - r2_keras: -99.2473 - rmse: 0.8713 - sae: 2631.5559 - sse: 3109.5444\n","Epoch 22: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0697 - loss: 0.2362 - mae: 0.2747 - mse: 0.1619 - pearson_correlation: -2.5382e-16 - r2_keras: -83.4556 - rmse: 0.8773 - sae: 1929.0792 - sse: 2279.7605 - val_huber_loss: 0.1609 - val_loss: 0.3192 - val_mae: 0.4174 - val_mse: 0.3898 - val_pearson_correlation: 3.7764e-16 - val_r2_keras: -28.0954 - val_rmse: 0.8784 - val_sae: 332.5617 - val_sse: 408.1534 - learning_rate: 2.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0902 - loss: 0.2485 - mae: 0.2979 - mse: 0.1884 - pearson_correlation: 3.3927e-16 - r2_keras: -99.3255 - rmse: 0.8716 - sae: 2631.4370 - sse: 3111.9727\n","Epoch 23: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0689 - loss: 0.2355 - mae: 0.2723 - mse: 0.1608 - pearson_correlation: 2.6085e-16 - r2_keras: -83.3686 - rmse: 0.8764 - sae: 1928.4692 - sse: 2279.7471 - val_huber_loss: 0.1613 - val_loss: 0.3195 - val_mae: 0.4169 - val_mse: 0.3906 - val_pearson_correlation: 5.6452e-16 - val_r2_keras: -28.1258 - val_rmse: 0.8788 - val_sae: 333.0523 - val_sse: 408.5796 - learning_rate: 2.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0896 - loss: 0.2478 - mae: 0.2963 - mse: 0.1874 - pearson_correlation: 4.1969e-16 - r2_keras: -99.5906 - rmse: 0.8728 - sae: 2634.0288 - sse: 3120.1953\n","Epoch 24: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0682 - loss: 0.2348 - mae: 0.2705 - mse: 0.1597 - pearson_correlation: 1.8405e-16 - r2_keras: -83.5111 - rmse: 0.8769 - sae: 1929.9808 - sse: 2284.8279 - val_huber_loss: 0.1617 - val_loss: 0.3199 - val_mae: 0.4159 - val_mse: 0.3917 - val_pearson_correlation: 7.0402e-17 - val_r2_keras: -28.1473 - val_rmse: 0.8792 - val_sae: 333.2735 - val_sse: 408.8819 - learning_rate: 2.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0890 - loss: 0.2472 - mae: 0.2946 - mse: 0.1863 - pearson_correlation: -2.9533e-16 - r2_keras: -99.9788 - rmse: 0.8745 - sae: 2638.2222 - sse: 3132.2349\n","Epoch 25: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0676 - loss: 0.2342 - mae: 0.2687 - mse: 0.1586 - pearson_correlation: -1.4689e-16 - r2_keras: -83.7676 - rmse: 0.8780 - sae: 1932.6860 - sse: 2292.8269 - val_huber_loss: 0.1618 - val_loss: 0.3200 - val_mae: 0.4154 - val_mse: 0.3920 - val_pearson_correlation: 5.5421e-16 - val_r2_keras: -28.1680 - val_rmse: 0.8795 - val_sae: 333.4934 - val_sse: 409.1716 - learning_rate: 2.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0883 - loss: 0.2466 - mae: 0.2932 - mse: 0.1853 - pearson_correlation: 2.1330e-17 - r2_keras: -100.3256 - rmse: 0.8760 - sae: 2641.2292 - sse: 3142.9944\n","Epoch 26: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0671 - loss: 0.2336 - mae: 0.2671 - mse: 0.1576 - pearson_correlation: 4.4753e-17 - r2_keras: -83.9839 - rmse: 0.8788 - sae: 1934.5513 - sse: 2299.8252 - val_huber_loss: 0.1621 - val_loss: 0.3203 - val_mae: 0.4152 - val_mse: 0.3936 - val_pearson_correlation: -1.0149e-16 - val_r2_keras: -28.1653 - val_rmse: 0.8794 - val_sae: 333.3943 - val_sse: 409.1347 - learning_rate: 2.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0876 - loss: 0.2458 - mae: 0.2912 - mse: 0.1841 - pearson_correlation: 2.6937e-16 - r2_keras: -100.8598 - rmse: 0.8783 - sae: 2645.6809 - sse: 3159.5632\n","Epoch 27: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0664 - loss: 0.2329 - mae: 0.2649 - mse: 0.1565 - pearson_correlation: 2.6948e-16 - r2_keras: -84.3399 - rmse: 0.8804 - sae: 1937.4089 - sse: 2310.8696 - val_huber_loss: 0.1619 - val_loss: 0.3201 - val_mae: 0.4138 - val_mse: 0.3933 - val_pearson_correlation: -5.4534e-17 - val_r2_keras: -28.1880 - val_rmse: 0.8798 - val_sae: 333.6172 - val_sse: 409.4527 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0872 - loss: 0.2454 - mae: 0.2904 - mse: 0.1834 - pearson_correlation: 1.1742e-17 - r2_keras: -100.9876 - rmse: 0.8788 - sae: 2646.9131 - sse: 3163.5288\n","Epoch 28: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0660 - loss: 0.2325 - mae: 0.2641 - mse: 0.1558 - pearson_correlation: 2.9890e-17 - r2_keras: -84.4165 - rmse: 0.8807 - sae: 1938.1497 - sse: 2313.4124 - val_huber_loss: 0.1620 - val_loss: 0.3202 - val_mae: 0.4134 - val_mse: 0.3934 - val_pearson_correlation: 1.5567e-17 - val_r2_keras: -28.1935 - val_rmse: 0.8799 - val_sae: 333.7408 - val_sse: 409.5289 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0868 - loss: 0.2450 - mae: 0.2896 - mse: 0.1828 - pearson_correlation: -8.7314e-17 - r2_keras: -101.1246 - rmse: 0.8794 - sae: 2647.9978 - sse: 3167.7776\n","Epoch 29: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0657 - loss: 0.2322 - mae: 0.2632 - mse: 0.1552 - pearson_correlation: -3.7834e-17 - r2_keras: -84.5000 - rmse: 0.8810 - sae: 1938.7867 - sse: 2316.1528 - val_huber_loss: 0.1615 - val_loss: 0.3197 - val_mae: 0.4118 - val_mse: 0.3928 - val_pearson_correlation: -3.5821e-16 - val_r2_keras: -28.1878 - val_rmse: 0.8798 - val_sae: 333.6683 - val_sse: 409.4498 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0864 - loss: 0.2446 - mae: 0.2887 - mse: 0.1820 - pearson_correlation: 5.2583e-18 - r2_keras: -101.3431 - rmse: 0.8804 - sae: 2649.8027 - sse: 3174.5562\n","Epoch 30: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0654 - loss: 0.2318 - mae: 0.2623 - mse: 0.1545 - pearson_correlation: -7.9609e-17 - r2_keras: -84.6614 - rmse: 0.8818 - sae: 1940.0590 - sse: 2320.8557 - val_huber_loss: 0.1621 - val_loss: 0.3203 - val_mae: 0.4126 - val_mse: 0.3942 - val_pearson_correlation: 6.9999e-17 - val_r2_keras: -28.1991 - val_rmse: 0.8799 - val_sae: 333.8069 - val_sse: 409.6082 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0861 - loss: 0.2443 - mae: 0.2875 - mse: 0.1816 - pearson_correlation: -2.0973e-16 - r2_keras: -101.5550 - rmse: 0.8813 - sae: 2651.3223 - sse: 3181.1289\n","Epoch 31: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0650 - loss: 0.2315 - mae: 0.2610 - mse: 0.1540 - pearson_correlation: -1.2879e-16 - r2_keras: -84.7920 - rmse: 0.8823 - sae: 1940.9293 - sse: 2325.1130 - val_huber_loss: 0.1614 - val_loss: 0.3196 - val_mae: 0.4104 - val_mse: 0.3927 - val_pearson_correlation: 5.0604e-16 - val_r2_keras: -28.1986 - val_rmse: 0.8799 - val_sae: 333.4498 - val_sse: 409.6013 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0857 - loss: 0.2439 - mae: 0.2866 - mse: 0.1809 - pearson_correlation: -5.6821e-16 - r2_keras: -101.7967 - rmse: 0.8823 - sae: 2653.6504 - sse: 3188.6255\n","Epoch 32: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0647 - loss: 0.2311 - mae: 0.2600 - mse: 0.1534 - pearson_correlation: -4.1182e-16 - r2_keras: -84.9949 - rmse: 0.8833 - sae: 1942.6357 - sse: 2330.6003 - val_huber_loss: 0.1623 - val_loss: 0.3205 - val_mae: 0.4119 - val_mse: 0.3953 - val_pearson_correlation: -5.7645e-16 - val_r2_keras: -28.1877 - val_rmse: 0.8798 - val_sae: 333.4443 - val_sse: 409.4489 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0853 - loss: 0.2435 - mae: 0.2854 - mse: 0.1802 - pearson_correlation: -4.1657e-16 - r2_keras: -102.0721 - rmse: 0.8835 - sae: 2656.0542 - sse: 3197.1670\n","Epoch 33: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0643 - loss: 0.2307 - mae: 0.2588 - mse: 0.1528 - pearson_correlation: -2.7263e-16 - r2_keras: -85.1594 - rmse: 0.8840 - sae: 1944.1235 - sse: 2336.0708 - val_huber_loss: 0.1625 - val_loss: 0.3207 - val_mae: 0.4120 - val_mse: 0.3966 - val_pearson_correlation: -2.3479e-16 - val_r2_keras: -28.1313 - val_rmse: 0.8789 - val_sae: 333.0506 - val_sse: 408.6575 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0849 - loss: 0.2431 - mae: 0.2848 - mse: 0.1796 - pearson_correlation: -2.1228e-16 - r2_keras: -102.1912 - rmse: 0.8840 - sae: 2656.4521 - sse: 3200.8618\n","Epoch 34: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0640 - loss: 0.2304 - mae: 0.2581 - mse: 0.1522 - pearson_correlation: -9.7498e-17 - r2_keras: -85.2543 - rmse: 0.8844 - sae: 1944.4313 - sse: 2338.7168 - val_huber_loss: 0.1625 - val_loss: 0.3207 - val_mae: 0.4115 - val_mse: 0.3968 - val_pearson_correlation: 1.4876e-16 - val_r2_keras: -28.1267 - val_rmse: 0.8789 - val_sae: 333.0621 - val_sse: 408.5929 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0845 - loss: 0.2427 - mae: 0.2838 - mse: 0.1790 - pearson_correlation: -2.6965e-16 - r2_keras: -102.2986 - rmse: 0.8845 - sae: 2656.9390 - sse: 3204.1941\n","Epoch 35: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0637 - loss: 0.2300 - mae: 0.2571 - mse: 0.1516 - pearson_correlation: -1.0861e-16 - r2_keras: -85.3152 - rmse: 0.8846 - sae: 1944.6813 - sse: 2340.8125 - val_huber_loss: 0.1624 - val_loss: 0.3206 - val_mae: 0.4105 - val_mse: 0.3967 - val_pearson_correlation: 3.0518e-16 - val_r2_keras: -28.1448 - val_rmse: 0.8791 - val_sae: 332.8091 - val_sse: 408.8464 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0842 - loss: 0.2424 - mae: 0.2828 - mse: 0.1785 - pearson_correlation: -3.3417e-16 - r2_keras: -102.5804 - rmse: 0.8857 - sae: 2658.8496 - sse: 3212.9331\n","Epoch 36: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0634 - loss: 0.2297 - mae: 0.2561 - mse: 0.1511 - pearson_correlation: -2.2532e-16 - r2_keras: -85.5181 - rmse: 0.8856 - sae: 1945.9989 - sse: 2346.8145 - val_huber_loss: 0.1633 - val_loss: 0.3215 - val_mae: 0.4121 - val_mse: 0.3997 - val_pearson_correlation: 3.1516e-17 - val_r2_keras: -28.0551 - val_rmse: 0.8778 - val_sae: 332.4020 - val_sse: 407.5880 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - huber_loss: 0.0838 - loss: 0.2420 - mae: 0.2819 - mse: 0.1779 - pearson_correlation: 6.4040e-17 - r2_keras: -102.6189 - rmse: 0.8858 - sae: 2658.1343 - sse: 3214.1299\n","Epoch 37: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0630 - loss: 0.2294 - mae: 0.2551 - mse: 0.1505 - pearson_correlation: 4.6083e-17 - r2_keras: -85.5245 - rmse: 0.8855 - sae: 1945.4126 - sse: 2347.3865 - val_huber_loss: 0.1637 - val_loss: 0.3219 - val_mae: 0.4122 - val_mse: 0.4016 - val_pearson_correlation: -2.9993e-16 - val_r2_keras: -28.0358 - val_rmse: 0.8775 - val_sae: 332.1672 - val_sse: 407.3168 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0835 - loss: 0.2417 - mae: 0.2807 - mse: 0.1774 - pearson_correlation: -1.2211e-16 - r2_keras: -102.7603 - rmse: 0.8864 - sae: 2657.5815 - sse: 3218.5154\n","Epoch 38: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0627 - loss: 0.2290 - mae: 0.2538 - mse: 0.1500 - pearson_correlation: -9.5772e-17 - r2_keras: -85.6617 - rmse: 0.8863 - sae: 1945.1417 - sse: 2350.8137 - val_huber_loss: 0.1636 - val_loss: 0.3217 - val_mae: 0.4115 - val_mse: 0.4012 - val_pearson_correlation: 7.9184e-17 - val_r2_keras: -27.9988 - val_rmse: 0.8769 - val_sae: 331.9126 - val_sse: 406.7982 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0832 - loss: 0.2413 - mae: 0.2800 - mse: 0.1768 - pearson_correlation: 3.0769e-16 - r2_keras: -102.7962 - rmse: 0.8866 - sae: 2657.1313 - sse: 3219.6270\n","Epoch 39: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0624 - loss: 0.2287 - mae: 0.2530 - mse: 0.1494 - pearson_correlation: 2.2376e-16 - r2_keras: -85.6540 - rmse: 0.8861 - sae: 1944.7354 - sse: 2351.1836 - val_huber_loss: 0.1633 - val_loss: 0.3215 - val_mae: 0.4094 - val_mse: 0.4009 - val_pearson_correlation: -3.9402e-16 - val_r2_keras: -28.0737 - val_rmse: 0.8781 - val_sae: 331.8751 - val_sse: 407.8493 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0828 - loss: 0.2410 - mae: 0.2788 - mse: 0.1763 - pearson_correlation: 8.9462e-17 - r2_keras: -103.2265 - rmse: 0.8884 - sae: 2661.5332 - sse: 3232.9753\n","Epoch 40: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0621 - loss: 0.2284 - mae: 0.2518 - mse: 0.1489 - pearson_correlation: 4.9502e-17 - r2_keras: -85.9734 - rmse: 0.8876 - sae: 1947.7665 - sse: 2360.4646 - val_huber_loss: 0.1636 - val_loss: 0.3217 - val_mae: 0.4098 - val_mse: 0.4024 - val_pearson_correlation: -2.4619e-16 - val_r2_keras: -27.9803 - val_rmse: 0.8766 - val_sae: 331.3152 - val_sse: 406.5383 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0825 - loss: 0.2406 - mae: 0.2779 - mse: 0.1756 - pearson_correlation: 4.5894e-16 - r2_keras: -103.2310 - rmse: 0.8884 - sae: 2660.1064 - sse: 3233.1147\n","Epoch 41: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0618 - loss: 0.2280 - mae: 0.2507 - mse: 0.1483 - pearson_correlation: 1.9178e-16 - r2_keras: -85.9607 - rmse: 0.8875 - sae: 1946.6683 - sse: 2360.3728 - val_huber_loss: 0.1637 - val_loss: 0.3219 - val_mae: 0.4093 - val_mse: 0.4035 - val_pearson_correlation: 8.7734e-17 - val_r2_keras: -27.9321 - val_rmse: 0.8759 - val_sae: 330.9202 - val_sse: 405.8632 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0821 - loss: 0.2403 - mae: 0.2771 - mse: 0.1750 - pearson_correlation: 3.8199e-16 - r2_keras: -103.2334 - rmse: 0.8885 - sae: 2658.6174 - sse: 3233.1885\n","Epoch 42: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0615 - loss: 0.2277 - mae: 0.2498 - mse: 0.1477 - pearson_correlation: 3.3424e-16 - r2_keras: -85.9476 - rmse: 0.8874 - sae: 1945.6635 - sse: 2360.2498 - val_huber_loss: 0.1638 - val_loss: 0.3219 - val_mae: 0.4080 - val_mse: 0.4048 - val_pearson_correlation: -2.0735e-16 - val_r2_keras: -27.9491 - val_rmse: 0.8762 - val_sae: 330.6018 - val_sse: 406.1006 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0817 - loss: 0.2399 - mae: 0.2757 - mse: 0.1745 - pearson_correlation: -1.8473e-16 - r2_keras: -103.6578 - rmse: 0.8903 - sae: 2662.7500 - sse: 3246.3525\n","Epoch 43: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0612 - loss: 0.2274 - mae: 0.2483 - mse: 0.1472 - pearson_correlation: -1.2146e-16 - r2_keras: -86.2966 - rmse: 0.8891 - sae: 1948.5997 - sse: 2369.8015 - val_huber_loss: 0.1646 - val_loss: 0.3227 - val_mae: 0.4093 - val_mse: 0.4065 - val_pearson_correlation: 1.3561e-16 - val_r2_keras: -27.9402 - val_rmse: 0.8760 - val_sae: 330.6669 - val_sse: 405.9762 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0814 - loss: 0.2396 - mae: 0.2746 - mse: 0.1741 - pearson_correlation: 5.0536e-16 - r2_keras: -103.6233 - rmse: 0.8901 - sae: 2660.7163 - sse: 3245.2839\n","Epoch 44: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0609 - loss: 0.2271 - mae: 0.2472 - mse: 0.1468 - pearson_correlation: 3.3522e-16 - r2_keras: -86.2616 - rmse: 0.8889 - sae: 1947.1766 - sse: 2368.9478 - val_huber_loss: 0.1643 - val_loss: 0.3225 - val_mae: 0.4086 - val_mse: 0.4068 - val_pearson_correlation: 1.5194e-16 - val_r2_keras: -27.9198 - val_rmse: 0.8757 - val_sae: 330.2446 - val_sse: 405.6898 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0811 - loss: 0.2392 - mae: 0.2736 - mse: 0.1734 - pearson_correlation: -3.7341e-16 - r2_keras: -103.9539 - rmse: 0.8915 - sae: 2663.9001 - sse: 3255.5386\n","Epoch 45: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0605 - loss: 0.2267 - mae: 0.2461 - mse: 0.1461 - pearson_correlation: -2.4725e-16 - r2_keras: -86.4521 - rmse: 0.8896 - sae: 1949.1049 - sse: 2375.4333 - val_huber_loss: 0.1643 - val_loss: 0.3225 - val_mae: 0.4070 - val_mse: 0.4078 - val_pearson_correlation: 2.0834e-16 - val_r2_keras: -27.9133 - val_rmse: 0.8756 - val_sae: 329.7774 - val_sse: 405.5984 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0807 - loss: 0.2389 - mae: 0.2727 - mse: 0.1726 - pearson_correlation: 2.3104e-16 - r2_keras: -104.1879 - rmse: 0.8925 - sae: 2666.3274 - sse: 3262.7983\n","Epoch 46: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0603 - loss: 0.2264 - mae: 0.2451 - mse: 0.1454 - pearson_correlation: 1.8017e-16 - r2_keras: -86.6445 - rmse: 0.8906 - sae: 1950.8585 - sse: 2380.7000 - val_huber_loss: 0.1654 - val_loss: 0.3236 - val_mae: 0.4086 - val_mse: 0.4101 - val_pearson_correlation: -3.7634e-16 - val_r2_keras: -27.9168 - val_rmse: 0.8757 - val_sae: 329.9396 - val_sse: 405.6482 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0803 - loss: 0.2385 - mae: 0.2712 - mse: 0.1721 - pearson_correlation: 4.2074e-16 - r2_keras: -104.1799 - rmse: 0.8925 - sae: 2664.3579 - sse: 3262.5500\n","Epoch 47: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0599 - loss: 0.2261 - mae: 0.2436 - mse: 0.1449 - pearson_correlation: 3.4121e-16 - r2_keras: -86.6383 - rmse: 0.8906 - sae: 1949.4360 - sse: 2380.5239 - val_huber_loss: 0.1648 - val_loss: 0.3229 - val_mae: 0.4071 - val_mse: 0.4096 - val_pearson_correlation: -5.6448e-17 - val_r2_keras: -27.8447 - val_rmse: 0.8746 - val_sae: 329.2278 - val_sse: 404.6361 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0800 - loss: 0.2381 - mae: 0.2706 - mse: 0.1712 - pearson_correlation: 4.1184e-16 - r2_keras: -104.3755 - rmse: 0.8933 - sae: 2666.9043 - sse: 3268.6167\n","Epoch 48: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0596 - loss: 0.2257 - mae: 0.2429 - mse: 0.1441 - pearson_correlation: 3.2529e-16 - r2_keras: -86.7280 - rmse: 0.8908 - sae: 1950.9727 - sse: 2384.0911 - val_huber_loss: 0.1649 - val_loss: 0.3230 - val_mae: 0.4061 - val_mse: 0.4099 - val_pearson_correlation: 2.5653e-16 - val_r2_keras: -27.9264 - val_rmse: 0.8758 - val_sae: 329.4503 - val_sse: 405.7832 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0795 - loss: 0.2377 - mae: 0.2693 - mse: 0.1706 - pearson_correlation: 1.4260e-17 - r2_keras: -104.6986 - rmse: 0.8947 - sae: 2669.6035 - sse: 3278.6379\n","Epoch 49: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0592 - loss: 0.2253 - mae: 0.2416 - mse: 0.1436 - pearson_correlation: -2.1681e-17 - r2_keras: -86.9921 - rmse: 0.8921 - sae: 1952.9434 - sse: 2391.3440 - val_huber_loss: 0.1654 - val_loss: 0.3236 - val_mae: 0.4075 - val_mse: 0.4117 - val_pearson_correlation: 8.0041e-18 - val_r2_keras: -27.9486 - val_rmse: 0.8762 - val_sae: 329.6704 - val_sse: 406.0935 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0792 - loss: 0.2373 - mae: 0.2684 - mse: 0.1698 - pearson_correlation: -1.0572e-16 - r2_keras: -104.6783 - rmse: 0.8946 - sae: 2667.2568 - sse: 3278.0098\n","Epoch 50: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0589 - loss: 0.2250 - mae: 0.2406 - mse: 0.1429 - pearson_correlation: -4.7728e-17 - r2_keras: -86.9856 - rmse: 0.8921 - sae: 1951.2715 - sse: 2391.0073 - val_huber_loss: 0.1653 - val_loss: 0.3235 - val_mae: 0.4059 - val_mse: 0.4125 - val_pearson_correlation: -3.1594e-16 - val_r2_keras: -27.8090 - val_rmse: 0.8740 - val_sae: 328.6764 - val_sse: 404.1363 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0788 - loss: 0.2370 - mae: 0.2675 - mse: 0.1691 - pearson_correlation: -1.1577e-15 - r2_keras: -104.7016 - rmse: 0.8947 - sae: 2667.9102 - sse: 3278.7310\n","Epoch 51: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0586 - loss: 0.2247 - mae: 0.2396 - mse: 0.1422 - pearson_correlation: -8.6299e-16 - r2_keras: -86.9699 - rmse: 0.8919 - sae: 1951.6033 - sse: 2391.1218 - val_huber_loss: 0.1652 - val_loss: 0.3233 - val_mae: 0.4053 - val_mse: 0.4122 - val_pearson_correlation: -4.5274e-16 - val_r2_keras: -27.8388 - val_rmse: 0.8745 - val_sae: 328.6207 - val_sse: 404.5537 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0785 - loss: 0.2366 - mae: 0.2663 - mse: 0.1686 - pearson_correlation: -6.3511e-16 - r2_keras: -105.0348 - rmse: 0.8961 - sae: 2670.6484 - sse: 3289.0659\n","Epoch 52: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0583 - loss: 0.2244 - mae: 0.2384 - mse: 0.1418 - pearson_correlation: -3.7538e-16 - r2_keras: -87.2245 - rmse: 0.8931 - sae: 1953.4989 - sse: 2398.3926 - val_huber_loss: 0.1662 - val_loss: 0.3244 - val_mae: 0.4074 - val_mse: 0.4146 - val_pearson_correlation: -1.2173e-16 - val_r2_keras: -27.7742 - val_rmse: 0.8735 - val_sae: 328.5760 - val_sse: 403.6472 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0781 - loss: 0.2363 - mae: 0.2648 - mse: 0.1681 - pearson_correlation: 3.7670e-16 - r2_keras: -104.8528 - rmse: 0.8953 - sae: 2665.8975 - sse: 3283.4211\n","Epoch 53: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0580 - loss: 0.2240 - mae: 0.2368 - mse: 0.1412 - pearson_correlation: 2.5788e-16 - r2_keras: -87.0852 - rmse: 0.8925 - sae: 1950.2001 - sse: 2394.4189 - val_huber_loss: 0.1657 - val_loss: 0.3239 - val_mae: 0.4047 - val_mse: 0.4141 - val_pearson_correlation: -1.6267e-16 - val_r2_keras: -27.7680 - val_rmse: 0.8734 - val_sae: 328.0804 - val_sse: 403.5601 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0779 - loss: 0.2360 - mae: 0.2642 - mse: 0.1676 - pearson_correlation: 1.1186e-15 - r2_keras: -104.9370 - rmse: 0.8957 - sae: 2666.0020 - sse: 3286.0347\n","Epoch 54: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0579 - loss: 0.2238 - mae: 0.2363 - mse: 0.1408 - pearson_correlation: 7.3477e-16 - r2_keras: -87.1678 - rmse: 0.8929 - sae: 1950.4077 - sse: 2396.4714 - val_huber_loss: 0.1665 - val_loss: 0.3247 - val_mae: 0.4071 - val_mse: 0.4155 - val_pearson_correlation: 4.2142e-16 - val_r2_keras: -27.7941 - val_rmse: 0.8738 - val_sae: 328.5374 - val_sse: 403.9261 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0775 - loss: 0.2356 - mae: 0.2625 - mse: 0.1670 - pearson_correlation: 2.8853e-16 - r2_keras: -105.1616 - rmse: 0.8966 - sae: 2667.0662 - sse: 3293.0000\n","Epoch 55: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0575 - loss: 0.2235 - mae: 0.2346 - mse: 0.1402 - pearson_correlation: 2.4630e-16 - r2_keras: -87.3002 - rmse: 0.8934 - sae: 1951.0149 - sse: 2400.9111 - val_huber_loss: 0.1664 - val_loss: 0.3245 - val_mae: 0.4048 - val_mse: 0.4160 - val_pearson_correlation: -4.4702e-16 - val_r2_keras: -27.8001 - val_rmse: 0.8739 - val_sae: 327.8222 - val_sse: 404.0104 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0770 - loss: 0.2351 - mae: 0.2614 - mse: 0.1660 - pearson_correlation: 7.8748e-17 - r2_keras: -105.0699 - rmse: 0.8962 - sae: 2664.6875 - sse: 3290.1565\n","Epoch 56: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0571 - loss: 0.2230 - mae: 0.2334 - mse: 0.1393 - pearson_correlation: 3.0643e-17 - r2_keras: -87.2831 - rmse: 0.8935 - sae: 1949.5907 - sse: 2399.5325 - val_huber_loss: 0.1666 - val_loss: 0.3247 - val_mae: 0.4058 - val_mse: 0.4156 - val_pearson_correlation: -2.1987e-16 - val_r2_keras: -27.7365 - val_rmse: 0.8729 - val_sae: 328.1115 - val_sse: 403.1187 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0768 - loss: 0.2349 - mae: 0.2603 - mse: 0.1657 - pearson_correlation: -7.5766e-16 - r2_keras: -105.3450 - rmse: 0.8974 - sae: 2667.4722 - sse: 3298.6890\n","Epoch 57: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0569 - loss: 0.2228 - mae: 0.2323 - mse: 0.1391 - pearson_correlation: -4.8743e-16 - r2_keras: -87.4445 - rmse: 0.8941 - sae: 1951.2830 - sse: 2404.9629 - val_huber_loss: 0.1658 - val_loss: 0.3239 - val_mae: 0.4029 - val_mse: 0.4146 - val_pearson_correlation: -4.3976e-16 - val_r2_keras: -27.7743 - val_rmse: 0.8735 - val_sae: 327.6166 - val_sse: 403.6485 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0764 - loss: 0.2345 - mae: 0.2595 - mse: 0.1648 - pearson_correlation: -7.5704e-17 - r2_keras: -105.3477 - rmse: 0.8974 - sae: 2666.3115 - sse: 3298.7742\n","Epoch 58: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0566 - loss: 0.2225 - mae: 0.2314 - mse: 0.1383 - pearson_correlation: -1.0953e-17 - r2_keras: -87.4641 - rmse: 0.8943 - sae: 1950.6174 - sse: 2405.2283 - val_huber_loss: 0.1671 - val_loss: 0.3252 - val_mae: 0.4048 - val_mse: 0.4172 - val_pearson_correlation: 9.0083e-17 - val_r2_keras: -27.6631 - val_rmse: 0.8718 - val_sae: 327.7092 - val_sse: 402.0887 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0763 - loss: 0.2345 - mae: 0.2586 - mse: 0.1650 - pearson_correlation: 9.1953e-17 - r2_keras: -105.4460 - rmse: 0.8978 - sae: 2667.2358 - sse: 3301.8203\n","Epoch 59: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0565 - loss: 0.2224 - mae: 0.2304 - mse: 0.1383 - pearson_correlation: 6.6340e-17 - r2_keras: -87.5503 - rmse: 0.8947 - sae: 1951.3424 - sse: 2407.5020 - val_huber_loss: 0.1662 - val_loss: 0.3243 - val_mae: 0.4023 - val_mse: 0.4157 - val_pearson_correlation: -1.6255e-16 - val_r2_keras: -27.7945 - val_rmse: 0.8738 - val_sae: 327.6414 - val_sse: 403.9330 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0758 - loss: 0.2339 - mae: 0.2577 - mse: 0.1639 - pearson_correlation: -2.5086e-16 - r2_keras: -105.7442 - rmse: 0.8991 - sae: 2669.9031 - sse: 3311.0718\n","Epoch 60: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0561 - loss: 0.2219 - mae: 0.2295 - mse: 0.1374 - pearson_correlation: -1.3446e-16 - r2_keras: -87.7354 - rmse: 0.8954 - sae: 1952.9984 - sse: 2413.5088 - val_huber_loss: 0.1659 - val_loss: 0.3241 - val_mae: 0.4013 - val_mse: 0.4151 - val_pearson_correlation: -3.5760e-16 - val_r2_keras: -27.7850 - val_rmse: 0.8737 - val_sae: 327.7168 - val_sse: 403.7988 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0756 - loss: 0.2337 - mae: 0.2570 - mse: 0.1633 - pearson_correlation: 1.6997e-16 - r2_keras: -105.8888 - rmse: 0.8997 - sae: 2671.3604 - sse: 3315.5581\n","Epoch 61: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0559 - loss: 0.2217 - mae: 0.2288 - mse: 0.1368 - pearson_correlation: 1.2507e-16 - r2_keras: -87.8415 - rmse: 0.8959 - sae: 1954.0186 - sse: 2416.6133 - val_huber_loss: 0.1666 - val_loss: 0.3247 - val_mae: 0.4023 - val_mse: 0.4168 - val_pearson_correlation: 1.9535e-16 - val_r2_keras: -27.7708 - val_rmse: 0.8735 - val_sae: 327.5430 - val_sse: 403.6003 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0755 - loss: 0.2336 - mae: 0.2561 - mse: 0.1632 - pearson_correlation: -2.5647e-17 - r2_keras: -105.7942 - rmse: 0.8993 - sae: 2667.3528 - sse: 3312.6221\n","Epoch 62: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0557 - loss: 0.2216 - mae: 0.2277 - mse: 0.1367 - pearson_correlation: 9.7712e-18 - r2_keras: -87.7825 - rmse: 0.8957 - sae: 1951.3446 - sse: 2414.7031 - val_huber_loss: 0.1663 - val_loss: 0.3244 - val_mae: 0.4016 - val_mse: 0.4160 - val_pearson_correlation: 1.6274e-17 - val_r2_keras: -27.7617 - val_rmse: 0.8733 - val_sae: 327.6891 - val_sse: 403.4726 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0750 - loss: 0.2331 - mae: 0.2547 - mse: 0.1622 - pearson_correlation: 1.5920e-16 - r2_keras: -106.0407 - rmse: 0.9003 - sae: 2670.2227 - sse: 3320.2698\n","Epoch 63: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0554 - loss: 0.2211 - mae: 0.2264 - mse: 0.1358 - pearson_correlation: 1.7997e-16 - r2_keras: -87.9585 - rmse: 0.8965 - sae: 1953.2990 - sse: 2419.9382 - val_huber_loss: 0.1670 - val_loss: 0.3251 - val_mae: 0.4028 - val_mse: 0.4176 - val_pearson_correlation: 2.4386e-16 - val_r2_keras: -27.7627 - val_rmse: 0.8733 - val_sae: 327.8838 - val_sse: 403.4862 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0747 - loss: 0.2328 - mae: 0.2537 - mse: 0.1618 - pearson_correlation: 4.5498e-16 - r2_keras: -106.0006 - rmse: 0.9002 - sae: 2668.1831 - sse: 3319.0244\n","Epoch 64: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0552 - loss: 0.2209 - mae: 0.2255 - mse: 0.1355 - pearson_correlation: 3.4866e-16 - r2_keras: -87.9226 - rmse: 0.8963 - sae: 1951.8386 - sse: 2419.0007 - val_huber_loss: 0.1661 - val_loss: 0.3242 - val_mae: 0.4001 - val_mse: 0.4154 - val_pearson_correlation: -9.7668e-17 - val_r2_keras: -27.7649 - val_rmse: 0.8734 - val_sae: 327.5476 - val_sse: 403.5165 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0745 - loss: 0.2326 - mae: 0.2532 - mse: 0.1611 - pearson_correlation: 2.5707e-16 - r2_keras: -106.2199 - rmse: 0.9011 - sae: 2670.5652 - sse: 3325.8274\n","Epoch 65: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0550 - loss: 0.2207 - mae: 0.2250 - mse: 0.1349 - pearson_correlation: 1.7138e-16 - r2_keras: -88.0773 - rmse: 0.8970 - sae: 1953.4792 - sse: 2423.6355 - val_huber_loss: 0.1669 - val_loss: 0.3250 - val_mae: 0.4003 - val_mse: 0.4175 - val_pearson_correlation: 1.3834e-16 - val_r2_keras: -27.7676 - val_rmse: 0.8734 - val_sae: 327.4442 - val_sse: 403.5555 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0743 - loss: 0.2324 - mae: 0.2526 - mse: 0.1610 - pearson_correlation: 3.2340e-16 - r2_keras: -106.5239 - rmse: 0.9024 - sae: 2674.8784 - sse: 3335.2559\n","Epoch 66: val_loss did not improve from 0.29505\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0548 - loss: 0.2205 - mae: 0.2244 - mse: 0.1348 - pearson_correlation: 1.5948e-16 - r2_keras: -88.3078 - rmse: 0.8981 - sae: 1956.4336 - sse: 2430.2485 - val_huber_loss: 0.1664 - val_loss: 0.3245 - val_mae: 0.3991 - val_mse: 0.4167 - val_pearson_correlation: 4.3009e-16 - val_r2_keras: -27.8301 - val_rmse: 0.8744 - val_sae: 327.3646 - val_sse: 404.4314 - learning_rate: 1.0000e-05\n","| \u001b[39m17       \u001b[39m | \u001b[39m-0.3245  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m85.86    \u001b[39m | \u001b[39m59.44    \u001b[39m | \u001b[39m68.67    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m72.52    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.5821 - loss: 0.7413 - mae: 0.9769 - mse: 1.5162 - pearson_correlation: -1.5977e-16 - r2_keras: -230.7220 - rmse: 1.3247 - sae: 4231.2656 - sse: 7187.7271\n","Epoch 1: val_loss improved from inf to 0.40323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624ms/step - huber_loss: 0.6024 - loss: 0.7536 - mae: 0.9847 - mse: 1.5523 - pearson_correlation: -7.9029e-17 - r2_keras: -188.7961 - rmse: 1.3028 - sae: 3070.0801 - sse: 5206.0610 - val_huber_loss: 0.2440 - val_loss: 0.4032 - val_mae: 0.5712 - val_mse: 0.6132 - val_pearson_correlation: 3.8992e-17 - val_r2_keras: -22.1298 - val_rmse: 0.7832 - val_sae: 301.1215 - val_sse: 324.4671 - learning_rate: 1.0000e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3732 - loss: 0.5324 - mae: 0.7169 - mse: 0.9261 - pearson_correlation: -1.6190e-16 - r2_keras: -183.9884 - rmse: 1.1836 - sae: 3586.1904 - sse: 5738.1094\n","Epoch 2: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.3709 - loss: 0.5310 - mae: 0.7135 - mse: 0.9324 - pearson_correlation: -7.8758e-17 - r2_keras: -148.8160 - rmse: 1.1525 - sae: 2591.8826 - sse: 4136.1396 - val_huber_loss: 0.2465 - val_loss: 0.4056 - val_mae: 0.5379 - val_mse: 0.6389 - val_pearson_correlation: 5.3790e-16 - val_r2_keras: -23.1267 - val_rmse: 0.7999 - val_sae: 282.2739 - val_sse: 338.4517 - learning_rate: 1.0000e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.3170 - loss: 0.4762 - mae: 0.6214 - mse: 0.7792 - pearson_correlation: 7.6863e-17 - r2_keras: -174.8801 - rmse: 1.1541 - sae: 3442.4297 - sse: 5455.5801\n","Epoch 3: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2937 - loss: 0.4620 - mae: 0.6021 - mse: 0.7628 - pearson_correlation: 1.2859e-17 - r2_keras: -140.8302 - rmse: 1.1195 - sae: 2485.6453 - sse: 3925.3406 - val_huber_loss: 0.2593 - val_loss: 0.4184 - val_mae: 0.5229 - val_mse: 0.6889 - val_pearson_correlation: -1.6039e-16 - val_r2_keras: -24.9301 - val_rmse: 0.8292 - val_sae: 271.0882 - val_sse: 363.7500 - learning_rate: 1.0000e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2827 - loss: 0.4418 - mae: 0.5688 - mse: 0.6839 - pearson_correlation: 7.8703e-17 - r2_keras: -166.7246 - rmse: 1.1270 - sae: 3345.3716 - sse: 5202.6074\n","Epoch 4: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2580 - loss: 0.4268 - mae: 0.5443 - mse: 0.6696 - pearson_correlation: -5.8368e-17 - r2_keras: -134.8794 - rmse: 1.0978 - sae: 2419.4683 - sse: 3750.6643 - val_huber_loss: 0.2816 - val_loss: 0.4408 - val_mae: 0.5233 - val_mse: 0.7643 - val_pearson_correlation: 4.1381e-16 - val_r2_keras: -27.3287 - val_rmse: 0.8667 - val_sae: 271.1386 - val_sse: 397.3987 - learning_rate: 1.0000e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2600 - loss: 0.4192 - mae: 0.5362 - mse: 0.6223 - pearson_correlation: 1.0825e-17 - r2_keras: -159.6496 - rmse: 1.1030 - sae: 3274.0742 - sse: 4983.1494\n","Epoch 5: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.2367 - loss: 0.4050 - mae: 0.5107 - mse: 0.6110 - pearson_correlation: -1.2616e-16 - r2_keras: -129.6383 - rmse: 1.0780 - sae: 2370.0425 - sse: 3598.2080 - val_huber_loss: 0.3086 - val_loss: 0.4677 - val_mae: 0.5384 - val_mse: 0.8524 - val_pearson_correlation: 1.2635e-16 - val_r2_keras: -30.0618 - val_rmse: 0.9076 - val_sae: 288.6939 - val_sse: 435.7377 - learning_rate: 1.0000e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2429 - loss: 0.4020 - mae: 0.5104 - mse: 0.5752 - pearson_correlation: -9.5257e-17 - r2_keras: -153.7656 - rmse: 1.0826 - sae: 3210.1021 - sse: 4800.6348\n","Epoch 6: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.2214 - loss: 0.3890 - mae: 0.4862 - mse: 0.5670 - pearson_correlation: -6.4406e-18 - r2_keras: -125.3981 - rmse: 1.0620 - sae: 2326.6653 - sse: 3472.8064 - val_huber_loss: 0.3387 - val_loss: 0.4979 - val_mae: 0.5822 - val_mse: 0.9430 - val_pearson_correlation: 4.7710e-17 - val_r2_keras: -32.6735 - val_rmse: 0.9450 - val_sae: 317.4659 - val_sse: 472.3748 - learning_rate: 1.0000e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2282 - loss: 0.3873 - mae: 0.4874 - mse: 0.5360 - pearson_correlation: -1.0594e-16 - r2_keras: -148.4052 - rmse: 1.0637 - sae: 3155.4211 - sse: 4634.3638\n","Epoch 7: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.2082 - loss: 0.3752 - mae: 0.4635 - mse: 0.5310 - pearson_correlation: -1.5466e-16 - r2_keras: -121.4871 - rmse: 1.0470 - sae: 2288.4146 - sse: 3358.0007 - val_huber_loss: 0.3708 - val_loss: 0.5299 - val_mae: 0.6580 - val_mse: 1.0319 - val_pearson_correlation: 1.3838e-16 - val_r2_keras: -34.4447 - val_rmse: 0.9695 - val_sae: 345.0942 - val_sse: 497.2227 - learning_rate: 2.0000e-05\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2250 - loss: 0.3841 - mae: 0.4820 - mse: 0.5274 - pearson_correlation: 9.4750e-17 - r2_keras: -147.2923 - rmse: 1.0597 - sae: 3140.9390 - sse: 4599.8403\n","Epoch 8: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2055 - loss: 0.3723 - mae: 0.4587 - mse: 0.5230 - pearson_correlation: 5.7905e-17 - r2_keras: -120.6948 - rmse: 1.0439 - sae: 2278.7314 - sse: 3334.3958 - val_huber_loss: 0.4140 - val_loss: 0.5731 - val_mae: 0.7358 - val_mse: 1.1247 - val_pearson_correlation: -4.7326e-16 - val_r2_keras: -36.4962 - val_rmse: 0.9972 - val_sae: 374.7785 - val_sse: 526.0013 - learning_rate: 2.0000e-05\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2220 - loss: 0.3811 - mae: 0.4767 - mse: 0.5193 - pearson_correlation: -1.3689e-16 - r2_keras: -146.2439 - rmse: 1.0560 - sae: 3127.4341 - sse: 4567.3218\n","Epoch 9: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.2030 - loss: 0.3696 - mae: 0.4541 - mse: 0.5155 - pearson_correlation: -1.0444e-16 - r2_keras: -119.9518 - rmse: 1.0411 - sae: 2269.7307 - sse: 3312.1990 - val_huber_loss: 0.4702 - val_loss: 0.6294 - val_mae: 0.8280 - val_mse: 1.2543 - val_pearson_correlation: -2.5696e-16 - val_r2_keras: -39.4390 - val_rmse: 1.0356 - val_sae: 405.7343 - val_sse: 567.2831 - learning_rate: 2.0000e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2189 - loss: 0.3781 - mae: 0.4711 - mse: 0.5113 - pearson_correlation: -2.8707e-16 - r2_keras: -145.1524 - rmse: 1.0520 - sae: 3112.6523 - sse: 4533.4648\n","Epoch 10: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.2005 - loss: 0.3668 - mae: 0.4492 - mse: 0.5081 - pearson_correlation: -1.1218e-16 - r2_keras: -119.1768 - rmse: 1.0381 - sae: 2259.8518 - sse: 3289.0730 - val_huber_loss: 0.5027 - val_loss: 0.6619 - val_mae: 0.8708 - val_mse: 1.3241 - val_pearson_correlation: -2.6731e-16 - val_r2_keras: -41.3292 - val_rmse: 1.0595 - val_sae: 421.3429 - val_sse: 593.7989 - learning_rate: 2.0000e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2160 - loss: 0.3752 - mae: 0.4659 - mse: 0.5037 - pearson_correlation: -2.1219e-16 - r2_keras: -144.1577 - rmse: 1.0485 - sae: 3100.0583 - sse: 4502.6089\n","Epoch 11: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.1980 - loss: 0.3642 - mae: 0.4446 - mse: 0.5009 - pearson_correlation: -9.9137e-17 - r2_keras: -118.4577 - rmse: 1.0353 - sae: 2251.3450 - sse: 3267.8457 - val_huber_loss: 0.4929 - val_loss: 0.6521 - val_mae: 0.8665 - val_mse: 1.2954 - val_pearson_correlation: 1.5818e-16 - val_r2_keras: -41.1277 - val_rmse: 1.0570 - val_sae: 414.9783 - val_sse: 590.9721 - learning_rate: 2.0000e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2131 - loss: 0.3722 - mae: 0.4609 - mse: 0.4958 - pearson_correlation: -7.0203e-17 - r2_keras: -143.0771 - rmse: 1.0446 - sae: 3087.3481 - sse: 4469.0908\n","Epoch 12: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1955 - loss: 0.3615 - mae: 0.4399 - mse: 0.4936 - pearson_correlation: -1.2109e-16 - r2_keras: -117.6570 - rmse: 1.0321 - sae: 2242.5256 - sse: 3244.5588 - val_huber_loss: 0.4783 - val_loss: 0.6375 - val_mae: 0.8376 - val_mse: 1.2725 - val_pearson_correlation: 1.5380e-16 - val_r2_keras: -42.0734 - val_rmse: 1.0688 - val_sae: 409.0826 - val_sse: 604.2385 - learning_rate: 1.0000e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2116 - loss: 0.3708 - mae: 0.4584 - mse: 0.4919 - pearson_correlation: 7.8019e-17 - r2_keras: -142.5663 - rmse: 1.0427 - sae: 3081.5938 - sse: 4453.2476\n","Epoch 13: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1943 - loss: 0.3602 - mae: 0.4376 - mse: 0.4900 - pearson_correlation: 4.6700e-17 - r2_keras: -117.2882 - rmse: 1.0307 - sae: 2238.6262 - sse: 3233.6648 - val_huber_loss: 0.4576 - val_loss: 0.6167 - val_mae: 0.7709 - val_mse: 1.2237 - val_pearson_correlation: 8.2952e-17 - val_r2_keras: -43.2748 - val_rmse: 1.0836 - val_sae: 411.5631 - val_sse: 621.0915 - learning_rate: 1.0000e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2102 - loss: 0.3694 - mae: 0.4560 - mse: 0.4880 - pearson_correlation: 1.6010e-16 - r2_keras: -142.0565 - rmse: 1.0408 - sae: 3076.0657 - sse: 4437.4346\n","Epoch 14: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1931 - loss: 0.3589 - mae: 0.4354 - mse: 0.4863 - pearson_correlation: 2.0785e-16 - r2_keras: -116.9007 - rmse: 1.0291 - sae: 2234.7793 - sse: 3222.5630 - val_huber_loss: 0.4334 - val_loss: 0.5926 - val_mae: 0.7365 - val_mse: 1.1527 - val_pearson_correlation: -2.0542e-17 - val_r2_keras: -43.4472 - val_rmse: 1.0857 - val_sae: 409.5125 - val_sse: 623.5107 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2088 - loss: 0.3680 - mae: 0.4536 - mse: 0.4842 - pearson_correlation: 6.9672e-17 - r2_keras: -141.5357 - rmse: 1.0389 - sae: 3071.3394 - sse: 4421.2783\n","Epoch 15: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1919 - loss: 0.3576 - mae: 0.4333 - mse: 0.4828 - pearson_correlation: -1.2399e-16 - r2_keras: -116.5308 - rmse: 1.0277 - sae: 2231.5833 - sse: 3211.5271 - val_huber_loss: 0.4177 - val_loss: 0.5768 - val_mae: 0.7116 - val_mse: 1.1038 - val_pearson_correlation: 3.8403e-16 - val_r2_keras: -44.0510 - val_rmse: 1.0930 - val_sae: 412.7948 - val_sse: 631.9805 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2072 - loss: 0.3664 - mae: 0.4506 - mse: 0.4801 - pearson_correlation: 2.4312e-17 - r2_keras: -141.0943 - rmse: 1.0373 - sae: 3065.9980 - sse: 4407.5869\n","Epoch 16: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1906 - loss: 0.3562 - mae: 0.4307 - mse: 0.4790 - pearson_correlation: 8.2866e-17 - r2_keras: -116.2047 - rmse: 1.0264 - sae: 2227.9365 - sse: 3202.0256 - val_huber_loss: 0.4080 - val_loss: 0.5671 - val_mae: 0.6964 - val_mse: 1.0727 - val_pearson_correlation: 1.0160e-16 - val_r2_keras: -44.6942 - val_rmse: 1.1008 - val_sae: 417.1023 - val_sse: 641.0035 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2057 - loss: 0.3648 - mae: 0.4478 - mse: 0.4761 - pearson_correlation: -5.2533e-17 - r2_keras: -140.7113 - rmse: 1.0359 - sae: 3061.7827 - sse: 4395.7061\n","Epoch 17: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1893 - loss: 0.3548 - mae: 0.4281 - mse: 0.4753 - pearson_correlation: -5.6635e-18 - r2_keras: -115.9233 - rmse: 1.0252 - sae: 2225.0742 - sse: 3193.8000 - val_huber_loss: 0.4026 - val_loss: 0.5617 - val_mae: 0.6827 - val_mse: 1.0533 - val_pearson_correlation: 6.6001e-16 - val_r2_keras: -45.1639 - val_rmse: 1.1064 - val_sae: 420.4816 - val_sse: 647.5918 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2041 - loss: 0.3632 - mae: 0.4459 - mse: 0.4719 - pearson_correlation: 1.4583e-17 - r2_keras: -140.2715 - rmse: 1.0343 - sae: 3057.0332 - sse: 4382.0645\n","Epoch 18: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1879 - loss: 0.3534 - mae: 0.4263 - mse: 0.4714 - pearson_correlation: 6.3164e-17 - r2_keras: -115.5992 - rmse: 1.0239 - sae: 2221.8296 - sse: 3184.3430 - val_huber_loss: 0.3995 - val_loss: 0.5586 - val_mae: 0.6753 - val_mse: 1.0407 - val_pearson_correlation: 1.1649e-16 - val_r2_keras: -45.5653 - val_rmse: 1.1112 - val_sae: 423.3940 - val_sse: 653.2224 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2025 - loss: 0.3617 - mae: 0.4441 - mse: 0.4679 - pearson_correlation: -1.3222e-16 - r2_keras: -139.8533 - rmse: 1.0328 - sae: 3053.1948 - sse: 4369.0918\n","Epoch 19: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1866 - loss: 0.3520 - mae: 0.4245 - mse: 0.4676 - pearson_correlation: -5.2351e-18 - r2_keras: -115.2950 - rmse: 1.0227 - sae: 2219.2434 - sse: 3175.3967 - val_huber_loss: 0.3976 - val_loss: 0.5567 - val_mae: 0.6731 - val_mse: 1.0331 - val_pearson_correlation: -3.6998e-16 - val_r2_keras: -45.8539 - val_rmse: 1.1147 - val_sae: 425.8536 - val_sse: 657.2711 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2010 - loss: 0.3602 - mae: 0.4421 - mse: 0.4639 - pearson_correlation: 9.8082e-17 - r2_keras: -139.4603 - rmse: 1.0314 - sae: 3049.7183 - sse: 4356.9043\n","Epoch 20: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1853 - loss: 0.3506 - mae: 0.4226 - mse: 0.4639 - pearson_correlation: 1.1093e-16 - r2_keras: -114.9940 - rmse: 1.0215 - sae: 2216.7979 - sse: 3166.8140 - val_huber_loss: 0.3958 - val_loss: 0.5550 - val_mae: 0.6714 - val_mse: 1.0265 - val_pearson_correlation: 2.6215e-16 - val_r2_keras: -46.0102 - val_rmse: 1.1165 - val_sae: 427.2668 - val_sse: 659.4642 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1997 - loss: 0.3588 - mae: 0.4404 - mse: 0.4601 - pearson_correlation: -6.3213e-16 - r2_keras: -139.0980 - rmse: 1.0300 - sae: 3046.4976 - sse: 4345.6660\n","Epoch 21: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1842 - loss: 0.3494 - mae: 0.4210 - mse: 0.4603 - pearson_correlation: -5.8769e-16 - r2_keras: -114.7224 - rmse: 1.0204 - sae: 2214.5542 - sse: 3158.9690 - val_huber_loss: 0.3942 - val_loss: 0.5533 - val_mae: 0.6693 - val_mse: 1.0199 - val_pearson_correlation: -1.1157e-16 - val_r2_keras: -46.0723 - val_rmse: 1.1173 - val_sae: 427.9886 - val_sse: 660.3353 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1983 - loss: 0.3574 - mae: 0.4395 - mse: 0.4564 - pearson_correlation: 4.7246e-16 - r2_keras: -138.6639 - rmse: 1.0284 - sae: 3042.5376 - sse: 4332.1992\n","Epoch 22: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1830 - loss: 0.3481 - mae: 0.4199 - mse: 0.4568 - pearson_correlation: 3.2839e-16 - r2_keras: -114.4136 - rmse: 1.0191 - sae: 2211.9170 - sse: 3149.7629 - val_huber_loss: 0.3926 - val_loss: 0.5517 - val_mae: 0.6674 - val_mse: 1.0134 - val_pearson_correlation: -3.5653e-16 - val_r2_keras: -46.0837 - val_rmse: 1.1174 - val_sae: 428.4863 - val_sse: 660.4955 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1970 - loss: 0.3562 - mae: 0.4377 - mse: 0.4529 - pearson_correlation: -1.9742e-16 - r2_keras: -138.3393 - rmse: 1.0272 - sae: 3039.7783 - sse: 4322.1299\n","Epoch 23: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1818 - loss: 0.3469 - mae: 0.4183 - mse: 0.4534 - pearson_correlation: -3.4876e-17 - r2_keras: -114.1636 - rmse: 1.0181 - sae: 2209.9688 - sse: 3142.6562 - val_huber_loss: 0.3906 - val_loss: 0.5497 - val_mae: 0.6655 - val_mse: 1.0057 - val_pearson_correlation: -6.5209e-17 - val_r2_keras: -45.9552 - val_rmse: 1.1159 - val_sae: 428.2112 - val_sse: 658.6921 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1958 - loss: 0.3550 - mae: 0.4370 - mse: 0.4494 - pearson_correlation: 8.8591e-17 - r2_keras: -137.8659 - rmse: 1.0255 - sae: 3036.5029 - sse: 4307.4478\n","Epoch 24: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1807 - loss: 0.3458 - mae: 0.4172 - mse: 0.4500 - pearson_correlation: 5.9060e-17 - r2_keras: -113.7864 - rmse: 1.0165 - sae: 2207.5674 - sse: 3132.1453 - val_huber_loss: 0.3889 - val_loss: 0.5480 - val_mae: 0.6638 - val_mse: 0.9986 - val_pearson_correlation: 6.5386e-17 - val_r2_keras: -45.8364 - val_rmse: 1.1145 - val_sae: 427.9414 - val_sse: 657.0268 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1946 - loss: 0.3538 - mae: 0.4356 - mse: 0.4460 - pearson_correlation: 4.1634e-16 - r2_keras: -137.5330 - rmse: 1.0243 - sae: 3034.0781 - sse: 4297.1211\n","Epoch 25: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1797 - loss: 0.3447 - mae: 0.4158 - mse: 0.4468 - pearson_correlation: 2.3169e-16 - r2_keras: -113.5231 - rmse: 1.0153 - sae: 2205.7952 - sse: 3124.7756 - val_huber_loss: 0.3873 - val_loss: 0.5464 - val_mae: 0.6622 - val_mse: 0.9924 - val_pearson_correlation: 3.9793e-16 - val_r2_keras: -45.7014 - val_rmse: 1.1128 - val_sae: 427.4561 - val_sse: 655.1320 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1934 - loss: 0.3526 - mae: 0.4346 - mse: 0.4427 - pearson_correlation: 2.5023e-16 - r2_keras: -137.1178 - rmse: 1.0227 - sae: 3030.9961 - sse: 4284.2422\n","Epoch 26: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1786 - loss: 0.3435 - mae: 0.4146 - mse: 0.4434 - pearson_correlation: 1.6412e-16 - r2_keras: -113.1972 - rmse: 1.0139 - sae: 2203.5884 - sse: 3115.6135 - val_huber_loss: 0.3855 - val_loss: 0.5446 - val_mae: 0.6607 - val_mse: 0.9853 - val_pearson_correlation: 4.7143e-17 - val_r2_keras: -45.5509 - val_rmse: 1.1111 - val_sae: 426.9700 - val_sse: 653.0214 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1921 - loss: 0.3513 - mae: 0.4329 - mse: 0.4391 - pearson_correlation: -2.0292e-17 - r2_keras: -136.7482 - rmse: 1.0214 - sae: 3028.9143 - sse: 4272.7769\n","Epoch 27: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1775 - loss: 0.3423 - mae: 0.4130 - mse: 0.4401 - pearson_correlation: 1.0290e-16 - r2_keras: -112.9075 - rmse: 1.0127 - sae: 2202.0332 - sse: 3107.4626 - val_huber_loss: 0.3839 - val_loss: 0.5430 - val_mae: 0.6589 - val_mse: 0.9795 - val_pearson_correlation: 4.6915e-16 - val_r2_keras: -45.3910 - val_rmse: 1.1091 - val_sae: 426.3041 - val_sse: 650.7778 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1909 - loss: 0.3500 - mae: 0.4320 - mse: 0.4356 - pearson_correlation: 2.5773e-16 - r2_keras: -136.2552 - rmse: 1.0195 - sae: 3025.3350 - sse: 4257.4839\n","Epoch 28: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.1764 - loss: 0.3412 - mae: 0.4119 - mse: 0.4367 - pearson_correlation: 2.1792e-16 - r2_keras: -112.5421 - rmse: 1.0112 - sae: 2199.5547 - sse: 3096.8372 - val_huber_loss: 0.3824 - val_loss: 0.5415 - val_mae: 0.6577 - val_mse: 0.9739 - val_pearson_correlation: 1.1072e-16 - val_r2_keras: -45.2515 - val_rmse: 1.1075 - val_sae: 425.8736 - val_sse: 648.8210 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1896 - loss: 0.3487 - mae: 0.4306 - mse: 0.4321 - pearson_correlation: -4.1255e-18 - r2_keras: -135.8645 - rmse: 1.0181 - sae: 3022.4321 - sse: 4245.3647\n","Epoch 29: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1753 - loss: 0.3400 - mae: 0.4105 - mse: 0.4334 - pearson_correlation: 6.2460e-17 - r2_keras: -112.2297 - rmse: 1.0099 - sae: 2197.4006 - sse: 3088.1482 - val_huber_loss: 0.3803 - val_loss: 0.5395 - val_mae: 0.6558 - val_mse: 0.9671 - val_pearson_correlation: -6.1291e-16 - val_r2_keras: -45.0080 - val_rmse: 1.1046 - val_sae: 424.8436 - val_sse: 645.4052 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1884 - loss: 0.3476 - mae: 0.4298 - mse: 0.4289 - pearson_correlation: -2.1183e-16 - r2_keras: -135.3218 - rmse: 1.0160 - sae: 3018.9365 - sse: 4228.5317\n","Epoch 30: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1742 - loss: 0.3389 - mae: 0.4092 - mse: 0.4302 - pearson_correlation: -1.3305e-16 - r2_keras: -111.7891 - rmse: 1.0079 - sae: 2194.7085 - sse: 3076.0012 - val_huber_loss: 0.3774 - val_loss: 0.5365 - val_mae: 0.6530 - val_mse: 0.9567 - val_pearson_correlation: -1.0793e-16 - val_r2_keras: -44.7836 - val_rmse: 1.1019 - val_sae: 423.8022 - val_sse: 642.2569 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1872 - loss: 0.3463 - mae: 0.4280 - mse: 0.4255 - pearson_correlation: 2.0328e-16 - r2_keras: -134.9872 - rmse: 1.0148 - sae: 3017.4104 - sse: 4218.1523\n","Epoch 31: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1731 - loss: 0.3377 - mae: 0.4076 - mse: 0.4270 - pearson_correlation: 2.1732e-16 - r2_keras: -111.5572 - rmse: 1.0070 - sae: 2193.7190 - sse: 3068.9788 - val_huber_loss: 0.3767 - val_loss: 0.5358 - val_mae: 0.6520 - val_mse: 0.9543 - val_pearson_correlation: 1.2717e-16 - val_r2_keras: -44.6815 - val_rmse: 1.1006 - val_sae: 423.4257 - val_sse: 640.8256 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1860 - loss: 0.3451 - mae: 0.4272 - mse: 0.4221 - pearson_correlation: 1.8429e-16 - r2_keras: -134.5332 - rmse: 1.0131 - sae: 3013.5068 - sse: 4204.0688\n","Epoch 32: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1720 - loss: 0.3366 - mae: 0.4064 - mse: 0.4237 - pearson_correlation: 2.1031e-16 - r2_keras: -111.1957 - rmse: 1.0054 - sae: 2190.8596 - sse: 3058.8992 - val_huber_loss: 0.3740 - val_loss: 0.5331 - val_mae: 0.6497 - val_mse: 0.9446 - val_pearson_correlation: -3.4208e-17 - val_r2_keras: -44.4753 - val_rmse: 1.0981 - val_sae: 422.5912 - val_sse: 637.9331 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1846 - loss: 0.3438 - mae: 0.4248 - mse: 0.4186 - pearson_correlation: 8.1347e-17 - r2_keras: -134.1835 - rmse: 1.0118 - sae: 3011.7168 - sse: 4193.2217\n","Epoch 33: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1708 - loss: 0.3354 - mae: 0.4044 - mse: 0.4203 - pearson_correlation: -8.2440e-17 - r2_keras: -110.9575 - rmse: 1.0045 - sae: 2189.7405 - sse: 3051.6091 - val_huber_loss: 0.3733 - val_loss: 0.5325 - val_mae: 0.6484 - val_mse: 0.9420 - val_pearson_correlation: -2.9421e-16 - val_r2_keras: -44.4055 - val_rmse: 1.0973 - val_sae: 422.4052 - val_sse: 636.9536 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1834 - loss: 0.3425 - mae: 0.4240 - mse: 0.4153 - pearson_correlation: -6.9609e-17 - r2_keras: -133.6773 - rmse: 1.0099 - sae: 3007.1177 - sse: 4177.5200\n","Epoch 34: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1697 - loss: 0.3342 - mae: 0.4031 - mse: 0.4171 - pearson_correlation: -6.0104e-17 - r2_keras: -110.5635 - rmse: 1.0028 - sae: 2186.4597 - sse: 3040.4783 - val_huber_loss: 0.3710 - val_loss: 0.5301 - val_mae: 0.6459 - val_mse: 0.9341 - val_pearson_correlation: 6.8822e-17 - val_r2_keras: -44.2073 - val_rmse: 1.0949 - val_sae: 421.6334 - val_sse: 634.1734 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1817 - loss: 0.3408 - mae: 0.4216 - mse: 0.4110 - pearson_correlation: -1.2283e-16 - r2_keras: -133.1394 - rmse: 1.0079 - sae: 3003.4724 - sse: 4160.8369\n","Epoch 35: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1684 - loss: 0.3327 - mae: 0.4008 - mse: 0.4131 - pearson_correlation: -1.6694e-16 - r2_keras: -110.1664 - rmse: 1.0012 - sae: 2183.9114 - sse: 3028.9036 - val_huber_loss: 0.3693 - val_loss: 0.5284 - val_mae: 0.6438 - val_mse: 0.9284 - val_pearson_correlation: -3.8807e-16 - val_r2_keras: -44.0378 - val_rmse: 1.0928 - val_sae: 420.8647 - val_sse: 631.7951 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1801 - loss: 0.3392 - mae: 0.4200 - mse: 0.4070 - pearson_correlation: -1.8819e-16 - r2_keras: -132.4952 - rmse: 1.0055 - sae: 2998.1814 - sse: 4140.8535\n","Epoch 36: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1670 - loss: 0.3312 - mae: 0.3992 - mse: 0.4093 - pearson_correlation: -1.8247e-17 - r2_keras: -109.6898 - rmse: 0.9992 - sae: 2180.2920 - sse: 3015.0291 - val_huber_loss: 0.3671 - val_loss: 0.5262 - val_mae: 0.6417 - val_mse: 0.9210 - val_pearson_correlation: -2.8660e-16 - val_r2_keras: -43.8655 - val_rmse: 1.0908 - val_sae: 420.2348 - val_sse: 629.3780 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1786 - loss: 0.3377 - mae: 0.4179 - mse: 0.4033 - pearson_correlation: -2.1405e-16 - r2_keras: -132.0331 - rmse: 1.0037 - sae: 2994.5654 - sse: 4126.5200\n","Epoch 37: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1658 - loss: 0.3299 - mae: 0.3974 - mse: 0.4058 - pearson_correlation: 5.7331e-18 - r2_keras: -109.3845 - rmse: 0.9981 - sae: 2177.9783 - sse: 3005.5059 - val_huber_loss: 0.3672 - val_loss: 0.5263 - val_mae: 0.6416 - val_mse: 0.9195 - val_pearson_correlation: 2.9943e-16 - val_r2_keras: -43.7626 - val_rmse: 1.0895 - val_sae: 420.0564 - val_sse: 627.9346 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1772 - loss: 0.3363 - mae: 0.4167 - mse: 0.3997 - pearson_correlation: 2.1176e-16 - r2_keras: -131.5435 - rmse: 1.0019 - sae: 2989.0420 - sse: 4111.3335\n","Epoch 38: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1646 - loss: 0.3286 - mae: 0.3961 - mse: 0.4024 - pearson_correlation: -1.0376e-17 - r2_keras: -108.9975 - rmse: 0.9964 - sae: 2174.0566 - sse: 2994.6699 - val_huber_loss: 0.3655 - val_loss: 0.5246 - val_mae: 0.6399 - val_mse: 0.9134 - val_pearson_correlation: -7.3993e-16 - val_r2_keras: -43.6987 - val_rmse: 1.0887 - val_sae: 419.7998 - val_sse: 627.0377 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1757 - loss: 0.3348 - mae: 0.4152 - mse: 0.3960 - pearson_correlation: -5.6803e-17 - r2_keras: -131.1144 - rmse: 1.0002 - sae: 2985.1406 - sse: 4098.0225\n","Epoch 39: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1634 - loss: 0.3273 - mae: 0.3945 - mse: 0.3988 - pearson_correlation: 1.7254e-17 - r2_keras: -108.7052 - rmse: 0.9953 - sae: 2171.5645 - sse: 2985.7239 - val_huber_loss: 0.3621 - val_loss: 0.5212 - val_mae: 0.6368 - val_mse: 0.9019 - val_pearson_correlation: 1.1336e-17 - val_r2_keras: -43.4198 - val_rmse: 1.0853 - val_sae: 418.5074 - val_sse: 623.1257 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1742 - loss: 0.3333 - mae: 0.4130 - mse: 0.3923 - pearson_correlation: -3.6429e-16 - r2_keras: -130.6491 - rmse: 0.9985 - sae: 2981.5571 - sse: 4083.5908\n","Epoch 40: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1621 - loss: 0.3259 - mae: 0.3924 - mse: 0.3953 - pearson_correlation: -2.8153e-16 - r2_keras: -108.3404 - rmse: 0.9937 - sae: 2168.9836 - sse: 2975.4612 - val_huber_loss: 0.3605 - val_loss: 0.5196 - val_mae: 0.6354 - val_mse: 0.8960 - val_pearson_correlation: -5.7895e-17 - val_r2_keras: -43.2869 - val_rmse: 1.0837 - val_sae: 418.0045 - val_sse: 621.2620 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1728 - loss: 0.3319 - mae: 0.4113 - mse: 0.3886 - pearson_correlation: 3.6468e-17 - r2_keras: -130.2264 - rmse: 0.9969 - sae: 2977.9019 - sse: 4070.4788\n","Epoch 41: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1609 - loss: 0.3246 - mae: 0.3908 - mse: 0.3918 - pearson_correlation: -4.7634e-17 - r2_keras: -108.0152 - rmse: 0.9923 - sae: 2166.4304 - sse: 2966.2112 - val_huber_loss: 0.3590 - val_loss: 0.5181 - val_mae: 0.6336 - val_mse: 0.8906 - val_pearson_correlation: 1.9061e-16 - val_r2_keras: -43.1940 - val_rmse: 1.0826 - val_sae: 417.6558 - val_sse: 619.9588 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1713 - loss: 0.3304 - mae: 0.4095 - mse: 0.3851 - pearson_correlation: 8.0321e-17 - r2_keras: -129.8548 - rmse: 0.9955 - sae: 2974.2219 - sse: 4058.9536\n","Epoch 42: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.1597 - loss: 0.3234 - mae: 0.3890 - mse: 0.3885 - pearson_correlation: 1.3376e-16 - r2_keras: -107.7766 - rmse: 0.9914 - sae: 2164.1479 - sse: 2958.6343 - val_huber_loss: 0.3572 - val_loss: 0.5163 - val_mae: 0.6323 - val_mse: 0.8840 - val_pearson_correlation: -1.0830e-16 - val_r2_keras: -42.9779 - val_rmse: 1.0799 - val_sae: 416.6999 - val_sse: 616.9264 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1699 - loss: 0.3290 - mae: 0.4076 - mse: 0.3815 - pearson_correlation: -9.9187e-17 - r2_keras: -129.4480 - rmse: 0.9939 - sae: 2970.8198 - sse: 4046.3342\n","Epoch 43: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1585 - loss: 0.3220 - mae: 0.3872 - mse: 0.3850 - pearson_correlation: 3.1874e-18 - r2_keras: -107.4491 - rmse: 0.9899 - sae: 2161.7075 - sse: 2949.5610 - val_huber_loss: 0.3552 - val_loss: 0.5143 - val_mae: 0.6303 - val_mse: 0.8771 - val_pearson_correlation: 6.7495e-17 - val_r2_keras: -42.7822 - val_rmse: 1.0775 - val_sae: 415.7998 - val_sse: 614.1810 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1684 - loss: 0.3275 - mae: 0.4059 - mse: 0.3779 - pearson_correlation: -2.6524e-16 - r2_keras: -128.9883 - rmse: 0.9922 - sae: 2967.0918 - sse: 4032.0754\n","Epoch 44: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1573 - loss: 0.3207 - mae: 0.3855 - mse: 0.3816 - pearson_correlation: -1.9350e-16 - r2_keras: -107.0928 - rmse: 0.9884 - sae: 2159.1123 - sse: 2939.4707 - val_huber_loss: 0.3541 - val_loss: 0.5132 - val_mae: 0.6293 - val_mse: 0.8729 - val_pearson_correlation: -6.7660e-17 - val_r2_keras: -42.6746 - val_rmse: 1.0762 - val_sae: 415.4022 - val_sse: 612.6725 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1671 - loss: 0.3262 - mae: 0.4042 - mse: 0.3745 - pearson_correlation: 5.0074e-17 - r2_keras: -128.6233 - rmse: 0.9908 - sae: 2963.7065 - sse: 4020.7527\n","Epoch 45: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1561 - loss: 0.3195 - mae: 0.3839 - mse: 0.3782 - pearson_correlation: -5.2937e-17 - r2_keras: -106.7942 - rmse: 0.9870 - sae: 2156.7305 - sse: 2931.2747 - val_huber_loss: 0.3522 - val_loss: 0.5113 - val_mae: 0.6272 - val_mse: 0.8664 - val_pearson_correlation: 2.5334e-17 - val_r2_keras: -42.4279 - val_rmse: 1.0731 - val_sae: 414.1005 - val_sse: 609.2109 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1657 - loss: 0.3248 - mae: 0.4026 - mse: 0.3711 - pearson_correlation: -2.4486e-16 - r2_keras: -128.1202 - rmse: 0.9888 - sae: 2959.7397 - sse: 4005.1472\n","Epoch 46: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1550 - loss: 0.3182 - mae: 0.3823 - mse: 0.3748 - pearson_correlation: -9.0649e-17 - r2_keras: -106.3957 - rmse: 0.9853 - sae: 2153.9688 - sse: 2920.1306 - val_huber_loss: 0.3517 - val_loss: 0.5108 - val_mae: 0.6269 - val_mse: 0.8643 - val_pearson_correlation: 3.2942e-16 - val_r2_keras: -42.3971 - val_rmse: 1.0728 - val_sae: 414.1738 - val_sse: 608.7797 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1643 - loss: 0.3234 - mae: 0.4008 - mse: 0.3676 - pearson_correlation: -2.6238e-16 - r2_keras: -127.8171 - rmse: 0.9877 - sae: 2956.5244 - sse: 3995.7446\n","Epoch 47: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1538 - loss: 0.3170 - mae: 0.3807 - mse: 0.3715 - pearson_correlation: -1.1901e-16 - r2_keras: -106.1644 - rmse: 0.9843 - sae: 2151.7864 - sse: 2913.5198 - val_huber_loss: 0.3494 - val_loss: 0.5085 - val_mae: 0.6249 - val_mse: 0.8561 - val_pearson_correlation: -9.6110e-17 - val_r2_keras: -42.1736 - val_rmse: 1.0700 - val_sae: 413.0651 - val_sse: 605.6442 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.1629 - loss: 0.3220 - mae: 0.3989 - mse: 0.3644 - pearson_correlation: 1.5711e-16 - r2_keras: -127.4490 - rmse: 0.9863 - sae: 2953.4678 - sse: 3984.3271\n","Epoch 48: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.1526 - loss: 0.3158 - mae: 0.3788 - mse: 0.3684 - pearson_correlation: 5.7064e-17 - r2_keras: -105.8393 - rmse: 0.9827 - sae: 2149.4910 - sse: 2904.9731 - val_huber_loss: 0.3473 - val_loss: 0.5064 - val_mae: 0.6228 - val_mse: 0.8492 - val_pearson_correlation: 3.8376e-16 - val_r2_keras: -41.9273 - val_rmse: 1.0669 - val_sae: 411.9004 - val_sse: 602.1887 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1616 - loss: 0.3207 - mae: 0.3969 - mse: 0.3612 - pearson_correlation: 1.8173e-16 - r2_keras: -126.9206 - rmse: 0.9842 - sae: 2949.7144 - sse: 3967.9365\n","Epoch 49: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1515 - loss: 0.3146 - mae: 0.3770 - mse: 0.3656 - pearson_correlation: 1.1274e-16 - r2_keras: -105.4795 - rmse: 0.9813 - sae: 2147.0466 - sse: 2893.9570 - val_huber_loss: 0.3462 - val_loss: 0.5053 - val_mae: 0.6216 - val_mse: 0.8455 - val_pearson_correlation: -8.8536e-17 - val_r2_keras: -41.7697 - val_rmse: 1.0650 - val_sae: 411.0056 - val_sse: 599.9786 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1602 - loss: 0.3193 - mae: 0.3958 - mse: 0.3578 - pearson_correlation: 2.0533e-16 - r2_keras: -126.4457 - rmse: 0.9824 - sae: 2946.5017 - sse: 3953.2053\n","Epoch 50: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1504 - loss: 0.3133 - mae: 0.3757 - mse: 0.3622 - pearson_correlation: 5.2417e-17 - r2_keras: -105.0772 - rmse: 0.9794 - sae: 2144.6802 - sse: 2883.1311 - val_huber_loss: 0.3453 - val_loss: 0.5044 - val_mae: 0.6204 - val_mse: 0.8430 - val_pearson_correlation: -7.1918e-16 - val_r2_keras: -41.5786 - val_rmse: 1.0626 - val_sae: 410.2133 - val_sse: 597.2968 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1588 - loss: 0.3179 - mae: 0.3940 - mse: 0.3542 - pearson_correlation: 2.6819e-16 - r2_keras: -125.8046 - rmse: 0.9799 - sae: 2942.7024 - sse: 3933.3206\n","Epoch 51: val_loss did not improve from 0.40323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.1492 - loss: 0.3120 - mae: 0.3742 - mse: 0.3588 - pearson_correlation: 7.4613e-17 - r2_keras: -104.6488 - rmse: 0.9778 - sae: 2142.2024 - sse: 2869.8633 - val_huber_loss: 0.3433 - val_loss: 0.5024 - val_mae: 0.6179 - val_mse: 0.8365 - val_pearson_correlation: -1.3608e-16 - val_r2_keras: -41.3663 - val_rmse: 1.0599 - val_sae: 408.9957 - val_sse: 594.3188 - learning_rate: 1.0000e-05\n","| \u001b[39m18       \u001b[39m | \u001b[39m-0.5024  \u001b[39m | \u001b[39m0.0001   \u001b[39m | \u001b[39m94.21    \u001b[39m | \u001b[39m56.04    \u001b[39m | \u001b[39m78.43    \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m81.44    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 0.6753 - loss: 0.8347 - mae: 1.0815 - mse: 1.7491 - pearson_correlation: -3.2855e-16 - r2_keras: -197.6797 - rmse: 1.2266 - sae: 4046.8562 - sse: 6162.7964\n","Epoch 1: val_loss improved from inf to 0.42429, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 619ms/step - huber_loss: 0.6411 - loss: 0.8146 - mae: 1.0662 - mse: 1.6687 - pearson_correlation: -2.0467e-16 - r2_keras: -170.1256 - rmse: 1.2569 - sae: 2972.8843 - sse: 4562.1602 - val_huber_loss: 0.2597 - val_loss: 0.4243 - val_mae: 0.6050 - val_mse: 0.6426 - val_pearson_correlation: 4.8471e-17 - val_r2_keras: -22.1179 - val_rmse: 0.7830 - val_sae: 311.9384 - val_sse: 324.3000 - learning_rate: 0.0063\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.5792 - loss: 0.7438 - mae: 1.0024 - mse: 1.4671 - pearson_correlation: 7.3629e-17 - r2_keras: -183.6967 - rmse: 1.1827 - sae: 3801.0181 - sse: 5729.0615\n","Epoch 2: val_loss improved from 0.42429 to 0.39330, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.5851 - loss: 0.7474 - mae: 1.0018 - mse: 1.4618 - pearson_correlation: 5.2570e-17 - r2_keras: -163.0838 - rmse: 1.2404 - sae: 2828.7070 - sse: 4299.7505 - val_huber_loss: 0.2285 - val_loss: 0.3933 - val_mae: 0.5587 - val_mse: 0.5676 - val_pearson_correlation: -1.1935e-16 - val_r2_keras: -22.1924 - val_rmse: 0.7842 - val_sae: 310.5767 - val_sse: 325.3452 - learning_rate: 0.0063\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.4192 - loss: 0.5841 - mae: 0.8115 - mse: 1.0533 - pearson_correlation: -3.0907e-16 - r2_keras: -125.7876 - rmse: 0.9799 - sae: 3261.7993 - sse: 3932.7925\n","Epoch 3: val_loss improved from 0.39330 to 0.38560, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.3651 - loss: 0.5511 - mae: 0.7613 - mse: 0.9639 - pearson_correlation: -1.9010e-16 - r2_keras: -99.3953 - rmse: 0.9346 - sae: 2342.4360 - sse: 2808.0198 - val_huber_loss: 0.2212 - val_loss: 0.3856 - val_mae: 0.5284 - val_mse: 0.5421 - val_pearson_correlation: 3.6538e-17 - val_r2_keras: -23.0808 - val_rmse: 0.7991 - val_sae: 313.8972 - val_sse: 337.8082 - learning_rate: 0.0063\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3846 - loss: 0.5490 - mae: 0.7755 - mse: 0.9082 - pearson_correlation: 9.2173e-17 - r2_keras: -193.4817 - rmse: 1.2136 - sae: 3807.3696 - sse: 6032.5781\n","Epoch 4: val_loss did not improve from 0.38560\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.3622 - loss: 0.5353 - mae: 0.7406 - mse: 0.8676 - pearson_correlation: 5.3921e-17 - r2_keras: -144.5534 - rmse: 1.0906 - sae: 2706.8245 - sse: 4208.2144 - val_huber_loss: 0.2332 - val_loss: 0.3972 - val_mae: 0.5736 - val_mse: 0.5530 - val_pearson_correlation: 1.3756e-16 - val_r2_keras: -24.0609 - val_rmse: 0.8152 - val_sae: 341.9407 - val_sse: 351.5576 - learning_rate: 0.0063\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2594 - loss: 0.4233 - mae: 0.6271 - mse: 0.5778 - pearson_correlation: 4.1930e-16 - r2_keras: -131.6692 - rmse: 1.0023 - sae: 3338.0361 - sse: 4115.2334\n","Epoch 5: val_loss improved from 0.38560 to 0.37751, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.2602 - loss: 0.4238 - mae: 0.6322 - mse: 0.5786 - pearson_correlation: 3.0182e-16 - r2_keras: -105.4722 - rmse: 0.9681 - sae: 2413.8928 - sse: 2954.9353 - val_huber_loss: 0.2142 - val_loss: 0.3775 - val_mae: 0.5403 - val_mse: 0.5107 - val_pearson_correlation: -2.7494e-16 - val_r2_keras: -24.7830 - val_rmse: 0.8269 - val_sae: 341.8818 - val_sse: 361.6869 - learning_rate: 0.0063\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2839 - loss: 0.4473 - mae: 0.5687 - mse: 0.7019 - pearson_correlation: 5.4349e-17 - r2_keras: -142.0608 - rmse: 1.0409 - sae: 3122.8601 - sse: 4437.5664\n","Epoch 6: val_loss improved from 0.37751 to 0.35292, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.2299 - loss: 0.4144 - mae: 0.5243 - mse: 0.6132 - pearson_correlation: 1.2936e-16 - r2_keras: -107.4540 - rmse: 0.9493 - sae: 2231.7407 - sse: 3111.8083 - val_huber_loss: 0.1902 - val_loss: 0.3529 - val_mae: 0.4795 - val_mse: 0.4538 - val_pearson_correlation: -2.2890e-16 - val_r2_keras: -25.1671 - val_rmse: 0.8330 - val_sae: 338.0150 - val_sse: 367.0752 - learning_rate: 0.0063\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1408 - loss: 0.3035 - mae: 0.3699 - mse: 0.3235 - pearson_correlation: 7.0521e-16 - r2_keras: -95.2117 - rmse: 0.8536 - sae: 2573.4849 - sse: 2984.3667\n","Epoch 7: val_loss did not improve from 0.35292\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1277 - loss: 0.2954 - mae: 0.3596 - mse: 0.3000 - pearson_correlation: 4.6246e-16 - r2_keras: -78.9290 - rmse: 0.8497 - sae: 1881.2303 - sse: 2174.7695 - val_huber_loss: 0.1921 - val_loss: 0.3538 - val_mae: 0.4912 - val_mse: 0.4575 - val_pearson_correlation: -1.7523e-16 - val_r2_keras: -24.3172 - val_rmse: 0.8194 - val_sae: 325.2997 - val_sse: 355.1521 - learning_rate: 0.0063\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1247 - loss: 0.2865 - mae: 0.3840 - mse: 0.2590 - pearson_correlation: -1.0494e-16 - r2_keras: -91.2112 - rmse: 0.8356 - sae: 2510.7026 - sse: 2860.2749\n","Epoch 8: val_loss improved from 0.35292 to 0.31865, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1155 - loss: 0.2808 - mae: 0.3761 - mse: 0.2463 - pearson_correlation: -4.9874e-17 - r2_keras: -76.8651 - rmse: 0.8430 - sae: 1848.1383 - sse: 2099.1167 - val_huber_loss: 0.1579 - val_loss: 0.3186 - val_mae: 0.4277 - val_mse: 0.3791 - val_pearson_correlation: -1.8063e-16 - val_r2_keras: -25.9964 - val_rmse: 0.8461 - val_sae: 327.2284 - val_sse: 378.7090 - learning_rate: 0.0063\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1422 - loss: 0.3029 - mae: 0.3677 - mse: 0.3025 - pearson_correlation: 1.7868e-16 - r2_keras: -120.4966 - rmse: 0.9592 - sae: 2814.0649 - sse: 3768.6729\n","Epoch 9: val_loss improved from 0.31865 to 0.29220, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - huber_loss: 0.1301 - loss: 0.2955 - mae: 0.3644 - mse: 0.2855 - pearson_correlation: 6.3818e-17 - r2_keras: -92.7575 - rmse: 0.8917 - sae: 2029.6886 - sse: 2662.1211 - val_huber_loss: 0.1325 - val_loss: 0.2922 - val_mae: 0.3733 - val_mse: 0.2996 - val_pearson_correlation: -3.1798e-16 - val_r2_keras: -30.2798 - val_rmse: 0.9108 - val_sae: 353.7608 - val_sse: 438.7970 - learning_rate: 0.0063\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1129 - loss: 0.2726 - mae: 0.3453 - mse: 0.2368 - pearson_correlation: -4.0092e-17 - r2_keras: -101.0246 - rmse: 0.8790 - sae: 2679.2839 - sse: 3164.6763\n","Epoch 10: val_loss did not improve from 0.29220\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1186 - loss: 0.2760 - mae: 0.3474 - mse: 0.2454 - pearson_correlation: -9.6731e-17 - r2_keras: -84.8106 - rmse: 0.8839 - sae: 1964.8428 - sse: 2318.5107 - val_huber_loss: 0.1715 - val_loss: 0.3301 - val_mae: 0.4612 - val_mse: 0.3941 - val_pearson_correlation: 3.0276e-17 - val_r2_keras: -28.2866 - val_rmse: 0.8813 - val_sae: 355.3011 - val_sse: 410.8353 - learning_rate: 0.0063\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1599 - loss: 0.3185 - mae: 0.4604 - mse: 0.3345 - pearson_correlation: 4.6075e-18 - r2_keras: -98.2480 - rmse: 0.8669 - sae: 2765.1218 - sse: 3078.5474\n","Epoch 11: val_loss improved from 0.29220 to 0.28364, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.1497 - loss: 0.3122 - mae: 0.4344 - mse: 0.3230 - pearson_correlation: 7.0974e-17 - r2_keras: -86.2246 - rmse: 0.9020 - sae: 2029.5289 - sse: 2299.3909 - val_huber_loss: 0.1261 - val_loss: 0.2836 - val_mae: 0.3561 - val_mse: 0.2897 - val_pearson_correlation: 2.7504e-16 - val_r2_keras: -33.3098 - val_rmse: 0.9539 - val_sae: 366.4524 - val_sse: 481.3019 - learning_rate: 0.0063\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1209 - loss: 0.2784 - mae: 0.3658 - mse: 0.2517 - pearson_correlation: 3.0529e-19 - r2_keras: -97.4259 - rmse: 0.8634 - sae: 2539.9028 - sse: 3053.0496\n","Epoch 12: val_loss did not improve from 0.28364\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1183 - loss: 0.2767 - mae: 0.3694 - mse: 0.2475 - pearson_correlation: -3.8158e-17 - r2_keras: -83.9237 - rmse: 0.8859 - sae: 1886.4618 - sse: 2261.8315 - val_huber_loss: 0.1326 - val_loss: 0.2888 - val_mae: 0.3790 - val_mse: 0.2914 - val_pearson_correlation: -1.8868e-16 - val_r2_keras: -33.7457 - val_rmse: 0.9599 - val_sae: 376.5013 - val_sse: 487.4171 - learning_rate: 0.0063\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - huber_loss: 0.1410 - loss: 0.2972 - mae: 0.3870 - mse: 0.3092 - pearson_correlation: -1.5275e-16 - r2_keras: -103.5719 - rmse: 0.8899 - sae: 2657.5298 - sse: 3243.6904\n","Epoch 13: val_loss improved from 0.28364 to 0.27608, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1271 - loss: 0.2886 - mae: 0.3832 - mse: 0.2870 - pearson_correlation: -8.2930e-17 - r2_keras: -84.7309 - rmse: 0.8759 - sae: 1948.5817 - sse: 2350.3323 - val_huber_loss: 0.1212 - val_loss: 0.2761 - val_mae: 0.3755 - val_mse: 0.2842 - val_pearson_correlation: 2.1484e-16 - val_r2_keras: -33.2861 - val_rmse: 0.9535 - val_sae: 374.1117 - val_sse: 480.9695 - learning_rate: 0.0063\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1488 - loss: 0.3036 - mae: 0.3954 - mse: 0.3165 - pearson_correlation: -5.7859e-16 - r2_keras: -128.5643 - rmse: 0.9905 - sae: 2940.3616 - sse: 4018.9231\n","Epoch 14: val_loss did not improve from 0.27608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1443 - loss: 0.3008 - mae: 0.3977 - mse: 0.3082 - pearson_correlation: -4.0687e-16 - r2_keras: -98.9587 - rmse: 0.9206 - sae: 2120.0447 - sse: 2838.6050 - val_huber_loss: 0.1705 - val_loss: 0.3241 - val_mae: 0.4655 - val_mse: 0.3781 - val_pearson_correlation: 8.3782e-17 - val_r2_keras: -43.0580 - val_rmse: 1.0809 - val_sae: 426.4649 - val_sse: 618.0505 - learning_rate: 0.0063\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1498 - loss: 0.3034 - mae: 0.4293 - mse: 0.3145 - pearson_correlation: 4.2965e-16 - r2_keras: -127.8952 - rmse: 0.9880 - sae: 3066.6138 - sse: 3998.1694\n","Epoch 15: val_loss did not improve from 0.27608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1332 - loss: 0.2932 - mae: 0.4074 - mse: 0.2913 - pearson_correlation: 2.5925e-16 - r2_keras: -98.8411 - rmse: 0.9221 - sae: 2200.0510 - sse: 2828.6223 - val_huber_loss: 0.1411 - val_loss: 0.2931 - val_mae: 0.3959 - val_mse: 0.3206 - val_pearson_correlation: -1.3631e-16 - val_r2_keras: -36.3505 - val_rmse: 0.9952 - val_sae: 373.8347 - val_sse: 523.9564 - learning_rate: 0.0063\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1250 - loss: 0.2771 - mae: 0.3776 - mse: 0.2644 - pearson_correlation: -1.1726e-16 - r2_keras: -128.2949 - rmse: 0.9895 - sae: 2950.5364 - sse: 4010.5671\n","Epoch 16: val_loss did not improve from 0.27608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.1367 - loss: 0.2840 - mae: 0.4029 - mse: 0.2758 - pearson_correlation: -1.0912e-17 - r2_keras: -103.6464 - rmse: 0.9630 - sae: 2157.4485 - sse: 2890.1279 - val_huber_loss: 0.1960 - val_loss: 0.3465 - val_mae: 0.5153 - val_mse: 0.4375 - val_pearson_correlation: -1.9556e-16 - val_r2_keras: -31.9277 - val_rmse: 0.9344 - val_sae: 374.9259 - val_sse: 461.9137 - learning_rate: 0.0063\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1894 - loss: 0.3399 - mae: 0.5097 - mse: 0.3843 - pearson_correlation: -5.4126e-16 - r2_keras: -116.0973 - rmse: 0.9417 - sae: 2940.9263 - sse: 3632.2119\n","Epoch 17: val_loss did not improve from 0.27608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1885 - loss: 0.3392 - mae: 0.5056 - mse: 0.3859 - pearson_correlation: -3.5294e-16 - r2_keras: -99.8915 - rmse: 0.9652 - sae: 2167.5396 - sse: 2689.2322 - val_huber_loss: 0.2058 - val_loss: 0.3549 - val_mae: 0.5475 - val_mse: 0.4358 - val_pearson_correlation: -1.2553e-16 - val_r2_keras: -35.6491 - val_rmse: 0.9858 - val_sae: 414.2884 - val_sse: 514.1180 - learning_rate: 0.0063\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1728 - loss: 0.3219 - mae: 0.4862 - mse: 0.3600 - pearson_correlation: -2.4947e-16 - r2_keras: -101.0581 - rmse: 0.8791 - sae: 2782.6777 - sse: 3165.7151\n","Epoch 18: val_loss did not improve from 0.27608\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1503 - loss: 0.3081 - mae: 0.4631 - mse: 0.3298 - pearson_correlation: -2.0731e-16 - r2_keras: -86.2099 - rmse: 0.8953 - sae: 2038.8029 - sse: 2335.3547 - val_huber_loss: 0.1861 - val_loss: 0.3337 - val_mae: 0.4715 - val_mse: 0.3944 - val_pearson_correlation: -6.4494e-16 - val_r2_keras: -41.3222 - val_rmse: 1.0594 - val_sae: 432.0698 - val_sse: 593.7008 - learning_rate: 0.0063\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1008 - loss: 0.2484 - mae: 0.3351 - mse: 0.2042 - pearson_correlation: 3.6780e-16 - r2_keras: -110.5714 - rmse: 0.9192 - sae: 2812.9517 - sse: 3460.8042\n","Epoch 19: val_loss improved from 0.27608 to 0.26903, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0920 - loss: 0.2430 - mae: 0.3294 - mse: 0.1930 - pearson_correlation: 2.5318e-16 - r2_keras: -90.1114 - rmse: 0.9017 - sae: 2050.9983 - sse: 2503.4519 - val_huber_loss: 0.1218 - val_loss: 0.2690 - val_mae: 0.3309 - val_mse: 0.2652 - val_pearson_correlation: 7.7719e-17 - val_r2_keras: -37.3697 - val_rmse: 1.0087 - val_sae: 396.8114 - val_sse: 538.2549 - learning_rate: 0.0013\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0805 - loss: 0.2278 - mae: 0.2666 - mse: 0.1665 - pearson_correlation: 1.8338e-16 - r2_keras: -103.9526 - rmse: 0.8915 - sae: 2656.8064 - sse: 3255.4976\n","Epoch 20: val_loss improved from 0.26903 to 0.25608, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - huber_loss: 0.0735 - loss: 0.2235 - mae: 0.2643 - mse: 0.1569 - pearson_correlation: 1.2962e-16 - r2_keras: -85.1430 - rmse: 0.8784 - sae: 1940.8179 - sse: 2360.0608 - val_huber_loss: 0.1093 - val_loss: 0.2561 - val_mae: 0.3039 - val_mse: 0.2419 - val_pearson_correlation: 2.0327e-16 - val_r2_keras: -35.9844 - val_rmse: 0.9903 - val_sae: 384.2660 - val_sse: 518.8212 - learning_rate: 0.0013\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0775 - loss: 0.2243 - mae: 0.2585 - mse: 0.1613 - pearson_correlation: 1.9575e-17 - r2_keras: -101.7781 - rmse: 0.8822 - sae: 2614.0034 - sse: 3188.0469\n","Epoch 21: val_loss improved from 0.25608 to 0.25227, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0703 - loss: 0.2198 - mae: 0.2539 - mse: 0.1513 - pearson_correlation: -2.8375e-18 - r2_keras: -83.5126 - rmse: 0.8706 - sae: 1910.2760 - sse: 2312.9729 - val_huber_loss: 0.1060 - val_loss: 0.2523 - val_mae: 0.2947 - val_mse: 0.2367 - val_pearson_correlation: 2.9247e-16 - val_r2_keras: -35.2226 - val_rmse: 0.9801 - val_sae: 377.8194 - val_sse: 508.1348 - learning_rate: 0.0013\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0755 - loss: 0.2218 - mae: 0.2546 - mse: 0.1573 - pearson_correlation: 2.0590e-16 - r2_keras: -100.9568 - rmse: 0.8787 - sae: 2598.0347 - sse: 3162.5723\n","Epoch 22: val_loss improved from 0.25227 to 0.24660, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.0682 - loss: 0.2173 - mae: 0.2482 - mse: 0.1471 - pearson_correlation: 1.8133e-16 - r2_keras: -82.9287 - rmse: 0.8679 - sae: 1899.0214 - sse: 2295.5632 - val_huber_loss: 0.1008 - val_loss: 0.2466 - val_mae: 0.2836 - val_mse: 0.2272 - val_pearson_correlation: 8.4971e-17 - val_r2_keras: -34.7711 - val_rmse: 0.9740 - val_sae: 372.6151 - val_sse: 501.8004 - learning_rate: 0.0013\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0741 - loss: 0.2199 - mae: 0.2500 - mse: 0.1550 - pearson_correlation: 8.4761e-17 - r2_keras: -100.0461 - rmse: 0.8748 - sae: 2580.1582 - sse: 3134.3237\n","Epoch 23: val_loss improved from 0.24660 to 0.24382, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0662 - loss: 0.2151 - mae: 0.2428 - mse: 0.1441 - pearson_correlation: 7.8237e-17 - r2_keras: -82.2242 - rmse: 0.8644 - sae: 1886.1053 - sse: 2275.5894 - val_huber_loss: 0.0986 - val_loss: 0.2438 - val_mae: 0.2804 - val_mse: 0.2227 - val_pearson_correlation: 1.2666e-16 - val_r2_keras: -34.9321 - val_rmse: 0.9761 - val_sae: 371.8072 - val_sse: 504.0595 - learning_rate: 0.0013\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0714 - loss: 0.2166 - mae: 0.2426 - mse: 0.1481 - pearson_correlation: -5.2238e-16 - r2_keras: -102.3662 - rmse: 0.8848 - sae: 2604.3708 - sse: 3206.2910\n","Epoch 24: val_loss improved from 0.24382 to 0.24046, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - huber_loss: 0.0641 - loss: 0.2121 - mae: 0.2364 - mse: 0.1382 - pearson_correlation: -4.1567e-16 - r2_keras: -84.0746 - rmse: 0.8738 - sae: 1903.7115 - sse: 2327.1287 - val_huber_loss: 0.0958 - val_loss: 0.2405 - val_mae: 0.2722 - val_mse: 0.2175 - val_pearson_correlation: -1.7395e-16 - val_r2_keras: -34.1908 - val_rmse: 0.9660 - val_sae: 366.7488 - val_sse: 493.6609 - learning_rate: 0.0013\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0697 - loss: 0.2144 - mae: 0.2375 - mse: 0.1449 - pearson_correlation: 1.5436e-16 - r2_keras: -100.8150 - rmse: 0.8781 - sae: 2581.4636 - sse: 3158.1750\n","Epoch 25: val_loss improved from 0.24046 to 0.23966, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - huber_loss: 0.0625 - loss: 0.2099 - mae: 0.2303 - mse: 0.1350 - pearson_correlation: 9.8199e-17 - r2_keras: -82.7809 - rmse: 0.8670 - sae: 1886.5219 - sse: 2292.0076 - val_huber_loss: 0.0957 - val_loss: 0.2397 - val_mae: 0.2693 - val_mse: 0.2157 - val_pearson_correlation: 3.3861e-16 - val_r2_keras: -34.8666 - val_rmse: 0.9753 - val_sae: 369.1109 - val_sse: 503.1412 - learning_rate: 0.0013\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0673 - loss: 0.2112 - mae: 0.2324 - mse: 0.1390 - pearson_correlation: -3.0126e-17 - r2_keras: -102.7074 - rmse: 0.8862 - sae: 2601.3362 - sse: 3216.8726\n","Epoch 26: val_loss improved from 0.23966 to 0.23819, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0604 - loss: 0.2070 - mae: 0.2261 - mse: 0.1298 - pearson_correlation: -2.8312e-17 - r2_keras: -84.4433 - rmse: 0.8760 - sae: 1901.9935 - sse: 2335.8411 - val_huber_loss: 0.0949 - val_loss: 0.2382 - val_mae: 0.2678 - val_mse: 0.2161 - val_pearson_correlation: 4.4308e-17 - val_r2_keras: -33.7501 - val_rmse: 0.9600 - val_sae: 362.8421 - val_sse: 487.4778 - learning_rate: 0.0013\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0658 - loss: 0.2091 - mae: 0.2278 - mse: 0.1365 - pearson_correlation: 6.2122e-16 - r2_keras: -101.5648 - rmse: 0.8813 - sae: 2585.1414 - sse: 3181.4331\n","Epoch 27: val_loss improved from 0.23819 to 0.23556, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0583 - loss: 0.2044 - mae: 0.2195 - mse: 0.1263 - pearson_correlation: 4.1975e-16 - r2_keras: -83.3904 - rmse: 0.8701 - sae: 1889.1974 - sse: 2308.7988 - val_huber_loss: 0.0930 - val_loss: 0.2356 - val_mae: 0.2710 - val_mse: 0.2123 - val_pearson_correlation: 3.2665e-16 - val_r2_keras: -33.3726 - val_rmse: 0.9547 - val_sae: 359.5554 - val_sse: 482.1824 - learning_rate: 0.0013\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0638 - loss: 0.2064 - mae: 0.2210 - mse: 0.1313 - pearson_correlation: 1.8188e-16 - r2_keras: -104.4709 - rmse: 0.8937 - sae: 2616.0420 - sse: 3271.5745\n","Epoch 28: val_loss improved from 0.23556 to 0.23076, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0561 - loss: 0.2016 - mae: 0.2127 - mse: 0.1211 - pearson_correlation: 1.4378e-16 - r2_keras: -85.2634 - rmse: 0.8778 - sae: 1909.2650 - sse: 2368.1372 - val_huber_loss: 0.0890 - val_loss: 0.2308 - val_mae: 0.2558 - val_mse: 0.2026 - val_pearson_correlation: -1.1131e-17 - val_r2_keras: -33.6746 - val_rmse: 0.9589 - val_sae: 358.4924 - val_sse: 486.4194 - learning_rate: 0.0013\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0625 - loss: 0.2042 - mae: 0.2163 - mse: 0.1293 - pearson_correlation: -3.8632e-16 - r2_keras: -104.6481 - rmse: 0.8945 - sae: 2606.6067 - sse: 3277.0713\n","Epoch 29: val_loss did not improve from 0.23076\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0544 - loss: 0.1992 - mae: 0.2091 - mse: 0.1185 - pearson_correlation: -1.7367e-16 - r2_keras: -85.7737 - rmse: 0.8818 - sae: 1905.0831 - sse: 2376.4026 - val_huber_loss: 0.0934 - val_loss: 0.2343 - val_mae: 0.2585 - val_mse: 0.2073 - val_pearson_correlation: -6.1671e-17 - val_r2_keras: -35.6386 - val_rmse: 0.9857 - val_sae: 370.6955 - val_sse: 513.9697 - learning_rate: 0.0013\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0607 - loss: 0.2016 - mae: 0.2099 - mse: 0.1246 - pearson_correlation: 4.4130e-16 - r2_keras: -106.7633 - rmse: 0.9034 - sae: 2634.7295 - sse: 3342.6841\n","Epoch 30: val_loss did not improve from 0.23076\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0556 - loss: 0.1984 - mae: 0.2074 - mse: 0.1177 - pearson_correlation: 3.0036e-16 - r2_keras: -87.6811 - rmse: 0.8920 - sae: 1926.6127 - sse: 2425.9761 - val_huber_loss: 0.0957 - val_loss: 0.2357 - val_mae: 0.2733 - val_mse: 0.2186 - val_pearson_correlation: 6.9223e-17 - val_r2_keras: -32.8767 - val_rmse: 0.9478 - val_sae: 356.6337 - val_sse: 475.2266 - learning_rate: 0.0013\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0625 - loss: 0.2025 - mae: 0.2187 - mse: 0.1293 - pearson_correlation: -1.2783e-16 - r2_keras: -104.9074 - rmse: 0.8956 - sae: 2612.2476 - sse: 3285.1138\n","Epoch 31: val_loss did not improve from 0.23076\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0543 - loss: 0.1974 - mae: 0.2096 - mse: 0.1184 - pearson_correlation: -5.7105e-17 - r2_keras: -85.5700 - rmse: 0.8792 - sae: 1906.4755 - sse: 2377.3474 - val_huber_loss: 0.0938 - val_loss: 0.2329 - val_mae: 0.2795 - val_mse: 0.2146 - val_pearson_correlation: -2.9561e-16 - val_r2_keras: -33.1768 - val_rmse: 0.9520 - val_sae: 357.7130 - val_sse: 479.4355 - learning_rate: 0.0013\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0597 - loss: 0.1988 - mae: 0.2095 - mse: 0.1220 - pearson_correlation: 2.1682e-16 - r2_keras: -106.8948 - rmse: 0.9039 - sae: 2635.5928 - sse: 3346.7607\n","Epoch 32: val_loss did not improve from 0.23076\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0512 - loss: 0.1935 - mae: 0.2002 - mse: 0.1111 - pearson_correlation: 1.3719e-16 - r2_keras: -87.1533 - rmse: 0.8871 - sae: 1922.9650 - sse: 2421.4753 - val_huber_loss: 0.0950 - val_loss: 0.2331 - val_mae: 0.2689 - val_mse: 0.2156 - val_pearson_correlation: 2.1638e-16 - val_r2_keras: -34.3112 - val_rmse: 0.9677 - val_sae: 365.3083 - val_sse: 495.3499 - learning_rate: 0.0013\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0575 - loss: 0.1956 - mae: 0.2008 - mse: 0.1182 - pearson_correlation: 3.1585e-16 - r2_keras: -108.8474 - rmse: 0.9121 - sae: 2650.8247 - sse: 3407.3281\n","Epoch 33: val_loss did not improve from 0.23076\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0504 - loss: 0.1912 - mae: 0.1961 - mse: 0.1089 - pearson_correlation: 2.4764e-16 - r2_keras: -89.0364 - rmse: 0.8975 - sae: 1936.1677 - sse: 2468.6736 - val_huber_loss: 0.1083 - val_loss: 0.2455 - val_mae: 0.2912 - val_mse: 0.2463 - val_pearson_correlation: 3.1631e-17 - val_r2_keras: -31.4358 - val_rmse: 0.9274 - val_sae: 336.6430 - val_sse: 455.0124 - learning_rate: 0.0013\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0607 - loss: 0.1979 - mae: 0.2067 - mse: 0.1272 - pearson_correlation: 8.4738e-16 - r2_keras: -107.7642 - rmse: 0.9076 - sae: 2641.0728 - sse: 3373.7302\n","Epoch 34: val_loss did not improve from 0.23076\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0580 - loss: 0.1962 - mae: 0.2012 - mse: 0.1236 - pearson_correlation: 5.9755e-16 - r2_keras: -87.1564 - rmse: 0.8844 - sae: 1923.6969 - sse: 2432.6919 - val_huber_loss: 0.0950 - val_loss: 0.2320 - val_mae: 0.2779 - val_mse: 0.2154 - val_pearson_correlation: 2.6617e-16 - val_r2_keras: -32.0491 - val_rmse: 0.9362 - val_sae: 343.7681 - val_sse: 463.6158 - learning_rate: 2.5091e-04\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0579 - loss: 0.1949 - mae: 0.2001 - mse: 0.1201 - pearson_correlation: 4.1458e-16 - r2_keras: -108.1896 - rmse: 0.9093 - sae: 2640.3196 - sse: 3386.9243\n","Epoch 35: val_loss improved from 0.23076 to 0.22636, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0536 - loss: 0.1923 - mae: 0.1924 - mse: 0.1143 - pearson_correlation: 2.3382e-16 - r2_keras: -87.6259 - rmse: 0.8872 - sae: 1924.3112 - sse: 2443.6689 - val_huber_loss: 0.0895 - val_loss: 0.2264 - val_mae: 0.2692 - val_mse: 0.2019 - val_pearson_correlation: -8.1053e-17 - val_r2_keras: -32.8251 - val_rmse: 0.9471 - val_sae: 352.0974 - val_sse: 474.5018 - learning_rate: 2.5091e-04\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0568 - loss: 0.1936 - mae: 0.1957 - mse: 0.1172 - pearson_correlation: -5.1337e-16 - r2_keras: -108.6166 - rmse: 0.9111 - sae: 2642.6670 - sse: 3400.1707\n","Epoch 36: val_loss improved from 0.22636 to 0.22620, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0505 - loss: 0.1898 - mae: 0.1875 - mse: 0.1088 - pearson_correlation: -4.1767e-16 - r2_keras: -88.2023 - rmse: 0.8910 - sae: 1927.3925 - sse: 2455.9224 - val_huber_loss: 0.0896 - val_loss: 0.2262 - val_mae: 0.2627 - val_mse: 0.2002 - val_pearson_correlation: -8.8625e-17 - val_r2_keras: -33.7556 - val_rmse: 0.9600 - val_sae: 359.6176 - val_sse: 487.5558 - learning_rate: 2.5091e-04\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0561 - loss: 0.1928 - mae: 0.1920 - mse: 0.1155 - pearson_correlation: 1.1069e-16 - r2_keras: -109.1758 - rmse: 0.9134 - sae: 2647.9805 - sse: 3417.5156\n","Epoch 37: val_loss did not improve from 0.22620\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0478 - loss: 0.1877 - mae: 0.1833 - mse: 0.1048 - pearson_correlation: 1.1418e-16 - r2_keras: -89.0066 - rmse: 0.8963 - sae: 1933.0162 - sse: 2472.5476 - val_huber_loss: 0.0906 - val_loss: 0.2270 - val_mae: 0.2626 - val_mse: 0.2010 - val_pearson_correlation: -1.0731e-16 - val_r2_keras: -34.5118 - val_rmse: 0.9704 - val_sae: 364.8284 - val_sse: 498.1639 - learning_rate: 2.5091e-04\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0557 - loss: 0.1921 - mae: 0.1901 - mse: 0.1145 - pearson_correlation: -6.3034e-18 - r2_keras: -109.4965 - rmse: 0.9148 - sae: 2650.8613 - sse: 3427.4629\n","Epoch 38: val_loss did not improve from 0.22620\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0464 - loss: 0.1864 - mae: 0.1814 - mse: 0.1026 - pearson_correlation: -7.0634e-19 - r2_keras: -89.6110 - rmse: 0.9006 - sae: 1936.7521 - sse: 2483.7603 - val_huber_loss: 0.0908 - val_loss: 0.2270 - val_mae: 0.2618 - val_mse: 0.2015 - val_pearson_correlation: -3.2122e-17 - val_r2_keras: -34.5683 - val_rmse: 0.9712 - val_sae: 364.9413 - val_sse: 498.9556 - learning_rate: 2.5091e-04\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0553 - loss: 0.1915 - mae: 0.1885 - mse: 0.1139 - pearson_correlation: -3.5898e-16 - r2_keras: -109.3060 - rmse: 0.9140 - sae: 2647.5874 - sse: 3421.5552\n","Epoch 39: val_loss improved from 0.22620 to 0.22586, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0460 - loss: 0.1858 - mae: 0.1798 - mse: 0.1019 - pearson_correlation: -2.6820e-16 - r2_keras: -89.4612 - rmse: 0.8998 - sae: 1934.3458 - sse: 2479.5547 - val_huber_loss: 0.0899 - val_loss: 0.2259 - val_mae: 0.2605 - val_mse: 0.2000 - val_pearson_correlation: 2.2759e-16 - val_r2_keras: -34.2744 - val_rmse: 0.9672 - val_sae: 362.9652 - val_sse: 494.8336 - learning_rate: 2.5091e-04\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0550 - loss: 0.1909 - mae: 0.1873 - mse: 0.1134 - pearson_correlation: 6.6978e-16 - r2_keras: -109.3086 - rmse: 0.9140 - sae: 2646.8022 - sse: 3421.6362\n","Epoch 40: val_loss did not improve from 0.22586\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0455 - loss: 0.1851 - mae: 0.1783 - mse: 0.1011 - pearson_correlation: 4.3686e-16 - r2_keras: -89.4120 - rmse: 0.8994 - sae: 1933.5082 - sse: 2479.0112 - val_huber_loss: 0.0904 - val_loss: 0.2261 - val_mae: 0.2611 - val_mse: 0.2006 - val_pearson_correlation: -5.0329e-16 - val_r2_keras: -34.5671 - val_rmse: 0.9712 - val_sae: 364.9550 - val_sse: 498.9392 - learning_rate: 2.5091e-04\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0548 - loss: 0.1905 - mae: 0.1863 - mse: 0.1129 - pearson_correlation: -2.5285e-16 - r2_keras: -109.3292 - rmse: 0.9141 - sae: 2646.9351 - sse: 3422.2727\n","Epoch 41: val_loss improved from 0.22586 to 0.22454, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0453 - loss: 0.1847 - mae: 0.1774 - mse: 0.1006 - pearson_correlation: -1.4497e-16 - r2_keras: -89.4990 - rmse: 0.9001 - sae: 1933.8793 - sse: 2480.2949 - val_huber_loss: 0.0891 - val_loss: 0.2245 - val_mae: 0.2590 - val_mse: 0.1981 - val_pearson_correlation: 2.1855e-16 - val_r2_keras: -34.0867 - val_rmse: 0.9646 - val_sae: 361.3135 - val_sse: 492.1994 - learning_rate: 2.5091e-04\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0546 - loss: 0.1900 - mae: 0.1864 - mse: 0.1126 - pearson_correlation: -1.4798e-16 - r2_keras: -109.0954 - rmse: 0.9131 - sae: 2642.6401 - sse: 3415.0217\n","Epoch 42: val_loss improved from 0.22454 to 0.22396, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.0449 - loss: 0.1841 - mae: 0.1766 - mse: 0.1001 - pearson_correlation: -1.3736e-16 - r2_keras: -89.2461 - rmse: 0.8986 - sae: 1930.5563 - sse: 2474.3223 - val_huber_loss: 0.0888 - val_loss: 0.2240 - val_mae: 0.2592 - val_mse: 0.1964 - val_pearson_correlation: 1.2832e-16 - val_r2_keras: -34.6041 - val_rmse: 0.9717 - val_sae: 365.0283 - val_sse: 499.4578 - learning_rate: 2.5091e-04\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0542 - loss: 0.1894 - mae: 0.1847 - mse: 0.1117 - pearson_correlation: -7.3853e-16 - r2_keras: -109.4312 - rmse: 0.9145 - sae: 2646.0420 - sse: 3425.4385\n","Epoch 43: val_loss did not improve from 0.22396\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0445 - loss: 0.1835 - mae: 0.1754 - mse: 0.0993 - pearson_correlation: -5.3664e-16 - r2_keras: -89.6673 - rmse: 0.9012 - sae: 1933.6699 - sse: 2483.5818 - val_huber_loss: 0.0891 - val_loss: 0.2240 - val_mae: 0.2605 - val_mse: 0.1984 - val_pearson_correlation: -1.0981e-16 - val_r2_keras: -33.9782 - val_rmse: 0.9631 - val_sae: 360.5273 - val_sse: 490.6780 - learning_rate: 2.5091e-04\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0542 - loss: 0.1891 - mae: 0.1852 - mse: 0.1118 - pearson_correlation: 1.7666e-16 - r2_keras: -109.2706 - rmse: 0.9138 - sae: 2643.6284 - sse: 3420.4565\n","Epoch 44: val_loss improved from 0.22396 to 0.22254, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.0443 - loss: 0.1830 - mae: 0.1746 - mse: 0.0991 - pearson_correlation: 1.5117e-16 - r2_keras: -89.3769 - rmse: 0.8992 - sae: 1931.1400 - sse: 2478.1099 - val_huber_loss: 0.0879 - val_loss: 0.2225 - val_mae: 0.2577 - val_mse: 0.1939 - val_pearson_correlation: -1.7033e-16 - val_r2_keras: -34.7204 - val_rmse: 0.9733 - val_sae: 365.1737 - val_sse: 501.0901 - learning_rate: 2.5091e-04\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0538 - loss: 0.1884 - mae: 0.1826 - mse: 0.1108 - pearson_correlation: -1.5089e-16 - r2_keras: -109.7362 - rmse: 0.9158 - sae: 2648.1665 - sse: 3434.8997\n","Epoch 45: val_loss did not improve from 0.22254\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0439 - loss: 0.1824 - mae: 0.1732 - mse: 0.0981 - pearson_correlation: -4.1492e-18 - r2_keras: -89.8613 - rmse: 0.9020 - sae: 1934.8289 - sse: 2489.7798 - val_huber_loss: 0.0899 - val_loss: 0.2243 - val_mae: 0.2621 - val_mse: 0.2007 - val_pearson_correlation: 1.6482e-16 - val_r2_keras: -33.9617 - val_rmse: 0.9629 - val_sae: 360.7444 - val_sse: 490.4470 - learning_rate: 2.5091e-04\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0539 - loss: 0.1883 - mae: 0.1835 - mse: 0.1113 - pearson_correlation: 9.7353e-16 - r2_keras: -109.7278 - rmse: 0.9157 - sae: 2649.0256 - sse: 3434.6367\n","Epoch 46: val_loss did not improve from 0.22254\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0437 - loss: 0.1820 - mae: 0.1725 - mse: 0.0982 - pearson_correlation: 6.2004e-16 - r2_keras: -89.6918 - rmse: 0.9006 - sae: 1934.6251 - sse: 2487.6816 - val_huber_loss: 0.0894 - val_loss: 0.2234 - val_mae: 0.2607 - val_mse: 0.1978 - val_pearson_correlation: 6.4640e-17 - val_r2_keras: -34.4258 - val_rmse: 0.9692 - val_sae: 363.8395 - val_sse: 496.9565 - learning_rate: 2.5091e-04\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0536 - loss: 0.1876 - mae: 0.1818 - mse: 0.1101 - pearson_correlation: -1.6022e-17 - r2_keras: -109.4894 - rmse: 0.9147 - sae: 2645.1355 - sse: 3427.2417\n","Epoch 47: val_loss did not improve from 0.22254\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0432 - loss: 0.1813 - mae: 0.1709 - mse: 0.0970 - pearson_correlation: -2.2812e-17 - r2_keras: -89.7388 - rmse: 0.9017 - sae: 1932.9316 - sse: 2485.1680 - val_huber_loss: 0.0888 - val_loss: 0.2226 - val_mae: 0.2616 - val_mse: 0.1969 - val_pearson_correlation: 2.0801e-16 - val_r2_keras: -34.0508 - val_rmse: 0.9641 - val_sae: 361.1494 - val_sse: 491.6967 - learning_rate: 2.5091e-04\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0532 - loss: 0.1870 - mae: 0.1816 - mse: 0.1095 - pearson_correlation: 5.6205e-16 - r2_keras: -109.7124 - rmse: 0.9157 - sae: 2648.2969 - sse: 3434.1606\n","Epoch 48: val_loss improved from 0.22254 to 0.22162, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0431 - loss: 0.1808 - mae: 0.1702 - mse: 0.0966 - pearson_correlation: 3.4585e-16 - r2_keras: -89.7503 - rmse: 0.9011 - sae: 1934.3773 - sse: 2488.1707 - val_huber_loss: 0.0882 - val_loss: 0.2216 - val_mae: 0.2591 - val_mse: 0.1938 - val_pearson_correlation: 5.0588e-16 - val_r2_keras: -34.9740 - val_rmse: 0.9767 - val_sae: 366.9303 - val_sse: 504.6476 - learning_rate: 2.5091e-04\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0530 - loss: 0.1865 - mae: 0.1793 - mse: 0.1089 - pearson_correlation: 3.1681e-16 - r2_keras: -110.3269 - rmse: 0.9182 - sae: 2654.5420 - sse: 3453.2202\n","Epoch 49: val_loss improved from 0.22162 to 0.22162, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.0428 - loss: 0.1802 - mae: 0.1693 - mse: 0.0959 - pearson_correlation: 1.9568e-16 - r2_keras: -90.3722 - rmse: 0.9046 - sae: 1939.3402 - sse: 2503.3669 - val_huber_loss: 0.0885 - val_loss: 0.2216 - val_mae: 0.2607 - val_mse: 0.1950 - val_pearson_correlation: -2.8270e-16 - val_r2_keras: -34.2129 - val_rmse: 0.9663 - val_sae: 362.2503 - val_sse: 493.9697 - learning_rate: 2.5091e-04\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0527 - loss: 0.1859 - mae: 0.1796 - mse: 0.1086 - pearson_correlation: 8.2067e-17 - r2_keras: -110.2499 - rmse: 0.9179 - sae: 2652.8938 - sse: 3450.8340\n","Epoch 50: val_loss did not improve from 0.22162\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0424 - loss: 0.1795 - mae: 0.1681 - mse: 0.0954 - pearson_correlation: -4.5688e-17 - r2_keras: -90.1306 - rmse: 0.9028 - sae: 1937.3943 - sse: 2499.5442 - val_huber_loss: 0.0904 - val_loss: 0.2232 - val_mae: 0.2641 - val_mse: 0.1998 - val_pearson_correlation: -9.5710e-17 - val_r2_keras: -34.7499 - val_rmse: 0.9737 - val_sae: 365.8158 - val_sse: 501.5028 - learning_rate: 2.5091e-04\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0526 - loss: 0.1855 - mae: 0.1788 - mse: 0.1078 - pearson_correlation: -9.4679e-17 - r2_keras: -110.1432 - rmse: 0.9174 - sae: 2650.8760 - sse: 3447.5220\n","Epoch 51: val_loss did not improve from 0.22162\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0421 - loss: 0.1790 - mae: 0.1675 - mse: 0.0945 - pearson_correlation: 4.0086e-17 - r2_keras: -90.2913 - rmse: 0.9045 - sae: 1936.9908 - sse: 2500.0564 - val_huber_loss: 0.0895 - val_loss: 0.2220 - val_mae: 0.2636 - val_mse: 0.1979 - val_pearson_correlation: -1.5184e-16 - val_r2_keras: -34.2741 - val_rmse: 0.9672 - val_sae: 362.8184 - val_sse: 494.8283 - learning_rate: 2.5091e-04\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0523 - loss: 0.1848 - mae: 0.1778 - mse: 0.1076 - pearson_correlation: -1.6576e-16 - r2_keras: -110.3644 - rmse: 0.9183 - sae: 2652.7361 - sse: 3454.3843\n","Epoch 52: val_loss did not improve from 0.22162\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0418 - loss: 0.1784 - mae: 0.1659 - mse: 0.0942 - pearson_correlation: -1.2609e-16 - r2_keras: -90.3280 - rmse: 0.9041 - sae: 1937.6459 - sse: 2503.3308 - val_huber_loss: 0.0897 - val_loss: 0.2219 - val_mae: 0.2631 - val_mse: 0.1970 - val_pearson_correlation: -1.2526e-16 - val_r2_keras: -35.2238 - val_rmse: 0.9801 - val_sae: 368.6494 - val_sse: 508.1512 - learning_rate: 2.5091e-04\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0520 - loss: 0.1842 - mae: 0.1756 - mse: 0.1066 - pearson_correlation: -4.7211e-16 - r2_keras: -110.8709 - rmse: 0.9204 - sae: 2658.7380 - sse: 3470.0952\n","Epoch 53: val_loss did not improve from 0.22162\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0416 - loss: 0.1778 - mae: 0.1650 - mse: 0.0934 - pearson_correlation: -3.4975e-16 - r2_keras: -90.8898 - rmse: 0.9074 - sae: 1942.6403 - sse: 2516.4338 - val_huber_loss: 0.0905 - val_loss: 0.2223 - val_mae: 0.2658 - val_mse: 0.2006 - val_pearson_correlation: 5.4357e-17 - val_r2_keras: -34.2251 - val_rmse: 0.9665 - val_sae: 362.1385 - val_sse: 494.1414 - learning_rate: 2.5091e-04\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0517 - loss: 0.1836 - mae: 0.1776 - mse: 0.1062 - pearson_correlation: 3.3839e-16 - r2_keras: -110.4049 - rmse: 0.9185 - sae: 2652.9517 - sse: 3455.6392\n","Epoch 54: val_loss did not improve from 0.22162\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0411 - loss: 0.1771 - mae: 0.1651 - mse: 0.0928 - pearson_correlation: 2.6190e-16 - r2_keras: -90.3843 - rmse: 0.9045 - sae: 1937.9086 - sse: 2504.5115 - val_huber_loss: 0.0902 - val_loss: 0.2220 - val_mae: 0.2659 - val_mse: 0.1989 - val_pearson_correlation: 3.0048e-16 - val_r2_keras: -34.5295 - val_rmse: 0.9707 - val_sae: 364.2012 - val_sse: 498.4114 - learning_rate: 5.0182e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0515 - loss: 0.1833 - mae: 0.1766 - mse: 0.1058 - pearson_correlation: -8.5596e-17 - r2_keras: -110.3791 - rmse: 0.9184 - sae: 2651.9934 - sse: 3454.8416\n","Epoch 55: val_loss did not improve from 0.22162\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0408 - loss: 0.1768 - mae: 0.1641 - mse: 0.0922 - pearson_correlation: -8.4564e-17 - r2_keras: -90.4591 - rmse: 0.9052 - sae: 1937.6233 - sse: 2505.0586 - val_huber_loss: 0.0902 - val_loss: 0.2219 - val_mae: 0.2661 - val_mse: 0.1982 - val_pearson_correlation: -5.9480e-16 - val_r2_keras: -34.7820 - val_rmse: 0.9741 - val_sae: 365.8830 - val_sse: 501.9541 - learning_rate: 5.0182e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0514 - loss: 0.1832 - mae: 0.1759 - mse: 0.1055 - pearson_correlation: 1.9304e-16 - r2_keras: -110.3805 - rmse: 0.9184 - sae: 2651.3555 - sse: 3454.8831\n","Epoch 56: val_loss improved from 0.22162 to 0.22150, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - huber_loss: 0.0407 - loss: 0.1766 - mae: 0.1636 - mse: 0.0919 - pearson_correlation: 9.6115e-17 - r2_keras: -90.4960 - rmse: 0.9055 - sae: 1937.3712 - sse: 2505.5090 - val_huber_loss: 0.0898 - val_loss: 0.2215 - val_mae: 0.2657 - val_mse: 0.1971 - val_pearson_correlation: -1.3773e-16 - val_r2_keras: -34.8464 - val_rmse: 0.9750 - val_sae: 366.1461 - val_sse: 502.8571 - learning_rate: 5.0182e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0513 - loss: 0.1830 - mae: 0.1754 - mse: 0.1053 - pearson_correlation: 3.6013e-16 - r2_keras: -110.4342 - rmse: 0.9186 - sae: 2651.5493 - sse: 3456.5491\n","Epoch 57: val_loss improved from 0.22150 to 0.22118, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.0406 - loss: 0.1765 - mae: 0.1631 - mse: 0.0917 - pearson_correlation: 2.6322e-16 - r2_keras: -90.5414 - rmse: 0.9057 - sae: 1937.5161 - sse: 2506.7324 - val_huber_loss: 0.0896 - val_loss: 0.2212 - val_mae: 0.2652 - val_mse: 0.1963 - val_pearson_correlation: 2.4326e-16 - val_r2_keras: -34.8894 - val_rmse: 0.9756 - val_sae: 366.3079 - val_sse: 503.4598 - learning_rate: 5.0182e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0512 - loss: 0.1828 - mae: 0.1751 - mse: 0.1051 - pearson_correlation: -6.7731e-16 - r2_keras: -110.4759 - rmse: 0.9188 - sae: 2651.8286 - sse: 3457.8428\n","Epoch 58: val_loss improved from 0.22118 to 0.22098, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0405 - loss: 0.1763 - mae: 0.1628 - mse: 0.0915 - pearson_correlation: -5.5259e-16 - r2_keras: -90.5796 - rmse: 0.9059 - sae: 1937.7303 - sse: 2507.7158 - val_huber_loss: 0.0894 - val_loss: 0.2210 - val_mae: 0.2649 - val_mse: 0.1958 - val_pearson_correlation: 2.4291e-16 - val_r2_keras: -34.9255 - val_rmse: 0.9761 - val_sae: 366.5897 - val_sse: 503.9662 - learning_rate: 5.0182e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0511 - loss: 0.1827 - mae: 0.1750 - mse: 0.1049 - pearson_correlation: 1.0445e-15 - r2_keras: -110.4556 - rmse: 0.9187 - sae: 2651.3848 - sse: 3457.2141\n","Epoch 59: val_loss improved from 0.22098 to 0.22079, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.0404 - loss: 0.1762 - mae: 0.1628 - mse: 0.0913 - pearson_correlation: 7.8104e-16 - r2_keras: -90.5800 - rmse: 0.9060 - sae: 1937.4823 - sse: 2507.4600 - val_huber_loss: 0.0893 - val_loss: 0.2208 - val_mae: 0.2649 - val_mse: 0.1955 - val_pearson_correlation: 1.5839e-16 - val_r2_keras: -34.9299 - val_rmse: 0.9761 - val_sae: 366.5909 - val_sse: 504.0284 - learning_rate: 5.0182e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0511 - loss: 0.1825 - mae: 0.1747 - mse: 0.1047 - pearson_correlation: -5.4520e-16 - r2_keras: -110.4891 - rmse: 0.9189 - sae: 2652.0669 - sse: 3458.2515\n","Epoch 60: val_loss did not improve from 0.22079\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0404 - loss: 0.1760 - mae: 0.1625 - mse: 0.0911 - pearson_correlation: -3.3867e-16 - r2_keras: -90.6130 - rmse: 0.9062 - sae: 1937.9811 - sse: 2508.2773 - val_huber_loss: 0.0895 - val_loss: 0.2209 - val_mae: 0.2650 - val_mse: 0.1955 - val_pearson_correlation: 5.2447e-17 - val_r2_keras: -35.1012 - val_rmse: 0.9784 - val_sae: 367.5354 - val_sse: 506.4322 - learning_rate: 5.0182e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0510 - loss: 0.1824 - mae: 0.1744 - mse: 0.1044 - pearson_correlation: 1.2584e-16 - r2_keras: -110.4416 - rmse: 0.9187 - sae: 2651.1399 - sse: 3456.7803\n","Epoch 61: val_loss improved from 0.22079 to 0.22077, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0403 - loss: 0.1759 - mae: 0.1622 - mse: 0.0909 - pearson_correlation: 3.1840e-17 - r2_keras: -90.6129 - rmse: 0.9063 - sae: 1937.4943 - sse: 2507.6663 - val_huber_loss: 0.0895 - val_loss: 0.2208 - val_mae: 0.2651 - val_mse: 0.1955 - val_pearson_correlation: -1.3662e-16 - val_r2_keras: -35.0535 - val_rmse: 0.9778 - val_sae: 367.1944 - val_sse: 505.7625 - learning_rate: 5.0182e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0509 - loss: 0.1822 - mae: 0.1741 - mse: 0.1043 - pearson_correlation: 3.8690e-16 - r2_keras: -110.5624 - rmse: 0.9192 - sae: 2652.2151 - sse: 3460.5264\n","Epoch 62: val_loss improved from 0.22077 to 0.22071, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - huber_loss: 0.0402 - loss: 0.1757 - mae: 0.1619 - mse: 0.0907 - pearson_correlation: 1.9138e-16 - r2_keras: -90.6958 - rmse: 0.9067 - sae: 1938.1942 - sse: 2510.1919 - val_huber_loss: 0.0895 - val_loss: 0.2207 - val_mae: 0.2652 - val_mse: 0.1954 - val_pearson_correlation: -5.2507e-17 - val_r2_keras: -35.0719 - val_rmse: 0.9780 - val_sae: 367.4723 - val_sse: 506.0211 - learning_rate: 5.0182e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0508 - loss: 0.1821 - mae: 0.1742 - mse: 0.1041 - pearson_correlation: -1.0781e-16 - r2_keras: -110.5226 - rmse: 0.9190 - sae: 2651.6785 - sse: 3459.2910\n","Epoch 63: val_loss improved from 0.22071 to 0.22045, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - huber_loss: 0.0401 - loss: 0.1755 - mae: 0.1619 - mse: 0.0906 - pearson_correlation: -5.6529e-17 - r2_keras: -90.6859 - rmse: 0.9067 - sae: 1937.9127 - sse: 2509.5637 - val_huber_loss: 0.0893 - val_loss: 0.2205 - val_mae: 0.2649 - val_mse: 0.1950 - val_pearson_correlation: -2.8381e-16 - val_r2_keras: -35.0489 - val_rmse: 0.9777 - val_sae: 367.1575 - val_sse: 505.6979 - learning_rate: 5.0182e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0507 - loss: 0.1819 - mae: 0.1739 - mse: 0.1039 - pearson_correlation: -6.5585e-16 - r2_keras: -110.5716 - rmse: 0.9192 - sae: 2652.2500 - sse: 3460.8130\n","Epoch 64: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0400 - loss: 0.1754 - mae: 0.1616 - mse: 0.0904 - pearson_correlation: -4.3723e-16 - r2_keras: -90.7261 - rmse: 0.9069 - sae: 1938.3152 - sse: 2510.6655 - val_huber_loss: 0.0898 - val_loss: 0.2209 - val_mae: 0.2658 - val_mse: 0.1960 - val_pearson_correlation: -4.1783e-17 - val_r2_keras: -35.2100 - val_rmse: 0.9799 - val_sae: 368.2107 - val_sse: 507.9576 - learning_rate: 5.0182e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0507 - loss: 0.1817 - mae: 0.1736 - mse: 0.1037 - pearson_correlation: -2.5186e-17 - r2_keras: -110.5664 - rmse: 0.9192 - sae: 2651.8750 - sse: 3460.6504\n","Epoch 65: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0400 - loss: 0.1752 - mae: 0.1614 - mse: 0.0902 - pearson_correlation: -2.0194e-17 - r2_keras: -90.7452 - rmse: 0.9071 - sae: 1938.1489 - sse: 2510.8232 - val_huber_loss: 0.0898 - val_loss: 0.2208 - val_mae: 0.2661 - val_mse: 0.1960 - val_pearson_correlation: -3.1406e-17 - val_r2_keras: -35.1532 - val_rmse: 0.9791 - val_sae: 367.8458 - val_sse: 507.1616 - learning_rate: 5.0182e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0506 - loss: 0.1816 - mae: 0.1733 - mse: 0.1035 - pearson_correlation: 8.7651e-16 - r2_keras: -110.6584 - rmse: 0.9196 - sae: 2652.9688 - sse: 3463.5049\n","Epoch 66: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0399 - loss: 0.1751 - mae: 0.1610 - mse: 0.0900 - pearson_correlation: 5.8434e-16 - r2_keras: -90.8083 - rmse: 0.9074 - sae: 1938.8651 - sse: 2512.7458 - val_huber_loss: 0.0898 - val_loss: 0.2207 - val_mae: 0.2662 - val_mse: 0.1961 - val_pearson_correlation: -9.4323e-17 - val_r2_keras: -35.1252 - val_rmse: 0.9788 - val_sae: 367.6611 - val_sse: 506.7680 - learning_rate: 5.0182e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0505 - loss: 0.1814 - mae: 0.1732 - mse: 0.1033 - pearson_correlation: -1.1158e-17 - r2_keras: -110.6218 - rmse: 0.9194 - sae: 2652.4529 - sse: 3462.3679\n","Epoch 67: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0398 - loss: 0.1749 - mae: 0.1609 - mse: 0.0898 - pearson_correlation: -5.9296e-17 - r2_keras: -90.7933 - rmse: 0.9073 - sae: 1938.5411 - sse: 2512.0991 - val_huber_loss: 0.0898 - val_loss: 0.2207 - val_mae: 0.2662 - val_mse: 0.1960 - val_pearson_correlation: 8.3801e-17 - val_r2_keras: -35.1371 - val_rmse: 0.9789 - val_sae: 367.9106 - val_sse: 506.9349 - learning_rate: 5.0182e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0504 - loss: 0.1813 - mae: 0.1730 - mse: 0.1032 - pearson_correlation: -6.8448e-16 - r2_keras: -110.7406 - rmse: 0.9199 - sae: 2653.5156 - sse: 3466.0552\n","Epoch 68: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0397 - loss: 0.1747 - mae: 0.1607 - mse: 0.0897 - pearson_correlation: -4.6822e-16 - r2_keras: -90.8776 - rmse: 0.9077 - sae: 1939.2664 - sse: 2514.6165 - val_huber_loss: 0.0902 - val_loss: 0.2210 - val_mae: 0.2669 - val_mse: 0.1967 - val_pearson_correlation: 6.2546e-17 - val_r2_keras: -35.2635 - val_rmse: 0.9806 - val_sae: 368.5890 - val_sse: 508.7086 - learning_rate: 5.0182e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0503 - loss: 0.1811 - mae: 0.1727 - mse: 0.1029 - pearson_correlation: 3.8305e-16 - r2_keras: -110.6777 - rmse: 0.9196 - sae: 2652.6987 - sse: 3464.1040\n","Epoch 69: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0396 - loss: 0.1746 - mae: 0.1604 - mse: 0.0894 - pearson_correlation: 2.5622e-16 - r2_keras: -90.8622 - rmse: 0.9078 - sae: 1938.8497 - sse: 2513.6272 - val_huber_loss: 0.0902 - val_loss: 0.2210 - val_mae: 0.2671 - val_mse: 0.1967 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.2910 - val_rmse: 0.9810 - val_sae: 368.7413 - val_sse: 509.0936 - learning_rate: 1.0036e-05\n","Epoch 70/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0503 - loss: 0.1811 - mae: 0.1727 - mse: 0.1029 - pearson_correlation: -3.0574e-16 - r2_keras: -110.6855 - rmse: 0.9197 - sae: 2652.7676 - sse: 3464.3450\n","Epoch 70: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0396 - loss: 0.1745 - mae: 0.1603 - mse: 0.0894 - pearson_correlation: -2.2674e-16 - r2_keras: -90.8682 - rmse: 0.9078 - sae: 1938.8951 - sse: 2513.7976 - val_huber_loss: 0.0902 - val_loss: 0.2209 - val_mae: 0.2671 - val_mse: 0.1966 - val_pearson_correlation: -2.0818e-17 - val_r2_keras: -35.3029 - val_rmse: 0.9812 - val_sae: 368.7931 - val_sse: 509.2617 - learning_rate: 1.0036e-05\n","Epoch 71/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0503 - loss: 0.1810 - mae: 0.1726 - mse: 0.1028 - pearson_correlation: 5.2850e-16 - r2_keras: -110.6867 - rmse: 0.9197 - sae: 2652.7515 - sse: 3464.3821\n","Epoch 71: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0396 - loss: 0.1745 - mae: 0.1603 - mse: 0.0893 - pearson_correlation: 3.9560e-16 - r2_keras: -90.8694 - rmse: 0.9078 - sae: 1938.8807 - sse: 2513.8269 - val_huber_loss: 0.0902 - val_loss: 0.2209 - val_mae: 0.2672 - val_mse: 0.1966 - val_pearson_correlation: -1.2489e-16 - val_r2_keras: -35.3068 - val_rmse: 0.9812 - val_sae: 368.8039 - val_sse: 509.3162 - learning_rate: 1.0036e-05\n","Epoch 72/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0503 - loss: 0.1810 - mae: 0.1726 - mse: 0.1028 - pearson_correlation: -7.0709e-16 - r2_keras: -110.6970 - rmse: 0.9197 - sae: 2652.8389 - sse: 3464.7009\n","Epoch 72: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0396 - loss: 0.1745 - mae: 0.1602 - mse: 0.0893 - pearson_correlation: -4.2898e-16 - r2_keras: -90.8778 - rmse: 0.9078 - sae: 1938.9408 - sse: 2514.0571 - val_huber_loss: 0.0901 - val_loss: 0.2208 - val_mae: 0.2672 - val_mse: 0.1965 - val_pearson_correlation: -2.7060e-16 - val_r2_keras: -35.3057 - val_rmse: 0.9812 - val_sae: 368.7861 - val_sse: 509.3001 - learning_rate: 1.0036e-05\n","Epoch 73/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0502 - loss: 0.1809 - mae: 0.1726 - mse: 0.1027 - pearson_correlation: 1.1045e-16 - r2_keras: -110.7055 - rmse: 0.9197 - sae: 2652.9006 - sse: 3464.9663\n","Epoch 73: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0395 - loss: 0.1744 - mae: 0.1602 - mse: 0.0892 - pearson_correlation: 5.3274e-17 - r2_keras: -90.8835 - rmse: 0.9079 - sae: 1938.9767 - sse: 2514.2341 - val_huber_loss: 0.0901 - val_loss: 0.2208 - val_mae: 0.2672 - val_mse: 0.1964 - val_pearson_correlation: 5.1002e-16 - val_r2_keras: -35.3043 - val_rmse: 0.9812 - val_sae: 368.7595 - val_sse: 509.2804 - learning_rate: 1.0036e-05\n","Epoch 74/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0502 - loss: 0.1809 - mae: 0.1725 - mse: 0.1027 - pearson_correlation: -2.5696e-16 - r2_keras: -110.6976 - rmse: 0.9197 - sae: 2652.7781 - sse: 3464.7202\n","Epoch 74: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0395 - loss: 0.1744 - mae: 0.1602 - mse: 0.0892 - pearson_correlation: -1.3908e-16 - r2_keras: -90.8807 - rmse: 0.9079 - sae: 1938.9036 - sse: 2514.0989 - val_huber_loss: 0.0901 - val_loss: 0.2207 - val_mae: 0.2672 - val_mse: 0.1963 - val_pearson_correlation: -4.1648e-17 - val_r2_keras: -35.2956 - val_rmse: 0.9811 - val_sae: 368.6966 - val_sse: 509.1579 - learning_rate: 1.0000e-05\n","Epoch 75/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0502 - loss: 0.1809 - mae: 0.1725 - mse: 0.1026 - pearson_correlation: 7.4852e-16 - r2_keras: -110.7046 - rmse: 0.9197 - sae: 2652.8320 - sse: 3464.9370\n","Epoch 75: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0395 - loss: 0.1744 - mae: 0.1601 - mse: 0.0892 - pearson_correlation: 4.0233e-16 - r2_keras: -90.8862 - rmse: 0.9079 - sae: 1938.9388 - sse: 2514.2534 - val_huber_loss: 0.0900 - val_loss: 0.2207 - val_mae: 0.2672 - val_mse: 0.1962 - val_pearson_correlation: -1.0412e-16 - val_r2_keras: -35.2951 - val_rmse: 0.9811 - val_sae: 368.6853 - val_sse: 509.1510 - learning_rate: 1.0000e-05\n","Epoch 76/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0502 - loss: 0.1808 - mae: 0.1724 - mse: 0.1026 - pearson_correlation: -5.1537e-16 - r2_keras: -110.7157 - rmse: 0.9198 - sae: 2652.9033 - sse: 3465.2798\n","Epoch 76: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0395 - loss: 0.1743 - mae: 0.1600 - mse: 0.0891 - pearson_correlation: -3.4273e-16 - r2_keras: -90.8954 - rmse: 0.9079 - sae: 1938.9913 - sse: 2514.5042 - val_huber_loss: 0.0900 - val_loss: 0.2207 - val_mae: 0.2672 - val_mse: 0.1962 - val_pearson_correlation: 1.0415e-16 - val_r2_keras: -35.2882 - val_rmse: 0.9810 - val_sae: 368.6832 - val_sse: 509.0555 - learning_rate: 1.0000e-05\n","Epoch 77/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0502 - loss: 0.1808 - mae: 0.1724 - mse: 0.1026 - pearson_correlation: 3.1890e-17 - r2_keras: -110.7056 - rmse: 0.9197 - sae: 2652.7720 - sse: 3464.9678\n","Epoch 77: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0395 - loss: 0.1743 - mae: 0.1600 - mse: 0.0891 - pearson_correlation: -2.6230e-17 - r2_keras: -90.8883 - rmse: 0.9079 - sae: 1938.9006 - sse: 2514.2908 - val_huber_loss: 0.0900 - val_loss: 0.2206 - val_mae: 0.2672 - val_mse: 0.1961 - val_pearson_correlation: 3.5416e-16 - val_r2_keras: -35.2844 - val_rmse: 0.9809 - val_sae: 368.6569 - val_sse: 509.0014 - learning_rate: 1.0000e-05\n","Epoch 78/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0501 - loss: 0.1808 - mae: 0.1724 - mse: 0.1025 - pearson_correlation: 3.6321e-16 - r2_keras: -110.7117 - rmse: 0.9198 - sae: 2652.8313 - sse: 3465.1580\n","Epoch 78: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0394 - loss: 0.1742 - mae: 0.1600 - mse: 0.0890 - pearson_correlation: 3.0235e-16 - r2_keras: -90.8934 - rmse: 0.9079 - sae: 1938.9392 - sse: 2514.4302 - val_huber_loss: 0.0899 - val_loss: 0.2206 - val_mae: 0.2672 - val_mse: 0.1960 - val_pearson_correlation: -7.2934e-17 - val_r2_keras: -35.2779 - val_rmse: 0.9808 - val_sae: 368.5971 - val_sse: 508.9108 - learning_rate: 1.0000e-05\n","Epoch 79/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0501 - loss: 0.1807 - mae: 0.1723 - mse: 0.1025 - pearson_correlation: -1.6230e-16 - r2_keras: -110.7068 - rmse: 0.9198 - sae: 2652.7334 - sse: 3465.0061\n","Epoch 79: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0394 - loss: 0.1742 - mae: 0.1599 - mse: 0.0890 - pearson_correlation: -1.3872e-16 - r2_keras: -90.8918 - rmse: 0.9079 - sae: 1938.8788 - sse: 2514.3481 - val_huber_loss: 0.0899 - val_loss: 0.2205 - val_mae: 0.2671 - val_mse: 0.1960 - val_pearson_correlation: -4.3785e-16 - val_r2_keras: -35.2634 - val_rmse: 0.9806 - val_sae: 368.4871 - val_sse: 508.7069 - learning_rate: 1.0000e-05\n","Epoch 80/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0501 - loss: 0.1807 - mae: 0.1723 - mse: 0.1024 - pearson_correlation: -1.0371e-16 - r2_keras: -110.7058 - rmse: 0.9198 - sae: 2652.7261 - sse: 3464.9736\n","Epoch 80: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0394 - loss: 0.1742 - mae: 0.1599 - mse: 0.0889 - pearson_correlation: -7.2484e-18 - r2_keras: -90.8928 - rmse: 0.9079 - sae: 1938.8727 - sse: 2514.3467 - val_huber_loss: 0.0899 - val_loss: 0.2205 - val_mae: 0.2672 - val_mse: 0.1959 - val_pearson_correlation: 4.2733e-16 - val_r2_keras: -35.2689 - val_rmse: 0.9807 - val_sae: 368.5606 - val_sse: 508.7843 - learning_rate: 1.0000e-05\n","Epoch 81/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0501 - loss: 0.1807 - mae: 0.1723 - mse: 0.1024 - pearson_correlation: -4.6275e-16 - r2_keras: -110.7145 - rmse: 0.9198 - sae: 2652.7424 - sse: 3465.2451\n","Epoch 81: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0394 - loss: 0.1741 - mae: 0.1598 - mse: 0.0889 - pearson_correlation: -3.5258e-16 - r2_keras: -90.9011 - rmse: 0.9080 - sae: 1938.8966 - sse: 2514.5566 - val_huber_loss: 0.0899 - val_loss: 0.2205 - val_mae: 0.2672 - val_mse: 0.1959 - val_pearson_correlation: -6.2549e-17 - val_r2_keras: -35.2633 - val_rmse: 0.9806 - val_sae: 368.5329 - val_sse: 508.7054 - learning_rate: 1.0000e-05\n","Epoch 82/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0501 - loss: 0.1806 - mae: 0.1722 - mse: 0.1023 - pearson_correlation: 2.4882e-16 - r2_keras: -110.7344 - rmse: 0.9199 - sae: 2652.9478 - sse: 3465.8604\n","Epoch 82: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0394 - loss: 0.1741 - mae: 0.1598 - mse: 0.0889 - pearson_correlation: 1.5995e-16 - r2_keras: -90.9154 - rmse: 0.9080 - sae: 1939.0361 - sse: 2514.9795 - val_huber_loss: 0.0900 - val_loss: 0.2206 - val_mae: 0.2674 - val_mse: 0.1961 - val_pearson_correlation: -3.9558e-16 - val_r2_keras: -35.3008 - val_rmse: 0.9811 - val_sae: 368.7603 - val_sse: 509.2313 - learning_rate: 1.0000e-05\n","Epoch 83/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0500 - loss: 0.1806 - mae: 0.1722 - mse: 0.1023 - pearson_correlation: 2.5768e-16 - r2_keras: -110.7180 - rmse: 0.9198 - sae: 2652.7314 - sse: 3465.3525\n","Epoch 83: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0394 - loss: 0.1741 - mae: 0.1597 - mse: 0.0888 - pearson_correlation: 1.5992e-16 - r2_keras: -90.9087 - rmse: 0.9080 - sae: 1938.9061 - sse: 2514.6895 - val_huber_loss: 0.0900 - val_loss: 0.2205 - val_mae: 0.2674 - val_mse: 0.1961 - val_pearson_correlation: -1.7708e-16 - val_r2_keras: -35.2842 - val_rmse: 0.9809 - val_sae: 368.6478 - val_sse: 508.9984 - learning_rate: 1.0000e-05\n","Epoch 84/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0500 - loss: 0.1805 - mae: 0.1721 - mse: 0.1022 - pearson_correlation: 4.0437e-16 - r2_keras: -110.7271 - rmse: 0.9198 - sae: 2652.8257 - sse: 3465.6350\n","Epoch 84: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0393 - loss: 0.1740 - mae: 0.1597 - mse: 0.0888 - pearson_correlation: 3.0516e-16 - r2_keras: -90.9166 - rmse: 0.9081 - sae: 1938.9701 - sse: 2514.8997 - val_huber_loss: 0.0900 - val_loss: 0.2205 - val_mae: 0.2675 - val_mse: 0.1961 - val_pearson_correlation: 2.0831e-17 - val_r2_keras: -35.2869 - val_rmse: 0.9809 - val_sae: 368.7024 - val_sse: 509.0360 - learning_rate: 1.0000e-05\n","Epoch 85/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0500 - loss: 0.1805 - mae: 0.1721 - mse: 0.1022 - pearson_correlation: -1.5033e-16 - r2_keras: -110.7337 - rmse: 0.9199 - sae: 2652.8469 - sse: 3465.8403\n","Epoch 85: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0393 - loss: 0.1740 - mae: 0.1597 - mse: 0.0888 - pearson_correlation: -1.4852e-16 - r2_keras: -90.9216 - rmse: 0.9081 - sae: 1938.9849 - sse: 2515.0432 - val_huber_loss: 0.0900 - val_loss: 0.2205 - val_mae: 0.2674 - val_mse: 0.1961 - val_pearson_correlation: -6.2523e-17 - val_r2_keras: -35.2742 - val_rmse: 0.9808 - val_sae: 368.6187 - val_sse: 508.8581 - learning_rate: 1.0000e-05\n","Epoch 86/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0500 - loss: 0.1805 - mae: 0.1721 - mse: 0.1022 - pearson_correlation: 3.3696e-18 - r2_keras: -110.7318 - rmse: 0.9199 - sae: 2652.8181 - sse: 3465.7798\n","Epoch 86: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0393 - loss: 0.1740 - mae: 0.1596 - mse: 0.0887 - pearson_correlation: 6.5781e-17 - r2_keras: -90.9231 - rmse: 0.9081 - sae: 1938.9769 - sse: 2515.0359 - val_huber_loss: 0.0900 - val_loss: 0.2205 - val_mae: 0.2674 - val_mse: 0.1961 - val_pearson_correlation: -3.2309e-16 - val_r2_keras: -35.2703 - val_rmse: 0.9807 - val_sae: 368.5962 - val_sse: 508.8038 - learning_rate: 1.0000e-05\n","Epoch 87/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0500 - loss: 0.1804 - mae: 0.1720 - mse: 0.1021 - pearson_correlation: 1.2181e-16 - r2_keras: -110.7392 - rmse: 0.9199 - sae: 2652.8640 - sse: 3466.0103\n","Epoch 87: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0393 - loss: 0.1739 - mae: 0.1596 - mse: 0.0887 - pearson_correlation: 2.7836e-17 - r2_keras: -90.9269 - rmse: 0.9081 - sae: 1939.0012 - sse: 2515.1758 - val_huber_loss: 0.0901 - val_loss: 0.2205 - val_mae: 0.2676 - val_mse: 0.1962 - val_pearson_correlation: 4.8932e-16 - val_r2_keras: -35.2981 - val_rmse: 0.9811 - val_sae: 368.7602 - val_sse: 509.1938 - learning_rate: 1.0000e-05\n","Epoch 88/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0500 - loss: 0.1804 - mae: 0.1720 - mse: 0.1021 - pearson_correlation: 2.2652e-16 - r2_keras: -110.7387 - rmse: 0.9199 - sae: 2652.8306 - sse: 3465.9946\n","Epoch 88: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0393 - loss: 0.1739 - mae: 0.1595 - mse: 0.0886 - pearson_correlation: 1.2053e-16 - r2_keras: -90.9328 - rmse: 0.9082 - sae: 1938.9995 - sse: 2515.2385 - val_huber_loss: 0.0901 - val_loss: 0.2205 - val_mae: 0.2676 - val_mse: 0.1963 - val_pearson_correlation: 2.1868e-16 - val_r2_keras: -35.2925 - val_rmse: 0.9810 - val_sae: 368.7320 - val_sse: 509.1156 - learning_rate: 1.0000e-05\n","Epoch 89/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0499 - loss: 0.1804 - mae: 0.1719 - mse: 0.1021 - pearson_correlation: -4.8588e-16 - r2_keras: -110.7547 - rmse: 0.9200 - sae: 2652.9795 - sse: 3466.4900\n","Epoch 89: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0392 - loss: 0.1739 - mae: 0.1595 - mse: 0.0886 - pearson_correlation: -2.8327e-16 - r2_keras: -90.9436 - rmse: 0.9082 - sae: 1939.0938 - sse: 2515.5710 - val_huber_loss: 0.0901 - val_loss: 0.2205 - val_mae: 0.2677 - val_mse: 0.1963 - val_pearson_correlation: -1.1457e-16 - val_r2_keras: -35.2868 - val_rmse: 0.9809 - val_sae: 368.7365 - val_sse: 509.0351 - learning_rate: 1.0000e-05\n","Epoch 90/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0499 - loss: 0.1803 - mae: 0.1719 - mse: 0.1020 - pearson_correlation: -4.0636e-16 - r2_keras: -110.7466 - rmse: 0.9199 - sae: 2652.8604 - sse: 3466.2407\n","Epoch 90: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - huber_loss: 0.0392 - loss: 0.1738 - mae: 0.1594 - mse: 0.0886 - pearson_correlation: -3.2171e-16 - r2_keras: -90.9396 - rmse: 0.9082 - sae: 1939.0206 - sse: 2515.4204 - val_huber_loss: 0.0901 - val_loss: 0.2205 - val_mae: 0.2677 - val_mse: 0.1963 - val_pearson_correlation: -6.0436e-16 - val_r2_keras: -35.2757 - val_rmse: 0.9808 - val_sae: 368.6635 - val_sse: 508.8795 - learning_rate: 1.0000e-05\n","Epoch 91/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0499 - loss: 0.1803 - mae: 0.1719 - mse: 0.1020 - pearson_correlation: 1.7932e-16 - r2_keras: -110.7535 - rmse: 0.9199 - sae: 2652.9282 - sse: 3466.4546\n","Epoch 91: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0392 - loss: 0.1738 - mae: 0.1594 - mse: 0.0885 - pearson_correlation: 9.0757e-17 - r2_keras: -90.9437 - rmse: 0.9082 - sae: 1939.0612 - sse: 2515.5574 - val_huber_loss: 0.0902 - val_loss: 0.2206 - val_mae: 0.2679 - val_mse: 0.1964 - val_pearson_correlation: -4.1631e-17 - val_r2_keras: -35.3064 - val_rmse: 0.9812 - val_sae: 368.8388 - val_sse: 509.3104 - learning_rate: 1.0000e-05\n","Epoch 92/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0499 - loss: 0.1803 - mae: 0.1718 - mse: 0.1019 - pearson_correlation: -1.0574e-16 - r2_keras: -110.7443 - rmse: 0.9199 - sae: 2652.8127 - sse: 3466.1680\n","Epoch 92: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - huber_loss: 0.0392 - loss: 0.1738 - mae: 0.1594 - mse: 0.0885 - pearson_correlation: -8.3190e-17 - r2_keras: -90.9429 - rmse: 0.9082 - sae: 1939.0021 - sse: 2515.4290 - val_huber_loss: 0.0902 - val_loss: 0.2205 - val_mae: 0.2678 - val_mse: 0.1965 - val_pearson_correlation: 4.1648e-16 - val_r2_keras: -35.2956 - val_rmse: 0.9811 - val_sae: 368.7780 - val_sse: 509.1587 - learning_rate: 1.0000e-05\n","Epoch 93/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0499 - loss: 0.1802 - mae: 0.1718 - mse: 0.1019 - pearson_correlation: 1.0545e-16 - r2_keras: -110.7666 - rmse: 0.9200 - sae: 2653.0283 - sse: 3466.8594\n","Epoch 93: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0392 - loss: 0.1737 - mae: 0.1593 - mse: 0.0884 - pearson_correlation: 8.5122e-18 - r2_keras: -90.9594 - rmse: 0.9083 - sae: 1939.1503 - sse: 2515.9092 - val_huber_loss: 0.0902 - val_loss: 0.2205 - val_mae: 0.2679 - val_mse: 0.1965 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.2978 - val_rmse: 0.9811 - val_sae: 368.8258 - val_sse: 509.1897 - learning_rate: 1.0000e-05\n","Epoch 94/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0499 - loss: 0.1802 - mae: 0.1717 - mse: 0.1019 - pearson_correlation: -6.8919e-16 - r2_keras: -110.7691 - rmse: 0.9200 - sae: 2653.0117 - sse: 3466.9380\n","Epoch 94: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0392 - loss: 0.1737 - mae: 0.1593 - mse: 0.0884 - pearson_correlation: -5.2802e-16 - r2_keras: -90.9620 - rmse: 0.9083 - sae: 1939.1425 - sse: 2515.9722 - val_huber_loss: 0.0902 - val_loss: 0.2205 - val_mae: 0.2679 - val_mse: 0.1965 - val_pearson_correlation: 1.1460e-16 - val_r2_keras: -35.2791 - val_rmse: 0.9808 - val_sae: 368.7148 - val_sse: 508.9269 - learning_rate: 1.0000e-05\n","Epoch 95/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0498 - loss: 0.1802 - mae: 0.1717 - mse: 0.1018 - pearson_correlation: -6.9956e-18 - r2_keras: -110.7682 - rmse: 0.9200 - sae: 2653.0291 - sse: 3466.9114\n","Epoch 95: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0391 - loss: 0.1737 - mae: 0.1592 - mse: 0.0884 - pearson_correlation: 5.0348e-17 - r2_keras: -90.9627 - rmse: 0.9083 - sae: 1939.1593 - sse: 2515.9700 - val_huber_loss: 0.0902 - val_loss: 0.2205 - val_mae: 0.2680 - val_mse: 0.1965 - val_pearson_correlation: 1.1445e-16 - val_r2_keras: -35.3145 - val_rmse: 0.9813 - val_sae: 368.9009 - val_sse: 509.4243 - learning_rate: 1.0000e-05\n","Epoch 96/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0498 - loss: 0.1801 - mae: 0.1716 - mse: 0.1018 - pearson_correlation: -1.3940e-16 - r2_keras: -110.7628 - rmse: 0.9200 - sae: 2652.8950 - sse: 3466.7434\n","Epoch 96: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0391 - loss: 0.1736 - mae: 0.1592 - mse: 0.0883 - pearson_correlation: -9.1242e-17 - r2_keras: -90.9624 - rmse: 0.9084 - sae: 1939.0773 - sse: 2515.8970 - val_huber_loss: 0.0902 - val_loss: 0.2205 - val_mae: 0.2681 - val_mse: 0.1966 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.3099 - val_rmse: 0.9813 - val_sae: 368.8847 - val_sse: 509.3588 - learning_rate: 1.0000e-05\n","Epoch 97/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - huber_loss: 0.0498 - loss: 0.1801 - mae: 0.1716 - mse: 0.1017 - pearson_correlation: -6.2175e-18 - r2_keras: -110.7809 - rmse: 0.9201 - sae: 2653.0981 - sse: 3467.3030\n","Epoch 97: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0391 - loss: 0.1736 - mae: 0.1591 - mse: 0.0883 - pearson_correlation: 4.3156e-18 - r2_keras: -90.9764 - rmse: 0.9084 - sae: 1939.2177 - sse: 2516.2922 - val_huber_loss: 0.0902 - val_loss: 0.2205 - val_mae: 0.2681 - val_mse: 0.1966 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -35.3011 - val_rmse: 0.9811 - val_sae: 368.8508 - val_sse: 509.2357 - learning_rate: 1.0000e-05\n","Epoch 98/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0498 - loss: 0.1801 - mae: 0.1716 - mse: 0.1017 - pearson_correlation: -5.2330e-17 - r2_keras: -110.7816 - rmse: 0.9201 - sae: 2653.1841 - sse: 3467.3247\n","Epoch 98: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0391 - loss: 0.1736 - mae: 0.1591 - mse: 0.0882 - pearson_correlation: 6.4535e-19 - r2_keras: -90.9779 - rmse: 0.9084 - sae: 1939.2754 - sse: 2516.3196 - val_huber_loss: 0.0903 - val_loss: 0.2205 - val_mae: 0.2681 - val_mse: 0.1966 - val_pearson_correlation: 6.2477e-17 - val_r2_keras: -35.2934 - val_rmse: 0.9810 - val_sae: 368.8428 - val_sse: 509.1283 - learning_rate: 1.0000e-05\n","Epoch 99/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0498 - loss: 0.1800 - mae: 0.1716 - mse: 0.1017 - pearson_correlation: 1.7484e-16 - r2_keras: -110.7971 - rmse: 0.9201 - sae: 2653.3115 - sse: 3467.8074\n","Epoch 99: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0391 - loss: 0.1735 - mae: 0.1590 - mse: 0.0882 - pearson_correlation: 2.5192e-16 - r2_keras: -90.9881 - rmse: 0.9085 - sae: 1939.3602 - sse: 2516.6392 - val_huber_loss: 0.0903 - val_loss: 0.2206 - val_mae: 0.2683 - val_mse: 0.1968 - val_pearson_correlation: 2.0803e-17 - val_r2_keras: -35.3225 - val_rmse: 0.9814 - val_sae: 369.0065 - val_sse: 509.5359 - learning_rate: 1.0000e-05\n","Epoch 100/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0498 - loss: 0.1800 - mae: 0.1715 - mse: 0.1016 - pearson_correlation: -3.9170e-16 - r2_keras: -110.7822 - rmse: 0.9201 - sae: 2653.1299 - sse: 3467.3425\n","Epoch 100: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0391 - loss: 0.1735 - mae: 0.1590 - mse: 0.0882 - pearson_correlation: -2.3576e-16 - r2_keras: -90.9833 - rmse: 0.9085 - sae: 1939.2582 - sse: 2516.3901 - val_huber_loss: 0.0904 - val_loss: 0.2206 - val_mae: 0.2683 - val_mse: 0.1969 - val_pearson_correlation: -1.2487e-16 - val_r2_keras: -35.3107 - val_rmse: 0.9813 - val_sae: 368.9413 - val_sse: 509.3709 - learning_rate: 1.0000e-05\n","Epoch 101/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0497 - loss: 0.1800 - mae: 0.1715 - mse: 0.1016 - pearson_correlation: -3.4579e-16 - r2_keras: -110.7960 - rmse: 0.9201 - sae: 2653.2729 - sse: 3467.7734\n","Epoch 101: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0390 - loss: 0.1735 - mae: 0.1589 - mse: 0.0881 - pearson_correlation: -1.8571e-16 - r2_keras: -90.9934 - rmse: 0.9085 - sae: 1939.3531 - sse: 2516.6868 - val_huber_loss: 0.0904 - val_loss: 0.2206 - val_mae: 0.2683 - val_mse: 0.1968 - val_pearson_correlation: -5.7241e-16 - val_r2_keras: -35.3074 - val_rmse: 0.9812 - val_sae: 368.9192 - val_sse: 509.3235 - learning_rate: 1.0000e-05\n","Epoch 102/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0497 - loss: 0.1799 - mae: 0.1714 - mse: 0.1015 - pearson_correlation: -1.0184e-15 - r2_keras: -110.8026 - rmse: 0.9201 - sae: 2653.3000 - sse: 3467.9766\n","Epoch 102: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0390 - loss: 0.1734 - mae: 0.1589 - mse: 0.0881 - pearson_correlation: -7.4404e-16 - r2_keras: -90.9994 - rmse: 0.9086 - sae: 1939.3756 - sse: 2516.8416 - val_huber_loss: 0.0905 - val_loss: 0.2207 - val_mae: 0.2686 - val_mse: 0.1971 - val_pearson_correlation: -1.8710e-16 - val_r2_keras: -35.3394 - val_rmse: 0.9817 - val_sae: 369.1613 - val_sse: 509.7736 - learning_rate: 1.0000e-05\n","Epoch 103/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0497 - loss: 0.1799 - mae: 0.1714 - mse: 0.1015 - pearson_correlation: -4.0010e-16 - r2_keras: -110.8170 - rmse: 0.9202 - sae: 2653.4238 - sse: 3468.4243\n","Epoch 103: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0390 - loss: 0.1734 - mae: 0.1588 - mse: 0.0881 - pearson_correlation: -2.7688e-16 - r2_keras: -91.0112 - rmse: 0.9086 - sae: 1939.4705 - sse: 2517.1658 - val_huber_loss: 0.0905 - val_loss: 0.2207 - val_mae: 0.2685 - val_mse: 0.1971 - val_pearson_correlation: -2.4964e-16 - val_r2_keras: -35.3221 - val_rmse: 0.9814 - val_sae: 369.0370 - val_sse: 509.5305 - learning_rate: 1.0000e-05\n","Epoch 104/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0497 - loss: 0.1799 - mae: 0.1714 - mse: 0.1014 - pearson_correlation: -2.2095e-16 - r2_keras: -110.7948 - rmse: 0.9201 - sae: 2653.2205 - sse: 3467.7339\n","Epoch 104: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0390 - loss: 0.1734 - mae: 0.1588 - mse: 0.0880 - pearson_correlation: -2.2508e-16 - r2_keras: -90.9974 - rmse: 0.9086 - sae: 1939.3302 - sse: 2516.7175 - val_huber_loss: 0.0904 - val_loss: 0.2206 - val_mae: 0.2685 - val_mse: 0.1970 - val_pearson_correlation: 8.3231e-17 - val_r2_keras: -35.3161 - val_rmse: 0.9813 - val_sae: 368.9951 - val_sse: 509.4465 - learning_rate: 1.0000e-05\n","Epoch 105/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0497 - loss: 0.1798 - mae: 0.1713 - mse: 0.1014 - pearson_correlation: 3.8042e-16 - r2_keras: -110.8172 - rmse: 0.9202 - sae: 2653.4106 - sse: 3468.4282\n","Epoch 105: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0390 - loss: 0.1733 - mae: 0.1588 - mse: 0.0880 - pearson_correlation: 2.7813e-16 - r2_keras: -91.0136 - rmse: 0.9086 - sae: 1939.4608 - sse: 2517.1960 - val_huber_loss: 0.0904 - val_loss: 0.2206 - val_mae: 0.2685 - val_mse: 0.1970 - val_pearson_correlation: -1.0406e-17 - val_r2_keras: -35.3118 - val_rmse: 0.9813 - val_sae: 368.9618 - val_sse: 509.3858 - learning_rate: 1.0000e-05\n","Epoch 106/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0496 - loss: 0.1798 - mae: 0.1713 - mse: 0.1014 - pearson_correlation: -4.2909e-16 - r2_keras: -110.8192 - rmse: 0.9202 - sae: 2653.4001 - sse: 3468.4902\n","Epoch 106: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0390 - loss: 0.1733 - mae: 0.1587 - mse: 0.0879 - pearson_correlation: -3.0466e-16 - r2_keras: -91.0168 - rmse: 0.9087 - sae: 1939.4612 - sse: 2517.2585 - val_huber_loss: 0.0905 - val_loss: 0.2207 - val_mae: 0.2688 - val_mse: 0.1972 - val_pearson_correlation: -5.1965e-17 - val_r2_keras: -35.3438 - val_rmse: 0.9817 - val_sae: 369.2022 - val_sse: 509.8340 - learning_rate: 1.0000e-05\n","Epoch 107/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0496 - loss: 0.1798 - mae: 0.1712 - mse: 0.1013 - pearson_correlation: -3.9984e-16 - r2_keras: -110.8165 - rmse: 0.9202 - sae: 2653.3350 - sse: 3468.4094\n","Epoch 107: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0390 - loss: 0.1733 - mae: 0.1587 - mse: 0.0879 - pearson_correlation: -2.6064e-16 - r2_keras: -91.0183 - rmse: 0.9087 - sae: 1939.4337 - sse: 2517.2422 - val_huber_loss: 0.0905 - val_loss: 0.2207 - val_mae: 0.2687 - val_mse: 0.1972 - val_pearson_correlation: -3.4319e-16 - val_r2_keras: -35.3266 - val_rmse: 0.9815 - val_sae: 369.0891 - val_sse: 509.5941 - learning_rate: 1.0000e-05\n","Epoch 108/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0496 - loss: 0.1797 - mae: 0.1712 - mse: 0.1013 - pearson_correlation: -2.1258e-16 - r2_keras: -110.8319 - rmse: 0.9203 - sae: 2653.5046 - sse: 3468.8862\n","Epoch 108: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0389 - loss: 0.1732 - mae: 0.1586 - mse: 0.0879 - pearson_correlation: -1.0031e-16 - r2_keras: -91.0298 - rmse: 0.9087 - sae: 1939.5463 - sse: 2517.5754 - val_huber_loss: 0.0905 - val_loss: 0.2206 - val_mae: 0.2687 - val_mse: 0.1972 - val_pearson_correlation: -1.5601e-16 - val_r2_keras: -35.3237 - val_rmse: 0.9814 - val_sae: 369.0789 - val_sse: 509.5526 - learning_rate: 1.0000e-05\n","Epoch 109/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0496 - loss: 0.1797 - mae: 0.1712 - mse: 0.1012 - pearson_correlation: 5.6549e-16 - r2_keras: -110.8308 - rmse: 0.9203 - sae: 2653.4851 - sse: 3468.8508\n","Epoch 109: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0389 - loss: 0.1732 - mae: 0.1586 - mse: 0.0878 - pearson_correlation: 4.4882e-16 - r2_keras: -91.0305 - rmse: 0.9087 - sae: 1939.5389 - sse: 2517.5688 - val_huber_loss: 0.0905 - val_loss: 0.2206 - val_mae: 0.2687 - val_mse: 0.1972 - val_pearson_correlation: -9.3654e-17 - val_r2_keras: -35.3109 - val_rmse: 0.9813 - val_sae: 368.9952 - val_sse: 509.3735 - learning_rate: 1.0000e-05\n","Epoch 110/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0496 - loss: 0.1797 - mae: 0.1711 - mse: 0.1012 - pearson_correlation: 1.8409e-16 - r2_keras: -110.8358 - rmse: 0.9203 - sae: 2653.5210 - sse: 3469.0054\n","Epoch 110: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0389 - loss: 0.1732 - mae: 0.1585 - mse: 0.0878 - pearson_correlation: 1.2695e-16 - r2_keras: -91.0338 - rmse: 0.9088 - sae: 1939.5583 - sse: 2517.6716 - val_huber_loss: 0.0907 - val_loss: 0.2207 - val_mae: 0.2690 - val_mse: 0.1975 - val_pearson_correlation: 1.1431e-16 - val_r2_keras: -35.3464 - val_rmse: 0.9818 - val_sae: 369.2633 - val_sse: 509.8709 - learning_rate: 1.0000e-05\n","Epoch 111/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0496 - loss: 0.1796 - mae: 0.1711 - mse: 0.1012 - pearson_correlation: -6.0580e-16 - r2_keras: -110.8445 - rmse: 0.9203 - sae: 2653.5938 - sse: 3469.2749\n","Epoch 111: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0389 - loss: 0.1731 - mae: 0.1585 - mse: 0.0878 - pearson_correlation: -4.0893e-16 - r2_keras: -91.0430 - rmse: 0.9088 - sae: 1939.6241 - sse: 2517.8914 - val_huber_loss: 0.0906 - val_loss: 0.2207 - val_mae: 0.2689 - val_mse: 0.1974 - val_pearson_correlation: -3.4306e-16 - val_r2_keras: -35.3369 - val_rmse: 0.9816 - val_sae: 369.1753 - val_sse: 509.7375 - learning_rate: 1.0000e-05\n","Epoch 112/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0495 - loss: 0.1796 - mae: 0.1711 - mse: 0.1011 - pearson_correlation: 5.4092e-16 - r2_keras: -110.8263 - rmse: 0.9202 - sae: 2653.4282 - sse: 3468.7126\n","Epoch 112: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0389 - loss: 0.1731 - mae: 0.1585 - mse: 0.0877 - pearson_correlation: 3.9018e-16 - r2_keras: -91.0311 - rmse: 0.9088 - sae: 1939.5060 - sse: 2517.5186 - val_huber_loss: 0.0906 - val_loss: 0.2207 - val_mae: 0.2690 - val_mse: 0.1975 - val_pearson_correlation: 4.5762e-16 - val_r2_keras: -35.3246 - val_rmse: 0.9815 - val_sae: 369.1116 - val_sse: 509.5650 - learning_rate: 1.0000e-05\n","Epoch 113/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0495 - loss: 0.1796 - mae: 0.1710 - mse: 0.1011 - pearson_correlation: 5.8770e-17 - r2_keras: -110.8411 - rmse: 0.9203 - sae: 2653.5837 - sse: 3469.1702\n","Epoch 113: val_loss did not improve from 0.22045\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0388 - loss: 0.1731 - mae: 0.1584 - mse: 0.0877 - pearson_correlation: 7.7189e-17 - r2_keras: -91.0436 - rmse: 0.9088 - sae: 1939.6202 - sse: 2517.8550 - val_huber_loss: 0.0906 - val_loss: 0.2206 - val_mae: 0.2690 - val_mse: 0.1974 - val_pearson_correlation: 1.3525e-16 - val_r2_keras: -35.3168 - val_rmse: 0.9814 - val_sae: 369.0581 - val_sse: 509.4557 - learning_rate: 1.0000e-05\n","| \u001b[35m19       \u001b[39m | \u001b[35m-0.2206  \u001b[39m | \u001b[35m0.006273 \u001b[39m | \u001b[35m89.01    \u001b[39m | \u001b[35m56.46    \u001b[39m | \u001b[35m70.9     \u001b[39m | \u001b[35m7.268    \u001b[39m | \u001b[35m78.74    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.5999 - loss: 0.7702 - mae: 1.0106 - mse: 1.5208 - pearson_correlation: -4.0963e-17 - r2_keras: -235.5647 - rmse: 1.3385 - sae: 4431.6221 - sse: 7337.9404\n","Epoch 1: val_loss improved from inf to 0.41378, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621ms/step - huber_loss: 0.5163 - loss: 0.7193 - mae: 0.9494 - mse: 1.3879 - pearson_correlation: -3.1923e-17 - r2_keras: -193.4226 - rmse: 1.3202 - sae: 3226.2307 - sse: 5322.6021 - val_huber_loss: 0.2435 - val_loss: 0.4138 - val_mae: 0.5944 - val_mse: 0.5898 - val_pearson_correlation: -2.2536e-16 - val_r2_keras: -22.1982 - val_rmse: 0.7843 - val_sae: 322.5951 - val_sse: 325.4265 - learning_rate: 2.0531e-04\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.2531 - loss: 0.4234 - mae: 0.5830 - mse: 0.5708 - pearson_correlation: 6.2757e-17 - r2_keras: -145.7644 - rmse: 1.0542 - sae: 3328.8245 - sse: 4552.4492\n","Epoch 2: val_loss improved from 0.41378 to 0.40269, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.2485 - loss: 0.4206 - mae: 0.5725 - mse: 0.5706 - pearson_correlation: 1.2923e-16 - r2_keras: -123.8183 - rmse: 1.0696 - sae: 2442.1245 - sse: 3351.3875 - val_huber_loss: 0.2324 - val_loss: 0.4027 - val_mae: 0.5615 - val_mse: 0.5710 - val_pearson_correlation: -1.6254e-16 - val_r2_keras: -22.3593 - val_rmse: 0.7870 - val_sae: 311.5607 - val_sse: 327.6864 - learning_rate: 2.0531e-04\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1986 - loss: 0.3689 - mae: 0.4962 - mse: 0.4413 - pearson_correlation: 9.0837e-17 - r2_keras: -134.0982 - rmse: 1.0115 - sae: 3136.1021 - sse: 4190.5771\n","Epoch 3: val_loss improved from 0.40269 to 0.39815, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - huber_loss: 0.1896 - loss: 0.3634 - mae: 0.4778 - mse: 0.4315 - pearson_correlation: 6.1828e-17 - r2_keras: -112.8533 - rmse: 1.0188 - sae: 2297.6501 - sse: 3072.7502 - val_huber_loss: 0.2279 - val_loss: 0.3981 - val_mae: 0.5237 - val_mse: 0.5702 - val_pearson_correlation: -1.6168e-17 - val_r2_keras: -23.4614 - val_rmse: 0.8054 - val_sae: 298.8656 - val_sse: 343.1473 - learning_rate: 2.0531e-04\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1536 - loss: 0.3238 - mae: 0.4201 - mse: 0.3350 - pearson_correlation: -3.0304e-16 - r2_keras: -117.2296 - rmse: 0.9462 - sae: 2869.5786 - sse: 3667.3354\n","Epoch 4: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1468 - loss: 0.3197 - mae: 0.4053 - mse: 0.3272 - pearson_correlation: -1.5183e-16 - r2_keras: -99.1453 - rmse: 0.9569 - sae: 2108.0061 - sse: 2695.0393 - val_huber_loss: 0.2358 - val_loss: 0.4060 - val_mae: 0.5058 - val_mse: 0.5937 - val_pearson_correlation: -1.0564e-16 - val_r2_keras: -26.3306 - val_rmse: 0.8513 - val_sae: 299.5457 - val_sse: 383.3965 - learning_rate: 2.0531e-04\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1368 - loss: 0.3070 - mae: 0.3800 - mse: 0.3022 - pearson_correlation: 2.2714e-16 - r2_keras: -120.4556 - rmse: 0.9590 - sae: 2867.3240 - sse: 3767.3997\n","Epoch 5: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1292 - loss: 0.3024 - mae: 0.3690 - mse: 0.2935 - pearson_correlation: 1.1384e-16 - r2_keras: -99.6106 - rmse: 0.9523 - sae: 2098.4985 - sse: 2741.9800 - val_huber_loss: 0.2679 - val_loss: 0.4381 - val_mae: 0.5696 - val_mse: 0.6681 - val_pearson_correlation: -1.6824e-16 - val_r2_keras: -30.8288 - val_rmse: 0.9187 - val_sae: 331.2523 - val_sse: 446.4985 - learning_rate: 2.0531e-04\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1190 - loss: 0.2893 - mae: 0.3464 - mse: 0.2568 - pearson_correlation: -1.6572e-16 - r2_keras: -111.1430 - rmse: 0.9215 - sae: 2765.2798 - sse: 3478.5347\n","Epoch 6: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1110 - loss: 0.2844 - mae: 0.3353 - mse: 0.2469 - pearson_correlation: -6.5596e-17 - r2_keras: -93.4941 - rmse: 0.9281 - sae: 2029.1222 - sse: 2550.4819 - val_huber_loss: 0.3041 - val_loss: 0.4743 - val_mae: 0.6369 - val_mse: 0.7409 - val_pearson_correlation: -5.0032e-18 - val_r2_keras: -34.8476 - val_rmse: 0.9750 - val_sae: 366.3665 - val_sse: 502.8742 - learning_rate: 2.0531e-04\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.1062 - loss: 0.2764 - mae: 0.3192 - mse: 0.2250 - pearson_correlation: 1.1629e-16 - r2_keras: -109.3550 - rmse: 0.9142 - sae: 2735.5596 - sse: 3423.0757\n","Epoch 7: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0983 - loss: 0.2716 - mae: 0.3097 - mse: 0.2158 - pearson_correlation: 1.0624e-16 - r2_keras: -91.0450 - rmse: 0.9130 - sae: 2003.0575 - sse: 2498.7622 - val_huber_loss: 0.3199 - val_loss: 0.4902 - val_mae: 0.6742 - val_mse: 0.7645 - val_pearson_correlation: 2.4520e-16 - val_r2_keras: -36.5354 - val_rmse: 0.9977 - val_sae: 387.9873 - val_sse: 526.5500 - learning_rate: 2.0531e-04\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0972 - loss: 0.2674 - mae: 0.3013 - mse: 0.2030 - pearson_correlation: -2.8244e-16 - r2_keras: -107.3804 - rmse: 0.9060 - sae: 2713.5542 - sse: 3361.8240\n","Epoch 8: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0885 - loss: 0.2621 - mae: 0.2910 - mse: 0.1926 - pearson_correlation: -1.6151e-16 - r2_keras: -89.9590 - rmse: 0.9094 - sae: 1987.5433 - sse: 2460.6309 - val_huber_loss: 0.3079 - val_loss: 0.4781 - val_mae: 0.6738 - val_mse: 0.7110 - val_pearson_correlation: 1.2540e-16 - val_r2_keras: -35.8014 - val_rmse: 0.9879 - val_sae: 397.8644 - val_sse: 516.2536 - learning_rate: 2.0531e-04\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0908 - loss: 0.2610 - mae: 0.2913 - mse: 0.1880 - pearson_correlation: -7.4503e-16 - r2_keras: -107.1765 - rmse: 0.9051 - sae: 2705.9717 - sse: 3355.4995\n","Epoch 9: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0790 - loss: 0.2538 - mae: 0.2754 - mse: 0.1727 - pearson_correlation: -5.4429e-16 - r2_keras: -89.6812 - rmse: 0.9077 - sae: 1980.7672 - sse: 2454.7507 - val_huber_loss: 0.2880 - val_loss: 0.4582 - val_mae: 0.6301 - val_mse: 0.6466 - val_pearson_correlation: 1.7109e-16 - val_r2_keras: -34.3961 - val_rmse: 0.9688 - val_sae: 392.2994 - val_sse: 496.5406 - learning_rate: 4.1061e-05\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0879 - loss: 0.2581 - mae: 0.2872 - mse: 0.1813 - pearson_correlation: 3.6676e-16 - r2_keras: -105.5810 - rmse: 0.8984 - sae: 2689.3018 - sse: 3306.0088\n","Epoch 10: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0763 - loss: 0.2510 - mae: 0.2711 - mse: 0.1663 - pearson_correlation: 2.7996e-16 - r2_keras: -88.3415 - rmse: 0.9009 - sae: 1968.0452 - sse: 2418.5193 - val_huber_loss: 0.2739 - val_loss: 0.4441 - val_mae: 0.6261 - val_mse: 0.5980 - val_pearson_correlation: -4.3456e-16 - val_r2_keras: -35.5073 - val_rmse: 0.9839 - val_sae: 397.4666 - val_sse: 512.1288 - learning_rate: 4.1061e-05\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0859 - loss: 0.2561 - mae: 0.2841 - mse: 0.1766 - pearson_correlation: -5.3414e-16 - r2_keras: -104.9389 - rmse: 0.8957 - sae: 2681.9058 - sse: 3286.0913\n","Epoch 11: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0744 - loss: 0.2491 - mae: 0.2680 - mse: 0.1619 - pearson_correlation: -3.5203e-16 - r2_keras: -87.7433 - rmse: 0.8977 - sae: 1962.1261 - sse: 2403.2446 - val_huber_loss: 0.2708 - val_loss: 0.4410 - val_mae: 0.6131 - val_mse: 0.5982 - val_pearson_correlation: -1.3838e-16 - val_r2_keras: -38.9657 - val_rmse: 1.0295 - val_sae: 407.6751 - val_sse: 560.6428 - learning_rate: 4.1061e-05\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0841 - loss: 0.2542 - mae: 0.2809 - mse: 0.1724 - pearson_correlation: 8.2898e-16 - r2_keras: -104.6385 - rmse: 0.8944 - sae: 2677.1199 - sse: 3276.7732\n","Epoch 12: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0727 - loss: 0.2473 - mae: 0.2647 - mse: 0.1579 - pearson_correlation: 5.4773e-16 - r2_keras: -87.3878 - rmse: 0.8956 - sae: 1958.1512 - sse: 2395.2117 - val_huber_loss: 0.2730 - val_loss: 0.4432 - val_mae: 0.6008 - val_mse: 0.6326 - val_pearson_correlation: 2.1502e-16 - val_r2_keras: -43.4804 - val_rmse: 1.0861 - val_sae: 421.9524 - val_sse: 623.9753 - learning_rate: 4.1061e-05\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0823 - loss: 0.2525 - mae: 0.2781 - mse: 0.1685 - pearson_correlation: -1.9695e-16 - r2_keras: -104.2936 - rmse: 0.8930 - sae: 2672.4575 - sse: 3266.0771\n","Epoch 13: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0710 - loss: 0.2456 - mae: 0.2616 - mse: 0.1541 - pearson_correlation: -1.3953e-16 - r2_keras: -87.1152 - rmse: 0.8943 - sae: 1954.7257 - sse: 2387.5808 - val_huber_loss: 0.2635 - val_loss: 0.4337 - val_mae: 0.5746 - val_mse: 0.6430 - val_pearson_correlation: -1.7712e-16 - val_r2_keras: -46.9464 - val_rmse: 1.1276 - val_sae: 429.3773 - val_sse: 672.5977 - learning_rate: 4.1061e-05\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0806 - loss: 0.2508 - mae: 0.2752 - mse: 0.1647 - pearson_correlation: 4.2767e-16 - r2_keras: -104.0928 - rmse: 0.8921 - sae: 2669.2026 - sse: 3259.8477\n","Epoch 14: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0689 - loss: 0.2437 - mae: 0.2579 - mse: 0.1498 - pearson_correlation: 2.1963e-16 - r2_keras: -87.0673 - rmse: 0.8944 - sae: 1953.0067 - sse: 2384.4360 - val_huber_loss: 0.2552 - val_loss: 0.4254 - val_mae: 0.5480 - val_mse: 0.6363 - val_pearson_correlation: -7.5079e-18 - val_r2_keras: -48.4520 - val_rmse: 1.1452 - val_sae: 431.4375 - val_sse: 693.7186 - learning_rate: 1.0000e-05\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0801 - loss: 0.2502 - mae: 0.2743 - mse: 0.1635 - pearson_correlation: 1.3664e-16 - r2_keras: -103.9902 - rmse: 0.8917 - sae: 2668.0791 - sse: 3256.6636\n","Epoch 15: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0685 - loss: 0.2432 - mae: 0.2571 - mse: 0.1488 - pearson_correlation: 1.1079e-16 - r2_keras: -86.9494 - rmse: 0.8937 - sae: 1952.0216 - sse: 2381.7332 - val_huber_loss: 0.2553 - val_loss: 0.4255 - val_mae: 0.5416 - val_mse: 0.6430 - val_pearson_correlation: -3.2477e-16 - val_r2_keras: -49.6484 - val_rmse: 1.1589 - val_sae: 434.3368 - val_sse: 710.5019 - learning_rate: 1.0000e-05\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0796 - loss: 0.2498 - mae: 0.2735 - mse: 0.1625 - pearson_correlation: -4.0526e-17 - r2_keras: -103.9073 - rmse: 0.8913 - sae: 2667.1143 - sse: 3254.0938\n","Epoch 16: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0680 - loss: 0.2427 - mae: 0.2563 - mse: 0.1478 - pearson_correlation: -3.4415e-17 - r2_keras: -86.8720 - rmse: 0.8933 - sae: 1951.2557 - sse: 2379.7598 - val_huber_loss: 0.2575 - val_loss: 0.4276 - val_mae: 0.5385 - val_mse: 0.6521 - val_pearson_correlation: -5.8255e-17 - val_r2_keras: -50.6396 - val_rmse: 1.1702 - val_sae: 436.9354 - val_sse: 724.4062 - learning_rate: 1.0000e-05\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0792 - loss: 0.2493 - mae: 0.2727 - mse: 0.1615 - pearson_correlation: -1.5154e-16 - r2_keras: -103.8357 - rmse: 0.8910 - sae: 2666.2446 - sse: 3251.8708\n","Epoch 17: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0676 - loss: 0.2423 - mae: 0.2554 - mse: 0.1468 - pearson_correlation: -1.6356e-16 - r2_keras: -86.8040 - rmse: 0.8929 - sae: 1950.5674 - sse: 2378.0400 - val_huber_loss: 0.2589 - val_loss: 0.4291 - val_mae: 0.5340 - val_mse: 0.6579 - val_pearson_correlation: -1.4384e-16 - val_r2_keras: -51.5108 - val_rmse: 1.1800 - val_sae: 439.7931 - val_sse: 736.6277 - learning_rate: 1.0000e-05\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0787 - loss: 0.2489 - mae: 0.2718 - mse: 0.1605 - pearson_correlation: 1.5022e-16 - r2_keras: -103.7822 - rmse: 0.8908 - sae: 2665.5886 - sse: 3250.2119\n","Epoch 18: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0671 - loss: 0.2418 - mae: 0.2545 - mse: 0.1458 - pearson_correlation: 1.4134e-16 - r2_keras: -86.7478 - rmse: 0.8926 - sae: 1950.0216 - sse: 2376.6943 - val_huber_loss: 0.2606 - val_loss: 0.4308 - val_mae: 0.5339 - val_mse: 0.6629 - val_pearson_correlation: -1.2108e-16 - val_r2_keras: -52.1719 - val_rmse: 1.1874 - val_sae: 442.5818 - val_sse: 745.9013 - learning_rate: 1.0000e-05\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0782 - loss: 0.2483 - mae: 0.2710 - mse: 0.1593 - pearson_correlation: 4.3391e-16 - r2_keras: -103.7516 - rmse: 0.8907 - sae: 2665.2104 - sse: 3249.2651\n","Epoch 19: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0666 - loss: 0.2413 - mae: 0.2536 - mse: 0.1446 - pearson_correlation: 2.4061e-16 - r2_keras: -86.7091 - rmse: 0.8923 - sae: 1949.6769 - sse: 2375.8474 - val_huber_loss: 0.2616 - val_loss: 0.4318 - val_mae: 0.5327 - val_mse: 0.6656 - val_pearson_correlation: -7.7788e-17 - val_r2_keras: -52.6297 - val_rmse: 1.1925 - val_sae: 445.0601 - val_sse: 752.3234 - learning_rate: 1.0000e-05\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0776 - loss: 0.2478 - mae: 0.2701 - mse: 0.1580 - pearson_correlation: -4.4809e-16 - r2_keras: -103.7328 - rmse: 0.8906 - sae: 2664.9873 - sse: 3248.6807\n","Epoch 20: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0661 - loss: 0.2408 - mae: 0.2526 - mse: 0.1435 - pearson_correlation: -2.7726e-16 - r2_keras: -86.6769 - rmse: 0.8921 - sae: 1949.4376 - sse: 2375.2278 - val_huber_loss: 0.2622 - val_loss: 0.4324 - val_mae: 0.5323 - val_mse: 0.6665 - val_pearson_correlation: 3.2421e-16 - val_r2_keras: -52.8464 - val_rmse: 1.1950 - val_sae: 446.6082 - val_sse: 755.3627 - learning_rate: 1.0000e-05\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0770 - loss: 0.2472 - mae: 0.2690 - mse: 0.1566 - pearson_correlation: 5.0157e-16 - r2_keras: -103.7003 - rmse: 0.8904 - sae: 2664.4968 - sse: 3247.6738\n","Epoch 21: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0656 - loss: 0.2402 - mae: 0.2517 - mse: 0.1422 - pearson_correlation: 3.6502e-16 - r2_keras: -86.6075 - rmse: 0.8916 - sae: 1948.8971 - sse: 2373.9958 - val_huber_loss: 0.2627 - val_loss: 0.4329 - val_mae: 0.5323 - val_mse: 0.6676 - val_pearson_correlation: -2.5975e-16 - val_r2_keras: -53.0782 - val_rmse: 1.1975 - val_sae: 448.1132 - val_sse: 758.6144 - learning_rate: 1.0000e-05\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0765 - loss: 0.2466 - mae: 0.2680 - mse: 0.1554 - pearson_correlation: -3.6694e-16 - r2_keras: -103.7141 - rmse: 0.8905 - sae: 2664.5439 - sse: 3248.1016\n","Epoch 22: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0650 - loss: 0.2397 - mae: 0.2506 - mse: 0.1410 - pearson_correlation: -1.9077e-16 - r2_keras: -86.6067 - rmse: 0.8916 - sae: 1948.8838 - sse: 2374.1641 - val_huber_loss: 0.2629 - val_loss: 0.4330 - val_mae: 0.5321 - val_mse: 0.6678 - val_pearson_correlation: 2.0303e-16 - val_r2_keras: -53.2361 - val_rmse: 1.1993 - val_sae: 449.1876 - val_sse: 760.8297 - learning_rate: 1.0000e-05\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0759 - loss: 0.2461 - mae: 0.2670 - mse: 0.1542 - pearson_correlation: -1.6550e-16 - r2_keras: -103.7409 - rmse: 0.8906 - sae: 2664.7100 - sse: 3248.9331\n","Epoch 23: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0645 - loss: 0.2391 - mae: 0.2496 - mse: 0.1398 - pearson_correlation: -1.0038e-16 - r2_keras: -86.6101 - rmse: 0.8915 - sae: 1948.9291 - sse: 2374.5486 - val_huber_loss: 0.2629 - val_loss: 0.4330 - val_mae: 0.5318 - val_mse: 0.6674 - val_pearson_correlation: -2.0274e-16 - val_r2_keras: -53.3180 - val_rmse: 1.2002 - val_sae: 449.8449 - val_sse: 761.9792 - learning_rate: 1.0000e-05\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0754 - loss: 0.2455 - mae: 0.2660 - mse: 0.1531 - pearson_correlation: -2.4355e-16 - r2_keras: -103.7535 - rmse: 0.8907 - sae: 2664.8750 - sse: 3249.3220\n","Epoch 24: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0640 - loss: 0.2386 - mae: 0.2485 - mse: 0.1387 - pearson_correlation: -2.2043e-16 - r2_keras: -86.6124 - rmse: 0.8915 - sae: 1949.0054 - sse: 2374.7366 - val_huber_loss: 0.2626 - val_loss: 0.4328 - val_mae: 0.5320 - val_mse: 0.6661 - val_pearson_correlation: -2.5891e-16 - val_r2_keras: -53.2644 - val_rmse: 1.1996 - val_sae: 449.7649 - val_sse: 761.2272 - learning_rate: 1.0000e-05\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0748 - loss: 0.2449 - mae: 0.2650 - mse: 0.1517 - pearson_correlation: -6.4496e-16 - r2_keras: -103.7838 - rmse: 0.8908 - sae: 2665.0383 - sse: 3250.2612\n","Epoch 25: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0634 - loss: 0.2380 - mae: 0.2476 - mse: 0.1374 - pearson_correlation: -3.5512e-16 - r2_keras: -86.5878 - rmse: 0.8912 - sae: 1948.9348 - sse: 2374.8376 - val_huber_loss: 0.2625 - val_loss: 0.4327 - val_mae: 0.5314 - val_mse: 0.6655 - val_pearson_correlation: 1.3979e-16 - val_r2_keras: -53.3149 - val_rmse: 1.2001 - val_sae: 450.1795 - val_sse: 761.9352 - learning_rate: 1.0000e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0743 - loss: 0.2444 - mae: 0.2640 - mse: 0.1505 - pearson_correlation: 1.4508e-16 - r2_keras: -103.7954 - rmse: 0.8908 - sae: 2665.2068 - sse: 3250.6216\n","Epoch 26: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0629 - loss: 0.2375 - mae: 0.2465 - mse: 0.1363 - pearson_correlation: 1.6494e-16 - r2_keras: -86.5918 - rmse: 0.8912 - sae: 1949.0333 - sse: 2375.0339 - val_huber_loss: 0.2622 - val_loss: 0.4324 - val_mae: 0.5308 - val_mse: 0.6645 - val_pearson_correlation: 1.1876e-16 - val_r2_keras: -53.3442 - val_rmse: 1.2005 - val_sae: 450.4471 - val_sse: 762.3461 - learning_rate: 1.0000e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0738 - loss: 0.2439 - mae: 0.2630 - mse: 0.1495 - pearson_correlation: -2.0642e-16 - r2_keras: -103.8212 - rmse: 0.8910 - sae: 2665.2959 - sse: 3251.4224\n","Epoch 27: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0624 - loss: 0.2370 - mae: 0.2455 - mse: 0.1353 - pearson_correlation: -2.4460e-17 - r2_keras: -86.6056 - rmse: 0.8913 - sae: 1949.0616 - sse: 2375.5273 - val_huber_loss: 0.2620 - val_loss: 0.4321 - val_mae: 0.5303 - val_mse: 0.6636 - val_pearson_correlation: -1.5358e-16 - val_r2_keras: -53.3738 - val_rmse: 1.2008 - val_sae: 450.6983 - val_sse: 762.7617 - learning_rate: 1.0000e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0733 - loss: 0.2434 - mae: 0.2621 - mse: 0.1484 - pearson_correlation: -3.4294e-16 - r2_keras: -103.9006 - rmse: 0.8913 - sae: 2666.1548 - sse: 3253.8838\n","Epoch 28: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0619 - loss: 0.2365 - mae: 0.2445 - mse: 0.1342 - pearson_correlation: -2.0699e-16 - r2_keras: -86.6574 - rmse: 0.8915 - sae: 1949.6398 - sse: 2377.1555 - val_huber_loss: 0.2616 - val_loss: 0.4317 - val_mae: 0.5301 - val_mse: 0.6619 - val_pearson_correlation: -4.1948e-17 - val_r2_keras: -53.2683 - val_rmse: 1.1996 - val_sae: 450.2211 - val_sse: 761.2819 - learning_rate: 1.0000e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0728 - loss: 0.2429 - mae: 0.2609 - mse: 0.1473 - pearson_correlation: -1.1093e-15 - r2_keras: -103.8979 - rmse: 0.8913 - sae: 2665.9707 - sse: 3253.8022\n","Epoch 29: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0614 - loss: 0.2360 - mae: 0.2434 - mse: 0.1331 - pearson_correlation: -7.0115e-16 - r2_keras: -86.6176 - rmse: 0.8912 - sae: 1949.3422 - sse: 2376.6548 - val_huber_loss: 0.2614 - val_loss: 0.4315 - val_mae: 0.5295 - val_mse: 0.6612 - val_pearson_correlation: -2.7960e-16 - val_r2_keras: -53.2711 - val_rmse: 1.1997 - val_sae: 450.2852 - val_sse: 761.3207 - learning_rate: 1.0000e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0723 - loss: 0.2425 - mae: 0.2600 - mse: 0.1463 - pearson_correlation: -1.4520e-16 - r2_keras: -103.8749 - rmse: 0.8912 - sae: 2665.6208 - sse: 3253.0884\n","Epoch 30: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0610 - loss: 0.2356 - mae: 0.2424 - mse: 0.1322 - pearson_correlation: -8.5122e-17 - r2_keras: -86.5979 - rmse: 0.8911 - sae: 1949.0881 - sse: 2376.1274 - val_huber_loss: 0.2606 - val_loss: 0.4307 - val_mae: 0.5278 - val_mse: 0.6593 - val_pearson_correlation: 1.6746e-16 - val_r2_keras: -53.3620 - val_rmse: 1.2007 - val_sae: 450.7521 - val_sse: 762.5957 - learning_rate: 1.0000e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0718 - loss: 0.2420 - mae: 0.2589 - mse: 0.1453 - pearson_correlation: 6.4238e-16 - r2_keras: -104.0197 - rmse: 0.8918 - sae: 2666.6936 - sse: 3257.5808\n","Epoch 31: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0605 - loss: 0.2351 - mae: 0.2413 - mse: 0.1312 - pearson_correlation: 4.5327e-16 - r2_keras: -86.7024 - rmse: 0.8916 - sae: 1949.8368 - sse: 2379.2158 - val_huber_loss: 0.2602 - val_loss: 0.4303 - val_mae: 0.5280 - val_mse: 0.6574 - val_pearson_correlation: -2.3088e-16 - val_r2_keras: -53.1987 - val_rmse: 1.1989 - val_sae: 449.9458 - val_sse: 760.3057 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0713 - loss: 0.2414 - mae: 0.2580 - mse: 0.1442 - pearson_correlation: -1.1441e-16 - r2_keras: -103.9534 - rmse: 0.8915 - sae: 2665.9946 - sse: 3255.5247\n","Epoch 32: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0600 - loss: 0.2346 - mae: 0.2406 - mse: 0.1301 - pearson_correlation: -4.0380e-17 - r2_keras: -86.6391 - rmse: 0.8912 - sae: 1949.2694 - sse: 2377.6211 - val_huber_loss: 0.2599 - val_loss: 0.4300 - val_mae: 0.5272 - val_mse: 0.6566 - val_pearson_correlation: -2.7961e-17 - val_r2_keras: -53.2346 - val_rmse: 1.1993 - val_sae: 450.1601 - val_sse: 760.8089 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0708 - loss: 0.2410 - mae: 0.2569 - mse: 0.1432 - pearson_correlation: 1.4717e-16 - r2_keras: -104.0197 - rmse: 0.8918 - sae: 2666.4780 - sse: 3257.5798\n","Epoch 33: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0596 - loss: 0.2341 - mae: 0.2395 - mse: 0.1292 - pearson_correlation: 4.6380e-17 - r2_keras: -86.6888 - rmse: 0.8914 - sae: 1949.6132 - sse: 2379.0557 - val_huber_loss: 0.2595 - val_loss: 0.4296 - val_mae: 0.5263 - val_mse: 0.6554 - val_pearson_correlation: -3.4948e-16 - val_r2_keras: -53.2337 - val_rmse: 1.1992 - val_sae: 450.0965 - val_sse: 760.7959 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0704 - loss: 0.2405 - mae: 0.2560 - mse: 0.1422 - pearson_correlation: 9.6349e-17 - r2_keras: -104.0062 - rmse: 0.8917 - sae: 2666.2244 - sse: 3257.1597\n","Epoch 34: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0592 - loss: 0.2337 - mae: 0.2386 - mse: 0.1282 - pearson_correlation: 1.0093e-16 - r2_keras: -86.6874 - rmse: 0.8915 - sae: 1949.4542 - sse: 2378.8660 - val_huber_loss: 0.2591 - val_loss: 0.4292 - val_mae: 0.5262 - val_mse: 0.6536 - val_pearson_correlation: 1.9604e-16 - val_r2_keras: -53.1141 - val_rmse: 1.1979 - val_sae: 449.4921 - val_sse: 759.1187 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0699 - loss: 0.2400 - mae: 0.2549 - mse: 0.1411 - pearson_correlation: -3.6517e-17 - r2_keras: -104.0037 - rmse: 0.8917 - sae: 2666.0762 - sse: 3257.0830\n","Epoch 35: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0587 - loss: 0.2332 - mae: 0.2377 - mse: 0.1272 - pearson_correlation: 2.3767e-18 - r2_keras: -86.6660 - rmse: 0.8913 - sae: 1949.2672 - sse: 2378.5823 - val_huber_loss: 0.2588 - val_loss: 0.4289 - val_mae: 0.5252 - val_mse: 0.6528 - val_pearson_correlation: 4.1983e-17 - val_r2_keras: -53.1396 - val_rmse: 1.1982 - val_sae: 449.4861 - val_sse: 759.4758 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0694 - loss: 0.2395 - mae: 0.2538 - mse: 0.1400 - pearson_correlation: -3.2679e-16 - r2_keras: -104.0459 - rmse: 0.8919 - sae: 2666.2920 - sse: 3258.3914\n","Epoch 36: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0583 - loss: 0.2327 - mae: 0.2366 - mse: 0.1263 - pearson_correlation: -2.1702e-16 - r2_keras: -86.7044 - rmse: 0.8915 - sae: 1949.4381 - sse: 2379.5754 - val_huber_loss: 0.2586 - val_loss: 0.4287 - val_mae: 0.5246 - val_mse: 0.6518 - val_pearson_correlation: -1.6095e-16 - val_r2_keras: -53.1176 - val_rmse: 1.1980 - val_sae: 449.4809 - val_sse: 759.1680 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0689 - loss: 0.2390 - mae: 0.2529 - mse: 0.1391 - pearson_correlation: 1.7668e-16 - r2_keras: -104.0014 - rmse: 0.8917 - sae: 2665.9263 - sse: 3257.0117\n","Epoch 37: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0578 - loss: 0.2323 - mae: 0.2356 - mse: 0.1254 - pearson_correlation: 9.1907e-17 - r2_keras: -86.6689 - rmse: 0.8913 - sae: 1949.1735 - sse: 2378.5872 - val_huber_loss: 0.2583 - val_loss: 0.4284 - val_mae: 0.5248 - val_mse: 0.6504 - val_pearson_correlation: -2.5246e-16 - val_r2_keras: -52.9847 - val_rmse: 1.1965 - val_sae: 448.8110 - val_sse: 757.3034 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0684 - loss: 0.2385 - mae: 0.2519 - mse: 0.1380 - pearson_correlation: 9.4981e-17 - r2_keras: -103.9638 - rmse: 0.8916 - sae: 2665.4092 - sse: 3255.8462\n","Epoch 38: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0574 - loss: 0.2318 - mae: 0.2348 - mse: 0.1244 - pearson_correlation: 1.1348e-16 - r2_keras: -86.6197 - rmse: 0.8910 - sae: 1948.7213 - sse: 2377.5273 - val_huber_loss: 0.2580 - val_loss: 0.4282 - val_mae: 0.5239 - val_mse: 0.6498 - val_pearson_correlation: 3.2231e-16 - val_r2_keras: -53.0220 - val_rmse: 1.1969 - val_sae: 448.9158 - val_sse: 757.8269 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0679 - loss: 0.2380 - mae: 0.2508 - mse: 0.1370 - pearson_correlation: 3.0973e-16 - r2_keras: -104.0187 - rmse: 0.8918 - sae: 2665.7866 - sse: 3257.5479\n","Epoch 39: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0570 - loss: 0.2314 - mae: 0.2337 - mse: 0.1235 - pearson_correlation: 2.1484e-16 - r2_keras: -86.6671 - rmse: 0.8913 - sae: 1949.0117 - sse: 2378.7878 - val_huber_loss: 0.2577 - val_loss: 0.4278 - val_mae: 0.5230 - val_mse: 0.6489 - val_pearson_correlation: -7.3538e-16 - val_r2_keras: -53.0475 - val_rmse: 1.1972 - val_sae: 448.9807 - val_sse: 758.1837 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0674 - loss: 0.2375 - mae: 0.2498 - mse: 0.1360 - pearson_correlation: 1.4880e-16 - r2_keras: -104.0319 - rmse: 0.8919 - sae: 2665.7974 - sse: 3257.9590\n","Epoch 40: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0565 - loss: 0.2309 - mae: 0.2327 - mse: 0.1225 - pearson_correlation: 9.5860e-17 - r2_keras: -86.6865 - rmse: 0.8914 - sae: 1949.0718 - sse: 2379.1858 - val_huber_loss: 0.2575 - val_loss: 0.4276 - val_mae: 0.5233 - val_mse: 0.6474 - val_pearson_correlation: -2.1057e-17 - val_r2_keras: -52.8988 - val_rmse: 1.1955 - val_sae: 448.3004 - val_sse: 756.0976 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0669 - loss: 0.2370 - mae: 0.2489 - mse: 0.1350 - pearson_correlation: -7.7314e-17 - r2_keras: -103.9170 - rmse: 0.8914 - sae: 2664.4414 - sse: 3254.3955\n","Epoch 41: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0561 - loss: 0.2305 - mae: 0.2320 - mse: 0.1216 - pearson_correlation: -1.2248e-17 - r2_keras: -86.5875 - rmse: 0.8909 - sae: 1948.0768 - sse: 2376.5481 - val_huber_loss: 0.2573 - val_loss: 0.4274 - val_mae: 0.5222 - val_mse: 0.6465 - val_pearson_correlation: 2.4546e-16 - val_r2_keras: -52.9243 - val_rmse: 1.1958 - val_sae: 448.5016 - val_sse: 756.4553 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0665 - loss: 0.2366 - mae: 0.2479 - mse: 0.1341 - pearson_correlation: -3.9878e-16 - r2_keras: -104.0035 - rmse: 0.8917 - sae: 2665.1748 - sse: 3257.0774\n","Epoch 42: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0557 - loss: 0.2301 - mae: 0.2308 - mse: 0.1207 - pearson_correlation: -1.9230e-16 - r2_keras: -86.6495 - rmse: 0.8912 - sae: 1948.5923 - sse: 2378.3872 - val_huber_loss: 0.2570 - val_loss: 0.4271 - val_mae: 0.5225 - val_mse: 0.6454 - val_pearson_correlation: 2.1776e-16 - val_r2_keras: -52.8302 - val_rmse: 1.1948 - val_sae: 448.0448 - val_sse: 755.1363 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0660 - loss: 0.2362 - mae: 0.2468 - mse: 0.1331 - pearson_correlation: 6.0136e-16 - r2_keras: -104.0629 - rmse: 0.8920 - sae: 2665.7007 - sse: 3258.9199\n","Epoch 43: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0553 - loss: 0.2296 - mae: 0.2299 - mse: 0.1199 - pearson_correlation: 3.7080e-16 - r2_keras: -86.6764 - rmse: 0.8912 - sae: 1948.9227 - sse: 2379.4656 - val_huber_loss: 0.2568 - val_loss: 0.4269 - val_mae: 0.5211 - val_mse: 0.6448 - val_pearson_correlation: -1.5418e-16 - val_r2_keras: -52.9362 - val_rmse: 1.1959 - val_sae: 448.5172 - val_sse: 756.6226 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0657 - loss: 0.2358 - mae: 0.2458 - mse: 0.1323 - pearson_correlation: -2.5478e-16 - r2_keras: -104.1549 - rmse: 0.8924 - sae: 2666.3093 - sse: 3261.7739\n","Epoch 44: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0549 - loss: 0.2292 - mae: 0.2289 - mse: 0.1191 - pearson_correlation: -1.9241e-16 - r2_keras: -86.7575 - rmse: 0.8916 - sae: 1949.3876 - sse: 2381.6011 - val_huber_loss: 0.2567 - val_loss: 0.4268 - val_mae: 0.5217 - val_mse: 0.6438 - val_pearson_correlation: -3.4426e-16 - val_r2_keras: -52.7906 - val_rmse: 1.1943 - val_sae: 447.8255 - val_sse: 754.5803 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0652 - loss: 0.2353 - mae: 0.2450 - mse: 0.1314 - pearson_correlation: -4.2068e-17 - r2_keras: -104.1053 - rmse: 0.8922 - sae: 2665.7607 - sse: 3260.2363\n","Epoch 45: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0545 - loss: 0.2288 - mae: 0.2281 - mse: 0.1182 - pearson_correlation: -2.6372e-17 - r2_keras: -86.7055 - rmse: 0.8913 - sae: 1948.9716 - sse: 2380.3530 - val_huber_loss: 0.2562 - val_loss: 0.4263 - val_mae: 0.5198 - val_mse: 0.6427 - val_pearson_correlation: -5.6057e-17 - val_r2_keras: -52.9117 - val_rmse: 1.1957 - val_sae: 448.4073 - val_sse: 756.2794 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0648 - loss: 0.2349 - mae: 0.2440 - mse: 0.1306 - pearson_correlation: 2.4182e-16 - r2_keras: -104.2666 - rmse: 0.8928 - sae: 2666.9102 - sse: 3265.2383\n","Epoch 46: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0542 - loss: 0.2284 - mae: 0.2271 - mse: 0.1175 - pearson_correlation: 2.4387e-16 - r2_keras: -86.8428 - rmse: 0.8920 - sae: 1949.8658 - sse: 2384.0378 - val_huber_loss: 0.2558 - val_loss: 0.4259 - val_mae: 0.5200 - val_mse: 0.6410 - val_pearson_correlation: -2.0371e-16 - val_r2_keras: -52.7681 - val_rmse: 1.1941 - val_sae: 447.7452 - val_sse: 754.2642 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0644 - loss: 0.2345 - mae: 0.2432 - mse: 0.1297 - pearson_correlation: -2.8613e-16 - r2_keras: -104.2409 - rmse: 0.8927 - sae: 2666.5908 - sse: 3264.4417\n","Epoch 47: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0538 - loss: 0.2280 - mae: 0.2263 - mse: 0.1166 - pearson_correlation: -2.0495e-16 - r2_keras: -86.8162 - rmse: 0.8919 - sae: 1949.6429 - sse: 2383.3955 - val_huber_loss: 0.2554 - val_loss: 0.4255 - val_mae: 0.5183 - val_mse: 0.6399 - val_pearson_correlation: 4.9060e-17 - val_r2_keras: -52.8772 - val_rmse: 1.1953 - val_sae: 448.2949 - val_sse: 755.7957 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0640 - loss: 0.2341 - mae: 0.2422 - mse: 0.1290 - pearson_correlation: 1.7948e-16 - r2_keras: -104.3551 - rmse: 0.8932 - sae: 2667.2983 - sse: 3267.9822\n","Epoch 48: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0534 - loss: 0.2277 - mae: 0.2253 - mse: 0.1159 - pearson_correlation: 5.3813e-17 - r2_keras: -86.9310 - rmse: 0.8925 - sae: 1950.2649 - sse: 2386.2095 - val_huber_loss: 0.2553 - val_loss: 0.4254 - val_mae: 0.5184 - val_mse: 0.6393 - val_pearson_correlation: -6.3121e-17 - val_r2_keras: -52.8484 - val_rmse: 1.1950 - val_sae: 448.2582 - val_sse: 755.3912 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0636 - loss: 0.2337 - mae: 0.2414 - mse: 0.1282 - pearson_correlation: -3.6677e-16 - r2_keras: -104.2947 - rmse: 0.8930 - sae: 2666.5867 - sse: 3266.1096\n","Epoch 49: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0530 - loss: 0.2273 - mae: 0.2244 - mse: 0.1151 - pearson_correlation: -2.3369e-16 - r2_keras: -86.9070 - rmse: 0.8925 - sae: 1949.8976 - sse: 2385.1514 - val_huber_loss: 0.2550 - val_loss: 0.4251 - val_mae: 0.5183 - val_mse: 0.6374 - val_pearson_correlation: -2.2471e-16 - val_r2_keras: -52.7391 - val_rmse: 1.1938 - val_sae: 447.8290 - val_sse: 753.8578 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0632 - loss: 0.2333 - mae: 0.2405 - mse: 0.1274 - pearson_correlation: 1.1147e-16 - r2_keras: -104.4096 - rmse: 0.8935 - sae: 2667.4165 - sse: 3269.6743\n","Epoch 50: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0527 - loss: 0.2269 - mae: 0.2236 - mse: 0.1143 - pearson_correlation: 1.7270e-16 - r2_keras: -86.9605 - rmse: 0.8926 - sae: 1950.3849 - sse: 2387.2573 - val_huber_loss: 0.2547 - val_loss: 0.4248 - val_mae: 0.5179 - val_mse: 0.6362 - val_pearson_correlation: 4.2180e-17 - val_r2_keras: -52.6961 - val_rmse: 1.1933 - val_sae: 447.7214 - val_sse: 753.2549 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0628 - loss: 0.2329 - mae: 0.2397 - mse: 0.1265 - pearson_correlation: 2.3705e-16 - r2_keras: -104.3556 - rmse: 0.8932 - sae: 2666.6934 - sse: 3268.0000\n","Epoch 51: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0523 - loss: 0.2265 - mae: 0.2228 - mse: 0.1135 - pearson_correlation: 2.0297e-16 - r2_keras: -86.9567 - rmse: 0.8928 - sae: 1950.0409 - sse: 2386.5178 - val_huber_loss: 0.2543 - val_loss: 0.4244 - val_mae: 0.5178 - val_mse: 0.6340 - val_pearson_correlation: 2.6758e-16 - val_r2_keras: -52.5770 - val_rmse: 1.1920 - val_sae: 447.3319 - val_sse: 751.5842 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0625 - loss: 0.2326 - mae: 0.2389 - mse: 0.1258 - pearson_correlation: -1.6831e-16 - r2_keras: -104.4762 - rmse: 0.8937 - sae: 2667.8057 - sse: 3271.7410\n","Epoch 52: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0520 - loss: 0.2262 - mae: 0.2222 - mse: 0.1128 - pearson_correlation: -1.1471e-16 - r2_keras: -87.0096 - rmse: 0.8929 - sae: 1950.6876 - sse: 2388.6897 - val_huber_loss: 0.2537 - val_loss: 0.4238 - val_mae: 0.5159 - val_mse: 0.6325 - val_pearson_correlation: 2.1092e-17 - val_r2_keras: -52.6470 - val_rmse: 1.1927 - val_sae: 447.6459 - val_sse: 752.5662 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.0621 - loss: 0.2322 - mae: 0.2380 - mse: 0.1251 - pearson_correlation: -4.5107e-16 - r2_keras: -104.5734 - rmse: 0.8941 - sae: 2668.3770 - sse: 3274.7559\n","Epoch 53: val_loss did not improve from 0.39815\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0516 - loss: 0.2258 - mae: 0.2212 - mse: 0.1121 - pearson_correlation: -3.5897e-16 - r2_keras: -87.1009 - rmse: 0.8934 - sae: 1951.1744 - sse: 2391.0100 - val_huber_loss: 0.2537 - val_loss: 0.4238 - val_mae: 0.5168 - val_mse: 0.6314 - val_pearson_correlation: 1.6210e-16 - val_r2_keras: -52.4921 - val_rmse: 1.1910 - val_sae: 447.0650 - val_sse: 750.3935 - learning_rate: 1.0000e-05\n","| \u001b[39m20       \u001b[39m | \u001b[39m-0.4238  \u001b[39m | \u001b[39m0.0002053\u001b[39m | \u001b[39m91.71    \u001b[39m | \u001b[39m60.39    \u001b[39m | \u001b[39m69.65    \u001b[39m | \u001b[39m8.281    \u001b[39m | \u001b[39m77.92    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - huber_loss: 0.7114 - loss: 0.8669 - mae: 1.1185 - mse: 2.1990 - pearson_correlation: 6.2664e-16 - r2_keras: -339.8164 - rmse: 1.6065 - sae: 4729.9395 - sse: 10571.6982\n","Epoch 1: val_loss improved from inf to 0.42219, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 638ms/step - huber_loss: 0.7232 - loss: 0.8746 - mae: 1.1257 - mse: 2.1686 - pearson_correlation: 5.3021e-16 - r2_keras: -266.5574 - rmse: 1.5196 - sae: 3420.6448 - sse: 7521.0649 - val_huber_loss: 0.2628 - val_loss: 0.4222 - val_mae: 0.5198 - val_mse: 0.7149 - val_pearson_correlation: -3.6840e-16 - val_r2_keras: -25.1732 - val_rmse: 0.8331 - val_sae: 270.9369 - val_sse: 367.1601 - learning_rate: 0.0061\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2438 - loss: 0.4032 - mae: 0.5267 - mse: 0.5829 - pearson_correlation: -1.5132e-16 - r2_keras: -103.8566 - rmse: 0.8911 - sae: 2511.1150 - sse: 3252.5200\n","Epoch 2: val_loss improved from 0.42219 to 0.40760, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.3068 - loss: 0.4416 - mae: 0.5910 - mse: 0.6689 - pearson_correlation: -1.2825e-16 - r2_keras: -99.2380 - rmse: 0.9830 - sae: 1919.3036 - sse: 2524.1614 - val_huber_loss: 0.2482 - val_loss: 0.4076 - val_mae: 0.6132 - val_mse: 0.5903 - val_pearson_correlation: 1.8715e-16 - val_r2_keras: -22.4880 - val_rmse: 0.7892 - val_sae: 331.3308 - val_sse: 329.4927 - learning_rate: 0.0061\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.3405 - loss: 0.4999 - mae: 0.7427 - mse: 0.7500 - pearson_correlation: 1.6844e-16 - r2_keras: -107.0523 - rmse: 0.9046 - sae: 3056.3545 - sse: 3351.6465\n","Epoch 3: val_loss improved from 0.40760 to 0.39478, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.2786 - loss: 0.4622 - mae: 0.6709 - mse: 0.6625 - pearson_correlation: 1.5215e-16 - r2_keras: -91.9906 - rmse: 0.9263 - sae: 2216.2146 - sse: 2480.2427 - val_huber_loss: 0.2356 - val_loss: 0.3948 - val_mae: 0.5571 - val_mse: 0.5810 - val_pearson_correlation: -2.7562e-16 - val_r2_keras: -22.1884 - val_rmse: 0.7842 - val_sae: 305.8273 - val_sse: 325.2896 - learning_rate: 0.0061\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.2532 - loss: 0.4124 - mae: 0.5998 - mse: 0.5532 - pearson_correlation: -2.3474e-16 - r2_keras: -103.7376 - rmse: 0.8906 - sae: 2863.3728 - sse: 3248.8286\n","Epoch 4: val_loss did not improve from 0.39478\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.2304 - loss: 0.3984 - mae: 0.5755 - mse: 0.5177 - pearson_correlation: -2.4886e-16 - r2_keras: -85.7241 - rmse: 0.8840 - sae: 2079.1365 - sse: 2364.1125 - val_huber_loss: 0.2470 - val_loss: 0.4057 - val_mae: 0.5113 - val_mse: 0.6602 - val_pearson_correlation: 2.1094e-16 - val_r2_keras: -25.0840 - val_rmse: 0.8317 - val_sae: 274.7252 - val_sse: 365.9088 - learning_rate: 0.0061\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1655 - loss: 0.3242 - mae: 0.4023 - mse: 0.3741 - pearson_correlation: 5.4633e-16 - r2_keras: -128.5896 - rmse: 0.9906 - sae: 2783.8083 - sse: 4019.7080\n","Epoch 5: val_loss improved from 0.39478 to 0.35745, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1514 - loss: 0.3155 - mae: 0.3945 - mse: 0.3490 - pearson_correlation: 5.2805e-16 - r2_keras: -97.3661 - rmse: 0.9048 - sae: 2002.7924 - sse: 2820.2490 - val_huber_loss: 0.1996 - val_loss: 0.3574 - val_mae: 0.4284 - val_mse: 0.5124 - val_pearson_correlation: -4.7610e-16 - val_r2_keras: -26.2896 - val_rmse: 0.8507 - val_sae: 283.8745 - val_sse: 382.8214 - learning_rate: 0.0061\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.2544 - loss: 0.4123 - mae: 0.5124 - mse: 0.6042 - pearson_correlation: -1.1786e-16 - r2_keras: -194.8673 - rmse: 1.2179 - sae: 3410.9805 - sse: 6075.5586\n","Epoch 6: val_loss improved from 0.35745 to 0.33530, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.2348 - loss: 0.4003 - mae: 0.5076 - mse: 0.5641 - pearson_correlation: -2.9511e-17 - r2_keras: -144.4792 - rmse: 1.0845 - sae: 2435.8877 - sse: 4225.1611 - val_huber_loss: 0.1782 - val_loss: 0.3353 - val_mae: 0.4210 - val_mse: 0.4397 - val_pearson_correlation: -1.5087e-16 - val_r2_keras: -25.1769 - val_rmse: 0.8332 - val_sae: 292.6945 - val_sse: 367.2127 - learning_rate: 0.0061\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1780 - loss: 0.3351 - mae: 0.4138 - mse: 0.4180 - pearson_correlation: 2.3995e-16 - r2_keras: -136.6304 - rmse: 1.0209 - sae: 2886.4163 - sse: 4269.1226\n","Epoch 7: val_loss improved from 0.33530 to 0.30691, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - huber_loss: 0.1509 - loss: 0.3185 - mae: 0.3941 - mse: 0.3731 - pearson_correlation: 1.4639e-16 - r2_keras: -103.0901 - rmse: 0.9287 - sae: 2070.4519 - sse: 2990.7891 - val_huber_loss: 0.1507 - val_loss: 0.3069 - val_mae: 0.3854 - val_mse: 0.3653 - val_pearson_correlation: 4.5132e-17 - val_r2_keras: -25.9859 - val_rmse: 0.8459 - val_sae: 307.6977 - val_sse: 378.5605 - learning_rate: 0.0061\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1300 - loss: 0.2862 - mae: 0.3112 - mse: 0.2943 - pearson_correlation: 4.5486e-16 - r2_keras: -123.3335 - rmse: 0.9703 - sae: 2720.5737 - sse: 3856.6689\n","Epoch 8: val_loss improved from 0.30691 to 0.29088, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - huber_loss: 0.1201 - loss: 0.2801 - mae: 0.3146 - mse: 0.2754 - pearson_correlation: 3.8494e-16 - r2_keras: -95.1448 - rmse: 0.9040 - sae: 1966.7164 - sse: 2726.6033 - val_huber_loss: 0.1356 - val_loss: 0.2909 - val_mae: 0.3648 - val_mse: 0.3162 - val_pearson_correlation: -7.4080e-17 - val_r2_keras: -27.4986 - val_rmse: 0.8693 - val_sae: 326.0283 - val_sse: 399.7816 - learning_rate: 0.0061\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1238 - loss: 0.2791 - mae: 0.3666 - mse: 0.2663 - pearson_correlation: -6.8795e-16 - r2_keras: -119.9730 - rmse: 0.9571 - sae: 2848.3467 - sse: 3752.4319\n","Epoch 9: val_loss did not improve from 0.29088\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1098 - loss: 0.2704 - mae: 0.3572 - mse: 0.2455 - pearson_correlation: -4.7211e-16 - r2_keras: -94.4950 - rmse: 0.9102 - sae: 2060.5186 - sse: 2675.7690 - val_huber_loss: 0.1400 - val_loss: 0.2943 - val_mae: 0.3712 - val_mse: 0.3176 - val_pearson_correlation: -1.6560e-16 - val_r2_keras: -30.9067 - val_rmse: 0.9198 - val_sae: 351.9771 - val_sse: 447.5900 - learning_rate: 0.0061\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1085 - loss: 0.2628 - mae: 0.3230 - mse: 0.2390 - pearson_correlation: 2.4166e-16 - r2_keras: -101.7111 - rmse: 0.8819 - sae: 2594.1267 - sse: 3185.9700\n","Epoch 10: val_loss did not improve from 0.29088\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1080 - loss: 0.2623 - mae: 0.3298 - mse: 0.2339 - pearson_correlation: 2.2906e-16 - r2_keras: -87.7987 - rmse: 0.9063 - sae: 1922.1394 - sse: 2362.3882 - val_huber_loss: 0.1787 - val_loss: 0.3318 - val_mae: 0.4350 - val_mse: 0.4207 - val_pearson_correlation: -1.4421e-16 - val_r2_keras: -27.6321 - val_rmse: 0.8714 - val_sae: 326.2671 - val_sse: 401.6547 - learning_rate: 0.0061\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1490 - loss: 0.3021 - mae: 0.4251 - mse: 0.3151 - pearson_correlation: -2.3276e-16 - r2_keras: -106.1343 - rmse: 0.9007 - sae: 2794.0190 - sse: 3323.1719\n","Epoch 11: val_loss improved from 0.29088 to 0.28323, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1282 - loss: 0.2894 - mae: 0.4069 - mse: 0.2864 - pearson_correlation: -1.3259e-16 - r2_keras: -86.4215 - rmse: 0.8830 - sae: 2032.3676 - sse: 2403.1130 - val_huber_loss: 0.1312 - val_loss: 0.2832 - val_mae: 0.3598 - val_mse: 0.2909 - val_pearson_correlation: -2.6099e-16 - val_r2_keras: -30.0609 - val_rmse: 0.9076 - val_sae: 341.6923 - val_sse: 435.7264 - learning_rate: 0.0061\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1255 - loss: 0.2775 - mae: 0.3447 - mse: 0.2710 - pearson_correlation: -6.4199e-17 - r2_keras: -136.9363 - rmse: 1.0220 - sae: 3009.7466 - sse: 4278.6104\n","Epoch 12: val_loss did not improve from 0.28323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1243 - loss: 0.2767 - mae: 0.3524 - mse: 0.2666 - pearson_correlation: -9.1289e-17 - r2_keras: -102.7012 - rmse: 0.9234 - sae: 2152.8740 - sse: 2990.1604 - val_huber_loss: 0.1731 - val_loss: 0.3241 - val_mae: 0.4030 - val_mse: 0.3949 - val_pearson_correlation: 5.4099e-17 - val_r2_keras: -54.1532 - val_rmse: 1.2094 - val_sae: 460.9063 - val_sse: 773.6957 - learning_rate: 0.0061\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1624 - loss: 0.3134 - mae: 0.3643 - mse: 0.3729 - pearson_correlation: -3.6566e-16 - r2_keras: -154.3702 - rmse: 1.0847 - sae: 3050.3887 - sse: 4819.3896\n","Epoch 13: val_loss did not improve from 0.28323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.1866 - loss: 0.3280 - mae: 0.4042 - mse: 0.3964 - pearson_correlation: -2.7766e-16 - r2_keras: -115.4331 - rmse: 0.9763 - sae: 2187.0432 - sse: 3363.6926 - val_huber_loss: 0.1806 - val_loss: 0.3311 - val_mae: 0.4298 - val_mse: 0.3997 - val_pearson_correlation: -2.5142e-16 - val_r2_keras: -47.1123 - val_rmse: 1.1295 - val_sae: 441.3295 - val_sse: 674.9248 - learning_rate: 0.0061\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2134 - loss: 0.3639 - mae: 0.4705 - mse: 0.5284 - pearson_correlation: -5.4743e-17 - r2_keras: -160.4855 - rmse: 1.1059 - sae: 3257.1306 - sse: 5009.0786\n","Epoch 14: val_loss did not improve from 0.28323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1959 - loss: 0.3531 - mae: 0.4662 - mse: 0.4883 - pearson_correlation: -3.1617e-17 - r2_keras: -120.0821 - rmse: 0.9960 - sae: 2324.4565 - sse: 3496.8628 - val_huber_loss: 0.2361 - val_loss: 0.3854 - val_mae: 0.4944 - val_mse: 0.6463 - val_pearson_correlation: 4.4264e-17 - val_r2_keras: -70.1966 - val_rmse: 1.3740 - val_sae: 509.3036 - val_sse: 998.7535 - learning_rate: 0.0061\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1606 - loss: 0.3100 - mae: 0.3900 - mse: 0.3723 - pearson_correlation: 3.2729e-16 - r2_keras: -146.0883 - rmse: 1.0554 - sae: 2915.4351 - sse: 4562.4937\n","Epoch 15: val_loss did not improve from 0.28323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1579 - loss: 0.3082 - mae: 0.4088 - mse: 0.3608 - pearson_correlation: 2.1629e-16 - r2_keras: -112.9053 - rmse: 0.9847 - sae: 2121.5754 - sse: 3227.5417 - val_huber_loss: 0.2517 - val_loss: 0.3998 - val_mae: 0.5720 - val_mse: 0.6161 - val_pearson_correlation: -2.6984e-16 - val_r2_keras: -41.5422 - val_rmse: 1.0621 - val_sae: 419.8382 - val_sse: 596.7866 - learning_rate: 0.0061\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1350 - loss: 0.2832 - mae: 0.4273 - mse: 0.2781 - pearson_correlation: -4.5816e-16 - r2_keras: -120.2973 - rmse: 0.9584 - sae: 2934.3879 - sse: 3762.4900\n","Epoch 16: val_loss did not improve from 0.28323\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.1324 - loss: 0.2815 - mae: 0.4128 - mse: 0.2753 - pearson_correlation: -3.2868e-16 - r2_keras: -97.7057 - rmse: 0.9372 - sae: 2128.4492 - sse: 2717.6011 - val_huber_loss: 0.1423 - val_loss: 0.2892 - val_mae: 0.3891 - val_mse: 0.3224 - val_pearson_correlation: -6.7517e-16 - val_r2_keras: -32.6476 - val_rmse: 0.9446 - val_sae: 369.1395 - val_sse: 472.0127 - learning_rate: 0.0061\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1172 - loss: 0.2640 - mae: 0.3757 - mse: 0.2522 - pearson_correlation: 6.8867e-17 - r2_keras: -105.1254 - rmse: 0.8965 - sae: 2680.9885 - sse: 3291.8777\n","Epoch 17: val_loss improved from 0.28323 to 0.28069, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1071 - loss: 0.2579 - mae: 0.3600 - mse: 0.2366 - pearson_correlation: 1.1975e-16 - r2_keras: -86.2449 - rmse: 0.8845 - sae: 1958.6959 - sse: 2388.0679 - val_huber_loss: 0.1341 - val_loss: 0.2807 - val_mae: 0.3568 - val_mse: 0.2920 - val_pearson_correlation: -1.8936e-16 - val_r2_keras: -36.5983 - val_rmse: 0.9985 - val_sae: 383.7468 - val_sse: 527.4326 - learning_rate: 0.0012\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0964 - loss: 0.2430 - mae: 0.3041 - mse: 0.2054 - pearson_correlation: 1.3875e-16 - r2_keras: -103.2463 - rmse: 0.8885 - sae: 2591.0239 - sse: 3233.5906\n","Epoch 18: val_loss did not improve from 0.28069\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0877 - loss: 0.2376 - mae: 0.2963 - mse: 0.1923 - pearson_correlation: 1.9360e-17 - r2_keras: -84.7792 - rmse: 0.8773 - sae: 1895.5817 - sse: 2346.7109 - val_huber_loss: 0.1348 - val_loss: 0.2810 - val_mae: 0.3528 - val_mse: 0.2926 - val_pearson_correlation: 1.8539e-16 - val_r2_keras: -37.2509 - val_rmse: 1.0071 - val_sae: 384.6437 - val_sse: 536.5875 - learning_rate: 0.0012\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0928 - loss: 0.2390 - mae: 0.2850 - mse: 0.1975 - pearson_correlation: 4.4833e-16 - r2_keras: -101.9538 - rmse: 0.8830 - sae: 2562.6711 - sse: 3193.4990\n","Epoch 19: val_loss improved from 0.28069 to 0.27988, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.0831 - loss: 0.2331 - mae: 0.2787 - mse: 0.1833 - pearson_correlation: 3.0169e-16 - r2_keras: -83.6327 - rmse: 0.8711 - sae: 1874.7195 - sse: 2316.6426 - val_huber_loss: 0.1341 - val_loss: 0.2799 - val_mae: 0.3506 - val_mse: 0.2910 - val_pearson_correlation: 3.3349e-16 - val_r2_keras: -37.0518 - val_rmse: 1.0045 - val_sae: 382.6076 - val_sse: 533.7952 - learning_rate: 0.0012\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0904 - loss: 0.2362 - mae: 0.2717 - mse: 0.1929 - pearson_correlation: -1.2252e-16 - r2_keras: -102.2004 - rmse: 0.8840 - sae: 2557.8872 - sse: 3201.1460\n","Epoch 20: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0801 - loss: 0.2299 - mae: 0.2660 - mse: 0.1779 - pearson_correlation: -6.5089e-17 - r2_keras: -83.6090 - rmse: 0.8702 - sae: 1870.3221 - sse: 2319.5352 - val_huber_loss: 0.1346 - val_loss: 0.2800 - val_mae: 0.3476 - val_mse: 0.2928 - val_pearson_correlation: 1.6658e-16 - val_r2_keras: -37.0547 - val_rmse: 1.0046 - val_sae: 381.4287 - val_sse: 533.8356 - learning_rate: 0.0012\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0877 - loss: 0.2331 - mae: 0.2618 - mse: 0.1871 - pearson_correlation: 3.8481e-16 - r2_keras: -102.2702 - rmse: 0.8843 - sae: 2556.5078 - sse: 3203.3127\n","Epoch 21: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0776 - loss: 0.2269 - mae: 0.2572 - mse: 0.1724 - pearson_correlation: 2.4218e-16 - r2_keras: -83.5385 - rmse: 0.8693 - sae: 1868.8623 - sse: 2319.6057 - val_huber_loss: 0.1351 - val_loss: 0.2801 - val_mae: 0.3468 - val_mse: 0.2953 - val_pearson_correlation: 4.9706e-17 - val_r2_keras: -36.6132 - val_rmse: 0.9987 - val_sae: 378.5331 - val_sse: 527.6420 - learning_rate: 0.0012\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0850 - loss: 0.2300 - mae: 0.2482 - mse: 0.1821 - pearson_correlation: -9.1778e-17 - r2_keras: -103.4766 - rmse: 0.8895 - sae: 2569.5940 - sse: 3240.7334\n","Epoch 22: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0750 - loss: 0.2238 - mae: 0.2457 - mse: 0.1675 - pearson_correlation: -9.7109e-17 - r2_keras: -84.3323 - rmse: 0.8726 - sae: 1877.4437 - sse: 2344.4307 - val_huber_loss: 0.1375 - val_loss: 0.2819 - val_mae: 0.3456 - val_mse: 0.3024 - val_pearson_correlation: -9.9995e-18 - val_r2_keras: -36.4374 - val_rmse: 0.9964 - val_sae: 377.6599 - val_sse: 525.1765 - learning_rate: 0.0012\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0838 - loss: 0.2282 - mae: 0.2474 - mse: 0.1794 - pearson_correlation: 5.5968e-16 - r2_keras: -103.6337 - rmse: 0.8902 - sae: 2571.0186 - sse: 3245.6072\n","Epoch 23: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0736 - loss: 0.2220 - mae: 0.2442 - mse: 0.1646 - pearson_correlation: 4.1389e-16 - r2_keras: -84.2751 - rmse: 0.8716 - sae: 1877.8008 - sse: 2345.7793 - val_huber_loss: 0.1366 - val_loss: 0.2805 - val_mae: 0.3427 - val_mse: 0.3012 - val_pearson_correlation: 4.0219e-17 - val_r2_keras: -36.2854 - val_rmse: 0.9944 - val_sae: 376.9160 - val_sse: 523.0436 - learning_rate: 0.0012\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0818 - loss: 0.2257 - mae: 0.2409 - mse: 0.1752 - pearson_correlation: 5.7802e-17 - r2_keras: -104.5315 - rmse: 0.8940 - sae: 2581.2280 - sse: 3273.4553\n","Epoch 24: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0715 - loss: 0.2194 - mae: 0.2375 - mse: 0.1604 - pearson_correlation: -9.0200e-20 - r2_keras: -84.9384 - rmse: 0.8748 - sae: 1884.5177 - sse: 2365.1045 - val_huber_loss: 0.1383 - val_loss: 0.2817 - val_mae: 0.3457 - val_mse: 0.3082 - val_pearson_correlation: 3.4472e-16 - val_r2_keras: -36.0463 - val_rmse: 0.9912 - val_sae: 375.1426 - val_sse: 519.6892 - learning_rate: 0.0012\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0806 - loss: 0.2239 - mae: 0.2397 - mse: 0.1727 - pearson_correlation: 4.0224e-16 - r2_keras: -104.5622 - rmse: 0.8941 - sae: 2581.2251 - sse: 3274.4072\n","Epoch 25: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0693 - loss: 0.2170 - mae: 0.2350 - mse: 0.1567 - pearson_correlation: 2.4627e-16 - r2_keras: -85.1285 - rmse: 0.8764 - sae: 1885.4028 - sse: 2367.7302 - val_huber_loss: 0.1386 - val_loss: 0.2818 - val_mae: 0.3450 - val_mse: 0.3093 - val_pearson_correlation: -2.6341e-16 - val_r2_keras: -36.0647 - val_rmse: 0.9914 - val_sae: 375.4250 - val_sse: 519.9478 - learning_rate: 2.4596e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0800 - loss: 0.2232 - mae: 0.2388 - mse: 0.1714 - pearson_correlation: -4.8943e-16 - r2_keras: -104.2837 - rmse: 0.8929 - sae: 2578.6680 - sse: 3265.7690\n","Epoch 26: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0688 - loss: 0.2163 - mae: 0.2335 - mse: 0.1554 - pearson_correlation: -2.8716e-16 - r2_keras: -84.9122 - rmse: 0.8753 - sae: 1883.4552 - sse: 2361.6111 - val_huber_loss: 0.1387 - val_loss: 0.2817 - val_mae: 0.3437 - val_mse: 0.3100 - val_pearson_correlation: -6.0800e-17 - val_r2_keras: -36.0583 - val_rmse: 0.9913 - val_sae: 375.5013 - val_sse: 519.8574 - learning_rate: 2.4596e-04\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0795 - loss: 0.2226 - mae: 0.2377 - mse: 0.1705 - pearson_correlation: 3.0170e-16 - r2_keras: -104.2475 - rmse: 0.8928 - sae: 2578.4414 - sse: 3264.6445\n","Epoch 27: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0683 - loss: 0.2157 - mae: 0.2321 - mse: 0.1544 - pearson_correlation: 1.8203e-16 - r2_keras: -84.8760 - rmse: 0.8751 - sae: 1883.2091 - sse: 2360.7209 - val_huber_loss: 0.1388 - val_loss: 0.2817 - val_mae: 0.3431 - val_mse: 0.3108 - val_pearson_correlation: 1.3189e-16 - val_r2_keras: -36.0249 - val_rmse: 0.9909 - val_sae: 375.3683 - val_sse: 519.3896 - learning_rate: 2.4596e-04\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0792 - loss: 0.2221 - mae: 0.2368 - mse: 0.1697 - pearson_correlation: 7.4256e-16 - r2_keras: -104.3967 - rmse: 0.8934 - sae: 2579.9233 - sse: 3269.2751\n","Epoch 28: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0679 - loss: 0.2152 - mae: 0.2311 - mse: 0.1537 - pearson_correlation: 4.7785e-16 - r2_keras: -84.9779 - rmse: 0.8755 - sae: 1884.1748 - sse: 2363.8352 - val_huber_loss: 0.1387 - val_loss: 0.2815 - val_mae: 0.3422 - val_mse: 0.3112 - val_pearson_correlation: 1.0137e-16 - val_r2_keras: -36.0471 - val_rmse: 0.9912 - val_sae: 375.4785 - val_sse: 519.7006 - learning_rate: 2.4596e-04\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0788 - loss: 0.2215 - mae: 0.2364 - mse: 0.1690 - pearson_correlation: -4.4239e-16 - r2_keras: -104.4221 - rmse: 0.8935 - sae: 2579.9426 - sse: 3270.0603\n","Epoch 29: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0675 - loss: 0.2146 - mae: 0.2305 - mse: 0.1529 - pearson_correlation: -3.0255e-16 - r2_keras: -85.0151 - rmse: 0.8758 - sae: 1884.2794 - sse: 2364.5977 - val_huber_loss: 0.1390 - val_loss: 0.2815 - val_mae: 0.3415 - val_mse: 0.3124 - val_pearson_correlation: 2.0268e-16 - val_r2_keras: -36.0588 - val_rmse: 0.9913 - val_sae: 375.7284 - val_sse: 519.8647 - learning_rate: 2.4596e-04\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0786 - loss: 0.2211 - mae: 0.2355 - mse: 0.1686 - pearson_correlation: -7.5234e-16 - r2_keras: -104.7261 - rmse: 0.8948 - sae: 2583.2651 - sse: 3279.4922\n","Epoch 30: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0670 - loss: 0.2141 - mae: 0.2290 - mse: 0.1522 - pearson_correlation: -5.3390e-16 - r2_keras: -85.2508 - rmse: 0.8769 - sae: 1886.6598 - sse: 2371.2725 - val_huber_loss: 0.1391 - val_loss: 0.2816 - val_mae: 0.3408 - val_mse: 0.3126 - val_pearson_correlation: 8.0705e-17 - val_r2_keras: -36.1866 - val_rmse: 0.9930 - val_sae: 376.3051 - val_sse: 521.6576 - learning_rate: 4.9192e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0784 - loss: 0.2209 - mae: 0.2354 - mse: 0.1682 - pearson_correlation: -1.6147e-16 - r2_keras: -104.6567 - rmse: 0.8945 - sae: 2582.4231 - sse: 3277.3384\n","Epoch 31: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0669 - loss: 0.2139 - mae: 0.2288 - mse: 0.1519 - pearson_correlation: -8.9574e-17 - r2_keras: -85.2030 - rmse: 0.8767 - sae: 1886.0787 - sse: 2369.8191 - val_huber_loss: 0.1392 - val_loss: 0.2817 - val_mae: 0.3403 - val_mse: 0.3129 - val_pearson_correlation: 2.7163e-16 - val_r2_keras: -36.2656 - val_rmse: 0.9941 - val_sae: 376.6866 - val_sse: 522.7662 - learning_rate: 4.9192e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0783 - loss: 0.2208 - mae: 0.2353 - mse: 0.1680 - pearson_correlation: 1.5478e-16 - r2_keras: -104.6714 - rmse: 0.8946 - sae: 2582.5283 - sse: 3277.7959\n","Epoch 32: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - huber_loss: 0.0668 - loss: 0.2138 - mae: 0.2286 - mse: 0.1516 - pearson_correlation: 4.8019e-17 - r2_keras: -85.2123 - rmse: 0.8768 - sae: 1886.1360 - sse: 2370.1174 - val_huber_loss: 0.1394 - val_loss: 0.2818 - val_mae: 0.3401 - val_mse: 0.3132 - val_pearson_correlation: 2.1089e-16 - val_r2_keras: -36.3161 - val_rmse: 0.9948 - val_sae: 376.9182 - val_sse: 523.4747 - learning_rate: 4.9192e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0782 - loss: 0.2206 - mae: 0.2351 - mse: 0.1678 - pearson_correlation: 1.0212e-15 - r2_keras: -104.6847 - rmse: 0.8946 - sae: 2582.5896 - sse: 3278.2073\n","Epoch 33: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0667 - loss: 0.2136 - mae: 0.2283 - mse: 0.1514 - pearson_correlation: 6.0087e-16 - r2_keras: -85.2190 - rmse: 0.8768 - sae: 1886.1520 - sse: 2370.3669 - val_huber_loss: 0.1394 - val_loss: 0.2818 - val_mae: 0.3401 - val_mse: 0.3134 - val_pearson_correlation: 3.0087e-17 - val_r2_keras: -36.3551 - val_rmse: 0.9953 - val_sae: 377.1006 - val_sse: 524.0217 - learning_rate: 4.9192e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0781 - loss: 0.2205 - mae: 0.2349 - mse: 0.1675 - pearson_correlation: -5.2877e-16 - r2_keras: -104.6602 - rmse: 0.8945 - sae: 2582.2808 - sse: 3277.4487\n","Epoch 34: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0666 - loss: 0.2135 - mae: 0.2281 - mse: 0.1512 - pearson_correlation: -4.4004e-16 - r2_keras: -85.2027 - rmse: 0.8767 - sae: 1885.9387 - sse: 2369.8611 - val_huber_loss: 0.1394 - val_loss: 0.2817 - val_mae: 0.3399 - val_mse: 0.3134 - val_pearson_correlation: 1.2028e-16 - val_r2_keras: -36.3708 - val_rmse: 0.9955 - val_sae: 377.1889 - val_sse: 524.2422 - learning_rate: 4.9192e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0780 - loss: 0.2203 - mae: 0.2348 - mse: 0.1673 - pearson_correlation: -9.8525e-16 - r2_keras: -104.6730 - rmse: 0.8946 - sae: 2582.3350 - sse: 3277.8438\n","Epoch 35: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.2133 - mae: 0.2278 - mse: 0.1509 - pearson_correlation: -5.9220e-16 - r2_keras: -85.2222 - rmse: 0.8769 - sae: 1886.0243 - sse: 2370.2537 - val_huber_loss: 0.1395 - val_loss: 0.2818 - val_mae: 0.3400 - val_mse: 0.3136 - val_pearson_correlation: -2.8033e-16 - val_r2_keras: -36.4047 - val_rmse: 0.9959 - val_sae: 377.3505 - val_sse: 524.7171 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - huber_loss: 0.0780 - loss: 0.2203 - mae: 0.2347 - mse: 0.1673 - pearson_correlation: -2.9900e-16 - r2_keras: -104.6774 - rmse: 0.8946 - sae: 2582.3760 - sse: 3277.9810\n","Epoch 36: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0664 - loss: 0.2132 - mae: 0.2278 - mse: 0.1509 - pearson_correlation: -2.5256e-16 - r2_keras: -85.2250 - rmse: 0.8769 - sae: 1886.0485 - sse: 2370.3435 - val_huber_loss: 0.1396 - val_loss: 0.2819 - val_mae: 0.3400 - val_mse: 0.3138 - val_pearson_correlation: 1.7008e-16 - val_r2_keras: -36.4260 - val_rmse: 0.9962 - val_sae: 377.4623 - val_sse: 525.0153 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0779 - loss: 0.2203 - mae: 0.2346 - mse: 0.1672 - pearson_correlation: -3.0230e-16 - r2_keras: -104.6853 - rmse: 0.8946 - sae: 2582.4546 - sse: 3278.2261\n","Epoch 37: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0664 - loss: 0.2132 - mae: 0.2277 - mse: 0.1508 - pearson_correlation: -1.3119e-16 - r2_keras: -85.2301 - rmse: 0.8769 - sae: 1886.0970 - sse: 2370.5049 - val_huber_loss: 0.1396 - val_loss: 0.2819 - val_mae: 0.3401 - val_mse: 0.3139 - val_pearson_correlation: 4.9997e-17 - val_r2_keras: -36.4407 - val_rmse: 0.9964 - val_sae: 377.5347 - val_sse: 525.2228 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0779 - loss: 0.2202 - mae: 0.2346 - mse: 0.1671 - pearson_correlation: 8.8856e-16 - r2_keras: -104.6883 - rmse: 0.8946 - sae: 2582.4634 - sse: 3278.3188\n","Epoch 38: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0663 - loss: 0.2132 - mae: 0.2276 - mse: 0.1508 - pearson_correlation: 6.6841e-16 - r2_keras: -85.2332 - rmse: 0.8769 - sae: 1886.1071 - sse: 2370.5789 - val_huber_loss: 0.1397 - val_loss: 0.2820 - val_mae: 0.3401 - val_mse: 0.3141 - val_pearson_correlation: 9.9963e-17 - val_r2_keras: -36.4499 - val_rmse: 0.9965 - val_sae: 377.5832 - val_sse: 525.3510 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.0779 - loss: 0.2202 - mae: 0.2345 - mse: 0.1671 - pearson_correlation: 1.9410e-16 - r2_keras: -104.7002 - rmse: 0.8947 - sae: 2582.5759 - sse: 3278.6895\n","Epoch 39: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0663 - loss: 0.2131 - mae: 0.2275 - mse: 0.1507 - pearson_correlation: 1.5506e-16 - r2_keras: -85.2417 - rmse: 0.8769 - sae: 1886.1832 - sse: 2370.8333 - val_huber_loss: 0.1397 - val_loss: 0.2820 - val_mae: 0.3401 - val_mse: 0.3141 - val_pearson_correlation: 9.9938e-18 - val_r2_keras: -36.4571 - val_rmse: 0.9966 - val_sae: 377.6247 - val_sse: 525.4527 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0778 - loss: 0.2201 - mae: 0.2345 - mse: 0.1670 - pearson_correlation: 1.1201e-16 - r2_keras: -104.7079 - rmse: 0.8947 - sae: 2582.6450 - sse: 3278.9270\n","Epoch 40: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0663 - loss: 0.2131 - mae: 0.2275 - mse: 0.1507 - pearson_correlation: 3.9511e-17 - r2_keras: -85.2474 - rmse: 0.8770 - sae: 1886.2294 - sse: 2370.9983 - val_huber_loss: 0.1397 - val_loss: 0.2820 - val_mae: 0.3402 - val_mse: 0.3142 - val_pearson_correlation: -4.9962e-17 - val_r2_keras: -36.4612 - val_rmse: 0.9967 - val_sae: 377.6420 - val_sse: 525.5097 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0778 - loss: 0.2201 - mae: 0.2344 - mse: 0.1670 - pearson_correlation: -9.3260e-16 - r2_keras: -104.7175 - rmse: 0.8948 - sae: 2582.7200 - sse: 3279.2256\n","Epoch 41: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0662 - loss: 0.2130 - mae: 0.2274 - mse: 0.1506 - pearson_correlation: -6.1508e-16 - r2_keras: -85.2556 - rmse: 0.8770 - sae: 1886.2858 - sse: 2371.2175 - val_huber_loss: 0.1398 - val_loss: 0.2820 - val_mae: 0.3401 - val_mse: 0.3143 - val_pearson_correlation: -1.3986e-16 - val_r2_keras: -36.4675 - val_rmse: 0.9968 - val_sae: 377.6779 - val_sse: 525.5984 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0778 - loss: 0.2200 - mae: 0.2343 - mse: 0.1669 - pearson_correlation: 3.1435e-16 - r2_keras: -104.7249 - rmse: 0.8948 - sae: 2582.7747 - sse: 3279.4526\n","Epoch 42: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0662 - loss: 0.2130 - mae: 0.2273 - mse: 0.1505 - pearson_correlation: 2.0386e-16 - r2_keras: -85.2610 - rmse: 0.8770 - sae: 1886.3215 - sse: 2371.3757 - val_huber_loss: 0.1398 - val_loss: 0.2820 - val_mae: 0.3402 - val_mse: 0.3144 - val_pearson_correlation: 3.6959e-16 - val_r2_keras: -36.4717 - val_rmse: 0.9968 - val_sae: 377.7010 - val_sse: 525.6575 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0778 - loss: 0.2200 - mae: 0.2343 - mse: 0.1669 - pearson_correlation: 7.2124e-16 - r2_keras: -104.7295 - rmse: 0.8948 - sae: 2582.7986 - sse: 3279.5967\n","Epoch 43: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0662 - loss: 0.2130 - mae: 0.2272 - mse: 0.1505 - pearson_correlation: 4.7703e-16 - r2_keras: -85.2649 - rmse: 0.8771 - sae: 1886.3378 - sse: 2371.4807 - val_huber_loss: 0.1398 - val_loss: 0.2820 - val_mae: 0.3402 - val_mse: 0.3144 - val_pearson_correlation: 1.9974e-17 - val_r2_keras: -36.4768 - val_rmse: 0.9969 - val_sae: 377.7313 - val_sse: 525.7283 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0777 - loss: 0.2200 - mae: 0.2342 - mse: 0.1668 - pearson_correlation: 5.3210e-17 - r2_keras: -104.7447 - rmse: 0.8949 - sae: 2582.9414 - sse: 3280.0669\n","Epoch 44: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0662 - loss: 0.2129 - mae: 0.2272 - mse: 0.1504 - pearson_correlation: -4.4332e-17 - r2_keras: -85.2763 - rmse: 0.8771 - sae: 1886.4371 - sse: 2371.8093 - val_huber_loss: 0.1398 - val_loss: 0.2820 - val_mae: 0.3401 - val_mse: 0.3145 - val_pearson_correlation: -1.9974e-16 - val_r2_keras: -36.4776 - val_rmse: 0.9969 - val_sae: 377.7366 - val_sse: 525.7399 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0777 - loss: 0.2199 - mae: 0.2341 - mse: 0.1667 - pearson_correlation: 2.9317e-16 - r2_keras: -104.7578 - rmse: 0.8949 - sae: 2583.0571 - sse: 3280.4761\n","Epoch 45: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0661 - loss: 0.2129 - mae: 0.2271 - mse: 0.1504 - pearson_correlation: 1.1280e-16 - r2_keras: -85.2863 - rmse: 0.8772 - sae: 1886.5153 - sse: 2372.0967 - val_huber_loss: 0.1398 - val_loss: 0.2820 - val_mae: 0.3402 - val_mse: 0.3146 - val_pearson_correlation: -1.0983e-16 - val_r2_keras: -36.4841 - val_rmse: 0.9970 - val_sae: 377.7660 - val_sse: 525.8307 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0777 - loss: 0.2199 - mae: 0.2341 - mse: 0.1667 - pearson_correlation: 2.7707e-18 - r2_keras: -104.7657 - rmse: 0.8950 - sae: 2583.1055 - sse: 3280.7195\n","Epoch 46: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0661 - loss: 0.2128 - mae: 0.2270 - mse: 0.1503 - pearson_correlation: -2.7598e-17 - r2_keras: -85.2933 - rmse: 0.8772 - sae: 1886.5543 - sse: 2372.2795 - val_huber_loss: 0.1398 - val_loss: 0.2820 - val_mae: 0.3402 - val_mse: 0.3146 - val_pearson_correlation: -8.9853e-17 - val_r2_keras: -36.4875 - val_rmse: 0.9970 - val_sae: 377.7889 - val_sse: 525.8789 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0776 - loss: 0.2198 - mae: 0.2340 - mse: 0.1666 - pearson_correlation: -1.2688e-16 - r2_keras: -104.7765 - rmse: 0.8950 - sae: 2583.1948 - sse: 3281.0547\n","Epoch 47: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0661 - loss: 0.2128 - mae: 0.2269 - mse: 0.1502 - pearson_correlation: -1.7101e-16 - r2_keras: -85.3020 - rmse: 0.8772 - sae: 1886.6163 - sse: 2372.5200 - val_huber_loss: 0.1399 - val_loss: 0.2821 - val_mae: 0.3402 - val_mse: 0.3147 - val_pearson_correlation: 1.5972e-16 - val_r2_keras: -36.4899 - val_rmse: 0.9971 - val_sae: 377.7910 - val_sse: 525.9125 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0776 - loss: 0.2198 - mae: 0.2339 - mse: 0.1665 - pearson_correlation: -1.0802e-15 - r2_keras: -104.7938 - rmse: 0.8951 - sae: 2583.3374 - sse: 3281.5903\n","Epoch 48: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0660 - loss: 0.2127 - mae: 0.2268 - mse: 0.1502 - pearson_correlation: -7.0684e-16 - r2_keras: -85.3154 - rmse: 0.8773 - sae: 1886.7189 - sse: 2372.9001 - val_huber_loss: 0.1399 - val_loss: 0.2821 - val_mae: 0.3402 - val_mse: 0.3148 - val_pearson_correlation: -5.9883e-17 - val_r2_keras: -36.4971 - val_rmse: 0.9972 - val_sae: 377.8360 - val_sse: 526.0137 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0776 - loss: 0.2197 - mae: 0.2338 - mse: 0.1665 - pearson_correlation: -5.9820e-17 - r2_keras: -104.8026 - rmse: 0.8951 - sae: 2583.4097 - sse: 3281.8635\n","Epoch 49: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0660 - loss: 0.2127 - mae: 0.2267 - mse: 0.1501 - pearson_correlation: -9.2101e-17 - r2_keras: -85.3231 - rmse: 0.8774 - sae: 1886.7739 - sse: 2373.1033 - val_huber_loss: 0.1399 - val_loss: 0.2821 - val_mae: 0.3402 - val_mse: 0.3148 - val_pearson_correlation: -1.3971e-16 - val_r2_keras: -36.5010 - val_rmse: 0.9972 - val_sae: 377.8598 - val_sse: 526.0687 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0775 - loss: 0.2197 - mae: 0.2338 - mse: 0.1664 - pearson_correlation: -2.6747e-16 - r2_keras: -104.8221 - rmse: 0.8952 - sae: 2583.5928 - sse: 3282.4702\n","Epoch 50: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0660 - loss: 0.2126 - mae: 0.2266 - mse: 0.1500 - pearson_correlation: -1.8780e-16 - r2_keras: -85.3380 - rmse: 0.8774 - sae: 1886.9010 - sse: 2373.5291 - val_huber_loss: 0.1399 - val_loss: 0.2821 - val_mae: 0.3403 - val_mse: 0.3149 - val_pearson_correlation: 9.9772e-17 - val_r2_keras: -36.5067 - val_rmse: 0.9973 - val_sae: 377.8812 - val_sse: 526.1476 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0775 - loss: 0.2196 - mae: 0.2337 - mse: 0.1663 - pearson_correlation: -4.7517e-16 - r2_keras: -104.8138 - rmse: 0.8952 - sae: 2583.4717 - sse: 3282.2129\n","Epoch 51: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0659 - loss: 0.2126 - mae: 0.2265 - mse: 0.1499 - pearson_correlation: -3.2248e-16 - r2_keras: -85.3323 - rmse: 0.8774 - sae: 1886.8124 - sse: 2373.3567 - val_huber_loss: 0.1400 - val_loss: 0.2821 - val_mae: 0.3404 - val_mse: 0.3151 - val_pearson_correlation: 2.7931e-16 - val_r2_keras: -36.5124 - val_rmse: 0.9974 - val_sae: 377.9091 - val_sse: 526.2285 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - huber_loss: 0.0774 - loss: 0.2196 - mae: 0.2336 - mse: 0.1662 - pearson_correlation: 7.5359e-16 - r2_keras: -104.8300 - rmse: 0.8952 - sae: 2583.5940 - sse: 3282.7139\n","Epoch 52: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0659 - loss: 0.2125 - mae: 0.2264 - mse: 0.1498 - pearson_correlation: 5.4511e-16 - r2_keras: -85.3443 - rmse: 0.8775 - sae: 1886.8971 - sse: 2373.7046 - val_huber_loss: 0.1401 - val_loss: 0.2822 - val_mae: 0.3405 - val_mse: 0.3153 - val_pearson_correlation: 3.0919e-16 - val_r2_keras: -36.5163 - val_rmse: 0.9974 - val_sae: 377.9238 - val_sse: 526.2834 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0774 - loss: 0.2195 - mae: 0.2335 - mse: 0.1662 - pearson_correlation: -8.8182e-16 - r2_keras: -104.8517 - rmse: 0.8953 - sae: 2583.7656 - sse: 3283.3862\n","Epoch 53: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - huber_loss: 0.0658 - loss: 0.2125 - mae: 0.2263 - mse: 0.1498 - pearson_correlation: -5.3568e-16 - r2_keras: -85.3598 - rmse: 0.8775 - sae: 1887.0114 - sse: 2374.1653 - val_huber_loss: 0.1402 - val_loss: 0.2822 - val_mae: 0.3405 - val_mse: 0.3155 - val_pearson_correlation: -2.2935e-16 - val_r2_keras: -36.5232 - val_rmse: 0.9975 - val_sae: 377.9601 - val_sse: 526.3801 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0774 - loss: 0.2194 - mae: 0.2334 - mse: 0.1661 - pearson_correlation: 2.9280e-16 - r2_keras: -104.8617 - rmse: 0.8954 - sae: 2583.8252 - sse: 3283.6980\n","Epoch 54: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0658 - loss: 0.2124 - mae: 0.2262 - mse: 0.1497 - pearson_correlation: 1.7242e-16 - r2_keras: -85.3682 - rmse: 0.8776 - sae: 1887.0555 - sse: 2374.3923 - val_huber_loss: 0.1402 - val_loss: 0.2823 - val_mae: 0.3406 - val_mse: 0.3157 - val_pearson_correlation: -2.4923e-16 - val_r2_keras: -36.5305 - val_rmse: 0.9976 - val_sae: 377.9971 - val_sse: 526.4824 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0773 - loss: 0.2194 - mae: 0.2333 - mse: 0.1660 - pearson_correlation: -3.0713e-16 - r2_keras: -104.8786 - rmse: 0.8954 - sae: 2583.9590 - sse: 3284.2212\n","Epoch 55: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0657 - loss: 0.2123 - mae: 0.2261 - mse: 0.1496 - pearson_correlation: -2.5505e-16 - r2_keras: -85.3805 - rmse: 0.8776 - sae: 1887.1471 - sse: 2374.7544 - val_huber_loss: 0.1402 - val_loss: 0.2823 - val_mae: 0.3406 - val_mse: 0.3157 - val_pearson_correlation: -9.9675e-18 - val_r2_keras: -36.5358 - val_rmse: 0.9977 - val_sae: 378.0225 - val_sse: 526.5568 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0773 - loss: 0.2193 - mae: 0.2332 - mse: 0.1659 - pearson_correlation: -5.8990e-16 - r2_keras: -104.8799 - rmse: 0.8954 - sae: 2583.9265 - sse: 3284.2605\n","Epoch 56: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0657 - loss: 0.2123 - mae: 0.2260 - mse: 0.1495 - pearson_correlation: -4.0939e-16 - r2_keras: -85.3833 - rmse: 0.8776 - sae: 1887.1290 - sse: 2374.8037 - val_huber_loss: 0.1403 - val_loss: 0.2824 - val_mae: 0.3407 - val_mse: 0.3160 - val_pearson_correlation: 1.2955e-16 - val_r2_keras: -36.5427 - val_rmse: 0.9978 - val_sae: 378.0525 - val_sse: 526.6526 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0772 - loss: 0.2193 - mae: 0.2331 - mse: 0.1658 - pearson_correlation: 5.8424e-16 - r2_keras: -104.8969 - rmse: 0.8955 - sae: 2584.0586 - sse: 3284.7905\n","Epoch 57: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0657 - loss: 0.2122 - mae: 0.2258 - mse: 0.1494 - pearson_correlation: 3.4396e-16 - r2_keras: -85.3965 - rmse: 0.8777 - sae: 1887.2235 - sse: 2375.1780 - val_huber_loss: 0.1404 - val_loss: 0.2824 - val_mae: 0.3408 - val_mse: 0.3162 - val_pearson_correlation: -6.9755e-17 - val_r2_keras: -36.5433 - val_rmse: 0.9978 - val_sae: 378.0486 - val_sse: 526.6615 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0772 - loss: 0.2192 - mae: 0.2330 - mse: 0.1657 - pearson_correlation: -3.8883e-16 - r2_keras: -104.9199 - rmse: 0.8956 - sae: 2584.2505 - sse: 3285.5020\n","Epoch 58: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0656 - loss: 0.2122 - mae: 0.2257 - mse: 0.1493 - pearson_correlation: -3.1329e-16 - r2_keras: -85.4131 - rmse: 0.8778 - sae: 1887.3529 - sse: 2375.6672 - val_huber_loss: 0.1405 - val_loss: 0.2825 - val_mae: 0.3409 - val_mse: 0.3164 - val_pearson_correlation: 1.5941e-16 - val_r2_keras: -36.5495 - val_rmse: 0.9979 - val_sae: 378.0811 - val_sse: 526.7490 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0771 - loss: 0.2192 - mae: 0.2329 - mse: 0.1656 - pearson_correlation: -2.0407e-16 - r2_keras: -104.9325 - rmse: 0.8957 - sae: 2584.3423 - sse: 3285.8926\n","Epoch 59: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0656 - loss: 0.2121 - mae: 0.2256 - mse: 0.1493 - pearson_correlation: -1.1518e-16 - r2_keras: -85.4227 - rmse: 0.8778 - sae: 1887.4171 - sse: 2375.9421 - val_huber_loss: 0.1405 - val_loss: 0.2825 - val_mae: 0.3409 - val_mse: 0.3164 - val_pearson_correlation: -1.4943e-16 - val_r2_keras: -36.5532 - val_rmse: 0.9979 - val_sae: 378.1021 - val_sse: 526.8010 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0771 - loss: 0.2191 - mae: 0.2328 - mse: 0.1656 - pearson_correlation: -2.9254e-16 - r2_keras: -104.9351 - rmse: 0.8957 - sae: 2584.3335 - sse: 3285.9741\n","Epoch 60: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0655 - loss: 0.2121 - mae: 0.2255 - mse: 0.1492 - pearson_correlation: -1.9218e-16 - r2_keras: -85.4265 - rmse: 0.8779 - sae: 1887.4180 - sse: 2376.0208 - val_huber_loss: 0.1406 - val_loss: 0.2825 - val_mae: 0.3411 - val_mse: 0.3167 - val_pearson_correlation: 1.8927e-16 - val_r2_keras: -36.5531 - val_rmse: 0.9979 - val_sae: 378.0932 - val_sse: 526.7984 - learning_rate: 1.0000e-05\n","Epoch 61/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0771 - loss: 0.2190 - mae: 0.2327 - mse: 0.1655 - pearson_correlation: 8.5691e-17 - r2_keras: -104.9590 - rmse: 0.8958 - sae: 2584.5410 - sse: 3286.7148\n","Epoch 61: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0655 - loss: 0.2120 - mae: 0.2254 - mse: 0.1491 - pearson_correlation: 9.7138e-18 - r2_keras: -85.4438 - rmse: 0.8779 - sae: 1887.5582 - sse: 2376.5303 - val_huber_loss: 0.1406 - val_loss: 0.2826 - val_mae: 0.3411 - val_mse: 0.3168 - val_pearson_correlation: 1.9920e-16 - val_r2_keras: -36.5580 - val_rmse: 0.9980 - val_sae: 378.1221 - val_sse: 526.8678 - learning_rate: 1.0000e-05\n","Epoch 62/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0770 - loss: 0.2190 - mae: 0.2326 - mse: 0.1654 - pearson_correlation: -1.2685e-15 - r2_keras: -104.9779 - rmse: 0.8959 - sae: 2584.7134 - sse: 3287.3025\n","Epoch 62: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0654 - loss: 0.2119 - mae: 0.2253 - mse: 0.1490 - pearson_correlation: -8.7980e-16 - r2_keras: -85.4578 - rmse: 0.8780 - sae: 1887.6786 - sse: 2376.9387 - val_huber_loss: 0.1407 - val_loss: 0.2826 - val_mae: 0.3412 - val_mse: 0.3169 - val_pearson_correlation: -1.3943e-16 - val_r2_keras: -36.5613 - val_rmse: 0.9980 - val_sae: 378.1385 - val_sse: 526.9135 - learning_rate: 1.0000e-05\n","Epoch 63/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0770 - loss: 0.2189 - mae: 0.2325 - mse: 0.1653 - pearson_correlation: -3.8193e-16 - r2_keras: -104.9786 - rmse: 0.8959 - sae: 2584.6958 - sse: 3287.3242\n","Epoch 63: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0654 - loss: 0.2119 - mae: 0.2252 - mse: 0.1489 - pearson_correlation: -3.1434e-16 - r2_keras: -85.4603 - rmse: 0.8780 - sae: 1887.6727 - sse: 2376.9763 - val_huber_loss: 0.1407 - val_loss: 0.2827 - val_mae: 0.3412 - val_mse: 0.3172 - val_pearson_correlation: 9.9567e-17 - val_r2_keras: -36.5684 - val_rmse: 0.9981 - val_sae: 378.1799 - val_sse: 527.0141 - learning_rate: 1.0000e-05\n","Epoch 64/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0769 - loss: 0.2189 - mae: 0.2324 - mse: 0.1652 - pearson_correlation: -2.4702e-16 - r2_keras: -104.9954 - rmse: 0.8959 - sae: 2584.8562 - sse: 3287.8442\n","Epoch 64: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0654 - loss: 0.2118 - mae: 0.2251 - mse: 0.1488 - pearson_correlation: -1.1918e-16 - r2_keras: -85.4727 - rmse: 0.8781 - sae: 1887.7838 - sse: 2377.3374 - val_huber_loss: 0.1408 - val_loss: 0.2827 - val_mae: 0.3413 - val_mse: 0.3174 - val_pearson_correlation: -1.9914e-17 - val_r2_keras: -36.5676 - val_rmse: 0.9981 - val_sae: 378.1759 - val_sse: 527.0029 - learning_rate: 1.0000e-05\n","Epoch 65/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0769 - loss: 0.2188 - mae: 0.2322 - mse: 0.1651 - pearson_correlation: -5.7461e-17 - r2_keras: -105.0095 - rmse: 0.8960 - sae: 2584.9792 - sse: 3288.2815\n","Epoch 65: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - huber_loss: 0.0653 - loss: 0.2118 - mae: 0.2249 - mse: 0.1488 - pearson_correlation: -2.5985e-17 - r2_keras: -85.4828 - rmse: 0.8781 - sae: 1887.8661 - sse: 2377.6372 - val_huber_loss: 0.1408 - val_loss: 0.2828 - val_mae: 0.3414 - val_mse: 0.3175 - val_pearson_correlation: -4.9784e-17 - val_r2_keras: -36.5682 - val_rmse: 0.9981 - val_sae: 378.1762 - val_sse: 527.0103 - learning_rate: 1.0000e-05\n","Epoch 66/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0768 - loss: 0.2188 - mae: 0.2321 - mse: 0.1651 - pearson_correlation: 4.0656e-16 - r2_keras: -105.0274 - rmse: 0.8961 - sae: 2585.1353 - sse: 3288.8381\n","Epoch 66: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0653 - loss: 0.2117 - mae: 0.2248 - mse: 0.1487 - pearson_correlation: 2.8431e-16 - r2_keras: -85.4960 - rmse: 0.8782 - sae: 1887.9720 - sse: 2378.0225 - val_huber_loss: 0.1409 - val_loss: 0.2828 - val_mae: 0.3415 - val_mse: 0.3177 - val_pearson_correlation: -1.2942e-16 - val_r2_keras: -36.5717 - val_rmse: 0.9982 - val_sae: 378.1942 - val_sse: 527.0597 - learning_rate: 1.0000e-05\n","Epoch 67/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0768 - loss: 0.2187 - mae: 0.2320 - mse: 0.1650 - pearson_correlation: -6.0531e-16 - r2_keras: -105.0437 - rmse: 0.8961 - sae: 2585.2791 - sse: 3289.3433\n","Epoch 67: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0652 - loss: 0.2117 - mae: 0.2247 - mse: 0.1486 - pearson_correlation: -3.6279e-16 - r2_keras: -85.5079 - rmse: 0.8782 - sae: 1888.0719 - sse: 2378.3713 - val_huber_loss: 0.1409 - val_loss: 0.2828 - val_mae: 0.3416 - val_mse: 0.3178 - val_pearson_correlation: -4.6790e-16 - val_r2_keras: -36.5728 - val_rmse: 0.9982 - val_sae: 378.1968 - val_sse: 527.0759 - learning_rate: 1.0000e-05\n","Epoch 68/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0768 - loss: 0.2186 - mae: 0.2319 - mse: 0.1649 - pearson_correlation: 3.5734e-16 - r2_keras: -105.0414 - rmse: 0.8961 - sae: 2585.2231 - sse: 3289.2710\n","Epoch 68: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0652 - loss: 0.2116 - mae: 0.2246 - mse: 0.1485 - pearson_correlation: 2.1643e-16 - r2_keras: -85.5092 - rmse: 0.8783 - sae: 1888.0446 - sse: 2378.3572 - val_huber_loss: 0.1410 - val_loss: 0.2828 - val_mae: 0.3416 - val_mse: 0.3179 - val_pearson_correlation: -2.0905e-16 - val_r2_keras: -36.5754 - val_rmse: 0.9982 - val_sae: 378.2104 - val_sse: 527.1113 - learning_rate: 1.0000e-05\n","Epoch 69/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0767 - loss: 0.2186 - mae: 0.2318 - mse: 0.1648 - pearson_correlation: 3.4180e-16 - r2_keras: -105.0600 - rmse: 0.8962 - sae: 2585.4082 - sse: 3289.8494\n","Epoch 69: val_loss did not improve from 0.27988\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0652 - loss: 0.2116 - mae: 0.2245 - mse: 0.1485 - pearson_correlation: 3.0650e-16 - r2_keras: -85.5233 - rmse: 0.8783 - sae: 1888.1776 - sse: 2378.7627 - val_huber_loss: 0.1410 - val_loss: 0.2828 - val_mae: 0.3416 - val_mse: 0.3180 - val_pearson_correlation: 1.1943e-16 - val_r2_keras: -36.5812 - val_rmse: 0.9983 - val_sae: 378.2481 - val_sse: 527.1929 - learning_rate: 1.0000e-05\n","| \u001b[39m21       \u001b[39m | \u001b[39m-0.2828  \u001b[39m | \u001b[39m0.006149 \u001b[39m | \u001b[39m88.63    \u001b[39m | \u001b[39m55.17    \u001b[39m | \u001b[39m70.26    \u001b[39m | \u001b[39m5.745    \u001b[39m | \u001b[39m80.93    \u001b[39m |\n","Epoch 1/1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/step - huber_loss: 0.7050 - loss: 0.8586 - mae: 1.0861 - mse: 2.2351 - pearson_correlation: -2.1387e-16 - r2_keras: -231.8508 - rmse: 1.3279 - sae: 4284.1963 - sse: 7222.7422\n","Epoch 1: val_loss improved from inf to 0.38446, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 633ms/step - huber_loss: 0.6661 - loss: 0.8350 - mae: 1.0701 - mse: 2.0881 - pearson_correlation: -1.2642e-16 - r2_keras: -177.5078 - rmse: 1.2260 - sae: 3073.1775 - sse: 5088.1646 - val_huber_loss: 0.2298 - val_loss: 0.3845 - val_mae: 0.5341 - val_mse: 0.5893 - val_pearson_correlation: -1.9606e-16 - val_r2_keras: -22.6276 - val_rmse: 0.7916 - val_sae: 290.3278 - val_sse: 331.4512 - learning_rate: 0.0034\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2428 - loss: 0.3975 - mae: 0.5523 - mse: 0.6092 - pearson_correlation: 2.8083e-17 - r2_keras: -108.7055 - rmse: 0.9115 - sae: 2829.4299 - sse: 3402.9268\n","Epoch 2: val_loss did not improve from 0.38446\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.2513 - loss: 0.4027 - mae: 0.5629 - mse: 0.6112 - pearson_correlation: -2.6562e-18 - r2_keras: -91.6322 - rmse: 0.9195 - sae: 2068.1157 - sse: 2497.2979 - val_huber_loss: 0.2339 - val_loss: 0.3886 - val_mae: 0.5433 - val_mse: 0.5945 - val_pearson_correlation: -2.9452e-16 - val_r2_keras: -22.5445 - val_rmse: 0.7902 - val_sae: 291.8069 - val_sse: 330.2852 - learning_rate: 0.0034\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.2176 - loss: 0.3723 - mae: 0.5252 - mse: 0.5133 - pearson_correlation: -4.6992e-16 - r2_keras: -84.8059 - rmse: 0.8061 - sae: 2451.0894 - sse: 2661.5908\n","Epoch 3: val_loss did not improve from 0.38446\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.2233 - loss: 0.3758 - mae: 0.5235 - mse: 0.5098 - pearson_correlation: -3.9517e-16 - r2_keras: -75.1245 - rmse: 0.8446 - sae: 1812.9325 - sse: 1996.3326 - val_huber_loss: 0.2428 - val_loss: 0.3973 - val_mae: 0.5385 - val_mse: 0.6235 - val_pearson_correlation: -5.1131e-17 - val_r2_keras: -23.2742 - val_rmse: 0.8023 - val_sae: 285.4871 - val_sse: 340.5209 - learning_rate: 0.0034\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.2701 - loss: 0.4246 - mae: 0.6366 - mse: 0.6027 - pearson_correlation: -1.2175e-16 - r2_keras: -121.4466 - rmse: 0.9630 - sae: 3192.3582 - sse: 3798.1416\n","Epoch 4: val_loss improved from 0.38446 to 0.36592, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.2388 - loss: 0.4055 - mae: 0.6100 - mse: 0.5534 - pearson_correlation: -7.6315e-17 - r2_keras: -96.2502 - rmse: 0.9211 - sae: 2303.4934 - sse: 2715.3066 - val_huber_loss: 0.2117 - val_loss: 0.3659 - val_mae: 0.4793 - val_mse: 0.5277 - val_pearson_correlation: -1.2748e-16 - val_r2_keras: -23.7095 - val_rmse: 0.8095 - val_sae: 284.0757 - val_sse: 346.6270 - learning_rate: 0.0034\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1405 - loss: 0.2947 - mae: 0.3776 - mse: 0.3236 - pearson_correlation: 1.2401e-16 - r2_keras: -95.4941 - rmse: 0.8548 - sae: 2480.7295 - sse: 2993.1250\n","Epoch 5: val_loss improved from 0.36592 to 0.35480, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.1269 - loss: 0.2864 - mae: 0.3693 - mse: 0.2986 - pearson_correlation: 1.3272e-16 - r2_keras: -77.2522 - rmse: 0.8334 - sae: 1809.1090 - sse: 2158.7322 - val_huber_loss: 0.2009 - val_loss: 0.3548 - val_mae: 0.4812 - val_mse: 0.4834 - val_pearson_correlation: 1.9051e-16 - val_r2_keras: -23.5721 - val_rmse: 0.8072 - val_sae: 292.0535 - val_sse: 344.7003 - learning_rate: 0.0034\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1308 - loss: 0.2847 - mae: 0.3756 - mse: 0.2907 - pearson_correlation: -2.7885e-16 - r2_keras: -90.4403 - rmse: 0.8321 - sae: 2471.8506 - sse: 2836.3647\n","Epoch 6: val_loss improved from 0.35480 to 0.35460, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - huber_loss: 0.1237 - loss: 0.2803 - mae: 0.3644 - mse: 0.2770 - pearson_correlation: -2.2707e-16 - r2_keras: -76.0059 - rmse: 0.8377 - sae: 1811.2355 - sse: 2079.1265 - val_huber_loss: 0.2011 - val_loss: 0.3546 - val_mae: 0.4948 - val_mse: 0.4752 - val_pearson_correlation: -3.9225e-17 - val_r2_keras: -23.5045 - val_rmse: 0.8061 - val_sae: 300.1483 - val_sse: 343.7516 - learning_rate: 0.0034\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1336 - loss: 0.2871 - mae: 0.3915 - mse: 0.2886 - pearson_correlation: 3.6679e-16 - r2_keras: -85.4624 - rmse: 0.8092 - sae: 2447.6067 - sse: 2681.9561\n","Epoch 7: val_loss improved from 0.35460 to 0.32844, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - huber_loss: 0.1215 - loss: 0.2796 - mae: 0.3746 - mse: 0.2698 - pearson_correlation: 3.1091e-16 - r2_keras: -72.5116 - rmse: 0.8208 - sae: 1795.6847 - sse: 1974.1256 - val_huber_loss: 0.1754 - val_loss: 0.3284 - val_mae: 0.4607 - val_mse: 0.4054 - val_pearson_correlation: -3.0637e-16 - val_r2_keras: -24.2988 - val_rmse: 0.8191 - val_sae: 307.9411 - val_sse: 354.8938 - learning_rate: 0.0034\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1070 - loss: 0.2600 - mae: 0.3347 - mse: 0.2357 - pearson_correlation: -3.7586e-16 - r2_keras: -91.2708 - rmse: 0.8359 - sae: 2473.1240 - sse: 2862.1262\n","Epoch 8: val_loss improved from 0.32844 to 0.30977, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - huber_loss: 0.1007 - loss: 0.2561 - mae: 0.3296 - mse: 0.2238 - pearson_correlation: -3.8987e-16 - r2_keras: -74.3721 - rmse: 0.8202 - sae: 1804.1635 - sse: 2070.6416 - val_huber_loss: 0.1572 - val_loss: 0.3098 - val_mae: 0.4261 - val_mse: 0.3583 - val_pearson_correlation: 1.7680e-16 - val_r2_keras: -25.6364 - val_rmse: 0.8404 - val_sae: 314.7163 - val_sse: 373.6585 - learning_rate: 0.0034\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.1110 - loss: 0.2635 - mae: 0.3275 - mse: 0.2511 - pearson_correlation: 4.8206e-16 - r2_keras: -96.6819 - rmse: 0.8601 - sae: 2545.4138 - sse: 3029.9690\n","Epoch 9: val_loss improved from 0.30977 to 0.28029, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - huber_loss: 0.1041 - loss: 0.2592 - mae: 0.3291 - mse: 0.2368 - pearson_correlation: 3.7153e-16 - r2_keras: -79.0734 - rmse: 0.8465 - sae: 1861.8107 - sse: 2195.3694 - val_huber_loss: 0.1283 - val_loss: 0.2803 - val_mae: 0.3706 - val_mse: 0.2779 - val_pearson_correlation: -9.4437e-17 - val_r2_keras: -27.9565 - val_rmse: 0.8763 - val_sae: 329.6113 - val_sse: 406.2048 - learning_rate: 0.0034\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - huber_loss: 0.1170 - loss: 0.2690 - mae: 0.3233 - mse: 0.2726 - pearson_correlation: 2.5163e-16 - r2_keras: -108.1356 - rmse: 0.9091 - sae: 2626.6724 - sse: 3385.2490\n","Epoch 10: val_loss improved from 0.28029 to 0.27787, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - huber_loss: 0.1072 - loss: 0.2630 - mae: 0.3213 - mse: 0.2528 - pearson_correlation: 1.8599e-16 - r2_keras: -84.5936 - rmse: 0.8591 - sae: 1901.9335 - sse: 2407.4058 - val_huber_loss: 0.1264 - val_loss: 0.2779 - val_mae: 0.3536 - val_mse: 0.2805 - val_pearson_correlation: -7.6780e-17 - val_r2_keras: -28.4073 - val_rmse: 0.8831 - val_sae: 325.0353 - val_sse: 412.5288 - learning_rate: 0.0034\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.1076 - loss: 0.2590 - mae: 0.3444 - mse: 0.2331 - pearson_correlation: -4.2807e-16 - r2_keras: -98.4453 - rmse: 0.8678 - sae: 2559.6470 - sse: 3084.6694\n","Epoch 11: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.1054 - loss: 0.2576 - mae: 0.3383 - mse: 0.2276 - pearson_correlation: -2.0977e-16 - r2_keras: -83.2907 - rmse: 0.8781 - sae: 1879.1617 - sse: 2267.5142 - val_huber_loss: 0.1602 - val_loss: 0.3110 - val_mae: 0.4449 - val_mse: 0.3671 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -25.1701 - val_rmse: 0.8331 - val_sae: 318.6435 - val_sse: 367.1166 - learning_rate: 0.0034\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1101 - loss: 0.2610 - mae: 0.3397 - mse: 0.2389 - pearson_correlation: 5.8212e-16 - r2_keras: -87.0834 - rmse: 0.8167 - sae: 2433.9531 - sse: 2732.2354\n","Epoch 12: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1097 - loss: 0.2607 - mae: 0.3516 - mse: 0.2347 - pearson_correlation: 3.3632e-16 - r2_keras: -75.1963 - rmse: 0.8397 - sae: 1802.2577 - sse: 2026.4615 - val_huber_loss: 0.1605 - val_loss: 0.3108 - val_mae: 0.3946 - val_mse: 0.3462 - val_pearson_correlation: -1.9090e-16 - val_r2_keras: -32.1516 - val_rmse: 0.9376 - val_sae: 361.7166 - val_sse: 465.0547 - learning_rate: 0.0034\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1142 - loss: 0.2645 - mae: 0.3346 - mse: 0.2495 - pearson_correlation: -1.6448e-16 - r2_keras: -89.4548 - rmse: 0.8277 - sae: 2468.5547 - sse: 2805.7949\n","Epoch 13: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1143 - loss: 0.2645 - mae: 0.3278 - mse: 0.2467 - pearson_correlation: -7.9591e-17 - r2_keras: -78.9893 - rmse: 0.8651 - sae: 1821.8063 - sse: 2101.4485 - val_huber_loss: 0.2036 - val_loss: 0.3533 - val_mae: 0.4759 - val_mse: 0.5060 - val_pearson_correlation: 8.9837e-17 - val_r2_keras: -26.5900 - val_rmse: 0.8554 - val_sae: 322.5418 - val_sse: 387.0359 - learning_rate: 0.0034\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1043 - loss: 0.2539 - mae: 0.3282 - mse: 0.2247 - pearson_correlation: 4.6026e-16 - r2_keras: -85.6642 - rmse: 0.8101 - sae: 2451.4785 - sse: 2688.2163\n","Epoch 14: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0942 - loss: 0.2477 - mae: 0.3200 - mse: 0.2093 - pearson_correlation: 2.1296e-16 - r2_keras: -72.4957 - rmse: 0.8201 - sae: 1797.4056 - sse: 1976.5347 - val_huber_loss: 0.1385 - val_loss: 0.2874 - val_mae: 0.3633 - val_mse: 0.3046 - val_pearson_correlation: -8.2633e-17 - val_r2_keras: -35.6440 - val_rmse: 0.9858 - val_sae: 371.0629 - val_sse: 514.0457 - learning_rate: 0.0034\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1070 - loss: 0.2559 - mae: 0.3101 - mse: 0.2280 - pearson_correlation: -3.3965e-16 - r2_keras: -119.7041 - rmse: 0.9561 - sae: 2762.2559 - sse: 3744.0908\n","Epoch 15: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1192 - loss: 0.2632 - mae: 0.3363 - mse: 0.2411 - pearson_correlation: -1.8865e-16 - r2_keras: -94.2094 - rmse: 0.9085 - sae: 2001.0763 - sse: 2668.9609 - val_huber_loss: 0.1484 - val_loss: 0.2966 - val_mae: 0.3926 - val_mse: 0.3083 - val_pearson_correlation: -2.4208e-16 - val_r2_keras: -39.4844 - val_rmse: 1.0361 - val_sae: 390.9920 - val_sse: 567.9196 - learning_rate: 0.0034\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1488 - loss: 0.2970 - mae: 0.3569 - mse: 0.3319 - pearson_correlation: -4.0420e-17 - r2_keras: -149.0837 - rmse: 1.0661 - sae: 2926.2004 - sse: 4655.4082\n","Epoch 16: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.1461 - loss: 0.2953 - mae: 0.3616 - mse: 0.3223 - pearson_correlation: -1.5880e-16 - r2_keras: -120.2105 - rmse: 1.0355 - sae: 2141.5825 - sse: 3351.7512 - val_huber_loss: 0.1357 - val_loss: 0.2837 - val_mae: 0.3820 - val_mse: 0.2815 - val_pearson_correlation: 1.9415e-16 - val_r2_keras: -36.0915 - val_rmse: 0.9918 - val_sae: 373.5126 - val_sse: 520.3233 - learning_rate: 6.7701e-04\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0884 - loss: 0.2365 - mae: 0.2689 - mse: 0.1853 - pearson_correlation: 6.5775e-16 - r2_keras: -118.7882 - rmse: 0.9524 - sae: 2755.3706 - sse: 3715.6787\n","Epoch 17: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0873 - loss: 0.2358 - mae: 0.2777 - mse: 0.1824 - pearson_correlation: 4.9855e-16 - r2_keras: -96.1018 - rmse: 0.9282 - sae: 2009.9567 - sse: 2679.3809 - val_huber_loss: 0.1372 - val_loss: 0.2851 - val_mae: 0.3806 - val_mse: 0.2863 - val_pearson_correlation: 1.0872e-17 - val_r2_keras: -34.4168 - val_rmse: 0.9691 - val_sae: 364.8236 - val_sse: 496.8310 - learning_rate: 6.7701e-04\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0756 - loss: 0.2235 - mae: 0.2574 - mse: 0.1577 - pearson_correlation: -5.6543e-16 - r2_keras: -107.1338 - rmse: 0.9049 - sae: 2637.6072 - sse: 3354.1738\n","Epoch 18: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0740 - loss: 0.2225 - mae: 0.2627 - mse: 0.1544 - pearson_correlation: -3.4932e-16 - r2_keras: -87.2845 - rmse: 0.8875 - sae: 1925.9124 - sse: 2426.0874 - val_huber_loss: 0.1355 - val_loss: 0.2833 - val_mae: 0.3746 - val_mse: 0.2846 - val_pearson_correlation: 5.5082e-17 - val_r2_keras: -34.0701 - val_rmse: 0.9644 - val_sae: 363.3930 - val_sse: 491.9674 - learning_rate: 6.7701e-04\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0724 - loss: 0.2202 - mae: 0.2507 - mse: 0.1513 - pearson_correlation: 2.1663e-16 - r2_keras: -104.9878 - rmse: 0.8959 - sae: 2613.8071 - sse: 3287.6089\n","Epoch 19: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0692 - loss: 0.2182 - mae: 0.2537 - mse: 0.1461 - pearson_correlation: 1.9903e-16 - r2_keras: -85.5624 - rmse: 0.8789 - sae: 1908.5775 - sse: 2378.2925 - val_huber_loss: 0.1378 - val_loss: 0.2854 - val_mae: 0.3757 - val_mse: 0.2916 - val_pearson_correlation: 1.5432e-16 - val_r2_keras: -34.0438 - val_rmse: 0.9640 - val_sae: 364.0426 - val_sse: 491.5985 - learning_rate: 6.7701e-04\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0692 - loss: 0.2168 - mae: 0.2438 - mse: 0.1441 - pearson_correlation: -2.6023e-16 - r2_keras: -103.5928 - rmse: 0.8900 - sae: 2593.8928 - sse: 3244.3364\n","Epoch 20: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0657 - loss: 0.2146 - mae: 0.2450 - mse: 0.1387 - pearson_correlation: -1.7160e-16 - r2_keras: -84.5695 - rmse: 0.8744 - sae: 1894.1644 - sse: 2348.7065 - val_huber_loss: 0.1388 - val_loss: 0.2862 - val_mae: 0.3786 - val_mse: 0.2947 - val_pearson_correlation: -5.5923e-17 - val_r2_keras: -33.7439 - val_rmse: 0.9599 - val_sae: 363.3251 - val_sse: 487.3911 - learning_rate: 6.7701e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0674 - loss: 0.2148 - mae: 0.2411 - mse: 0.1399 - pearson_correlation: 5.5552e-16 - r2_keras: -102.5049 - rmse: 0.8853 - sae: 2581.1094 - sse: 3210.5938\n","Epoch 21: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0627 - loss: 0.2119 - mae: 0.2399 - mse: 0.1331 - pearson_correlation: 3.7422e-16 - r2_keras: -83.5466 - rmse: 0.8687 - sae: 1884.0707 - sse: 2322.7192 - val_huber_loss: 0.1421 - val_loss: 0.2894 - val_mae: 0.3835 - val_mse: 0.3014 - val_pearson_correlation: 2.1190e-16 - val_r2_keras: -34.9741 - val_rmse: 0.9767 - val_sae: 370.6906 - val_sse: 504.6486 - learning_rate: 1.3540e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0663 - loss: 0.2136 - mae: 0.2368 - mse: 0.1374 - pearson_correlation: -5.2169e-16 - r2_keras: -103.1430 - rmse: 0.8881 - sae: 2586.0796 - sse: 3230.3870\n","Epoch 22: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0618 - loss: 0.2108 - mae: 0.2359 - mse: 0.1310 - pearson_correlation: -3.6519e-16 - r2_keras: -83.9957 - rmse: 0.8707 - sae: 1887.3207 - sse: 2336.1924 - val_huber_loss: 0.1430 - val_loss: 0.2903 - val_mae: 0.3843 - val_mse: 0.3033 - val_pearson_correlation: -5.1316e-17 - val_r2_keras: -35.7715 - val_rmse: 0.9875 - val_sae: 375.3377 - val_sse: 515.8347 - learning_rate: 1.3540e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0655 - loss: 0.2128 - mae: 0.2342 - mse: 0.1358 - pearson_correlation: -3.8563e-16 - r2_keras: -103.4650 - rmse: 0.8894 - sae: 2588.2280 - sse: 3240.3745\n","Epoch 23: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0611 - loss: 0.2101 - mae: 0.2337 - mse: 0.1295 - pearson_correlation: -1.8569e-16 - r2_keras: -84.2302 - rmse: 0.8718 - sae: 1888.8112 - sse: 2343.0840 - val_huber_loss: 0.1442 - val_loss: 0.2914 - val_mae: 0.3849 - val_mse: 0.3061 - val_pearson_correlation: -1.6032e-16 - val_r2_keras: -36.4127 - val_rmse: 0.9960 - val_sae: 379.0573 - val_sse: 524.8288 - learning_rate: 1.3540e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0648 - loss: 0.2120 - mae: 0.2318 - mse: 0.1342 - pearson_correlation: 3.5533e-16 - r2_keras: -103.8270 - rmse: 0.8910 - sae: 2591.1687 - sse: 3251.6035\n","Epoch 24: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0605 - loss: 0.2093 - mae: 0.2315 - mse: 0.1280 - pearson_correlation: 2.4459e-16 - r2_keras: -84.4968 - rmse: 0.8730 - sae: 1890.8016 - sse: 2350.8665 - val_huber_loss: 0.1446 - val_loss: 0.2918 - val_mae: 0.3850 - val_mse: 0.3071 - val_pearson_correlation: -2.3869e-16 - val_r2_keras: -36.6209 - val_rmse: 0.9988 - val_sae: 380.3095 - val_sse: 527.7506 - learning_rate: 1.3540e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0644 - loss: 0.2115 - mae: 0.2301 - mse: 0.1332 - pearson_correlation: -2.2884e-16 - r2_keras: -104.0650 - rmse: 0.8920 - sae: 2593.0312 - sse: 3258.9839\n","Epoch 25: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0600 - loss: 0.2088 - mae: 0.2299 - mse: 0.1270 - pearson_correlation: -2.1690e-16 - r2_keras: -84.6889 - rmse: 0.8740 - sae: 1892.1704 - sse: 2356.1794 - val_huber_loss: 0.1463 - val_loss: 0.2933 - val_mae: 0.3864 - val_mse: 0.3112 - val_pearson_correlation: 1.9697e-17 - val_r2_keras: -36.8979 - val_rmse: 1.0025 - val_sae: 381.7903 - val_sse: 531.6365 - learning_rate: 1.3540e-04\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0638 - loss: 0.2109 - mae: 0.2289 - mse: 0.1319 - pearson_correlation: 1.9841e-16 - r2_keras: -104.4008 - rmse: 0.8934 - sae: 2596.9375 - sse: 3269.3999\n","Epoch 26: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0593 - loss: 0.2081 - mae: 0.2281 - mse: 0.1255 - pearson_correlation: 1.4093e-16 - r2_keras: -84.8894 - rmse: 0.8747 - sae: 1894.4933 - sse: 2362.8496 - val_huber_loss: 0.1469 - val_loss: 0.2939 - val_mae: 0.3867 - val_mse: 0.3127 - val_pearson_correlation: 8.7830e-17 - val_r2_keras: -37.1631 - val_rmse: 1.0060 - val_sae: 383.2071 - val_sse: 535.3561 - learning_rate: 2.7080e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0637 - loss: 0.2108 - mae: 0.2285 - mse: 0.1316 - pearson_correlation: -3.4444e-16 - r2_keras: -104.4167 - rmse: 0.8935 - sae: 2596.9648 - sse: 3269.8940\n","Epoch 27: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0591 - loss: 0.2080 - mae: 0.2277 - mse: 0.1252 - pearson_correlation: -2.5079e-16 - r2_keras: -84.9018 - rmse: 0.8748 - sae: 1894.5050 - sse: 2363.1992 - val_huber_loss: 0.1474 - val_loss: 0.2944 - val_mae: 0.3869 - val_mse: 0.3139 - val_pearson_correlation: -1.9408e-16 - val_r2_keras: -37.3285 - val_rmse: 1.0082 - val_sae: 384.0955 - val_sse: 537.6767 - learning_rate: 2.7080e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0636 - loss: 0.2106 - mae: 0.2282 - mse: 0.1313 - pearson_correlation: 2.5179e-16 - r2_keras: -104.4188 - rmse: 0.8935 - sae: 2596.9543 - sse: 3269.9585\n","Epoch 28: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0590 - loss: 0.2078 - mae: 0.2274 - mse: 0.1249 - pearson_correlation: 1.4670e-16 - r2_keras: -84.9043 - rmse: 0.8748 - sae: 1894.4889 - sse: 2363.2561 - val_huber_loss: 0.1478 - val_loss: 0.2948 - val_mae: 0.3872 - val_mse: 0.3149 - val_pearson_correlation: -2.3219e-16 - val_r2_keras: -37.4201 - val_rmse: 1.0094 - val_sae: 384.5965 - val_sse: 538.9609 - learning_rate: 2.7080e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0635 - loss: 0.2105 - mae: 0.2280 - mse: 0.1311 - pearson_correlation: 1.6665e-16 - r2_keras: -104.4192 - rmse: 0.8935 - sae: 2596.9434 - sse: 3269.9712\n","Epoch 29: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0589 - loss: 0.2077 - mae: 0.2271 - mse: 0.1247 - pearson_correlation: 9.5716e-17 - r2_keras: -84.9079 - rmse: 0.8748 - sae: 1894.4883 - sse: 2363.3025 - val_huber_loss: 0.1481 - val_loss: 0.2951 - val_mae: 0.3874 - val_mse: 0.3157 - val_pearson_correlation: 3.2814e-16 - val_r2_keras: -37.4924 - val_rmse: 1.0103 - val_sae: 384.9734 - val_sse: 539.9753 - learning_rate: 2.7080e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0633 - loss: 0.2103 - mae: 0.2276 - mse: 0.1308 - pearson_correlation: -2.3775e-16 - r2_keras: -104.4619 - rmse: 0.8937 - sae: 2597.2979 - sse: 3271.2959\n","Epoch 30: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0587 - loss: 0.2075 - mae: 0.2267 - mse: 0.1244 - pearson_correlation: -1.6715e-16 - r2_keras: -84.9400 - rmse: 0.8750 - sae: 1894.7294 - sse: 2364.2290 - val_huber_loss: 0.1484 - val_loss: 0.2954 - val_mae: 0.3876 - val_mse: 0.3164 - val_pearson_correlation: -1.4450e-16 - val_r2_keras: -37.5471 - val_rmse: 1.0110 - val_sae: 385.2925 - val_sse: 540.7433 - learning_rate: 2.7080e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0632 - loss: 0.2102 - mae: 0.2273 - mse: 0.1305 - pearson_correlation: 1.5342e-16 - r2_keras: -104.5034 - rmse: 0.8939 - sae: 2597.8564 - sse: 3272.5830\n","Epoch 31: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0586 - loss: 0.2074 - mae: 0.2263 - mse: 0.1241 - pearson_correlation: 1.0036e-16 - r2_keras: -84.9614 - rmse: 0.8751 - sae: 1895.0468 - sse: 2365.0134 - val_huber_loss: 0.1486 - val_loss: 0.2956 - val_mae: 0.3877 - val_mse: 0.3170 - val_pearson_correlation: -1.7316e-16 - val_r2_keras: -37.5900 - val_rmse: 1.0116 - val_sae: 385.5255 - val_sse: 541.3450 - learning_rate: 1.0000e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.0631 - loss: 0.2101 - mae: 0.2272 - mse: 0.1304 - pearson_correlation: -2.8294e-16 - r2_keras: -104.5026 - rmse: 0.8938 - sae: 2597.8013 - sse: 3272.5583\n","Epoch 32: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0585 - loss: 0.2073 - mae: 0.2262 - mse: 0.1239 - pearson_correlation: -1.9632e-16 - r2_keras: -84.9590 - rmse: 0.8750 - sae: 1895.0039 - sse: 2364.9753 - val_huber_loss: 0.1489 - val_loss: 0.2958 - val_mae: 0.3878 - val_mse: 0.3176 - val_pearson_correlation: 7.6819e-17 - val_r2_keras: -37.6456 - val_rmse: 1.0123 - val_sae: 385.8137 - val_sse: 542.1249 - learning_rate: 1.0000e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0631 - loss: 0.2101 - mae: 0.2270 - mse: 0.1303 - pearson_correlation: -2.9178e-16 - r2_keras: -104.5181 - rmse: 0.8939 - sae: 2597.9795 - sse: 3273.0400\n","Epoch 33: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0585 - loss: 0.2073 - mae: 0.2261 - mse: 0.1238 - pearson_correlation: -1.5894e-16 - r2_keras: -84.9720 - rmse: 0.8751 - sae: 1895.1313 - sse: 2365.3274 - val_huber_loss: 0.1490 - val_loss: 0.2959 - val_mae: 0.3879 - val_mse: 0.3179 - val_pearson_correlation: -3.8403e-17 - val_r2_keras: -37.6509 - val_rmse: 1.0124 - val_sae: 385.8539 - val_sse: 542.1994 - learning_rate: 1.0000e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0630 - loss: 0.2100 - mae: 0.2269 - mse: 0.1301 - pearson_correlation: -3.4986e-16 - r2_keras: -104.5161 - rmse: 0.8939 - sae: 2597.9128 - sse: 3272.9761\n","Epoch 34: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0584 - loss: 0.2072 - mae: 0.2260 - mse: 0.1237 - pearson_correlation: -2.5344e-16 - r2_keras: -84.9689 - rmse: 0.8751 - sae: 1895.0812 - sse: 2365.2642 - val_huber_loss: 0.1491 - val_loss: 0.2961 - val_mae: 0.3880 - val_mse: 0.3182 - val_pearson_correlation: 1.7262e-16 - val_r2_keras: -37.6846 - val_rmse: 1.0128 - val_sae: 386.0344 - val_sse: 542.6722 - learning_rate: 1.0000e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0630 - loss: 0.2099 - mae: 0.2267 - mse: 0.1300 - pearson_correlation: -1.7500e-16 - r2_keras: -104.5509 - rmse: 0.8941 - sae: 2598.3120 - sse: 3274.0562\n","Epoch 35: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0584 - loss: 0.2071 - mae: 0.2258 - mse: 0.1236 - pearson_correlation: -7.5311e-17 - r2_keras: -84.9928 - rmse: 0.8752 - sae: 1895.3484 - sse: 2365.9929 - val_huber_loss: 0.1493 - val_loss: 0.2962 - val_mae: 0.3881 - val_mse: 0.3186 - val_pearson_correlation: 5.7506e-17 - val_r2_keras: -37.7032 - val_rmse: 1.0131 - val_sae: 386.1264 - val_sse: 542.9326 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0629 - loss: 0.2099 - mae: 0.2266 - mse: 0.1299 - pearson_correlation: -4.5904e-16 - r2_keras: -104.5720 - rmse: 0.8941 - sae: 2598.5601 - sse: 3274.7104\n","Epoch 36: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0583 - loss: 0.2070 - mae: 0.2256 - mse: 0.1234 - pearson_correlation: -2.9353e-16 - r2_keras: -85.0102 - rmse: 0.8753 - sae: 1895.5231 - sse: 2366.4675 - val_huber_loss: 0.1494 - val_loss: 0.2963 - val_mae: 0.3882 - val_mse: 0.3187 - val_pearson_correlation: 2.1094e-16 - val_r2_keras: -37.6914 - val_rmse: 1.0129 - val_sae: 386.0673 - val_sse: 542.7669 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0628 - loss: 0.2098 - mae: 0.2264 - mse: 0.1297 - pearson_correlation: 1.0580e-16 - r2_keras: -104.5759 - rmse: 0.8942 - sae: 2598.5259 - sse: 3274.8325\n","Epoch 37: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0582 - loss: 0.2070 - mae: 0.2255 - mse: 0.1233 - pearson_correlation: 5.7073e-17 - r2_keras: -85.0132 - rmse: 0.8753 - sae: 1895.5073 - sse: 2366.5537 - val_huber_loss: 0.1496 - val_loss: 0.2965 - val_mae: 0.3884 - val_mse: 0.3193 - val_pearson_correlation: -1.3408e-16 - val_r2_keras: -37.7272 - val_rmse: 1.0134 - val_sae: 386.2580 - val_sse: 543.2689 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0628 - loss: 0.2097 - mae: 0.2262 - mse: 0.1296 - pearson_correlation: -5.6665e-16 - r2_keras: -104.6338 - rmse: 0.8944 - sae: 2599.1973 - sse: 3276.6289\n","Epoch 38: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0582 - loss: 0.2069 - mae: 0.2253 - mse: 0.1231 - pearson_correlation: -3.2393e-16 - r2_keras: -85.0523 - rmse: 0.8755 - sae: 1895.9515 - sse: 2367.7566 - val_huber_loss: 0.1496 - val_loss: 0.2965 - val_mae: 0.3886 - val_mse: 0.3194 - val_pearson_correlation: -2.7799e-16 - val_r2_keras: -37.6988 - val_rmse: 1.0130 - val_sae: 386.1265 - val_sse: 542.8716 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0627 - loss: 0.2096 - mae: 0.2261 - mse: 0.1294 - pearson_correlation: 5.0775e-17 - r2_keras: -104.6445 - rmse: 0.8944 - sae: 2599.3530 - sse: 3276.9590\n","Epoch 39: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0581 - loss: 0.2068 - mae: 0.2252 - mse: 0.1230 - pearson_correlation: -8.4595e-18 - r2_keras: -85.0570 - rmse: 0.8755 - sae: 1896.0459 - sse: 2367.9492 - val_huber_loss: 0.1497 - val_loss: 0.2966 - val_mae: 0.3886 - val_mse: 0.3196 - val_pearson_correlation: -3.4473e-16 - val_r2_keras: -37.7306 - val_rmse: 1.0134 - val_sae: 386.2749 - val_sse: 543.3165 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0626 - loss: 0.2096 - mae: 0.2258 - mse: 0.1293 - pearson_correlation: -6.3751e-16 - r2_keras: -104.6927 - rmse: 0.8947 - sae: 2599.7891 - sse: 3278.4548\n","Epoch 40: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0580 - loss: 0.2067 - mae: 0.2249 - mse: 0.1229 - pearson_correlation: -4.0963e-16 - r2_keras: -85.0902 - rmse: 0.8756 - sae: 1896.3356 - sse: 2368.9585 - val_huber_loss: 0.1498 - val_loss: 0.2967 - val_mae: 0.3888 - val_mse: 0.3198 - val_pearson_correlation: -2.8755e-17 - val_r2_keras: -37.7014 - val_rmse: 1.0131 - val_sae: 386.1351 - val_sse: 542.9071 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0626 - loss: 0.2095 - mae: 0.2257 - mse: 0.1291 - pearson_correlation: 2.7454e-16 - r2_keras: -104.6883 - rmse: 0.8946 - sae: 2599.7700 - sse: 3278.3188\n","Epoch 41: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0580 - loss: 0.2067 - mae: 0.2248 - mse: 0.1227 - pearson_correlation: 2.3688e-16 - r2_keras: -85.0858 - rmse: 0.8756 - sae: 1896.3188 - sse: 2368.8501 - val_huber_loss: 0.1499 - val_loss: 0.2968 - val_mae: 0.3888 - val_mse: 0.3201 - val_pearson_correlation: 6.7058e-17 - val_r2_keras: -37.7183 - val_rmse: 1.0133 - val_sae: 386.2295 - val_sse: 543.1451 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0625 - loss: 0.2094 - mae: 0.2255 - mse: 0.1289 - pearson_correlation: -1.3221e-16 - r2_keras: -104.7309 - rmse: 0.8948 - sae: 2600.2676 - sse: 3279.6406\n","Epoch 42: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0579 - loss: 0.2066 - mae: 0.2246 - mse: 0.1225 - pearson_correlation: -7.5642e-17 - r2_keras: -85.1166 - rmse: 0.8757 - sae: 1896.6515 - sse: 2369.7595 - val_huber_loss: 0.1500 - val_loss: 0.2969 - val_mae: 0.3890 - val_mse: 0.3203 - val_pearson_correlation: 1.1501e-16 - val_r2_keras: -37.7050 - val_rmse: 1.0131 - val_sae: 386.1598 - val_sse: 542.9581 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0624 - loss: 0.2093 - mae: 0.2253 - mse: 0.1288 - pearson_correlation: 2.9708e-16 - r2_keras: -104.7446 - rmse: 0.8949 - sae: 2600.3623 - sse: 3280.0659\n","Epoch 43: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0578 - loss: 0.2065 - mae: 0.2245 - mse: 0.1224 - pearson_correlation: 1.9902e-16 - r2_keras: -85.1226 - rmse: 0.8757 - sae: 1896.7074 - sse: 2370.0063 - val_huber_loss: 0.1501 - val_loss: 0.2969 - val_mae: 0.3890 - val_mse: 0.3205 - val_pearson_correlation: 2.7775e-16 - val_r2_keras: -37.7249 - val_rmse: 1.0134 - val_sae: 386.2499 - val_sse: 543.2376 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0624 - loss: 0.2092 - mae: 0.2250 - mse: 0.1286 - pearson_correlation: -6.0768e-16 - r2_keras: -104.7908 - rmse: 0.8951 - sae: 2600.7761 - sse: 3281.4985\n","Epoch 44: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0578 - loss: 0.2064 - mae: 0.2242 - mse: 0.1222 - pearson_correlation: -4.4647e-16 - r2_keras: -85.1537 - rmse: 0.8759 - sae: 1896.9772 - sse: 2370.9646 - val_huber_loss: 0.1502 - val_loss: 0.2970 - val_mae: 0.3891 - val_mse: 0.3208 - val_pearson_correlation: 2.5857e-16 - val_r2_keras: -37.7280 - val_rmse: 1.0134 - val_sae: 386.2536 - val_sse: 543.2803 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0623 - loss: 0.2091 - mae: 0.2248 - mse: 0.1284 - pearson_correlation: 6.0555e-16 - r2_keras: -104.8180 - rmse: 0.8952 - sae: 2601.0913 - sse: 3282.3413\n","Epoch 45: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - huber_loss: 0.0577 - loss: 0.2063 - mae: 0.2240 - mse: 0.1220 - pearson_correlation: 4.3831e-16 - r2_keras: -85.1757 - rmse: 0.8760 - sae: 1897.1967 - sse: 2371.5730 - val_huber_loss: 0.1503 - val_loss: 0.2971 - val_mae: 0.3893 - val_mse: 0.3210 - val_pearson_correlation: 1.9171e-17 - val_r2_keras: -37.6994 - val_rmse: 1.0130 - val_sae: 386.1160 - val_sse: 542.8793 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0622 - loss: 0.2091 - mae: 0.2247 - mse: 0.1283 - pearson_correlation: 4.1364e-16 - r2_keras: -104.8237 - rmse: 0.8952 - sae: 2601.2021 - sse: 3282.5190\n","Epoch 46: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0576 - loss: 0.2063 - mae: 0.2238 - mse: 0.1219 - pearson_correlation: 2.8249e-16 - r2_keras: -85.1773 - rmse: 0.8760 - sae: 1897.2611 - sse: 2371.6648 - val_huber_loss: 0.1504 - val_loss: 0.2973 - val_mae: 0.3894 - val_mse: 0.3214 - val_pearson_correlation: 5.7439e-17 - val_r2_keras: -37.7394 - val_rmse: 1.0136 - val_sae: 386.3047 - val_sse: 543.4406 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0622 - loss: 0.2090 - mae: 0.2244 - mse: 0.1281 - pearson_correlation: -6.4109e-16 - r2_keras: -104.8771 - rmse: 0.8954 - sae: 2601.6548 - sse: 3284.1758\n","Epoch 47: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0575 - loss: 0.2062 - mae: 0.2236 - mse: 0.1217 - pearson_correlation: -3.9663e-16 - r2_keras: -85.2149 - rmse: 0.8762 - sae: 1897.5677 - sse: 2372.7930 - val_huber_loss: 0.1505 - val_loss: 0.2973 - val_mae: 0.3895 - val_mse: 0.3215 - val_pearson_correlation: 5.7481e-17 - val_r2_keras: -37.7168 - val_rmse: 1.0133 - val_sae: 386.1938 - val_sse: 543.1235 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0621 - loss: 0.2089 - mae: 0.2243 - mse: 0.1280 - pearson_correlation: -9.5450e-17 - r2_keras: -104.8839 - rmse: 0.8955 - sae: 2601.7383 - sse: 3284.3862\n","Epoch 48: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0575 - loss: 0.2061 - mae: 0.2234 - mse: 0.1216 - pearson_correlation: -3.4786e-17 - r2_keras: -85.2168 - rmse: 0.8761 - sae: 1897.6100 - sse: 2372.9021 - val_huber_loss: 0.1506 - val_loss: 0.2975 - val_mae: 0.3896 - val_mse: 0.3219 - val_pearson_correlation: 1.5311e-16 - val_r2_keras: -37.7512 - val_rmse: 1.0137 - val_sae: 386.3643 - val_sse: 543.6065 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0620 - loss: 0.2088 - mae: 0.2241 - mse: 0.1278 - pearson_correlation: -6.2767e-17 - r2_keras: -104.9327 - rmse: 0.8957 - sae: 2602.2795 - sse: 3285.8997\n","Epoch 49: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0574 - loss: 0.2060 - mae: 0.2232 - mse: 0.1214 - pearson_correlation: -4.7613e-17 - r2_keras: -85.2523 - rmse: 0.8763 - sae: 1897.9781 - sse: 2373.9458 - val_huber_loss: 0.1507 - val_loss: 0.2975 - val_mae: 0.3898 - val_mse: 0.3221 - val_pearson_correlation: -2.2034e-16 - val_r2_keras: -37.7180 - val_rmse: 1.0133 - val_sae: 386.1754 - val_sse: 543.1397 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0619 - loss: 0.2087 - mae: 0.2239 - mse: 0.1276 - pearson_correlation: -3.9128e-16 - r2_keras: -104.9283 - rmse: 0.8956 - sae: 2602.1001 - sse: 3285.7637\n","Epoch 50: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0573 - loss: 0.2059 - mae: 0.2230 - mse: 0.1212 - pearson_correlation: -3.5026e-16 - r2_keras: -85.2482 - rmse: 0.8763 - sae: 1897.8555 - sse: 2373.8423 - val_huber_loss: 0.1509 - val_loss: 0.2976 - val_mae: 0.3899 - val_mse: 0.3224 - val_pearson_correlation: -2.1059e-16 - val_r2_keras: -37.7431 - val_rmse: 1.0136 - val_sae: 386.3106 - val_sse: 543.4924 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0619 - loss: 0.2086 - mae: 0.2237 - mse: 0.1275 - pearson_correlation: 2.7776e-16 - r2_keras: -104.9727 - rmse: 0.8958 - sae: 2602.6089 - sse: 3287.1421\n","Epoch 51: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - huber_loss: 0.0572 - loss: 0.2058 - mae: 0.2228 - mse: 0.1211 - pearson_correlation: 1.6114e-16 - r2_keras: -85.2790 - rmse: 0.8764 - sae: 1898.1891 - sse: 2374.7744 - val_huber_loss: 0.1509 - val_loss: 0.2977 - val_mae: 0.3900 - val_mse: 0.3226 - val_pearson_correlation: 3.8315e-16 - val_r2_keras: -37.7219 - val_rmse: 1.0133 - val_sae: 386.1985 - val_sse: 543.1949 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0618 - loss: 0.2086 - mae: 0.2235 - mse: 0.1273 - pearson_correlation: 1.3623e-16 - r2_keras: -104.9856 - rmse: 0.8959 - sae: 2602.7998 - sse: 3287.5422\n","Epoch 52: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - huber_loss: 0.0572 - loss: 0.2057 - mae: 0.2227 - mse: 0.1209 - pearson_correlation: 6.9668e-17 - r2_keras: -85.2858 - rmse: 0.8764 - sae: 1898.3069 - sse: 2375.0203 - val_huber_loss: 0.1511 - val_loss: 0.2979 - val_mae: 0.3901 - val_mse: 0.3230 - val_pearson_correlation: -1.4350e-16 - val_r2_keras: -37.7596 - val_rmse: 1.0138 - val_sae: 386.3824 - val_sse: 543.7242 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0617 - loss: 0.2085 - mae: 0.2233 - mse: 0.1272 - pearson_correlation: -2.7427e-16 - r2_keras: -105.0256 - rmse: 0.8961 - sae: 2603.1892 - sse: 3288.7803\n","Epoch 53: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0571 - loss: 0.2057 - mae: 0.2224 - mse: 0.1207 - pearson_correlation: -1.5304e-16 - r2_keras: -85.3138 - rmse: 0.8766 - sae: 1898.5609 - sse: 2375.8611 - val_huber_loss: 0.1512 - val_loss: 0.2979 - val_mae: 0.3902 - val_mse: 0.3233 - val_pearson_correlation: -9.5735e-17 - val_r2_keras: -37.7388 - val_rmse: 1.0135 - val_sae: 386.2502 - val_sse: 543.4327 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0616 - loss: 0.2084 - mae: 0.2231 - mse: 0.1270 - pearson_correlation: -2.2869e-16 - r2_keras: -105.0281 - rmse: 0.8961 - sae: 2603.1345 - sse: 3288.8601\n","Epoch 54: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0570 - loss: 0.2056 - mae: 0.2222 - mse: 0.1206 - pearson_correlation: -1.3131e-16 - r2_keras: -85.3167 - rmse: 0.8766 - sae: 1898.5278 - sse: 2375.9282 - val_huber_loss: 0.1514 - val_loss: 0.2981 - val_mae: 0.3904 - val_mse: 0.3237 - val_pearson_correlation: 3.0603e-16 - val_r2_keras: -37.7715 - val_rmse: 1.0140 - val_sae: 386.4136 - val_sse: 543.8914 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0616 - loss: 0.2083 - mae: 0.2230 - mse: 0.1268 - pearson_correlation: 5.0237e-17 - r2_keras: -105.0777 - rmse: 0.8963 - sae: 2603.6846 - sse: 3290.3975\n","Epoch 55: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0569 - loss: 0.2055 - mae: 0.2220 - mse: 0.1204 - pearson_correlation: 2.7344e-18 - r2_keras: -85.3514 - rmse: 0.8767 - sae: 1898.8927 - sse: 2376.9734 - val_huber_loss: 0.1514 - val_loss: 0.2981 - val_mae: 0.3905 - val_mse: 0.3238 - val_pearson_correlation: 2.8713e-16 - val_r2_keras: -37.7469 - val_rmse: 1.0137 - val_sae: 386.2791 - val_sse: 543.5457 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0615 - loss: 0.2082 - mae: 0.2227 - mse: 0.1267 - pearson_correlation: -7.6938e-16 - r2_keras: -105.0983 - rmse: 0.8964 - sae: 2603.8564 - sse: 3291.0376\n","Epoch 56: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0568 - loss: 0.2054 - mae: 0.2218 - mse: 0.1203 - pearson_correlation: -4.8120e-16 - r2_keras: -85.3642 - rmse: 0.8768 - sae: 1898.9995 - sse: 2377.3882 - val_huber_loss: 0.1516 - val_loss: 0.2983 - val_mae: 0.3906 - val_mse: 0.3242 - val_pearson_correlation: -4.7781e-17 - val_r2_keras: -37.7950 - val_rmse: 1.0143 - val_sae: 386.5430 - val_sse: 544.2200 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0615 - loss: 0.2082 - mae: 0.2226 - mse: 0.1265 - pearson_correlation: 1.3015e-16 - r2_keras: -105.1661 - rmse: 0.8967 - sae: 2604.6807 - sse: 3293.1411\n","Epoch 57: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0568 - loss: 0.2053 - mae: 0.2216 - mse: 0.1201 - pearson_correlation: 3.5823e-17 - r2_keras: -85.4102 - rmse: 0.8770 - sae: 1899.5449 - sse: 2378.7998 - val_huber_loss: 0.1517 - val_loss: 0.2984 - val_mae: 0.3908 - val_mse: 0.3244 - val_pearson_correlation: -4.7828e-17 - val_r2_keras: -37.7644 - val_rmse: 1.0139 - val_sae: 386.3788 - val_sse: 543.7908 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0614 - loss: 0.2081 - mae: 0.2225 - mse: 0.1264 - pearson_correlation: 2.3384e-16 - r2_keras: -105.1595 - rmse: 0.8966 - sae: 2604.5161 - sse: 3292.9351\n","Epoch 58: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0567 - loss: 0.2052 - mae: 0.2215 - mse: 0.1199 - pearson_correlation: 1.4052e-16 - r2_keras: -85.4049 - rmse: 0.8770 - sae: 1899.4320 - sse: 2378.6528 - val_huber_loss: 0.1517 - val_loss: 0.2984 - val_mae: 0.3907 - val_mse: 0.3244 - val_pearson_correlation: -2.8660e-17 - val_r2_keras: -37.8038 - val_rmse: 1.0144 - val_sae: 386.5932 - val_sse: 544.3445 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0613 - loss: 0.2080 - mae: 0.2223 - mse: 0.1262 - pearson_correlation: -5.3194e-17 - r2_keras: -105.2033 - rmse: 0.8968 - sae: 2604.9546 - sse: 3294.2930\n","Epoch 59: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0566 - loss: 0.2052 - mae: 0.2213 - mse: 0.1198 - pearson_correlation: -2.7777e-18 - r2_keras: -85.4329 - rmse: 0.8771 - sae: 1899.7050 - sse: 2379.5444 - val_huber_loss: 0.1518 - val_loss: 0.2985 - val_mae: 0.3910 - val_mse: 0.3247 - val_pearson_correlation: -1.6264e-16 - val_r2_keras: -37.7598 - val_rmse: 1.0138 - val_sae: 386.3353 - val_sse: 543.7266 - learning_rate: 1.0000e-05\n","Epoch 60/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0612 - loss: 0.2079 - mae: 0.2221 - mse: 0.1261 - pearson_correlation: 2.6458e-17 - r2_keras: -105.2061 - rmse: 0.8968 - sae: 2604.9331 - sse: 3294.3799\n","Epoch 60: val_loss did not improve from 0.27787\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0566 - loss: 0.2051 - mae: 0.2211 - mse: 0.1196 - pearson_correlation: -5.4304e-18 - r2_keras: -85.4361 - rmse: 0.8771 - sae: 1899.6959 - sse: 2379.6179 - val_huber_loss: 0.1519 - val_loss: 0.2985 - val_mae: 0.3909 - val_mse: 0.3249 - val_pearson_correlation: -2.5782e-16 - val_r2_keras: -37.8184 - val_rmse: 1.0146 - val_sae: 386.6419 - val_sse: 544.5493 - learning_rate: 1.0000e-05\n","| \u001b[39m22       \u001b[39m | \u001b[39m-0.2985  \u001b[39m | \u001b[39m0.003385 \u001b[39m | \u001b[39m90.06    \u001b[39m | \u001b[39m55.73    \u001b[39m | \u001b[39m72.27    \u001b[39m | \u001b[39m5.568    \u001b[39m | \u001b[39m77.78    \u001b[39m |\n","=================================================================================================\n","Mejores parámetros encontrados:\n","  learning_rate: 0.006272700480069102\n","  units_1: 89\n","  units_2: 56\n","  units_3: 71\n","  units_4: 7\n","  units_5: 79\n","Epoch 1/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - huber_loss: 0.7964 - loss: 0.9584 - mae: 1.2117 - mse: 2.9168 - pearson_correlation: 3.1972e-17 - r2_keras: -417.6022 - rmse: 1.7805 - sae: 5066.2734 - sse: 12984.5166\n","Epoch 1: val_loss improved from inf to 0.40607, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624ms/step - huber_loss: 0.6972 - loss: 0.8987 - mae: 1.1422 - mse: 2.5624 - pearson_correlation: 6.1926e-17 - r2_keras: -303.6321 - rmse: 1.5440 - sae: 3599.5515 - sse: 8956.2109 - val_huber_loss: 0.2398 - val_loss: 0.4061 - val_mae: 0.6009 - val_mse: 0.5650 - val_pearson_correlation: 6.7884e-17 - val_r2_keras: -22.6326 - val_rmse: 0.7916 - val_sae: 335.7435 - val_sse: 331.5203 - learning_rate: 0.0063\n","Epoch 2/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3079 - loss: 0.4742 - mae: 0.6069 - mse: 0.7812 - pearson_correlation: 3.7854e-16 - r2_keras: -161.8334 - rmse: 1.1105 - sae: 3231.4973 - sse: 5050.8877\n","Epoch 2: val_loss improved from 0.40607 to 0.36859, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.2938 - loss: 0.4655 - mae: 0.5927 - mse: 0.7626 - pearson_correlation: 2.1042e-16 - r2_keras: -128.8033 - rmse: 1.0658 - sae: 2335.7627 - sse: 3616.4949 - val_huber_loss: 0.2026 - val_loss: 0.3686 - val_mae: 0.5247 - val_mse: 0.4896 - val_pearson_correlation: 1.8849e-16 - val_r2_keras: -22.7496 - val_rmse: 0.7936 - val_sae: 323.4350 - val_sse: 333.1614 - learning_rate: 0.0063\n","Epoch 3/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.2525 - loss: 0.4185 - mae: 0.6137 - mse: 0.5840 - pearson_correlation: 2.3841e-16 - r2_keras: -155.3446 - rmse: 1.0881 - sae: 3463.3716 - sse: 4849.6138\n","Epoch 3: val_loss improved from 0.36859 to 0.35218, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.4216 - loss: 0.5214 - mae: 0.7249 - mse: 0.9120 - pearson_correlation: 4.6834e-17 - r2_keras: -149.8864 - rmse: 1.2078 - sae: 2598.8345 - sse: 3780.3601 - val_huber_loss: 0.1864 - val_loss: 0.3522 - val_mae: 0.4752 - val_mse: 0.4550 - val_pearson_correlation: 2.6672e-17 - val_r2_keras: -23.6314 - val_rmse: 0.8082 - val_sae: 308.0363 - val_sse: 345.5313 - learning_rate: 0.0063\n","Epoch 4/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.3997 - loss: 0.5655 - mae: 0.7287 - mse: 0.9938 - pearson_correlation: -8.9730e-17 - r2_keras: -238.6888 - rmse: 1.3473 - sae: 4180.8564 - sse: 7434.8457\n","Epoch 4: val_loss improved from 0.35218 to 0.34897, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.3043 - loss: 0.5073 - mae: 0.6641 - mse: 0.8383 - pearson_correlation: -8.2776e-17 - r2_keras: -172.4481 - rmse: 1.1592 - sae: 2951.6975 - sse: 5116.7441 - val_huber_loss: 0.1838 - val_loss: 0.3490 - val_mae: 0.4936 - val_mse: 0.4451 - val_pearson_correlation: -7.7306e-17 - val_r2_keras: -22.9881 - val_rmse: 0.7976 - val_sae: 319.7052 - val_sse: 336.5078 - learning_rate: 0.0063\n","Epoch 5/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1644 - loss: 0.3295 - mae: 0.4139 - mse: 0.3654 - pearson_correlation: -1.5358e-17 - r2_keras: -100.2867 - rmse: 0.8758 - sae: 2640.9448 - sse: 3141.7869\n","Epoch 5: val_loss did not improve from 0.34897\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.1623 - loss: 0.3281 - mae: 0.4276 - mse: 0.3559 - pearson_correlation: -5.0112e-17 - r2_keras: -84.3300 - rmse: 0.8819 - sae: 1949.1852 - sse: 2303.3843 - val_huber_loss: 0.2035 - val_loss: 0.3679 - val_mae: 0.5073 - val_mse: 0.5039 - val_pearson_correlation: -2.0282e-16 - val_r2_keras: -23.2607 - val_rmse: 0.8021 - val_sae: 316.4880 - val_sse: 340.3324 - learning_rate: 0.0063\n","Epoch 6/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.2332 - loss: 0.3975 - mae: 0.5755 - mse: 0.5354 - pearson_correlation: 1.1363e-16 - r2_keras: -111.9390 - rmse: 0.9248 - sae: 2871.1890 - sse: 3503.2280\n","Epoch 6: val_loss improved from 0.34897 to 0.34402, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - huber_loss: 0.1982 - loss: 0.3762 - mae: 0.5331 - mse: 0.4800 - pearson_correlation: 1.3281e-16 - r2_keras: -94.0445 - rmse: 0.9304 - sae: 2102.7102 - sse: 2567.1750 - val_huber_loss: 0.1804 - val_loss: 0.3440 - val_mae: 0.4454 - val_mse: 0.4578 - val_pearson_correlation: 4.6207e-16 - val_r2_keras: -24.7969 - val_rmse: 0.8271 - val_sae: 303.1938 - val_sse: 361.8816 - learning_rate: 0.0063\n","Epoch 7/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - huber_loss: 0.1878 - loss: 0.3514 - mae: 0.4853 - mse: 0.3855 - pearson_correlation: -5.1984e-16 - r2_keras: -111.6501 - rmse: 0.9236 - sae: 2859.2185 - sse: 3494.2656\n","Epoch 7: val_loss improved from 0.34402 to 0.32222, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - huber_loss: 0.1696 - loss: 0.3402 - mae: 0.4594 - mse: 0.3626 - pearson_correlation: -3.9735e-16 - r2_keras: -90.5420 - rmse: 0.9021 - sae: 2076.6816 - sse: 2522.3743 - val_huber_loss: 0.1595 - val_loss: 0.3222 - val_mae: 0.4194 - val_mse: 0.3941 - val_pearson_correlation: -2.5812e-16 - val_r2_keras: -27.3532 - val_rmse: 0.8671 - val_sae: 313.9243 - val_sse: 397.7414 - learning_rate: 0.0063\n","Epoch 8/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - huber_loss: 0.1469 - loss: 0.3096 - mae: 0.4160 - mse: 0.3016 - pearson_correlation: -2.1776e-16 - r2_keras: -110.9130 - rmse: 0.9206 - sae: 2760.5488 - sse: 3471.4023\n","Epoch 8: val_loss improved from 0.32222 to 0.26467, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - huber_loss: 0.1374 - loss: 0.3037 - mae: 0.4016 - mse: 0.2897 - pearson_correlation: -1.3812e-16 - r2_keras: -87.1891 - rmse: 0.8740 - sae: 1994.8466 - sse: 2473.5671 - val_huber_loss: 0.1030 - val_loss: 0.2647 - val_mae: 0.3196 - val_mse: 0.2332 - val_pearson_correlation: -7.8287e-17 - val_r2_keras: -30.4684 - val_rmse: 0.9135 - val_sae: 350.2530 - val_sse: 441.4424 - learning_rate: 0.0063\n","Epoch 9/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1389 - loss: 0.3006 - mae: 0.3392 - mse: 0.2989 - pearson_correlation: -4.6986e-16 - r2_keras: -124.4207 - rmse: 0.9746 - sae: 2840.1902 - sse: 3890.3931\n","Epoch 9: val_loss improved from 0.26467 to 0.25670, saving model to best_model.keras\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - huber_loss: 0.1243 - loss: 0.2916 - mae: 0.3387 - mse: 0.2777 - pearson_correlation: -3.3214e-16 - r2_keras: -96.1880 - rmse: 0.9099 - sae: 2050.3147 - sse: 2752.8218 - val_huber_loss: 0.0963 - val_loss: 0.2567 - val_mae: 0.3194 - val_mse: 0.2086 - val_pearson_correlation: 4.4960e-17 - val_r2_keras: -33.4032 - val_rmse: 0.9551 - val_sae: 365.3226 - val_sse: 482.6117 - learning_rate: 0.0063\n","Epoch 10/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.1298 - loss: 0.2903 - mae: 0.3456 - mse: 0.2861 - pearson_correlation: -4.7304e-16 - r2_keras: -111.8666 - rmse: 0.9245 - sae: 2680.8242 - sse: 3500.9819\n","Epoch 10: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.1153 - loss: 0.2813 - mae: 0.3403 - mse: 0.2633 - pearson_correlation: -2.6841e-16 - r2_keras: -90.0050 - rmse: 0.8967 - sae: 1958.3442 - sse: 2518.8599 - val_huber_loss: 0.1036 - val_loss: 0.2628 - val_mae: 0.3057 - val_mse: 0.2309 - val_pearson_correlation: -1.0369e-16 - val_r2_keras: -30.6538 - val_rmse: 0.9162 - val_sae: 356.4763 - val_sse: 444.0426 - learning_rate: 0.0063\n","Epoch 11/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.1092 - loss: 0.2683 - mae: 0.3165 - mse: 0.2343 - pearson_correlation: -1.3834e-16 - r2_keras: -98.0780 - rmse: 0.8662 - sae: 2576.5010 - sse: 3073.2769\n","Epoch 11: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0980 - loss: 0.2614 - mae: 0.3087 - mse: 0.2176 - pearson_correlation: -1.3386e-16 - r2_keras: -82.1971 - rmse: 0.8699 - sae: 1890.9047 - sse: 2249.9639 - val_huber_loss: 0.1256 - val_loss: 0.2834 - val_mae: 0.3481 - val_mse: 0.2862 - val_pearson_correlation: -1.1453e-16 - val_r2_keras: -29.1952 - val_rmse: 0.8948 - val_sae: 351.0389 - val_sse: 423.5808 - learning_rate: 0.0063\n","Epoch 12/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.1119 - loss: 0.2696 - mae: 0.3044 - mse: 0.2492 - pearson_correlation: 1.7059e-16 - r2_keras: -101.8733 - rmse: 0.8826 - sae: 2602.9385 - sse: 3190.9998\n","Epoch 12: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0998 - loss: 0.2622 - mae: 0.2969 - mse: 0.2296 - pearson_correlation: 1.3991e-16 - r2_keras: -84.1210 - rmse: 0.8756 - sae: 1903.2914 - sse: 2321.3347 - val_huber_loss: 0.1386 - val_loss: 0.2949 - val_mae: 0.3895 - val_mse: 0.3111 - val_pearson_correlation: -1.7799e-16 - val_r2_keras: -29.8195 - val_rmse: 0.9040 - val_sae: 352.8767 - val_sse: 432.3390 - learning_rate: 0.0063\n","Epoch 13/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.1232 - loss: 0.2795 - mae: 0.3478 - mse: 0.2715 - pearson_correlation: -3.5657e-16 - r2_keras: -102.3985 - rmse: 0.8849 - sae: 2627.0552 - sse: 3207.2930\n","Epoch 13: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1152 - loss: 0.2746 - mae: 0.3502 - mse: 0.2568 - pearson_correlation: -3.2828e-16 - r2_keras: -85.0346 - rmse: 0.8820 - sae: 1928.5737 - sse: 2338.8059 - val_huber_loss: 0.1662 - val_loss: 0.3211 - val_mae: 0.4627 - val_mse: 0.3589 - val_pearson_correlation: 3.1397e-16 - val_r2_keras: -32.2096 - val_rmse: 0.9384 - val_sae: 379.6933 - val_sse: 465.8672 - learning_rate: 0.0063\n","Epoch 14/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.1505 - loss: 0.3055 - mae: 0.4314 - mse: 0.3174 - pearson_correlation: 1.3426e-16 - r2_keras: -101.4128 - rmse: 0.8807 - sae: 2681.9641 - sse: 3176.7175\n","Epoch 14: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.1313 - loss: 0.2936 - mae: 0.4069 - mse: 0.2921 - pearson_correlation: 7.5436e-17 - r2_keras: -83.2952 - rmse: 0.8698 - sae: 1961.3322 - sse: 2305.7263 - val_huber_loss: 0.1288 - val_loss: 0.2823 - val_mae: 0.3636 - val_mse: 0.2760 - val_pearson_correlation: -1.2065e-16 - val_r2_keras: -36.3483 - val_rmse: 0.9952 - val_sae: 382.5885 - val_sse: 523.9266 - learning_rate: 0.0063\n","Epoch 15/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0980 - loss: 0.2515 - mae: 0.3019 - mse: 0.2037 - pearson_correlation: -1.1375e-16 - r2_keras: -109.2402 - rmse: 0.9137 - sae: 2631.7332 - sse: 3419.5139\n","Epoch 15: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0896 - loss: 0.2464 - mae: 0.2997 - mse: 0.1919 - pearson_correlation: -8.4098e-17 - r2_keras: -88.7370 - rmse: 0.8938 - sae: 1922.9149 - sse: 2470.2131 - val_huber_loss: 0.1175 - val_loss: 0.2707 - val_mae: 0.3267 - val_mse: 0.2608 - val_pearson_correlation: -1.9079e-16 - val_r2_keras: -34.8358 - val_rmse: 0.9748 - val_sae: 372.2374 - val_sse: 502.7083 - learning_rate: 0.0013\n","Epoch 16/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0826 - loss: 0.2357 - mae: 0.2524 - mse: 0.1706 - pearson_correlation: 5.1409e-16 - r2_keras: -111.2346 - rmse: 0.9219 - sae: 2696.2229 - sse: 3481.3767\n","Epoch 16: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0753 - loss: 0.2312 - mae: 0.2531 - mse: 0.1606 - pearson_correlation: 3.7615e-16 - r2_keras: -89.0082 - rmse: 0.8898 - sae: 1959.8605 - sse: 2499.0400 - val_huber_loss: 0.1143 - val_loss: 0.2670 - val_mae: 0.3092 - val_mse: 0.2574 - val_pearson_correlation: 3.0864e-16 - val_r2_keras: -33.8577 - val_rmse: 0.9614 - val_sae: 366.8821 - val_sse: 488.9872 - learning_rate: 0.0013\n","Epoch 17/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0783 - loss: 0.2311 - mae: 0.2418 - mse: 0.1616 - pearson_correlation: -2.5142e-16 - r2_keras: -109.9494 - rmse: 0.9166 - sae: 2686.6997 - sse: 3441.5127\n","Epoch 17: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0712 - loss: 0.2267 - mae: 0.2414 - mse: 0.1520 - pearson_correlation: -1.2246e-16 - r2_keras: -88.0834 - rmse: 0.8857 - sae: 1952.6050 - sse: 2471.6655 - val_huber_loss: 0.1154 - val_loss: 0.2677 - val_mae: 0.3144 - val_mse: 0.2604 - val_pearson_correlation: 8.7797e-17 - val_r2_keras: -33.9616 - val_rmse: 0.9629 - val_sae: 369.1453 - val_sse: 490.4455 - learning_rate: 0.0013\n","Epoch 18/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0771 - loss: 0.2294 - mae: 0.2383 - mse: 0.1606 - pearson_correlation: -1.3430e-16 - r2_keras: -111.8204 - rmse: 0.9243 - sae: 2712.7368 - sse: 3499.5474\n","Epoch 18: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0697 - loss: 0.2249 - mae: 0.2367 - mse: 0.1503 - pearson_correlation: -7.1284e-17 - r2_keras: -89.2104 - rmse: 0.8897 - sae: 1969.1898 - sse: 2508.9451 - val_huber_loss: 0.1145 - val_loss: 0.2663 - val_mae: 0.3071 - val_mse: 0.2587 - val_pearson_correlation: -1.1150e-16 - val_r2_keras: -33.5903 - val_rmse: 0.9577 - val_sae: 366.0773 - val_sse: 485.2367 - learning_rate: 0.0013\n","Epoch 19/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0744 - loss: 0.2262 - mae: 0.2321 - mse: 0.1544 - pearson_correlation: 4.3945e-16 - r2_keras: -110.3283 - rmse: 0.9182 - sae: 2683.6055 - sse: 3453.2632\n","Epoch 19: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0674 - loss: 0.2219 - mae: 0.2293 - mse: 0.1448 - pearson_correlation: 2.3668e-16 - r2_keras: -88.5232 - rmse: 0.8884 - sae: 1951.1420 - sse: 2481.6965 - val_huber_loss: 0.1160 - val_loss: 0.2673 - val_mae: 0.3130 - val_mse: 0.2612 - val_pearson_correlation: 2.1979e-16 - val_r2_keras: -33.9295 - val_rmse: 0.9624 - val_sae: 369.4677 - val_sse: 489.9943 - learning_rate: 0.0013\n","Epoch 20/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0731 - loss: 0.2244 - mae: 0.2297 - mse: 0.1517 - pearson_correlation: 3.3810e-16 - r2_keras: -110.5726 - rmse: 0.9192 - sae: 2692.6724 - sse: 3460.8430\n","Epoch 20: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - huber_loss: 0.0658 - loss: 0.2199 - mae: 0.2244 - mse: 0.1417 - pearson_correlation: 2.2060e-16 - r2_keras: -89.0244 - rmse: 0.8921 - sae: 1958.9801 - sse: 2490.7178 - val_huber_loss: 0.1172 - val_loss: 0.2684 - val_mae: 0.3132 - val_mse: 0.2637 - val_pearson_correlation: -2.4418e-16 - val_r2_keras: -33.6955 - val_rmse: 0.9592 - val_sae: 368.0193 - val_sse: 486.7118 - learning_rate: 2.5091e-04\n","Epoch 21/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0720 - loss: 0.2232 - mae: 0.2256 - mse: 0.1496 - pearson_correlation: -2.0687e-16 - r2_keras: -110.0195 - rmse: 0.9169 - sae: 2681.9392 - sse: 3443.6858\n","Epoch 21: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0649 - loss: 0.2189 - mae: 0.2208 - mse: 0.1399 - pearson_correlation: -1.9174e-16 - r2_keras: -88.6402 - rmse: 0.8905 - sae: 1951.7347 - sse: 2479.0977 - val_huber_loss: 0.1177 - val_loss: 0.2688 - val_mae: 0.3135 - val_mse: 0.2649 - val_pearson_correlation: -8.9371e-17 - val_r2_keras: -33.5471 - val_rmse: 0.9571 - val_sae: 367.1420 - val_sse: 484.6310 - learning_rate: 2.5091e-04\n","Epoch 22/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - huber_loss: 0.0712 - loss: 0.2223 - mae: 0.2231 - mse: 0.1480 - pearson_correlation: 3.6773e-17 - r2_keras: -109.4954 - rmse: 0.9148 - sae: 2673.7197 - sse: 3427.4302\n","Epoch 22: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0644 - loss: 0.2181 - mae: 0.2189 - mse: 0.1385 - pearson_correlation: 2.6440e-17 - r2_keras: -88.2734 - rmse: 0.8889 - sae: 1946.1385 - sse: 2468.0566 - val_huber_loss: 0.1180 - val_loss: 0.2690 - val_mae: 0.3139 - val_mse: 0.2656 - val_pearson_correlation: 3.1393e-16 - val_r2_keras: -33.4659 - val_rmse: 0.9560 - val_sae: 366.6922 - val_sse: 483.4916 - learning_rate: 2.5091e-04\n","Epoch 23/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0707 - loss: 0.2217 - mae: 0.2218 - mse: 0.1468 - pearson_correlation: 7.4358e-16 - r2_keras: -109.0061 - rmse: 0.9127 - sae: 2667.1484 - sse: 3412.2505\n","Epoch 23: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0640 - loss: 0.2176 - mae: 0.2178 - mse: 0.1376 - pearson_correlation: 5.0437e-16 - r2_keras: -87.9613 - rmse: 0.8876 - sae: 1941.8124 - sse: 2458.1035 - val_huber_loss: 0.1188 - val_loss: 0.2696 - val_mae: 0.3158 - val_mse: 0.2669 - val_pearson_correlation: 1.9022e-16 - val_r2_keras: -33.5144 - val_rmse: 0.9567 - val_sae: 367.2663 - val_sse: 484.1718 - learning_rate: 2.5091e-04\n","Epoch 24/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0701 - loss: 0.2209 - mae: 0.2196 - mse: 0.1457 - pearson_correlation: -3.2035e-16 - r2_keras: -109.2183 - rmse: 0.9136 - sae: 2668.2407 - sse: 3418.8350\n","Epoch 24: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0636 - loss: 0.2169 - mae: 0.2162 - mse: 0.1366 - pearson_correlation: -2.6553e-16 - r2_keras: -88.0927 - rmse: 0.8881 - sae: 1942.4530 - sse: 2462.3743 - val_huber_loss: 0.1188 - val_loss: 0.2694 - val_mae: 0.3154 - val_mse: 0.2666 - val_pearson_correlation: -2.8000e-16 - val_r2_keras: -33.4935 - val_rmse: 0.9564 - val_sae: 367.1012 - val_sse: 483.8793 - learning_rate: 2.5091e-04\n","Epoch 25/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0696 - loss: 0.2202 - mae: 0.2190 - mse: 0.1443 - pearson_correlation: 3.2950e-16 - r2_keras: -108.7210 - rmse: 0.9115 - sae: 2662.2004 - sse: 3403.4094\n","Epoch 25: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0631 - loss: 0.2162 - mae: 0.2151 - mse: 0.1353 - pearson_correlation: 2.4643e-16 - r2_keras: -87.8441 - rmse: 0.8875 - sae: 1938.8918 - sse: 2453.0625 - val_huber_loss: 0.1193 - val_loss: 0.2699 - val_mae: 0.3170 - val_mse: 0.2677 - val_pearson_correlation: 2.0159e-16 - val_r2_keras: -33.4991 - val_rmse: 0.9565 - val_sae: 367.3805 - val_sse: 483.9568 - learning_rate: 5.0182e-05\n","Epoch 26/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0694 - loss: 0.2200 - mae: 0.2184 - mse: 0.1440 - pearson_correlation: -2.8477e-16 - r2_keras: -108.7935 - rmse: 0.9118 - sae: 2662.7075 - sse: 3405.6567\n","Epoch 26: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0629 - loss: 0.2161 - mae: 0.2145 - mse: 0.1351 - pearson_correlation: -1.9463e-16 - r2_keras: -87.8933 - rmse: 0.8877 - sae: 1939.2317 - sse: 2454.5723 - val_huber_loss: 0.1197 - val_loss: 0.2703 - val_mae: 0.3182 - val_mse: 0.2684 - val_pearson_correlation: -1.4554e-16 - val_r2_keras: -33.5109 - val_rmse: 0.9566 - val_sae: 367.6143 - val_sse: 484.1226 - learning_rate: 5.0182e-05\n","Epoch 27/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0692 - loss: 0.2198 - mae: 0.2177 - mse: 0.1437 - pearson_correlation: 3.6495e-17 - r2_keras: -108.8631 - rmse: 0.9121 - sae: 2663.1201 - sse: 3407.8154\n","Epoch 27: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0628 - loss: 0.2159 - mae: 0.2140 - mse: 0.1348 - pearson_correlation: -5.2466e-19 - r2_keras: -87.9388 - rmse: 0.8879 - sae: 1939.4957 - sse: 2456.0005 - val_huber_loss: 0.1200 - val_loss: 0.2705 - val_mae: 0.3189 - val_mse: 0.2688 - val_pearson_correlation: -7.8360e-17 - val_r2_keras: -33.5148 - val_rmse: 0.9567 - val_sae: 367.7109 - val_sse: 484.1768 - learning_rate: 5.0182e-05\n","Epoch 28/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0691 - loss: 0.2196 - mae: 0.2174 - mse: 0.1434 - pearson_correlation: -1.5187e-16 - r2_keras: -108.8210 - rmse: 0.9120 - sae: 2662.4380 - sse: 3406.5105\n","Epoch 28: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0627 - loss: 0.2157 - mae: 0.2138 - mse: 0.1346 - pearson_correlation: -1.4330e-16 - r2_keras: -87.9117 - rmse: 0.8878 - sae: 1939.0386 - sse: 2455.1414 - val_huber_loss: 0.1201 - val_loss: 0.2706 - val_mae: 0.3193 - val_mse: 0.2691 - val_pearson_correlation: -3.3577e-17 - val_r2_keras: -33.5201 - val_rmse: 0.9568 - val_sae: 367.7895 - val_sse: 484.2518 - learning_rate: 5.0182e-05\n","Epoch 29/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0689 - loss: 0.2194 - mae: 0.2171 - mse: 0.1431 - pearson_correlation: 3.0228e-16 - r2_keras: -108.7822 - rmse: 0.9118 - sae: 2661.8208 - sse: 3405.3081\n","Epoch 29: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0626 - loss: 0.2156 - mae: 0.2135 - mse: 0.1343 - pearson_correlation: 1.8432e-16 - r2_keras: -87.8906 - rmse: 0.8877 - sae: 1938.6476 - sse: 2454.3958 - val_huber_loss: 0.1204 - val_loss: 0.2708 - val_mae: 0.3200 - val_mse: 0.2695 - val_pearson_correlation: 1.1183e-17 - val_r2_keras: -33.5416 - val_rmse: 0.9571 - val_sae: 367.9937 - val_sse: 484.5536 - learning_rate: 5.0182e-05\n","Epoch 30/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0688 - loss: 0.2193 - mae: 0.2164 - mse: 0.1429 - pearson_correlation: 4.4476e-16 - r2_keras: -108.8740 - rmse: 0.9122 - sae: 2662.4438 - sse: 3408.1545\n","Epoch 30: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0625 - loss: 0.2154 - mae: 0.2128 - mse: 0.1341 - pearson_correlation: 3.3277e-16 - r2_keras: -87.9690 - rmse: 0.8881 - sae: 1939.1610 - sse: 2456.4954 - val_huber_loss: 0.1205 - val_loss: 0.2709 - val_mae: 0.3203 - val_mse: 0.2697 - val_pearson_correlation: 2.0133e-16 - val_r2_keras: -33.5376 - val_rmse: 0.9570 - val_sae: 368.0062 - val_sse: 484.4972 - learning_rate: 1.0036e-05\n","Epoch 31/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0688 - loss: 0.2192 - mae: 0.2164 - mse: 0.1428 - pearson_correlation: -2.6083e-16 - r2_keras: -108.8343 - rmse: 0.9120 - sae: 2661.9517 - sse: 3406.9229\n","Epoch 31: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - huber_loss: 0.0624 - loss: 0.2153 - mae: 0.2128 - mse: 0.1340 - pearson_correlation: -1.6148e-16 - r2_keras: -87.9419 - rmse: 0.8880 - sae: 1938.8271 - sse: 2455.6670 - val_huber_loss: 0.1205 - val_loss: 0.2710 - val_mae: 0.3205 - val_mse: 0.2699 - val_pearson_correlation: -1.4543e-16 - val_r2_keras: -33.5341 - val_rmse: 0.9570 - val_sae: 368.0113 - val_sse: 484.4486 - learning_rate: 1.0036e-05\n","Epoch 32/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - huber_loss: 0.0687 - loss: 0.2192 - mae: 0.2164 - mse: 0.1427 - pearson_correlation: -3.0646e-16 - r2_keras: -108.7979 - rmse: 0.9119 - sae: 2661.4934 - sse: 3405.7925\n","Epoch 32: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0624 - loss: 0.2153 - mae: 0.2128 - mse: 0.1339 - pearson_correlation: -1.9953e-16 - r2_keras: -87.9171 - rmse: 0.8879 - sae: 1938.5164 - sse: 2454.9065 - val_huber_loss: 0.1206 - val_loss: 0.2710 - val_mae: 0.3207 - val_mse: 0.2699 - val_pearson_correlation: 2.1258e-16 - val_r2_keras: -33.5321 - val_rmse: 0.9569 - val_sae: 368.0149 - val_sse: 484.4204 - learning_rate: 1.0036e-05\n","Epoch 33/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0687 - loss: 0.2191 - mae: 0.2164 - mse: 0.1426 - pearson_correlation: -1.5568e-16 - r2_keras: -108.7593 - rmse: 0.9117 - sae: 2661.0166 - sse: 3404.5972\n","Epoch 33: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - huber_loss: 0.0624 - loss: 0.2153 - mae: 0.2128 - mse: 0.1338 - pearson_correlation: -9.9967e-17 - r2_keras: -87.8923 - rmse: 0.8878 - sae: 1938.2015 - sse: 2454.1211 - val_huber_loss: 0.1206 - val_loss: 0.2710 - val_mae: 0.3208 - val_mse: 0.2700 - val_pearson_correlation: -1.0068e-16 - val_r2_keras: -33.5355 - val_rmse: 0.9570 - val_sae: 368.0548 - val_sse: 484.4684 - learning_rate: 1.0036e-05\n","Epoch 34/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0687 - loss: 0.2191 - mae: 0.2163 - mse: 0.1425 - pearson_correlation: -1.8799e-16 - r2_keras: -108.7523 - rmse: 0.9117 - sae: 2660.8867 - sse: 3404.3794\n","Epoch 34: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - huber_loss: 0.0623 - loss: 0.2152 - mae: 0.2127 - mse: 0.1338 - pearson_correlation: -1.3964e-16 - r2_keras: -87.8885 - rmse: 0.8878 - sae: 1938.1177 - sse: 2453.9861 - val_huber_loss: 0.1207 - val_loss: 0.2711 - val_mae: 0.3209 - val_mse: 0.2701 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.5366 - val_rmse: 0.9570 - val_sae: 368.0739 - val_sse: 484.4832 - learning_rate: 1.0036e-05\n","Epoch 35/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0686 - loss: 0.2190 - mae: 0.2162 - mse: 0.1424 - pearson_correlation: -4.0250e-17 - r2_keras: -108.7415 - rmse: 0.9116 - sae: 2660.7234 - sse: 3404.0449\n","Epoch 35: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0623 - loss: 0.2152 - mae: 0.2127 - mse: 0.1337 - pearson_correlation: 1.3241e-17 - r2_keras: -87.8816 - rmse: 0.8878 - sae: 1938.0090 - sse: 2453.7666 - val_huber_loss: 0.1207 - val_loss: 0.2711 - val_mae: 0.3210 - val_mse: 0.2701 - val_pearson_correlation: 1.1185e-16 - val_r2_keras: -33.5395 - val_rmse: 0.9570 - val_sae: 368.1025 - val_sse: 484.5241 - learning_rate: 1.0000e-05\n","Epoch 36/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0686 - loss: 0.2189 - mae: 0.2161 - mse: 0.1423 - pearson_correlation: 5.2966e-17 - r2_keras: -108.7337 - rmse: 0.9116 - sae: 2660.5808 - sse: 3403.8018\n","Epoch 36: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0623 - loss: 0.2151 - mae: 0.2126 - mse: 0.1336 - pearson_correlation: -2.1934e-17 - r2_keras: -87.8776 - rmse: 0.8877 - sae: 1937.9181 - sse: 2453.6189 - val_huber_loss: 0.1207 - val_loss: 0.2711 - val_mae: 0.3211 - val_mse: 0.2702 - val_pearson_correlation: -3.1315e-16 - val_r2_keras: -33.5427 - val_rmse: 0.9571 - val_sae: 368.1270 - val_sse: 484.5682 - learning_rate: 1.0000e-05\n","Epoch 37/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0685 - loss: 0.2189 - mae: 0.2160 - mse: 0.1422 - pearson_correlation: 1.3242e-17 - r2_keras: -108.7272 - rmse: 0.9116 - sae: 2660.4604 - sse: 3403.6021\n","Epoch 37: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0622 - loss: 0.2151 - mae: 0.2125 - mse: 0.1335 - pearson_correlation: 4.7941e-17 - r2_keras: -87.8747 - rmse: 0.8877 - sae: 1937.8438 - sse: 2453.5022 - val_huber_loss: 0.1207 - val_loss: 0.2711 - val_mae: 0.3211 - val_mse: 0.2702 - val_pearson_correlation: 1.7892e-16 - val_r2_keras: -33.5453 - val_rmse: 0.9571 - val_sae: 368.1481 - val_sse: 484.6054 - learning_rate: 1.0000e-05\n","Epoch 38/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0685 - loss: 0.2188 - mae: 0.2159 - mse: 0.1421 - pearson_correlation: -7.7290e-16 - r2_keras: -108.7174 - rmse: 0.9115 - sae: 2660.2998 - sse: 3403.2959\n","Epoch 38: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0622 - loss: 0.2150 - mae: 0.2124 - mse: 0.1334 - pearson_correlation: -5.4007e-16 - r2_keras: -87.8691 - rmse: 0.8877 - sae: 1937.7399 - sse: 2453.3093 - val_huber_loss: 0.1208 - val_loss: 0.2711 - val_mae: 0.3212 - val_mse: 0.2702 - val_pearson_correlation: 3.5780e-16 - val_r2_keras: -33.5483 - val_rmse: 0.9572 - val_sae: 368.1656 - val_sse: 484.6470 - learning_rate: 1.0000e-05\n","Epoch 39/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0684 - loss: 0.2188 - mae: 0.2158 - mse: 0.1420 - pearson_correlation: -3.2848e-17 - r2_keras: -108.7073 - rmse: 0.9115 - sae: 2660.1421 - sse: 3402.9824\n","Epoch 39: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0622 - loss: 0.2150 - mae: 0.2123 - mse: 0.1333 - pearson_correlation: -6.2908e-17 - r2_keras: -87.8649 - rmse: 0.8877 - sae: 1937.6469 - sse: 2453.1296 - val_huber_loss: 0.1208 - val_loss: 0.2712 - val_mae: 0.3214 - val_mse: 0.2703 - val_pearson_correlation: 4.3592e-16 - val_r2_keras: -33.5566 - val_rmse: 0.9573 - val_sae: 368.2371 - val_sse: 484.7634 - learning_rate: 1.0000e-05\n","Epoch 40/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0684 - loss: 0.2187 - mae: 0.2156 - mse: 0.1419 - pearson_correlation: 7.0171e-16 - r2_keras: -108.7441 - rmse: 0.9116 - sae: 2660.4155 - sse: 3404.1245\n","Epoch 40: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0621 - loss: 0.2149 - mae: 0.2122 - mse: 0.1333 - pearson_correlation: 4.3539e-16 - r2_keras: -87.8910 - rmse: 0.8878 - sae: 1937.8344 - sse: 2453.9094 - val_huber_loss: 0.1208 - val_loss: 0.2712 - val_mae: 0.3213 - val_mse: 0.2703 - val_pearson_correlation: 0.0000e+00 - val_r2_keras: -33.5581 - val_rmse: 0.9573 - val_sae: 368.2384 - val_sse: 484.7854 - learning_rate: 1.0000e-05\n","Epoch 41/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0683 - loss: 0.2187 - mae: 0.2155 - mse: 0.1418 - pearson_correlation: -4.7145e-17 - r2_keras: -108.7233 - rmse: 0.9116 - sae: 2660.1313 - sse: 3403.4805\n","Epoch 41: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0621 - loss: 0.2149 - mae: 0.2121 - mse: 0.1332 - pearson_correlation: -7.7198e-17 - r2_keras: -87.8782 - rmse: 0.8878 - sae: 1937.6494 - sse: 2453.4924 - val_huber_loss: 0.1209 - val_loss: 0.2712 - val_mae: 0.3214 - val_mse: 0.2704 - val_pearson_correlation: 2.1233e-16 - val_r2_keras: -33.5616 - val_rmse: 0.9573 - val_sae: 368.2591 - val_sse: 484.8344 - learning_rate: 1.0000e-05\n","Epoch 42/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0683 - loss: 0.2186 - mae: 0.2154 - mse: 0.1417 - pearson_correlation: -2.6595e-16 - r2_keras: -108.7106 - rmse: 0.9115 - sae: 2659.9436 - sse: 3403.0867\n","Epoch 42: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0621 - loss: 0.2148 - mae: 0.2120 - mse: 0.1331 - pearson_correlation: -1.5061e-16 - r2_keras: -87.8716 - rmse: 0.8878 - sae: 1937.5321 - sse: 2453.2517 - val_huber_loss: 0.1209 - val_loss: 0.2712 - val_mae: 0.3214 - val_mse: 0.2704 - val_pearson_correlation: 2.2348e-16 - val_r2_keras: -33.5634 - val_rmse: 0.9574 - val_sae: 368.2744 - val_sse: 484.8591 - learning_rate: 1.0000e-05\n","Epoch 43/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - huber_loss: 0.0683 - loss: 0.2185 - mae: 0.2153 - mse: 0.1416 - pearson_correlation: 3.7937e-16 - r2_keras: -108.6998 - rmse: 0.9115 - sae: 2659.7778 - sse: 3402.7510\n","Epoch 43: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0620 - loss: 0.2147 - mae: 0.2119 - mse: 0.1330 - pearson_correlation: 2.6340e-16 - r2_keras: -87.8669 - rmse: 0.8878 - sae: 1937.4335 - sse: 2453.0569 - val_huber_loss: 0.1210 - val_loss: 0.2712 - val_mae: 0.3216 - val_mse: 0.2705 - val_pearson_correlation: -6.7019e-17 - val_r2_keras: -33.5727 - val_rmse: 0.9575 - val_sae: 368.3510 - val_sse: 484.9897 - learning_rate: 1.0000e-05\n","Epoch 44/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0682 - loss: 0.2185 - mae: 0.2151 - mse: 0.1415 - pearson_correlation: 8.9876e-16 - r2_keras: -108.7399 - rmse: 0.9116 - sae: 2660.0923 - sse: 3403.9941\n","Epoch 44: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0620 - loss: 0.2147 - mae: 0.2118 - mse: 0.1329 - pearson_correlation: 5.5723e-16 - r2_keras: -87.8942 - rmse: 0.8879 - sae: 1937.6449 - sse: 2453.8931 - val_huber_loss: 0.1209 - val_loss: 0.2712 - val_mae: 0.3215 - val_mse: 0.2704 - val_pearson_correlation: -1.3405e-16 - val_r2_keras: -33.5705 - val_rmse: 0.9575 - val_sae: 368.3246 - val_sse: 484.9593 - learning_rate: 1.0000e-05\n","Epoch 45/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0682 - loss: 0.2184 - mae: 0.2152 - mse: 0.1414 - pearson_correlation: -1.9767e-16 - r2_keras: -108.6806 - rmse: 0.9114 - sae: 2659.4153 - sse: 3402.1562\n","Epoch 45: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0620 - loss: 0.2146 - mae: 0.2118 - mse: 0.1328 - pearson_correlation: -9.8434e-17 - r2_keras: -87.8590 - rmse: 0.8877 - sae: 1937.2136 - sse: 2452.7178 - val_huber_loss: 0.1210 - val_loss: 0.2712 - val_mae: 0.3217 - val_mse: 0.2706 - val_pearson_correlation: -2.6799e-16 - val_r2_keras: -33.5807 - val_rmse: 0.9576 - val_sae: 368.4091 - val_sse: 485.1023 - learning_rate: 1.0000e-05\n","Epoch 46/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0681 - loss: 0.2183 - mae: 0.2150 - mse: 0.1413 - pearson_correlation: -7.5429e-16 - r2_keras: -108.7253 - rmse: 0.9116 - sae: 2659.7957 - sse: 3403.5430\n","Epoch 46: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - huber_loss: 0.0619 - loss: 0.2146 - mae: 0.2116 - mse: 0.1328 - pearson_correlation: -5.0953e-16 - r2_keras: -87.8905 - rmse: 0.8879 - sae: 1937.4752 - sse: 2453.6624 - val_huber_loss: 0.1210 - val_loss: 0.2712 - val_mae: 0.3218 - val_mse: 0.2706 - val_pearson_correlation: -1.8979e-16 - val_r2_keras: -33.5849 - val_rmse: 0.9577 - val_sae: 368.4361 - val_sse: 485.1609 - learning_rate: 1.0000e-05\n","Epoch 47/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0681 - loss: 0.2183 - mae: 0.2149 - mse: 0.1412 - pearson_correlation: -3.1098e-16 - r2_keras: -108.7121 - rmse: 0.9115 - sae: 2659.5908 - sse: 3403.1306\n","Epoch 47: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0619 - loss: 0.2145 - mae: 0.2115 - mse: 0.1327 - pearson_correlation: -2.3590e-16 - r2_keras: -87.8835 - rmse: 0.8879 - sae: 1937.3451 - sse: 2453.4094 - val_huber_loss: 0.1210 - val_loss: 0.2712 - val_mae: 0.3218 - val_mse: 0.2706 - val_pearson_correlation: 2.3441e-16 - val_r2_keras: -33.5881 - val_rmse: 0.9577 - val_sae: 368.4521 - val_sse: 485.2062 - learning_rate: 1.0000e-05\n","Epoch 48/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0680 - loss: 0.2182 - mae: 0.2148 - mse: 0.1411 - pearson_correlation: 5.4312e-16 - r2_keras: -108.6955 - rmse: 0.9114 - sae: 2659.3716 - sse: 3402.6167\n","Epoch 48: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0618 - loss: 0.2145 - mae: 0.2114 - mse: 0.1326 - pearson_correlation: 3.0590e-16 - r2_keras: -87.8765 - rmse: 0.8879 - sae: 1937.2192 - sse: 2453.1147 - val_huber_loss: 0.1211 - val_loss: 0.2713 - val_mae: 0.3219 - val_mse: 0.2707 - val_pearson_correlation: -2.2315e-17 - val_r2_keras: -33.5984 - val_rmse: 0.9579 - val_sae: 368.5320 - val_sse: 485.3502 - learning_rate: 1.0000e-05\n","Epoch 49/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0680 - loss: 0.2181 - mae: 0.2146 - mse: 0.1410 - pearson_correlation: -1.7213e-16 - r2_keras: -108.7373 - rmse: 0.9116 - sae: 2659.7197 - sse: 3403.9128\n","Epoch 49: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - huber_loss: 0.0618 - loss: 0.2144 - mae: 0.2113 - mse: 0.1325 - pearson_correlation: -1.1380e-16 - r2_keras: -87.9048 - rmse: 0.8880 - sae: 1937.4534 - sse: 2453.9841 - val_huber_loss: 0.1211 - val_loss: 0.2713 - val_mae: 0.3219 - val_mse: 0.2706 - val_pearson_correlation: 1.8970e-16 - val_r2_keras: -33.5957 - val_rmse: 0.9578 - val_sae: 368.5078 - val_sse: 485.3120 - learning_rate: 1.0000e-05\n","Epoch 50/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0679 - loss: 0.2181 - mae: 0.2146 - mse: 0.1409 - pearson_correlation: 8.7970e-17 - r2_keras: -108.6832 - rmse: 0.9114 - sae: 2659.0991 - sse: 3402.2358\n","Epoch 50: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0618 - loss: 0.2143 - mae: 0.2113 - mse: 0.1324 - pearson_correlation: 7.5782e-17 - r2_keras: -87.8724 - rmse: 0.8879 - sae: 1937.0574 - sse: 2452.9082 - val_huber_loss: 0.1212 - val_loss: 0.2713 - val_mae: 0.3221 - val_mse: 0.2708 - val_pearson_correlation: 1.1154e-16 - val_r2_keras: -33.6073 - val_rmse: 0.9580 - val_sae: 368.6008 - val_sse: 485.4756 - learning_rate: 1.0000e-05\n","Epoch 51/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0679 - loss: 0.2180 - mae: 0.2144 - mse: 0.1408 - pearson_correlation: 1.1865e-16 - r2_keras: -108.7262 - rmse: 0.9116 - sae: 2659.4583 - sse: 3403.5708\n","Epoch 51: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - huber_loss: 0.0617 - loss: 0.2143 - mae: 0.2111 - mse: 0.1323 - pearson_correlation: 1.0575e-16 - r2_keras: -87.9035 - rmse: 0.8880 - sae: 1937.3083 - sse: 2453.8264 - val_huber_loss: 0.1212 - val_loss: 0.2713 - val_mae: 0.3221 - val_mse: 0.2708 - val_pearson_correlation: 3.2339e-16 - val_r2_keras: -33.6119 - val_rmse: 0.9580 - val_sae: 368.6317 - val_sse: 485.5400 - learning_rate: 1.0000e-05\n","Epoch 52/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0678 - loss: 0.2179 - mae: 0.2143 - mse: 0.1407 - pearson_correlation: 3.4858e-16 - r2_keras: -108.7140 - rmse: 0.9115 - sae: 2659.2842 - sse: 3403.1914\n","Epoch 52: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0617 - loss: 0.2142 - mae: 0.2110 - mse: 0.1322 - pearson_correlation: 2.0574e-16 - r2_keras: -87.8977 - rmse: 0.8880 - sae: 1937.2039 - sse: 2453.6018 - val_huber_loss: 0.1212 - val_loss: 0.2713 - val_mae: 0.3222 - val_mse: 0.2708 - val_pearson_correlation: -4.4590e-17 - val_r2_keras: -33.6201 - val_rmse: 0.9582 - val_sae: 368.6869 - val_sse: 485.6541 - learning_rate: 1.0000e-05\n","Epoch 53/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - huber_loss: 0.0678 - loss: 0.2179 - mae: 0.2142 - mse: 0.1406 - pearson_correlation: -3.1043e-16 - r2_keras: -108.7175 - rmse: 0.9115 - sae: 2659.2847 - sse: 3403.2993\n","Epoch 53: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - huber_loss: 0.0616 - loss: 0.2142 - mae: 0.2109 - mse: 0.1321 - pearson_correlation: -1.6890e-16 - r2_keras: -87.9033 - rmse: 0.8880 - sae: 1937.2206 - sse: 2453.7122 - val_huber_loss: 0.1212 - val_loss: 0.2713 - val_mae: 0.3222 - val_mse: 0.2708 - val_pearson_correlation: 1.7832e-16 - val_r2_keras: -33.6254 - val_rmse: 0.9582 - val_sae: 368.7222 - val_sse: 485.7282 - learning_rate: 1.0000e-05\n","Epoch 54/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - huber_loss: 0.0677 - loss: 0.2178 - mae: 0.2141 - mse: 0.1405 - pearson_correlation: -3.4065e-16 - r2_keras: -108.7092 - rmse: 0.9115 - sae: 2659.1362 - sse: 3403.0425\n","Epoch 54: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0616 - loss: 0.2141 - mae: 0.2108 - mse: 0.1320 - pearson_correlation: -1.9952e-16 - r2_keras: -87.9016 - rmse: 0.8880 - sae: 1937.1398 - sse: 2453.5852 - val_huber_loss: 0.1213 - val_loss: 0.2714 - val_mae: 0.3223 - val_mse: 0.2709 - val_pearson_correlation: -3.2306e-16 - val_r2_keras: -33.6361 - val_rmse: 0.9584 - val_sae: 368.8092 - val_sse: 485.8791 - learning_rate: 1.0000e-05\n","Epoch 55/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - huber_loss: 0.0677 - loss: 0.2177 - mae: 0.2139 - mse: 0.1404 - pearson_correlation: 3.6007e-16 - r2_keras: -108.7572 - rmse: 0.9117 - sae: 2659.5513 - sse: 3404.5317\n","Epoch 55: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0616 - loss: 0.2140 - mae: 0.2106 - mse: 0.1320 - pearson_correlation: 2.3244e-16 - r2_keras: -87.9343 - rmse: 0.8882 - sae: 1937.4170 - sse: 2454.5857 - val_huber_loss: 0.1213 - val_loss: 0.2713 - val_mae: 0.3222 - val_mse: 0.2708 - val_pearson_correlation: 1.7826e-16 - val_r2_keras: -33.6332 - val_rmse: 0.9583 - val_sae: 368.7725 - val_sse: 485.8377 - learning_rate: 1.0000e-05\n","Epoch 56/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.2177 - mae: 0.2139 - mse: 0.1403 - pearson_correlation: 1.9233e-16 - r2_keras: -108.6990 - rmse: 0.9115 - sae: 2658.8606 - sse: 3402.7249\n","Epoch 56: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - huber_loss: 0.0615 - loss: 0.2140 - mae: 0.2106 - mse: 0.1318 - pearson_correlation: 7.4865e-18 - r2_keras: -87.9003 - rmse: 0.8881 - sae: 1936.9813 - sse: 2453.4380 - val_huber_loss: 0.1214 - val_loss: 0.2714 - val_mae: 0.3224 - val_mse: 0.2710 - val_pearson_correlation: -5.5681e-17 - val_r2_keras: -33.6444 - val_rmse: 0.9585 - val_sae: 368.8686 - val_sse: 485.9958 - learning_rate: 1.0000e-05\n","Epoch 57/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - huber_loss: 0.0676 - loss: 0.2176 - mae: 0.2137 - mse: 0.1402 - pearson_correlation: 8.7164e-16 - r2_keras: -108.7497 - rmse: 0.9117 - sae: 2659.3242 - sse: 3404.2971\n","Epoch 57: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0615 - loss: 0.2139 - mae: 0.2104 - mse: 0.1318 - pearson_correlation: 5.1265e-16 - r2_keras: -87.9340 - rmse: 0.8882 - sae: 1937.2896 - sse: 2454.4858 - val_huber_loss: 0.1213 - val_loss: 0.2714 - val_mae: 0.3224 - val_mse: 0.2709 - val_pearson_correlation: -1.8931e-16 - val_r2_keras: -33.6447 - val_rmse: 0.9585 - val_sae: 368.8616 - val_sse: 485.9994 - learning_rate: 1.0000e-05\n","Epoch 58/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - huber_loss: 0.0675 - loss: 0.2176 - mae: 0.2137 - mse: 0.1400 - pearson_correlation: 7.6828e-16 - r2_keras: -108.6990 - rmse: 0.9115 - sae: 2658.7273 - sse: 3402.7271\n","Epoch 58: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - huber_loss: 0.0614 - loss: 0.2139 - mae: 0.2104 - mse: 0.1316 - pearson_correlation: 5.6730e-16 - r2_keras: -87.9053 - rmse: 0.8881 - sae: 1936.9163 - sse: 2453.4976 - val_huber_loss: 0.1214 - val_loss: 0.2714 - val_mae: 0.3226 - val_mse: 0.2710 - val_pearson_correlation: -8.9050e-17 - val_r2_keras: -33.6550 - val_rmse: 0.9586 - val_sae: 368.9504 - val_sse: 486.1448 - learning_rate: 1.0000e-05\n","Epoch 59/1000\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - huber_loss: 0.0675 - loss: 0.2175 - mae: 0.2135 - mse: 0.1400 - pearson_correlation: -5.7034e-16 - r2_keras: -108.7483 - rmse: 0.9117 - sae: 2659.1599 - sse: 3404.2563\n","Epoch 59: val_loss did not improve from 0.25670\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - huber_loss: 0.0614 - loss: 0.2138 - mae: 0.2102 - mse: 0.1316 - pearson_correlation: -3.3081e-16 - r2_keras: -87.9400 - rmse: 0.8883 - sae: 1937.2134 - sse: 2454.5383 - val_huber_loss: 0.1214 - val_loss: 0.2714 - val_mae: 0.3226 - val_mse: 0.2711 - val_pearson_correlation: -1.3354e-16 - val_r2_keras: -33.6619 - val_rmse: 0.9587 - val_sae: 368.9898 - val_sse: 486.2413 - learning_rate: 1.0000e-05\n"]}],"source":["# Función que entrena el modelo y devuelve la pérdida final, el historial y el modelo\n","def train_model_with_params(units_1, units_2, units_3, units_4, units_5, learning_rate):\n","    model = Sequential([\n","        Dense(int(units_1), input_dim=X_train.shape[1], kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(units_2), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(units_3), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(units_4), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(units_5), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(1, activation='linear')\n","    ])\n","\n","    # Usar Huber como pérdida y agregar Huber Loss como métrica\n","    model.compile(optimizer=RMSprop(learning_rate),\n","                  loss=tf.keras.losses.Huber(), #----------------------------\n","                  metrics=['mae', 'mse', rmse, sse, sae, r2_keras, pearson_correlation, tf.keras.losses.Huber(name='huber_loss')])\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True) #----------------50\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n","    checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n","\n","    history = model.fit(X_train, y_train,\n","                        validation_data=(X_val, y_val),\n","                        epochs=1000,   #---------------1000\n","                        batch_size=64,\n","                        callbacks=[early_stopping, reduce_lr, checkpoint],\n","                        verbose=1)\n","\n","    return -history.history['val_loss'][-1], history, model\n","\n","# Función solo para la optimización bayesiana (retorna solo la pérdida)\n","def train_model_for_optimization(units_1, units_2, units_3, units_4, units_5, learning_rate):\n","\n","    val_loss, _, _ = train_model_with_params(units_1, units_2, units_3, units_4, units_5, learning_rate)\n","    return val_loss\n","\n","# Definir los límites para la optimización\n","pbounds = {\n","    'units_1': (5, 100),\n","    'units_2': (5, 100),\n","    'units_3': (5, 100),\n","    'units_4': (5, 100),\n","    'units_5': (5, 100),\n","    'learning_rate': (0.0001, 0.01)\n","}\n","\n","# Crear una instancia de BayesianOptimization con semilla\n","optimizer = BayesianOptimization(\n","    f=train_model_for_optimization,\n","    pbounds=pbounds,\n","    random_state=42,  # Fijar la semilla para la optimización bayesiana\n","    verbose=2\n",")\n","\n","# Ejecutar la optimización\n","optimizer.maximize(init_points=2, n_iter=20) #---------------20\n","\n","# Recuperar los mejores hiperparámetros\n","best_params = optimizer.max['params']\n","\n","# Redondear los valores de las unidades a enteros para las capas\n","best_params['units_1'] = int(round(best_params['units_1']))\n","best_params['units_2'] = int(round(best_params['units_2']))\n","best_params['units_3'] = int(round(best_params['units_3']))\n","best_params['units_4'] = int(round(best_params['units_4']))\n","best_params['units_5'] = int(round(best_params['units_5']))\n","\n","# Imprimir los mejores hiperparámetros encontrados\n","print(\"Mejores parámetros encontrados:\")\n","for param, value in best_params.items():\n","    print(f\"  {param}: {value}\")\n","\n","# Entrenar el modelo con los mejores hiperparámetros encontrados y obtener el historial y el modelo\n","val_loss, history, model = train_model_with_params(\n","    best_params['units_1'],\n","    best_params['units_2'],\n","    best_params['units_3'],\n","    best_params['units_4'],\n","    best_params['units_5'],\n","    best_params['learning_rate']\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LFLJLT-xqlOu","outputId":"054621a9-2b99-4182-f867-2d22232c1828","executionInfo":{"status":"ok","timestamp":1726378234247,"user_tz":300,"elapsed":1164,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 4 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABKQAAAMWCAYAAADPhl4gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hTZRsG8DvpSLpb6IK2tFBm2RYpQ2UVqyxBkKkM2UNF5FMQZENVFEGmIAgie4gICEIFZAnK3rOlLdABpXsn5/sj5NCQtE3apOm4f9eVq83JGe9JM94+53mfVyIIggAiIiIiIiIiIqISIjV3A4iIiIiIiIiIqGJhQIqIiIiIiIiIiEoUA1JERERERERERFSiGJAiIiIiIiIiIqISxYAUERERERERERGVKAakiIiIiIiIiIioRDEgRUREREREREREJYoBKSIiIiIiIiIiKlEMSFGhLl26hBkzZiAqKsrcTSEiIiIiIiKicoABKSpQUlISevTogadPn8LHx6dY+4qIiIBEIsHatWvFZTNmzIBEItFre4lEghkzZhSrDS+KioqCXC7HiRMnjLrfiqRt27Zo0KBBiRzryZMnsLOzw759+4q1n7Vr10IikSAiIsI4DSvHDHmPUvG0bdsWbdu2NXcziKgUU39//ffffyV6XD8/PwwePLhEj1la6epDmOLzW6lUokGDBpg7d65R92tM+/fvh729PeLj44u1n8GDB8PPz884jSrn2FcoOab435O0MSBVgai/QNU3uVyO2rVrY9y4cYiNjdW5zZAhQ9C0aVN89913JdzakjFr1iwEBQWhdevW4rLBgwfD3t7ejK0yvsLOSSKRYNy4cSXYoqKpXLkyhg0bhi+++MLcTSkxy5Yt0wjiViTz5s3Drl27zN2McuXkyZOYMWMGEhMTzd0UIqN7sZ/z4u2ff/4xdxML1bt3b0gkEnz22WfmborRmOp7zM/PDxKJBMHBwTofX7Vqlfi3L+kAnjFs2rQJUVFRGv2zvK/x48ePa20jCAJ8fHwgkUjQpUsXnftNTEyEXC6HRCLB9evXda4zePDgfN9HcrlcXO+NN95AzZo1ERoaWsyzLRvS09MxY8YMHDlyxNxNKXEPHz7EjBkzcOHCBXM3pVzZuHEjFi5caO5mmJWluRtAJW/WrFmoXr06MjMzcfz4cSxfvhz79u3DlStXYGtrK64XERGBZs2aYcKECZBKTRO7nDp1KiZNmmSSfRcmPj4e69atw7p168xyfCqaUaNG4fvvv8dff/2F9u3bm7s5Jrds2TK4urpWyCvT8+bNQ69evdC9e3dzN6VE/PnnnyY/xsmTJzFz5kwMHjwYzs7OJj8ekTmo+zkvqlmzphlao7/k5GT8/vvv8PPzw6ZNm/Dll1+WiwxVU36PyeVyHD58GDExMfD09NR4bMOGDZDL5cjMzDT6cV9kis/v+fPno2/fvnByctJ6TC6XY+PGjXjllVc0lh89ehTR0dGQyWT57nfbtm2QSCTw9PTEhg0bMGfOHJ3ryWQy/Pjjj1rLLSwsNO6PHDkSEydOxMyZM+Hg4KDPqZVZ6enpmDlzJgBUuCylhw8fYubMmfDz80OTJk3M3ZwSkZGRAUtL04ZLNm7ciCtXrmD8+PEmPU5pxoBUBfTmm2+iWbNmAIBhw4ahcuXKWLBgAX777Tf069dPXM/Pzw+ff/65QftOT0/XCGoVxtLS0uRv9Pz88ssvsLS0RNeuXc1yfNKfUqlEdnY25HI56tWrhwYNGmDt2rWlJiCVlpYGOzs7czejQisPfwNra2tzN4GoXMjbz9FXbm4ulEqlzvdhcT9fBEFAZmYmbGxsClxvx44dUCgUWLNmDdq3b4+///4bbdq0KfJxK4LWrVvj33//xZYtW/DRRx+Jy6Ojo3Hs2DH06NEDO3bsMHk7jP35ff78eVy8eBHffvutzsc7deqEbdu24fvvv9foR2/cuBGBgYF4/Phxvvv+5Zdf0KlTJ/j6+mLjxo35BqQsLS3x7rvvFtrWnj174oMPPsC2bdvw/vvvF7p+SSgPfYKyztD/CUujvNmAZDocskfiP/Xh4eHisl9++QWBgYGwsbFBpUqV0LdvX62i5uraQWfPnsVrr70GW1tbMYCVmJiIwYMHw8nJCc7Ozhg0aJDOISK66tNkZWXh448/hpubGxwcHNCtWzdER0drbXv//n2MGTMGderUgY2NDSpXrox33nlH77pAu3btQlBQUJGH523btk18jlxdXfHuu+/iwYMHGuvExMRgyJAh8Pb2hkwmQ5UqVfDWW29ptPG///5DSEgIXF1dYWNjg+rVq5v9Cz2/GktHjhyBRCLRmap89uxZtGrVSjyHFStWaK2TlZWF6dOno2bNmpDJZPDx8cGnn36KrKwsjfXUQwg3bNiA+vXrQyaTYf/+/eLjHTt2xO+//w5BEAo9l6tXr6J9+/awsbGBt7c35syZA6VSqbVefuPEX6yboX5ujh49ijFjxsDd3R3e3t4A9H9Nqvdx4sQJTJgwAW5ubrCzs0OPHj006jD4+fnh6tWrOHr0qJgqn/eKXGJiIsaPHw8fHx/IZDLUrFkTX331lc7z0+WPP/7Aq6++Cjs7Ozg4OKBz5864evWqXtvqcvr0abzxxhtwcnKCra0t2rRpo1WfTf2ev3Pnjpil4+TkhCFDhiA9PV1cTyKRIC0tDevWrRPPXf13UO/j2rVr6N+/P1xcXDSuEhvy+XXt2jW0a9cOtra28PLywtdff62xXnZ2NqZNm4bAwEA4OTnBzs4Or776Kg4fPqyxnrpG3jfffIOlS5eiRo0asLW1xeuvv46oqCgIgoDZs2fD29sbNjY2eOutt5CQkKDVphevuBr6ntm1axcaNGgAmUyG+vXra7xvZsyYgf/9738AgOrVq4vPq/r1mZubi9mzZ8Pf3x8ymUy8KPHisYjKurzv14ULF4qv+WvXrhX4+aLve8TPzw9dunTBgQMH0KxZM9jY2OCHH34otF0bNmxAx44d0a5dO9SrVw8bNmzId9309HSMHDkSlStXhqOjIwYOHIinT59qrKNP/yItLQ2ffPKJ+D1Sp04dfPPNN4V+v+ZXX/DF/kNh32P37t3DO++8g0qVKsHW1hYtWrTA3r17C3mmnpPL5Xj77bexceNGjeWbNm2Ci4sLQkJCdG5348YN9OrVC5UqVYJcLkezZs2we/durfX07UPo+vyOi4vD0KFD4eHhAblcjsaNG+udlb9r1y5YW1vjtdde0/l4v3798OTJExw8eFBclp2dje3bt6N///757jcyMhLHjh1D37590bdvX4SHh+PkyZN6tSk/7u7uaNSoEX777Te91ld/T8nlcjRo0AC//vqr1jr59Td11aNVl6W4e/cuOnXqBAcHBwwYMAAAcOzYMbzzzjuoVq2a+B368ccfIyMjQ2O/6n08ePAA3bt3h729Pdzc3DBx4kQoFArx2G5ubgCAmTNniq/nvH1HfV9XuiiVSixcuBD169eHXC6Hh4cHRo4cqfW+NoSx+kNHjhzByy+/DEBVzkV97uq/Q0H/ExqzHwMY3tc+fvw4PvzwQ7i5ucHZ2RkjR45EdnY2EhMTMXDgQLi4uMDFxQWffvqp1ueerv8NHjx4gPfffx8eHh5iG9esWaOxjvr1u3XrVsydOxfe3t6Qy+Xo0KED7ty5o/Hc7927F/fv3xef07y11IrzGVKWMEOKcPfuXQCq+jwAMHfuXHzxxRfo3bs3hg0bhvj4eCxevBivvfYazp8/rzHM48mTJ3jzzTfRt29fvPvuu/Dw8IAgCHjrrbdw/PhxjBo1CvXq1cOvv/6KQYMG6dWeYcOG4ZdffkH//v3RqlUr/PXXX+jcubPWev/++y9OnjyJvn37wtvbGxEREVi+fDnatm2La9euFRiVz8nJwb///ovRo0cb8Ew9t3btWgwZMgQvv/wyQkNDERsbi0WLFuHEiRMaz1HPnj1x9epVfPDBB/Dz80NcXBwOHjyIyMhI8f7rr78ONzc3TJo0Cc7OzoiIiMDOnTuL1K7CFHTFrDiePn2KTp06oXfv3ujXrx+2bt2K0aNHw9raWuz8KpVKdOvWDcePH8eIESNQr149XL58Gd999x1u3bqlVSvor7/+wtatWzFu3Di4urpqfEAHBgbiu+++w9WrVwssqB4TE4N27dohNzcXkyZNgp2dHVauXFnoVWp9jBkzBm5ubpg2bRrS0tIAGP6a/OCDD+Di4oLp06cjIiICCxcuxLhx47BlyxYAwMKFC/HBBx/A3t4eU6ZMAQB4eHgAUP0z0qZNGzx48AAjR45EtWrVcPLkSUyePBmPHj0qdDz6+vXrMWjQIISEhOCrr75Ceno6li9fjldeeQXnz583uLjoX3/9hTfffBOBgYGYPn06pFIpfvrpJ7Rv3x7Hjh1D8+bNNdbv3bs3qlevjtDQUJw7dw4//vgj3N3d8dVXX4ntGzZsGJo3b44RI0YAAPz9/TX28c4776BWrVqYN2+e2Ikw5PPr6dOneOONN/D222+jd+/e2L59Oz777DM0bNgQb775JgDVEJoff/wR/fr1w/Dhw5GSkoLVq1cjJCQEZ86c0Upb37BhA7Kzs/HBBx8gISEBX3/9NXr37o327dvjyJEj+Oyzz3Dnzh0sXrwYEydO1OrE5GXoe+b48ePYuXMnxowZAwcHB3z//ffo2bMnIiMjUblyZbz99tu4desWNm3ahO+++w6urq4AIHawhw0bhnXr1qFXr1745JNPcPr0aYSGhuL69es6/2EgKq2SkpK0vu8kEonYz1H76aefkJmZiREjRkAmk6FSpUriY7o+Xwx5j9y8eRP9+vXDyJEjMXz4cNSpU6fANj98+BCHDx8W/9no168fvvvuOyxZskRn9s24cePg7OyMGTNm4ObNm1i+fDnu378v/iOkT/9CEAR069YNhw8fxtChQ9GkSRMcOHAA//vf//DgwQOj1A8t6HssNjYWrVq1Qnp6Oj788ENUrlwZ69atQ7du3bB9+3b06NFDr2P0798fr7/+Ou7evSt+T2zcuBG9evWClZWV1vpXr15F69at4eXlJfYNtm7diu7du2PHjh3icYvTh8jIyEDbtm1x584djBs3DtWrV8e2bdswePBgJCYmamRz6XLy5Ek0aNBAZ/sBVaCvZcuW2LRpk/h99ccffyApKQl9+/bF999/r3O7TZs2wc7ODl26dIGNjQ38/f2xYcMGtGrVSuf6uvqN1tbWcHR01FgWGBioV83HP//8Ez179kRAQABCQ0Px5MkT8cJtceTm5iIkJASvvPIKvvnmG7G/tW3bNqSnp2P06NGoXLkyzpw5g8WLFyM6Ohrbtm3T2IdCoUBISAiCgoLwzTff4NChQ/j222/h7++P0aNHw83NDcuXL8fo0aPRo0cPvP322wCARo0aAdD/dZWfkSNHiv9ffPjhhwgPD8eSJUtw/vx5nDhxIt/XQn6M2R+qV68eZs2ahWnTpmHEiBF49dVXAUDjdaPrf0Jj92OAovW1PT09MXPmTPzzzz9YuXIlnJ2dcfLkSVSrVg3z5s3Dvn37MH/+fDRo0AADBw7M9zmNjY1FixYtxOCZm5sb/vjjDwwdOhTJyclaw+6+/PJLSKVSTJw4EUlJSfj6668xYMAAnD59GgAwZcoUJCUlITo6Wvy8VSdKFPczpEwRqML46aefBADCoUOHhPj4eCEqKkrYvHmzULlyZcHGxkaIjo4WIiIiBAsLC2Hu3Lka216+fFmwtLTUWN6mTRsBgLBixQqNdXft2iUAEL7++mtxWW5urvDqq68KAISffvpJXD59+nQh78vwwoULAgBhzJgxGvvs37+/AECYPn26uCw9PV3rHE+dOiUAEH7++ecCn4s7d+4IAITFixdrPTZo0CDBzs4u322zs7MFd3d3oUGDBkJGRoa4fM+ePQIAYdq0aYIgCMLTp08FAML8+fPz3devv/4qABD+/fffAttbXIMGDRIAFHgbO3asuL76tRIeHq6xn8OHDwsAhMOHD4vL1K+Db7/9VlyWlZUlNGnSRHB3dxeys7MFQRCE9evXC1KpVDh27JjGPlesWCEAEE6cOCEuAyBIpVLh6tWrOs/n5MmTAgBhy5YtBZ73+PHjBQDC6dOnxWVxcXGCk5OT1vm9+PpS8/X1FQYNGiTeVz83r7zyipCbm6uxrr6vSfU+goODBaVSKS7/+OOPBQsLCyExMVFcVr9+faFNmzZa+509e7ZgZ2cn3Lp1S2P5pEmTBAsLCyEyMlJrG7WUlBTB2dlZGD58uMbymJgYwcnJSWP5i+9RXZRKpVCrVi0hJCRE43zS09OF6tWrCx07dtTa3/vvv6+xjx49egiVK1fWWGZnZ6fx3L+4j379+mksL8rnV96/S1ZWluDp6Sn07NlTXJabmytkZWVp7O/p06eCh4eHxjmEh4cLAAQ3NzeNv9/kyZMFAELjxo2FnJwccXm/fv0Ea2trITMzU6NNef/Whr5nrK2thTt37ojLLl68qPU5N3/+fJ3vbfVn77BhwzSWT5w4UQAg/PXXXwJRaaf+bNV1k8lk4nrq96ujo6MQFxensY/8Pl8MeY/4+voKAIT9+/fr3fZvvvlGsLGxEZKTkwVBEIRbt24JAIRff/1V5zkGBgaK36+CIAhff/21AED47bffBEHQr3+h7q/NmTNHY3mvXr0EiUSi8Xny4ndhft8NuvoP+X2Pqb+j837GpaSkCNWrVxf8/PwEhUKRb9vVbercubOQm5sreHp6CrNnzxYEQRCuXbsmABCOHj0qtifv89ChQwehYcOGGp+/SqVSaNWqlVCrVi2t9unTh3jx83vhwoUCAOGXX34Rl2VnZwstW7YU7O3txb9zfry9vTW+i9Tyns+SJUsEBwcHse/xzjvvCO3atdN4bl7UsGFDYcCAAeL9zz//XHB1ddX4fhKEgvuNISEhWvudN2+eAECIjY0t8LyaNGkiVKlSReN78s8//xQACL6+vuIyXf1NQXj+3s37v4S6rZMmTdI6nq5+WWhoqCCRSIT79+9r7WPWrFka6zZt2lQIDAwU78fHx+fbX9T3daXLsWPHBADChg0bNJbv379fa/mLrzVdTNEf+vfff7We+xf38eL/hKboxxja136xb9qyZUtBIpEIo0aNEpfl5uYK3t7eWs/ri3/roUOHClWqVBEeP36ssV7fvn0FJycnsW3q12+9evU0+pCLFi0SAAiXL18Wl3Xu3Fnjta9W3M+QsoRD9iqg4OBguLm5wcfHB3379oW9vT1+/fVXeHl5YefOnVAqlejduzceP34s3jw9PVGrVi2tYSoymQxDhgzRWLZv3z5YWlpqZB9ZWFjggw8+KLRt+/btAwB8+OGHGst1FXrLe4UqJycHT548Qc2aNeHs7Ixz584VeJwnT54AAFxcXApt04v+++8/xMXFYcyYMRpjizt37oy6deuKqeY2NjawtrbGkSNH8k23VV+d2LNnD3JycgxuiyHkcjkOHjyo81ZclpaWGDlypHjf2toaI0eORFxcHM6ePQtAdZWqXr16qFu3rsZrSz1k9MXXVps2bRAQEKDzeOq/W2EZX/v27UOLFi00snPc3NzEVO7iGD58uFZhT0NfkyNGjNAY8vDqq69CoVDg/v37hR5/27ZtePXVV+Hi4qLxfAYHB0OhUODvv//Od9uDBw8iMTER/fr109jWwsICQUFBWn+Lwly4cAG3b99G//798eTJE3F/aWlp6NChA/7++2+tIQ6jRo3SuP/qq6/iyZMnSE5O1vu4L+7D0M8ve3t7jfoY1tbWaN68Oe7duycus7CwELMTlEolEhISkJubi2bNmun8m77zzjsaBWiDgoIAAO+++65GnY+goCBkZ2drDfPNy9D3THBwsEYWWaNGjeDo6KhxPvlRf/ZOmDBBY/knn3wCAAYNoSEyt6VLl2p9z/3xxx9a6/Xs2VPMEHzRi58vhr5Hqlevnu9wMV02bNiAzp07i0Wha9WqhcDAwHyH7Y0YMUIjY2L06NGwtLQU26lP/2Lfvn2wsLDQ6nN98sknEARB53NmTPv27UPz5s01hlzb29tjxIgRiIiIwLVr1/Taj4WFBXr37o1NmzYBUD2XPj4+YhZHXgkJCfjrr7/Qu3dvpKSkiJ+rT548QUhICG7fvi1+LhenD7Fv3z54enpq1Ga1srLChx9+iNTUVBw9erTA7Z88eVJoH7V3797IyMjAnj17kJKSgj179hQ4XO/SpUu4fPmyRpvU/YADBw5orZ9fv/HLL7/UWlefftmjR49w4cIFDBo0SON7smPHjvn29wyha9RD3n5ZWloaHj9+jFatWkEQBJw/f15rfV19E32+Qw15Xemybds2ODk5oWPHjhrf94GBgbC3tze4X2aK/lBhdP1PaIp+jKF97aFDh2r0tYOCgiAIAoYOHSous7CwQLNmzQo8X0EQsGPHDnTt2hWCIGicT0hICJKSkrSOP2TIEI0MV/Vnkr79suJ8hpQlHLJXAS1duhS1a9eGpaUlPDw8UKdOHXEWvdu3b0MQBNSqVUvnti+mi3p5eWmlkt+/fx9VqlTRqs1UWLq6elupVKo1NEfXthkZGQgNDcVPP/2EBw8eaIz7TUpKKvRYAPSqQaSrjfm1qW7duuI0vDKZDF999RU++eQTeHh4oEWLFujSpQsGDhwozgTTpk0b9OzZEzNnzsR3332Htm3bonv37ujfv3+BM6QkJSVpjH+3trbWGGqgi4WFRb5TIxdX1apVtYpH1q5dG4BqzH2LFi1w+/ZtXL9+Pd/Of1xcnMZ9XTMkqan/boXNPnT//n0xIJCXPq/Fwuhqn6GvyWrVqmncV3fo9KkXcPv2bVy6dEnv5/PFbQHkWxT+xVR8fdoCoMBhuUlJSRqd64LOXd/jv/g3MPTzy9vbW+s15OLigkuXLmksW7duHb799lvcuHFD4x87Xa+BF89L3en28fHRubygv7Wh75kXjw2ozkef15P6s/fFWcg8PT3h7OysV5CUqLRo3ry5XkXNC/qeefExQ98jBe37RdevX8f58+cxcOBArfoiS5cuRXJystbn4oufc/b29qhSpYpYR0Wf/sX9+/dRtWpVrZnR6tWrJz5uSvl9R+c9fkHD8vPq378/vv/+e1y8eBEbN25E3759dfYR7ty5A0EQ8MUXX+CLL77Qua+4uDh4eXkVqw9x//591KpVS2uWakOe28L6qG5ubggODsbGjRuRnp4OhUKBXr165bv+L7/8Ajs7O9SoUUN8ncnlcvj5+YkB0bwM6Tfq0y9Tn7Ou7+g6deoUejG5IJaWljqH/UVGRmLatGnYvXu31nfhi/0yuVyu9X2r73eoIa8rXW7fvo2kpCS4u7vnu60hTNUfKoiu/wlN0Y8pbl+7oH5ZQX/r+Ph4JCYmYuXKlVi5cmWRzseQfr4xPkPKCgakKqCCOmpKpRISiQR//PGHVvYHAK0gkzFq8RTVBx98gJ9++gnjx49Hy5Yt4eTkBIlEgr59+xZa1Fk9Drk4hQL1MX78eHTt2hW7du3CgQMH8MUXXyA0NBR//fUXmjZtColEgu3bt+Off/7B77//jgMHDuD999/Ht99+i3/++SffgusfffSRRlG7Nm3a6Cw0XlT5dSjUhR2LQqlUomHDhliwYIHOx1/8YijotaX+u6lr4JhSfuesq32GviZ1vccA/QKlSqUSHTt2xKeffqrzcXVAML9tAVWdphenyQZg8MyX6v3Nnz8/36mAX3wtF+fc1V78Gxj6+aVPG3755RcMHjwY3bt3x//+9z+4u7vDwsICoaGhYv09ffZZlPM19D1jjOe0PEwxT6Svgr5n8ntM3/eIIf2jX375BQDw8ccf4+OPP9Z6fMeOHVqZB4Upav/CkP3rUpx+QnEEBQXB398f48ePR3h4eL6ZQurvq4kTJ+abwfZi0NEcKleurFcftX///hg+fDhiYmLw5ptvatQFyksQBGzatAlpaWk6s5Hi4uKQmppa5NeFsftlhr6+ZDKZ1j/uCoUCHTt2REJCAj777DPUrVsXdnZ2ePDgAQYPHqzVL8vvO1QfxX1dKZVKuLu755sRmV9Ap6D9Gbs/VBhdn3mm6McYq6+ta3lhfTJAlfGe3wVYdT2xwo5dlISI8owBKdLg7+8PQRBQvXr1Av+hLYivry/CwsK0vthu3ryp17ZKpRJ3797VuAKla9vt27dj0KBBGlPiZmZm6pzN70XVqlWDjY2NxsyC+vL19RXb9GKGyc2bN8XH1fz9/fHJJ5/gk08+we3bt9GkSRN8++23YgcUAFq0aIEWLVpg7ty52LhxIwYMGIDNmzdj2LBhOtvw6aefaqTWFmXoYUHU+3vxucwvGv/w4UOtKXZv3boFAGJxbH9/f1y8eBEdOnQo9j+96r+b+ipBfnx9fcXsnbx0vZ5cXFy0zjc7OxuPHj3Su13FeU3mJ7/nyt/fH6mpqUXKelNnILq7uxsla069P0dHR6Nm4Rn6OjHG59eLtm/fjho1amDnzp0a7Zk+fbpR9l8QY75n1PLbj/qz9/bt2xrvq9jYWCQmJmp9rhFVNKZ6jwiCgI0bN6Jdu3YYM2aM1uOzZ8/Ghg0btAJSt2/fRrt27cT7qampePToETp16qSxXkH9C19fXxw6dAgpKSkaWVI3btwQzzk/efsJeYMguvoJBX3u6Po+1uf4uvTr1w9z5sxBvXr18r04UqNGDQCqDJHCvq8M6UPo2vbSpUtQKpUagRJ9z61u3bp69VF79OiBkSNH4p9//hEnRNHl6NGjiI6OxqxZs7T6Tk+fPsWIESOwa9cujb6lIcLDw+Hq6lpg4ER9zvo8p4b2Q3W5fPkybt26hXXr1mkUqi5OqYr8XsuGvK508ff3x6FDh9C6dWujXOw3RX+oKP0QU/RjTNHX1od69neFQlEifd3ifoaUJawhRRrefvttWFhYYObMmVrRW0EQxNpLBenUqRNyc3OxfPlycZlCocDixYsL3VY9U8iLs4PomjHMwsJCq42LFy/W6+qclZUVmjVrhv/++6/QdV/UrFkzuLu7Y8WKFRpTlv7xxx+4fv26mPKcnp6OzMxMjW39/f3h4OAgbvf06VOtc1B3ogqaaj0gIADBwcHiLTAw0ODzKIg6wJC3DpFCocg3RTU3N1djSuvs7Gz88MMPcHNzE9vWu3dvPHjwAKtWrdLaPiMjQ5ypTh9nz56Fk5MT6tevX+B6nTp1wj///IMzZ86Iy+Lj43VegfL399equ7Ry5UqDrvYW5zWZHzs7O51fsr1798apU6d01n1ITExEbm5uvvsMCQmBo6Mj5s2bp7O2SHx8vEFtDAwMhL+/P7755hukpqYWe39q+Z17fozx+fUi9dWtvPs7ffo0Tp06ZfC+DGXM94yaOmj84vOq/if2xc9a9VVNXTOdElUkpnqPnDhxAhERERgyZAh69eqldevTpw8OHz6Mhw8famy3cuVKjc/v5cuXIzc3V+xH6dO/6NSpExQKBZYsWaKx3nfffQeJRCLuSxdd/YS0tDSdU5Ln91neqVMnnDlzRuPzNC0tDStXroSfn5/BdYWGDRuG6dOna/yj+iJ3d3e0bdsWP/zwg84LTnm/rwzpQ7yoU6dOiImJ0QgS5ebmYvHixbC3t0ebNm0K3L5ly5a4cuVKgX1BQJXpsnz5csyYMQNdu3bNdz31cL3//e9/Wq+x4cOHo1atWnqdV37Onj2Lli1bFrhOlSpV0KRJE6xbt05jaNXBgwe16oX5+vrCwsJCq1+2bNkyvduk6/tbEAQsWrRI7328SD2D24uvZ0NeV7r07t0bCoUCs2fP1nosNzfX4GCLKfpD+fUfCmKKfowp+tr6Hrdnz57YsWMHrly5ovV4cfq6uoYaFvczpCxhhhRp8Pf3x5w5czB58mRERESge/fucHBwQHh4OH799VeMGDECEydOLHAfXbt2RevWrTFp0iREREQgICAAO3fu1KuuU5MmTdCvXz8sW7YMSUlJaNWqFcLCwjRqKqh16dIF69evh5OTEwICAnDq1CkcOnRIa1rn/Lz11luYMmWKztoMOTk5mDNnjtY2lSpVwpgxY/DVV19hyJAhaNOmDfr164fY2FgsWrQIfn5+Yrr9rVu30KFDB/Tu3RsBAQGwtLTEr7/+itjYWPTt2xeAqjbNsmXL0KNHD/j7+yMlJQWrVq2Co6Oj1lXOklS/fn20aNECkydPRkJCAipVqoTNmzfnG+SoWrUqvvrqK0RERKB27drYsmULLly4gJUrV4rj1N977z1s3boVo0aNwuHDh9G6dWsoFArcuHEDW7duxYEDB/Sq+QGoOi9du3Yt9GrLp59+ivXr1+ONN97ARx99JE7ZrL7qkNewYcMwatQo9OzZEx07dsTFixdx4MABg9LPi/ua1CUwMBDLly/HnDlzULNmTbi7u6N9+/b43//+h927d6NLly4YPHgwAgMDkZaWhsuXL2P79u2IiIjIt+2Ojo5Yvnw53nvvPbz00kvo27cv3NzcEBkZib1796J169Za/6AURCqV4scff8Sbb76J+vXrY8iQIfDy8sKDBw9w+PBhODo64vfffy/SuR86dAgLFixA1apVUb16dZ31PNSM8fn1oi5dumDnzp3o0aMHOnfujPDwcKxYsQIBAQE6g2/GZMz3jJo6QDxlyhT07dsXVlZW6Nq1Kxo3boxBgwZh5cqVSExMRJs2bXDmzBmsW7cO3bt318jEICrt/vjjD/Eqcl6tWrUSMxkMZar3yIYNG2BhYZFvQKtbt26YMmUKNm/erFFQPTs7W+xj3Lx5E8uWLcMrr7yCbt26AdCvf9G1a1e0a9cOU6ZMQUREBBo3bow///wTv/32G8aPH69VzzOv119/HdWqVcPQoUPxv//9DxYWFlizZo34XZJXft9jkyZNwqZNm/Dmm2/iww8/RKVKlbBu3TqEh4djx44dWkOwCuPr64sZM2YUut7SpUvxyiuvoGHDhhg+fDhq1KiB2NhYnDp1CtHR0bh48SIAw/oQLxoxYgR++OEHDB48GGfPnoWfnx+2b9+OEydOYOHChVp1u1701ltvYfbs2Th69Chef/31AtctqH4joApA7tixAx07dtSYjCevbt26YdGiRYiLixPrGOXm5mpk8+fVo0cPMUARFxeHS5cuYezYsQW2AwBCQ0PRuXNnvPLKK3j//feRkJCAxYsXo379+hrfqU5OTnjnnXewePFiSCQS+Pv7Y8+ePQbVUqpbty78/f0xceJEPHjwAI6OjtixY0exynXY2NggICAAW7ZsQe3atVGpUiU0aNAADRo00Pt1pUubNm0wcuRIhIaG4sKFC3j99ddhZWWF27dvY9u2bVi0aFGB9cFeZIr+kL+/P5ydnbFixQo4ODjAzs4OQUFBBdbLM0U/xhR9bX19+eWXOHz4MIKCgjB8+HAEBAQgISEB586dw6FDh5CQkGDwPgMDA7FlyxZMmDABL7/8Muzt7dG1a9dif4aUKSaZu49KJV1T3+Znx44dwiuvvCLY2dkJdnZ2Qt26dYWxY8cKN2/eFNdp06aNUL9+fZ3bP3nyRHjvvfcER0dHwcnJSXjvvfeE8+fPa00Xqmva4IyMDOHDDz8UKleuLNjZ2Qldu3YVoqKitKbefPr0qTBkyBDB1dVVsLe3F0JCQoQbN25oTU2cn9jYWMHS0lJYv369xvKCprr19/cX19uyZYvQtGlTQSaTCZUqVRIGDBggREdHi48/fvxYGDt2rFC3bl3Bzs5OcHJyEoKCgoStW7eK65w7d07o16+fUK1aNUEmkwnu7u5Cly5dhP/++6/Q9hti0KBBgp2dXb6PAxDGjh2rsezu3btCcHCwIJPJBA8PD+Hzzz8XDh48qDUNr/p18N9//wktW7YU5HK54OvrKyxZskTrONnZ2cJXX30l1K9fX5DJZIKLi4sQGBgozJw5U0hKSiqwPWrXr18XAAiHDh3S69wvXboktGnTRpDL5YKXl5cwe/ZsYfXq1VpTNisUCuGzzz4TXF1dBVtbWyEkJES4c+eO1uupoPeRvq/J/Paha5rjmJgYoXPnzoKDg4MAQGNK2pSUFGHy5MlCzZo1BWtra8HV1VVo1aqV8M0332hMB56fw4cPCyEhIYKTk5Mgl8sFf39/YfDgwRqvv/ym9tbl/Pnzwttvvy1UrlxZkMlkgq+vr9C7d28hLCxMa3/x8fEa2+qaKvzGjRvCa6+9JtjY2AgAxOcwv32oFefza9CgQRrT7yqVSmHevHmCr6+vIJPJhKZNmwp79uzRWk89FfX8+fM19qf+m27btk3n+eZ9Deiayrm47xldn4ezZ88WvLy8BKlUqvGc5+TkCDNnzhSqV68uWFlZCT4+PsLkyZM1prAmKs3U76v8bur+R37vV0Eo+PNF3/eIr6+v0Llz50Lbm52dLVSuXFl49dVXC1yvevXqQtOmTTXO8ejRo8KIESMEFxcXwd7eXhgwYIDw5MkTcRt9+xcpKSnCxx9/LFStWlWwsrISatWqJcyfP19jmnT1Ob34WXL27FkhKChIsLa2FqpVqyYsWLBA52d5Qd9jd+/eFXr16iU4OzsLcrlcaN68ubBnz55Cnzt1mwp7nvP7vr17964wcOBAwdPTU7CyshK8vLyELl26CNu3b9dYT98+hK7P79jYWLFPYG1tLTRs2FCjD1yYRo0aCUOHDtXrfF6U97nZsWOHAEBYvXp1vusfOXJEACAsWrRIEISC+8Ivnvvy5csFW1tbvaeh37Fjh1CvXj1BJpMJAQEBws6dO7W+UwVBEOLj44WePXsKtra2gouLizBy5EjhypUrWv9LFNTHvXbtmhAcHCzY29sLrq6uwvDhw4WLFy/qvQ9dfaCTJ08KgYGBgrW1tdb/Jvq+rvKzcuVKITAwULCxsREcHByEhg0bCp9++qnw8OFDcR1dr7X8GLM/JAiC8NtvvwkBAQGCpaWlxnNY0P+Exu7HFLevnd9nvK7XwIt/X0FQva/Hjh0r+Pj4CFZWVoKnp6fQoUMHYeXKleI6+fX91N89eV97qampQv/+/QVnZ2cBgMZzXtzPkLJCIgisqkUV19ChQ3Hr1i0cO3bM3E0hPY0fPx5///03zp49ywLMREREVC6tX78eY8eORWRkZL7FykuDpk2bom3btvjuu+/M3RQiKoMYkKIKLTIyErVr10ZYWBhat25t7uZQIZ48eQJfX19s3brVrEMaiYiIiExJqVSiUaNG6NevH6ZMmWLu5ui0f/9+9OrVC/fu3ROH+hERGYIBKSIiIiIiIiIiKlGcZY+IiIiIiIiIiEoUA1JERERERERERFSizB6QWrp0Kfz8/CCXyxEUFIQzZ87ku25OTg5mzZoFf39/yOVyNG7cGPv37y/B1hIRERERERERUXGZNSC1ZcsWTJgwAdOnT8e5c+fQuHFjhISEIC4uTuf6U6dOxQ8//IDFixfj2rVrGDVqFHr06IHz58+XcMuJiIiIiIiIiKiozFrUPCgoCC+//DKWLFkCQDWbhI+PDz744ANMmjRJa/2qVatiypQpGDt2rLisZ8+esLGxwS+//KLXMZVKJR4+fAgHBwdOGU9EREQ6CYKAlJQUVK1aFVKp2RPKSwX2oYiIiKgghvafLEugTTplZ2fj7NmzmDx5srhMKpUiODgYp06d0rlNVlYW5HK5xjIbGxscP3483+NkZWUhKytLvP/gwQMEBAQUs/VERERUEURFRcHb29vczSgVHj58CB8fH3M3g4iIiEo5fftPZgtIPX78GAqFAh4eHhrLPTw8cOPGDZ3bhISEYMGCBXjttdfg7++PsLAw7Ny5EwqFIt/jhIaGYubMmVrLo6Ki4OjoWLyTICIionIpOTkZPj4+cHBwMHdTSg31c8E+FBEREeliaP/JbAGpoli0aBGGDx+OunXrQiKRwN/fH0OGDMGaNWvy3Wby5MmYMGGCeF/9BDk6OrIzRURERAXi0LTn1M8F+1BERERUEH37T2YriuDq6goLCwvExsZqLI+NjYWnp6fObdzc3LBr1y6kpaXh/v37uHHjBuzt7VGjRo18jyOTycSOEztQRERERERERETmZ7aAlLW1NQIDAxEWFiYuUyqVCAsLQ8uWLQvcVi6Xw8vLC7m5udixYwfeeustUzeXiIiIiIiIiIiMxKxD9iZMmIBBgwahWbNmaN68ORYuXIi0tDQMGTIEADBw4EB4eXkhNDQUAHD69Gk8ePAATZo0wYMHDzBjxgwolUp8+umn5jwNIiIiIiIiIiIygFkDUn369EF8fDymTZuGmJgYNGnSBPv37xcLnUdGRmpMFZiZmYmpU6fi3r17sLe3R6dOnbB+/Xo4Ozub6QyIiMjUlEolsrOzzd0MKmesrKxgYWFh7mYQERGZjEKhQE5OjrmbQeWIsftPEkEQBKPtrQxITk6Gk5MTkpKSWE+KiKiUy87ORnh4OJRKpbmbQuWQs7MzPD09dRbeZH9BG58TIqKyQRAExMTEIDEx0dxNoXLImP2nMjXLHhERVRyCIODRo0ewsLCAj4+PRsYsUXEIgoD09HTExcUBAKpUqWLmFhERERmPOhjl7u4OW1tbzhhLRmGK/hMDUkREVCrl5uYiPT0dVatWha2trbmbQ+WMjY0NACAuLg7u7u4cvkdEROWCQqEQg1GVK1c2d3OonDF2/4mXm4mIqFRSKBQAVLOyEpmCOtDJ+hpERFReqL/TeDGPTMWY/ScGpIiIqFRjmjmZCl9bRERUXvE7jkzFmK8tBqSIiIiIiIiIiKhEMSBlREqlgMk7L+HDTeeRmpVr7uYQERGZnZ+fHxYuXGjuZlApd+haLD7ZehFb/4syd1OIiIjMrqL0nxiQMiKpVILtZ6Ox++JDJGewHgURUUU1ePBgSCQSrdsbb7yh1/ZHjhyBRCIpF9M1//vvvxgxYoRR99m2bVuMHz/eqPsk87oZm4Id56LxX0SCuZtCRERmwv7TcxWl/8RZ9ozM1toSSRk5SM9mhhQRUUX2xhtv4KefftJYJpPJjHqM7OzsUl/03c3NzdxNoDLAXqbqkqZlKczcEiIiMif2n1QqSv+JGVJGZmetmvaQHSoioopNJpPB09NT4+bi4gJAVQzyxx9/RI8ePWBra4tatWph9+7dAICIiAi0a9cOAODi4gKJRILBgwcDUF3ZGjduHMaPHw9XV1eEhIQAAK5cuYI333wT9vb28PDwwHvvvYfHjx+LbWnbti0+/PBDfPrpp6hUqRI8PT0xY8YMjfYuWLAADRs2hJ2dHXx8fDBmzBikpqaKj69duxbOzs7Ys2cP6tSpA1tbW/Tq1Qvp6elYt24d/Pz84OLigg8//FCcIRHQTjlPTEzEsGHD4ObmBkdHR7Rv3x4XL14UH58xYwaaNGmC9evXw8/PD05OTujbty9SUlIAqK6eHj16FIsWLRKvnEZERAAAjh49iubNm0Mmk6FKlSqYNGkScnN5gagssH3Wf2LJAyKiio39J5WK0n9iQMrIbNVX+JghRURkVIIgID071yw3QRCMfj4zZ85E7969cenSJXTq1AkDBgxAQkICfHx8sGPHDgDAzZs38ejRIyxatEjcbt26dbC2tsaJEyewYsUKJCYmon379mjatCn+++8/7N+/H7Gxsejdu7fG8datWwc7OzucPn0aX3/9NWbNmoWDBw+Kj0ulUnz//fe4evUq1q1bh7/++guffvqpxj7S09Px/fffY/Pmzdi/fz+OHDmCHj16YN++fdi3bx/Wr1+PH374Adu3b8/3vN955x3ExcXhjz/+wNmzZ/HSSy+hQ4cOSEh4PlTr7t272LVrF/bs2YM9e/bg6NGj+PLLLwEAixYtQsuWLTF8+HA8evQIjx49go+PDx48eIBOnTrh5ZdfxsWLF7F8+XKsXr0ac+bMKfofiUrM8wwp9p+IiIytPPWh2H8qX/0nDtkzMnWGVDozpIiIjCojR4GAaQfMcuxrs0Jga23YV+aePXtgb2+vsezzzz/H559/DkB1papfv34AgHnz5uH777/HmTNn8MYbb6BSpUoAAHd3dzg7O2vso1atWvj666/F+3PmzEHTpk0xb948cdmaNWvg4+ODW7duoXbt2gCARo0aYfr06eI+lixZgrCwMHTs2BEANGoK+Pn5Yc6cORg1ahSWLVsmLs/JycHy5cvh7+8PAOjVqxfWr1+P2NhY2NvbIyAgAO3atcPhw4fRp08frefk+PHjOHPmDOLi4sT0+2+++Qa7du3C9u3bxVoJSqUSa9euhYODAwDgvffeQ1hYGObOnQsnJydYW1vD1tYWnp6e4r6XLVsGHx8fLFmyBBKJBHXr1sXDhw/x2WefYdq0aZBKeQ2uNLMTL+ix/0REZGxlqQ/F/lPF6j8xIGVk6jcbM6SIiCq2du3aYfny5RrL1B0lQNXBUbOzs4OjoyPi4uIK3W9gYKDG/YsXL+Lw4cNanTdAdaUsb4cqrypVqmgc79ChQwgNDcWNGzeQnJyM3NxcZGZmIj09Hba2tgAAW1tbsTMFAB4eHvDz89M4toeHR77ncfHiRaSmpqJy5coayzMyMnD37l3xvp+fn9iZ0tVWXa5fv46WLVtCIpGIy1q3bo3U1FRER0ejWrVqBW5P5mXHDCkiIgL7T7qU5/4TA1JGZid7liHFK3xEREZlY2WBa7NCzHZsQ9nZ2aFmzZr5Pm5lZaVxXyKRQKlU6rXfvFJTU9G1a1d89dVXWutWqVJFr+NFRESgS5cuGD16NObOnYtKlSrh+PHjGDp0KLKzs8UOla59GHIeqampqFKlCo4cOaL1WN4rmUV9bqjs4pA9IiLTKUt9KPaftJXn/hMDUkbGK3xERKYhkUgMHjZXVqlnfslb3DI/L730Enbs2AE/Pz9YWhbt+Tl79iyUSiW+/fZbMTV769atRdpXQV566SXExMTA0tISfn5+Rd6PtbW11nNTr1497NixA4IgiFf5Tpw4AQcHB3h7exen2VQC1Bf0WNSciMj4Kkofiv2ngpXG/hMLKhiZ+o3ODCkioootKysLMTExGre8M7cUxNfXFxKJBHv27EF8fLzGbC0vGjt2LBISEtCvXz/8+++/uHv3Lg4cOIAhQ4bo1SEDgJo1ayInJweLFy/GvXv3sH79eqxYsUKvbQ0RHByMli1bonv37vjzzz8RERGBkydPYsqUKfjvv//03o+fnx9Onz6NiIgIPH78GEqlEmPGjEFUVBQ++OAD3LhxA7/99humT5+OCRMmsH5UGaDOkMrKVSJXUbqv5hIRkemw/6StPPef2EMzMnVRc9aQIiKq2Pbv348qVapo3F555RW9tvXy8sLMmTMxadIkeHh4YNy4cfmuW7VqVZw4cQIKhQKvv/46GjZsiPHjx8PZ2VnvjkTjxo2xYMECfPXVV2jQoAE2bNiA0NBQvbY1hEQiwb59+/Daa69hyJAhqF27Nvr27Yv79+/Dw8ND7/1MnDgRFhYWCAgIgJubGyIjI+Hl5YV9+/bhzJkzaNy4MUaNGoWhQ4di6tSpRj8PMr68V+7TODEMEVGFxf6TtvLcf5IIppjLuhRLTk6Gk5MTkpKS4OjoaPT9Lzh4C9+H3cZ7LXwxu3sDo++fiKiiyMzMRHh4OKpXrw65XG7u5lA5VNBrzNT9hbLI1M9J7Sl/IFuhxMlJ7VHV2cbo+yciqgjYfyJTM2b/iRlSRsYMKSIiIiLDqetIsQ4nERFRxcCAlJHZPquBkM50cyIiIiK9qSeGYWFzIiKiioEBKSNjhhQRERGR4ezFmYp5UY+IiKgiYEDKyDjLHhEREZHhmCFFRERUsTAgZWSsf0BERERkOFtr9qGIiIgqEgakjIwZUkRERESGUw/ZS2fZAyIiogqBASkjU2dIsTNFREREpL/nQ/Z4UY+IiKgiYEDKyOysWZCTiIiIyFDPi5rzoh4REVFFwICUkanrH2TkKKBQCmZuDRERkXHduXMH8+bNQ0ZGhrmbQuWMOsucRc2JiKg8Yh9KGwNSRqZONwdUQSkiIiJDtG3bFuPHjxfv+/n5YeHChQVuI5FIsGvXLqO1Ib9jZmZmolevXqhatSpsbGyMdjwi4HkfihlSRERUFOxDlT2Wha9ChpBZSiGVAEoBSM/KFdPPiYio/OvatStycnKwf/9+rceOHTuG1157DRcvXkSjRo303ue///4LOzs7YzazyMf84IMP0L17dwwePLhE20MVg1j2gHU4iYgqHPahKiZGS4xMIpHAztoSKVm5SONMe0REFcrQoUPRs2dPREdHw9vbW+Oxn376Cc2aNTOoIwUAbm5uxmxisY65atWqEm4JVSQsak5EVHGxD1UxccieCdg+q4HAlHMiooqlS5cucHNzw9q1azWWp6amYtu2bejevTv69esHLy8v2NraomHDhti0aVOB+3wx9fv27dt47bXXIJfLERAQgIMHD2pt89lnn6F27dqwtbVFjRo18MUXXyAnJ0djnd9//x0vv/wy5HI5XF1d0aNHj3yPGRkZibfeegv29vZwdHRE7969ERsbKz4+Y8YMNGnSBOvXr4efnx+cnJzQt29fpKSk6PGsEanYq2cqZv+JiKjCYR+qYvahGJAyAXXKeTozpIiIjEcQgOw089wE/SapsLS0xMCBA7F27VoIebbZtm0bFAoF3n33XQQGBmLv3r24cuUKRowYgffeew9nzpzRa/9KpRJvv/02rK2tcfr0aaxYsQKfffaZ1noODg5Yu3Ytrl27hkWLFmHVqlX47rvvxMf37t2LHj16oFOnTjh//jzCwsLQvHnzfI/51ltvISEhAUePHsXBgwdx79499OnTR2O9u3fvYteuXdizZw/27NmDo0eP4ssvv9TrvIiAvBlSDEgRERkV+1DsQ5VSZh+yt3TpUsyfPx8xMTFo3LgxFi9enO8fFAAWLlyI5cuXIzIyEq6urujVqxdCQ0Mhl8tLsNUFEzOkWAOBiMh4ctKBeVXNc+zPHwLW+tUgeP/99zF//nwcPXoUbdu2BaBKNe/Zsyd8fX0xceJEcd0PPvgABw4cwNatWwv87lM7dOgQbty4gQMHDqBqVdVzMW/ePLz55psa602dOlX83c/PDxMnTsTmzZvx6aefAgDmzp2Lvn37YubMmeJ6jRs31nnMsLAwXL58GeHh4fDx8QEA/Pzzz6hfvz7+/fdfvPzyywBUna61a9fCwcEBAPDee+8hLCwMc+fOLfS8iIA8Rc3ZfyIiMi72odiHKqXMmiG1ZcsWTJgwAdOnT8e5c+fQuHFjhISEIC4uTuf6GzduxKRJkzB9+nRcv34dq1evxpYtW/D555+XcMsLZqvOkGINBCKiCqdu3bpo1aoV1qxZA0A1xe+xY8cwdOhQKBQKzJ49Gw0bNkSlSpVgb2+PAwcOIDIyUq99X79+HT4+PmJHCgBatmyptd6WLVvQunVreHp6wt7eHlOnTtU4xoULF9ChQweDjqnuSAFAQEAAnJ2dcf36dXGZn5+f2JECgCpVquT7fU6ki704yx77T0REFRH7UCoVqQ9l1gypBQsWYPjw4RgyZAgAYMWKFdi7dy/WrFmDSZMmaa1/8uRJtG7dGv379weg+sP169cPp0+fLtF2F8bOmhlSRERGZ2WruspmrmMbYOjQofjggw+wdOlS/PTTT/D390ebNm3w1VdfYdGiRVi4cCEaNmwIOzs7jB8/HtnZ2UZr6qlTpzBgwADMnDkTISEhcHJywubNm/Htt9+K65hiumErKyuN+xKJBEql0ujHofLL9ln/iUP2iIiMjH0ovbAPVfLMliGVnZ2Ns2fPIjg4+HljpFIEBwfj1KlTOrdp1aoVzp49K44TvXfvHvbt24dOnTqVSJv1ZStTZ0ixQ0VEZDQSiSrl2xw3icSgpvbu3RtSqRQbN27Ezz//jPfffx8SiQQnTpzAW2+9hXfffReNGzdGjRo1cOvWLb33W69ePURFReHRo0fisn/++UdjnZMnT8LX1xdTpkxBs2bNUKtWLdy/f19jnUaNGiEsLMygY0ZFRYnLrl27hsTERAQEBOjddqLCqDOksnOVyFFUjI44EVGJYB+KfahSymwZUo8fP4ZCoYCHh4fGcg8PD9y4cUPnNv3798fjx4/xyiuvQBAE5ObmYtSoUQUO2cvKykJWVpZ4Pzk52TgnUIDnGVJMOSciqojs7e3Rp08fTJ48GcnJyRg8eDAAoFatWti+fTtOnjwJFxcXLFiwALGxsXp3SoKDg1G7dm0MGjQI8+fPR3JyMqZMmaKxTq1atRAZGYnNmzfj5Zdfxt69e/Hrr79qrDN9+nR06NAB/v7+6Nu3L3Jzc7Fv3z6dxT2Dg4PRsGFDDBgwAAsXLkRubi7GjBmDNm3aoFmzZkV7goh0UNeQAlRlD5xsOfcOEVFFwz5UxVKmvumPHDmCefPmYdmyZTh37hx27tyJvXv3Yvbs2fluExoaCicnJ/GWd/ymqYg1pDhkj4iowho6dCiePn2KkJAQsV7B1KlT8dJLLyEkJARt27aFp6cnunfvrvc+pVIpfv31V2RkZKB58+YYNmyYVsHLbt264eOPP8a4cePQpEkTnDx5El988YXGOm3btsW2bduwe/duNGnSBO3bt893lhqJRILffvsNLi4ueO211xAcHIwaNWpgy5Ythj0hZFR///03unbtiqpVq0IikWDXrl2FbnPkyBG89NJLkMlkqFmzptbU2uZmZSGFtaWqa5rKPhQRUYXFPlTFIREEPedhNLLs7GzY2tpi+/btGi+kQYMGITExEb/99pvWNq+++ipatGiB+fPni8t++eUXjBgxAqmpqZBKteNrujKkfHx8kJSUBEdHR+Oe1DPzD9zA0sN3MbiVH2Z0q2+SYxARlXeZmZkIDw9H9erVS9VMqlR+FPQaS05OhpOTk0n7C8Xxxx9/4MSJEwgMDMTbb7+NX3/9tcCOeXh4OBo0aIBRo0Zh2LBhCAsLw/jx47F3716EhITodcySeE5emn0QCWnZ+PPj11Dbw6HwDYiISAP7T2Rqxuw/mW3InrW1NQIDAxEWFiZ2oJRKJcLCwjBu3Did26Snp2sFnSwsVMPj8ouryWQyyGQy4zVcD8yQIiIiIlN68803taaqLsiKFStQvXp1sTBrvXr1cPz4cXz33Xd6B6RKgp3MAglpLGxORERUEZh1lr0JEyZg0KBBaNasGZo3b46FCxciLS1NnHVv4MCB8PLyQmhoKACga9euWLBgAZo2bYqgoCDcuXMHX3zxBbp27SoGpkoD1pAiIiKi0uTUqVMaE8kAQEhICMaPH5/vNuapw6nqmqYxIEVERFTumTUg1adPH8THx2PatGmIiYlBkyZNsH//frHQeWRkpEZG1NSpUyGRSDB16lQ8ePAAbm5u6Nq1q9bYT3PjLHtERERUmsTExOicSCY5ORkZGRk6p7EODQ3FzJkzS6qJAJ4XNmdAioiIqPwza0AKAMaNG5fvEL0jR45o3Le0tMT06dMxffr0EmhZ0YlX95ghRURERGXU5MmTMWHCBPG+ug6nKakDUqlZ7EMRERGVd2YPSJVHtjLVkD3WkCIiIqLSwNPTE7GxsRrLYmNj4ejoqDM7CjBPHU579qGIiIgqDO1p6ajY1BlS6by6R0RUbGaaDJYqAKVSae4mlJiWLVsiLCxMY9nBgwfRsmVLM7VIN3UfikXNiYiKpyJ9x1HJMuZrixlSJmArFjVnZ4qIqKisrKwgkUgQHx8PNzc3SCQSczeJyglBEJCdnY34+HhIpVJYW1ubu0kGS01NxZ07d8T74eHhuHDhAipVqoRq1aph8uTJePDgAX7++WcAwKhRo7BkyRJ8+umneP/99/HXX39h69at2Lt3r7lOQSfWkCIiKh5ra2tIpVI8fPgQbm5usLa2Zh+KjMIU/ScGpEzATsYMKSKi4rKwsIC3tzeio6MRERFh7uZQOWRra4tq1appTKBSVvz3339o166deF9d62nQoEFYu3YtHj16hMjISPHx6tWrY+/evfj444+xaNEieHt748cff0RISEiJt70gds+G7KWxD0VEVCRSqRTVq1fHo0eP8PDhQ3M3h8ohY/afGJAyAbs8GVKCIDAiTURURPb29qhVqxZycnLM3RQqZywsLGBpaVlmv6Pbtm1b4HDWtWvX6tzm/PnzJmxV8T0vas4MKSKiorK2tka1atWQm5sLhYIBfjIeY/efGJAyAdtnnSmlAGTlKiG3sjBzi4iIyi4LCwtYWPBzlKgisOeQPSIio5BIJLCysoKVlZW5m0KUr7KXo14G2OQJQLFDRURERKQfdVHztGxe0SciIirvGJAyAQupRAxKpbNDRURERKQXFjUnIiKqOBiQMhGxKCdn2iMiIiLSC4fsERERVRwMSJmIrTrlnLPEEBEREenF9tkFPRY1JyIiKv8YkDIRW2v1kD12qIiIiIj0wQwpIiKiioMBKRN5XgOBGVJERERE+mD/iYiIqOJgQMpEmCFFREREZBj7ZyUPshVKZOcqzdwaIiIiMiUGpEyE0xYTERERGUY9KQzAi3pERETlHQNSJqIuypnOGghEREREerG0kEJmqeqesrA5ERFR+caAlIkwQ4qIiIjIcKwjRUREVDEwIGUizJAiIiIiMpx62B4zpIiIiMo3BqRMhBlSRERERIYT+1AMSBEREZVrDEiZCGfZIyIiIjKcvYwBKSIiooqAASkTYf0DIiIiIsOJfShmmRMREZVrDEiZCDOkiIiIiAzHDCkiIqKKgQEpE2ENKSIiIiLDqS/qsag5ERFR+caAlIlwlj0iIiIiw9kxQ4qIiKhCYEDKRNQZUunMkCIiIiLSG4fsERERVQwMSJmI3bMMqTTWkCIiIiLSmzpDKpUTwxAREZVrDEiZiK06Q4qdKSIiIiK92cs4MQwREVFFwICUiaiH7GUrlMjOVZq5NURERERlw/MMKQakiIiIyjMGpEzE5tkMMQCv8BERERHpS51lzhpSRERE5RsDUiZibSmFtYXq6U1jYXMiIiIivTwvas7+ExERUXnGgJQJ2aprIPAKHxEREZFe1BPDcMgeERFR+caAlAmp60gxQ4qIiIhIP2KGFEseEBERlWsMSJmQrTUzpIiIiIgMYSdjDSkiIqKKoFQEpJYuXQo/Pz/I5XIEBQXhzJkz+a7btm1bSCQSrVvnzp1LsMX6sZUxQ4qIiIjIEOqAVI5C4EzFRERE5ZjZA1JbtmzBhAkTMH36dJw7dw6NGzdGSEgI4uLidK6/c+dOPHr0SLxduXIFFhYWeOedd0q45YWzU2dIMeWciIiISC92eWYqZpYUERFR+WX2gNSCBQswfPhwDBkyBAEBAVixYgVsbW2xZs0anetXqlQJnp6e4u3gwYOwtbUtlQGp59MWM0OKiIiISB+WFlLILFVdVBY2JyIiKr/MGpDKzs7G2bNnERwcLC6TSqUIDg7GqVOn9NrH6tWr0bdvX9jZ2ZmqmUWmniWGGVJERERE+mNhcyIiovLP0pwHf/z4MRQKBTw8PDSWe3h44MaNG4Vuf+bMGVy5cgWrV6/Od52srCxkZWWJ95OTk4veYAMxQ4qIiIjIcHYySzxJy+aQPSIionLM7EP2imP16tVo2LAhmjdvnu86oaGhcHJyEm8+Pj4l1j7WkCIiIiIynLqweSov6hEREZVbZg1Iubq6wsLCArGxsRrLY2Nj4enpWeC2aWlp2Lx5M4YOHVrgepMnT0ZSUpJ4i4qKKna79WXLdHMiIiIig9mryx4wQ4qIiKjcMmtAytraGoGBgQgLCxOXKZVKhIWFoWXLlgVuu23bNmRlZeHdd98tcD2ZTAZHR0eNW0l53pni1T0iIiIifT3PkGJAioiIqLwyaw0pAJgwYQIGDRqEZs2aoXnz5li4cCHS0tIwZMgQAMDAgQPh5eWF0NBQje1Wr16N7t27o3LlyuZotl7EGlLMkCIiIiLSm51Yh5N9KCIiovLK7AGpPn36ID4+HtOmTUNMTAyaNGmC/fv3i4XOIyMjIZVqJnLdvHkTx48fx59//mmOJuvt+Sx7zJAiIiIi0pe6D5XGPhQREVG5ZfaAFACMGzcO48aN0/nYkSNHtJbVqVMHgiCYuFXFZ8ure0REREQG45A9IiKi8q9Mz7JX2qnTzZkhRURERKQ/exkv6hEREZV3DEiZkK2Ybs7OFBEREZG+7MSAFC/qERERlVcMSJmQmCHFzhQRERGR3uyYIUVERFTuMSBlQrbWzJAiIiIiMpQd+1BERETlHgNSJqS+upeZo4RCWfqLsBMRERGVBixqTkREVP4xIGVC6gwpAEjnFT4iIiIivbCoORERUfnHgJQJySylsJBKAHCmPSIiIiJ9sag5ERFR+ceAlAlJJJLndaR4hY+IiIhIL/bPZirmkD0iIqLyiwEpExNn2mOGFBEREZFe1BlSLHlARERUfjEgZWK2MmZIERERERnC9tkFvRyFgKxcXtQjIiIqjxiQMjFmSBEREREZxi7PxDCsI0VERFQ+MSBlYmINKaacExEREenF0kIKuZWqm8oscyIiovKJASkTE2sg8OoeERERkd7sn/WhWNiciIiofGJAysSYIUVERESmsHTpUvj5+UEulyMoKAhnzpwpcP2FCxeiTp06sLGxgY+PDz7++GNkZmaWUGsNp76oxwwpIiKi8okBKRNjDSkiIiIyti1btmDChAmYPn06zp07h8aNGyMkJARxcXE619+4cSMmTZqE6dOn4/r161i9ejW2bNmCzz//vIRbrj91HyqNfSgiIqJyydKQlbOysnD69Gncv38f6enpcHNzQ9OmTVG9enVTta/M4yx7REREZGwLFizA8OHDMWTIEADAihUrsHfvXqxZswaTJk3SWv/kyZNo3bo1+vfvDwDw8/NDv379cPr06RJttyHs2IciIiIq1/QKSJ04cQKLFi3C77//jpycHDg5OcHGxgYJCQnIyspCjRo1MGLECIwaNQoODg6mbnOZwgwpIiIiMqbs7GycPXsWkydPFpdJpVIEBwfj1KlTOrdp1aoVfvnlF5w5cwbNmzfHvXv3sG/fPrz33nsl1WyD2bGGFBERUblW6JC9bt26oU+fPvDz88Off/6JlJQUPHnyBNHR0UhPT8ft27cxdepUhIWFoXbt2jh48GBJtLvMYIYUERERGdPjx4+hUCjg4eGhsdzDwwMxMTE6t+nfvz9mzZqFV155BVZWVvD390fbtm0LHLKXlZWF5ORkjVtJYg0pIiKi8q3QgFTnzp0RHh6Or7/+Gq+++ipsbGw0Hq9RowYGDRqE/fv3IywsDFIpy1LlxQwpIiIiMrcjR45g3rx5WLZsGc6dO4edO3di7969mD17dr7bhIaGwsnJSbz5+PiUYIsBe2sGpIiIiMqzQofsjRw5Uu+dBQQEICAgoFgNKm84yx4REREZk6urKywsLBAbG6uxPDY2Fp6enjq3+eKLL/Dee+9h2LBhAICGDRsiLS0NI0aMwJQpU3ReUJw8eTImTJgg3k9OTi7RoNTzIXu8qEdERFQeGZTOFBUVhejoaPH+mTNnMH78eKxcudLoDSsv1J2pdHamiIiIyAisra0RGBiIsLAwcZlSqURYWBhatmypc5v09HStoJOFheqimSAIOreRyWRwdHTUuJUk+2dlD9J5UY+IiKhcMigg1b9/fxw+fBgAEBMTg44dO+LMmTOYMmUKZs2aZZIGlnXMkCIiIiJjmzBhAlatWoV169bh+vXrGD16NNLS0sRZ9wYOHKhR9Lxr165Yvnw5Nm/ejPDwcBw8eBBffPEFunbtKgamShtbFjUnIiIq1/SaZU/typUraN68OQBg69ataNCgAU6cOIE///wTo0aNwrRp00zSyLJMzJBiDSkiIiIykj59+iA+Ph7Tpk1DTEwMmjRpgv3794uFziMjIzUyoqZOnQqJRIKpU6fiwYMHcHNzQ9euXTF37lxznUKhDC1qnpaVCwupBHKr0hlgIyIiIk0GBaRycnIgk8kAAIcOHUK3bt0AAHXr1sWjR4+M37pyQMyQ4tU9IiIiMqJx48Zh3LhxOh87cuSIxn1LS0tMnz4d06dPL4GWGYe9OFNx4Rf1snIV6PDtUcitpAj7pC0spBJTN4+IiIiKyaAhe/Xr18eKFStw7NgxHDx4EG+88QYA4OHDh6hcubJJGljWcZY9IiIiIsOp+1D6DNmLfJKOmORMRDxJR1RCuqmbRkREREZgUEDqq6++wg8//IC2bduiX79+aNy4MQBg9+7d4lA+0mQre15DKr+ioURERESkyd6AIXuReYJQN2JSTNYmIiIiMh6Dhuy1bdsWjx8/RnJyMlxcXMTlI0aMgK2trdEbVx6or+4JApCZo4SNNesaEBERERXGkBpS9588D0jdjEnBGw08TdYuIiIiMg6DMqQyMjKQlZUlBqPu37+PhQsX4ubNm3B3dzdJA8s6mzyFNTnTHhEREZF+7MQs88LLHuTNkLoZm2yyNhEREZHxGBSQeuutt/Dzzz8DABITExEUFIRvv/0W3bt3x/Lly03SwLJOKpWIhc3T9SjKSURERESaGVKFlT3IWzfqxiMO2SMiIioLDApInTt3Dq+++ioAYPv27fDw8MD9+/fx888/4/vvvzdJA8sD22fD9pghRURERKQfdUAqVykgK1dZ4Lr38wSkIp6kITOHFwGJiIhKO4MCUunp6XBwcAAA/Pnnn3j77bchlUrRokUL3L9/3yQNLA/UKefpDEgRERER6UVdhxMouI6UUimIGVIWUgmUAnA7NtXk7SMiIqLiMSggVbNmTezatQtRUVE4cOAAXn/9dQBAXFwcHB0dTdLA8kDMkOKQPSIiIiK9WEglYi3OgvpQ8alZyMpVwkIqwUvVnAEAN2JYR4qIiKi0MyggNW3aNEycOBF+fn5o3rw5WrZsCUCVLdW0adMiNWDp0qXw8/ODXC5HUFAQzpw5U+D6iYmJGDt2LKpUqQKZTIbatWtj3759RTp2SbGzZoYUERERkaHUw/ZSC8iQUs+wV9VZjvpVnQCoZtojIiKi0s2y8FWe69WrF1555RU8evQIjRs3Fpd36NABPXr0MPjgW7ZswYQJE7BixQoEBQVh4cKFCAkJyXfWvuzsbHTs2BHu7u7Yvn07vLy8cP/+fTg7Oxt87JJkK2OGFBEREZGh7GQWeJxa8EU99Qx71SrZoo6nqrTEzVgGpIiIiEo7gwJSAODp6QlPT09ER0cDALy9vdG8efMiHXzBggUYPnw4hgwZAgBYsWIF9u7dizVr1mDSpEla669ZswYJCQk4efIkrKysAAB+fn5FOnZJYoYUERERkeHUdaQKypB6HpCyEwNSN5ghRUREVOoZNGRPqVRi1qxZcHJygq+vL3x9feHs7IzZs2dDqSx49pMXZWdn4+zZswgODn7eGKkUwcHBOHXqlM5tdu/ejZYtW2Ls2LHw8PBAgwYNMG/ePCgUpTvz6Pkse6W7nURERESlib0eWeaRT9IAqDKkanuoAlLxKVlISMs2fQOJiIioyAzKkJoyZQpWr16NL7/8Eq1btwYAHD9+HDNmzEBmZibmzp2r974eP34MhUIBDw8PjeUeHh64ceOGzm3u3buHv/76CwMGDMC+fftw584djBkzBjk5OZg+fbrObbKyspCVlSXeT04u+SKX4ix7BVzdIyIiIiJN6j5UQbPsqTOkfCvbwl5mCZ9KNohKyMCNmGS08nctkXYSERGR4QwKSK1btw4//vgjunXrJi5r1KgRvLy8MGbMGIMCUkWhVCrh7u6OlStXwsLCAoGBgXjw4AHmz5+fb0AqNDQUM2fONGm7CsMMKSIiIiLD6VPUPG8NKQCo4+GIqIQM3IxJYUCKiIioFDNoyF5CQgLq1q2rtbxu3bpISEgw6MCurq6wsLBAbGysxvLY2Fh4enrq3KZKlSqoXbs2LCwsxGX16tVDTEwMsrN1p2VPnjwZSUlJ4i0qKsqgdhoDa0gRERERGe75kD3dfai0rFw8TlX1AX2eBaTqVXlW2Jx1pIiIiEo1gwJSjRs3xpIlS7SWL1myRGPWPX1YW1sjMDAQYWFh4jKlUomwsDC0bNlS5zatW7fGnTt3NOpV3bp1C1WqVIG1tbXObWQyGRwdHTVuJY2z7BEREREZTp1lnprPRb2op6rsKGdbKzjZqCa8YWFzIiKissGgIXtff/01OnfujEOHDolBo1OnTiEqKgr79u0z+OATJkzAoEGD0KxZMzRv3hwLFy5EWlqaOOvewIED4eXlhdDQUADA6NGjsWTJEnz00Uf44IMPcPv2bcybNw8ffvihwccuScyQIiIiIjKcvViHU/dFvftPNIfrAUDdZwGpW7EpUCoFSKUSE7eSiIiIisKggFSbNm1w69YtLF26VCw8/vbbb2PMmDGoWrWqwQfv06cP4uPjMW3aNMTExKBJkybYv3+/WOg8MjISUunzJC4fHx8cOHAAH3/8sVi76qOPPsJnn31m8LFLEjOkiIiIiAxnV8iQvahn9aN88gSk/CrbwdpSivRsBaKfZqBaZVud2xIREZF5GRSQAoCqVatqFS+Pjo7GiBEjsHLlSoMbMG7cOIwbN07nY0eOHNFa1rJlS/zzzz8GH8ecmCFFREREZLjCipqLM+zlCUhZWkhR080e1x4l40ZMMgNSREREpZRBNaTy8+TJE6xevdoYuyqXOMseERERkeHEoub5XNTTNWQPeD5sj4XNiYiISi+jBKSoYHZi/QNmSBERERHp63mGlO6Leuohey8GpMTC5rEMSBEREZVWDEiVAGZIERERERlOfVFPVw0phVJA9NMMANAalleHGVJERESlHgNSJUDMkGINKSIiIiK92T27qKcryzwmORPZCiUspRJUcbLReKyupyMAIPxxGrJyeUGQiIioNNKrqPnbb79d4OOJiYnGaEu5pc6QylEIyM5Vwtoy/zjgg8QMrPr7Hsa2qwk3B1lJNZGIiIio1CmoqHnks/pR3i42sJBKNB7zcJTBycYKSRk5uBOXivpVnUzfWCIiIjKIXgEpJ6eCv8SdnJwwcOBAozSoPLJ9NsseoMqSsra0znfdJX/dwaYzkZBKJJjWNaAkmkdERERUKj0vaq6AIAiQSJ4HnsT6UZXttLaTSCSo4+mAM+EJuBmTwoAUERFRKaRXQOqnn34ydTvKNSsLKawtpcjOVSItWwHnAmYfvhGTDAC4FJ1YMo0jIiIiKqXUZQ8USgFZuUrIrZ5f5LufkAYAqFbJRue2dfMEpIiIiKj0YQ2pEmJnnX9RTjVBEHDrWafp6sNk5CqUJdI2IiIiMq0zZ85Aoci/llFWVha2bt1agi0qG9Q1pADtYXuRCaqC5r6VtDOkgDwz7TEgRUREVCoVGpAaNWoUoqOj9drZli1bsGHDhmI3qjwSZ9orICD1IDFDnIkvI0eBu/FpJdI2IiIiMq2WLVviyZMn4n1HR0fcu3dPvJ+YmIh+/fqZo2mlmlQqEUsfvNiHinw2ZM+nku7U87qcaY+IiKhUK3TInpubG+rXr4/WrVuja9euaNasGapWrQq5XI6nT5/i2rVrOH78ODZv3oyqVati5cqVJdHuMuf5THv5Xx29FavZYbr8IEm8ukdERERllyAIBd7PbxmpLuqlZyuQlqXZh4p8oh6ypzsgVdtD1YeKSc5EUnoOnGytTNtQIiIiMkihGVKzZ8/GrVu30Lp1ayxbtgwtWrRAtWrV4O7ujjp16mDgwIG4d+8eVq5ciX/++QeNGjUqiXaXOfpkSN2KTdW4f5l1pIiIiCqMvAW76Tn7Zxf10rKf96GSM3PwND0HAFCtsu6AlIPcCl7OqvpS6hqdREREVHroVdTcw8MDU6ZMwZQpU/D06VNERkYiIyMDrq6u8Pf3ZwdKD3plSD1LKa/lbo/bcam49CCpRNpGREREVFrZPZtpL28NKfUMe5XtrMWZ+HSp6+mAB4kZuBmbgqAalU3bUCIiIjKIXgGpvFxcXODi4mKKtpRrYoZUdv4ZUjefDdnrFeiN0D9u4NqzwuaWFqw9T0REVNZdu3YNMTExAFTD827cuIHUVFV29OPHj83ZtFJNHZDKm2Ue+aTg+lFqdTwdEHYjjoXNiYiISiGDA1JUNOpZ9tKzdGdIKZQCbsepOqWv1/fEkr/uICUrF7fjUlGvimOJtZOIiIhMo0OHDhp1orp06QJANVRPEARmnOfDXldA6lmGlG8+w/XU6rCwORERUanFgFQJsZUVnCF1/0kasnOVkFtJ4VvJFvW9HPHPvQRcjk5iQIqIiKiMCw8PN3cTyqznQ/aeX9S7/ywglV9Bc7W6nqo+1K2YFAb9iIiIShkGpEqImCGVTw0p9Qx7tT0cIJVK0MjbGf/cS8ClB4no/bJPibWTiIiIjM/X17fQda5cuVICLSl71H2oNB01pAobslfDzQ5WFhKkZOXiQWIGvF0KXp+IiIhKDosTlZDCZtm7GaMarqeeorihlxMA4HI0C5sTERGVVykpKVi5ciWaN2+Oxo0bm7s5pZKdjixzccheIQEpKwsp/N3sAXDYHhERUWnDgFQJKWyWPXWGVJ1nAalG3qqA1PWYFGTnKkughURERFRS/v77bwwaNAhVqlTBN998g/bt2+Off/4xd7NKpReLmucqlHjwNAMAUK2QGlLA8zpSLGxORERUuhg8ZG/79u3YunUrIiMjkZ2drfHYuXPnjNaw8qawDClxyN6zTlO1SrZwlFsiOTMXt2JT0OBZxhQRERGVTTExMVi7di1Wr16N5ORk9O7dG1lZWdi1axcCAgLM3bxSy16mHrKnuqj3KCkTuUoB1pZSeDjIC92ehc2JiIhKJ4MypL7//nsMGTIEHh4eOH/+PJo3b47KlSvj3r17ePPNN03VxnKhoAyprFwFwh+nAQBqe6jSyiUSCRo+y5K6/IDD9oiIiMqyrl27ok6dOrh06RIWLlyIhw8fYvHixeZuVpnwvKi56qKeeriej4sNpNLCi5TXZUCKiIioVDIoILVs2TKsXLkSixcvhrW1NT799FMcPHgQH374IZKSGDQpiJghpWOWvfDHachVCnCQW8LT8fmVvoZezgCAS6wjRUREVKb98ccfGDp0KGbOnInOnTvDwsLC3E0qM+xfGLJ3/4l+M+yp1Xk2097d+FSWQSAiIipFDApIRUZGolWrVgAAGxsbpKSorjS999572LRpk/FbV46oO1PpWdoZUuordnU8HDSmI24kZkglmr6BREREZDLHjx9HSkoKAgMDERQUhCVLluDx48fmblaZ8GLZA7GgeWU7vbav6iSHg9wSuUoBd+NTTdNIIiIiMphBASlPT08kJCQAAKpVqyYW3wwPD4cgCMZvXTliq56yWEeG1Iv1o9TUM+3djElBVq7uYuhERERU+rVo0QKrVq3Co0ePMHLkSGzevBlVq1aFUqnEwYMHxYt8pE1d9iDtWdmDKPWQPT0zpCQSiThpDIftERERlR4GBaTat2+P3bt3AwCGDBmCjz/+GB07dkSfPn3Qo0cPkzSwvFDXP9BVQ+pmjOpqnbqzpObtYgNnWyvkKAR2oIiIiMoBOzs7vP/++zh+/DguX76MTz75BF9++SXc3d3RrVs3czevVNIaspegqrup75A9gDPtERERlUYGBaRWrlyJKVOmAADGjh2LNWvWoF69epg1axaWL19ukgaWF2KGlI5Z9sQMqRcCUhKJRMySYh0pIiKi8qVOnTr4+uuvER0djc2bN2sM26fntIqaP1EP2dM/IPW8sHmykVtHRERERWVpyMpSqRRS6fMYVt++fdG3b1+jN6o8sntW/yArV4lchRKWFqrnMT07V6yFoJ5hL69G3k44dvsxLjMgRUREVGa9//77ha5TuXLlEmhJ2ZM3QyoxPRvJmarAlI+LIRlSqsLmzDgnIiIqPQoNSF26dEnvnTVq1KhYjSnPbGXPZ9NJz1HA8VlA6k6carieq70Mle1lWtupZ9q7/IABKSIiorJq7dq18PX1RdOmTfOtu8kMKd3UGVJKAbgVq+o3uTnIYGOt/0yF6rIID5MykZSRAycbK+M3lIiIiAxSaECqSZMmkEgkEASh0I6SQsHC2/mxtpDCUipBrlJAepYCjnJVR0h9pU5XdhQANHw2096t2BRk5iggt+I00URERGXN6NGjsWnTJoSHh2PIkCF49913UalSJXM3q0ywzdP3ufZQdYHO14D6UQDgZGuFKk5yPErKxJ24FAT68rknIiIyt0JrSIWHh+PevXsIDw/Hjh07UL16dSxbtgznz5/H+fPnsWzZMvj7+2PHjh0l0d4ySyKR6JxpL7/6UWpVneSobGeNXKWA649Y94CIiKgsWrp0KR49eoRPP/0Uv//+O3x8fNC7d28cOHCAMxUXQip93oe6/kjVbzKkoLmaX2U7ABBLJRAREZF5FZoh5evrK/7+zjvv4Pvvv0enTp3EZY0aNYKPjw+++OILdO/e3SSNLC/sZJZIzsxFetbzTLKbz1LP1bO/vEgikaChtxOO3IzH5QdJaFrNpUTaSkRERMYlk8nQr18/9OvXD/fv38fatWsxZswY5Obm4urVq7C3150tTao+VHq2AtefFSX3KUJAqlolW5y69wRRCRnGbh4REREVgUGz7F2+fBnVq1fXWl69enVcu3bNaI0qr3RmSMUUnCEFAI2ezbTHwuZERETlg1QqFUsisORB4dSFzdWlDgyZYU+t2rNtmCFFRERUOhgUkKpXrx5CQ0ORnZ0tLsvOzkZoaCjq1atn9MaVN+qinOnPAlJJ6TmISc4EkH8NKQBooA5IsbA5ERFRmZWVlYVNmzahY8eOqF27Ni5fvowlS5YgMjKS2VGFsHs2OUxWrhJA0YbsqbOqGJAiIiIqHQwKSK1YsQIHDhyAt7c3goODERwcDG9vbxw4cAArVqwociOWLl0KPz8/yOVyBAUF4cyZM/muu3btWkgkEo2bXC4v8rFLkpgh9WzI3q041VU+L2cbOMjzn+2lkbezav3YFGRk8yoqERFRWTNmzBhUqVIFX375Jbp06YKoqChs27YNnTp1glRqUHesQrKz1qwyUaSAlIsNACCKASkiIqJSwaAeUPPmzXHv3j3MmTMHjRo1QqNGjTB37lzcu3cPzZs3L1IDtmzZggkTJmD69Ok4d+4cGjdujJCQEMTFxeW7jaOjIx49eiTe7t+/X6RjlzR1Z0qdIVXYDHtqHo4yuDnIoBSAa4+YJUVERFTWrFixAo6OjqhRowaOHj2KESNG4O2339a6GcKQC3oAkJiYiLFjx6JKlSqQyWSoXbs29u3bV5zTKjHqLHMAkFtJ4eYgM3gf6iBWTHImMnN4gY+IiMjcCi1q/iI7OzuMGDHCaA1YsGABhg8fjiFDhgBQddj27t2LNWvWYNKkSTq3kUgk8PT0NFobSorts86UOkPqdiEz7KlJJBI08nJC2I04XIpO4lTFREREZczAgQMhkUiMtj/1Bb0VK1YgKCgICxcuREhICG7evAl3d3et9bOzs9GxY0e4u7tj+/bt8PLywv379+Hs7Gy0NplS3oBUtUq2RXouK9lZw87aAmnZCjxIzIC/G4dJEhERmVOhAandu3fjzTffhJWVFXbv3l3gut26dTPo4NnZ2Th79iwmT54sLpNKpQgODsapU6fy3S41NRW+vr5QKpV46aWXMG/ePNSvX9+gY5uD3bMhe2KGlJ4BKQBo6K0KSLGOFBERUdmzdu1ao+7P0At6a9asQUJCAk6ePAkrK1WZAD8/P6O2qdiUSkCZA1hqZz/ZP6shBQDVKtkVafcSiQQ+lWxxIyYFkQnpDEgRERGZWaEBqe7duyMmJgbu7u7o3r17vutJJBKDZ4l5/PgxFAoFPDw8NJZ7eHjgxo0bOrepU6cO1qxZg0aNGiEpKQnffPMNWrVqhatXr8Lb21tr/aysLGRlZYn3k5OTDWqjMdk+G7KXlq2AIAjikL06nnoEpDjTHhEREaFoF/R2796Nli1bYuzYsfjtt9/g5uaG/v3747PPPoOFhYXObUq0D/Xvj8CxBUCrD4EWo7QezltDqij1o/JueyMmhXWkiIiISoFCa0gplUox9VupVOZ7K6kpi1u2bImBAweiSZMmaNOmDXbu3Ak3Nzf88MMPOtcPDQ2Fk5OTePPx8SmRduqiniEmPSsXj1Oz8TQ9BxIJUNO98Ct06oDUnfhUpGXlmrSdREREVHoVdEEvJiZG5zb37t3D9u3boVAosG/fPnzxxRf49ttvMWfOnHyPU6J9KEUukPwAuLJD58OaQ/ZsinwYdTAr8gkDUkREROZm1mldXF1dYWFhgdjYWI3lsbGxeteIsrKyQtOmTXHnzh2dj0+ePBlJSUniLSoqqtjtLqq8GVK3ng3X86tsB7mV7iuTebk7yuHpKIcgAFcfmi/Li4iIiMoe9QXGlStXIjAwEH369MGUKVMKnCW5RPtQ9bsDkADRZ4Cn2pPV2OcJSPlWLtqQPQCoVvlZQIoZUkRERGZX6JC977//Xu+dffjhhwYd3NraGoGBgQgLCxOHAyqVSoSFhWHcuHF67UOhUODy5cvo1KmTzsdlMhlkMsNnYjEFMUMqO1fvGfbyaujthJhrmbj8IAnNq7OwORERUUVUlAt6VapUgZWVlcbwvHr16iEmJgbZ2dmwtrbW2qZE+1AOnoDfK0DEMeDqr8Ar4zUets1TQ8qnGEP21NsyIEVERGR+hQakvvvuO4378fHxSE9PF2dlSUxMhK2tLdzd3Q0OSAHAhAkTMGjQIDRr1gzNmzfHwoULkZaWJhbpHDhwILy8vBAaGgoAmDVrFlq0aIGaNWsiMTER8+fPx/379zFs2DCDj13SxAyprOcZUnX0KGiu1tDLCQevxeJydKIpmkdERERlQFEu6LVu3RobN26EUqmEVKpKkL916xaqVKmiMxhlFg16qgJSV3ZoBaTUGVISCeDtUvwhe1EJ6RAEwagzHxIREZFhCh2yFx4eLt7mzp2LJk2a4Pr160hISEBCQgKuX7+Ol156CbNnzy5SA/r06YNvvvkG06ZNQ5MmTXDhwgXs379frIsQGRmJR48eies/ffoUw4cPR7169dCpUyckJyfj5MmTCAgIKNLxS1LeWfbEGfb0KGiu1tBbVUfqEmfaIyIiqtAmTJiAVatWYd26dbh+/TpGjx6tdUEvb9Hz0aNHIyEhAR999BFu3bqFvXv3Yt68eRg7dqy5TkFbvW6A1BKIuQQ8vq3xkLqouaejXK9SB/nxcraBRKIqn5CQll2s5hIREVHxFJohldcXX3yB7du3o06dOuKyOnXq4LvvvkOvXr0wYMCAIjVi3Lhx+V7RO3LkiMb97777Titrq6ywfXZ1LzVLIc7uUtvADCkAuBefhpTMHDjIrYzfSCIiIir1+vTpg/j4eEybNg0xMTFo0qSJ1gU9dSYUAPj4+ODAgQP4+OOP0ahRI3h5eeGjjz7CZ599Zq5T0GZXGajRDrhzELiyE2j7vG2NfJzg5iBD54ZVinUIuZUFPB3leJSUiciEdFS2Lx1lHYiIiCoigwJSjx49Qm6u9gxvCoVCq44BaVNnSIU/TkVmjhJWFhL4GVCY09VeBi9nGzxIzMCVB8lo6V/ZVE0lIiKiUs6QC3qAaqbif/75x8StKqYGPZ8FpLYDbT5VjdED4O4gx5nPOxhliJ1PJVsxINW0mkux90dERERFY9Asex06dMDIkSNx7tw5cdnZs2cxevRoBAcHG71x5Y26hlRmjhIAUMPVHtaWhk102MDLEQBwhcP2iIiIqLyp2wmwkAGPbwGxVzQeMla9p7x1pIiIiMh8DIqGrFmzBp6enmjWrJk480rz5s3h4eGBH3/80VRtLDfsZJo1DwypH6XWyNsZAOtIERERUTkkdwJqdVT9fmWHSQ5RjTPtERERlQp6D9kTBAEZGRnYsWMHoqOjcf36dQBA3bp1Ubt2bZM1sDxRZ0ip1fGwN3gf6ppT4Y9TjdImIiIiolKlQU/gxh5VQKrDdHHYnrE8z5DKMOp+iYiIyDAGBaRq1qyJq1evolatWqhVq5Yp21UuaWVIGVDQXM2nkmqq4+in7EQRERFROVQ7BLCyAxIjgQdnAe9mRt29DzOkiIiISgW9h+xJpVLUqlULT548MWV7yjW5pYXGRb46RRiy5+2i6kQlpucgJTPHWE0jIiIiKh2s7YA6b6p+N8GwPfXFvUdJGcjOVRp9/0RERKQfg2pIffnll/jf//6HK1euFL4yaZFKJbC1UmVJya2k8HkWXDKEvcwSLrZWAJglRUREROVUg56qn1d2AkqFUXftZi+D3EoKpQA8TGRfioiIyFwMCkgNHDgQZ86cQePGjWFjY4NKlSpp3KhwtjLVKMla7g6QSotWE0GdJcXZYYiIiKhcqtkBkDkBqTFA5Cmj7loikbCwORERUSmgdw0pAFi4cKGJmlFx2FlbIB5Fqx+l5lPJBpcfJDFDioiIiMonSxlQrytw4RfVsD2/V4y6+2qVbHErNpUBKSIiIjMyKCA1aNAgU7WjwlDPtFfH0/AZ9tTUGVIMSBEREVG51eBtVUDq2m/Am18DFlZG27VPJWabExERmZtBQ/YA4O7du5g6dSr69euHuLg4AMAff/yBq1evGr1x5VF1VzsAwMt+RR/i6OOiKsYZ9ZSdKCIiIiqnqrcBbCsD6U+A8KNG3TWH7BEREZlfgQGpmzdvatw/evQoGjZsiNOnT2Pnzp1ITU0FAFy8eBHTp083XSvLkW/eaYwD419D02ouRd4HM6SIiIio3LOwBAK6q36/stOou2ZAioiIyPwKDEjt3LkTAwYMgEKhmt1k0qRJmDNnDg4ePAhra2txvfbt2+Off/4xbUvLCRtrC9TxLHr9KADwfpYhFZ2QDkEQjNEsIiIiotKnYS/Vz+u/A7lZRtutGJB6wr4UERGRuRQYkJo4cSIqVaqEkJAQAMDly5fRo0cPrfXc3d3x+PFj07SQtKgzpFKycpGckWvm1hARERGZiE8LwKEqkJUM3DlktN3m7UslZeQYbb9ERESkvwIDUlZWVli8eDFGjhwJAHB2dsajR4+01jt//jy8vLxM00LSYmNtAVd7VYYa60gRERFRuSWVqoqbA6rZ9ozExtoC7g4yABy2R0REZC56FTV/5513AAB9+/bFZ599hpiYGEgkEiiVSpw4cQITJ07EwIEDTdpQ0vS8jhQ7UURERFSOqQNSN/8AstOMtlvWkSIiIjIvg2bZmzdvHurWrQsfHx+kpqYiICAAr732Glq1aoWpU6eaqo2kg7qOVFQCC5sTERFROVb1JcDFD8hJB27tN9puGZAiIiIyL4MCUtbW1li1ahXu3buHPXv24JdffsGNGzewfv16WFhYmKqNpINPJWZIERERUQUgkQANeqp+v7TVaLtV96WiGJAiIiIyC0t9VlIqlZg/fz52796N7OxsdOjQAdOnT4eNjY2p20f5EDOknjJDioiIiMq5Rn2BYwtUGVIPLwBVmxR7l8yQIiIiMi+9MqTmzp2Lzz//HPb29vDy8sKiRYswduxYU7eNCuDDGlJERERUUbjVBhqqapoibJZRdlmtMgNSRERE5qRXQOrnn3/GsmXLcODAAezatQu///47NmzYAKVSaer2UT7y1pASBMHMrSEiIiIysXaTAaklcDcMiDhe7N2pM6QeJmYiV8E+LRERUUnTKyAVGRmJTp06ifeDg4MhkUjw8OFDkzWMCub1LCCVkaNAQlq2mVtDREREZGKVagCBg1W/H5oJFPOCnJu9DNaWUiiUAh4lZRa6/rnIpwiadwi/no8u1nGJiIhIRa+AVG5uLuRyucYyKysr5OTkmKRRVDiZpQU8HGUAWEeKiIiIKojX/gdY2gDRZ4CbfxRrV1KpBD7PLvBFJqQD0WeB0z8AuVk61//x2D3EJmfhmwO3oFAyO52IiKi49CpqLggCBg8eDJlMJi7LzMzEqFGjYGdnJy7buXOn8VtI+fJxsUVschain6ajiY+zuZtDREREZFoOnkCLUcDx74C/ZgO1QwBp0Wd6rlbJFpaPr8P34Cog9rBqYdpjoP0UjfXSsnLx1404AMCDxAwcux2PtnXci3xcIiIi0jNDatCgQXB3d4eTk5N4e/fdd1G1alWNZVSy1HWkopkhRURERBVF648AuRMQdw24vL3o+0m4h/HJ8/GH9WR4q4NRAHD2J60sqbAbccjMeV5natOZyKIfl4iIiADomSH1008/mbodVAQ+z4pxRnF2GCIiIqoobFyA1uOBsJnA4blA/R6ApbX+2yc/BP6eD5z7GY2VuYAEOGffBi+99yXwS08g5SFwbTfQ6B1xk72XVHVTOwZ44OC1WBy6Hoe45Ey4O8rzOwoREREVQq8MKSqdmCFFREREFVLQKMDeA0i8D5xbp9826QnAn1OB75sC/60BlLl47PkqOmfNxQz5p4BHANDsfdW6Z1aKm6Vk5uDwzXgAwMfBtdHM1wUKpYBtZ1ncnIiIqDgYkCrDfFyeZUg9ZYYUERERVSDWtqoC5wBw9GsgO63g9W/uB5Y2B04uBnIzgWotgcH78Lj7RlwVqquKmgNA4CBAaqUqmv7wPAAg7HocsnOVqOFqh3pVHNA/qBoA1bA9JYubExERFRkDUmWY97OA1IOnGRCKOfUxERERUZny0iDA2RdIiwNOr9C9TnYasOdjYFMfIC0ecKsLDNgODPkD8GstXtxLTM9BUkYOYO+uGgIIAGdWAQD2XHoEAOjSqAokEgk6NawCR7klop9m4NidxyY/TSIiovKKAakyrIqzHFIJkJWrRHyK7imKiYiIiMolS2ug/VTV7ycWARlPNR9/cA744TXV8DwAaDkOGHEUqNURkEgAAHYyS7jaq+pPiTU5m49Q/by8HclPYvD3LdVwvc6NqgIA5FYWePslbwDAptMsbk5ERFRUDEiVYVYWUlRxUtWRimIdKSIiIqpoGvQC3OsDmUnA8YWqZUqFqmj56o7AkzuAQ1Vg4G9AyFzASrsIudYkMd7NgCpNAEUW7h9agWyFEjXd7VHbw17cpl9z1bC9Q9djEZecacozJCIiKrcYkCrjvMTC5qwjRURERBWMVAp0+EL1++kfgMjTwE+dgL/mAMpcIKA7MPoEUKNtvruo9iwgJdaRkkjELKkqtzZACqU4XE+tjqcDAn1dkMvi5kREREVWKgJSS5cuhZ+fH+RyOYKCgnDmzBm9ttu8eTMkEgm6d+9u2gYaIiMRuPtXiR1OXfuAM+0RERFRhVT7DcC7OZCbAax5HYj6B7B2AHr8ALyzFrCtVODmWgEpAGjwNpQ2leCqiEMH6Tl0blhFazt1ltTmf1ncnIiIqCjMHpDasmULJkyYgOnTp+PcuXNo3LgxQkJCEBcXV+B2ERERmDhxIl599dUSaqkeEu4BCxsBmwcAqfElckjvZxlSUQnMkCIiIqIKSCIBgmc8v1+tlSorqnFfsVZUQXx0BaSsbHCzqqq4+Wjbv1DLw0Fru84Nq8BBbomohAycuMvi5kRERIYye0BqwYIFGD58OIYMGYKAgACsWLECtra2WLNmTb7bKBQKDBgwADNnzkSNGjVKsLWFcKkOuNYEctKBEwtL5JDqThQzpIiIiKjC8msNdF8OdP0eGLwHcPHVe9NqL9aQeubHjLZQCBK8lHsBiL+ptZ2NtQXebuoFANh0hsXNiYiIDGXWgFR2djbOnj2L4OBgcZlUKkVwcDBOnTqV73azZs2Cu7s7hg4dWugxsrKykJycrHEzGYkEaPe56vd/fwSSH5nuWM+IGVKsIUVEREQVWZP+QOAgQGph0GbV8lzcUzwbevc0LRu/RVgiTPmSaqV/f9S5bb8g1bC9P6/GIi6Fxc2JiIgMYdaA1OPHj6FQKODh4aGx3MPDAzExMTq3OX78OFavXo1Vq1bpdYzQ0FA4OTmJNx8fn2K3u0D+HQCfICA3Ezj+nWmPhecZUg8Tn3eiiIiIiEg/Ho5yWFtIkasU8ChJlXF+4GoMcpUCDjuphu3hwkYgU/uiZl1PRzSt5oxcpYDt5aW4+e2DwK0/zd0KIiKqAMw+ZM8QKSkpeO+997Bq1Sq4urrqtc3kyZORlJQk3qKiokzbSIkEaDdF9fvZn4Ak03ZOPB3lsJRKkKMQEMtph4mIiIgMYiGViLMWq+tI7b2synL3fukNwLU2kJ0KXNysc/v+6uLmZ6LKfnHzpGhgY29gU18gJdbcrSEionLOrAEpV1dXWFhYIDZW8wsvNjYWnp6eWuvfvXsXERER6Nq1KywtLWFpaYmff/4Zu3fvhqWlJe7evau1jUwmg6Ojo8bN5Kq/Bvi+Aiiygb+/MemhLKQSVHVWdaJYR4qIiIjIcGJNzoQMPEnNwsm7TwAAXRpXBZqPUK10ZiUgaAecujSqCge5JSIT0sXtyqzL2wFBCQgKIPxvc7eGiIjKObMGpKytrREYGIiwsDBxmVKpRFhYGFq2bKm1ft26dXH58mVcuHBBvHXr1g3t2rXDhQsXTD8cT18SCdD+WZbU+fXA0/smPZy6jlQ060gRERERGaxapecZUvuvxkChFNDQywm+le1Us/VZOwBPbgP3jmhta2NtgR7lpbj55W3Pfw8/YrZmEBFRxWD2IXsTJkzAqlWrsG7dOly/fh2jR49GWloahgwZAgAYOHAgJk+eDACQy+Vo0KCBxs3Z2RkODg5o0KABrK2tzXkqmnxbATXaAcpc4O+vTXooHxf17DDMkCIiIiIylLqweWRCOvZeUg3X69yoiupBmQPQpJ/q9zO6a5j2fVk1bO/A1RjEp2SZtrGmEnMFiL3y/P69ozozwoiIiIzF7AGpPn364JtvvsG0adPQpEkTXLhwAfv37xcLnUdGRuLRI9PPVmcS6lpSFzYBT7SHExoLM6SIiIiIik4dkLoQlYh/7qmG3XVuWOX5Ci8PV/289YfOzPeAqo5o4qMqbr7jXBktbn55q+qnf3vAwhpIigIS7pm3TUREVK6ZPSAFAOPGjcP9+/eRlZWF06dPIygoSHzsyJEjWLt2bb7brl27Frt27TJ9I4vC52Wg1uuqcfhHTZclpa57EMWAFBEREZHBfPJkSCkFoLGPs7gMAOBWG6jRVlVf6dAMQKnQ2oe6uPn6U/eRnassgVYbkVKpqh8FAIGDAe/mqt91DFEkIiIyllIRkCrX2n2u+nl5KxB/yySHeJ4hxSF7RERERIbSCD4B6JI3O0rt1YmAxAK4uhP4baxWUKpbk6pwc5DhQWIGtp8tY1lS908AyQ8AmRNQK0QVfAMYkCIiIpNiQMrUqjYF6nRWXVE7+qVJDqHuRD1KykSuooxdkSMiIiIyM0e5FVxsrcT7nRrpCEhVfxXotVoVlLq4Cdg1WiMoJbeywOg2/gCApYfvICtXO4uq1FIP1wvoBljJgRptVPcjjunMBiMiIjIGBqRKQjtVUXZc2QnEXjP67t3sZbC2lEKhFPAoKdPo+yciIiIq79R1pF6q5gwvZxvdK9XvAbzzEyC1BC5tAX4dCShyxYf7B1WD+7Msqa3/lZEsqZxM4Opvqt8b9VH9rPqSambBjKdAzCXztY2IiMo1BqRKgmdDIOAtAAJwJNTou5dKJfB+1nFiHSkiIiIiwwVUdQIA9GjqVciKbwG9ngWlLm8Dfh0hBqXkVhYY01aVJbWsrGRJ3T4AZCUBjl6Ab2vVMgtLVUYYoJptj4iIyAQYkCopbScDkADXdwOPjH+lyYt1pIiIiIiK7LM36mDN4GZ4t4Vv4SsHdAPeWacKSl3ZAewcJgal+javBk9HOR4lZWLLv1EmbrURXHo2XK9hL0Ca51+D6s+G7bGOFBERmQgDUiXFvZ7qix4ADs8z+u7VdaSiE5ghRURERGQoZ1trtK/rAYlEot8G9boAvdcDUivg6q/AjvcBRY4qS6rd81pSmTmlOEsq4ylw+0/V7+rhemrqwuaRp1TD+oiIiIyMAamS1OYzQCIFbv0BXNhk1F2rZ9qLf/wY+P0j4OQSo+6fiIiIiF5QtxPQ5xfAwhq49huwfQigyEGfl31QxUmO2OQsbD4Tae5W5u/ab4AiG3CvD3jU13zMrQ5g7wnkZgLRZ8zTPiIiKtcYkCpJrrWA5iNUv+8aBRwOBQTBKLv2drGFA9IxJHwCcHYt8OcU4L+fdK7747F7mL3nGmfkIyIiIiquOm88D0pd/x3YNxEySwuMbVcTALDsyN3SmyWlHq7XqLf2YxLJ89n2OGyPiIhMgAGpkhYSCrzyser3o1+qZmfJzSr2bv1ss7HeOhS1c26oOkQAsO9/QORpjfWuPEjCnL3Xsfp4ONadul/s4xIRERFVeLVDVIXOAVWQJzcbvZv5wMvZBnEpWdh4uhRmSSVGAfdPAJA8LyvxIvWwPRY2JyIiE2BAqqRJpUDwDKDr98+nDP65O5CeUPR9pieg3qGBaCK9iwTBHjlDDgIB3QFlDrD1PSD5kbjqwkO3xd8X/HkTj5JYBJ2IiIio2Op0AmxdgZx0IPpfWFtKxSyp5UdLYZbU5W2qn36vAE7eutdRFzZ/eA7ISCyRZhERUcXBgJS5BA4CBmwHZI5A5Engx2DgyV3D95OeAPz8FqxiLyJBcED/7Kl4IK8FvLVUVQ8gNVYVlMrNwuXoJBy6HgupBKjtYY+0bAVm7L5q/HMjIiIik1u6dCn8/Pwgl8sRFBSEM2f0q/OzefNmSCQSdO/e3bQNrGik0udD3MJVGUW9Ar3h5WyD+JQs/PJPKcpMF4SCh+upOXkBlWsBghKIOF4ybSMiogqDASlz8m8HDP0TcKoGJNwFfuwA3D+p//ZpT4B13YCYS4CtKz61n4cbQjVEP80AZPZA318AuTMQ/S+w9xMsOnQTANCtcVV8368pLKUSHLgai0PXYk1zfkRERGQSW7ZswYQJEzB9+nScO3cOjRs3RkhICOLi4grcLiIiAhMnTsSrr75aQi2tYNQZRc+GuFlbSvFBe1WW1Iqj95CRXUqypGKvAPHXAQsZUK9bweu+EGQjIiIyFgakzM29HjA8DPAKVE29+/NbwMUthW+X9hhY1xWIvQzYuQOD90LhWhcAEPU0XbVOpRpAr9Wqmf3Or4fn7Y2QSoAPO9RCXU9HDH21OgBg+u6rSM/ONdUZEhERkZEtWLAAw4cPx5AhQxAQEIAVK1bA1tYWa9asyXcbhUKBAQMGYObMmahRo0YJtrYCUQdvHvwHZKUAAHoGesOnkg0ep5aiLKlLz/qatUMAG+eC1xXrSB0xYYOIiKgiYkCqNLB3BwbtUV2hUmQDv44Avq0HrO8B7P8cOPczEPUvkJmsWj81DljbBYi7Cth7AIP3Au514e1iCwCIVgekAKBmMNBhOgBguuXP+Lj2E9RwswcAfNShFrycbfAgMQOL8tSWIiIiotIrOzsbZ8+eRXBwsLhMKpUiODgYp06dyne7WbNmwd3dHUOHDtXrOFlZWUhOTta4USFc/ABnX0CZK2a9W1lI8UG7WgCAFUfvmv8ioFIBXN6h+r1Rn8LX93tFdXHz8S0g+aFp20ZERBUKA1KlhbUt8M461Qx8EimQ8hC4+xfwz1Jg9wfA6mDgSx9gQX3gh9dUadb2nqpglFttAIBPJRsAQFSCZqHyC9UG4XdFC1hJFBgdPwtIegAAsLW2xKy36gMAfjwejuuP2NEkIiIq7R4/fgyFQgEPDw+N5R4eHoiJidG5zfHjx7F69WqsWrVK7+OEhobCyclJvPn4+BSr3RVGDc1hewDQ4yUvVKtkiydp2Vhv7lmOI46r+plyJ6BWx8LXt3EBqjRR/X7vKDJzFIhPKf4M0URERAxIlSbqGfg+DQfe/xPouggIGq1Klbb3VK2THA2kPAIcqgJD9gGutcTNdWZIAVgUdhuf5ozAQ5k/LNPjgS3vAjmZAIAO9TzwRn1PKJQCPv/1MpRKoSTOlIiIiEpISkoK3nvvPaxatQqurq56bzd58mQkJSWJt6ioKBO2shyprl1zycrieS2pH/6+Z94sKXUx8/o9AEuZfts8G7anvHcY7/54Gq2//At341NN0z4iIqowLM3dANLBxhmoFqS65ZWeAMTfBBLuqQqiO1bVeNjnWUAq6unzDKnzkU9x+GY8LKQ2UPb+BdjeSTV1794Jqpn4JBJM7xaAY7fjcT4yEZv+jcSAIF9TnyEREREVkaurKywsLBAbqzkpSWxsLDw9PbXWv3v3LiIiItC1a1dxmVKpBABYWlri5s2b8Pf319pOJpNBJtMzYEHPqQNSsVeA1HjA3g0A0KOpFxb/dQeRCenY+m8UBreuXvJty8kAru9W/a7PcD21Gm2A4wuQefMv/JfUDYAEB67GYEzbmiZpJhERVQzMkCpLbCsBvi2BpgO0glEA4O2iGrIXn5KFzBzVLC4Ln9WG6tHUC97+AUCvn1RDAi9sAI4vAABUcbLBJ6/XAQB89ccNpmETERGVYtbW1ggMDERYWJi4TKlUIiwsDC1bttRav27durh8+TIuXLgg3rp164Z27drhwoULHIpnbPZugLuqJAIi/hYXW1pIMeI1VTH5VcfCkaNQlnzbTi0FspJVMzz7tNB/O58WECzlsM2Kh79EVUfq+O3HJmokERFVFAxIlSPOtlawl6mS3qKfZuDs/ac4eiseFlKJmCYO/3bAG1+qfg+bJaZtD2rlhwZejkjOzMWcvdfM0XwiIiLS04QJE7Bq1SqsW7cO169fx+jRo5GWloYhQ4YAAAYOHIjJkycDAORyORo0aKBxc3Z2hoODAxo0aABra2tznkr5JM5Md1Rjca9Ab7jay/AgMQO/XyzhAuFP7gJHv1b93uELVakIfVnJcVvWAADQ2f4WAOC/iKfmL9BORERlGgNS5YhEIhGzpKKfpmNRmCo76u2mXvCtbPd8xaCRQMtxqt93jQHC/4aFVIJ5PRpCKgF+u/AQx27Hl3TziYiISE99+vTBN998g2nTpqFJkya4cOEC9u/fLxY6j4yMxKNHj8zcygqshnYdKQCQW1lgSGs/AKoZ90qsdqcgAHvGA4oswL890PAdgzb/NyIBvyaqLm6+XyUCXs42yFYocTo8wQSNJSKiioIBqXJGXdh894WH+PtWPCylEnzQvpb2ih1nAwHdAWUOsPldIPYaGnk7Y2BLPwDAF7uuiMP+iIiIqPQZN24c7t+/j6ysLJw+fRpBQc9rTx45cgRr167Nd9u1a9di165dpm9kReXbCpBaAk8jVLc83m3hC3uZJW7FpuLwzbiSac/FTUD434ClDdB5ASCR6L1prkKJL3ZdwXGlKkPKOfY02tZyBgAcu8Vhe0REVHQMSJUz6gypnecfAAB6vuSNapVttVeUSoEePwDVWgJZScCGd4DkR/jk9drwcJQh4kk6Vh8PL8mmExEREZUPMgfAK1D1+wvD9pxsrDCgRTUAwPIjd03flrTHwIEpqt/bTgIqGVZMfe3JCNyIScEDeU0oZU5AVjI6uaoCacyoJyKi4mBAqpzxqfQ8+GQplWBc+wJmP7GSA303ApVrAcnRwMZ34CDJxOQ36wEAlh2+g7iUTFM3mYiIiKj8qa572B4ADG1dHdYWUvx3/yn+jTDxsLcDU4CMBMCjAdByrEGbxiZnihPk/O/N+pDWeA0A8FLuBUglwO24VMQksa9IRERFw4BUOaPOkAJUhTPzBqh0sq0EvLsdsHMDYi4DWwehWwM3NPZxRlq2Agv+vGXiFhMRERGVQ2Idqb9VNZzycHeUo2egFwBghSmzpO4eBi5tBiABun4PWFgZtPmcvdeRmpWLJj7O6NPMRyzWbhN1HA29nQEwS4qIiIqOAalyprqrqni5pVSCse0KyI7Ky8UP6L8VsLIF7oZBuu9jTOtcFwCw5b8oXHuYbKLWEhEREZVT3i+rajalxQNx2jMYj3jNHxIJEHYjDjdiTNDXyk5XFTIHVBPaeAcatPmJO4/x+8WHkEqAOd0bQCqVANXbqh6MOo32NewBAMdus44UEREVDQNS5UxtDwdM7VwPS/o3LTw7Ki+vl4BePwESKXD+FwRG/Ij/s3ffYU1dfRzAv0mAsJeyVATFiaIoqHUvLO5qtY4uV+vWqtVW27oHjurrqNVq66i1ap21bsVR91514AJxIU5QViA57x8hMSFhSSCo38/z5Ely77nnnnsScn+ce+45rap4QQhg0tbLEKKAZoEhIiIiehtYyNWDmwMG40gB6ouILSt7AQB+OXDL9Pv/d7p6QHXH4kCTH3K1aUqaEqP//g8A8Nl7Pqhc3Em9oogf4OQNKBVon7YdAHDoxuOCmy2QiIjeKmyQegt9Ub80mqcHOLlSvjnQaqb69f4pGBPwHFYWUhy5+QThVwpoFhhTeXgJWNsDeGh4RZKIiIioQJTOfBwpAOjb0A8AsPn8fdx5mmi6/cb8BxyZp37d8kf1IOu58OvBSNx6lICi9nIMe7/8qxUSCdBgBADA++yPCLK6g6cJClx+wN70RESUe2yQIn3BPYEqXQAAHpGb0LOueiaWKduuQJGmMmfJci45DljVBbi0Adgy1GDcBiIiIqICoRnYPOowoEwzWB1Qwgn1yhSFUiVMN7uxSgn88xWgSgMqtgEqtMzV5nefJWLeXvVA5t+1rAAnmwzjTlX/HKjQGhJVKubJ58MaKbxtj4iIXgsbpMhQYFf185V/MKChD4raW+HW4wT8cey2ecuVE0IA/wwBnker3985BkQdNGuRiIiI6B3lWQWwcQEUL4D7Z4wm6ddI3Utq9cloPHmZkvd9nloC3DsFyB2BFtNzvfnELZeRnKpCzVKuaF+tuGECSfoA6faeKJYajVEWf3JgcyIiei1skCJDPvUA2yJA0lM4PDiKYc3UXbXnhF/H80SFmQuXjbMr1D2jJLJXVyUP5D4YIyIiIsozqRTwra9+fWu/0SR1/IogoLgTklNVWH4kKm/7i78P7Bmvft10DOBYLFeb/3cvDjsvPYRMKsHEDypDIpEYT2hXBGi/AADQzWI37G+HI0mhzEvJiYjoHcQGKTIks1B38QaAS5vQKbgEyns4IC4pFXPCr5u3bFl5FAFs/1b9uskPQLufAamluodU1GHzlo2IiIjeTZpxpIwMbA4AEolE20tq+dHbSEgxvLUvx7Z/q+6NVaIGENwr15v/elA9uHqrAC+U98xm3Cm/JhDv9QcATJYtxJnLEbneHxERvdvYIEXG+bdTP1/dAguo8EPrigCAFUdv4+ajl+YrV2ZSk4F1PYHURKB0I6DuEMCpBFDtU/X6f9lLioiIiMygVCP1890TgML4wOWhlTxRqqgd4pJSsepE9Ovt59pO4MpmdS/xNnPUvbNy4UFcErZceAAA+LJ+6RxtI2k6Fg+s/eAmiYf7vq85bicREeVKoWiQmj9/Pnx9fWFtbY1atWrhxIkTmabdsGEDgoOD4ezsDDs7OwQGBmLFihUFWNp3hG999W17iU+AqIOoX9YNjcu7IU0lELbtqrlLZ2j3aODhf4BtUaD9L6+CsHpDAamFupv8ncy/V0RERET5oogf4FgCUCqA6KNGk8ikEvRpoG4EWnjgJsb+/R+mbLuCWbsiMH/fDfx2KBJ/HLuNdafv4vCNxxAZG34UicC24erXtQcAHpVyXcxlR6KQphKoVcoVASWccraRpTWu1ZuNFGGJsnFHgJO/5nq/RET07jJ7g9SaNWswbNgwjB07FmfOnEHVqlURGhqK2NhYo+ldXV3x/fff4+jRo7hw4QJ69OiBHj16YOfOnQVc8reczAKo0Fr9+vImAMD3rSpCJpVgz5WHOHKjEM2mcnUrcGKR+nX7hYCD56t1Lj5A1fRB2jmWFBERERU0ieTVbXuRxm/bA4D21YvDw1GOxy8VWH70Nhb9ewtz997AjJ0RmLjlMn7Y9B+Grz2PT349jvH/XNbf+N8Z6gldnLyBRiNzXcSXKWn487i6Z1ZOe0dpVK3+HsLSPgYAiJ0/ALGF8MIlEREVSmZvkJo1axa+/PJL9OjRA/7+/li4cCFsbW2xZMkSo+kbNWqE9u3bo2LFivDz88NXX32FKlWq4NChQwVc8ndApXbq5yv/AMo0lHF3wKe1SgIAJmy5DKWqEHTLjrsH/D1A/br2QKBsM8M09Yepu6/f2A3cO12w5SMiIiIqlfU4UgAgt5Bhec+aGBFaHoOalMGX9Uvhs/d80Cm4BNpWLYb3/T1Qv2xRAOreTOtP31VvGHsFODJX/brFdMDKLtfF++vkHbxITkNpNzs0qeCeq22dba1w1qsT9iurQqJMBtZ/AaSZYLZAIiJ661mYc+cKhQKnT5/GqFGjtMukUilCQkJw9KjxLs26hBDYu3cvIiIiMG3aNKNpUlJSkJLy6qQYHx+f94K/K3wbADau6tv2bh8CSjfCVyHlsOHsPVyNeYFJWy9jVIuKsLIwU7umSgls6A0kPQO8AoGmY42ncy0NVOkMnP8TODAD+Hh1gRaTiIiI3nGlGqifH5wHEp8Ctq5Gk1XwdEQFT8css5q1+xrmhl/Hdxsvopy7PQJ2DwNUaUD5VkCFlrkuWppShSWHIwEAveqVglSaycx6Wahf1g0j7vbBPqtRsH94EQifAIROznU+RET0bjFrD6nHjx9DqVTCw8NDb7mHhwdiYmIy3S4uLg729vawsrJCq1atMG/ePDRrZqRnDICwsDA4OTlpH97e3iY9hreazAKomH7b3qVNAABXOyt827wCAGDp4Sh0WHAEt8w1yPm/P6obyqzsgY5LAAurzNPW/xqQSIFr29XBIBEREVFBcfQCipYHIICovPXqH9K0LJpWcEdKmgp/L58BRB8BLG2BFsYvzmZn56WHuPssCS62luhQvcRr5VG/bFE8gjN+EP3UC47+BBz/BVCpXis/IiJ6N5i1h9TrcnBwwLlz5/Dy5UuEh4dj2LBhKF26NBo1amSQdtSoURg2bJj2fXx8PBulcqNSe+DM7+rb9lr+CMgs8Ol7Pihqb4Vv11/ExXtxaDX3EMa3rYSPgktAIsn9VbXXcms/cGCq+nWrWeoBQ7NStAxQuSNw8S/1WFJdVuZ7EYmIiIi0SjcEHkeox5Hyb/va2UilEszqHIjPf9qO/i+XARJA2eBbyJxzH98KIbD44C0AwGfv+cDaUvZaZapW0gV2VjJsSqyC0dW7o8jlZcD2b9Tx4wc/AS6+r5UvvUWESJ+FUQBClf5epf8eIsNy8WpbiOyfDdIik/Uwsh6GaYy9N7Yv7fHpHodK56GTTk/G/5uyOwYjabVvdesv4/4z1KdE8mrfmtea/+F0PxvtttB/bayO9JZltjzDZ6ZbLoM60i0f9F8bOz69us5Kxno1Ui5j2+i9NfLdzVjHemWWGD7rfUeMfV56mRivA4N61OSVw7+Lap+9Gt/QjMzaIFW0aFHIZDI8fPhQb/nDhw/h6emZyVbq2/rKlCkDAAgMDMSVK1cQFhZmtEFKLpdDLpebtNzvFO1te4+B24e1X9rmlb1Q1dsZw9acx9FbT/DN+gvYfy0WYe2rwMnWMv/Kk/Qc2DsJOPWb+o+uShegauecbdtgOHBxLXB1CxDzH+BZOf/KSURERKSrVEP1JCz/rQdepN8JIJHqPCTqZ3sPoFYfwLlkplk52Vjid++tcLr6EldV3lj3rAl+eI0inb79DOfuPIeVhRSf1fZ9rcMCACsLKWr7FcGeK7FY6z4QfX0qAXvGAlEHgZ/rAO9PAIJ6vpoFmXIvTQGkJgAKzeOl+jktRT2DY1oKoEwFlJr3CvVrVZp6mAtlavrr9Pea15ptNPnobqvJUyjV2wilutebKk1/WWb/VGf6DzYRmZ1PHTZIWVlZISgoCOHh4WjXrh0AQKVSITw8HAMHDsxxPiqVSm+cKDIhzW17Z35Xz7an86X1crLBH1/UwqJ/b2HmrghsuxiDs9HP8b/OgXivdBHTlkMI4PxqYPdoIOGRelnljkCrmTnPw628usfXpQ3q2Wg6LTdtGYmIiIgy41tPfWtd0jP1xbGsnFgEBPcE6g8H7N0M198+Cqer6jExv0/tidNH7qCStyvaV8vdLXe/HlSPHdU+sDjcHPJ2AbdemaLYcyUWB288Qd8vegNlQ4C/B6ovaG79Grj8N9D2J/UMyNlJSwGkloW/AUsIdaNQ0lP155qY/qx5n5YCSC0AqUz9LEl/1iwTKiAlHkiON3xOjgNSXrxqeFKlmvtoCxFJFr18slmntyxjfjrvtS8l+suy2pdU9mqZpoEZklcNzlkRIuueSwZlzFBOzVtNA7d2vzoN3pqeOZr9qV/ov9bdBjrHoZdHJnWjtyyzMkoy5K05ztyUUZbh2DKUL6uqFpoi5eDzNDge3eUZLiRol+n2gMrQK0n3ve62mR2HtsDQ2V7nIAy+Y9Cv2yz/FgCUqJlFRRUcs9+yN2zYMHTr1g3BwcGoWbMmZs+ejYSEBPTo0QMA8Pnnn6N48eIICwsDoB4TKjg4GH5+fkhJScG2bduwYsUKLFiwwJyH8Xbzb6d/2570VXdumVSCfo38UMevCL5afRZRTxLRdfEx9G/khyEh5WApM0Eg8fCSOpCJTh/ovmg5oOUMoHSj3OfVYARwaQPE5b9x8cxR+PoHw9E6H3t0EREREQGAjTPQYzvw4FyG3iQ6t/iolMC1HeqeRccXAmdWAO/1A+oMUm8PqHusbBmqfl39c9SWt8LpfTcwcv1FlHV3QOXiTjkqzu0nCdh5Wd1T64v6pfJ8ePXLqRvOTkY+Q5JCCRvX0kC3LerGtT3jgMh/gQV1gGYT1I1tmn+KUl4CMReA++fU43w+OAc8vqbuoe/XGPBrCvg1ARw8Mtv1K8nx6hmV754Cnt7S6b2TXrcZe+1oegppev7o9QRKe9UbKGPPIpHe4yjlRcE3FMms1DMpWtmrGzgtrdXLZHJAZglYyNPfax6WOo1gFuqLzdIMD91tNK8t5Ol5Wug0pslePeu+lsiy/ufaoIEjYyOA7j/2Gf/RlmTYjojeJmZvkOrcuTMePXqEMWPGICYmBoGBgdixY4d2oPPo6GhIda6OJCQkoH///rh79y5sbGxQoUIF/PHHH+jcOYe3bVHulWoA2LioeybdPvxqphgdVb2dsXVwfYz/5xL+OnUX8/fdxM5LD/FNaHk08/d4vbGlkuOB/VPVAZlQqk+6Db8B3huQ9QDmWfHwR1r5NrCI+AeRGydg8skxWNOn9uvlRURERJQbxQLVj6zUHgDc2qeeqe7+WeDgj8DJX4F6Q4CafdQNPI+uALZFgJDxGGrtgkv347Av4hH6rDiNfwbVg6td9nHSkkOREAJoVN4NZT0c8nxopYvaobizDe49T8LxyCdoVN5d3cPpvb5A2WbA3wPUFxe3DgMubQQcvNIbn67DYIwWQD1cxMW16gcAeAQAZZqoG6hKvqduNHlyA7hzArh7ArhzEoi9bDyv/CazUjeg2bioZ1C0cVE/LKx1GreU+rfKqdLUDSxyJ8DaEZA7Gj7LHQG5fXoDlB1gaff6MTARUSEkESLbkb/eKvHx8XByckJcXBwcHbOeVpd0/D0QOLsCCO4FtJ6VZdKtFx7gh00X8SxRfcUo2McFI1tUQLCv8SmOjbq6FdgyDHiZPsZCxbZA6BTgNQbs1HX7SQLClv6FhS+HQCUkaKaYjpn9OyHQ2zlP+RIR0duF8YIh1kkBE0J9a9/eScCjq+pl9h7qC3ZpSUC7BUDgxwCAuKRUfPDTIUQ9SUQdvyL4vWdNWGTRS/15ogK1w/YiKVWJlV/UQt0yRU1S5JHrL2D1yTv4ol4p/NDaX3+lSqW+yBg+QV1+XQ7F1A11XlUBr0DAMwB4FgXcDAduhKsbrnRpGmaSnhkWwrmk+lYUD391Q5FEqnOLjyS9R4/01XLN7XMSqWGvH93eRLppNc9yB3XDk6Ute+8QESH3sQIbpChnbuwB/ugA2LkBX0fo3bZnTHxyKhbuv4klhyORnKoeyLCZvwe+CS2f/VW4S5uAdT3UXaldSwMtZqjHIcijQ9cfY8CfZxCXlIrlNv9DQ3ES51Wlsd3vB4zs1iHP+RMR0duD8YIh1omZqJTAhb+A/VOA59HqZT71gO5b9BpBrj18gXbzDyNRoUT1ks7o09APIRU9IJMaNpTM33cDM3ZGoKKXI7YNrmeyWZK3XLiPgX+eRXkPB+wcatijHgDw5CZwaglg7axugCoWCNi7Z51xwmPg5j51PHpzL5AQq14ukwPFqgHeNdWPEjUAh8wnRiIiovzFBqlsMJh6TcpU4Mey6itR3f4xetueMTFxyZgTfg1rTt6BSgBSCfBRkDeGNisHTydrww1u7gVWdlLfjx/4qXrQcksj6XJBCIGlh6MwedsVKFUCgd7O+K25DZxXtYIsLRFpQoqU4D6we/979ZUuIiJ65zFeMMQ6MbO0FPWYnrePACFjARdfgyQ7L8Vg0J9noVCqLwb6FrFFr3ql0DHIGzZW6ouJijQV6k3bi9gXKZjVqSo+rJ67gdCz8ixBgeqTdkMI4Ph3TeHhmLcYziiVSn1rnlIBeFTmLWxERIVIbmOFQj51BRUaMkugQiv160ubcryZp5M1wj6sgl1DG+B9fw+oBLDm1B00nLEP8/fdgF576J2TwOpP1Y1R/u2AtnPz3BiVkqbEiHUXMGHLZShVAh2ql8Dq3u+hiF91yAYexwl5HVhIVLA7vQD4qaZ6TIN3q42WiIiI3gQWcqDml8BHS402RgFAaCVPHPy2Mfo38oOTjSWiniRi9N+XUHtqOH7cGYHYF8nYfP4+Yl+kwMNRjtZVipm0iC52VqiSPqj67ssPTZq3llQKeFYGildnYxQR0RuODVKUc/7t1c9X/lF3H8+FMu4OWPR5MNb3q41gHxekpKkwY2cEpmy7om6UengZWNkRSE1Qz6Ty4aJsbwvMTmx8MrosOoZ1p+9CKgFGt/bHjx9VgbVler7OJfG0zRJ0V4zAHXgAL+4Da7sDf3yo7k5ORERE9IbxcLTGN80r4MjIJhjfthJKutrieWIqftp3A/Wm7sPkrZcBAN3q+MLKwvT/CrSq4gUAmLf3OhJS0kyePxERvT14yx7lnDIVmFEGSH6unsa3VP3XykYIgd+P3sbYzZcAAEODLTE4ahAkL2PUg1B+vkk9k0genL79FP1XnsHD+BQ42Vjip4+roX5ZN4N0SpVAwxn78OhZHNYHHEflW0sAZYp6EMy6XwH1hgFWtnkqC+VRxqmxhQra6bH11mWc1llpZIpn3e0zvNZ91uwXQmeyHs16GKbRvs64zth76C/XPU5j6zLmk11dZZ0gB6szO7acniryOg6Jkc9D71l3V5JX+9OOfyIxzAfI5LMyRTk1b3NTRt1ssjnGnJRDL69cbpfVd1hLt/wZjiVXn1XGvDLsMyefUcblljZA9c+Mp80jxguGWCdvJqVKYPflGCw+GInTt9WDgNtayXB0ZFM42VqafH/JqUq8/79/Ef00EQMa+2FEaAWT74OIiAonjiGVDQZTefT3AODsH0CNL9TjO+XBqhPRmLXhX6yzGg8faSyEuz8k3beqp8t9TWlKFebtvYF5e69DJYAy7vb49fNg+BbNvIFr8b+3MHnbFZT3cMCOz4tDsv0b9aCZgLphyr0i4FlF/fCqoh6vQG7/2mU0GWUqkPICSE1Sj6OgTE1/TtF5rQCUaa8aaPQabcSrqYjTUtQPZfpzWvKrZ6UCgERn9hmdmWkkUnXXeWWazraafBQ6zwr1rZjKtPTnVPV+lanq96o0dXmMNSaZY/pmInoz2HsAw6/lS9aMFwyxTt58Z6KfYcOZu6jrVxQtArzybT87L8Wgz4rTsLKQYs/QhihZhBf3iIjeBbmNFSwKoEz0NvFvr26QurwZaDE9T7fVdQ1wQIuDs+H8Iha3Ve5YVXQKvrF2ee37SKOfJGLImrM4E/0cAPBhteIY/0ElOFhnffWvUw1v/G/PNUQ8fIGjz5xQ55N16tsSd34PxEUDD86rH1oSoIifekpipxLqBpjUJHXjje5zapK6QcXGWT0lsI1r+rOLutHNxgWQO6rTK14CKS/Tn18Yvk+JVz8npz+nvDCcMpnS6U7pLNN5nd67Q5LeuKZ5rbcMhsu1PToAg94dWb7PoleJbln13uZ2vZE02TFIbmwf2RxHpkzVeJjxM8iwTHdfxnqiZbZNdr2VMmO0d5tO2UxVRoNjzqZMBr3CkLvjyrJejB2DsePJZfkNegJmSJ/b75y1U9briUhP9ZIuqF7SJd/3876/B+qVKYpDNx5j0tbLWPR5cL7vk4iI3jxskKLcKd1QPU1vQiwQsR2o2Pr18lEkACs7wfnFdSTJ3fBZ/ChEn0nEc9lFTGkfAKmRKYozI4TAxrP3MObvS3iZkgYHuQUmta+MDwKL52h7JxtLdAwqgd+P3saSw5GoU6Yo4N8WqNgGeBYFxFwEYi4ADy6oX7+4Dzy5oX4UBjKr9IelkdeWgNRCpzeTbg8nzXuZeqBUC+v0h+a1lfpZlt6gJ1TqmW10e1tpejFJLdTbyawyPMvV+cisAKklILNIf7Z89awtozRDGTOWWbchSee9ZplewxMRERGZi0Qiwdg2/mg+5yB2XX6IQ9cfo17ZouYuFhERFTJskKLckVmqG2rOrgDWfAJ4v6e+fc+/rboBIjupScDNvcCRn4C7JwBrZ9j02Ixh950w7K9zWH3yDtJUAtM6VIEsB41ScUmpGL3pP2w+fx8AUMPXBbM6BcLbNXddw7vX8cXvR28j/Gosoh4nqG/xk0gA11Lqh3/bV4lfPlI3UMVcABIeqxttLK0BCxv1eCaWNunLbNQNJEnPgaRnQNLT9OdnQGL66+Q4dTore/VtgNpnB/U4WnJ7dS8quSMgdwCs05/lOs8y/hkTERFR4VLWwwGfveeDZUeiMP6fS9j2VX1YyjifEhERvcL/ZCn3mk1Q30p25R/gzjH1Y6cbUP1zIKgH4Oytnz7pOXB9F3BlM3AjHEhNVC+3tAU+WQt4+KOdByCTSjBkzTmsO30XKpXAjI+qZtkodTLqKYasPod7z5Mgk0rwVdOy6N/IDxavEeyUdrNHkwru2Hs1FsuORGFc20qZJ7Z3A8o0VT+IiIiIyKihIeXw97l7uB77En8cu40edUuZu0hERFSIcFBzen0vYoDTy4HTS4EXD9TLJFKgfEt141TcXeDqFiDyX/Wg1RpO3kCFVkD1boCHv16W2y4+wOBVZ5GmEgj2cYG7oxyKNBUUSgFFmhKKNBVSlQKKNBWux76ASgDerjaY06VansdEOHj9ET777QTsrGQ4+l1TOGYz9hQREb29GC8YYp3Q6/jj2G38sOk/OFpbYP+IxnC1szJ3kYiIKJ9wlr1sMJjKB8pUIGIbcGIxEHXQeBq3CkCF1uoxp7wCsxznZ8d/MRj45xmkqbL/an5YvTjGt81+4PKcEELg/f/9i+uxLzG6tT961eNVPCKidxXjBUOsE3odSpVA63mHcOVBPD6pVRKT2weYu0hERJRP2CCVDQZT+Sz2KnDqN/UsfE4l1A1QFdoARcvkKptL9+Nw9OYTWFlIYSWTwlImVb9Of29lIUVReznKezqYtPh/Ho/GdxsvwtvVBvuHN87ROFZERPT2YbxgiHVCr+v4rSfovOgYpBJgy6D68C/G7w8R0duIDVLZYDBFWUlSKFF7ajieJ6Zi0WdBeL+Sp7mLREREZsB4wRDrhPJiwJ9nsPXCA9Qs5Yo1vd+DhLPiEhG9dXIbK3CqCyIdNlYyfFyzJABgyeFIM5eGiIiI6O3wXcuKsLaU4kTkU2y9+MDcxSEiokKADVJEGXxW2wcyqQTHbj3Fpftx5i4OERER0RuvuLMN+jb0AwBM2XoFSQqlmUtERETmxgYpogy8nGzQMsALAPDbQfaSIiIiIjKFPg38UNzZBvfjktF7xSmcu/Pc3EUiIiIzYoMUkRE96/oCADacvYdRGy4gOZVX8YiIiIjywsZKhvFtK0EqAQ5ef4x28w+j66Jj+PfaI7xjw9oSERHYIEVkVLWSLvimeXlIJMCqE3fQceER3HmaaO5iEREREb3RQvw9sHNIA3SoXgIWUgmO3nqCz5ecQJufDmHrhQdQqtgwRUT0ruAse0RZOHj9EQavOotnialwsrHE7M6BaFzB3dzFIiKifMZ4wRDrhEzt3vMk/HrwFlafuIOk9N7ovkVs0aehH9oFFoeNlczMJSQiotzIbazABimibNx7noT+K8/gfPo4B4OblMFXIeUgk3K6YiKitxXjBUOsE8ovTxMUWH4kCsuPRuF5YioAQCaVoKy7PQKKO6FKCScElHBGBU8HWFuykYqIqLBig1Q2GEzR60hJU2LSlitYcew2AKB+2aKY06UaXO2szFwyIiLKD4wXDLFOKL8lpKRh9ck7WHIoEveeJxmst5BKUM7DAVVKOCHIxwVNKrijiL3cDCUlIiJj2CCVDQZTlBcbz97FqA0XkZyqQjEna8zpWg3BPi6QSNhbiojobcJ4wRDrhAqKEAIx8cm4eDcOF+/F4UL689MEhV46iQQI9nFBM38PNPP3RKmidmYqMRERAWyQyhaDKcqrqzHx6PfHGUQ+TgAAFLW3QrCPK4J9XVDD1xX+xRxhKeN8AUREbzLGC4ZYJ2ROQgjcj0vGxbvPcf5uHP699giX7sfrpSnjbp/eOOWBwBLOkHJ4BSKiAsUGqWwwmCJTeJGcijF/X8LWCw+gUKr01tlYyhDo7Ywavi4ILOmMYs42cHewhoutJXtSERG9IRgvGGKdUGFz73kS9lx+iF2XY3D81lOk6czQV8TOCjV81RcMg31dUYkXDImI8h0bpLLBYIpMKTlVif/uxeFk1DOcvv0UJ6OeIS4p1WhaK5kUbg5yuDvK4e4gh4ejNTwcrVHS1RalitrBt6gd7OUWBXwERERkDOMFQ6wTKsziklKxPyIWuy4/xIGIR3iZkqa33tpSmn7B0BXBvq6oVtIZjtaWZiotEdHbiQ1S2WAwRflJpRK4+eglTkY9w6mop7j8IB6xL1IMxjzIjJuDHKWK2qFUEXUDVamidijhYgMvJ2u42lmxhxURUQFhvGCIdUJvipQ0JS7cjcPJqKc4HfUMp24bv2BY1F6Okq428Ha1hbeLLbxdbdKfbeHlZA0L9qgiIsoVNkhlg8EUmUNKmhKPXqQg9kUKYuOTEfsiBQ/jk/EgLhm3nyQi6nECnmTTaGVlIYWnozU8nazh5WQNLyd1Q5WLnRXs5TLYWVnATm4Be/mrZ2tLKRuxiIheA+MFQ6wTelPpXTC8/RSnbz/D7SeJWW4jk0rgaG0BRxtLOFhbwNHaEo7W6a/Tl9lZqWMta0sZrC1lsEl/1iyztZLBXm4Be2sL2FjKGJMR0Vsvt7EC7w8iKgByCxlKuNiihIttpmniklIR9TgBUU8ScOuR+jnqcQLuxyXj0YsUKNJUiH6aiOinWQdQumRSCWwtZZDrBEfWllLILdLfW6gDJysLKaxkUvWz5pH+Xq55WMrSX+vnIbeQQZ6et9wifR8WUl5VJCIiokJBKpWgrIcDyno44ONaJQEAcYmpiH6aiDvPEnFH+5yEO08TcfdZEhRKFZ4lpuJZovGhGHJdBglgZ6VunLJLv3jooHMh0cHaAnZyGezllrCXy2BvbQFbKwtYyaSQSSWwkElgIZWmPxu+lqW/lkl1n6WQSgGpRJL+ABvFiKhQYYMUUSHhZGOJqt7OqOrtbLBOkabCw/hkxKT3qoqJS8L958mIiUvG8yQFElKUSEhJw8uUNCSkpCFBoQQAKFUCL1LS8CLDOAoFQSaVwDq9IctSJnkVDOkERhIJINN9LdUPmKTpyzSvdbfTX2Ys/av1Ep106jIY5idND9A0YZpEJ2jThm4SzZNEmybjNpr1euuM5J2jfHSCRonEePpM89LZp356iU5+rzLP9hgylAGSDPlp1hvZXlMeY/kYOxZk2LfBtkbKobuPjGXQ/fx092usPjKWIWPeuuXXP74MeRvZ16vjNX58meabsY4z5pvJZ5YxX20dZPbZGXyHjNej4eehU2AqUPPnz8eMGTMQExODqlWrYt68eahZs6bRtIsXL8bvv/+O//77DwAQFBSEKVOmZJqe6G3nZGuJAFsnBJRwMlinUgk8fpmC50mpeJGcivikNMQnpyI+OQ3xSanq10lpSFKkITlVheQ0JZIUSiSnqZCSqkRSqvp9kkKJl4o0CAGoBMwWk+nSjYm0sZM2RjOMvSykUljKJLCykMJSpn/R0kqmXpbX00BOtpfonPAznsM0eeiep7TrMj1HGp63keH8qnteNsg7q3wz7F83D039a8/Teu/195HtfrKJ/XT3IUlPaFgG3Xjh1fk9M1Lpq7JIDcqf+/jNWAxkUDcSdYNuxtgs0zJKdP9fyBjvaz+ZLOMh3VgoszJmFlfq1atO/eiWKbua1v37fNvjLDZIEb0BrCyk6vENXDPvYaVLpRJISlVqG6eSUzUPddCUonmdqkRKmgqKNBUUStWr12kqKJRK7euU9Icmve5zcqoKKWmv8tFQqgQSFEpt4xgRvf2ybOzSC+iNN6BpXmteZBXgSiTq8V92DGlQAEdW+KxZswbDhg3DwoULUatWLcyePRuhoaGIiIiAu7u7Qfr9+/eja9euqFOnDqytrTFt2jS8//77uHTpEooXL26GIyAqvKRSCdwdreHuaJ3nvIRQx2Qvk9UXDrWP5DQkKNLwMkW9LsHoujSkKQXSVAJpShWUKoFUlQpKpUCqzjKlKj1N+uusywMohYA6OnunRm4hemNlbEjOronKWEOYVKr7XoJRLSqgQ1CJAih91jiGFBGZjEol0huvXjV4JacpkaYU6VcHhc5DnV6lt1z9WggBlUodMAkhoFQBAur1QpNWpUmrSaezrTZPpG8vIJC+TJX5es2voYDQxmiaH0iRvg/9ZelpdbaFTvqMaTV5G8sHGfLJmLexfIyW0SCdYVmQMe9MyiZ0NtAvgzBIo7sfY8dr8D6zsmRyLK/SZ1yufxwGZcz02ESGMhgeV8ay65Yrs+PRfJaZ1b8QGT6PLI9ZJ28j9WTs837XuDnIcfL7kHzJu7DHC7Vq1UKNGjXw008/AQBUKhW8vb0xaNAgjBw5MtvtlUolXFxc8NNPP+Hzzz/P0T4Le50Q0au4RtNApRICQqUfa+nGSkrVq1gqY5ykaexKVb66eKlIUyFVKV5duFTm8QSUgxOY3nk3m1hHs9zwnKlJKwzP6xliH4O4xEh8oLded7nuOdpIvpo4QOBVHGuQXuiXM2P5jcUOmcZ9OuVVqfRjC6Gzf5XQrxdjdLdRGXlWZRIfag7KaIyTMQbTWafSOTbNd1YnetOmN/Zev1zqkmi+19DJ01gsaPB56dTj2xSDTWkfoL2F2ZTeyDGk2OWc6O0glUpgYyWDjZXM3EUhemfpBpja98gqGDfe2KVOm76dkW2NBWQZG0oNAjqd8mm20c03szLDSMOfgICF9O3uxp4ZhUKB06dPY9SoUdplUqkUISEhOHr0aI7ySExMRGpqKlxdXfOrmERkBhJJ+nhTDMWICpQmdtI0+uo1Ogr9RuHsM3vVIKdt7BPqvJU5aAFTqTRl0W+Y0y2Xh0Pee4CagtkbpNjlnIiIyHR0b3FLX2KuolA+efz4MZRKJTw8PPSWe3h44OrVqznK49tvv0WxYsUQEpJ5D7OUlBSkpKRo38fHx79egYmIiN5ymqEHZLqDl1G2zD4N1qxZs/Dll1+iR48e8Pf3x8KFC2Fra4slS5YYTb9y5Ur0798fgYGBqFChAn799VeoVCqEh4cXcMmJiIiI3jxTp07F6tWrsXHjRlhbZ36FNCwsDE5OTtqHt7d3AZaSiIiI3nZmbZDSdDnXvTpn6i7nKSkpiI+P13sQERERvamKFi0KmUyGhw8f6i1/+PAhPD09s9z2xx9/xNSpU7Fr1y5UqVIly7SjRo1CXFyc9nHnzp08l52IiIhIw6wNUll1OY+JiclRHtl1OefVPSIiInqbWFlZISgoSK93uKa3eO3atTPdbvr06Zg4cSJ27NiB4ODgbPcjl8vh6Oio9yAiIiIyFbPfspcXOelyzqt7RERE9LYZNmwYFi9ejOXLl+PKlSvo168fEhIS0KNHDwDA559/rjfo+bRp0zB69GgsWbIEvr6+iImJQUxMDF6+fGmuQyAiIqJ3nFkHNTdFl/M9e/Zk2eVcLpdDLpebpLxEREREhUHnzp3x6NEjjBkzBjExMQgMDMSOHTu0vc6jo6Mhlb667rhgwQIoFAp07NhRL5+xY8di3LhxBVl0IiIiIgBmbpDS7XLerl07AK+6nA8cODDT7aZPn47Jkydj586dOepyTkRERPS2GThwYKbx0v79+/XeR0VF5X+BiIiIiHLBrA1SgLrLebdu3RAcHIyaNWti9uzZBl3OixcvjrCwMADqLudjxozBn3/+qe1yDgD29vawt7c323EQEREREREREVHOmL1Bil3OiYiIiIiIiIjeLRIhhDB3IQpSfHw8nJycEBcXx9liiIiIyCjGC4ZYJ0RERJSV3MYKb/Qse0RERERERERE9OYx+y17BU3TISw+Pt7MJSEiIqLCShMnvGMdybPEGIqIiIiyktv46Z1rkHrx4gUAwNvb28wlISIiosLuxYsXcHJyMncxCgXGUERERJQTOY2f3rkxpFQqFe7fvw8HBwdIJBKT5x8fHw9vb2/cuXOH4yvkAevRNFiPpsF6NA3Wo2mwHk0ju3oUQuDFixcoVqyY3uQq7zLGUG8G1qNpsB5Ng/VoGqxH02A9mkZW9Zjb+Omd6yEllUpRokSJfN+Po6Mjv+QmwHo0DdajabAeTYP1aBqsR9PIqh7ZM0ofY6g3C+vRNFiPpsF6NA3Wo2mwHk0js3rMTfzES35ERERERERERFSg2CBFREREREREREQFig1SJiaXyzF27FjI5XJzF+WNxno0DdajabAeTYP1aBqsR9NgPRY+/ExMg/VoGqxH02A9mgbr0TRYj6Zhynp85wY1JyIiIiIiIiIi82IPKSIiIiIiIiIiKlBskCIiIiIiIiIiogLFBikiIiIiIiIiIipQbJAiIiIiIiIiIqICxQYpE5s/fz58fX1hbW2NWrVq4cSJE+YuUqH277//ok2bNihWrBgkEgk2bdqkt14IgTFjxsDLyws2NjYICQnB9evXzVPYQiosLAw1atSAg4MD3N3d0a5dO0REROilSU5OxoABA1CkSBHY29ujQ4cOePjwoZlKXDgtWLAAVapUgaOjIxwdHVG7dm1s375du551+HqmTp0KiUSCIUOGaJexLnNm3LhxkEgkeo8KFSpo17Mec+bevXv49NNPUaRIEdjY2CAgIACnTp3Srud5pnBg/JQ7jJ9MgzGUaTCGyh+MoV4P4yfTKYgYig1SJrRmzRoMGzYMY8eOxZkzZ1C1alWEhoYiNjbW3EUrtBISElC1alXMnz/f6Prp06dj7ty5WLhwIY4fPw47OzuEhoYiOTm5gEtaeB04cAADBgzAsWPHsHv3bqSmpuL9999HQkKCNs3QoUPxzz//YO3atThw4ADu37+PDz/80IylLnxKlCiBqVOn4vTp0zh16hSaNGmCDz74AJcuXQLAOnwdJ0+exC+//IIqVaroLWdd5lylSpXw4MED7ePQoUPadazH7D179gx169aFpaUltm/fjsuXL2PmzJlwcXHRpuF5xvwYP+Ue4yfTYAxlGoyhTI8xVN4wfsq7AouhBJlMzZo1xYABA7TvlUqlKFasmAgLCzNjqd4cAMTGjRu171UqlfD09BQzZszQLnv+/LmQy+Vi1apVZijhmyE2NlYAEAcOHBBCqOvM0tJSrF27VpvmypUrAoA4evSouYr5RnBxcRG//vor6/A1vHjxQpQtW1bs3r1bNGzYUHz11VdCCH4fc2Ps2LGiatWqRtexHnPm22+/FfXq1ct0Pc8zhQPjp7xh/GQ6jKFMhzHU62MMlTeMn0yjoGIo9pAyEYVCgdOnTyMkJES7TCqVIiQkBEePHjVjyd5ckZGRiImJ0atTJycn1KpVi3Wahbi4OACAq6srAOD06dNITU3Vq8cKFSqgZMmSrMdMKJVKrF69GgkJCahduzbr8DUMGDAArVq10qszgN/H3Lp+/TqKFSuG0qVL45NPPkF0dDQA1mNObd68GcHBwfjoo4/g7u6OatWqYfHixdr1PM+YH+Mn0+P3+vUxhso7xlB5xxgq7xg/5V1BxVBskDKRx48fQ6lUwsPDQ2+5h4cHYmJizFSqN5um3linOadSqTBkyBDUrVsXlStXBqCuRysrKzg7O+ulZT0aunjxIuzt7SGXy9G3b19s3LgR/v7+rMNcWr16Nc6cOYOwsDCDdazLnKtVqxaWLVuGHTt2YMGCBYiMjET9+vXx4sUL1mMO3bp1CwsWLEDZsmWxc+dO9OvXD4MHD8by5csB8DxTGDB+Mj1+r18PY6i8YQxlGoyh8o7xk2kUVAxlYboiE5G5DRgwAP/995/efdKUc+XLl8e5c+cQFxeHdevWoVu3bjhw4IC5i/VGuXPnDr766ivs3r0b1tbW5i7OG61Fixba11WqVEGtWrXg4+ODv/76CzY2NmYs2ZtDpVIhODgYU6ZMAQBUq1YN//33HxYuXIhu3bqZuXREVJgwhsobxlB5xxjKNBg/mUZBxVDsIWUiRYsWhUwmMxih/+HDh/D09DRTqd5smnpjnebMwIEDsWXLFuzbtw8lSpTQLvf09IRCocDz58/10rMeDVlZWaFMmTIICgpCWFgYqlatijlz5rAOc+H06dOIjY1F9erVYWFhAQsLCxw4cABz586FhYUFPDw8WJevydnZGeXKlcONGzf4ncwhLy8v+Pv76y2rWLGitus+zzPmx/jJ9Pi9zj3GUHnHGCrvGEPlD8ZPr6egYig2SJmIlZUVgoKCEB4erl2mUqkQHh6O2rVrm7Fkb65SpUrB09NTr07j4+Nx/Phx1qkOIQQGDhyIjRs3Yu/evShVqpTe+qCgIFhaWurVY0REBKKjo1mP2VCpVEhJSWEd5kLTpk1x8eJFnDt3TvsIDg7GJ598on3Nunw9L1++xM2bN+Hl5cXvZA7VrVvXYAr3a9euwcfHBwDPM4UB4yfT4/c65xhD5R/GULnHGCp/MH56PQUWQ+Vh4HXKYPXq1UIul4tly5aJy5cvi969ewtnZ2cRExNj7qIVWi9evBBnz54VZ8+eFQDErFmzxNmzZ8Xt27eFEEJMnTpVODs7i7///ltcuHBBfPDBB6JUqVIiKSnJzCUvPPr16yecnJzE/v37xYMHD7SPxMREbZq+ffuKkiVLir1794pTp06J2rVri9q1a5ux1IXPyJEjxYEDB0RkZKS4cOGCGDlypJBIJGLXrl1CCNZhXujOECME6zKnvv76a7F//34RGRkpDh8+LEJCQkTRokVFbGysEIL1mBMnTpwQFhYWYvLkyeL69eti5cqVwtbWVvzxxx/aNDzPmB/jp9xj/GQajKFMgzFU/mEMlXuMn0yjoGIoNkiZ2Lx580TJkiWFlZWVqFmzpjh27Ji5i1So7du3TwAweHTr1k0IoZ5OcvTo0cLDw0PI5XLRtGlTERERYd5CFzLG6g+AWLp0qTZNUlKS6N+/v3BxcRG2traiffv24sGDB+YrdCHUs2dP4ePjI6ysrISbm5to2rSpNpASgnWYFxmDKdZlznTu3Fl4eXkJKysrUbx4cdG5c2dx48YN7XrWY878888/onLlykIul4sKFSqIRYsW6a3neaZwYPyUO4yfTIMxlGkwhso/jKFyj/GT6RREDCURQohc9d0iIiIiIiIiIiLKA44hRUREREREREREBYoNUkREREREREREVKDYIEVERERERERERAWKDVJERERERERERFSg2CBFREREREREREQFig1SRERERERERERUoNggRUREREREREREBYoNUkT0Rvrqq6/Qu3dvqFQqcxeFiIiI6I3A+ImIChM2SBHRG+fOnTsoX748fvnlF0il/BkjIiIiyg7jJyIqbCRCCGHuQhARERERERER0buDTeNE9Mbo3r07JBKJwaN58+bmLhoRERFRocT4iYgKKwtzF4CIKDeaN2+OpUuX6i2Ty+VmKg0RERFR4cf4iYgKI/aQIqI3ilwuh6enp97DxcUFACCRSLBgwQK0aNECNjY2KF26NNatW6e3/cWLF9GkSRPY2NigSJEi6N27N16+fKmXZsmSJahUqRLkcjm8vLwwcOBA7bpZs2YhICAAdnZ28Pb2Rv/+/fW2v337Ntq0aQMXFxfY2dmhUqVK2LZtWz7WCBEREVHWGD8RUWHEBikiequMHj0aHTp0wPnz5/HJJ5+gS5cuuHLlCgAgISEBoaGhcHFxwcmTJ7F27Vrs2bNHL2BasGABBgwYgN69e+PixYvYvHkzypQpo10vlUoxd+5cXLp0CcuXL8fevXvxzTffaNcPGDAAKSkp+Pfff3Hx4kVMmzYN9vb2BVcBRERERLnE+ImIzEIQEb0hunXrJmQymbCzs9N7TJ48WQghBADRt29fvW1q1aol+vXrJ4QQYtGiRcLFxUW8fPlSu37r1q1CKpWKmJgYIYQQxYoVE99//32Oy7R27VpRpEgR7fuAgAAxbty41z5GIiIiIlNi/EREhRXHkCKiN0rjxo2xYMECvWWurq7a17Vr19ZbV7t2bZw7dw4AcOXKFVStWhV2dnba9XXr1oVKpUJERAQkEgnu37+Ppk2bZrr/PXv2ICwsDFevXkV8fDzS0tKQnJyMxMRE2NraYvDgwejXrx927dqFkJAQdOjQAVWqVDHBkRMRERG9HsZPRFQY8ZY9Inqj2NnZoUyZMnoP3YAqL2xsbLJcHxUVhdatW6NKlSpYv349Tp8+jfnz5wMAFAoFAOCLL77ArVu38Nlnn+HixYsIDg7GvHnzTFI+IiIiotfB+ImICiM2SBHRW+XYsWMG7ytWrAgAqFixIs6fP4+EhATt+sOHD0MqlaJ8+fJwcHCAr68vwsPDjeZ9+vRpqFQqzJw5E++99x7KlSuH+/fvG6Tz9vZG3759sWHDBnz99ddYvHixCY+QiIiIyLQYPxGROfCWPSJ6o6SkpCAmJkZvmYWFBYoWLQoAWLt2LYKDg1GvXj2sXLkSJ06cwG+//QYA+OSTTzB27Fh069YN48aNw6NHjzBo0CB89tln8PDwAACMGzcOffv2hbu7O1q0aIEXL17g8OHDGDRoEMqUKYPU1FTMmzcPbdq0weHDh7Fw4UK9sgwZMgQtWrRAuXLl8OzZM+zbt08b0BERERGZA+MnIiqUzD2IFRFRTnXr1k0AMHiUL19eCKEelHP+/PmiWbNmQi6XC19fX7FmzRq9PC5cuCAaN24srK2thaurq/jyyy/Fixcv9NIsXLhQlC9fXlhaWgovLy8xaNAg7bpZs2YJLy8vYWNjI0JDQ8Xvv/8uAIhnz54JIYQYOHCg8PPzE3K5XLi5uYnPPvtMPH78OH8rhoiIiCgTjJ+IqLCSCCGEORrCiIhMTSKRYOPGjWjXrp25i0JERET0RmD8RETmwjGkiIiIiIiIiIioQLFBioiIiIiIiIiIChRv2SMiIiIiIiIiogLFHlJERERERERERFSg2CBFREREREREREQFig1SRERERERERERUoNggRUREREREREREBYoNUkREREREREREVKDYIEVERERERERERAWKDVJERERERERERFSg2CBFREREREREREQFig1SRERERERERERUoNggRUREREREREREBYoNUkREREREREREVKDYIEVERERERERERAWKDVJERERERERERFSg2CBF76zk5GRMnjwZu3btMndRiIiIiIiIiN4pbJCiN1r37t3h6+v7WtsOHToUq1atQq1atXK8zbhx4yCRSF5rf28iX19fdO/eXft+//79kEgk2L9/v0n389dff8HV1RUvX740ab6m0qVLF3Tq1CnP+UgkEowbNy7vBXrLRUVFQSKRYNmyZeYuyltv2bJlkEgkiIqKMndRiOgNoomHHj9+bO6ivLEaNWqERo0ambsYb4SM8SjlD8ZfZA5skCpgmuA/s8exY8fMXcQs7d+/Hx9++CE8PT1hZWUFd3d3tGnTBhs2bDB30XJl7dq12Lx5M7Zt2wYnJye9dYmJiRg3bpzJG11el+535tChQwbrhRDw9vaGRCJB69atzVDCvFEqlRg7diwGDRoEe3t77XJfX19IJBKEhIQY3W7x4sXaejl16pTeukOHDqFFixYoXrw4rK2tUbJkSbRp0wZ//vmnXrqs/hb79u2rTfftt99i/fr1OH/+vAmPvPA6cuQIxo0bh+fPn5u7KAVu27ZtbDQ0scL2m0r0rtDEDxnPkRqNGjVC5cqVC7hUpsNGsYJx//59jBs3DufOnTN3UQrc5cuXMW7cOF60MbGff/6ZjV6kZWHuAryrJkyYgFKlShksL1OmjBlKkzNjx47FhAkTULZsWfTp0wc+Pj548uQJtm3bhg4dOmDlypX4+OOPzV3MbAkhcPfuXWzfvh0lS5Y0WJ+YmIjx48cDgMGVqx9++AEjR44siGIasLa2xp9//ol69erpLT9w4ADu3r0LuVye72Vo0KABkpKSYGVlZbI8//nnH0RERKB3794G66ytrbFv3z7ExMTA09NTb93KlSthbW2N5ORkveVr165F586dERgYiK+++gouLi6IjIzEv//+i8WLFxt8R5s1a4bPP//cYN/lypXTvq5WrRqCg4Mxc+ZM/P7773k53DfCkSNHMH78eHTv3h3Ozs7mLk6B2rZtG+bPn//ONEp99tln6NKlS77+fmT1m0pERIXb/fv3MX78ePj6+iIwMNDcxSlQly9fxvjx49GoUaPXviPjTeLj44OkpCRYWlrm635+/vlnFC1alL3eCAAbpMymRYsWCA4OztU2aWlpUKlURhsDEhISYGdn99rlEUIgOTkZNjY2RtevW7cOEyZMQMeOHfHnn3/q/VCNGDECO3fuRGpq6mvvPz9lrDeJRIKhQ4e+Vl4WFhawsDDPn03Lli2xdu1azJ07V68Mf/75J4KCggrkCqFUKoW1tbVJ81y6dCnq1q2L4sWLG6yrW7cuTp48iTVr1uCrr77SLr979y4OHjyI9u3bY/369XrbjBs3Dv7+/jh27JjB30psbKzBPsqVK4dPP/0023J26tQJY8eOxc8//6zXk8tcVCoVFAqFyT8PyrmsfpPfFDKZDDKZzNzFICIyKjExEba2tuYuxhuBdWVe2f0v9SaQSCSMK6nA8Za9QkpzD++PP/6I2bNnw8/PD3K5XNt1VCKR4PLly/j444/h4uKi7TWTlpaGiRMnatP7+vriu+++Q0pKil7+vr6+aN26NXbu3Ing4GDY2Njgl19+ybQ8o0ePhqurK5YsWWK01Tw0NFR7u1hmY5IYG3/o4MGD+Oijj1CyZEnI5XJ4e3tj6NChSEpKMtjHpk2bULlyZVhbW6Ny5crYuHFjrupNoVBgzJgxCAoKgpOTE+zs7FC/fn3s27dPb3s3NzcAwPjx47W3b2l6S2Q2htQff/yBmjVrwtbWFi4uLmjQoIHBYOk///wzKlWqBLlcjmLFimHAgAG5uiWqa9euePLkCXbv3q1dplAosG7dukx7pqlUKsyePRuVKlWCtbU1PDw80KdPHzx79kwvnRACkyZNQokSJWBra4vGjRvj0qVLBvllNobU2rVrERQUBBsbGxQtWhSffvop7t27l+0xJScnY8eOHZnelmdtbY0PP/zQ4Fa7VatWwcXFBaGhoQbb3Lx5EzVq1DDaSODu7p5tmTLTrFkzJCQk6NV/ZlJSUjB06FC4ubnBwcEBbdu2xd27dw3SZTYGmrHvmUQiwcCBA7Fy5Urt92jHjh0AgB9//BF16tRBkSJFYGNjg6CgIKxbt84gX00emr8luVyOSpUqafPR7HvEiBEAgFKlSmn/BnT/nv/44w/t5+3q6oouXbrgzp072dYLANy7dw89e/aEh4eHdv9LlizJ0bbGPH/+HEOGDIG3tzfkcjnKlCmDadOmQaVSadPo/i4sWrRI+7tQo0YNnDx5Upuue/fumD9/vrauNI+MeWT8bQGAq1evomPHjnB1dYW1tTWCg4OxefNmvbJqfhsPHz6MYcOGwc3NDXZ2dmjfvj0ePXqkl/bvv/9Gq1atUKxYMcjlcvj5+WHixIlQKpV66TS33Fy4cAENGzaEra0typQpo/38Dxw4gFq1asHGxgbly5fHnj17jJYp4+/19u3bUb9+fdjZ2cHBwQGtWrUy+E3o3r077O3tce/ePbRr1w729vZwc3PD8OHDteXM7jcVAPbu3avdl7OzMz744ANcuXIlk0+ciPJLVuPHZDYG4uPHj9GpUyc4OjqiSJEi+Oqrrwx6LgM5O29ofs9Onz6NBg0awNbWFt99912ejysnvzEvXrzAkCFD4OvrC7lcDnd3dzRr1gxnzpzRprl+/To6dOgAT09PWFtbo0SJEujSpQvi4uKyLYPm3GNjY4OaNWvi4MGDBmlyEz9nVVe5PX9cvnwZjRs3hq2tLYoXL47p06fr7btGjRoAgB49emh/w3W/I8ePH0fz5s3h5OQEW1tbNGzYEIcPH862TgB1vDR27FiUKVNG+3/AN998Y/B/S07lNO7V/B906NAh1KxZE9bW1ihdurReL/hly5bho48+AgA0btxYe+yazyGr/6VMGZsAwIULF9C9e3eULl0a1tbW8PT0RM+ePfHkyRO9dJr48dq1a/j000/h5OQENzc3jB49GkII3LlzBx988AEcHR3h6emJmTNn6m2f2W+AKWMcX19fXLp0CQcOHNDWqW7v6Vu3buGjjz6Cq6srbG1t8d5772Hr1q2ZfeT0FmAPKTOJi4sz6NEikUhQpEgRvWVLly5FcnIyevfuDblcDldXV+26jz76CGXLlsWUKVMghAAAfPHFF1i+fDk6duyIr7/+GsePH0dYWBiuXLli0IATERGBrl27ok+fPvjyyy9Rvnx5o2W9fv06rl69ip49e8LBwcEUh6+1du1aJCYmol+/fihSpAhOnDiBefPm4e7du1i7dq023a5du9ChQwf4+/sjLCwMT548QY8ePVCiRAmj+Rqrt/j4eO0tW19++SXi4+Px66+/IjQ0FCdOnEBgYCDc3NywYMEC9OvXD+3bt8eHH34IAKhSpUqmxzB+/HiMGzcOderUwYQJE2BlZYXjx49j7969eP/99wGoTxDjx49HSEgI+vXrh4iICCxYsAAnT57E4cOHc9Q11tfXF7Vr18aqVavQokULAOp/GuPi4tClSxfMnTvXYJs+ffpg2bJl6NGjBwYPHozIyEj89NNPOHv2rN5+x4wZg0mTJqFly5Zo2bIlzpw5g/fffx8KhSLbcmnyr1GjBsLCwvDw4UPMmTMHhw8fxtmzZ7O85ev06dNQKBSoXr16pmk+/vhjvP/++7h58yb8/PwAqHuFdezY0Wi9+fj4IDw8HHfv3s30+6ErOTnZaO8yR0dHvUYtf39/2NjY4PDhw2jfvn2WeX7xxRf4448/8PHHH6NOnTrYu3cvWrVqlW1ZsrN371789ddfGDhwIIoWLaptzJozZw7atm2LTz75BAqFAqtXr8ZHH32ELVu2GOz30KFD2LBhA/r37w8HBwfMnTsXHTp0QHR0NIoUKYIPP/wQ165dw6pVq/C///0PRYsWBQBto8LkyZMxevRodOrUCV988QUePXqEefPmoUGDBtl+3g8fPsR7772nbRhzc3PD9u3b0atXL8THx2PIkCG5qo/ExEQ0bNgQ9+7dQ58+fVCyZEkcOXIEo0aNwoMHDzB79my99H/++SdevHiBPn36QCKRYPr06fjwww9x69YtWFpaok+fPrh//z52796NFStWGN2nsd+WS5cuaXv5jRw5EnZ2dvjrr7/Qrl07rF+/3uD7MmjQILi4uGDs2LGIiorC7NmzMXDgQKxZs0abZtmyZbC3t8ewYcNgb2+PvXv3YsyYMYiPj8eMGTP08nv27Blat26NLl264KOPPsKCBQvQpUsXrFy5EkOGDEHfvn3x8ccfY8aMGejYsSPu3LmT5W/5ihUr0K1bN4SGhmLatGlITEzEggULUK9ePZw9e1avEVWpVCI0NBS1atXCjz/+iD179mDmzJnw8/NDv379sv1N3bNnD1q0aIHSpUtj3LhxSEpKwrx581C3bl2cOXPmnbhFgii/GYs5AZikZ3unTp3g6+uLsLAwHDt2DHPnzsWzZ8/0/rHPzXnjyZMnaNGiBbp06YJPP/0UHh4eeSpfTn9j+vbti3Xr1mHgwIHw9/fHkydPcOjQIVy5cgXVq1eHQqFAaGgoUlJSMGjQIHh6euLevXvYsmULnj9/bjAeqa7ffvsNffr0QZ06dTBkyBDcunULbdu2haurK7y9vV/72DKrq9yeP5o3b44PP/wQnTp1wrp16/Dtt98iICAALVq0QMWKFTFhwgSMGTMGvXv3Rv369QEAderUAaCOS1q0aIGgoCCMHTsWUqkUS5cuRZMmTXDw4EHUrFkz0/KrVCq0bdsWhw4dQu/evVGxYkVcvHgR//vf/3Dt2jVs2rQp13WS07gXAG7cuIGOHTuiV69e6NatG5YsWYLu3bsjKCgIlSpVQoMGDTB48GDMnTsX3333HSpWrAgA2mfA+P9Spo5NAGD37t24desWevToAU9PT1y6dAmLFi3CpUuXcOzYMYOLmJ07d0bFihUxdepUbN26FZMmTYKrqyt++eUXNGnSBNOmTcPKlSsxfPhw1KhRAw0aNMi0Tk0d48yePVs7buz3338PANrv7sOHD1GnTh0kJiZi8ODBKFKkCJYvX462bdti3bp12cbf9IYSVKCWLl0qABh9yOVybbrIyEgBQDg6OorY2Fi9PMaOHSsAiK5du+otP3funAAgvvjiC73lw4cPFwDE3r17tct8fHwEALFjx45sy/z3338LAOJ///tfro4xMjJSb/m+ffsEALFv3z7tssTERIPtw8LChEQiEbdv39YuCwwMFF5eXuL58+faZbt27RIAhI+Pj3ZZVvWWlpYmkpOT9ZY9ffpUuLm5iZ49e2qXPXr0SAAQY8eONSibpu41rl+/LqRSqWjfvr1QKpV6aVUqlRBCiNjYWGFlZSXef/99vTQ//fSTACCWLFlisB9dmvo8efKk+Omnn4SDg4O23j766CPRuHFjIYT6M23VqpV2u4MHDwoAYuXKlXr57dixQ2+5pnytWrXSllkIIb777jsBQHTr1k27LONnqFAohLu7u6hcubJISkrSptuyZYsAIMaMGZPlsf36668CgLh48aLBOs3xpKWlCU9PTzFx4kQhhBCXL18WAMSBAwf06kbjt99+EwCElZWVaNy4sRg9erQ4ePCgwecjhMj0bxGAWLVqlUH6cuXKiRYtWmR5TJq/w/79++st//jjjw2+V926ddP7/mpk/J5pyiqVSsWlS5cM0mf8O1IoFKJy5cqiSZMmBnlYWVmJGzduaJedP39eABDz5s3TLpsxY4bRv+GoqCghk8nE5MmT9ZZfvHhRWFhYGCzPqFevXsLLy0s8fvxYb3mXLl2Ek5OT9jg0f8dLly7NMr+JEycKOzs7ce3aNb3lI0eOFDKZTERHR+vlV6RIEfH06VNtOs1v2z///KNdNmDAAIO6183D2G9L06ZNRUBAgN7vi0qlEnXq1BFly5bVLtN8X0NCQvT+1oYOHSpkMpne75ux38Y+ffoIW1tbvf00bNhQABB//vmndtnVq1e135djx45pl+/cudOgXjP+Xr948UI4OzuLL7/8Um/fMTExwsnJSW95t27dBAAxYcIEvbTVqlUTQUFB2vdZ/aYGBgYKd3d38eTJE+2y8+fPC6lUKj7//HOD9ESUc1nFnJpHpUqVtOmz+u3N+DesOU+1bdtWL13//v0FAHH+/HkhRO7OG5rfs4ULF+bo+DRlePToUaZpcvob4+TkJAYMGJBpPmfPnhUAxNq1a3NUNg1NnBQYGChSUlK0yxctWiQAiIYNG2qX5SZ+zqqucnv++P3337XLUlJShKenp+jQoYN22cmTJ41+L1QqlShbtqwIDQ3VO6clJiaKUqVKiWbNmmVaL0IIsWLFCiGVSsXBgwf1li9cuFAAEIcPH9Yu8/Hx0YtHjclp3KvJD4D4999/tctiY2OFXC4XX3/9tXbZ2rVrDeo+Yx4Z/5fKj9jE2Ge6atUqg2PQ/E307t1buywtLU2UKFFCSCQSMXXqVO3yZ8+eCRsbG716NfYbkB8xTqVKlfS++xpDhgwRAPS+Ey9evBClSpUSvr6+RmN5evPxlj0zmT9/Pnbv3q332L59u0G6Dh06aHsmZKQ7CxigHowXAIYNG6a3/OuvvwYAg+6OpUqVMnrLU0bx8fEAYPLeUQD07rNOSEjA48ePUadOHQghcPbsWQDAgwcPcO7cOXTr1k3vClSzZs3g7+9vNF9j9SaTyfQG7lUoFLCxsUGdOnX0umTnxqZNm6BSqTBmzBhIpfp/TpqrFXv27IFCocCQIUP00nz55ZdwdHTMVTfUTp06ISkpCVu2bMGLFy+wZcuWTG/XW7t2LZycnNCsWTM8fvxY+wgKCoK9vb32VkVN+QYNGqR3hSUnvVVOnTqF2NhY9O/fX++e81atWqFChQrZHpumq7GLi0umaWQyGTp16oRVq1YBUA9m7u3trb1Kl1HPnj2xY8cONGrUCIcOHcLEiRNRv359lC1bFkeOHDFI/8EHHxj8Le7evRuNGzc2SOvi4pLtWF2av8PBgwfrLc9t7x9jGjZsaPQ7r/t39OzZM8TFxaF+/fpGv9chISHanmaAuqeKo6Mjbt26le3+N2zYAJVKhU6dOul9pzw9PVG2bFm9218zEkJg/fr1aNOmDYQQetuHhoYiLi4u13+Ha9euRf369bWfi+YREhICpVKJf//9Vy99586d9b5rmu9QTo5dI+Nvy9OnT7F371506tQJL1680JbhyZMnCA0NxfXr1w1uX+3du7fe31r9+vWhVCpx+/Zt7TLdz1STb/369ZGYmIirV6/q5Wdvb48uXbpo35cvXx7Ozs6oWLEiatWqpV2ueZ3V8e7evRvPnz9H165d9epUJpOhVq1aRj/jjOei+vXr56hONb/t3bt31+v9W6VKFTRr1kz7t0REeWMs5ty9e3eWvb9zasCAAXrvBw0aBODVuTC35w25XI4ePXrkuVxA7n5jnJ2dcfz4cdy/f99oXpr4c+fOnUhMTMxxGTRxUt++ffV6XXfv3j3LXlU5kVld5fb8oTuOppWVFWrWrJmj3/Bz587h+vXr+Pjjj/HkyRPtZ5uQkICmTZvi33//1btFLaO1a9eiYsWKqFChgt53o0mTJgCQZUyRWX45iXs1/P399WJJNzc3lC9fPlcxgbH/pfIjNtH9TDU9+9977z0AMBo7ffHFF9rXMpkMwcHBEEKgV69e2uXOzs7ZHm9+xTiZ2bZtG2rWrKk3gZO9vT169+6NqKgo7TAJ9HbhLXtmUrNmzRwNam5sJr7M1t2+fRtSqdRgpj5PT084Ozsb/BBklbcuR0dHAOqTmqlFR0djzJgx2Lx5s8H93Zp78jXlLlu2rMH25cuXN/pDnNmxrVmzBv/73/9w5coVbUNbVumzc/PmTUil0kwbxoBX5c94S6SVlRVKly6dox9oDTc3N4SEhODPP/9EYmIilEolOnbsaDTt9evXERcXl+m4SZoBvjOrXzc3tywbinS3NXa7Z4UKFXDo0KGsDyidSL/lNDMff/wx5s6di/Pnz+PPP/9Ely5djI7lpREaGorQ0FAkJibi9OnTWLNmDRYuXIjWrVvj6tWrenVSokSJTMewMlbOrPYLvPo71G30AYzXUW5l9j3dsmULJk2ahHPnzumNu2CsrMZmlnRxcTH4+zPm+vXrEEIY/VsEkOWtp48ePcLz58+xaNEiLFq0yGgaY4POZ1eeCxcuZNponzG/jMeu+X7n5Ng1Mn4GN27cgBACo0ePxujRozMth+6g/Tkpx6VLl/DDDz9g7969er9VAAzGKylRooTBZ+3k5GRwK4jmn5+sjvf69esAoP2HICPN+UDD2traoP5z+n3K6vejYsWK2LlzZ54n7CCizGPOnFxkyU7G84Gfnx+kUql2HKTcnjeKFy9usokicvMbM336dHTr1g3e3t4ICgpCy5Yt8fnnn6N06dIA1L/9w4YNw6xZs7By5UrUr18fbdu21Y7Tk10ZMh6/paWlNu/XlVld5fX84eLiggsXLmS7f835olu3bpmmiYuLyzSWvH79Oq5cuZLjc3hOypOTuFcjL/GQhrG4LD9ik6dPn2L8+PFYvXq1wfbGxjDLmKeTkxOsra21wzDoLs84DpWu/IpxMnP79m29C2kamtskb9++jcqVK2ebD71Z2CBVyGU1U0Nm67L7hzkneeuqUKECAODixYs5Sp/Z/jMOpqhUKtGsWTM8ffoU3377LSpUqAA7Ozvcu3cP3bt3z/KqSnaMHdvq1avRtWtXdOnSBd9++y3c3d0hk8kwduxYREREvPa+CppmDKyYmBi0aNEi0zF7VCoV3N3dsXLlSqPrMztRFiTNmGnPnj3LcrynWrVqwc/PD0OGDEFkZGSmvcIysrW1Rf369VG/fn0ULVoU48ePx/bt27MMnrLy7NmzTIPq15HTvxUNY9/rgwcPom3btmjQoAF+/vlneHl5wdLSEkuXLjUYDB5ApjOqZdcoCKi/UxKJBNu3bzeaT1azD2r+nj/99NNM6z+3V+tVKhWaNWuGb775xuj6cuXK6b3Py7FrZPwMNMc1fPjwTHucZrxIkF05nj9/joYNG8LR0RETJkyAn58frK2tcebMGXz77bcGv42Z5fc6x6vJe8WKFfD09DRYn3GWUc7QR/T2yO05KSd55Pa8Ya4Zyjp16oT69etj48aN2LVrF2bMmIFp06Zhw4YN2nE7Z86cie7du+Pvv//Grl27MHjwYO3YWTkZszI7pogJTHX+yGlMAAAzZsxAYGCg0TTZxQUBAQGYNWuW0fW5HV8rt3FvfsQEmnKYOjbp1KkTjhw5ghEjRiAwMBD29vZQqVRo3ry50f+XjOWZl5jAlDEOUUZskHqL+Pj4QKVS4fr163oD7j18+BDPnz+Hj4/Pa+Vbrlw5lC9fHn///TfmzJmT7ZT3mpbwjDPIZewJdPHiRVy7dg3Lly/H559/rl2ecRYzTbk1V2J05aYhac2aNShTpoz21i+NjD2/ctqgB6ivBKpUKly+fDnTk7Gm/BEREXpXwxQKBSIjI3PcO0ejffv26NOnD44dO6Y3CLKxsu3Zswd169bNMsDTrV/d8j169Cjbqxm6x5axR0VERES23zlNY2dkZCQCAgKyTNu1a1dMmjQJFStWzLSus6K5OvzgwYNcbwuoZ7C8c+cO2rZtm2U6zd/hzZs39a7KGvuuuri4GJ1pMTe95tavXw9ra2vs3LlT75bUpUuX5jiPjDL7G/Dz84MQAqVKlTIIqLKjmXFQqVTm+jufGT8/P7x8+dJk+QG5+/sHoP2bsbS0NFk59u/fjydPnmDDhg16A41GRkaaJP+saHr2ubu7m+x4MqtT3d+PjK5evYqiRYuydxRRAcpp/Kbr+vXrer1Ebty4AZVKpR0sPC/njbzK7W+Ml5cX+vfvj/79+yM2NhbVq1fH5MmTtQ1SABAQEICAgAD88MMPOHLkCOrWrYuFCxdi0qRJWZbh+vXrenFSamoqIiMjUbVqVe2y16n/jPLj/JFVTACoe86+zvnCz88P58+fR9OmTXN97s0sv5zEvbnxOuUydWzy7NkzhIeHY/z48RgzZox2ubH/i0wtP2IcIOu4ILO/V816evtwDKm3SMuWLQHAYPYGzZWHvMzyNX78eDx58gRffPEF0tLSDNbv2rULW7ZsAfDqBKV7j7RSqTS4TUfTgq7bYi6EwJw5c/TSeXl5ITAwEMuXL9frlrp79+5c3UsskUigUqn0riQcOXIEx44d00tna2sLwDAgMKZdu3aQSqWYMGGCwRUKzXGFhITAysoKc+fO1TvW3377DXFxcbn+XOzt7bFgwQKMGzcObdq0yTRdp06doFQqMXHiRIN1aWlp2uMLCQmBpaUl5s2bp1e+jN8jY4KDg+Hu7o6FCxfq3Sq2fft2XLlyJdtjCwoKgpWVFU6dOpXtvr744guMHTvWYIrajMLDw40u14wV8bq3zl2+fBnJycnamWUyowlcM856aKw+/fz8EBcXp9c1/sGDBwYzYmZFJpNBIpHoXUGNiop6rdlpNDQBesa/gQ8//BAymQzjx483uNIlhMiy27dMJkOHDh2wfv16/PfffwbrdacEzqlOnTrh6NGj2Llzp8G658+fG/2tyk5mx54Zd3d3NGrUCL/88ovRxs7XOS5jv40KhQI///xzrvPKrdDQUDg6OmLKlClGZ+B6nePJ7DdV97ddd91///2HXbt2ac9pRFQwHB0dUbRoUYMxbrL67Zk/f77e+3nz5gF4dS7My3kjr3L6G6NUKg1ue3J3d0exYsW0sU18fLzBOSUgIABSqVQv/skoODgYbm5uWLhwod7MxcuWLTP4Tcxp/JyV/Dh/ZHZeDAoKgp+fH3788Ue8fPnSYLvszhedOnXCvXv3sHjxYoN1SUlJSEhIyFU5cxr35kZuYwJNOUwZmxj7TIGcxel5lR8xDqCuV2N12rJlS5w4cQJHjx7VLktISMCiRYvg6+ub5RAp9OZiDykz2b59u8HAgoB6GtXXvae8atWq6NatGxYtWqTtsnvixAksX74c7dq1MzpIc0517twZFy9exOTJk3H27Fl07doVPj4+ePLkCXbs2IHw8HDt7UGVKlXCe++9h1GjRuHp06dwdXXF6tWrDX6AK1SoAD8/PwwfPhz37t2Do6Mj1q9fb7RXTlhYGFq1aoV69eqhZ8+eePr0KebNm4dKlSoZPQka06pVK2zcuBHt27dHq1atcOvWLfzyyy+oVKmSXi8pGxsb+Pv7Y82aNShXrhxcXV1RuXJlo/cslylTBt9//7124OwPP/wQcrkcJ0+eRLFixRAWFgY3NzeMGjUK48ePR/PmzdG2bVtERETg559/Ro0aNfQGk8ypnNxy1rBhQ/Tp0wdhYWE4d+4c3n//fVhaWuL69etYu3Yt5syZg44dO8LNzQ3Dhw9HWFgYWrdujZYtW+Ls2bPYvn27wb3mGVlaWmLatGno0aMHGjZsiK5du+Lhw4eYM2cOfH19MXTo0Cy3t7a2xvvvv489e/ZgwoQJWab18fHBuHHjsj3uDz74AKVKlUKbNm3g5+eHhIQE7NmzB//88w9q1Khh0Ih37do1/PHHHwb5eHh4oFmzZtr3u3fvhq2trd4yYwIDA9G1a1f8/PPPiIuLQ506dRAeHo4bN24YpNXcPtq+fXsMHjwYiYmJWLBgAcqVK5fjAb5btWqFWbNmoXnz5vj4448RGxuL+fPno0yZMjkaA8KYoKAgAMD333+PLl26wNLSUlufkyZNwqhRoxAVFYV27drBwcEBkZGR2LhxI3r37o3hw4dnmu/UqVOxb98+1KpVC19++SX8/f3x9OlTnDlzBnv27MHTp09zVc4RI0Zg8+bNaN26tXaq5oSEBFy8eBHr1q1DVFRUtt/hzI598ODBCA0NhUwm0xsw3Jj58+ejXr16CAgIwJdffonSpUvj4cOHOHr0KO7evYvz58/nqgx16tSBi4sLunXrhsGDB0MikWDFihUF0t3d0dERCxYswGeffYbq1aujS5cucHNzQ3R0NLZu3Yq6devip59+ylWeWf2mzpgxAy1atEDt2rXRq1cv7ZTsTk5OOfp7JyLT+uKLLzB16lR88cUXCA4Oxr///otr165lmj4yMhJt27ZF8+bNcfToUfzxxx/4+OOPtT1/8nreyIlZs2ZpG741pFIpvvvuuxz9xrx48QIlSpRAx44dUbVqVdjb22PPnj04efKk9iLY3r17MXDgQHz00UcoV64c0tLSsGLFCu3FlsxYWlpi0qRJ6NOnD5o0aYLOnTsjMjISS5cuNYj3cxo/ZyU/zh9+fn5wdnbGwoUL4eDgADs7O9SqVQulSpXCr7/+ihYtWqBSpUro0aMHihcvjnv37mHfvn1wdHTEP//8k2m+n332Gf766y/07dsX+/btQ926daFUKnH16lX89ddf2LlzZ47G29XIadybG4GBgZDJZJg2bRri4uIgl8vRpEmTTMepAkwfmzg6OqJBgwaYPn06UlNTUbx4cezatatAek0Dpo9xAHWstWDBAkyaNAllypSBu7s7mjRpgpEjR2LVqlVo0aIFBg8eDFdXVyxfvhyRkZFYv369wQRS9JbI51n8KIPspuDVTLOpmXZzxowZBnlkNc1tamqqGD9+vChVqpSwtLQU3t7eYtSoUXpTdQqhnqq0VatWuS5/eHi4+OCDD4S7u7uwsLAQbm5uok2bNuLvv//WS3fz5k0REhIi5HK58PDwEN99953YvXu3wdSply9fFiEhIcLe3l4ULVpUfPnll9pp6DNOL7t+/XpRsWJFIZfLhb+/v9iwYYPo1q2b8PHx0abJqt5UKpWYNGmSKFmypLC2thZBQUFi+/btBnkIIcSRI0dEUFCQsLKy0pvqWFP3GS1ZskRUq1ZNyOVy4eLiIho2bCh2796tl+ann34SFSpUEJaWlsLDw0P069dPPHv2LNs613xnTp48mWW6zD7TRYsWiaCgIGFjYyMcHBxEQECA+Oabb8T9+/e1aZRKpRg/frzw8vISNjY2olGjRuK///4zmGbX2NTDQgixZs0a7fG7urqKTz75RNy9ezfbYxNCiA0bNgiJRKKdBje749FlrG5WrVolunTpIvz8/ISNjY2wtrYW/v7+4vvvvxfx8fF622f1t5hxOtpatWqJTz/9NEfHlJSUJAYPHiyKFCki7OzsRJs2bcSdO3cMps0WQohdu3aJypUrCysrK1G+fHnxxx9/GP2eAch0SurffvtNlC1bVsjlclGhQgWxdOnSXOVhbDrliRMniuLFiwupVGowDfX69etFvXr1hJ2dnbCzsxMVKlQQAwYMEBEREdnWzcOHD8WAAQOEt7e3sLS0FJ6enqJp06Zi0aJF2jRZTT2e0YsXL8SoUaNEmTJlhJWVlShatKioU6eO+PHHH4VCodDLz9jvQsbPJC0tTQwaNEi4ubkJiUSircOs8hBC/Zv3+eefC09PT2FpaSmKFy8uWrduLdatW6dNk9nfsrG/q8OHD4v33ntP2NjYiGLFiolvvvlG7Ny50+jU37rTtmtk9veT8TuQ1TTjoaGhwsnJSVhbWws/Pz/RvXt3cerUKW2abt26CTs7O4N9GPvuZfabKoQQe/bsEXXr1hU2NjbC0dFRtGnTRly+fNkgXyLKneziB2O/H4mJiaJXr17CyclJODg4iE6dOonY2FiDv1vN3/nly5dFx44dhYODg3BxcREDBw4USUlJBvvKyXkjs9+zzGjKYOwhk8m06bL7jUlJSREjRowQVatWFQ4ODsLOzk5UrVpV/Pzzz9o0t27dEj179hR+fn7C2tpauLq6isaNG4s9e/bkqKw///yzKFWqlJDL5SI4OFj8+++/omHDhgaxRk7j56zqKq/nD2Nx8d9//y38/f2FhYWFwfn57Nmz4sMPPxRFihQRcrlc+Pj4iE6dOonw8PBs60WhUIhp06aJSpUqaWPooKAgMX78eBEXF6dNZyxOyUxO4t7MzpHGPpPFixeL0qVLC5lMpleHWcWppo5N7t69K9q3by+cnZ2Fk5OT+Oijj8T9+/cz/bvM+D9iZufrjN+BzOIvU8c4MTExolWrVsLBwcEg5r5586bo2LGjcHZ2FtbW1qJmzZpiy5YtBmWnt4dECI4wRkTmo1Qq4e/vj06dOhntZl0YnDt3DtWrV8eZM2dea/wqIiIiIiIi0scGKSIyuzVr1qBfv36Ijo7OdtB8c+jSpQtUKhX++usvcxeFiIiIiIjorcAGKSIiIiIiIiIiKlAcGYyIiIiIiIiIiAoUG6SIiIiIiIiIiKhAsUGKiIiIiIiIiIgKFBukiIiIiIiIiIioQLFBioiIiIiIiIiICpSFuQtQ0FQqFe7fvw8HBwdIJBJzF4eIiIgKISEEXrx4gWLFikEq5fU7gDEUERERZS238dM71yB1//59eHt7m7sYRERE9Aa4c+cOSpQoYe5iFAqMoYiIiCgncho/vXMNUg4ODgDUFeTo6Gjm0hAREVFhFB8fD29vb23cQIyhiIiIKGu5jZ/euQYpTRdzR0dHBlNERESUJd6a9gpjKCIiIsqJnMZPHBSBiIiIiIiIiIgKFBukiIiIiIiIiIioQLFBioiIiIiIiIiICtQ7N4YUERG9WVQqFRQKhbmLQW8ZS0tLyGQycxeDiIgyoVQqkZqaau5iEJEOU8dPbJAiIqJCS6FQIDIyEiqVytxFobeQs7MzPD09OXA5EVEhIoRATEwMnj9/bu6iEJERpoyf2CBFRESFkhACDx48gEwmg7e3N6RS3mVOpiGEQGJiImJjYwEAXl5eZi4RERFpaBqj3N3dYWtry4sGRIVEfsRPbJAiIqJCKS0tDYmJiShWrBhsbW3NXRx6y9jY2AAAYmNj4e7uztv3iIgKAaVSqW2MKlKkiLmLQ0QZmDp+4uVmIiIqlJRKJQDAysrKzCWht5WmoZNjlBARFQ6a32NeiCIqvEwZP7FBioiICjV21af8wu8WEVHhxN9nosLLlH+fbJAyISEEHsYnI/JxApQqYe7iEBERmZ2vry9mz55t7mJQIZeQkoY7TxMR+yLZ3EUhIjKr7t27o127duYuBpnZu/I9YIOUib0XFo7GP+7Hk4QUcxeFiIjMpHv37pBIJAaP5s2b52j7/fv3QyKRvBUzDJ08eRK9e/c2aZ6NGjXCkCFDTJonmdeif2+h/vR9mLPnurmLQkSUa5k1HrwJ53OJRIJNmzaZuxhYtmyZ0djJ2to6V/kUluPJqzlz5mDZsmUmzXPcuHEIDAw0aZ55xUHNTUgikcDGUoZEhRLJCk5RTkT0LmvevDmWLl2qt0wul5t0HwqFotCPseXm5mbuItAbwF6uDkkTFUozl4SI6O0jhIBSqYSFReH+99/R0RERERF6y/Lj9s03IX5ycnIydxEKBHtImZiNpXqU+aRUBlRERO8yuVwOT09PvYeLiwsAdXD166+/on379rC1tUXZsmWxefNmAEBUVBQaN24MAHBxcYFEIkH37t0BqHsGDRw4EEOGDEHRokURGhoKAPjvv//QokUL2Nvbw8PDA5999hkeP36sLUujRo0wePBgfPPNN3B1dYWnpyfGjRunV95Zs2YhICAAdnZ28Pb2Rv/+/fHy5Uvt+mXLlsHZ2RlbtmxB+fLlYWtri44dOyIxMRHLly+Hr68vXFxcMHjwYO2A9IDhLXvPnz/HF198ATc3Nzg6OqJJkyY4f/68dr3m6t2KFSvg6+sLJycndOnSBS9evACgvgp94MABzJkzR3v1NCoqCgBw4MAB1KxZE3K5HF5eXhg5ciTS0tLy8ClSQbGVq+OnhBR+XkT09jLWQ2X27Nnw9fU1SDt+/HjtubJv375QKBTadSqVCmFhYShVqhRsbGxQtWpVrFu3Trte0zNr+/btCAoKglwux6FDh3JdXpVKhQkTJqBEiRKQy+UIDAzEjh07tOsVCgUGDhwILy8vWFtbw8fHB2FhYQDUjWDjxo1DyZIlIZfLUaxYMQwePDjL/UkkEoPYycPDQ7s+u3hGU4/t27eHRCLRvtfU+6+//opSpUppe13lNSYBgB07dqBevXpwdnZGkSJF0Lp1a9y8eVO7PioqChKJBH/99Rfq168PGxsb1KhRA9euXcPJkycRHBwMe3t7tGjRAo8ePdJul7HXXU4/8/DwcAQHB8PW1hZ16tTRNvAtW7YM48ePx/nz57Xxk6YHVnR0ND744APY29vD0dERnTp1wsOHD7P8rEyFDVImZs0GKSKifCGEQKIizSwPIUw/LuD48ePRqVMnXLhwAS1btsQnn3yCp0+fwtvbG+vXrwcARERE4MGDB5gzZ452u+XLl8PKygqHDx/GwoUL8fz5czRp0gTVqlXDqVOnsGPHDjx8+BCdOnXS29/y5cthZ2eH48ePY/r06ZgwYQJ2796tXS+VSjF37lxcunQJy5cvx969e/HNN9/o5ZGYmIi5c+di9erV2LFjB/bv34/27dtj27Zt2LZtG1asWIFffvlFL0DK6KOPPkJsbCy2b9+O06dPo3r16mjatCmePn2qTXPz5k1s2rQJW7ZswZYtW3DgwAFMnToVgLoLe+3atfHll1/iwYMHePDgAby9vXHv3j20bNkSNWrUwPnz57FgwQL89ttvmDRp0ut/SFRg7KzYQ4qIjDPX+T8/zv05FR4ejitXrmD//v1YtWoVNmzYgPHjx2vXh4WF4ffff8fChQtx6dIlDB06FJ9++ikOHDigl8/IkSMxdepUXLlyBVWqVMl1OebMmYOZM2fixx9/xIULFxAaGoq2bdvi+nX17dVz587F5s2b8ddffyEiIgIrV67UNgKtX78e//vf//DLL7/g+vXr2LRpEwICAl6/UtJlFc+cPHkSALB06VI8ePBA+x4Abty4gfXr12PDhg04d+4cgLzHJACQkJCAYcOG4dSpUwgPD4dUKkX79u2hUunfMTV27Fj88MMPOHPmDCwsLPDxxx/jm2++wZw5c3Dw4EHcuHEDY8aMyfS4c/qZf//995g5cyZOnToFCwsL9OzZEwDQuXNnfP3116hUqZI2furcuTNUKhU++OADPH36FAcOHMDu3btx69YtdO7c+TU+ndwr3H323kC2VuoGqUQFr/AREZlSUqoS/mN2mmXflyeEwtYqd6fMLVu2wN7eXm/Zd999h++++w6A+spX165dAQBTpkzB3LlzceLECTRv3hyurq4AAHd3dzg7O+vlUbZsWUyfPl37ftKkSahWrRqmTJmiXbZkyRJ4e3vj2rVrKFeuHACgSpUqGDt2rDaPn376CeHh4WjWrBkA6I3J5Ovri0mTJqFv3774+eeftctTU1OxYMEC+Pn5AQA6duyIFStW4OHDh7C3t4e/vz8aN26Mffv2GQ1kDh06hBMnTiA2NlZ7++KPP/6ITZs2Yd26ddqxplQqFZYtWwYHBwcAwGeffYbw8HBMnjwZTk5OsLKygq2tLTw9PbV5//zzz/D29sZPP/0EiUSCChUq4P79+/j2228xZswYSKW8BleYaeKnBMZPRJSBuc7/uT33Gzvv6/YYzg0rKyssWbIEtra2qFSpEiZMmIARI0Zg4sSJSE1NxZQpU7Bnzx7Url0bAFC6dGkcOnQIv/zyCxo2bKjNZ8KECdrz/Ov48ccf8e2336JLly4AgGnTpmHfvn2YPXs25s+fj+joaJQtWxb16tWDRCKBj4+Pdtvo6Gh4enoiJCQElpaWKFmyJGrWrJnl/uLi4gzqsH79+ti+fbv2fVbxjGaYAGdnZ70YAVD35vr999+1aUwRkwBAhw4d9PazZMkSuLm54fLly6hcubJ2+fDhw7U927/66it07doV4eHhqFu3LgCgV69emY4ZlZKSkuPPfPLkydr3I0eORKtWrZCcnAwbGxvY29vDwsJCr252796NixcvIjIyEt7e3gCA33//HZUqVcLJkydRo0YNo2UyFTZImZhNekCVzB5SRETvtMaNG2PBggV6yzQNTQD0rlTa2dnB0dERsbGx2eYbFBSk9/78+fPYt2+fQQAHqK/q6TZI6fLy8tLb3549exAWFoarV68iPj4eaWlpSE5ORmJiImxtbQEAtra22sYoAPDw8ICvr6/evj08PDI9jvPnz+Ply5coUqSI3vKkpCS97u2+vr7awM9YWY25cuUKateurTfWRN26dfHy5UvcvXsXJUuWzHJ7Mi+79DGkeMseEb2pjJ33jx8/jk8//TTXeVWtWlV77gWA2rVr4+XLl7hz5w5evnyJxMREg4YmhUKBatWq6S0LDg7O9b414uPjcf/+fW2DiUbdunW1t7V1794dzZo1Q/ny5dG8eXO0bt0a77//PgB176PZs2ejdOnSaN68OVq2bIk2bdpkOY6Vg4MDzpw5o7fMxsZG73128UxmfHx89Ma1NFVMcv36dYwZMwbHjx/H48ePtT2joqOj9RqkdMutuQ1Rt8dYVvHTjRs3cvyZ6+7Hy8sLABAbG5tpHHTlyhV4e3trG6MAwN/fH87Ozrhy5QobpN402lv2OKg5EZFJ2VjKcHlCqNn2nVt2dnYoU6ZMpustLS313kskEoPu3Znlq+vly5do06YNpk2bZpBWE4hkt7+oqCi0bt0a/fr1w+TJk+Hq6opDhw6hV69eUCgU2qDYWB65OY6XL1/Cy8sL+/fvN1in2xPsdeuG3lzaHlIpvKBHRPrMdf7P7bnf2Hn/7t27eu+lUqnBrYCpqam52o9mfMetW7eiePHieusyTp6SMWYwterVqyMyMhLbt2/Hnj170KlTJ4SEhGDdunXw9vZGREQE9uzZg927d6N///6YMWMGDhw4YHCe15BKpVnGToBp4ydTxCRt2rSBj48PFi9ejGLFikGlUqFy5cp6Y35lzEdz8SzjsqziJyBnn7mx/RTmGIoNUibGW/aIiPKHRCLJ9W1zbyrNzC856epfvXp1rF+/Hr6+vq89e87p06ehUqkwc+ZM7a1tf/3112vllZXq1asjJiYGFhYWRgdwzSkrKyuDuqlYsSLWr18PIYQ2ADt8+DAcHBxQokSJvBSbCsCrWfYYPxGRvrfp/O/m5oaYmBi9c5VmPCNd58+fR1JSkrZ30LFjx2Bvbw9vb2+4urpCLpcjOjpa71YtU3N0dESxYsVw+PBhvf0cPnxY79Y7R0dHdO7cGZ07d0bHjh3RvHlzPH36FK6urrCxsUGbNm3Qpk0bDBgwABUqVMDFixdRvXr1fCu3paVljuOnvMYkT548QUREBBYvXoz69esDwGsNHp8df39/k3zmmcVPd+7cwZ07d7S9pC5fvoznz5/D398/T+XOibfjL7sQ0bSk85Y9IqJ3W0pKCmJiYvSWWVhYoGjRotlu6+PjA4lEgi1btqBly5ba+/6NGTBgABYvXoyuXbtqZ525ceMGVq9ejV9//RUyWfZXeMuUKYPU1FTMmzcPbdq00Q6YbmohISGoXbs22rVrh+nTp6NcuXK4f/8+tm7divbt2+f41gJfX18cP34cUVFRsLe3h6urK/r374/Zs2dj0KBBGDhwICIiIjB27FgMGzaM40e9AWw1t+xxUHMieos1atQIjx49wvTp09GxY0fs2LED27dvh6Ojo146hUKBXr164YcffkBUVBTGjh2LgQMHQiqVwsHBAcOHD8fQoUOhUqlQr149xMXF4fDhw3B0dES3bt1yXa7IyEiDhrGyZctixIgRGDt2LPz8/BAYGIilS5fi3LlzWLlyJQD1DL1eXl6oVq0apFIp1q5dC09PTzg7O2PZsmVQKpWoVasWbG1t8ccff8DGxkZvnKmMhBAGsROgHlMzp+dyX19f7dhMcrlcO8NxRqaISVxcXFCkSBEsWrQIXl5eiI6OxsiRI3NUztww1Wfu6+ur/axLlCgBBwcHhISEICAgAJ988glmz56NtLQ09O/fHw0bNszTLZ85xQjNxGw4yx4REUE9DbCXl5feo169ejnatnjx4hg/fjxGjhwJDw8PDBw4MNO0mquXSqUS77//PgICAjBkyBA4OzvnOHirWrUqZs2ahWnTpqFy5cpYuXKldtpmU5JIJNi2bRsaNGiAHj16oFy5cujSpQtu376tN61zdoYPHw6ZTAZ/f3+4ubkhOjoaxYsXx7Zt23DixAlUrVoVffv21QbzVPjZpfcwV6SpkKosvLcWEBHlRcWKFfHzzz9j/vz5qFq1Kk6cOIHhw4cbpGvatCnKli2LBg0aoHPnzmjbti3GjRunXT9x4kSMHj0aYWFhqFixIpo3b46tW7eiVKlSr1WuYcOGoVq1anqPs2fPigJpmgAAhZtJREFUYvDgwRg2bBi+/vprBAQEYMeOHdi8eTPKli0LQN1QMn36dAQHB6NGjRqIiorCtm3bIJVK4ezsjMWLF6Nu3bqoUqUK9uzZg3/++cdgzCZd8fHxBrFTTseI0pg5cyZ2794Nb29vg/GVdJkiJpFKpVi9ejVOnz6NypUrY+jQoZgxY0aOy5obpvjMO3TogObNm6Nx48Zwc3PDqlWrIJFI8Pfff8PFxQUNGjRASEgISpcujTVr1uTLcWQkEeacz9IM4uPj4eTkhLi4OIOWaFP4buNF/Hk8GkNCymJISDmT509E9K5ITk5GZGQkSpUqBWtra3MXh95CWX3H8jteeBPlZ50o0lQo94N6FqXzY9+Hk43x8UWI6O3Gcz9R4WfK+Ik9pEzMlj2kiIiIiHLFykIKS5l6PBXOtEdERPRuYIOUidmkdzlP5hgIRERERDmmGbSYA5sTERG9G9ggZWLWlppZ9tggRURERJRTmpn2ElIYQxEREb0L2CBlYrZWvGWPiIiIKLc0MVQCe0gRERG9E9ggZWKaWfaS2SBFRERElGO26T2kEtlDioiI6J3ABikT04whxVv2iIiIiHLOjj2kiIiI3ilskDIxG86yR0RERJRrmkHNOYYUERHRu4ENUiam6SGVxB5SRERERDlmJ9f0MmcPKSIioncBG6RMjGNIERHR2+zGjRuYMmUKkpKSzF2Ud978+fPh6+sLa2tr1KpVCydOnMgy/fPnzzFgwAB4eXlBLpejXLly2LZtWwGVNnt2nGWPiIjeYsnJyZg8eTJu3Lhh7qIUGmyQMjGOIUVERHnRqFEjDBkyRPve19cXs2fPznIbiUSCTZs2mawMme0zOTkZHTt2RLFixWBjY2Oy/VHurVmzBsOGDcPYsWNx5swZVK1aFaGhoYiNjTWaXqFQoFmzZoiKisK6desQERGBxYsXo3jx4gVc8szZWbGHFBFR9+7d0a5dO3MX4400btw4BAYGat/npC4zxl15ldU+Bw8ejBs3bqBMmTIm29+bjg1SJsYxpIiI3l1t2rRB8+bNja47ePAgJBIJLly4kKs8T548id69e5uieHne56BBg9CuXTt07969QMtDhmbNmoUvv/wSPXr0gL+/PxYuXAhbW1ssWbLEaPolS5bg6dOn2LRpE+rWrQtfX180bNgQVatWLeCSZ047hhQbpIjoDZNZI8T+/fshkUjw/PnzAi9TTpn6otbrmDlzJlxcXJCcnGywLjExEY6Ojpg7d26u850zZw6WLVtmghLmfZ8rV65EVFQUFi1aVKDlKezYIGVimh5SvGWPiOjd06tXL+zevRt37941WLd06VIEBwejSpUqucrTzc0Ntra2pipinva5ePFijBs3rkDLQoYUCgVOnz6NkJAQ7TKpVIqQkBAcPXrU6DabN29G7dq1MWDAAHh4eKBy5cqYMmUKlMrCE69ox5DiLXtERCYlhEBaWuFt7P/ss8+QkJCADRs2GKxbt24dFAoFPv3001zn6+TkBGdnZxOUMO/7/OSTT7Br1y5YWloWaHkKOzZImZitpfrqXqpSIFWpMnNpiIioILVu3Rpubm4GV8ZevnyJtWvXol27dujatSuKFy8OW1tbBAQEYNWqVVnmmfH2uevXr6NBgwawtraGv78/du/ebbDNt99+i3LlysHW1halS5fG6NGjkZqaqpfmn3/+QY0aNWBtbY2iRYuiffv2me4zOjoaH3zwAezt7eHo6IhOnTrh4cOH2vWaLvIrVqyAr68vnJyc0KVLF7x48SIHtUa59fjxYyiVSnh4eOgt9/DwQExMjNFtbt26hXXr1kGpVGLbtm0YPXo0Zs6ciUmTJmW6n5SUFMTHx+s98pOmh9TLlML7TxMRUV5kvKUMAGbPng1fX1+DtOPHj4ebmxscHR3Rt29fKBQK7TqVSoWwsDCUKlUKNjY2qFq1KtatW6ddr+mZtX37dgQFBUEul+PQoUO5Lq9KpcKECRNQokQJyOVyBAYGYseOHdr1CoUCAwcOhJeXF6ytreHj44OwsDAA6kawcePGoWTJkpDL5ShWrBgGDx5sdD/u7u5o06aN0V6+S5YsQbt27eDq6pqj+EZXxp5rCQkJ+Pzzz2Fvbw8vLy/MnDnTYJsVK1YgODgYDg4O8PT0xMcff2xwO/ylS5fQunVrODo6wsHBAfXr18fNmzeN7jMlJQWDBw+Gu7s7rK2tUa9ePZw8eVK7XvNZhYeHIzg4GLa2tqhTpw4iIiIyPa63CRukTMza6lWV8rY9IiITEgJQJJjnIUSOimhhYYHPP/8cy5Ytg9DZZu3atVAqlfj0008RFBSErVu34r///kPv3r3x2WefZTsYtYZKpcKHH34IKysrHD9+HAsXLsS3335rkM7BwQHLli3D5cuXMWfOHCxevBj/+9//tOu3bt2K9u3bo2XLljh79izCw8NRs2bNTPf5wQcf4OnTpzhw4AB2796NW7duoXPnznrpbt68iU2bNmHLli3YsmULDhw4gKlTp+bouCj/qVQquLu7Y9GiRQgKCkLnzp3x/fffY+HChZluExYWBicnJ+3D29s7X8v4apY9xk9EpMNc5/8cnvvzQ3h4OK5cuYL9+/dj1apV2LBhA8aPH69dHxYWht9//x0LFy7EpUuXMHToUHz66ac4cOCAXj4jR47E1KlTceXKlVz30AbUt5/NnDkTP/74Iy5cuIDQ0FC0bdsW169fBwDMnTsXmzdvxl9//YWIiAisXLlS27i2fv16/O9//8Mvv/yC69evY9OmTQgICMh0X7169cLevXtx+/Zt7bJbt27h33//Ra9evQBkH99kZ8SIEThw4AD+/vtv7Nq1C/v378eZM2f00qSmpmLixIk4f/48Nm3ahKioKL2hCu7du4cGDRpALpdj7969OH36NHr27JlpD7RvvvkG69evx/Lly3HmzBmUKVMGoaGhePr0qV6677//HjNnzsSpU6dgYWGBnj175vi43mQW5i7A28ZKJoVUAqgEkKxQwtGaXfKIiEwiNRGYUsw8+/7uPmBll6OkPXv2xIwZM3DgwAE0atQIgPp2vQ4dOsDHxwfDhw/Xph00aBB27tyJv/76K9MGIV179uzB1atXsXPnThQrpq6LKVOmoEWLFnrpfvjhB+1rX19fDB8+HKtXr8Y333wDAJg8eTK6dOmiF9xmNpZQeHg4Ll68iMjISG2DxO+//45KlSrh5MmTqFGjBgB1g8eyZcvg4OAAQN39Pjw8HJMnT872uCh3ihYtCplMptdLDQAePnwIT09Po9t4eXnB0tISMplMu6xixYqIiYmBQqGAlZWVwTajRo3CsGHDtO/j4+PztVHKjmNIEZEx5jr/5+LcDwBbtmyBvb293rLXvS3aysoKS5Ysga2tLSpVqoQJEyZgxIgRmDhxIlJTUzFlyhTs2bMHtWvXBgCULl0ahw4dwi+//IKGDRtq85kwYQKaNWv2WmUAgB9//BHffvstunTpAgCYNm0a9u3bh9mzZ2P+/PmIjo5G2bJlUa9ePUgkEvj4+Gi3jY6OhqenJ0JCQmBpaYmSJUtmGeuEhoaiWLFiWLp0qXZ4gGXLlsHb2xtNmzYFkH18k5WXL1/it99+wx9//KHNb/ny5ShRooReOt2GoNKlS2Pu3LmoUaMGXr58CXt7e8yfPx9OTk5YvXq19va7cuXKGd1nQkICFixYgGXLlmljtcWLF2P37t347bffMGLECG3ayZMnaz+7kSNHolWrVkhOToa1tXW2x/YmYw8pE5NIJNqBzXmFj4jo3VOhQgXUqVNH2+38xo0bOHjwIHr16gWlUomJEyciICAArq6usLe3x86dOxEdHZ2jvK9cuQJvb29tYxQAbTCqa82aNahbty48PT1hb2+PH374QW8f586d0wZjOd2nbkOEv78/nJ2dceXKFe0yX19fbWMUoG4AyWzGN8obKysrBAUFITw8XLtMpVIhPDzc6PcBAOrWrYsbN25ApXo1nMC1a9fg5eVltDEKAORyORwdHfUe+clOrm6Q4hhSRPQmaty4Mc6dO6f3+PXXX18rr6pVq+qN5Vi7dm28fPkSd+7cwY0bN5CYmIhmzZrB3t5e+/j999+1t41pBAcHv/bxxMfH4/79+6hbt67e8rp162rP/927d8e5c+dQvnx5DB48GLt27dKm++ijj5CUlITSpUvjyy+/xMaNG7Mcx0omk6Fbt27aXuYqlQrLly9Hjx49IJWqmy2yi2+ycvPmTSgUCtSqVUu7zNXVFeXLl9dLd/r0abRp0wYlS5aEg4ODtpFIs59z586hfv36ORoL6ubNm0hNTdWrQ0tLS9SsWVMvhgKg14PNy8sLAN6JOIo9pPKBjZUFEhRK3rJHRGRKlrbqq5Xm2ncu9OrVC4MGDcL8+fOxdOlS+Pn5oWHDhpg2bRrmzJmD2bNnIyAgAHZ2dhgyZIjeuBB5dfToUXzyyScYP348QkNDtVfxdMdJsLGxMdn+NDIGZhKJRK/xg0xr2LBh6NatG4KDg1GzZk3Mnj0bCQkJ6NGjBwDg888/R/HixbVjefTr1w8//fQTvvrqKwwaNAjXr1/HlClTMh3Pwxxs0yeGYQ8pItJjrvN/Ls/9dnZ2KFOmjN6yjJOcSKVSvVv6AWQ5BpIxL1++BKC+/b548eJ66+RyuUGZ8lP16tURGRmJ7du3Y8+ePejUqRNCQkKwbt06eHt7IyIiAnv27MHu3bvRv39/bQ/yzBpzevbsibCwMOzduxcqlQp37tzRntdyEt/kVUJCAkJDQxEaGoqVK1fCzc0N0dHRCA0N1cZq+RFDAfpxlEQiAYB3Io5ig1Q+sEkfR4oNUkREJiSR5KrrvDl16tQJX331Ff7880/8/vvv6NevHyQSCQ4fPowPPvhAO1OMSqXCtWvX4O/vn6N8K1asiDt37uDBgwfaq2fHjh3TS3PkyBH4+Pjg+++/1y7THY8BUF+FCw8P1wZ5OdnnnTt3tL2kLl++jOfPn+e43GR6nTt3xqNHjzBmzBjExMRoB5rVDHQeHR2tvaIMAN7e3ti5cyeGDh2KKlWqoHjx4vjqq6+MjkFmLtoeUuxhTkS63qDzf3bc3NwQExMDIYS20eHcuXMG6c6fP4+kpCRt48exY8dgb28Pb29vuLq6Qi6XIzo6Wu/2PFNzdHREsWLFcPjwYb39HD58WO/WO0dHR3Tu3BmdO3dGx44d0bx5czx9+hSurq6wsbFBmzZt0KZNGwwYMAAVKlTAxYsXUb16daP71FzAW7JkCYQQCAkJ0d4GmJP4Jit+fn6wtLTE8ePHUbJkSQDAs2fPcO3aNe3xXb16FU+ePMHUqVO1Mc+pU6f08qlSpQqWL1+O1NTUbHtJ+fn5wcrKCocPH9YeR2pqKk6ePIkhQ4bkuOxvMzZI5QPNLXtJDKiIiN5J9vb26Ny5M0aNGoX4+HjtYJhly5bFunXrcOTIEbi4uGDWrFl4+PBhjht2QkJCUK5cOXTr1g0zZsxAfHy8XmCm2Ud0dDRWr16NGjVqYOvWrdi4caNemrFjx6Jp06bw8/NDly5dkJaWhm3bthltnAgJCUFAQAA++eQTzJ49G2lpaejfvz8aNmyYp1sBKO8GDhyIgQMHGl23f/9+g2W1a9c2aMAsTDQ9pDjLHhG9rRo1aoRHjx5h+vTp6NixI3bs2IHt27cb3BKtUCjQq1cv/PDDD4iKisLYsWMxcOBASKVSODg4YPjw4Rg6dChUKhXq1auHuLg4HD58GI6OjujWrVuuyxUZGWnQMFa2bFmMGDECY8eOhZ+fHwIDA7F06VKcO3cOK1euBADMmjULXl5eqFatGqRSKdauXQtPT084Oztj2bJlUCqVqFWrFmxtbfHHH3/AxsZGb5wpY3r16oUvv/wSAPRmLc5JfJMVe3t79OrVCyNGjECRIkXg7u6O77//Xu/iTcmSJWFlZYV58+ahb9+++O+//zBx4kS9fAYOHIh58+ahS5cuGDVqFJycnHDs2DHUrFnT4PY/Ozs79OvXDyNGjICrqytKliyJ6dOnIzExUTtQ+7uOY0jlA5v0QTnZIEVE9O7q1asXnj17ph2kE1APxlm9enWEhoaiUaNG8PT01JsaODtSqRQbN25EUlISatasiS+++MJg0PC2bdti6NChGDhwIAIDA3HkyBGMHj1aL02jRo2wdu1abN68GYGBgWjSpEmmM/1JJBL8/fffcHFxQYMGDRASEoLSpUtjzZo1uasQomzYp/eQUqSpkKp8+29TIKJ3T8WKFfHzzz9j/vz5qFq1Kk6cOKE32YlG06ZNUbZsWTRo0ACdO3dG27ZttQN9A8DEiRMxevRohIWFoWLFimjevDm2bt2KUqVKvVa5hg0bhmrVquk9zp49i8GDB2PYsGH4+uuvERAQgB07dmDz5s0oW7YsAPWsd9OnT0dwcDBq1KiBqKgobNu2DVKpFM7Ozli8eDHq1q2LKlWqYM+ePfjnn39QpEiRLMvSoUMHyOVy2Nra6sVIOYlvsjNjxgzUr18fbdq0QUhICOrVq4egoCDtejc3Nyxbtgxr166Fv78/pk6dih9//FEvjyJFimDv3r14+fIlGjZsiKCgICxevDjT3lJTp05Fhw4d8Nlnn6F69eq4ceMGdu7cCRcXl1yV/W0lERlvYn3LxcfHw8nJCXFxcfk2OGeXRUdx7NZTzOtaDW2qmmlGKCKiN1xycjIiIyNRqlSpt36GETKPrL5jBREvvGnyu04UaSqU+2E7AOD82PfhZMOZioneNTz3ExV+poyf2EMqH/CWPSIiIqLcsbKQwlKmHlMlkQObExERvfXYIJUPbDW37HFQcyIiIqIc08RQCSmMoYiIiN52bJDKB9aaHlJskCIiIiLKMbv0gc0TOLA5ERHRW48NUvnAxkpdrbxlj4iIiCjnbNMHNk/gLXtERERvPTZI5QPeskdERESUe3bpDVKJvGWPiIjorccGqXxgzUHNiYhM5h2bDJYKEL9bhY/2lj32kCJ6p/H3majwMuXfJxuk8oENx5AiIsozmUz9W6pQKMxcEnpbJSYmAgAsLS3NXBLS0PQyT+RFPaJ3kub3WPP7TESFjynjJ4s850AGbK3YQ4qIKK8sLCxga2uLR48ewdLSElIpr6GQaQghkJiYiNjYWDg7O2sbP8n87OQc1JzoXSaTyeDs7IzY2FgAgK2tLSQSiZlLRURA/sRPbJDKB+whRUSUdxKJBF5eXoiMjMTt27fNXRx6Czk7O8PT09PcxSAdmh5SCRxDiuidpfld1jRKEVHhYsr4iQ1S+cCaPaSIiEzCysoKZcuW5W17ZHKWlpbsGVUIacaQSuQYUkTvLM0FKXd3d6Smppq7OESkw9TxExuk8oFteg+pRPaQIiLKM6lUCmtra3MXg4gKgGaWPQ5qTkQymYwXDojechyQIx/YpF/dS2YPKSIiIqIc04whlchb9oiIiN56Zm2QCgsLQ40aNeDg4AB3d3e0a9cOERER2W63du1aVKhQAdbW1ggICMC2bdsKoLQ5Z80xpIiIiIhyTTuGFHtIERERvfXM2iB14MABDBgwAMeOHcPu3buRmpqK999/HwkJCZluc+TIEXTt2hW9evXC2bNn0a5dO7Rr1w7//fdfAZY8a5pBzTllMREREVHOaXtIMYYiIiJ665l1DKkdO3bovV+2bBnc3d1x+vRpNGjQwOg2c+bMQfPmzTFixAgAwMSJE7F792789NNPWLhwYb6XOSdsNbfssYcUERERUY5peki9TGEPKSIiorddoRpDKi4uDgDg6uqaaZqjR48iJCREb1loaCiOHj2ar2XLDc0YUkmpSgghzFwaIiIiojeDXXqDFMeQIiIievsVmln2VCoVhgwZgrp166Jy5cqZpouJiYGHh4feMg8PD8TExBhNn5KSgpSUFO37+Ph40xQ4C5oxpJQqAYVSBbkFZ4cgIiIiyo7mlj2OIUVERPT2KzQ9pAYMGID//vsPq1evNmm+YWFhcHJy0j68vb1Nmr8xmlv2ACBZocr3/RERERG9Dezk6T2kOIYUERHRW69QNEgNHDgQW7Zswb59+1CiRIks03p6euLhw4d6yx4+fAhPT0+j6UeNGoW4uDjt486dOyYrd2YsZVJYSCUAONMeERERUU5pLuolcAwpIiKit55ZG6SEEBg4cCA2btyIvXv3otT/27vv8KjK9P/j7zOTzKQ3AgklEIpSVEBBEVw7irhrWevuqiAqioorsq7Kz1Wx7BfLWlYXwYa4NrB3saBgAxEQQQRWmtTQ0/vM+f1xZiY9mYRpST6v65qdmTPnnLnnJG4e7rmf++nZs8ljhg8fzvz582ts++yzzxg+fHi9+zudTpKSkmrcQsG70p4SUiIiIiL+8faQKqt0U+lSlbmIiEhbFtaE1PXXX89LL73EK6+8QmJiIjk5OeTk5FBSUuLbZ8yYMUyZMsX3/MYbb2TevHk8/PDDrF27lqlTp7J06VImTpwYjo/QIG9j82L1QBARERHxS5yzqu1BkabtiYiItGlhTUjNmDGDvLw8TjrpJDp37uy7zZ0717fPli1b2Llzp+/5iBEjeOWVV3j66acZNGgQb7zxBu+8806jjdDDwZuQKlWFlIiIiIhfHNXaHuhLPRERkbYtrKvsmabZ5D4LFiyos+3CCy/kwgsvDEJEgeObsqem5iIiIiJ+MQyDeGcUeSUVFJXpSz0REZG2LCKamrdFmrInIiIi0nzxGkOJiIi0C0pIBYmamouIiIg0X5zTKuBXhZSIiEjbpoRUkHgTUuohJSIiIuI/VUiJiIi0D0pIBUnVlD0lpERERET8FeewKqQKy5SQEhERacuUkAoSTdkTERERab54z5Q9faknIiLStikhFSTeCqlSDaZERERE/BbvtMZQRaqQEhERadOUkAoSTdkTERERaT7vlD2NoURERNo2JaSCRFP2RERERJrP29S8SE3NRURE2jQlpIJECSkRERGR5ovz9pAq0xhKRESkLVNCKkh8PaSUkBIRERHxm69CSj2kRERE2jQlpILEWyGl/gciIiIi/vOusqcpeyIiIm2bElJB4q2QKlFCSkRERMRv3lX29KWeiIhI26aEVJB4K6Q0ZU9ERESCYfr06WRnZxMTE8OwYcNYsmRJg/vOnj0bwzBq3GJiYkIYrf+8q+w1d8ret+v3smTT/mCEJCIiIkGghFSQeCuk9O2eiIiIBNrcuXOZPHkyd911F8uXL2fQoEGMGjWK3bt3N3hMUlISO3fu9N1+++23EEbsv3hPQqo5Y6jCskrGPf8D455fQqXLHazQREREJICUkAoSrbInIiIiwfLII48wfvx4xo0bx4ABA5g5cyZxcXHMmjWrwWMMwyAzM9N3y8jICGHE/ovzTNlrTg+pPQVllLvcFJW7yC9V7ykREZHWQAmpINEqeyIiIhIM5eXlLFu2jJEjR/q22Ww2Ro4cyaJFixo8rrCwkB49epCVlcU555zD6tWrQxFus8X7puz5P4baX1Tue5xbXN7IniIiIhIplJAKkrjo5pebi4iIiDRl7969uFyuOhVOGRkZ5OTk1HtM3759mTVrFu+++y4vvfQSbrebESNGsG3btgbfp6ysjPz8/Bq3UPA2NW9OD6kD1RNSJRUBj0lEREQCTwmpIIlxWJe2pMKFaZphjkZERETas+HDhzNmzBgGDx7MiSeeyFtvvUXHjh156qmnGjxm2rRpJCcn+25ZWVkhidVbIVVW6fa7H9T+alVReUpIiYiItApKSAWJt4eUaVoDKhEREZFASE9Px263s2vXrhrbd+3aRWZmpl/niI6O5sgjj2T9+vUN7jNlyhTy8vJ8t61btx5U3P7y9pACKPaz9UH1Cqm8YiWkREREWgMlpILEm5ACKNG0PREREQkQh8PBkCFDmD9/vm+b2+1m/vz5DB8+3K9zuFwuVq1aRefOnRvcx+l0kpSUVOMWCg67jSibAUCxn32kVCElIiLS+kSFO4C2Kspuw2G3Ue5yU1LhIjXcAYmIiEibMXnyZMaOHcvQoUM55phjeOyxxygqKmLcuHEAjBkzhq5duzJt2jQA7rnnHo499lj69OlDbm4uDz30EL/99htXXXVVOD9GvQzDIM5hJ7+00u+V9mr0kFKFlIiISKughFQQxURXJaREREREAuXiiy9mz5493HnnneTk5DB48GDmzZvna3S+ZcsWbLaqQvgDBw4wfvx4cnJySE1NZciQIXz33XcMGDAgXB+hUfHOKCsh5Wdj8/1FVUmo3BKtsiciItIaKCEVRHEOazClKXsiIiISaBMnTmTixIn1vrZgwYIazx999FEeffTREEQVGPFOa4ha5OeUvQOasiciItLqqIdUEMU6rD5SqpASERER8V+8ZwxV3IIpe2pqLiIi0jooIRVEMZ7G5qqQEhEREfFfnMNTIeXnGEpNzUVERFofJaSCKDbauryqkBIRERHxX7zTUyHlRw+pSpe7RhIqVwkpERGRVkEJqSDyfrunCikRERER/zWnQiqvpALTrHquVfZERERaByWkgsg3ZU8VUiIiIiJ+81ZI+bPKXvWG5gD5JRWY1TNUIiIiEpGUkAoiX1NzVUiJiIiI+C3eVyHVdEJqf5FVEZWR5ASg3OXWl4EiIiKtgBJSQRSnCikRERGRZotzWgmp4rKmx1D7PSvsdU2JJcpmAGpsLiIi0hooIRVEqpASERERab54zxjKnwop75S9tHgnKXHRgPpIiYiItAZKSAWRekiJiIiINF9LKqTS4qNJjlVCSkREpLVQQiqI4jzf7hWrQkpERETEb82qkPIkpFLjHb6ElKbsiYiIRD4lpIIo1lMhVaoKKRERERG/xXsqpPxZZW+/d8penIOUOAcAeSXljR0iIiIiEUAJqSCKUQ8pERERkWbzrrLnT5W5KqRERERaJyWkgsi7yl6xKqRERERE/Bbn9H/K3n5Pv6i0OId6SImIiLQiSkgFkXeVvVJVSImIiIj4zVch5UdT8+oVUr5V9lQhJSIiEvGUkAqiWK2yJyIiItJscS1oap6mKXsiIiKtihJSQRTrW2Wv6cGUiIiIiFi8Tc1LK9y43GaD+5VXuinwND63mpp7ElKasiciIhLxlJAKoqpV9txhjkRERESk9Yj39JCCxqukDnhW2LPbDBJjolQhJSIi0oooIRVE3gopTdkTERER8Z/DbiPKZgCN95Ha7+0fFReNzWaQHOsAILekPPhBioiIyEFRQiqIfD2k1NRcRERExG+GYfjVR8rX0DzOSkRpyp6IiEjroYRUEFWvkHI30v9ARERERGry9pFqtEKquGqFPcA3ZS+/tLLR3lMiIiISfkpIBZG3QgqgrFJ9pERERET81ZwKqbS4mgkpgHz1kRIREYloSkgFUUy1hJT6SImIiIj4z1ch1UhCan+RlXTyVkhF223EexJZamwuIiIS2ZSQCiK7zcAZZV3ixgZTIiIiIlJTvMNKSBU2MmXPu8peWnxVZVRKnLexuRJSIiIikUwJqSDz9pEqVYWUiIiIiN/indYYqrissQqpmk3NoWraniqkREREIpsSUkFWtdKeekiJiIiI+CvOUyFV1MhqxVUVUnUTUrme10RERCQyKSEVZN4KKU3ZExEREfFfsyqkqiWkUuJUISUiItIaKCEVZL4KKU3ZExERkWpcLhcrVqzgwIED4Q4lIvlVIVVrlT2oNmWvWAkpERGRSKaEVJB5E1LqISUiItK+TZo0ieeeew6wklEnnngiRx11FFlZWSxYsCC8wUWgeD+qzPfXN2XPUyGlpuYiIiKRTQmpIKuasqeElIiISHv2xhtvMGjQIADef/99Nm3axNq1a7npppu4/fbbwxxd5Il3elfZqz8hVVLuorTC6tFZY8perPVYU/ZEREQiW1gTUl999RVnnXUWXbp0wTAM3nnnnUb3X7BgAYZh1Lnl5OSEJuAW0JQ9ERERAdi7dy+ZmZkAfPTRR1x44YUceuihXHHFFaxatSrM0UWeOE9Cqris/jGUtzrKYbf5qqmgelNzJaREREQiWVgTUkVFRQwaNIjp06c367h169axc+dO361Tp05BivDgeSukSlQhJSIi0q5lZGTwyy+/4HK5mDdvHqeddhoAxcXF2O32Jo5uf7xJpqIGpuwd8DU0j8YwDN/2qqbmWmVPREQkkkWF881Hjx7N6NGjm31cp06dSElJCXxAQRCnhJSIiIgA48aN46KLLqJz584YhsHIkSMB+P777+nXr1+Yo4s83qbmDbU98K2wV62hOVRraq4peyIiIhEtrAmplho8eDBlZWUcfvjhTJ06leOOO67BfcvKyigrK/M9z8/PD0WIPjGasiciIiLA1KlTOfzww9m6dSsXXnghTqcTALvdzm233Rbm6CJPvNNTIdVAD6kD9TQ0B03ZExERaS1aVUKqc+fOzJw5k6FDh1JWVsazzz7LSSedxPfff89RRx1V7zHTpk3j7rvvDnGkVdRDSkRERLwuuOCCGs9zc3MZO3ZsmKKJbN4KqYam7PkqpGolpKqm7CkhJSIiEsla1Sp7ffv25ZprrmHIkCGMGDGCWbNmMWLECB599NEGj5kyZQp5eXm+29atW0MYcdWUvVIlpERERNq1Bx54gLlz5/qeX3TRRXTo0IFu3bqxcuXKMEYWmRKaaGru7SGV1sCUvbJKt8ZfIiIiEaxVJaTqc8wxx7B+/foGX3c6nSQlJdW4hZJ3yl5D/Q9ERESkfZg5cyZZWVkAfPbZZ3z22Wd8/PHHnHHGGdx8881hji7yxDXR1Ny7yl7tCqkEZxR2m9XkXNP2REREIlermrJXnxUrVtC5c+dwh9EgrbInIiIiADk5Ob6E1AcffMBFF13E6aefTnZ2NsOGDQtzdJEn3lMhVVrhxuU2fUkmrwNFVrIpzTNFz8swDJJjo9lfVE5eSQWZyTGhCVhERESaJawVUoWFhaxYsYIVK1YAsGnTJlasWMGWLVsAa7rdmDFjfPs/9thjvPvuu6xfv56ff/6ZSZMm8cUXX3D99deHI3y/qIeUiIiIAKSmpvpaB8ybN8+3yp5pmrhczR8nTJ8+nezsbGJiYhg2bBhLlizx67g5c+ZgGAbnnntus98zlLwVUgDF9VRJNdRDCiDF19i8PEjRiYiIyMEKa4XU0qVLOfnkk33PJ0+eDMDYsWOZPXs2O3fu9CWnAMrLy/nb3/7G9u3biYuLY+DAgXz++ec1zhFp4lQhJSIiIsB5553HX/7yFw455BD27dvH6NGjAfjxxx/p06dPs841d+5cJk+ezMyZMxk2bBiPPfYYo0aNYt26dXTq1KnB4zZv3szNN9/M8ccff1CfJRScUTbsNgOX26S43EViTM1KqIZW2QNIVmNzERGRiBfWhNRJJ52EaZoNvj579uwaz2+55RZuueWWIEcVWDGqkBIRERHg0UcfJTs7m61bt/Lggw+SkJAAwM6dO7nuuuuada5HHnmE8ePHM27cOMDqT/Xhhx8ya9YsbrvttnqPcblcXHLJJdx99918/fXX5ObmHtTnCTbDMIh32MkvraSwrJKMWq/7KqTi6klIeSuklJASERGJWK2+h1Sk05Q9ERERAYiOjq63eflNN93UrPOUl5ezbNkypkyZ4ttms9kYOXIkixYtavC4e+65h06dOnHllVfy9ddfN/k+ZWVllJWV+Z7n5+c3K85AiHdGkV9aWWelPdM0G62Q8k7Zy1NTcxERkYilhFSQxTmsS6wpeyIiIrJhwwYee+wx1qxZA8CAAQOYNGkSvXr18vsce/fuxeVykZFRs2YoIyODtWvX1nvMN998w3PPPefr2+mPadOmcffdd/u9fzA0tNJeYVklFS6ryr6xCilN2RMREYlcYW1q3h7EOqxLrAopERGR9u2TTz5hwIABLFmyhIEDBzJw4EC+//57BgwYwGeffRa09y0oKOCyyy7jmWeeIT093e/jpkyZQl5enu/mbcgeSt6V9mo3NfeusBcbbfetaFxdsidJlVuipuYiIiKRShVSQebrIaUKKRERkXbttttu46abbuL++++vs/3WW2/ltNNO8+s86enp2O12du3aVWP7rl27yMzMrLP/hg0b2Lx5M2eddZZvm9vtBiAqKop169bRu3fvOsc5nU6cTqdfMQWLr0Kq1pS9/Y1M14NqU/ZK6q7OJyIiIpFBFVJB5p2yV1bpxuVuuIG7iIiItG1r1qzhyiuvrLP9iiuu4JdffvH7PA6HgyFDhjB//nzfNrfbzfz58xk+fHid/fv168eqVatYsWKF73b22Wdz8skns2LFCrKyslr2gUIg3tFQhZSnoXl8dJ1joFpT82JVSImIiEQqVUgFmbepOUBphctXei4iIiLtS8eOHVmxYgWHHHJIje0rVqygU6dOzTrX5MmTGTt2LEOHDuWYY47hscceo6ioyLfq3pgxY+jatSvTpk0jJiaGww8/vMbxKSkpAHW2RxrvuKmwdoVUkbdCqv4KrpQ49ZASERGJdMqOBJkzqqoIrUQJKRERkXZr/PjxXH311WzcuJERI0YA8O233/LAAw8wefLkZp3r4osvZs+ePdx5553k5OQwePBg5s2b52t0vmXLFmy21l8IH++0vtgrLqtVIeWdshfXeIWUElIiIiKRS9mRILPZDGKj7ZRUuNRHSkREpB274447SExM5OGHH2bKlCkAdOnShalTp3LjjTc2+3wTJ05k4sSJ9b62YMGCRo+dPXt2s98vHLytD4rK66+QSm2oh1Scd8qeElIiIiKRqvV/ddYKeFd/0Up7IiIi7ZdhGNx0001s27bNt3Ldtm3bGD9+PN999124w4tI8Z4xVJ0eUr4KqfoTUsmx1vb80grc6uEpIiISkZSQCoFYrbQnIiIi1SQmJpKYmAjAr7/+yvHHHx/miCJTnKfVQZ1V9pqokPJO2TNNKCjVSnsiIiKRSAmpEFCFlIiIiEjzNVghVWRNxUtrICHliLIR5zk2t0Qr7YmIiEQiJaRCQBVSIiIiIs1XtcpezYTUfs+UvdQGpuyBGpuLiIhEOiWkQsCXkFKFlIiIiIjfvE3Ni2t9qXfAM2WvoQopqEpIqbG5iIhIZGrWKnsPPvggN9xwA7GxsYC1VPHQoUNxOp0AFBQUcOutt/Lkk08GPtJWzDdlTxVSIiIi7c57773X6OubNm0KUSStT7zTGkMVVauQcrtNX1Pz1PjoBo/1rrSnCikREZHI1KyE1JQpU7j88st9CanRo0ezYsUKevXqBUBxcTFPPfWUElK1eCukilUhJSIi0u6ce+65Te5jGEbwA2mF6quQyiupwLtwnj9T9nKVkBIREYlIzUpImabZ6HOpn7dCqlQVUiIiIu2O2+0OdwitlrdCqnpTc2//qMSYKKLtDXefSIm1klV5xWpqLiIiEonUQyoEYtRDSkRERKTZ4j0VUkVlVWMof/pHASRryp6IiEhEU0IqBOJ8SxYrISUiIiLiL+8qeyUVLlyeeXr7i5peYQ/U1FxERCTSNWvKHsCzzz5LQkICAJWVlcyePZv09HTAamoudXl7SJWqQkpERETEb94v9cCatpcYE+1raN5khVSsKqREREQiWbMSUt27d+eZZ57xPc/MzOTFF1+ss4/UpFX2RERERJrPGWXDbjNwuU2Ky10kxkSzv8hKMDVVIeVdZU9NzUVERCJTsxJSmzdvDlIYbZtW2RMREWnfXC4X3377LQMHDiQlJSXc4bQahmEQ57BTUFpJUZnV2LyqQiq60WOrmporISUiIhKJ1EMqBFQhJSIi0r7Z7XZOP/10Dhw4EO5QWh1vY3NvL05fDylN2RMREWnVmpWQWrRoER988EGNbf/973/p2bMnnTp14uqrr6asrCygAbYF6iElIiIihx9+OBs3bgx3GK1OnNMaR/kqpLyr7Pk9Za88iNGJiIhISzUrIXXPPfewevVq3/NVq1Zx5ZVXMnLkSG677Tbef/99pk2bFvAgW7tY3yp7lWGORERERMLlvvvu4+abb+aDDz5g586d5Ofn17hJ/RI8K+0VecZR+4v9q5BK8lRIlVa49aWgiIhIBGpWD6kVK1Zw7733+p7PmTOHYcOG+RqdZ2VlcddddzF16tSABtnaeSukSircYY5EREREwuXMM88E4Oyzz8YwDN920zQxDAOXS0mT+nhX2isqs66Pr0KqiYRUojMKmwFuE/JLKoiJtje6v4iIiIRWsxJSBw4cICMjw/d84cKFjB492vf86KOPZuvWrYGLro3wVkjp2zkREZH268svvwx3CK1SVQ8pT4WUt4dUE1P2bDaD5NhoDhRXkFtSQaekmOAGKiIiIs3SrIRURkYGmzZtIisri/LycpYvX87dd9/te72goIDo6MZXPGmPfBVSamouIiLSbp144onhDqFVivNO2StzUeFyk19qJaaaqpACfAkpNTYXERGJPM3qIXXmmWdy22238fXXXzNlyhTi4uI4/vjjfa+vXLmS3r17BzzI1k49pERERATg66+/5tJLL2XEiBFs374dgBdffJFvvvkmzJFFrvhq46jcYiuxZBhVq+g1JtlTReU9TkRERCJHsxJS9957L1FRUZx44ok888wzPP300zgcVd9OzZo1i9NPPz3gQbZ2VavsqYeUiIhIe/Xmm28yatQoYmNjWb58uW9l4ry8PP7v//4vzNFFrnhfU3MXBzwNzVNio7HbjMYOA6qSVqqQEhERiTzNmrKXnp7OV199RV5eHgkJCdjtNZtDvv766yQmJgY0wLbA24yz3OWm0uUmyt6sPKCIiIi0Affddx8zZ85kzJgxzJkzx7f9uOOO47777gtjZJEt3tfUvLKqf5Qf0/XASlwB5HoSWSIiIhI5mpWQuuKKK/zab9asWS0Kpq2qvqpLSYWLRCWkRERE2p1169Zxwgkn1NmenJxMbm5u6ANqJar3kPKtsNdEQ3OvlDhVSImIiESqZiWkZs+eTY8ePTjyyCMxTTNYMbU5zigbhgGm6UlIxajxu4iISHuTmZnJ+vXryc7OrrH9m2++oVevXuEJqhWo3kNqf3HzKqQ0ZU9ERCRyNSshde211/Lqq6+yadMmxo0bx6WXXkpaWlqwYmszDMMgLtpOUbmL0nL1kRIREWmPxo8fz4033sisWbMwDIMdO3awaNEibr75Zu64445whxex4hzVekg1s0Iq2TdlTwkpERGRSNOsuWPTp09n586d3HLLLbz//vtkZWVx0UUX8cknn6hiqgm+lfYqtNKeiIhIe3Tbbbfxl7/8hVNPPZXCwkJOOOEErrrqKq655hpuuOGGcIcXseKdnjFUWSX7i6zEkiqkREREWr9mNzNyOp38+c9/5rPPPuOXX37hsMMO47rrriM7O5vCwsJgxNgmePtIlZS7whyJiIiIhINhGNx+++3s37+fn3/+mcWLF7Nnzx7uvffecIcW0epbZS8t3r/2BymeSqpcJaREREQiTrOm7NVms9kwDAPTNHG5lGhpTKw3IVWh6yQiItKeORwOEhMTSUxMJCEhIdzhRDzflL3qq+w1t6m5VtkTERGJOM2ukCorK+PVV1/ltNNO49BDD2XVqlX85z//YcuWLRpUNSLOoQopERGR9qyyspI77riD5ORksrOzyc7OJjk5mX/84x9UVKiCpyG+KXvlldUqpDRlT0REpLVrVoXUddddx5w5c8jKyuKKK67g1VdfJT09PVixtSkxqpASERFp12644QbeeustHnzwQYYPHw7AokWLmDp1Kvv27WPGjBlhjjAyxfsqpFxVFVJ+JqRSqiWk3G4Tm80ITpAiIiLSbM1KSM2cOZPu3bvTq1cvFi5cyMKFC+vd76233gpIcG1JrCqkRERE2rVXXnmFOXPmMHr0aN+2gQMHkpWVxZ///GclpBrgqzKvcLGvsHmr7CV5ElJuEwrLK0mK8a/3lIiIiARfsxJSY8aMwTD0zVJLVB9MiYiISPvjdDrJzs6us71nz544HP4lWNojb1NzqBpH+VshFRNtJybaRmmFm7ziCiWkREREIkizElKzZ88OUhhtn1bZExERad8mTpzIvffey/PPP4/T6QSs3pz//Oc/mThxYpiji1zOKBt2m4HLbQJgtxkkxfg/hE2JdZBTUUpucQVZacGKUkRERJrroFbZE/9plT0REZH257zzzqvx/PPPP6dbt24MGjQIgJ9++ony8nJOPfXUcITXKhiGQZzDTkFpJWCtsNeciv3k2Ghy8kvV2FxERCTCKCEVIpqyJyIi0v4kJyfXeH7++efXeJ6VlRXKcFqteEeULyGVFt+8aXfJcdb+uSXlAY9LREREWk4JqRCJ1ZQ9ERGRduf5558PdwhtQpzT7nuc6mdDc6/kaivtiYiISOSwhTuA9iJGq+yJiIiItEi8o+o71DQ/G5p7pXgSUrnFSkiJiIhEEiWkQiTOzx5S63cXcMOrP7J1f3EowhIREZEQ6dmzJ7169Wrw1lzTp08nOzubmJgYhg0bxpIlSxrc96233mLo0KGkpKQQHx/P4MGDefHFFw/m44SUt/UB+L/CnleKZ8peviqkREREIoqm7IVIrJ8VUtO/3MD7P+0gJTaae889PBShiYiISAhMmjSpxvOKigp+/PFH5s2bx9///vdmnWvu3LlMnjyZmTNnMmzYMB577DFGjRrFunXr6NSpU53909LSuP322+nXrx8Oh4MPPviAcePG0alTJ0aNGnUwHyskEpzVKqRaOGVPFVIiIiKRRQmpEInxs0Jq5bbcGvciIiLSNtx44431bp8+fTpLly5t1rkeeeQRxo8fz7hx4wCYOXMmH374IbNmzeK2226rs/9JJ51UJ5YXXniBb775plUkpOKqJaSaWyGV7Elgqam5iIhIZNGUvRCJ8/Q+aCwhVVBawca9RQD8sjOfskr1mxIREWnrRo8ezZtvvun3/uXl5SxbtoyRI0f6ttlsNkaOHMmiRYuaPN40TebPn8+6des44YQTGtyvrKyM/Pz8Grdwia82Za/Zq+ypqbmIiEhEUkIqRPxZZW/1jnxM03pc4TJZu7MgFKGJiIhIGL3xxhukpaX5vf/evXtxuVxkZGTU2J6RkUFOTk6Dx+Xl5ZGQkIDD4eD3v/89TzzxBKeddlqD+0+bNo3k5GTfLSsry+8YAy2uWlPz5q6yp6bmIiIikUlT9kIk1mHl/hqrkFq1La/G85XbchmUlRLMsERERCREjjzySAzD8D03TZOcnBz27NnDk08+GfT3T0xMZMWKFRQWFjJ//nwmT55Mr1696kzn85oyZQqTJ0/2Pc/Pzw9bUireWb1CSk3NRURE2oKwJqS++uorHnroIZYtW8bOnTt5++23Offccxs9ZsGCBUyePJnVq1eTlZXFP/7xDy6//PKQxHswYvyokPrJ0zcqMSaKgtJKVmzN47LhoYhOREREgq32GMdms9GxY0dOOukk+vXr5/d50tPTsdvt7Nq1q8b2Xbt2kZmZ2eBxNpuNPn36ADB48GDWrFnDtGnTGkxIOZ1OnE6n33EF08FUSPmamishJSIiElHCmpAqKipi0KBBXHHFFZx33nlN7r9p0yZ+//vfM2HCBF5++WXmz5/PVVddRefOnSO+Iaevh1QjCalV260KqQuGdOP5bzersbmIiEgbctdddwXkPA6HgyFDhjB//nxfksvtdjN//nwmTpzo93ncbjdlZWUBiSnYEg6mQirW2r+43EV5pRtHlDpWiIiIRIKwJqRGjx7N6NGj/d5/5syZ9OzZk4cffhiA/v3788033/Doo49GfEIqtolV9vKKK/htXzEAlwzrwfPfbmb9nkIKyyprLHUsIiIirYu/zcCTkpL8PufkyZMZO3YsQ4cO5ZhjjuGxxx6jqKjIt+remDFj6Nq1K9OmTQOsflBDhw6ld+/elJWV8dFHH/Hiiy8yY8aM5n+gMPB+seeIshFXrcG5PxJjojAMME2rsXnHxMio+hIREWnvWlWmY9GiRTVWlAEYNWoUkyZNCk9AzeBNSFW6TSpcbqLtNb+d81ZH9egQR59OCXRJjmFHXimrtuUxvHeHkMcrIiIigZGSklKjd1RtpmliGAYul/+r61588cXs2bOHO++8k5ycHAYPHsy8efN8jc63bNmCzVY11igqKuK6665j27ZtxMbG0q9fP1566SUuvvjiln+wEPL2kEqLczR6LetjsxkkxUSTV1JBXkm5ElIiIiIRolUlpHJycupdUSY/P5+SkhJiY2PrHFNWVlajHD1cSxbHVvs2r7jcRXJszYTUyu25ABzRNRmAQVkp7MjLYeW2XCWkREREWrEvv/zS99g0Tc4880yeffZZunbtelDnnThxYoNT9BYsWFDj+X333cd99913UO8XTt4kUpeUmBYdnxLnTUipj5SIiEikaFUJqZaYNm0ad999d7jDINpuYLcZuNwmpRUuX4NNr5VbrQqpgd2SPfcpfPxzjq/RuYiIiLROJ554Yo3ndrudY489ll69eoUpotbnqO6pPHj+wBavPuxrbF6shJSIiEikaFVdHTMzM+tdUSYpKane6iiwlizOy8vz3bZu3RqKUOswDKOqj1Q9jc29U/aO6JoCwCBPYuonT6JKREREpL0yDIOLjs6ib2Zii45XQkpERCTytKoKqeHDh/PRRx/V2PbZZ58xfPjwBo+JpCWLYx12Cssq6zQ231tYxvbcEgwDDu9qNTQ9vFsyhgHbc0vYW1hGekJkfAYRERGR1sabkNKUPRERkcgR1gqpwsJCVqxYwYoVKwDYtGkTK1asYMuWLYBV3TRmzBjf/hMmTGDjxo3ccsstrF27lieffJLXXnuNm266KRzhN5u3Qqq4VoWUtzqqV3o8iTHWgCkpJppe6fEArNS0PRERkTaluY255eCkxHkqpJSQEhERiRhhrZBaunQpJ598su/55MmTARg7diyzZ89m586dvuQUQM+ePfnwww+56aab+Pe//023bt149tlnGTVqVMhjbwlvQqq0VoXUqm3e/lEpNbYPykphw54iftqaxyn9ajZzFxERkdbhvPPOq/G8tLSUCRMmEB8fX2P7W2+9Fcqw2pWUWAcA+UpIiYiIRIywJqROOukkTNNs8PXZs2fXe8yPP/4YxKiCx7vSXu0eUiu3eftHJdfYPqhbCm8t364KKRERkVYsObnm3/dLL700TJG0X1U9pMrDHImIiIh4taoeUq2db8peRe2EVC5QtcKel/f5T9vyME1T5f0iIiKt0PPPPx/uENq9ZE3ZExERiTitapW91s5bIVVarUJqV34puwvKsBkwoEtSjf37d04i2m6wv6icbQdKQhqriIiISFuhpuYiIiKRRwmpEPJN2atWIeWdrndIp0TiHDUL1mKi7fTLtJJUP2nanoiIiEiLpHgTUsVKSImIiEQKJaRCqL5V9lY1MF3Py7vdm7gSERERkeZJibOamqtCSkREJHIoIRVC3oRUjQqp7d4V9upPSA3KSgHgp625QY1NREREpK3yNTUvqWh0QR0REREJHSWkQijO20PKk5AyTZNV3hX2uqXUe8wgz/ZV2/NwuTWAEhEREWmuFE9Tc5fbpLCsMszRiIiICCghFVIxvil71kBoe24J+4rKibIZ9MtMrPeYPp0SiHPYKS53sWFPYchiFREREWkrYqLtOKKsYa+m7YmIiEQGJaRCyNfUvNwN4KuO6puZ6EtW1Wa3GRze1ZrOp2l7IiIiIi3jbWyeq8bmIiIiEUEJqRDy9pDyTtlrqn+U1yDP61ppT0RERKRluqbGArBpb1GYIxERERFQQiqkvBVS3il7vv5RXVMaPW6gp4+UVtoTERERaZl+mUkArM3JD3MkIiIiAkpIhVT1VfZM02Slp+KpqQqpwZ6V9tbszKes0tXoviIiIiJS14DOVr/OtTsLwhyJiIiIgBJSIVWVkHKzZX8x+aWVOKJsHJpRf0Nzr26psaTGRVPhMlmjQZSIiIhIs/Xr7K2Q0lhKREQkEighFUJxnil7peUufvJMv+vfOcm36ktDDMNgkKdKaqX6SImIiIg0W1/Pisbbc0u00p6IiEgEUEIqhGK8PaQqKlnlna7XtfHpel7ePlIrtNKeiIiISLMlxUTTNcVqbL5OVVIiIiJhp4RUCPmm7JW7fQ3Kj2iif5SXd6U9NTYXERGRNmnbUijcHdS36O/tI6XG5iIiImGnhFQIeafsFZVV8vN2K7HUVENzL2+F1IY9hRSUqsxcRERE2pCPb4VnT4XFTwb1bbwr7aknp4iISPgpIRVC1VfZKyp3ERNto0/HBL+O7ZjopGtKLKYJq7arSkpERETakJ4nWPc/zILS4FUv9fNUSK3ZqQopERGRcFNCKoS8PaS8Du+STJTd/x/BQE3bExERkbbo0NGQfiiU5cHyF4L2Nt4KqXU5BbjdZtDeR0RERJqmhFQIeSukvPztH+WllfZERESkTbLZYMRfrceLnoTK8qC8TXaHOJxRNkoqXGzZXxyU9xARERH/KCEVQtF2G9F2w/fc3/5Rtff/aasqpERERKSNGXgRJGRCwQ5Y9XpQ3iLKbuPQDDU2FxERiQRKSIVYTLUqqSO6pjTr2CO6JmMYsD23hD0FZQGOTERERCSMopxw7LXW4+8eB7c7KG/TL9PbR0qNzUVERMJJCakQ8660F++w0ys9vlnHJsZE09vTBF3T9kRERKTNGToOHImwZy38+mlQ3qJfZ6uPlCqkREREwksJqRDz9pE6vGsyNpvRxN51+abtqbG5iIiItDUxyVZSCuDbfwflLfpneqfsqUJKREQknJSQCjHvlL3m9o/yGtQtBYBVqpASERGRtujY68AWDVu+g61LAn56b4XUb/uKKSqrDPj5RURExD9KSIVYapwDgCO7p7boeG/fg193FwYsJhEREZGIkdQZBl1sPQ5ClVRavIOMJCcA63apSkpERCRclJAKsdt/359bzujL6QMyWnR8n05WD6ntuSWUlLsCGZqIiIhIZBjxV+t+7Yew538BP32/TE8fKTU2FxERCRslpELs8K7JXHdSH6LsLbv0HRKcpMZFY5qwYY+qpERERKQN6tgX+p4JmLDoiYCfvl9nbx8pNTYXEREJFyWkWiFvlZQSUiIiItJmHXejdf/THCjICeip+6tCSkREJOyUkGqFvAmp9eojJSIiIm1V92Mh61hwlcPiGQE9tbdCak1OPqZpBvTcIiIi4h8lpFqh3h2thNSvu5SQEhERkTbMWyW1dBaUBm56Xa/0BKLtBgWllWzPLQnYeUVERMR/Ski1Qr4KKU3ZExERabemT59OdnY2MTExDBs2jCVLljS47zPPPMPxxx9PamoqqampjBw5stH9I8ahZ0D6oVCWD8tmB+y0jiib7ws+TdsTEREJDyWkWiFvQmrz3iIqXO4wRyMiIiKhNnfuXCZPnsxdd93F8uXLGTRoEKNGjWL37t317r9gwQL+/Oc/8+WXX7Jo0SKysrI4/fTT2b59e4gjbyabrWrFvcVPQmV5wE7dv7Onj5Qam4uIiISFElKtUJfkWOIcdirdJr/tKw53OCIiIhJijzzyCOPHj2fcuHEMGDCAmTNnEhcXx6xZs+rd/+WXX+a6665j8ODB9OvXj2effRa32838+fNDHHkLDLwIEjtDwU5Y9XrATtsv09tHylMhtW4evDYG9m0I2HuIiIhIw5SQaoVsNsNXZq7G5iIiIu1LeXk5y5YtY+TIkb5tNpuNkSNHsmjRIr/OUVxcTEVFBWlpacEKM3CinHDstdbjz+6AHSsCctp+3gqpnfmw6SuYeyn88i7MuQTK9YWfiIhIsCkh1Up5p+1tUB8pERGRdmXv3r24XC4yMjJqbM/IyCAnJ8evc9x666106dKlRlKrtrKyMvLz82vcwuboq6DLkVC8D144C7YsPuhT9vdUSNn3rcOccwm4K6wX9qyBj2856POLiIhI45SQaqV8jc1VISUiIiLNcP/99zNnzhzefvttYmJiGtxv2rRpJCcn+25ZWVkhjLIWRzyMeQ+6j7AanL/4R9jwxUGdsmOik0PiipgV/SBGWT5kHQt/eR0w4McXYeVrgYldRERE6qWEVCulKXsiIiLtU3p6Ona7nV27dtXYvmvXLjIzMxs99l//+hf3338/n376KQMHDmx03ylTppCXl+e7bd269aBjPygxSXDpm9BnJFQUwysXw5r3W3w6o7yIp+0P0M3YS0F8D/jzq3Do6XDirdYOH9wEe9cHKHgRERGpTQmpVqp6hZTbbYY5GhEREQkVh8PBkCFDajQk9zYoHz58eIPHPfjgg9x7773MmzePoUOHNvk+TqeTpKSkGrewc8TBn16F/meDqxxeGws/zWn+eVyV8MYV9KxYz14zidk9/wVxnn5aJ94C2cdDeSG8fjlUlAb0I4iIiIhFCalWqkeHOKJsBiUVLnbklYQ7HBEREQmhyZMn88wzz/DCCy+wZs0arr32WoqKihg3bhwAY8aMYcqUKb79H3jgAe644w5mzZpFdnY2OTk55OTkUFjYCiutoxxwwfMw+BIwXfD2NbDkGf+PN02rR9Svn+CyORlf/jcWHaiWbLPZ4bxnIC4ddq2CT/5f4D+DiIiIKCHVWkXbbWSnxwOaticiItLeXHzxxfzrX//izjvvZPDgwaxYsYJ58+b5Gp1v2bKFnTt3+vafMWMG5eXlXHDBBXTu3Nl3+9e//hWuj3Bw7FFw9n9g2ATr+Uc3w9eP+Hfsd4/D0ucAg22nPMGP5iGs2ZmPaVarOE/qDOc9ZT1e+hz8/FZAwxcRERGICncA0nKHdEpg/e5C1u8u5KS+ncIdjoiIiITQxIkTmThxYr2vLViwoMbzzZs3Bz+gULPZ4Iz7wZkIXz0E8++G3b9A92OhQx/ocAgkdQHDqDrm5zfhszutx2dMI2PIBdg+nMeB4gp2F5SRkVStyXufkfC7yfDNI/D+jdBlMKT1CulHFBERacuUkGrFvH2kNuxRhZSIiIi0Q4YBp/wDHAnw+V2w6nXr5hUdBx16Wwmq5G7w/dPW9mOvg2OvJQbo1dH6gm/NzvyaCSmAk2+H376DrYvh9XFw5acQ5QzZxxMREWnLNGWvFave2FxERESk3frdJLj0LRg+EQ49w0pA2aKs1fhyVsHqt+G7J8BVBv3+AKff5zu0X2YiAGtzCuqe1x4FFzwHsamwc0VVdZWIiIgcNFVItWK9OyohJSIiIgJAn1Otm5erAg78Bvt+hX3rYe+vEB0Lp95lNS736N85iQ9W7mTtzvz6z5vcDc6dAa/+Cb6fyVL6M3T05cH9LCIiIu2AElKtWO+OCRgGHCiuYF9hGR0SVEIuIiIiAoA9GtL7WLdGNFoh5fG/lN+xiD8wlg/ot/hWVnQ8hMFDjwtouCIiIu2Npuy1YrEOO11TYgFVSYmIiIi0RL/OSYA1liqvdNd5fVd+KZfPWsK9pRex2DyMBKOU9A8uZ+OWLaEOVUREpE1RQirQygpg34aQvZ23j9SvSkiJiIiINFuX5BgSY6KodJt1FoopKK3g8ud/YEdeKd07JtPz2tfJsWXSjd3kzv4L+/OLwhS1iIhI66eEVCAV5MDzo+GFsyB/R0jeso/6SImIiIi0mGEY9M+0qqTW5lT1kapwubnu5eWs2ZlPeoKDF8YdQ0ZmV2Ium0sxMRzlXsX3M66hrNIVrtBFRERaNSWkAsnugIpSyN8OL19kVUsF2SEZVkKq9jd6IiIiIuKffp09faR2WmM30zS57c1VfP3rXmKj7cy6/Giy0uIASOk5mNwzpgMwuuR93nn2n5imGZ7ARUREWjElpAIpLg0ufQPiO8KuVfDaWGuFlyDyTtlThZSIiIhIy/TzVEit8TQ2f/TzX3lz+TZsBky/5EgGdkupsX+XYy9g86DJAJy38zHeeOu1kMYrIiLSFighFWip2fCXuRAVCxvmw4eTIYjfmvXpaH2jtzOvlMKyyqC9j4iIiEhbVVUhlc+cJVt4fP6vANx37hGc0i+j3mOyz72T3zqPItpwccrKv/Hpd0tCFm/QVJbBf8+FF/8ILo0rRUQkuJSQCoauQ+CCWWDYYPl/4euHg/ZWyXHRpCc4AdigKikRERGRZuubkYhhwO6CMm5/52cAJp7ch78M697wQYZBj3HPkxN3KB2MArp/ciU/rt8WooiD5NvHYeOXsOEL+OWdcEcjIiJtXEQkpKZPn052djYxMTEMGzaMJUsa/oZp9uzZGIZR4xYTExPCaP3U70w44wHr8Rf3wsrglXL36RQPaNqeiIiISEvEO6Po4ekR5XKbnHdkV/52+qFNH+iIp+P4N8m3p9DP2MK+l65ky95WOh7btwG+eqjq+bf/DmqVv4iISNgTUnPnzmXy5MncddddLF++nEGDBjFq1Ch2797d4DFJSUns3LnTd/vtt99CGHEzDLsahk+0Hr9zHWz6Oihv4+sjpcbmIiIiIi1yhKdP1HF9OnD/+QMxDMOv4+yp3XH85RUqiGIki/ni2SlUutxBjDQITBM+/Bu4yqD7cIiOg5yVsGlhuCMTEZE2LOwJqUceeYTx48czbtw4BgwYwMyZM4mLi2PWrFkNHmMYBpmZmb5bRkb9c/sjwmn3Qv+zwV0Bcy+B3WsD/hZ9OloJqV93eRJSW76Hvb8G/H1ERERE2qrbRvfj7rMP46nLhuKIat4QOab3cRSfOg2Ac0ve5IVv1gcjxOD5+U1rqp7dCedMhyMvs7Z/++/wxiUiIm1aWBNS5eXlLFu2jJEjR/q22Ww2Ro4cyaJFixo8rrCwkB49epCVlcU555zD6tWrG9y3rKyM/Pz8GreQstngvKeh2zFQmgcvXwgFuwL6Fn06WY04N+wugC//D2adDk8eC1/9C9yugL6XiIiISFvUNSWWsSOySXBGtej45BFXUBadQopRxML5H7AjtyTAEQZJSS7Mm2I9PuFm6NAbhl9n9ULd8AXkrApreCIi0naFNSG1d+9eXC5XnQqnjIwMcnJy6j2mb9++zJo1i3fffZeXXnoJt9vNiBEj2Lat/iaS06ZNIzk52XfLysoK+OdoUnQs/HkOpPWCvC3wyoVwIHDTDA/JSMCOiwn5j8FCT98qd6XVu+r5M+HA5oC9l4iIiIjUwx6Fo/8ZAPzOvZR73v8lzAH5af7dULQbOhwCx91obUvNhsP+aD3+7omwhSYiIm1b2KfsNdfw4cMZM2YMgwcP5sQTT+Stt96iY8eOPPXUU/XuP2XKFPLy8ny3rVu3hjhij/gOcMkbEJsGO3+CJ4bAR3+HwoZ7Zfmrk7OSWc5Hudi+ANOwwR8ehXNngiMRti6GGcfBjy+pMaWIiIhIEBl9RwNwun0Z81bv5Iu1ga2KD7itP8DS563Hf3gUopxVr434q3W/6g3IDdP4WURE2rSwJqTS09Ox2+3s2lXzj/WuXbvIzMz06xzR0dEceeSRrF9f/1x9p9NJUlJSjVvYdOgN4z6CXidZPaWWPA3/HgTz77HKpVuiaC/Gf8/mRGM5pWY0y4Y9AUOvgMF/hmu/tRpTlhfCu9fDa5dB0b5AfiIRERER8epzKtgdZBs59DZ2cOe7qykpj9D2Ca5K+OAmwIRBf4aex9d8vctg6HkCmC5YPCMcEYqISBsX1oSUw+FgyJAhzJ8/37fN7XYzf/58hg8f7tc5XC4Xq1atonPnzsEKM7A69Ycx71q3rkOgohi+fthKTH3zKJQX+3+u/ZvgudNh+zKK7En8pfx2vo0aVvV6ag+4/EM49S6wRcOa92HGcPj188B/LhEREZH2zpkI2VZi57y4lWw7UMITX0ToQjPfz4BdqyA2FU6/r/59vFP4lr8AJQdCF5uIiLQLYZ+yN3nyZJ555hleeOEF1qxZw7XXXktRURHjxo0DYMyYMUyZMsW3/z333MOnn37Kxo0bWb58OZdeeim//fYbV111Vbg+Qsv0Ogmumg8XvwQd+0FpLnw+FR4/EpY8A/s2WN9cNWTHCisZtX8DJHfn/SHPs9w8lPV7CmvuZ7PD8ZNh/HxI7wuFu+Dl8+GjWxo/v4iIiIg0n2fa3l9SrR5ST3+1kf/tKghnRHXlbrUWwgE47R6IT69/v96nQsbhVrX90oZXwBYREWmJli0jEkAXX3wxe/bs4c477yQnJ4fBgwczb948X6PzLVu2YLNV5c0OHDjA+PHjycnJITU1lSFDhvDdd98xYMCAcH2EljMM6H8W9D0TVr5mDQzytsBHN1uv26IgtSekH2JN9+twiPW4eD+8fY01OMg4Ai55nfRtNvhqKet3F9b/Xp0HwTULMT+7E2PJ07DkKSryc4i+8DmwR4fuM4uIiIi0ZYeeAR/dTOq+Hzn3UCfv/K+Mf7z9M3OvORbDMMIdneXjW6wq/e7DYfClDe9nGDDiBmvc+f1TMHxizT5TIiIiB8EwzfbV6To/P5/k5GTy8vLC20+qPpVlsGw2/Pgi7F0PlU0sF9zzBKvCKiaZzXuLOOlfC3BG2fjlnjOw2+of8Lzw3Wa+++B5noh+Aofhgr6/hwuf1+BCRESkmogeL4SJrkkzzPwd5Kxi/2n/5rh5mZRUuHjogoFcODQMqz3XtvZDmPMX64vPCd9Y7SQa46qAfw+G/G1w9hNw1JiQhCkiIq1Pc8cKYZ+yJ9VEOWHYNdbg4P/tgEk/w2XvwJn/gmETrLLplB5gd8KRl8Ilb0JMMgBZaXE4omyUVbrZdqD+PlRb9xfzwLy1fOI+hqsrJlNmRsO6D2HOJVDRRPJLRERERPzT90wA0rbNZ9LIQwD4v4/WcKCoPJxRQd52q20DWKvoNZWMAquS/thrrcffPg5ud/DiExGRdkUJqUhls0FKFvQ+GY4ZD6MfgMvegkkr4R+74JzpEOXw7W63GfRKjweod9qeaZr8v7dXUVzu4pjsNDoPPZtxFX+nFAes/wxeuQjKi0L28URERETarEPPsO7Xz+eKYzvTNyORA8UV3P/x2vDFtP5zeOp4q9IpNRtO+Lv/xw4ZC85k2Pcr/G9e0EIUEZH2RQmp1qiB/gN9OiUA9Sek3li2ja9/3Ysjysb95x/BlDP7szFhKGPKbqXMFgebvoKXzofS/KCGLiIiItLmdR4MiZ2hoojoLd/xzz8eDsDcpVv5YfP+0MbidsEX98FLF0DxPsgcCJe9DY44/8/hTISjr7Aef/d4cOIUEZF2RwmpNqShhNTuglLu/cBa6eWmkYfSq2MCSTHR/POPh7PE7M+fS2/F5UiCLYvgxT9CSW6oQxcRERFpO2y2qiqpdR8xNDuNPx1t9Y+67c2V7C0sC00cBTnw33Pgq4cAE4ZeCVd+Bmm9mn+uYRPA7rDGi1uXBDxUERFpf5SQakN8Cak9NRNSd76zmvzSSo7omsz443v6tp/aP4NzBndhufsQbnTcjRmbCtuXwn/PtlbyExEREZGW6Tvauv/fPDBNbj2jHx0TnWzYU8SFMxexdX/9PT8DZuNCmHk8bP4aHAlw/nPwh0cgOqZl50vMhIEXWY+//Xfg4hQRkXZLCak2pHqFlHfxxI9W7WTe6hyibAYPnD+QKHvNH/mdfxhAWryDD/Zm8Eq/JyEuHXb+BLP/AKV5If8MIiIiIm1CzxMgOg7yt0POSlLjHcy9+li6psSyaW8R58/4jjU7g9Aqwe2GhQ/Ci+dC0W7odBhcvQCOuODgzz3ir9b92g9h8Uw1OBcRkYOihFQb0jM9HpsBBaWV7CkoI7e4nDvf/RmAa0/qzYAudZdd7JDgZOrZhwEwdQlsOut1SMiE3avhh2dDGr+IiIhImxEdC71PsR6v+xiAXh0TeOu6EfTNSGR3QRkXPbWIJZsCWJVekgsvnw9f/hNMNxx5GVz1OaQfEpjzd+xrrfSMCfNuhedHw95fA3NuERFpd5SQakOcUXa6p1kNKtfvLuSeD35hb2E5fTolMPGUPg0ed9bAzozs34kKl8mkL0pwn3qn9cKy2VYjTBERERFpPu+0vXUf+TZlJMXw2jXDOTo7lYLSSi577ns++2XXwb+X2w1vXgkbvoCoWDh3Bpzzn+Y1L/fHWU/A7x+xpgFuXQwzjoNvHgNXZWDfR0RE2ryocAcggdWnUwKb9xUz69tNfL5mN4YBD5w/EGeUvcFjDMPgvnOP4PuNC/lpay4v5B3JuJgUyN0C6+fDoaeH7gOIiIiItBWHjAIMqx1C3nZI7gpAclw0L145jImvLOfzNbu55sWl3H/eQC7yND5vkYUPwPrPrWTUFR9DlyMD8xmqcbtN3ly+nR15J3DdhO+I/vAm2DAfPr8LfnkHzpkOGYcF/H0lxNxuMF3grrS+nDbdgGndm6bnVmsbZs173+um56TVH1PrGGoeX/1132MO4nn1D1d7n1o71Lfd333ruw61P1dD6rxca4PZxPGNXX/v4xo8q7b7Vm836jmPu+p9a3+G2tfYHw1eH3cD16jayvLVV5mv8zlrn7vGm9YTQ7XtDf3O1XtMtXPW+QwNvF/1z1HtI1i71fffSn2fgZqfv3qsjd439Bk8jwecC92H1RNvaCkh1cb06ZTI52t28/ma3QCMG9GTIT1SmzwuMzmG//f7/kx5axUPzP+N84dcRNKKp2HprNaZkHJVwK7V1tLGNhUCioiISBgkdIRuR8O2JVZz86Ov9L0UE21n5qVDmPLWKl5fto1b3lzJ3qIyrj2xN0btf3w05X+fwML7rcdn/TsoyaiV23K5452f+Wmb1WM0Lf4wLrv0TVjxCnwyBXb8CE+dCCfcDL+bDFGOgMcQkVyVUFEEFSVQXgQVxVBebG2rXjVW+x/+BtY/EitLoaLUuvfeqj93VYCrvNp9rZvb5blVepJInps3oWS6Pc9Na5vvudtzq3a89745SQYRaZ3SD1FCSgLP29gcICstlptHHer3sX86Oov3Vuxg0cZ9TN1xDI/wNPz6CeRuhZSD+MYu1PZvhDevgu3LYOCf4I8z62aVRUREREKh72grIbXu4xoJKYAou40HLxhIhwQnMxdu4MF569idX8Zto/sRE91wdXsN+zfBW+Otx0ePh0EXBzT83OJyHvpkHa8s2YJpgs0AtwlPfbWRPx3TnegjL4E+p8IHk2Hdh7BgGqx+BwacDZlHWF8OpnQP/VjMNK0kUWkulByodvM8L83zJH9KoLIMKj33vuelnoRPpZUMcldWe1xhJZsqS6x92i3D83P19772MTT8GtTzmIN4XivuGvvU2aGe39eGKopo4LPVvscPDZyzwZjqOb76+xq2emKh8Yov3762qv1rf5Yab9nAdWowRH9/T6rFVHNDtc/n5znqBlEr9vp+B+v5PLW31/j9red3trEKvto/n4Z+Vk1dgxoxV9vW2H873m2ZA4kESki1MYdUS0jdf95A4hz+/4gNw+D+849g1GNf8daWOG7oOISeBctg+Qtwyj+CEW7grXzNGhCVF3iez7G+JTx2QnjjEhERkfap72iYfzds+grKCsGZUONlwzC4bXQ/0hMc3PfhGmZ/t5lPV+cwaeShnHdU1zorJNdQXgxzL7OSK92OhlH/F7Cw3W6TN5Zv4/6P17K/yEq6nDu4C5NP68sfn/yWbQdKeP+nHZx3VDdIzIQ/vQyr34KP/g571sDCNVUni0m2/vHjTVBlDLD+kVWaayWISvOsx6V5Vc9tUda1ciZa/aqcSTWfu11QtKfaba+1qqDv8V5wlQXsejTNAEe8tbKiIw6i48Ee7XmtgWlehmFNsYxyQlSMdR9d67ndCXaHdS67w7PN89gWDfYoMOzW9bLZrVv154bd+seuzeZJMnieGzbP67Zqx0ZZN8Ne81ze/b3/cK6erBAROQiGaTY5IbVNyc/PJzk5mby8PJKS6q4619qZpsl9H66he1ocY0dkt+gcry3dyi1vrGS07XtmOP6NmZCBcdPqan9UI1BZgTUA+ulV63n3EdBjBHz9L+sP6dj3IPt34Y1RRERajbY+XmgJXZMWMk14fDAc2AwXvwT9z2pw149X7eSeD35hZ14pAL07xvP3UX0ZdVhm3Wl8pgnvXGuNfeI7wtULfT2qDtbqHXnc+e5qlv12ALC+8LznnMMZ3rsDANO/XM9Dn6zjkE4JfDLpBGy2arEV7YOf37T6ZuWshN1rrIqicDHsEJvquaVUPY5J9iR/YqybLxFULSFkd1gJH1u0lajxPrZ7nkfFVCWhopxK0ohIu9fcsYIqpNoYwzC44w8DDuocFw3NoqTcxb3vVbLbTKFT4S5Y+wEc9scARRlgO36EN66E/Rusb2xOvBWOv9n6Vif3N1j1Orx+eUAHaiIiIiJ+MQzoeyYsftKattdIQmr0EZ05uV8nXlr8G9O/XM+GPUVMeGk5g7olc+sZ/RjRJ71q56WzrGSUYYcLng/IGMftNnngk7U889VG3CbEOexMGnkI447rSXS1Sq3Lhvdg5oIN/Lq7kM/X7OL0wzKrThLfAYZdXfW8shz2rIWcVVaCKmeV9dzutJJCsSnWfUxKtcfJVgVUeaH1paP3Vv25YbMScfEdIaETxKdXPY9Ph7h0iEuzqqmUKBIRiUiqkJIGPfv1Roo/uZu/Rr3DtpSj6Tbp83CHVJPbDYunw+d3W9+8JXWD85+FHsOr9ikvhudOh12roOsQGPex9Q2WiIhIIzReqEvX5CBs+gpeOAviOsDNv1pfmjUhv7SCZ7/ayLPfbKK43AXA7/qkc8sZfRnIeph1hjX+Oe1eOO6vBx2i221y+zureHXJVgB+P7Az//h9fzonx9a7/wPz1jJjwQYGZaXwznUjmt+IXURE2pzmjhW0/Jg06Krje5Hyu6twmQbdcn/g9XlfhDukKrlb4ZUL4dN/WIOx/mfBhK9rJqPAmsP/p5es0uzty+Cjm8MTr4iISIBNnz6d7OxsYmJiGDZsGEuWLGlw39WrV3P++eeTnZ2NYRg89thjoQtUoPtwcCZD8T7YttSvQ5Jiopl8el++uuVkLh+RTbTd4Jv1exn3n48o+O9fPOOfs2HEDQcdnmma3Pnez7y6ZCs2Ax69eBDT/3JUg8kogCuO64kzysZPW3NZtGHfQccgIiLtjxJS0qgxZxzP5g5W76W8b57mv4s2hy+YilJY9Qa8+Ed47AhY/7k1d/8Pj8JFL1pl2fVJzYbzn7NKu5f/F5Y+H9KwRUREAm3u3LlMnjyZu+66i+XLlzNo0CBGjRrF7t27692/uLiYXr16cf/995OZmVnvPhJE9mg45DTr8bqPmnVoeoKTqWcfxhd/O4nzB2fwRPQTJJbvYo+zB66zpx/0dDTTNLn7/V94afEWDAP+deEg/nhktyaP65jo5OKjrVWYn1yw4aBiEBGR9kkJKWlSrzOsMvAL7F/xz3d/5JXvt4TuzU3Tqmz6YDI8fCi8eSVs+AIwIft4uHoBDL2i6cFYn1PhlDusxx/9Hbb+EOzIRUREguaRRx5h/PjxjBs3jgEDBjBz5kzi4uKYNWtWvfsfffTRPPTQQ/zpT3/C6dTU9bDoO9q6//kt2LK4nqW8G+GqJGvXfB4u/gcj7L9QaMbwp/yJ3PDWr5RWuFockmma/NOzsh/AA+cPtFbN89P443tht1mVWyu35bY4DhERaZ+UkJImGX1OxUzpTopRxB9si7n9nVW8vnRrcN+0aB98+zg8ORyeOQWWPmctAZycBSfcAn/9ES7/ADr19/+cv7vJKm13V8Brl0HBruDFLyIiEiTl5eUsW7aMkSNH+rbZbDZGjhzJokWLwhiZNKrPSKtZd94WmDUKpg+D7/5jjXkaUrwfvnkMHj8S5l4KWxaBLZq1xz7AVlsWH63K4fLnl5Bf2vxV7EzT5P55a3n2m00ATDvvCC4amtWsc2SlxXHOoC4APPmlqqRERKR5lJCSptnsGEPGAXBTyteYJtzy5kqunP0Dz369kZ+35+F2B7A3/pbFMP0Y+OwO2LPGmpZ3xIVw2Ttw40o45XZI69X88xoGnPskdOwHBTvJfeHP7MsrCFzcIiIiIbB3715cLhcZGRk1tmdkZJCTkxOw9ykrKyM/P7/GTQ5CbApc8QkMvhSi42DvOvj0dnikH7w+DjYusBZsAdi1Gt77KzwyAD6/y0pixabB8X+DG39i6OjLmT3uaBKcUSzeuJ+Ln1rM7vxSv0MxTZN/fbqOpxZuBODecw/nz8d0b9HHmnBSbwDmrc5h/W6Nq0RExH9R4Q5AWokjL4Mv/49uxau5ZWAZD650Mn/tbuavtXpVJMdGM6xnGsN7d2BE73QOzUho2WorP82F9yaCqxzS+8KxE+Cw86xBXADkupx80OOfnLvnMlL2LmPTv0eQfNQZRGUfC1nHBmTJZGkm0/Tc3IDn3nTXs830PDZrPq5xX+tY7837PtX3rbPNF1C11xp5XmNbQ9vNel9u4ELUvS6Nvd4STZ3Tn88cbNXfs97H9Wjo/2ua/Pm0lFnjru71qkd9MTZ4vZsRQ51zteD4hq5THfVd51r/LTUVS5M/q2b+nKJioN+ZTe8nLTJt2jTuvvvucIfRtnTqD+dOhzOmwc9vwLIXYOcKWP2WdUvNhsQusOW7qmMyj4BhE+Dw8yG6qsn4iD7pzLn6WC5//gfW7MznvBnf8d8rjqFXx4Qmw3js81+Z7qlomnrWAC47tkeLP9KhGYmcPiCDT3/ZxYwFG3n4okEtPpeIiLQvhmke9Mi8VdGSxQfhjSvg5zdhyOX8fNQ9fLdhL4s27GPJpv0UldfsX9Ah3sHQ7FSG9kjjqB6pHN41CWdUI0scu93w5T/h639Zz/v9Ac57GhzxAQl96/5invtmE3N/2EpJhYtTbMuZEf0YTqOy5o7JWZA1DLofa92nH2L9g6elDUNNs2XHuiqgothq5F5RDBUlnltxzfvKEqgsA3eldUz1e3cFuCqtx6YbTFdVgsbtrtrmdlXbt6Laeco9jz0/W8PzP4ZR997tPU9ltVut56bLuh5uV9X7emMSEWmJhAy4+X9BOXUkjxfKy8uJi4vjjTfe4Nxzz/VtHzt2LLm5ubz77ruNHp+dnc2kSZOYNGlSo/uVlZVRVlbme56fn09WVlZEXpNWbedP1qIrK1+DMk8VmmG3VhAedo21Ql8jY4kt+4oZM+t7Nu8rJi3ewfOXH82grBTf6xUuNweKyzlQVMH+onIW/G+3rzLqH7/vz1XHt6DqvJYVW3M5d/q3RNkMFt5yMl1TGl6dT0RE2q7mjp+UkBL/bf4WZp8J0fHwt7UQY12/SpebVdvzWLRxH4s27GPp5gOU1Gqw6YiyMahbMkf18CSpuqfQIcHTVLW8GN6ZAL94BtC/m2w1ILcd/IzSldtyefqrjXy0aifeWYX9OydxzQm96GAeYM4bcxlqW8cFHbeRmLum/uSIYQdnonVzJIAzoeqxLQrKi6wEUXmh9VnKi6CiyHrsKgNbNNgdEOWw7u1Oa7WdKCfY7FBZbiWWKkqqElBmyxuUtk+GtYqiYbMG7d7Hvu1GtcF8tWQa1EqwVTuf77VGntfYVmt7ndfqe72ez9EYv5KbzT1HYzE39DkP4v39OkXtn1Xtxx4NVbb59XM7iPjM6sc3EWOdOGudoMFY/dHU71szjm/s97jRaqqGPn8j1VTVz9XUz6qpzxSbAhe/1Pg+LRTp44Vhw4ZxzDHH8MQTTwDgdrvp3r07EydO5Lbbbmv0WH8TUrVF+jVp9cqLYc17ULQHDvsjJPvfXHxvYRnjnv+BVdvziHPYOTQjkQPF5ewvKqegtLLeY6aM7sc1J/YOVPT85ZnFfLdhH5ePyGbq2YcF7LwiItJ6NHesoCl74r8eI6z+S3vWwsq5cMx4AKLsNo7snsqR3VO57qQ+lFe6Wbktl6W/HWCZ57a/qJwfNh/gh80HeArrW7kRvTsw7bR0enx6Fez40UrcnP04DP7LQYXpdpss+N9unv5qI4s37vdtP/6QdK45oTfH9engmU7YlfnbDO7+bjNPFjqZd8ORdMhdBVu+h62LrZX4ygus5FBprnVrUUAV1q2iqAUHG1aVWFSM1W8iOrbmLSrWk9iKspJcvvtoK9nl3WbYrcSMzZu08T63W4/tUZ7EmedYe5SVPPOeB7CmTXnvq0+RM633sNk999Vv9pqPvYki7/t672snkryPqyeUalRl1U4yiYi0L5MnT2bs2LEMHTqUY445hscee4yioiLGjbN6Po4ZM4auXbsybdo0wKqq+uWXX3yPt2/fzooVK0hISKBPnz5h+xxSjSMOBv2pRYemJzh59epjufalZXz9615WbM2t8bphQGqcg9S4aNLiHZx3VLcW94xqyHUn9eG7Dft4dckWJp7Sh/QEreYoIiKNU4WUNM/3T8HHt0CnAXDtd34lBEzTZNPeIpb+doDlvx1g6W8HWL+7kMOMTTzneJhMYz9mbBrGn162kl4tVFrh4p0ft/PsN5tYv7sQgCibwdmDujD+hF7071z3511a4eKsJ77h192FnD4gg6cuG1LV+8rttqqeygo894VWgqqssGq722UNIB3xVuWYI9567n0c5bSmvbnKrPvKsmrPy61pclHOagmmWoknu0NJFxGRMGgN44X//Oc/PPTQQ+Tk5DB48GAef/xxhg0bBsBJJ51EdnY2s2fPBmDz5s307NmzzjlOPPFEFixY4Nf7tYZr0t5VuNx8/eseKl0mafEOUuMdpMU5SIqNxm4L7njCNE3Onf4tP23L4/qTe/P3Uf2C+n4iIhJ5NGWvCRpMHaSSXHikvzWt7Oz/WN/k2aObdw63i71L5pL4ySScZhm/urtyf9rd/O2iUQzo0vyfyYGicl5a/BsvLNrM3sJyABKdUfx5WHfGHZdN5+TG+xis3pHHudO/pcJl8sD5R3Dx0YH9xlBERFofjRfq0jWRpsz7OYcJLy0jMSaK7247hcSYZo4RRUSkVVNCqgkaTAXAe3+F5S9Yj+PSYeBF1jS7zCMaPsbthq3fw+q3rV5Rhday1DkdR3D+nqvZXuogymYw4cTeTDylDzHRjTRA99i8t4jnvtnE68u2Ulph9X7qmhLLuOOyufjorGYNgp5auIFpH68lzmHnw78eT8/0wDRTFxGR1knjhbp0TaQpbrfJ6Y99xfrdhQzv1YHplxxFWrwj3GGJiEiIKCHVBA2mAqC8CBZMg5/mQtHuqu2ZR8Cgv8ARF0JCR6u30LalniTUO5C/vWrfmGQYeiWcfDu7iyuZ+t5qPlplJal6d4znwQsGMqRHGmBNq9uwp5D1uwvZsKeIDbutx//bXeDrr3t41yTGH9+LM4/oTLS9+c3QXW6TS55dzOKN+xmUlcIbE4a36DwiItI2aLxQl66J+OO7DXu56oWlFJe76JoSy9NjhnBYl+RwhyUiIiGghFQTNJgKIFclbJgPK16GdR9bPZHAamDd80TY+z/I21q1vzMJ+v3eWjmm18nWqnPVzPt5J/94ZzV7C8swDDgmO40deSVsO1BSd5Eqj1P6dWL88b04tldaVe+nFtqeW8IZj31FQWklN556CDedduhBnU9ERFovjRfq0jURf63LKeDqF5fy275iYqJtPHjBIM4e1CXcYYmISJApIdUEDaaCpHg//PwmrHgFdiyv2u5IgL6jrSRU71MhOqbR0+QVV3Dfh7/w+rJtNbanxEXTp2MCvTsm0KeTdevXObHJ/lDN9e6K7dw4ZwV2m8Fr1wxnSI/UgJ5fRERaB40X6tI1kebIK67gr3N+ZOH/9gBwzQm9uOWMfkFvri4iIuGjhFQTNJgKgd1r4ddPIDUbDjndWi2umZb9doD/7SqgZ3o8fTol0CHecdAVUP6aNOdH3lmxg+5pcXx04/EkOKNC8r4iIhI5NF6oS9dEmsvlNvnXp+uYsWADAMcfks4Tfz6SlDj1lRIRaYuUkGqCBlPSlLySCs7899dszy1hZP8Mpp49gG6pceEOS0REQkjjhbp0TaSlPli5g7+/vpKSChfd0+J4eswQ+mXqd0hEpK1p7lhBXZtFakmOjebhiwZhM+DzNbs48aEF3DR3BWtz8sMdmoiIiEir84eBXXjz2hF0S41ly/5iznvyO6a+t5oPV+5kV35puMMTEZEwUYWUSAO+37iPx7/4lW/X7/NtO6lvRyac2JthPQ++ibqIiEQujRfq0jWRg3WgqJyJry6vMbYCyEqLZWiPNIZmpzK0RxqHdErApl5TIiKtjqbsNUGDKWmuldtyeeqrjXy8aiduz38tg7JSuPbEXpw2IFPNOUVE2iCNF+rSNZFAqHS5+fSXXSzeuI+lmw+wNiffN77ySoqJonenBDomOOmYWHXrlBhT9TzBiSNKkz1ERCKJElJN0GBKWmrz3iKe/WYjry/dRlmlG4D0BAc90+PJSo2jW1ocWamxZKXFkZUWR2ZSjJJVIiKtlMYLdemaSDAUlFbw45Zclv52gGW/7efHLbkUl7uaPM4woFOik64psXRNjbPuU2LomhpL15Q4uqbGamEaEZEQU0KqCRpMycHaW1jGC99t5r+LfiOvpKLB/aLtBp0SY4iJtuGMsuOIsuGMsnnu7TijbDijbaTEOkiLjyYt3klafDSpcQ46JDhIjXOQEudQUktEJAw0XqhL10RCodLlZm1OAdtzS9hdUMae6rfCMvZ6Hpe73E2eK8EZRWZyDJlJMTXuOyfH0CkxhninnViHnbjoKGIcNhx2m1oyiIgcBCWkmqDBlARKSbmLdbsK2Lq/mK0Hiq37/SVsPVDM9gMlVNauP28Bw4B4RxTxTjvxzigSnFGe51EkeLbFRtuJjrIRbbcSXtF2g2i7lfiKtluDK7vNINpuEGWzYbcbRNtsRNkNomwGUXYbdsPAbvPewG7zbLMb2A0Dmw3rWM9j376e4zR4E5G2RuOFunRNJFKYpsm+onK2Hyhhe25J1X21x419adgQu80gNtpKUsVG2z3jKhvRUTYc9YyvojxjK2s8VTWuqnru3d86NspedR7vzftlZfUvLh32qm02w8BmGBiAzTDAAJsBhmFY9xgYhjVmrL6f4dlHRCSUmjtWUB2rSAvFOuwMzkphcFZKnddcbpOc/FJ25ZdSVuGm3OWmrMLlua96Xlrp5kBxOQeKytlfVMGB4nL2F1m3vJIKTBMKyyopLKsEykL+Gf1lt3kGYZ6BmDf5FeUZdNmqDYoMrEGTdwAF1mu+7d5t3gGW902q71P7GKyNtc9d+31qv1dVPAbVh2w1x29Gne0N7VvzLLXPU89z6myo72GNa1db3XPWft1o+PVq19r/89V+veHPHLTrWCem+gfcRq3PZzRwfet9j/queQMxNvV56o2tVkzVf8/9jrGJz1X7975ODM34PPW9f0Mx1Dym7nVsON4mfk71XJvYaDvnD+lW/5uLSJtlGAbpCU7SE5wMqmccBlBUVklOfik5eZ6b5/HOPGt8truglOJyF6UVLipc1peILrdZbdzVNnjHTb4kVa0xkneMVjUOM2okt6qe40uOAdhsNfeB6n/LatzV+BtU39+DxsYhVdub+HvSwN/8xv6+1vf3pvb71Bdjw+O1BmJoZDxS33vWG38jsdHQZ25GTA39zOpeh6rX6/68jXr2a/z9G4u/qZ9pnTFuPfvXOVcDcTf1/g39Pvkfq/8xNxVD7fM0NsaqPraqHrsBDOuZxiEZiYSbElIiQWC3GZ5eBrEtPkely82B4goKyyop8gyOqu5dvsellS4qKk0qXG4qXG7KK62El/dxhcuk0u2m0mVS6a712GW97jZNXG7rVuk2cXvuXdW2N8a7j5Uya7rvg4hIIHRMdCohJSL1indG0btjAr07JjS5b4XL7UtOFZe7KCl3UVJRSblnfGWNp7zjq5rbvGOnSu94yzO+qnRb+1W6zKrjqp3Hu728smrs5vvystq2g53LYppgAm7fidrV5BgRacA//3i4ElIi0rAou823kkwkcNdKULnMaomraoOuSrcnCeYyqfAkv9ym6RkQWaMiE6qeUzVYMk3PFs9YycRzXO3XPcfgfb3a+arvS33vY1LtHDXfz/ue1HgP7/b6ttW/b61T1tnBrGdz7dnTtY+vb0Bad5+6OzUUb33nrC+u6sc1Z1BcPZaQXscmfn71v0f9b1rzmJZ9nvrer/Y5W3KO+o6hoc/exLWpeWRDrzf8C1j9v6eGY2v899WsZ6cGf5bVHifFahgjIgcv2m4jOdZGcmx0uEOpl2mauM1q957xTtX4qtpjs+o1777U3gdrXEetbd7z4zt/1evVx3JV280aKyTWN6ZpamxR8//3G9/XrHVI7b871Z809Tekvr/xdf9+NfS+TcdW/bw1wqsVX9U1q/0etT5bQ8c1ElPd7VUbqh9X33Vs6vPU9zlqx9LQ+LH+81SLp77P2MDPqKnrUfv3rM71NRt/7/ribm4MdX6PWhB79bgb+znV93vT0O9aVmpc3Q8ZBhrJiYhfbDYDGwbR9nBHIiIiItJ+GIaB3YC6k6lFRFo3W7gDEBERERERERGR9kUJKRERERERERERCSklpEREREREREREJKSUkBIRERERERERkZBSQkpEREREREREREJKCSkREREREREREQkpJaRERERERERERCSklJASEREREREREZGQUkJKRERERERERERCSgkpEREREREREREJKSWkREREREREREQkpKLCHUComaYJQH5+fpgjERERkUjlHSd4xw2iMZSIiIg0rrnjp3aXkCooKAAgKysrzJGIiIhIpCsoKCA5OTncYUQEjaFERETEH/6OnwyznX3153a72bFjB4mJiRiGEfDz5+fnk5WVxdatW0lKSgr4+dsLXcfA0HUMDF3HwNB1DAxdx8Bo6jqapklBQQFdunTBZlOHA9AYqrXQdQwMXcfA0HUMDF3HwNB1DIzGrmNzx0/trkLKZrPRrVu3oL9PUlKSfskDQNcxMHQdA0PXMTB0HQND1zEwGruOqoyqSWOo1kXXMTB0HQND1zEwdB0DQ9cxMBq6js0ZP+krPxERERERERERCSklpEREREREREREJKSUkAowp9PJXXfdhdPpDHcorZquY2DoOgaGrmNg6DoGhq5jYOg6Rh79TAJD1zEwdB0DQ9cxMHQdA0PXMTACeR3bXVNzEREREREREREJL1VIiYiIiIiIiIhISCkhJSIiIiIiIiIiIaWElIiIiIiIiIiIhJQSUgE2ffp0srOziYmJYdiwYSxZsiTcIUW0r776irPOOosuXbpgGAbvvPNOjddN0+TOO++kc+fOxMbGMnLkSH799dfwBBuhpk2bxtFHH01iYiKdOnXi3HPPZd26dTX2KS0t5frrr6dDhw4kJCRw/vnns2vXrjBFHJlmzJjBwIEDSUpKIikpieHDh/Pxxx/7Xtc1bJn7778fwzCYNGmSb5uupX+mTp2KYRg1bv369fO9ruvon+3bt3PppZfSoUMHYmNjOeKII1i6dKnvdf2diQwaPzWPxk+BoTFUYGgMFRwaQ7WMxk+BE4oxlBJSATR37lwmT57MXXfdxfLlyxk0aBCjRo1i9+7d4Q4tYhUVFTFo0CCmT59e7+sPPvggjz/+ODNnzuT7778nPj6eUaNGUVpaGuJII9fChQu5/vrrWbx4MZ999hkVFRWcfvrpFBUV+fa56aabeP/993n99ddZuHAhO3bs4Lzzzgtj1JGnW7du3H///SxbtoylS5dyyimncM4557B69WpA17AlfvjhB5566ikGDhxYY7uupf8OO+wwdu7c6bt98803vtd0HZt24MABjjvuOKKjo/n444/55ZdfePjhh0lNTfXto78z4afxU/Np/BQYGkMFhsZQgacx1MHR+OnghWwMZUrAHHPMMeb111/ve+5yucwuXbqY06ZNC2NUrQdgvv32277nbrfbzMzMNB966CHfttzcXNPpdJqvvvpqGCJsHXbv3m0C5sKFC03TtK5ZdHS0+frrr/v2WbNmjQmYixYtCleYrUJqaqr57LPP6hq2QEFBgXnIIYeYn332mXniiSeaN954o2ma+n1sjrvuusscNGhQva/pOvrn1ltvNX/3u981+Lr+zkQGjZ8OjsZPgaMxVOBoDNVyGkMdHI2fAiNUYyhVSAVIeXk5y5YtY+TIkb5tNpuNkSNHsmjRojBG1npt2rSJnJycGtc0OTmZYcOG6Zo2Ii8vD4C0tDQAli1bRkVFRY3r2K9fP7p3767r2ACXy8WcOXMoKipi+PDhuoYtcP311/P73/++xjUD/T4216+//kqXLl3o1asXl1xyCVu2bAF0Hf313nvvMXToUC688EI6derEkUceyTPPPON7XX9nwk/jp8DT73XLaQx18DSGOngaQx08jZ8OXqjGUEpIBcjevXtxuVxkZGTU2J6RkUFOTk6YomrdvNdN19R/brebSZMmcdxxx3H44YcD1nV0OBykpKTU2FfXsa5Vq1aRkJCA0+lkwoQJvP322wwYMEDXsJnmzJnD8uXLmTZtWp3XdC39N2zYMGbPns28efOYMWMGmzZt4vjjj6egoEDX0U8bN25kxowZHHLIIXzyySdce+21/PWvf+WFF14A9HcmEmj8FHj6vW4ZjaEOjsZQgaEx1MHT+CkwQjWGigpcyCISbtdffz0///xzjXnS4r++ffuyYsUK8vLyeOONNxg7diwLFy4Md1itytatW7nxxhv57LPPiImJCXc4rdro0aN9jwcOHMiwYcPo0aMHr732GrGxsWGMrPVwu90MHTqU//u//wPgyCOP5Oeff2bmzJmMHTs2zNGJSCTRGOrgaAx18DSGCgyNnwIjVGMoVUgFSHp6Ona7vU6H/l27dpGZmRmmqFo373XTNfXPxIkT+eCDD/jyyy/p1q2bb3tmZibl5eXk5ubW2F/XsS6Hw0GfPn0YMmQI06ZNY9CgQfz73//WNWyGZcuWsXv3bo466iiioqKIiopi4cKFPP7440RFRZGRkaFr2UIpKSkceuihrF+/Xr+TfurcuTMDBgyosa1///6+0n39nQk/jZ8CT7/Xzacx1MHTGOrgaQwVHBo/tUyoxlBKSAWIw+FgyJAhzJ8/37fN7XYzf/58hg8fHsbIWq+ePXuSmZlZ45rm5+fz/fff65pWY5omEydO5O233+aLL76gZ8+eNV4fMmQI0dHRNa7junXr2LJli65jE9xuN2VlZbqGzXDqqaeyatUqVqxY4bsNHTqUSy65xPdY17JlCgsL2bBhA507d9bvpJ+OO+64Oku4/+9//6NHjx6A/s5EAo2fAk+/1/7TGCp4NIZqPo2hgkPjp5YJ2RjqIBqvSy1z5swxnU6nOXv2bPOXX34xr776ajMlJcXMyckJd2gRq6CgwPzxxx/NH3/80QTMRx55xPzxxx/N3377zTRN07z//vvNlJQU89133zVXrlxpnnPOOWbPnj3NkpKSMEceOa699lozOTnZXLBggblz507frbi42LfPhAkTzO7du5tffPGFuXTpUnP48OHm8OHDwxh15LntttvMhQsXmps2bTJXrlxp3nbbbaZhGOann35qmqau4cGovkKMaepa+utvf/ubuWDBAnPTpk3mt99+a44cOdJMT083d+/ebZqmrqM/lixZYkZFRZn//Oc/zV9//dV8+eWXzbi4OPOll17y7aO/M+Gn8VPzafwUGBpDBYbGUMGjMVTzafwUGKEaQykhFWBPPPGE2b17d9PhcJjHHHOMuXjx4nCHFNG+/PJLE6hzGzt2rGma1nKSd9xxh5mRkWE6nU7z1FNPNdetWxfeoCNMfdcPMJ9//nnfPiUlJeZ1111npqammnFxceYf//hHc+fOneELOgJdccUVZo8ePUyHw2F27NjRPPXUU30DKdPUNTwYtQdTupb+ufjii83OnTubDofD7Nq1q3nxxReb69ev972u6+if999/3zz88MNNp9Np9uvXz3z66adrvK6/M5FB46fm0fgpMDSGCgyNoYJHY6jm0/gpcEIxhjJM0zSbVbslIiIiIiIiIiJyENRDSkREREREREREQkoJKRERERERERERCSklpEREREREREREJKSUkBIRERERERERkZBSQkpEREREREREREJKCSkREREREREREQkpJaRERERERERERCSklJASEREREREREZGQUkJKRFqlG2+8kauvvhq32x3uUERERERaBY2fRCSSKCElIq3O1q1b6du3L0899RQ2m/5vTERERKQpGj+JSKQxTNM0wx2EiIiIiIiIiIi0H0qNi0ircfnll2MYRp3bGWecEe7QRERERCKSxk8iEqmiwh2AiEhznHHGGTz//PM1tjmdzjBFIyIiIhL5NH4SkUikCikRaVWcTieZmZk1bqmpqQAYhsGMGTMYPXo0sbGx9OrVizfeeKPG8atWreKUU04hNjaWDh06cPXVV1NYWFhjn1mzZnHYYYfhdDrp3LkzEydO9L32yCOPcMQRRxAfH09WVhbXXXddjeN/++03zjrrLFJTU4mPj+ewww7jo48+CuIVEREREWmcxk8iEomUkBKRNuWOO+7g/PPP56effuKSSy7hT3/6E2vWrAGgqKiIUaNGkZqayg8//MDrr7/O559/XmPANGPGDK6//nquvvpqVq1axXvvvUefPn18r9tsNh5//HFWr17NCy+8wBdffMEtt9zie/3666+nrKyMr776ilWrVvHAAw+QkJAQugsgIiIi0kwaP4lIWJgiIq3E2LFjTbvdbsbHx9e4/fOf/zRN0zQBc8KECTWOGTZsmHnttdeapmmaTz/9tJmammoWFhb6Xv/www9Nm81m5uTkmKZpml26dDFvv/12v2N6/fXXzQ4dOvieH3HEEebUqVNb/BlFREREAknjJxGJVOohJSKtysknn8yMGTNqbEtLS/M9Hj58eI3Xhg8fzooVKwBYs2YNgwYNIj4+3vf6cccdh9vtZt26dRiGwY4dOzj11FMbfP/PP/+cadOmsXbtWvLz86msrKS0tJTi4mLi4uL461//yrXXXsunn37KyJEjOf/88xk4cGAAPrmIiIhIy2j8JCKRSFP2RKRViY+Pp0+fPjVu1QdUByM2NrbR1zdv3swf/vAHBg4cyJtvvsmyZcuYPn06AOXl5QBcddVVbNy4kcsuu4xVq1YxdOhQnnjiiYDEJyIiItISGj+JSCRSQkpE2pTFixfXed6/f38A+vfvz08//URRUZHv9W+//RabzUbfvn1JTEwkOzub+fPn13vuZcuW4Xa7efjhhzn22GM59NBD2bFjR539srKymDBhAm+99RZ/+9vfeOaZZwL4CUVEREQCS+MnEQkHTdkTkValrKyMnJycGtuioqJIT08H4PXXX2fo0KH87ne/4+WXX2bJkiU899xzAFxyySXcddddjB07lqlTp7Jnzx5uuOEGLrvsMjIyMgCYOnUqEyZMoFOnTowePZqCggK+/fZbbrjhBvr06UNFRQVPPPEEZ511Ft9++y0zZ86sEcukSZMYPXo0hx56KAcOHODLL7/0DehEREREwkHjJxGJSOFuYiUi4q+xY8eaQJ1b3759TdO0mnJOnz7dPO2000yn02lmZ2ebc+fOrXGOlStXmieffLIZExNjpqWlmePHjzcLCgpq7DNz5kyzb9++ZnR0tNm5c2fzhhtu8L32yCOPmJ07dzZjY2PNUaNGmf/9739NwDxw4IBpmqY5ceJEs3fv3qbT6TQ7duxoXnbZZebevXuDe2FEREREGqDxk4hEKsM0TTMciTARkUAzDIO3336bc889N9yhiIiIiLQKGj+JSLioh5SIiIiIiIiIiISUElIiIiIiIiIiIhJSmrInIiIiIiIiIiIhpQopEREREREREREJKSWkREREREREREQkpJSQEhERERERERGRkFJCSkREREREREREQkoJKRERERERERERCSklpEREREREREREJKSUkBIRERERERERkZBSQkpEREREREREREJKCSkREREREREREQmp/w9ok6Bax6p9UQAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Métricas de entrenamiento:\n","MSE: 0.276271808996558\n","RMSE: 0.5256156475948542\n","MAE: 0.32004665533869747\n","R^2: 0.4059471779553394\n","Correlación de Pearson: 2.0190981739074587e-16\n","Correlación de Spearman: 0.6381994937369364\n","SSE: 6009.407036164139\n","SAE: 5074.966400497307\n","Media del error: 0.06369365491864376\n","Desviación estándar del error: 0.8402018946241557\n","Huber Loss (Entrenamiento): 0.05836803466081619\n","\n","Métricas de validación:\n","MSE: 0.20862554135729314\n","RMSE: 0.4567554502765053\n","MAE: 0.31942150631276056\n","R^2: 0.6579447607302339\n","Correlación de Pearson: -1.4611895041535894e-16\n","Correlación de Spearman: 0.7045454545454546\n","SSE: 482.6116491930593\n","SAE: 365.322645639691\n","Media del error: -0.0013588105233351868\n","Desviación estándar del error: 0.955147899221077\n","Huber Loss (Validación): 0.12143297493457794\n","El punto de convergencia (mejor epoch): 9\n"]}],"source":["# Graficar las curvas de aprendizaje (entrenamiento y validación)\n","plt.figure(figsize=(12, 8))\n","\n","plt.subplot(2, 2, 1)\n","plt.plot(history.history['loss'], label='Entrenamiento')\n","plt.plot(history.history['val_loss'], label='Validación')\n","plt.title('Pérdida (Loss - Huber) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Pérdida (Loss)')\n","plt.legend()\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(history.history['mae'], label='Entrenamiento')\n","plt.plot(history.history['val_mae'], label='Validación')\n","plt.title('Error Absoluto Medio (MAE) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MAE')\n","plt.legend()\n","\n","plt.subplot(2, 2, 3)\n","plt.plot(history.history['mse'], label='Entrenamiento')\n","plt.plot(history.history['val_mse'], label='Validación')\n","plt.title('Error Cuadrático Medio (MSE) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MSE')\n","plt.legend()\n","\n","plt.subplot(2, 2, 4)\n","plt.plot(history.history['huber_loss'], label='Huber Loss Entrenamiento')\n","plt.plot(history.history['val_huber_loss'], label='Huber Loss Validación')\n","plt.title('Huber Loss durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Huber Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Graficar los datos entrenados vs reales y validados vs reales\n","y_train_pred = model.predict(X_train)\n","y_val_pred = model.predict(X_val)\n","\n","plt.figure(figsize=(12, 6))\n","\n","# Gráfico de datos de entrenamiento\n","plt.subplot(1, 2, 1)\n","plt.scatter(y_train, y_train_pred, alpha=0.3)\n","plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Datos de Entrenamiento')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","# Gráfico de datos de validación\n","plt.subplot(1, 2, 2)\n","plt.scatter(y_val, y_val_pred, alpha=0.3)\n","plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Datos de Validación')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Función para calcular la media y desviación estándar\n","def calcular_media_desviacion(y_true, y_pred):\n","    diferencia = y_true - y_pred\n","    media = np.mean(diferencia)\n","    desviacion = np.std(diferencia)\n","    return media, desviacion\n","\n","# Evaluar el modelo final en el conjunto de entrenamiento\n","mse_train = mean_squared_error(y_train, y_train_pred)\n","mae_train = mean_absolute_error(y_train, y_train_pred)\n","rmse_train = np.sqrt(mse_train)\n","r2_train = r2_score(y_train, y_train_pred)\n","pearson_train = pearson_correlation(y_train, y_train_pred).numpy()\n","spearman_train, _ = spearmanr(y_train, y_train_pred)  # Correlación de Spearman\n","sse_train = np.sum((y_train - y_train_pred) ** 2)\n","sae_train = np.sum(np.abs(y_train - y_train_pred))\n","media_train, desviacion_train = calcular_media_desviacion(y_train, y_train_pred)\n","huber_loss_train = history.history['huber_loss'][-1]\n","\n","print(\"\\nMétricas de entrenamiento:\")\n","print(f\"MSE: {mse_train}\")\n","print(f\"RMSE: {rmse_train}\")\n","print(f\"MAE: {mae_train}\")\n","print(f\"R^2: {r2_train}\")\n","print(f\"Correlación de Pearson: {pearson_train}\")\n","print(f\"Correlación de Spearman: {spearman_train}\")\n","print(f\"SSE: {sse_train}\")\n","print(f\"SAE: {sae_train}\")\n","print(f\"Media del error: {media_train}\")\n","print(f\"Desviación estándar del error: {desviacion_train}\")\n","print(f\"Huber Loss (Entrenamiento): {huber_loss_train}\")\n","\n","# Evaluar el modelo final en el conjunto de validación\n","mse_val = mean_squared_error(y_val, y_val_pred)\n","mae_val = mean_absolute_error(y_val, y_val_pred)\n","rmse_val = np.sqrt(mse_val)\n","r2_val = r2_score(y_val, y_val_pred)\n","pearson_val = pearson_correlation(y_val, y_val_pred).numpy()\n","spearman_val, _ = spearmanr(y_val, y_val_pred)  # Correlación de Spearman\n","sse_val = np.sum((y_val - y_val_pred) ** 2)\n","sae_val = np.sum(np.abs(y_val - y_val_pred))\n","media_val, desviacion_val = calcular_media_desviacion(y_val, y_val_pred)\n","huber_loss_val = history.history['val_huber_loss'][-1]\n","\n","print(\"\\nMétricas de validación:\")\n","print(f\"MSE: {mse_val}\")\n","print(f\"RMSE: {rmse_val}\")\n","print(f\"MAE: {mae_val}\")\n","print(f\"R^2: {r2_val}\")\n","print(f\"Correlación de Pearson: {pearson_val}\")\n","print(f\"Correlación de Spearman: {spearman_val}\")\n","print(f\"SSE: {sse_val}\")\n","print(f\"SAE: {sae_val}\")\n","print(f\"Media del error: {media_val}\")\n","print(f\"Desviación estándar del error: {desviacion_val}\")\n","print(f\"Huber Loss (Validación): {huber_loss_val}\")\n","\n","# Imprimir la época en la que se alcanzó la mejor validación\n","best_epoch = np.argmin(history.history['val_loss']) + 1\n","print(f\"El punto de convergencia (mejor epoch): {best_epoch}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"K71LbvUpoBQT","outputId":"b3d40b0c-afbb-4440-c3fd-03af12963bec","executionInfo":{"status":"ok","timestamp":1726378282938,"user_tz":300,"elapsed":48692,"user":{"displayName":"Johan Coronado Herrera","userId":"00703545902433518266"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n","WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7abc655f8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n","WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7abbd4222200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 4 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Simulación de cross_val_score (MSE): 0.275037561602259 ± 0.14268626843268664\n","Simulación de cross_val_score (RMSE): 0.5103283756320647 ± 0.12084084833779203\n","Simulación de cross_val_score (MAE): 0.3440116113658143 ± 0.08758741996184051\n","SSE promedio: 425.45546235736504\n","SAE promedio: 337.41588919230446\n","R^2 promedio: 0.43829282905267897, Desviación estándar: 0.15417246769653437\n","Correlación de Pearson promedio: -1.5270764979406993e-18, Desviación estándar: 1.7314304723206964e-16\n","Correlación de Spearman promedio: 0.7166677981127957, Desviación estándar: 0.04906030101567886\n","Huber Loss promedio: 0.04743613116443157, Desviación estándar: 0.014852699496122066\n","El punto de convergencia (mejor epoch): 49\n"]}],"source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from scipy.stats import spearmanr\n","import numpy as np\n","\n","# Definir el número de pliegues (k) para la validación cruzada\n","k = 5\n","\n","# Crear un objeto KFold\n","kf = KFold(n_splits=k, shuffle=True, random_state=42)\n","\n","# Inicializar listas para almacenar las métricas en cada pliegue\n","mse_scores = []\n","mae_scores = []\n","sse_scores = []\n","sae_scores = []\n","r2_scores = []\n","pearson_scores = []\n","rmse_scores = []\n","spearman_scores = []\n","huber_loss_scores = []\n","\n","# Iterar sobre los pliegues\n","for train_index, val_index in kf.split(X):\n","    X_train, X_val = X[train_index], X[val_index]\n","    y_train, y_val = y[train_index], y[val_index]\n","\n","    # Crear y entrenar el modelo con los datos del pliegue actual\n","    model = Sequential([\n","        Dense(int(best_params['units_1']), input_dim=X_train.shape[1], kernel_regularizer=tf.keras.regularizers.l2(0.001)), # Access units_1 from best_params\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(best_params['units_2']), kernel_regularizer=tf.keras.regularizers.l2(0.001)), # Access units_2 from best_params\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(best_params['units_3']), kernel_regularizer=tf.keras.regularizers.l2(0.001)), # Access units_3 from best_params\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(best_params['units_4']), kernel_regularizer=tf.keras.regularizers.l2(0.001)), # Access units_4 from best_params\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(int(best_params['units_5']), kernel_regularizer=tf.keras.regularizers.l2(0.001)), # Access units_5 from best_params\n","        LeakyReLU(alpha=0.1),  # Cambiar ELU por LeakyReLU\n","        BatchNormalization(momentum=0.8),\n","\n","        Dense(1, activation='linear')\n","    ])\n","\n","    # Función personalizada para calcular SSE\n","    def sse(y_true, y_pred):\n","        return tf.reduce_sum(tf.square(y_true - y_pred))\n","\n","    # Función personalizada para calcular SAE\n","    def sae(y_true, y_pred):\n","        return tf.reduce_sum(tf.abs(y_true - y_pred))\n","\n","    # Función personalizada para calcular el coeficiente de determinación R^2\n","    def r2_keras(y_true, y_pred):\n","        ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n","        ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n","        return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n","\n","    # Función personalizada para calcular el coeficiente de correlación de Pearson\n","    def pearson_correlation(y_true, y_pred):\n","        y_true = tf.cast(y_true, tf.float64)  # Cast y_true to float64\n","        y_pred = tf.cast(y_pred, tf.float64)  # Cast y_pred to float64\n","        x = y_true - tf.reduce_mean(y_true)\n","        y = y_pred - tf.reduce_mean(y_pred)\n","        r_num = tf.reduce_sum(x * y)\n","        r_den = tf.sqrt(tf.reduce_sum(tf.square(x)) * tf.reduce_sum(tf.square(y)))\n","        return r_num / (r_den + tf.keras.backend.epsilon())\n","\n","    model.compile(optimizer=RMSprop(best_params['learning_rate']),#------------------------------------\n","                  loss=tf.keras.losses.Huber(),                      #---------------------\n","                  metrics=['mae', 'mse', sse, sae, r2_keras, pearson_correlation, tf.keras.losses.Huber(name='huber_loss')])\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True) #-----------------------50\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n","\n","    history = model.fit(X_train, y_train,\n","                        validation_data=(X_val, y_val),\n","                        epochs=1000, #--------------------------1000\n","                        batch_size=64,\n","                        callbacks=[early_stopping, reduce_lr],\n","                        verbose=0)\n","\n","    # Predecir con el modelo en el conjunto de validación\n","    y_pred = model.predict(X_val)\n","\n","    # Calcular las métricas de error\n","    mse = mean_squared_error(y_val, y_pred)\n","    rmse = np.sqrt(mse)\n","    mae = mean_absolute_error(y_val, y_pred)\n","    sse = np.sum((y_val - y_pred) ** 2)\n","    sae = np.sum(np.abs(y_val - y_pred))\n","    r2 = r2_score(y_val, y_pred)\n","    pearson = pearson_correlation(y_val, y_pred).numpy()\n","    spearman, _ = spearmanr(y_val, y_pred)\n","    huber_loss = history.history['huber_loss'][-1]\n","\n","    # Almacenar las métricas en las listas\n","    mse_scores.append(mse)\n","    rmse_scores.append(rmse)\n","    mae_scores.append(mae)\n","    sse_scores.append(sse)\n","    sae_scores.append(sae)\n","    r2_scores.append(r2)\n","    pearson_scores.append(pearson)\n","    spearman_scores.append(spearman)\n","    huber_loss_scores.append(huber_loss)\n","\n","import matplotlib.pyplot as plt\n","\n","# Graficar las curvas de aprendizaje (pérdida, huber_loss, mse, mae)\n","plt.figure(figsize=(12, 8))\n","\n","# Pérdida (Loss)\n","plt.subplot(2, 2, 1)\n","plt.plot(history.history['loss'], label='Entrenamiento')\n","plt.plot(history.history['val_loss'], label='Prueba')\n","plt.title('Pérdida (Loss) durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Pérdida (Loss)')\n","plt.legend()\n","\n","# Huber Loss\n","plt.subplot(2, 2, 2)\n","plt.plot(history.history['huber_loss'], label='Huber Loss Entrenamiento')\n","plt.plot(history.history['val_huber_loss'], label='Huber Loss Prueba')\n","plt.title('Huber Loss durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Huber Loss')\n","plt.legend()\n","\n","# MSE\n","plt.subplot(2, 2, 3)\n","plt.plot(history.history['mse'], label='Entrenamiento')\n","plt.plot(history.history['val_mse'], label='Prueba')\n","plt.title('MSE durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MSE')\n","plt.legend()\n","\n","# MAE\n","plt.subplot(2, 2, 4)\n","plt.plot(history.history['mae'], label='Entrenamiento')\n","plt.plot(history.history['val_mae'], label='Prueba')\n","plt.title('MAE durante el entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('MAE')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Gráfico de predicciones en los datos de entrenamiento\n","y_train_pred = model.predict(X_train)\n","y_val_pred = model.predict(X_val)\n","\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.scatter(y_train, y_train_pred, alpha=0.3)\n","plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Entrenamiento')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","plt.subplot(1, 2, 2)\n","plt.scatter(y_val, y_val_pred, alpha=0.3)\n","plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r', lw=2)\n","plt.title('Predicción vs Real - Prueba')\n","plt.xlabel('Valor Real')\n","plt.ylabel('Valor Predicho')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Calcular estadísticas de las métricas\n","mse_mean = np.mean(mse_scores)\n","mse_std = np.std(mse_scores)\n","rmse_mean = np.mean(rmse_scores)\n","rmse_std = np.std(rmse_scores)\n","mae_mean = np.mean(mae_scores)\n","mae_std = np.std(mae_scores)\n","sse_mean = np.mean(sse_scores)\n","sae_mean = np.mean(sae_scores)\n","r2_mean = np.mean(r2_scores)\n","r2_std = np.std(r2_scores)\n","pearson_mean = np.mean(pearson_scores)\n","pearson_std = np.std(pearson_scores)\n","spearman_mean = np.mean(spearman_scores)\n","spearman_std = np.std(spearman_scores)\n","huber_loss_mean = np.mean(huber_loss_scores)\n","huber_loss_std = np.std(huber_loss_scores)\n","\n","# Simular cross_val_score al imprimir el promedio de las métricas\n","print(f\"Simulación de cross_val_score (MSE): {mse_mean} ± {mse_std}\")\n","print(f\"Simulación de cross_val_score (RMSE): {rmse_mean} ± {rmse_std}\")\n","print(f\"Simulación de cross_val_score (MAE): {mae_mean} ± {mae_std}\")\n","print(f\"SSE promedio: {sse_mean}\")\n","print(f\"SAE promedio: {sae_mean}\")\n","print(f\"R^2 promedio: {r2_mean}, Desviación estándar: {r2_std}\")\n","print(f\"Correlación de Pearson promedio: {pearson_mean}, Desviación estándar: {pearson_std}\")\n","print(f\"Correlación de Spearman promedio: {spearman_mean}, Desviación estándar: {spearman_std}\")\n","print(f\"Huber Loss promedio: {huber_loss_mean}, Desviación estándar: {huber_loss_std}\")\n","\n","# Imprimir la época en la que se alcanzó la mejor validación\n","best_epoch = np.argmin(history.history['val_loss']) + 1\n","print(f\"El punto de convergencia (mejor epoch): {best_epoch}\")"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1EATYBn5pRBQR-y6UtnACmeBPxL8IJfMZ","timestamp":1725907861504},{"file_id":"1r_JM6X0nvIs1tPxWdSL2ks_3znzQkbU3","timestamp":1725900803257},{"file_id":"1q_AARXwxesxS8p5h5DHxPu87f4W90Piu","timestamp":1725671031145},{"file_id":"1Iu7gaS-rMsag8yv6B7u5GyAGYgzlNMQo","timestamp":1725668219370},{"file_id":"1lc3MJOj5LnHhLKbPODnyWxrF2Qy18W40","timestamp":1725653291124},{"file_id":"1T8NuI3Vdm1GKDP6FHv5YfZpFRzCB8yJ0","timestamp":1725647067341},{"file_id":"1YEO6Z9OG6wghZ9hpgw22ZlghESt248yh","timestamp":1725642363686},{"file_id":"1Nftb0ZvXUIvmIoKXWo8gsG9ZgxkRB4Pj","timestamp":1725416240579},{"file_id":"148WaN3mx63rXNhUjGCfDYS00LlaCs-lN","timestamp":1725371486778},{"file_id":"1zqXXtvghnQzJCVVcEU9S4N-28Q_GdjyF","timestamp":1725306949217},{"file_id":"1zDXIbxi0v_uZmIa1CWqiBcBHDxLnKk63","timestamp":1725036289643}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}